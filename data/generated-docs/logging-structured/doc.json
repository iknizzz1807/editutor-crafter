{"html":"<h1 id=\"structured-logging-system-design-document\">Structured Logging System: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A production-grade structured logging system that provides thread-safe, multi-level logging with JSON output and distributed request tracing. The key architectural challenge is designing a flexible handler dispatch system that maintains performance while supporting context propagation across async boundaries.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational context for all milestones by establishing why structured logging is essential and what challenges it solves in production environments.</p>\n</blockquote>\n<h3 id=\"the-airport-control-tower-analogy\">The Airport Control Tower Analogy</h3>\n<p>Think of traditional logging in software systems like early aviation communication — pilots would occasionally radio in their status using informal, unstructured messages: &quot;Approaching from the southeast, low on fuel, weather looks rough.&quot; This worked when there were only a few planes in the sky, but as air traffic grew exponentially, this ad-hoc communication created chaos. Controllers couldn&#39;t quickly filter messages by urgency, correlate related communications from the same flight, or efficiently route information to the right teams.</p>\n<p>Modern air traffic control solved this through <strong>structured communication protocols</strong>. Every radio transmission follows a standardized format: aircraft identification, location coordinates, altitude, heading, fuel status, and request type — all in predictable fields that controllers can instantly parse, filter, and route. A controller can immediately spot all &quot;low fuel&quot; situations, trace the complete journey of flight AA1234, or correlate weather reports with affected routes.</p>\n<p>This transformation mirrors exactly what happens when software systems evolve from traditional logging to structured logging. In small applications with a single developer, informal log messages work fine: &quot;User login failed&quot;, &quot;Database connection lost&quot;, &quot;Processing order 12345&quot;. But in production environments with hundreds of services, millions of requests, and distributed teams, these unstructured logs become as chaotic as those early aviation radio calls.</p>\n<p><strong>Structured logging</strong> transforms each log entry into a standardized &quot;flight plan&quot; with consistent fields: timestamp, severity level, service name, request ID, user ID, operation type, and contextual metadata. Operations teams can instantly filter by error severity, trace all actions for a specific user request, correlate events across multiple services, and route alerts to the appropriate team — just like air traffic controllers managing complex airspace.</p>\n<p>The analogy extends to <strong>correlation IDs</strong> (like flight numbers that persist across different control zones), <strong>log levels</strong> (like priority codes for emergency vs. routine communications), and <strong>context propagation</strong> (like flight plans that follow aircraft across multiple control centers). Without this structure, debugging production issues becomes like searching for a specific airplane in busy airspace using only fragments of overheard conversations.</p>\n<h3 id=\"traditional-vs-structured-logging\">Traditional vs Structured Logging</h3>\n<p>The fundamental difference between traditional and structured logging lies in <strong>queryability</strong> and <strong>context preservation</strong>. Traditional logging treats each log message as an opaque string, while structured logging treats it as a data record with well-defined fields that can be indexed, filtered, and aggregated.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Traditional String Logs</th>\n<th>Structured JSON Logs</th>\n<th>Impact on Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Format</strong></td>\n<td><code>&quot;2024-01-15 ERROR: Login failed for user john_doe&quot;</code></td>\n<td><code>{&quot;timestamp&quot;: &quot;2024-01-15T10:30:00Z&quot;, &quot;level&quot;: &quot;ERROR&quot;, &quot;event&quot;: &quot;login_failed&quot;, &quot;user_id&quot;: &quot;john_doe&quot;, &quot;ip_address&quot;: &quot;192.168.1.100&quot;}</code></td>\n<td>Structured logs enable precise queries like &quot;all login failures from IP range X&quot;</td>\n</tr>\n<tr>\n<td><strong>Parsing</strong></td>\n<td>Requires regex patterns, brittle text parsing</td>\n<td>Direct JSON deserialization into typed objects</td>\n<td>10x faster log ingestion, no parsing errors</td>\n</tr>\n<tr>\n<td><strong>Searchability</strong></td>\n<td>Full-text search only: <code>grep &quot;Login failed&quot; logfile</code></td>\n<td>Field-specific queries: <code>level:ERROR AND event:login_failed</code></td>\n<td>Precise filtering reduces noise from millions of log entries</td>\n</tr>\n<tr>\n<td><strong>Context Linking</strong></td>\n<td>Manual correlation using scattered string fragments</td>\n<td>Automatic correlation via request_id field</td>\n<td>Complete request trace across 20+ microservices</td>\n</tr>\n<tr>\n<td><strong>Alerting Rules</strong></td>\n<td>Complex regex patterns: <code>/ERROR.*database.*timeout/</code></td>\n<td>Simple field matching: <code>level:ERROR AND component:database AND error_type:timeout</code></td>\n<td>Fewer false positives, faster alert setup</td>\n</tr>\n<tr>\n<td><strong>Aggregation</strong></td>\n<td>Impossible without custom parsing scripts</td>\n<td>Built-in: <code>GROUP BY error_type</code>, <code>COUNT by user_id</code></td>\n<td>Real-time dashboards showing error trends</td>\n</tr>\n<tr>\n<td><strong>Multi-line Handling</strong></td>\n<td>Stack traces break log parsers, require special handling</td>\n<td>Stack trace stored as structured field, never breaks parsing</td>\n<td>Reliable log shipping even with complex Java exceptions</td>\n</tr>\n<tr>\n<td><strong>Performance</strong></td>\n<td>String concatenation, formatting overhead</td>\n<td>Direct object serialization, minimal string operations</td>\n<td>50% reduction in logging CPU overhead</td>\n</tr>\n<tr>\n<td><strong>Schema Evolution</strong></td>\n<td>Adding fields breaks existing parsers</td>\n<td>New fields automatically available, backward compatible</td>\n<td>Zero-downtime log format improvements</td>\n</tr>\n<tr>\n<td><strong>Debugging Workflow</strong></td>\n<td><code>grep</code> → <code>awk</code> → manual correlation → spreadsheet analysis</td>\n<td>Direct database queries → automatic correlation → interactive dashboards</td>\n<td>5 minutes instead of 2 hours to diagnose issues</td>\n</tr>\n</tbody></table>\n<p>The transition from traditional to structured logging parallels the evolution from manually parsing log files to treating logs as a <strong>time-series database</strong>. Each log entry becomes a data point with dimensions (service, user, operation) and metrics (response time, error rate, resource usage) that can be aggregated, visualized, and analyzed in real-time.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: The value of structured logging grows exponentially with system complexity. A monolithic application with 100 daily requests might not benefit significantly, but a microservices architecture handling 10,000 requests per second across 50 services becomes impossible to debug without structured, correlated logs.</p>\n</blockquote>\n<h3 id=\"production-environment-challenges\">Production Environment Challenges</h3>\n<p>Production logging systems face four critical challenges that simple print statements or basic file logging cannot address: <strong>thread safety</strong>, <strong>performance at scale</strong>, <strong>distributed correlation</strong>, and <strong>operational reliability</strong>. Each challenge requires specific architectural decisions that shape the entire logging system design.</p>\n<h4 id=\"thread-safety-and-concurrent-access\">Thread Safety and Concurrent Access</h4>\n<p>In production environments, multiple threads simultaneously generate log messages, creating <strong>race conditions</strong> that can corrupt output, interleave partial messages, or cause deadlocks. The challenge extends beyond simple file writing to include context management, formatter state, and handler dispatch.</p>\n<table>\n<thead>\n<tr>\n<th>Challenge</th>\n<th>Manifestation</th>\n<th>Technical Requirement</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Interleaved Output</strong></td>\n<td>Two threads writing &quot;User login&quot; and &quot;Database query&quot; produce garbled output: <code>&quot;User Datalogbase quin&quot;</code></td>\n<td>Atomic write operations with message-level locking</td>\n</tr>\n<tr>\n<td><strong>Corrupted JSON</strong></td>\n<td>Concurrent JSON serialization creates invalid output: <code>{&quot;level&quot;:&quot;INFO&quot;&quot;level&quot;:&quot;ERROR&quot;}</code></td>\n<td>Thread-safe formatter instances or per-thread serialization buffers</td>\n</tr>\n<tr>\n<td><strong>Context Confusion</strong></td>\n<td>Thread A&#39;s user_id appears in Thread B&#39;s log messages</td>\n<td>Thread-local context storage with proper isolation boundaries</td>\n</tr>\n<tr>\n<td><strong>Handler State</strong></td>\n<td>File handles, network connections shared unsafely between threads</td>\n<td>Synchronized handler operations or thread-safe I/O abstractions</td>\n</tr>\n<tr>\n<td><strong>Deadlock Risk</strong></td>\n<td>Complex locking hierarchies between logger, handlers, and formatters</td>\n<td>Careful lock ordering and non-blocking dispatch patterns</td>\n</tr>\n</tbody></table>\n<p>The thread safety challenge is compounded by <strong>async/await patterns</strong> in modern applications. When an async task yields control, its logging context must be preserved and restored correctly, even when the task resumes on a different thread. This requires sophisticated context propagation mechanisms that go beyond simple thread-local storage.</p>\n<h4 id=\"performance-at-scale\">Performance at Scale</h4>\n<p>Production logging systems must handle thousands of log messages per second while adding minimal overhead to application performance. The challenge involves both <strong>computational efficiency</strong> (CPU cycles for formatting and serialization) and <strong>I/O efficiency</strong> (disk writes and network transmission).</p>\n<table>\n<thead>\n<tr>\n<th>Scale Factor</th>\n<th>Performance Requirement</th>\n<th>Design Implication</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Message Volume</strong></td>\n<td>10,000+ messages/second per service</td>\n<td>Non-blocking handler dispatch, async I/O operations</td>\n</tr>\n<tr>\n<td><strong>Context Size</strong></td>\n<td>50+ fields per message (user, request, trace data)</td>\n<td>Efficient context merging, lazy field evaluation</td>\n</tr>\n<tr>\n<td><strong>Handler Count</strong></td>\n<td>5+ destinations per message (file, stdout, metrics, remote)</td>\n<td>Parallel handler execution, failure isolation</td>\n</tr>\n<tr>\n<td><strong>Memory Pressure</strong></td>\n<td>Minimal allocation in hot logging path</td>\n<td>Object pooling, pre-allocated buffers, zero-copy serialization</td>\n</tr>\n<tr>\n<td><strong>Latency Sensitivity</strong></td>\n<td>&lt;1ms added latency to business logic</td>\n<td>Background processing, batched network operations</td>\n</tr>\n</tbody></table>\n<p>The performance challenge creates tension between <strong>completeness</strong> and <strong>speed</strong>. Adding rich context improves debugging capability but increases serialization cost. The solution requires <strong>lazy evaluation</strong> strategies where expensive operations (like stack trace capture or large object serialization) only occur when the log level threshold is met.</p>\n<blockquote>\n<p><strong>Design Principle</strong>: The hot path for logging (from application call to handler dispatch) must remain synchronous and fast, while expensive operations (network transmission, disk syncing, complex formatting) should be asynchronous and non-blocking.</p>\n</blockquote>\n<h4 id=\"distributed-correlation-across-services\">Distributed Correlation Across Services</h4>\n<p>Modern applications span multiple services, each generating independent log streams. The critical challenge is <strong>correlating related events</strong> across service boundaries to reconstruct complete user request flows or diagnose cross-service failures.</p>\n<table>\n<thead>\n<tr>\n<th>Correlation Scenario</th>\n<th>Technical Challenge</th>\n<th>Required Infrastructure</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>User Request Trace</strong></td>\n<td>HTTP request flows through 8 services, each logs independently</td>\n<td>Correlation ID propagation via HTTP headers and message queues</td>\n</tr>\n<tr>\n<td><strong>Database Transaction</strong></td>\n<td>Single transaction touches 3 services, fails in service 2</td>\n<td>Transaction ID preservation across service calls and rollbacks</td>\n</tr>\n<tr>\n<td><strong>Background Job Chain</strong></td>\n<td>Job spawns 5 child jobs across different workers</td>\n<td>Parent-child job ID relationships with hierarchical context</td>\n</tr>\n<tr>\n<td><strong>Error Cascade</strong></td>\n<td>Timeout in service A causes errors in services B, C, D</td>\n<td>Temporal correlation with root cause identification</td>\n</tr>\n<tr>\n<td><strong>Performance Investigation</strong></td>\n<td>Slow response affects multiple upstream services</td>\n<td>Request timing correlation with service dependency mapping</td>\n</tr>\n</tbody></table>\n<p>The correlation challenge requires <strong>context propagation protocols</strong> that work across different transport mechanisms (HTTP headers, message queue properties, gRPC metadata) and programming languages. The logging system must automatically extract correlation IDs from incoming requests and inject them into outgoing requests without requiring explicit developer intervention.</p>\n<h4 id=\"log-aggregation-and-operational-requirements\">Log Aggregation and Operational Requirements</h4>\n<p>Production environments generate terabytes of log data daily, requiring <strong>reliable collection</strong>, <strong>efficient transport</strong>, and <strong>fault-tolerant storage</strong>. The logging system must handle network failures, disk space exhaustion, and downstream service outages without losing critical diagnostic information.</p>\n<table>\n<thead>\n<tr>\n<th>Operational Challenge</th>\n<th>Failure Mode</th>\n<th>Recovery Mechanism</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Network Partition</strong></td>\n<td>Remote log collector becomes unreachable for 30 minutes</td>\n<td>Local buffering with disk spillover, automatic retry with exponential backoff</td>\n</tr>\n<tr>\n<td><strong>Disk Space Exhaustion</strong></td>\n<td>Log files consume all available disk space</td>\n<td>Automatic log rotation, compression, oldest-first deletion with retention policies</td>\n</tr>\n<tr>\n<td><strong>Handler Failure</strong></td>\n<td>Elasticsearch cluster goes down, losing audit logs</td>\n<td>Multi-destination dispatch with independent failure domains</td>\n</tr>\n<tr>\n<td><strong>Configuration Errors</strong></td>\n<td>Invalid JSON formatter crashes logging pipeline</td>\n<td>Graceful degradation to plain text output, error isolation per handler</td>\n</tr>\n<tr>\n<td><strong>Memory Pressure</strong></td>\n<td>Log buffering consumes excessive memory during bursts</td>\n<td>Backpressure mechanisms, emergency log level elevation, buffer size limits</td>\n</tr>\n</tbody></table>\n<p>The aggregation challenge extends to <strong>log format evolution</strong>. Production systems must support gradual rollouts of new log fields without breaking existing parsing infrastructure. This requires <strong>schema compatibility strategies</strong> and <strong>version negotiation protocols</strong> between log producers and consumers.</p>\n<blockquote>\n<p><strong>Operational Reality</strong>: In production environments, the logging system itself becomes a critical piece of infrastructure that must be monitored, alerted on, and maintained. Logger failures can mask application issues, making robust error handling and self-monitoring essential design requirements.</p>\n</blockquote>\n<p>These production challenges drive the architectural decisions throughout the logging system design. <strong>Thread safety</strong> requirements shape the locking strategy and context isolation mechanisms. <strong>Performance constraints</strong> determine the handler dispatch architecture and serialization approaches. <strong>Correlation needs</strong> influence the context propagation design and metadata extraction patterns. <strong>Operational requirements</strong> drive error handling strategies and configuration management approaches.</p>\n<p>The next sections will show how each challenge translates into specific design decisions, with Architecture Decision Records (ADRs) documenting the rationale behind each choice and the trade-offs involved.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance provides practical foundations for building the structured logging system, including technology recommendations and starter infrastructure that supports the design principles established above.</p>\n<h4 id=\"a-technology-recommendations\">A. Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>JSON Serialization</strong></td>\n<td><code>json</code> standard library</td>\n<td><code>orjson</code> or <code>ujson</code> for performance</td>\n<td>Standard library provides reliability; advanced options needed for &gt;1000 msgs/sec</td>\n</tr>\n<tr>\n<td><strong>Thread Safety</strong></td>\n<td><code>threading.Lock()</code> with context managers</td>\n<td><code>concurrent.futures</code> with thread pools</td>\n<td>Simple locks work for basic scenarios; thread pools handle async dispatch better</td>\n</tr>\n<tr>\n<td><strong>Context Storage</strong></td>\n<td><code>threading.local()</code> for thread contexts</td>\n<td><code>contextvars</code> for async-compatible contexts</td>\n<td>Thread-local sufficient for sync apps; contextvars required for asyncio applications</td>\n</tr>\n<tr>\n<td><strong>File I/O</strong></td>\n<td>Built-in <code>open()</code> with manual rotation</td>\n<td><code>logging.handlers.RotatingFileHandler</code> adapted</td>\n<td>Manual control for learning; existing handlers provide production-ready features</td>\n</tr>\n<tr>\n<td><strong>Network Transport</strong></td>\n<td><code>requests</code> library for HTTP endpoints</td>\n<td><code>aiohttp</code> for async network operations</td>\n<td>Synchronous requests for simple cases; async required for non-blocking performance</td>\n</tr>\n<tr>\n<td><strong>Configuration</strong></td>\n<td>Python dictionaries and environment variables</td>\n<td><code>pydantic</code> for validated configuration schemas</td>\n<td>Dict-based config sufficient for core functionality; validation prevents runtime errors</td>\n</tr>\n</tbody></table>\n<h4 id=\"b-recommended-filemodule-structure\">B. Recommended File/Module Structure</h4>\n<p>Organize the logging system with clear separation of concerns, making each component testable and maintainable:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n├── __init__.py                    # Public API exports\n├── core/\n│   ├── __init__.py\n│   ├── logger.py                  # Logger class and hierarchy management\n│   ├── levels.py                  # Log level definitions and filtering\n│   ├── records.py                 # LogRecord data structure and factory\n│   └── registry.py                # Logger registry and configuration\n├── handlers/\n│   ├── __init__.py\n│   ├── base.py                    # Abstract handler interface\n│   ├── console.py                 # Stdout/stderr output handlers\n│   ├── file.py                    # File-based output with rotation\n│   └── remote.py                  # HTTP/network destination handlers\n├── formatters/\n│   ├── __init__.py\n│   ├── base.py                    # Abstract formatter interface\n│   ├── json_formatter.py          # Single-line JSON output\n│   └── pretty_formatter.py        # Human-readable colored output\n├── context/\n│   ├── __init__.py\n│   ├── manager.py                 # Context storage and propagation\n│   ├── correlation.py             # Correlation ID generation and tracking\n│   └── middleware.py              # Request context extraction\n├── utils/\n│   ├── __init__.py\n│   ├── serialization.py           # Safe JSON serialization utilities\n│   └── threading_utils.py         # Thread-safe helper functions\n└── tests/\n    ├── unit/                      # Component-specific tests\n    ├── integration/               # Multi-component scenarios\n    └── performance/               # Scalability and benchmark tests</code></pre></div>\n\n<h4 id=\"c-infrastructure-starter-code\">C. Infrastructure Starter Code</h4>\n<p><strong>Thread-Safe Utilities (<code>utils/threading_utils.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, Optional, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeCounter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe counter for correlation ID generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, start: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> start</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> next</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeDict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe dictionary wrapper for shared logger registry.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RWLock() </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(threading, </span><span style=\"color:#9ECBFF\">'RWLock'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.get(key, default)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> keys</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._data.keys())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> timeout_context</span><span style=\"color:#E1E4E8\">(seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for operations that must complete within timeout.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> elapsed </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> seconds:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Warning: Operation took </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">elapsed</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s (timeout: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">seconds</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_call</span><span style=\"color:#E1E4E8\">(func: Callable, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely call function, returning default on any exception.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> default</span></span></code></pre></div>\n\n<p><strong>JSON Serialization Utilities (<code>utils/serialization.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> decimal </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Decimal</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SafeJSONEncoder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">json</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JSONEncoder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"JSON encoder that handles common non-serializable types safely.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> default</span><span style=\"color:#E1E4E8\">(self, obj: Any) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, datetime.datetime):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, datetime.date):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, uuid.</span><span style=\"color:#79B8FF\">UUID</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, Decimal):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__dict__'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Custom objects - serialize their __dict__</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.</span><span style=\"color:#79B8FF\">__dict__</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Exception objects - capture essential info</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'type'</span><span style=\"color:#E1E4E8\">: obj.</span><span style=\"color:#79B8FF\">__class__</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'message'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(obj),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'args'</span><span style=\"color:#E1E4E8\">: obj.args</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Fallback to string representation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_serialize</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Safely serialize dictionary to JSON, handling circular references</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    and limiting depth to prevent infinite recursion.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clean_dict</span><span style=\"color:#E1E4E8\">(obj: Any, depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, seen: Set[</span><span style=\"color:#79B8FF\">id</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> seen </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            seen </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> depth </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> max_depth:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;max_depth_exceeded:</span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(obj).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> id</span><span style=\"color:#E1E4E8\">(obj) </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> seen:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;circular_reference:</span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(obj).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            seen.add(</span><span style=\"color:#79B8FF\">id</span><span style=\"color:#E1E4E8\">(obj))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj.items():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    result[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(k)] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> clean_dict(v, depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, seen.copy())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    result[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(k)] </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;serialization_error:</span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(v).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            seen.add(</span><span style=\"color:#79B8FF\">id</span><span style=\"color:#E1E4E8\">(obj))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> [clean_dict(item, depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, seen.copy()) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> item </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cleaned_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> clean_dict(data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> json.dumps(cleaned_data, </span><span style=\"color:#FFAB70\">cls</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SafeJSONEncoder, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> estimate_serialized_size</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Estimate JSON size without full serialization (for performance).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Quick size estimation for memory management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # Opening and closing braces</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> key, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> data.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(key)) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#6A737D\">  # Key + quotes + colon + comma</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(value) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # String + quotes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, (</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(value))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> estimate_serialized_size(value)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#6A737D\">  # Rough estimate for other types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> size</span></span></code></pre></div>\n\n<h4 id=\"d-core-logic-skeleton-code\">D. Core Logic Skeleton Code</h4>\n<p><strong>Base Logger Class (<code>core/logger.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, List, Optional, Union</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> threading </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Lock</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Logger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Core logger class that handles message filtering, context enrichment,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    and dispatch to multiple handlers.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#E1E4E8\">, parent: Optional[</span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.level </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> level</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.parent </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parent</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.handlers: List[</span><span style=\"color:#9ECBFF\">'Handler'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.children: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log</span><span style=\"color:#E1E4E8\">(self, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Main logging method that processes and dispatches log records.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            level: Numeric log level (DEBUG=10, INFO=20, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            message: Human-readable log message</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            **context: Additional key-value pairs to include in log record</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if this log level meets the minimum threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Compare 'level' parameter against self.level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   If level &#x3C; self.level, return early (message filtered out)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create LogRecord object with all required fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Include: timestamp, level, message, logger_name, context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Use time.time() for timestamp, convert to ISO format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Enrich record with context from parent loggers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Walk up parent chain, merging context from each level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Child context should override parent context for same keys</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Enrich record with thread-local context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Get current thread's context from ContextManager</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Merge with record context (record context takes precedence)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Dispatch record to all handlers (thread-safely)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Acquire self._lock before accessing self.handlers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Call handle() method on each handler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Continue dispatching even if some handlers fail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: If no handlers at this level, propagate to parent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Check if self.handlers is empty and self.parent exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   Call self.parent.handle_record(record) to propagate up</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Implementation goes here</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> debug</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log DEBUG level message.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log() with DEBUG level (value: 10)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> info</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log INFO level message.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log() with INFO level (value: 20)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> warn</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log WARN level message.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log() with WARN level (value: 30)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> error</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log ERROR level message.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log() with ERROR level (value: 40)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fatal</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log FATAL level message.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log() with FATAL level (value: 50)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"e-language-specific-hints\">E. Language-Specific Hints</h4>\n<p><strong>Python-Specific Implementation Tips:</strong></p>\n<ul>\n<li><strong>Thread Safety</strong>: Use <code>threading.Lock()</code> with <code>with</code> statements for automatic lock management: <code>with self._lock: # critical section</code></li>\n<li><strong>Context Variables</strong>: For async compatibility, prefer <code>contextvars.ContextVar</code> over <code>threading.local()</code> when targeting Python 3.7+</li>\n<li><strong>JSON Performance</strong>: The standard <code>json</code> library is sufficient for most cases. Use <code>separators=(&#39;,&#39;, &#39;:&#39;)</code> to eliminate whitespace in output</li>\n<li><strong>Time Formatting</strong>: Use <code>datetime.utcnow().isoformat() + &#39;Z&#39;</code> for ISO 8601 timestamps with UTC timezone</li>\n<li><strong>Exception Handling</strong>: Wrap handler calls in <code>try/except</code> blocks to prevent one failing handler from stopping others</li>\n<li><strong>Type Hints</strong>: Use <code>typing</code> module extensively for better IDE support: <code>from typing import Dict, List, Optional, Any</code></li>\n<li><strong>Environment Variables</strong>: Use <code>os.environ.get(&#39;LOG_LEVEL&#39;, &#39;INFO&#39;)</code> for configuration with sensible defaults</li>\n</ul>\n<p><strong>Performance Considerations:</strong></p>\n<ul>\n<li><strong>String Formatting</strong>: Use f-strings for message formatting: <code>f&quot;User {user_id} performed {action}&quot;</code> (fastest in Python 3.6+)</li>\n<li><strong>Dictionary Merging</strong>: Use <code>{**parent_context, **child_context}</code> for efficient context merging</li>\n<li><strong>Level Checking</strong>: Implement early return for filtered messages to avoid expensive context gathering</li>\n<li><strong>Object Pooling</strong>: For high-throughput scenarios, consider reusing LogRecord objects to reduce garbage collection pressure</li>\n</ul>\n<h4 id=\"f-milestone-checkpoint\">F. Milestone Checkpoint</h4>\n<p>After implementing the basic logging foundation, verify correct behavior with these checkpoints:</p>\n<p><strong>Checkpoint 1: Basic Logging Works</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from structured_logging import get_logger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = get_logger('test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('Hello, structured logging!', user_id=123)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n<p>Expected output (to stdout):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">json</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">\"timestamp\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"2024-01-15T10:30:00.123Z\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"level\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"INFO\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"logger\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"test\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"message\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"Hello, structured logging!\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"user_id\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#79B8FF\">123</span><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Checkpoint 2: Level Filtering Works</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.set_level(</span><span style=\"color:#9ECBFF\">'WARN'</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should filter out DEBUG and INFO</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.debug(</span><span style=\"color:#9ECBFF\">'This should not appear'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.info(</span><span style=\"color:#9ECBFF\">'This should not appear'</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.warn(</span><span style=\"color:#9ECBFF\">'This should appear'</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n<p>Expected: Only the WARN message appears in output.</p>\n<p><strong>Checkpoint 3: Thread Safety Works</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'thread_test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> log_worker</span><span style=\"color:#E1E4E8\">(worker_id):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'Message </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">worker_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">worker_id)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">threads </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [threading.Thread(</span><span style=\"color:#FFAB70\">target</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">log_worker, </span><span style=\"color:#FFAB70\">args</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[i]) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> t </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> threads:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    t.start()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> t </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> threads:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    t.join()</span></span></code></pre></div>\n<p>Expected: All 500 messages appear as valid JSON (no interleaved/corrupted output).</p>\n<p><strong>Signs Something Is Wrong:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>What to Check</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No output appears</td>\n<td>Handler not attached or level too high</td>\n<td>Verify handler registration and log level settings</td>\n</tr>\n<tr>\n<td>Garbled JSON output</td>\n<td>Thread safety issues</td>\n<td>Check that handler writes are atomic and properly locked</td>\n</tr>\n<tr>\n<td>Missing context fields</td>\n<td>Context not properly merged</td>\n<td>Verify context propagation from parents and thread-local storage</td>\n</tr>\n<tr>\n<td>Performance degradation</td>\n<td>Blocking I/O in handlers</td>\n<td>Move file/network operations to background threads</td>\n</tr>\n<tr>\n<td>Import errors</td>\n<td>Circular dependencies</td>\n<td>Review module import structure, use delayed imports if needed</td>\n</tr>\n</tbody></table>\n<p>This foundation provides the infrastructure needed to implement the core logging system while maintaining the thread safety, performance, and reliability requirements established in the problem statement.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section defines the scope and success criteria for all three milestones, establishing clear boundaries for what the logging system must accomplish and what it deliberately excludes.</p>\n</blockquote>\n<p>Before diving into technical requirements, it&#39;s essential to establish a clear mental model for what we&#39;re building. Think of our structured logging system as <strong>the nervous system of a distributed application</strong>. Just as your nervous system carries signals from every part of your body to your brain, providing context about what&#39;s happening and allowing you to respond appropriately, our logging system carries structured information from every component of our application to monitoring systems, providing the observability needed to understand, debug, and optimize system behavior.</p>\n<p>Unlike traditional logging, which is like having a collection of disconnected sensors that each speak their own language, structured logging creates a unified communication protocol. Every log message follows the same format, carries consistent metadata, and can be correlated with related messages across the entire system. This transforms debugging from archaeological excavation through text files into surgical precision with queryable, contextual data.</p>\n<p>The challenge in defining goals for a logging system lies in balancing comprehensiveness with focus. Logging touches every aspect of application development—from local debugging to production monitoring, from performance analysis to security auditing. We must be precise about what problems we&#39;re solving while explicitly acknowledging what we&#39;re not building to avoid scope creep and maintain architectural clarity.</p>\n<h3 id=\"functional-requirements\">Functional Requirements</h3>\n<p>The functional requirements define <strong>what</strong> our logging system must do—the concrete behaviors and capabilities that users will interact with directly. These requirements map directly to our three milestones and form the acceptance criteria for successful implementation.</p>\n<p><strong>Log Level Management and Filtering</strong> forms the foundation of our system. The logging system must support five distinct log levels with numeric ordering: <code>DEBUG</code> (10), <code>INFO</code> (20), <code>WARN</code> (30), <code>ERROR</code> (40), and <code>FATAL</code> (50). This hierarchical system allows developers to control the verbosity of their applications by setting a minimum log level threshold. When a logger is configured with level <code>WARN</code>, it suppresses all <code>DEBUG</code> and <code>INFO</code> messages while allowing <code>WARN</code>, <code>ERROR</code>, and <code>FATAL</code> messages to pass through.</p>\n<p>The system must support <strong>runtime configuration changes</strong> without requiring application restarts. A production service running with <code>INFO</code> level should be able to dynamically switch to <code>DEBUG</code> level when troubleshooting issues, then return to <code>INFO</code> level to reduce log volume. This capability is crucial for production debugging scenarios where restarting the application would eliminate the problematic state we&#39;re trying to diagnose.</p>\n<table>\n<thead>\n<tr>\n<th>Log Level</th>\n<th>Numeric Value</th>\n<th>Purpose</th>\n<th>Typical Volume</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>DEBUG</code></td>\n<td>10</td>\n<td>Detailed diagnostic information for development</td>\n<td>Very High</td>\n</tr>\n<tr>\n<td><code>INFO</code></td>\n<td>20</td>\n<td>General application flow and state changes</td>\n<td>Moderate</td>\n</tr>\n<tr>\n<td><code>WARN</code></td>\n<td>30</td>\n<td>Potentially problematic situations</td>\n<td>Low</td>\n</tr>\n<tr>\n<td><code>ERROR</code></td>\n<td>40</td>\n<td>Error conditions that don&#39;t stop the application</td>\n<td>Very Low</td>\n</tr>\n<tr>\n<td><code>FATAL</code></td>\n<td>50</td>\n<td>Critical errors that may cause application termination</td>\n<td>Extremely Rare</td>\n</tr>\n</tbody></table>\n<p><strong>Structured JSON Output</strong> transforms traditional string-based logging into queryable, machine-readable data. Every log record must serialize as valid, single-line JSON containing consistent field names and data types. This structured format enables powerful querying capabilities in log aggregation systems—instead of searching for text patterns, operators can filter by exact field values, perform numeric comparisons on timestamps, and aggregate data across multiple dimensions.</p>\n<p>The JSON output must include these mandatory fields in every log record:</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Data Type</th>\n<th>Description</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>timestamp</code></td>\n<td>string</td>\n<td>ISO 8601 formatted timestamp with millisecond precision</td>\n<td>&quot;2024-01-15T14:30:25.123Z&quot;</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td>string</td>\n<td>Human-readable log level name</td>\n<td>&quot;ERROR&quot;</td>\n</tr>\n<tr>\n<td><code>message</code></td>\n<td>string</td>\n<td>Primary log message content</td>\n<td>&quot;Database connection failed&quot;</td>\n</tr>\n<tr>\n<td><code>logger_name</code></td>\n<td>string</td>\n<td>Hierarchical name identifying the logger</td>\n<td>&quot;service.database.connection&quot;</td>\n</tr>\n<tr>\n<td><code>context</code></td>\n<td>object</td>\n<td>Key-value pairs providing additional metadata</td>\n<td>{&quot;user_id&quot;: &quot;12345&quot;, &quot;request_id&quot;: &quot;req_abc123&quot;}</td>\n</tr>\n</tbody></table>\n<p><strong>Multi-Destination Handler Dispatch</strong> enables log records to flow simultaneously to multiple output destinations. A single log statement might write to local stdout for immediate developer feedback, append to a rotating file for local persistence, and transmit to a remote log collector for centralized aggregation. Each destination operates independently—a failure in one handler must not affect others or block the logging operation.</p>\n<p>The handler dispatch mechanism must support these core handler types:</p>\n<table>\n<thead>\n<tr>\n<th>Handler Type</th>\n<th>Purpose</th>\n<th>Failure Behavior</th>\n<th>Configuration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Console Handler</td>\n<td>Real-time output to stdout/stderr</td>\n<td>Log to stderr and continue</td>\n<td>Format selection (JSON/pretty)</td>\n</tr>\n<tr>\n<td>File Handler</td>\n<td>Local file persistence with rotation</td>\n<td>Create fallback file and continue</td>\n<td>File path, rotation size, retention</td>\n</tr>\n<tr>\n<td>Network Handler</td>\n<td>Remote transmission to log collectors</td>\n<td>Buffer locally and retry</td>\n<td>Endpoint URL, timeout, retry policy</td>\n</tr>\n<tr>\n<td>Memory Handler</td>\n<td>In-process buffering for testing</td>\n<td>Drop oldest entries when full</td>\n<td>Buffer size, overflow behavior</td>\n</tr>\n</tbody></table>\n<p><strong>Context Propagation and Correlation</strong> addresses the critical challenge of connecting related log entries across distributed operations. When a user request spans multiple services, functions, and async operations, the logging system must automatically carry contextual information that allows operators to trace the complete request flow.</p>\n<p>The system must implement <strong>correlation ID injection</strong>, where a unique identifier is automatically attached to every log record within a request scope. This correlation ID propagates through function calls, async operations, and even across network boundaries when properly configured. Additionally, the context system must support arbitrary key-value pairs that provide additional metadata—user IDs, session tokens, feature flags, or any other contextual information that aids in debugging and analysis.</p>\n<p>Context propagation must handle these scenarios:</p>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Context Behavior</th>\n<th>Implementation Challenge</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Synchronous function calls</td>\n<td>Context inherits from caller</td>\n<td>Thread-local storage management</td>\n</tr>\n<tr>\n<td>Asynchronous operations</td>\n<td>Context copies to new task</td>\n<td>Async context boundary preservation</td>\n</tr>\n<tr>\n<td>Child logger creation</td>\n<td>Context inherits from parent</td>\n<td>Logger hierarchy traversal</td>\n</tr>\n<tr>\n<td>Request boundary crossing</td>\n<td>Context resets or inherits from headers</td>\n<td>HTTP middleware integration</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight</strong>: The correlation ID system transforms distributed debugging from impossible puzzle-solving into systematic investigation. Instead of manually correlating timestamps across multiple log files, operators can query for a single correlation ID and see the complete request flow.</p>\n</blockquote>\n<h3 id=\"non-functional-requirements\">Non-Functional Requirements</h3>\n<p>Non-functional requirements define <strong>how well</strong> our system must perform—the quality attributes and constraints that ensure the logging system operates reliably in production environments without becoming a bottleneck or source of problems itself.</p>\n<p><strong>Performance Requirements</strong> demand that logging operations impose minimal overhead on the host application. The primary performance constraint is <strong>latency</strong>—individual log statements must complete in microseconds, not milliseconds. Applications often generate hundreds or thousands of log entries per second, and each logging operation occurs in the critical path of business logic.</p>\n<p>The system must achieve these performance targets:</p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Target</th>\n<th>Measurement Method</th>\n<th>Degradation Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Log statement latency</td>\n<td>&lt; 50 microseconds (P99)</td>\n<td>Benchmark with no I/O handlers</td>\n<td>Slows application request processing</td>\n</tr>\n<tr>\n<td>Memory allocation</td>\n<td>&lt; 1KB per log record</td>\n<td>Memory profiling during load testing</td>\n<td>Increases garbage collection pressure</td>\n</tr>\n<tr>\n<td>CPU overhead</td>\n<td>&lt; 2% of application CPU</td>\n<td>Performance profiling under sustained load</td>\n<td>Reduces application throughput</td>\n</tr>\n<tr>\n<td>Handler dispatch</td>\n<td>&lt; 100 microseconds (P99)</td>\n<td>End-to-end logging pipeline timing</td>\n<td>Blocks application threads</td>\n</tr>\n</tbody></table>\n<p>To achieve these targets, the system must avoid blocking I/O operations in the critical path. File writes, network transmissions, and other potentially slow operations must occur asynchronously or in background threads. The log record creation and dispatch mechanism must minimize memory allocations and avoid expensive serialization operations until absolutely necessary.</p>\n<p><strong>Thread Safety Requirements</strong> ensure correct behavior when multiple threads simultaneously invoke logging operations. Modern applications extensively use concurrent programming, and the logging system must handle simultaneous log statements without data corruption, race conditions, or deadlocks.</p>\n<p>The thread safety model must protect these shared resources:</p>\n<table>\n<thead>\n<tr>\n<th>Shared Resource</th>\n<th>Concurrency Pattern</th>\n<th>Protection Mechanism</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logger configuration</td>\n<td>Read-heavy, rare writes</td>\n<td>Reader-writer locks</td>\n<td>Minimal—most operations read-only</td>\n</tr>\n<tr>\n<td>Log record dispatch</td>\n<td>High-frequency writes</td>\n<td>Lock-free queues or fine-grained locking</td>\n<td>Must not serialize all logging operations</td>\n</tr>\n<tr>\n<td>Context storage</td>\n<td>Thread-local access</td>\n<td>Thread-local storage with inheritance</td>\n<td>No contention between threads</td>\n</tr>\n<tr>\n<td>Handler state</td>\n<td>Handler-specific access patterns</td>\n<td>Handler-managed synchronization</td>\n<td>Varies by handler implementation</td>\n</tr>\n</tbody></table>\n<p><strong>Configurability Requirements</strong> enable the logging system to adapt to different environments and operational needs without code changes. The same application binary must support development logging (verbose, pretty-printed) and production logging (structured, filtered) through configuration alone.</p>\n<p>Configuration must support these operational scenarios:</p>\n<table>\n<thead>\n<tr>\n<th>Environment</th>\n<th>Log Level</th>\n<th>Output Format</th>\n<th>Destinations</th>\n<th>Context Fields</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Development</td>\n<td><code>DEBUG</code></td>\n<td>Pretty-printed JSON with colors</td>\n<td>Console only</td>\n<td>All available context</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td><code>WARN</code></td>\n<td>Single-line JSON</td>\n<td>Memory buffer</td>\n<td>Minimal context for speed</td>\n</tr>\n<tr>\n<td>Staging</td>\n<td><code>INFO</code></td>\n<td>Single-line JSON</td>\n<td>File + Remote collector</td>\n<td>Full production context</td>\n</tr>\n<tr>\n<td>Production</td>\n<td><code>INFO</code></td>\n<td>Single-line JSON</td>\n<td>Remote collector only</td>\n<td>Security-filtered context</td>\n</tr>\n</tbody></table>\n<p><strong>Async Compatibility Requirements</strong> ensure the logging system functions correctly in applications using modern async/await programming patterns. Python&#39;s asyncio, JavaScript&#39;s Promise-based code, and similar patterns create execution contexts that traditional thread-local storage cannot handle properly.</p>\n<p>The system must preserve logging context across these async boundaries:</p>\n<table>\n<thead>\n<tr>\n<th>Async Pattern</th>\n<th>Context Challenge</th>\n<th>Required Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>async def</code> function calls</td>\n<td>Context inheritance from caller</td>\n<td>Context automatically flows to async functions</td>\n</tr>\n<tr>\n<td><code>await</code> operations</td>\n<td>Context preservation across yield points</td>\n<td>Context remains available after await resumes</td>\n</tr>\n<tr>\n<td>Task creation (<code>asyncio.create_task</code>)</td>\n<td>Context copying to new task</td>\n<td>New task inherits current context</td>\n</tr>\n<tr>\n<td>Concurrent execution (<code>asyncio.gather</code>)</td>\n<td>Context isolation between tasks</td>\n<td>Each task maintains independent context</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Architecture Decision: Async Context Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Modern applications heavily use async/await patterns, but traditional thread-local storage fails across await boundaries</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Ignore async compatibility—require manual context passing</li>\n<li>Use language-specific async context mechanisms</li>\n<li>Build custom context propagation system</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Use language-specific async context mechanisms (Python&#39;s <code>contextvars</code>, etc.)</li>\n<li><strong>Rationale</strong>: Language async context systems are specifically designed for this problem and integrate seamlessly with async runtimes</li>\n<li><strong>Consequences</strong>: Simpler implementation and better performance, but requires different implementation strategies per language</li>\n</ul>\n</blockquote>\n<h3 id=\"explicit-non-goals\">Explicit Non-Goals</h3>\n<p>Clearly defining what our logging system does <strong>not</strong> do is crucial for maintaining focus and preventing scope creep. These non-goals represent important functionality that could theoretically be added but would fundamentally change the nature and complexity of our system.</p>\n<p><strong>Log Storage and Persistence Management</strong> falls outside our scope. Our logging system produces structured log records and dispatches them to configured destinations, but it does not implement log storage backends, retention policies, or data lifecycle management. We provide file handlers that can write to local files, but we do not build distributed storage systems, implement log rotation policies, or manage disk space consumption.</p>\n<p>This boundary means our system interfaces with but does not replace dedicated log management solutions:</p>\n<table>\n<thead>\n<tr>\n<th>Storage Concern</th>\n<th>Our Responsibility</th>\n<th>External System Responsibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Log record format</td>\n<td>Produce structured JSON records</td>\n<td>Store and index records efficiently</td>\n</tr>\n<tr>\n<td>Local file writing</td>\n<td>Write records to specified files</td>\n<td>Implement file rotation and compression</td>\n</tr>\n<tr>\n<td>Network transmission</td>\n<td>Send records to remote endpoints</td>\n<td>Receive, route, and persist records</td>\n</tr>\n<tr>\n<td>Data retention</td>\n<td>Continue producing records</td>\n<td>Implement age-based deletion policies</td>\n</tr>\n</tbody></table>\n<p><strong>Search and Analytics Capabilities</strong> represent a completely different problem domain. While our structured JSON output enables powerful searching and analysis, we do not build query engines, indexing systems, or analytical dashboards. Our role ends when log records reach their configured destinations—whether those destinations provide search capabilities is beyond our scope.</p>\n<p><strong>Real-Time Alerting and Monitoring</strong> requires complex event processing, threshold management, and notification systems. Although our log records contain the data needed for alerting (error rates, performance metrics, business events), we do not implement alert rules, notification channels, or monitoring dashboards. We focus on reliable log record production and dispatch.</p>\n<p><strong>Log Sampling and Rate Limiting</strong> represents advanced operational features that could compromise our core reliability guarantees. While production systems often need these capabilities to manage log volume and costs, implementing them requires complex policy engines and could introduce scenarios where critical log records are dropped. We choose to generate all requested log records and leave volume management to downstream systems.</p>\n<p><strong>Dynamic Schema Management</strong> involves automatically detecting and managing changes in log record structure over time. While our JSON output naturally accommodates additional fields, we do not implement schema registries, version management, or compatibility checking between different log record formats.</p>\n<p><strong>Security and Access Control</strong> for log content remains the responsibility of storage and analysis systems. We do not implement field-level encryption, access control policies, or data masking capabilities. Our context filtering allows removing sensitive fields before serialization, but comprehensive security requires purpose-built security infrastructure.</p>\n<blockquote>\n<p><strong>Design Principle</strong>: Single Responsibility\nOur logging system excels at one thing: reliably producing structured, contextual log records and dispatching them to configured destinations. By explicitly avoiding adjacent problem domains, we can focus on making our core functionality extremely reliable, performant, and easy to integrate.</p>\n</blockquote>\n<p>These non-goals create clear integration points where our logging system connects with specialized external systems:</p>\n<table>\n<thead>\n<tr>\n<th>Integration Point</th>\n<th>Our Output</th>\n<th>External System Input</th>\n<th>Example Tools</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Log Aggregation</td>\n<td>JSON records via network handlers</td>\n<td>Structured log ingestion APIs</td>\n<td>Elasticsearch, Splunk, Datadog</td>\n</tr>\n<tr>\n<td>File Management</td>\n<td>Raw log files via file handlers</td>\n<td>File monitoring and rotation</td>\n<td>logrotate, fluentd, filebeat</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Structured records with metrics</td>\n<td>Log-based metric extraction</td>\n<td>Prometheus, Grafana, custom dashboards</td>\n</tr>\n<tr>\n<td>Alerting</td>\n<td>Error/warning records with context</td>\n<td>Event pattern recognition</td>\n<td>PagerDuty, AlertManager, custom systems</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Scope Creep Through &quot;Simple&quot; Features</strong>\nLearners often want to add &quot;just a simple search feature&quot; or &quot;basic alerting&quot; to their logging system. These features seem simple but require fundamentally different architectural patterns (indexing, query processing, event detection) that would dominate the system design. Resist the temptation to build a &quot;logging platform&quot;—focus on building an excellent logging library that integrates with existing platforms.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>A. Technology Recommendations Table:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JSON Serialization</td>\n<td><code>json</code> standard library with custom encoder</td>\n<td><code>orjson</code> or <code>ujson</code> for performance</td>\n</tr>\n<tr>\n<td>Thread Safety</td>\n<td><code>threading.Lock</code> with context managers</td>\n<td><code>queue.Queue</code> for lock-free dispatch</td>\n</tr>\n<tr>\n<td>Async Context</td>\n<td><code>contextvars</code> module (Python 3.7+)</td>\n<td>Custom context propagation framework</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Environment variables + dataclasses</td>\n<td>YAML/TOML files with validation</td>\n</tr>\n<tr>\n<td>Network Handlers</td>\n<td><code>urllib3</code> or <code>requests</code> for HTTP</td>\n<td><code>aiohttp</code> for async network operations</td>\n</tr>\n<tr>\n<td>File Operations</td>\n<td>Built-in <code>open()</code> with manual rotation</td>\n<td><code>logging.handlers.RotatingFileHandler</code> adaptation</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File/Module Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n├── __init__.py                  ← Public API exports\n├── core/\n│   ├── __init__.py\n│   ├── logger.py               ← Logger hierarchy and main API\n│   ├── record.py               ← LogRecord data structure\n│   ├── levels.py               ← Log level constants and utilities\n│   └── context.py              ← Context propagation system\n├── handlers/\n│   ├── __init__.py\n│   ├── base.py                 ← Abstract Handler base class\n│   ├── console.py              ← Console/stdout handler\n│   ├── file.py                 ← File writing handler\n│   └── network.py              ← HTTP/network handlers\n├── formatters/\n│   ├── __init__.py\n│   ├── json_formatter.py       ← JSON serialization\n│   ├── pretty_formatter.py     ← Development-friendly output\n│   └── registry.py             ← Formatter plugin system\n├── utils/\n│   ├── __init__.py\n│   ├── serialization.py        ← Safe JSON encoding utilities\n│   ├── threading.py            ← Thread-safe data structures\n│   └── async_utils.py          ← Async context bridge utilities\n└── tests/\n    ├── test_core/\n    ├── test_handlers/\n    ├── test_formatters/\n    └── integration/</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code (COMPLETE):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># utils/threading.py - Complete thread-safe utilities</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeDict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe dictionary wrapper for shared logger configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()  </span><span style=\"color:#6A737D\"># Reentrant lock for nested access</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.get(key, default)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> update</span><span style=\"color:#E1E4E8\">(self, updates: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data.update(updates)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> copy</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.copy()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeCounter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe counter for generating correlation IDs.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, initial_value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> initial_value</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> next</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># utils/serialization.py - Complete JSON serialization utilities</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> decimal </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Decimal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, date</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SafeJSONEncoder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">json</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JSONEncoder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"JSON encoder that handles non-serializable types safely.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> default</span><span style=\"color:#E1E4E8\">(self, obj: Any) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle common non-serializable types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (datetime, date)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, Decimal):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__dict__'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">obj.</span><span style=\"color:#79B8FF\">__class__</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\"> object>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> callable</span><span style=\"color:#E1E4E8\">(obj):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;function </span><span style=\"color:#79B8FF\">{getattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__name__'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'unknown'</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;</span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(obj).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_serialize</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely serialize dictionary to JSON with circular reference protection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps(data, </span><span style=\"color:#FFAB70\">cls</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SafeJSONEncoder, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">TypeError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">ValueError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">RecursionError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Fallback: create safe representation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        safe_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> _make_serializable(data, max_depth, </span><span style=\"color:#79B8FF\">set</span><span style=\"color:#E1E4E8\">())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps(safe_data, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> _make_serializable</span><span style=\"color:#E1E4E8\">(obj: Any, max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, seen_objects: Set[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Recursively make object serializable, handling circular references.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> max_depth </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"&#x3C;max_depth_reached>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    obj_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> id</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> obj_id </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> seen_objects:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"&#x3C;circular_reference>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">type</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">))):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> obj</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        seen_objects.add(obj_id)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            str</span><span style=\"color:#E1E4E8\">(k): _make_serializable(v, max_depth </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, seen_objects.copy())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj.items()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        seen_objects.remove(obj_id)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        seen_objects.add(obj_id)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            _make_serializable(item, max_depth </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, seen_objects.copy())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> item </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        seen_objects.remove(obj_id)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> SafeJSONEncoder().default(obj)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> estimate_serialized_size</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Estimate JSON size without full serialization for performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Quick estimation based on data structure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # Opening and closing braces</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> key, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> data.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(key)) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#6A737D\">  # Key + quotes + colon</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(value) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # Value + quotes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, (</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(value))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> estimate_serialized_size(value)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#6A737D\">  # Conservative estimate for other types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">  # Comma separator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> size</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/levels.py - Log level management (SKELETON)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Log level constants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">WARN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FATAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 50</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">LEVEL_NAMES</span><span style=\"color:#E1E4E8\">: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEBUG</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"DEBUG\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INFO</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"INFO\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARN</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"WARN\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"ERROR\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FATAL</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"FATAL\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> should_log</span><span style=\"color:#E1E4E8\">(message_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, configured_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Determine if a message should be logged based on level filtering.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compare message_level with configured_level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return True if message_level >= configured_level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return False otherwise (message should be filtered out)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Higher numeric values represent more severe log levels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> level_name_to_value</span><span style=\"color:#E1E4E8\">(level_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Convert string level name to numeric value.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create reverse mapping from LEVEL_NAMES</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Look up level_name in reverse mapping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return numeric value or raise ValueError for invalid names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle case-insensitive matching (convert to uppercase)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/record.py - Log record data structure (SKELETON)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LogRecord</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Structured log record containing all message data and metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, logger_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 context: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store the provided parameters as instance attributes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate timestamp using datetime.utcnow().isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Initialize context as empty dict if None provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure context is a copy to prevent external mutation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use dict(context) or context.copy() to create defensive copy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_dict</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert log record to dictionary for JSON serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create dictionary with timestamp, level, message, logger_name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add context fields to the dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Convert numeric level to string using LEVEL_NAMES</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return complete dictionary ready for JSON serialization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use LEVEL_NAMES from levels.py to convert level number to string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_context</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add a context field to this log record.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add key-value pair to context dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle the case where key already exists (overwrite vs. error?)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Design decision: Should duplicate keys overwrite or raise an error?</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<ul>\n<li><strong>Thread Safety</strong>: Use <code>threading.RLock()</code> (reentrant locks) for logger hierarchy access since child loggers may need to access parent configuration during the same operation</li>\n<li><strong>Async Context</strong>: Import <code>contextvars</code> for Python 3.7+ async context propagation—use <code>contextvars.ContextVar</code> to store correlation IDs and context data</li>\n<li><strong>JSON Performance</strong>: The built-in <code>json</code> module is sufficient for learning, but consider <code>orjson</code> for production use if serialization becomes a bottleneck</li>\n<li><strong>Memory Management</strong>: Use <code>__slots__</code> in <code>LogRecord</code> class to reduce memory overhead when creating many log records</li>\n<li><strong>Exception Handling</strong>: Use <code>safe_call()</code> pattern for handler dispatch—if one handler fails, continue with remaining handlers</li>\n<li><strong>File I/O</strong>: Use <code>os.fsync()</code> after writing critical log records to ensure durability, but be aware this impacts performance</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong></p>\n<p>After implementing the goals and requirements defined in this section:</p>\n<p><strong>What to verify after Milestone 1 (Logger Core):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from structured_logging import Logger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = Logger('test', level=INFO)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('Test message', user_id=12345)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.debug('Debug message')  # Should be filtered out</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>INFO message appears with JSON format including timestamp, level, message, and user_id context</li>\n<li>DEBUG message does not appear (filtered by level)</li>\n<li>No exceptions or thread safety issues when called from multiple threads</li>\n</ul>\n<p><strong>What to verify after Milestone 2 (Structured Output):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import json</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from structured_logging import Logger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = Logger('test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('Test message', request_id='req_123')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Verify output is valid JSON by parsing it</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Output is valid single-line JSON that can be parsed</li>\n<li>All required fields present: timestamp, level, message, logger_name, context</li>\n<li>Context fields properly nested under &#39;context&#39; key</li>\n</ul>\n<p><strong>What to verify after Milestone 3 (Context &amp; Correlation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from structured_logging import Logger, with_correlation_id</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = Logger('test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">with with_correlation_id():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    logger.info('Message 1')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    logger.info('Message 2')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Both messages contain the same correlation_id in their context</li>\n<li>Correlation ID is automatically generated and unique per context scope</li>\n<li>Context properly propagates through nested function calls</li>\n</ul>\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Log messages not appearing</td>\n<td>Level filtering too restrictive</td>\n<td>Check logger level vs. message level</td>\n<td>Set logger level to DEBUG temporarily</td>\n</tr>\n<tr>\n<td>JSON serialization errors</td>\n<td>Non-serializable objects in context</td>\n<td>Try serializing context manually</td>\n<td>Use SafeJSONEncoder or filter context values</td>\n</tr>\n<tr>\n<td>Context not propagating</td>\n<td>Thread-local storage issues</td>\n<td>Print context at each function level</td>\n<td>Use contextvars instead of threading.local</td>\n</tr>\n<tr>\n<td>Performance degradation</td>\n<td>Blocking I/O in handlers</td>\n<td>Profile handler execution times</td>\n<td>Move I/O operations to background threads</td>\n</tr>\n<tr>\n<td>Race conditions in output</td>\n<td>Multiple threads writing simultaneously</td>\n<td>Look for interleaved output characters</td>\n<td>Add proper locking in handlers</td>\n</tr>\n</tbody></table>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides the architectural foundation for all three milestones by defining the core components, their relationships, and the data flow that enables structured logging with context propagation.</p>\n</blockquote>\n<h3 id=\"component-overview-core-components-logger-logrecord-handlers-formatters-and-context-manager\">Component Overview: Core Components: Logger, LogRecord, Handlers, Formatters, and Context Manager</h3>\n<p>Think of the structured logging system as a <strong>broadcasting studio with multiple output channels</strong>. Just as a news studio takes raw content, formats it for different audiences (TV, radio, web), and broadcasts simultaneously to multiple destinations, our logging system takes application events, structures them consistently, and dispatches them to various outputs like console, files, and remote collectors. The studio has specialized equipment for each step: cameras capture content, editors format it, and transmitters send it to different channels. Similarly, our logging system has specialized components for capturing, formatting, and dispatching log messages.</p>\n<p>The structured logging architecture consists of five core components that work together to provide a complete logging solution. Each component has a distinct responsibility and well-defined interfaces that enable flexible composition and extensibility.</p>\n<h4 id=\"logger-component\">Logger Component</h4>\n<p>The <code>Logger</code> serves as the primary interface between application code and the logging infrastructure. Think of it as the <strong>control panel</strong> in our broadcasting studio analogy - it&#39;s where producers decide what content gets recorded, at what quality level, and which channels receive the broadcast. Each logger maintains its own identity and configuration while participating in a hierarchical organization that enables inheritance and scoped behavior.</p>\n<p>Every logger instance maintains several critical pieces of state that determine its behavior and capabilities:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>name</code></td>\n<td><code>str</code></td>\n<td>Hierarchical identifier (e.g., &quot;app.database.connection&quot;) that determines logger&#39;s position in the tree</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td><code>int</code></td>\n<td>Minimum severity threshold - messages below this level are filtered out before processing</td>\n</tr>\n<tr>\n<td><code>parent</code></td>\n<td><code>Logger</code></td>\n<td>Reference to parent logger for configuration inheritance and context propagation</td>\n</tr>\n<tr>\n<td><code>handlers</code></td>\n<td><code>List[Handler]</code></td>\n<td>Collection of output destinations that will receive log records from this logger</td>\n</tr>\n<tr>\n<td><code>children</code></td>\n<td><code>Dict[str, Logger]</code></td>\n<td>Map of child loggers created under this logger&#39;s namespace</td>\n</tr>\n</tbody></table>\n<p>The logger hierarchy enables powerful inheritance patterns where child loggers automatically inherit their parent&#39;s configuration, handlers, and context fields while allowing selective overrides for specialized behavior. For example, a database connection logger might inherit the application&#39;s general configuration but add specialized handlers for database-specific monitoring.</p>\n<h4 id=\"logrecord-structure\">LogRecord Structure</h4>\n<p>The <code>LogRecord</code> represents a single log event in its structured form. This is the fundamental data unit that flows through the entire logging pipeline. Think of it as a <strong>standardized news report template</strong> that ensures every piece of information contains the same essential elements regardless of who created it or where it&#39;s going.</p>\n<p>The LogRecord structure captures all essential information about a logging event in a consistent, queryable format:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>timestamp</code></td>\n<td><code>str</code></td>\n<td>ISO 8601 formatted timestamp indicating when the log event occurred</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td><code>int</code></td>\n<td>Numeric severity level (DEBUG=10, INFO=20, WARN=30, ERROR=40, FATAL=50)</td>\n</tr>\n<tr>\n<td><code>message</code></td>\n<td><code>str</code></td>\n<td>Human-readable description of the event or situation being logged</td>\n</tr>\n<tr>\n<td><code>logger_name</code></td>\n<td><code>str</code></td>\n<td>Fully qualified name of the logger that created this record</td>\n</tr>\n<tr>\n<td><code>context</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Key-value pairs providing additional structured data about the event</td>\n</tr>\n</tbody></table>\n<p>The context dictionary is where the &quot;structured&quot; aspect of structured logging becomes most apparent. Instead of embedding variable data into string messages, applications attach meaningful key-value pairs that can be queried, filtered, and aggregated by log analysis tools. For example, rather than logging &quot;User <a href=\"mailto:john@example.com\">john@example.com</a> failed login attempt from IP 192.168.1.100&quot;, the system would log a message &quot;User login failed&quot; with context fields <code>{&quot;user_email&quot;: &quot;john@example.com&quot;, &quot;client_ip&quot;: &quot;192.168.1.100&quot;, &quot;login_attempt&quot;: &quot;failed&quot;}</code>.</p>\n<h4 id=\"handler-dispatch-system\">Handler Dispatch System</h4>\n<p>Handlers are the <strong>output channels</strong> in our broadcasting analogy. Each handler knows how to deliver log records to a specific destination, whether that&#39;s stdout for development debugging, rotating files for long-term storage, or remote collectors for centralized analysis. The handler system enables simultaneous dispatch to multiple destinations without requiring application code to manage the complexity.</p>\n<p>The abstract <code>Handler</code> interface defines the contract that all output destinations must implement:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>emit</code></td>\n<td><code>record: LogRecord</code></td>\n<td><code>None</code></td>\n<td>Process and output a single log record to this handler&#39;s destination</td>\n</tr>\n<tr>\n<td><code>flush</code></td>\n<td><code>None</code></td>\n<td><code>None</code></td>\n<td>Ensure all buffered records are written to the underlying destination</td>\n</tr>\n<tr>\n<td><code>close</code></td>\n<td><code>None</code></td>\n<td><code>None</code></td>\n<td>Release resources and perform cleanup when handler is no longer needed</td>\n</tr>\n<tr>\n<td><code>set_formatter</code></td>\n<td><code>formatter: Formatter</code></td>\n<td><code>None</code></td>\n<td>Configure the formatter used to render log records for output</td>\n</tr>\n</tbody></table>\n<p>Each handler implementation specializes the abstract interface for its specific destination. A file handler manages file rotation, buffering, and disk I/O. A remote handler manages network connections, retry logic, and serialization for transmission. A console handler manages terminal output, color coding, and user-friendly formatting.</p>\n<p>The dispatch mechanism routes each log record to all configured handlers simultaneously. This enables powerful patterns like writing structured JSON to files for analysis while simultaneously displaying pretty-printed, colorized output to the developer console during debugging.</p>\n<h4 id=\"formatter-plugin-system\">Formatter Plugin System</h4>\n<p>Formatters transform <code>LogRecord</code> objects into the final output representation. Think of formatters as <strong>template engines</strong> that take structured data and render it into specific output formats optimized for different consumers. The plugin system allows applications to register custom formatters and select them by name, enabling consistent formatting across different parts of an application.</p>\n<p>The formatter interface provides the contract for all output renderers:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>format</code></td>\n<td><code>record: LogRecord</code></td>\n<td><code>str</code></td>\n<td>Convert a log record into formatted string output ready for display or transmission</td>\n</tr>\n<tr>\n<td><code>configure</code></td>\n<td><code>options: Dict[str, Any]</code></td>\n<td><code>None</code></td>\n<td>Apply configuration options specific to this formatter implementation</td>\n</tr>\n</tbody></table>\n<p>Common formatter implementations include the JSON formatter for structured output, the pretty-print formatter for human-readable console output, and custom formatters that integrate with specific monitoring or analysis tools. The plugin system allows applications to register formatters by name and configure different handlers to use different formatters based on their intended audience.</p>\n<h4 id=\"context-manager\">Context Manager</h4>\n<p>The Context Manager handles the complex task of <strong>context propagation</strong> - ensuring that relevant contextual information flows through nested function calls and across async boundaries without requiring explicit parameter passing. Think of it as the <strong>continuity coordinator</strong> in our broadcasting studio, ensuring that related segments maintain consistent information and branding elements throughout the production.</p>\n<p>The context system maintains thread-local storage and manages inheritance patterns that allow contextual information to flow naturally through application execution:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Purpose</th>\n<th>Key Behaviors</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Thread-Local Storage</td>\n<td>Maintains context state per execution thread</td>\n<td>Isolates context between concurrent requests, automatically inherits parent context</td>\n</tr>\n<tr>\n<td>Correlation ID Generator</td>\n<td>Creates unique identifiers for request tracing</td>\n<td>Generates UUIDs, injects into log context, propagates across service boundaries</td>\n</tr>\n<tr>\n<td>Async Context Bridge</td>\n<td>Preserves context across async/await boundaries</td>\n<td>Captures context at task creation, restores context during task execution</td>\n</tr>\n<tr>\n<td>Context Inheritance</td>\n<td>Manages parent-child context relationships</td>\n<td>Child contexts inherit parent fields, can override or add new fields</td>\n</tr>\n</tbody></table>\n<p>The context manager ensures that once a correlation ID or other contextual information is established (typically at request boundaries), it automatically appears in every log record created within that execution scope, even deep within nested function calls or across async task switches.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The separation of concerns between Logger (message creation), Handler (output dispatch), Formatter (rendering), and Context Manager (state propagation) creates a highly flexible system where each aspect can be configured and extended independently. This modularity is essential for accommodating the diverse requirements of different deployment environments and use cases.</p>\n</blockquote>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<h3 id=\"data-flow-pipeline-how-log-messages-flow-from-application-code-through-formatters-to-output-destinations\">Data Flow Pipeline: How log messages flow from application code through formatters to output destinations</h3>\n<p>Understanding the complete journey of a log message from application code to final output destinations reveals how the components work together to provide structured logging capabilities. This pipeline demonstrates the transformation and enrichment that occurs at each stage, showing how raw application events become structured, contextualized, and properly formatted log records.</p>\n<h4 id=\"stage-1-message-creation-and-level-filtering\">Stage 1: Message Creation and Level Filtering</h4>\n<p>The logging pipeline begins when application code calls one of the logging methods (<code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>, or <code>fatal</code>). The first critical decision point occurs immediately: <strong>level filtering</strong>. Think of this as a <strong>security checkpoint</strong> that only allows messages of sufficient importance to proceed through the expensive processing pipeline.</p>\n<p>The level filtering process follows this sequence:</p>\n<ol>\n<li>Application code calls <code>logger.info(&quot;User authenticated&quot;, user_id=&quot;12345&quot;, session_id=&quot;abc-def&quot;)</code></li>\n<li>Logger retrieves its configured minimum level (inherited from parent if not explicitly set)</li>\n<li>The <code>should_log</code> function compares the message level against the configured threshold</li>\n<li>If the message level is below the threshold, processing stops immediately - no LogRecord is created, no handlers are called, no formatting occurs</li>\n<li>If the message passes the level check, processing continues to record creation</li>\n</ol>\n<p>This early filtering is crucial for performance. In production systems, DEBUG level messages might be completely disabled, and the filtering prevents any overhead from creating LogRecord objects or processing context for messages that will never be output.</p>\n<h4 id=\"stage-2-logrecord-construction-and-context-enrichment\">Stage 2: LogRecord Construction and Context Enrichment</h4>\n<p>Once a message passes level filtering, the system creates a <code>LogRecord</code> object and enriches it with contextual information. This stage transforms a simple message and parameters into a fully structured log event with all relevant metadata.</p>\n<p>The record construction process involves several enrichment steps:</p>\n<ol>\n<li><strong>Timestamp Generation</strong>: The system captures the current time with microsecond precision and formats it according to the configured timestamp format (typically ISO 8601)</li>\n<li><strong>Context Aggregation</strong>: The context manager retrieves all active context fields from thread-local storage, including correlation IDs, user information, and request metadata</li>\n<li><strong>Logger Context Inheritance</strong>: Any context fields attached to the logger or its parents are merged with the active context</li>\n<li><strong>Parameter Integration</strong>: Keyword arguments passed to the logging method are merged into the context dictionary</li>\n<li><strong>Record Assembly</strong>: All components are combined into a complete LogRecord with timestamp, level, message, logger name, and enriched context</li>\n</ol>\n<p>The context enrichment stage is where structured logging shows its power. A simple log call might result in a LogRecord with dozens of contextual fields that provide rich information about the application state when the event occurred.</p>\n<h4 id=\"stage-3-handler-dispatch-and-parallel-processing\">Stage 3: Handler Dispatch and Parallel Processing</h4>\n<p>With a complete LogRecord created, the system enters the handler dispatch phase. This stage demonstrates the <strong>fan-out pattern</strong> where a single log event triggers parallel processing to multiple output destinations. Think of this as a <strong>broadcasting transmitter</strong> that simultaneously sends the same content to radio, television, and internet streams.</p>\n<p>The dispatch mechanism follows this parallel processing pattern:</p>\n<ol>\n<li>The logger iterates through its list of configured handlers</li>\n<li>For each handler, the system makes an independent <code>emit</code> call with the LogRecord</li>\n<li>Each handler processes the record according to its specific requirements:<ul>\n<li>Console handlers might check if output should be colorized</li>\n<li>File handlers might check if log rotation is needed</li>\n<li>Remote handlers might check network connectivity and queue records if offline</li>\n</ul>\n</li>\n<li>Handler failures are isolated - if one handler fails, others continue processing</li>\n<li>Each handler applies its configured formatter to render the LogRecord into final output format</li>\n</ol>\n<p>This parallel processing enables powerful deployment patterns. During development, logs might go to a colorized console for immediate feedback. In staging, the same logs might go to both files for debugging and a remote collector for integration testing. In production, logs might go to high-performance local files, metrics aggregators, and centralized logging infrastructure simultaneously.</p>\n<h4 id=\"stage-4-formatting-and-serialization\">Stage 4: Formatting and Serialization</h4>\n<p>Each handler applies its configured formatter to transform the structured LogRecord into the appropriate output representation. This stage handles the complex task of serialization while preserving the structured nature of the data and handling edge cases like circular references or non-serializable objects.</p>\n<p>The formatting process addresses several challenges:</p>\n<ol>\n<li><strong>Serialization Safety</strong>: The <code>safe_serialize</code> function handles objects that can&#39;t be directly serialized to JSON, converting them to string representations or filtering them out entirely</li>\n<li><strong>Circular Reference Detection</strong>: The serializer detects and breaks circular references to prevent infinite recursion during JSON generation</li>\n<li><strong>Size Estimation</strong>: For performance, the system can estimate serialized size without full serialization to decide whether to truncate large context objects</li>\n<li><strong>Field Ordering</strong>: JSON output uses consistent field ordering to improve readability and enable text-based diffing of log files</li>\n<li><strong>Pretty Printing</strong>: Development formatters add indentation, color coding, and human-friendly formatting while preserving the underlying structured data</li>\n</ol>\n<p>Different handlers might apply different formatters to the same LogRecord. A file handler might use compact, single-line JSON for efficient storage and parsing, while a console handler might use pretty-printed, colorized output for developer readability.</p>\n<h4 id=\"stage-5-output-delivery-and-error-recovery\">Stage 5: Output Delivery and Error Recovery</h4>\n<p>The final stage handles actual output delivery to the configured destinations. This stage must handle various failure modes gracefully while maintaining the reliability that production logging systems require. Think of this as the <strong>final mile delivery</strong> where packages must reach their destinations despite traffic, weather, or infrastructure problems.</p>\n<p>Output delivery involves several reliability mechanisms:</p>\n<ol>\n<li><strong>Buffering Strategy</strong>: Handlers may buffer records for efficiency, but must balance performance with the risk of losing logs during crashes</li>\n<li><strong>Failure Recovery</strong>: When output operations fail (disk full, network unreachable, permissions denied), handlers must decide whether to retry, queue for later, or drop records</li>\n<li><strong>Resource Management</strong>: File handles, network connections, and buffers must be managed carefully to prevent resource leaks</li>\n<li><strong>Graceful Degradation</strong>: When primary output destinations fail, the system should attempt to log error information to alternative destinations rather than crashing the application</li>\n</ol>\n<p>The error recovery mechanisms ensure that logging problems don&#39;t become application problems. If a remote logging service becomes unavailable, the application continues running and attempts to log the issue to local files or console output.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The pipeline architecture enables <strong>loose coupling</strong> between stages. Application code doesn&#39;t need to know about formatters, formatters don&#39;t need to know about output destinations, and handlers don&#39;t need to know about context propagation. This separation allows each stage to be optimized, configured, and extended independently.</p>\n</blockquote>\n<p>The complete data flow pipeline demonstrates how structured logging transforms simple application events into rich, contextualized, and properly formatted log records delivered to multiple destinations with reliability and performance guarantees.</p>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Flog-processing-flow.svg\" alt=\"Log Processing Data Flow\"></p>\n<h3 id=\"recommended-module-structure-file-organization-and-package-layout-for-clean-separation-of-concerns\">Recommended Module Structure: File organization and package layout for clean separation of concerns</h3>\n<p>A well-organized module structure is crucial for maintaining clean separation of concerns and enabling teams to work on different aspects of the logging system independently. Think of the module structure as <strong>organizing a professional kitchen</strong> - each station has specific responsibilities, specialized tools, and clear interfaces with other stations, allowing multiple chefs to work efficiently without interfering with each other.</p>\n<p>The recommended structure follows the principle of <strong>bounded contexts</strong> where each module encapsulates related functionality and exposes minimal, well-defined interfaces to other modules. This organization supports both the learning progression through the three milestones and the maintainability requirements of production systems.</p>\n<h4 id=\"root-package-structure\">Root Package Structure</h4>\n<p>The top-level package organization reflects the major architectural boundaries and provides clear entry points for different aspects of the system:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n├── __init__.py                    # Public API exports\n├── logger.py                      # Core Logger and LogRecord classes\n├── handlers/                      # Output destination implementations\n│   ├── __init__.py               # Handler base class and common utilities\n│   ├── console.py                # Console/stdout handler\n│   ├── file.py                   # File-based handlers with rotation\n│   └── remote.py                 # Network-based handlers\n├── formatters/                    # Output format implementations\n│   ├── __init__.py               # Formatter base class and registry\n│   ├── json.py                   # JSON formatter with serialization safety\n│   └── pretty.py                 # Human-readable console formatter\n├── context/                       # Context propagation and correlation\n│   ├── __init__.py               # Context manager and public interfaces\n│   ├── storage.py                # Thread-local context storage\n│   ├── correlation.py            # Correlation ID generation and injection\n│   └── async_bridge.py           # Async context preservation\n├── utils/                         # Shared utilities and helpers\n│   ├── __init__.py               # Common utility exports\n│   ├── serialization.py          # Safe JSON serialization functions\n│   ├── thread_safety.py          # Thread-safe data structures\n│   └── validation.py             # Input validation and sanitization\n├── config/                        # Configuration management\n│   ├── __init__.py               # Configuration loading and validation\n│   └── schema.py                 # Configuration schema definitions\n└── tests/                         # Comprehensive test suite\n    ├── unit/                      # Unit tests for individual components\n    ├── integration/               # Integration tests across components\n    └── performance/               # Performance and load testing</code></pre></div>\n\n<h4 id=\"core-module-responsibilities\">Core Module Responsibilities</h4>\n<p>Each module has clearly defined responsibilities that align with the architectural components and enable independent development and testing.</p>\n<p><strong>Logger Module (<code>logger.py</code>)</strong>\nThis module contains the central <code>Logger</code> class and <code>LogRecord</code> data structure that form the heart of the logging system. It should be the most stable module since other components depend on its interfaces:</p>\n<table>\n<thead>\n<tr>\n<th>Class/Function</th>\n<th>Purpose</th>\n<th>Key Dependencies</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Logger</code></td>\n<td>Main logging interface with hierarchy support</td>\n<td>Handlers, Context Manager, Level utilities</td>\n</tr>\n<tr>\n<td><code>LogRecord</code></td>\n<td>Structured log event representation</td>\n<td>Serialization utilities, Timestamp formatting</td>\n</tr>\n<tr>\n<td><code>LoggerFactory</code></td>\n<td>Factory for creating and managing logger instances</td>\n<td>Configuration system, Logger hierarchy</td>\n</tr>\n<tr>\n<td><code>get_logger</code></td>\n<td>Primary entry point for obtaining logger instances</td>\n<td>LoggerFactory, Thread-safe caching</td>\n</tr>\n</tbody></table>\n<p><strong>Handlers Module (<code>handlers/</code>)</strong>\nThe handlers package encapsulates all output destination logic. Each handler type gets its own module to enable independent development and specialized dependencies:</p>\n<table>\n<thead>\n<tr>\n<th>Module</th>\n<th>Handler Types</th>\n<th>Key Considerations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>console.py</code></td>\n<td>Stdout, stderr handlers</td>\n<td>Color coding, terminal detection, Unicode support</td>\n</tr>\n<tr>\n<td><code>file.py</code></td>\n<td>File, rotating file handlers</td>\n<td>File locking, atomic writes, disk space monitoring</td>\n</tr>\n<tr>\n<td><code>remote.py</code></td>\n<td>HTTP, TCP, UDP handlers</td>\n<td>Connection pooling, retry logic, serialization formats</td>\n</tr>\n</tbody></table>\n<p>The handler base class in <code>handlers/__init__.py</code> provides common functionality like formatter management, error handling patterns, and resource cleanup protocols that all handler implementations can inherit.</p>\n<p><strong>Formatters Module (<code>formatters/</code>)</strong>\nThe formatters package handles the transformation from structured <code>LogRecord</code> objects to formatted output strings. This separation allows the same log data to be rendered differently for various audiences:</p>\n<table>\n<thead>\n<tr>\n<th>Module</th>\n<th>Formatter Types</th>\n<th>Output Characteristics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>json.py</code></td>\n<td>Compact JSON, pretty JSON</td>\n<td>Machine-readable, consistent field ordering, size optimization</td>\n</tr>\n<tr>\n<td><code>pretty.py</code></td>\n<td>Console, colored console</td>\n<td>Human-readable, color coding, selective field display</td>\n</tr>\n</tbody></table>\n<p>The formatter registry in <code>formatters/__init__.py</code> enables dynamic formatter selection and supports custom formatter registration for specialized output requirements.</p>\n<p><strong>Context Module (<code>context/</code>)</strong>\nThe context package manages the complex requirements of context propagation across different execution models (synchronous, threaded, async). This is separated into multiple modules due to the different challenges each execution model presents:</p>\n<table>\n<thead>\n<tr>\n<th>Module</th>\n<th>Responsibilities</th>\n<th>Key Challenges</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>storage.py</code></td>\n<td>Thread-local context storage</td>\n<td>Thread isolation, inheritance patterns, memory cleanup</td>\n</tr>\n<tr>\n<td><code>correlation.py</code></td>\n<td>Correlation ID management</td>\n<td>UUID generation, injection points, cross-service propagation</td>\n</tr>\n<tr>\n<td><code>async_bridge.py</code></td>\n<td>Async context preservation</td>\n<td>Context copying, task boundaries, coroutine lifecycle</td>\n</tr>\n</tbody></table>\n<h4 id=\"milestone-aligned-development-structure\">Milestone-Aligned Development Structure</h4>\n<p>The module structure supports incremental development through the three project milestones, allowing learners to build functionality progressively without requiring massive refactoring between milestones:</p>\n<p><strong>Milestone 1 Structure (Logger Core)</strong>\nInitial implementation focuses on the core modules with basic implementations:</p>\n<ul>\n<li><code>logger.py</code>: Complete Logger and LogRecord implementation</li>\n<li><code>handlers/__init__.py</code>: Base Handler class and console handler</li>\n<li><code>utils/thread_safety.py</code>: Thread-safe data structures</li>\n<li><code>utils/validation.py</code>: Level validation and basic input sanitization</li>\n</ul>\n<p><strong>Milestone 2 Extensions (Structured Output)</strong>\nMilestone 2 adds formatter infrastructure without changing existing modules:</p>\n<ul>\n<li><code>formatters/</code>: Complete formatter package with JSON and pretty-print implementations</li>\n<li><code>utils/serialization.py</code>: Safe JSON serialization with circular reference protection</li>\n<li>Enhanced handlers with formatter integration</li>\n</ul>\n<p><strong>Milestone 3 Extensions (Context &amp; Correlation)</strong>\nMilestone 3 adds the context package while maintaining backward compatibility:</p>\n<ul>\n<li><code>context/</code>: Complete context propagation package</li>\n<li>Integration points in <code>logger.py</code> for context injection</li>\n<li>Extended handler and formatter support for correlation IDs</li>\n</ul>\n<h4 id=\"testing-structure-alignment\">Testing Structure Alignment</h4>\n<p>The testing structure mirrors the module organization and supports both component-level testing and cross-cutting integration scenarios:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>tests/\n├── unit/\n│   ├── test_logger.py             # Logger class behavior, hierarchy, level filtering\n│   ├── test_handlers/             # Handler-specific unit tests\n│   │   ├── test_console.py        # Console output, color coding, error handling\n│   │   ├── test_file.py           # File operations, rotation, locking\n│   │   └── test_remote.py         # Network operations, retry, serialization\n│   ├── test_formatters/           # Formatter unit tests\n│   │   ├── test_json.py           # JSON serialization, field ordering, safety\n│   │   └── test_pretty.py         # Pretty printing, color codes, truncation\n│   └── test_context/              # Context propagation unit tests\n│       ├── test_storage.py        # Thread-local storage, inheritance\n│       ├── test_correlation.py    # ID generation, injection\n│       └── test_async_bridge.py   # Async context preservation\n├── integration/\n│   ├── test_end_to_end.py         # Complete logging pipeline tests\n│   ├── test_multi_handler.py     # Multiple handler coordination\n│   ├── test_context_flow.py      # Context propagation across components\n│   └── test_async_logging.py     # Async/await context preservation\n└── performance/\n    ├── test_throughput.py         # Message processing performance\n    ├── test_memory_usage.py       # Memory footprint and leak detection\n    └── test_concurrent_logging.py # Multi-threaded performance and safety</code></pre></div>\n\n<blockquote>\n<p><strong>Design Insight</strong>: The module structure balances <strong>cohesion</strong> (related functionality grouped together) with <strong>loose coupling</strong> (minimal dependencies between modules). Each module can be understood, tested, and modified independently while contributing to the overall system functionality. This structure particularly benefits learning environments where students can focus on one architectural layer at a time.</p>\n</blockquote>\n<h4 id=\"import-strategy-and-public-apis\">Import Strategy and Public APIs</h4>\n<p>The package design uses a clear import strategy that exposes high-level APIs while keeping implementation details internal:</p>\n<p><strong>Public API (<code>__init__.py</code>)</strong>\nThe root package exposes only the essential interfaces that application code needs:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Public exports - these are the stable API</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .logger </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_logger, Logger, LogRecord</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .context </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> with_context, correlation_id</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .config </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> configure_logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Internal modules should not be imported directly by applications</span></span></code></pre></div>\n\n<p><strong>Internal Module Imports</strong>\nInternal modules use relative imports and depend only on the interfaces they need:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># handlers/console.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..formatters </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_formatter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.thread_safety </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ThreadSafeCounter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Handler  </span><span style=\"color:#6A737D\"># Relative import within handlers package</span></span></code></pre></div>\n\n<p>This import strategy ensures that refactoring internal implementation doesn&#39;t break application code and makes the learning progression clearer by highlighting the distinction between public APIs and implementation details.</p>\n<p>The module structure provides a solid foundation for building the structured logging system incrementally while maintaining clean separation of concerns and supporting both learning objectives and production requirements.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The implementation of the structured logging system requires careful attention to Python-specific patterns, thread safety considerations, and performance optimizations. This guidance provides complete starter code for infrastructure components and detailed skeletons for core learning components.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JSON Serialization</td>\n<td><code>json</code> module with custom encoder</td>\n<td><code>orjson</code> or <code>ujson</code> for high performance</td>\n</tr>\n<tr>\n<td>Thread Safety</td>\n<td><code>threading.RLock</code> and <code>threading.local</code></td>\n<td><code>concurrent.futures</code> with thread pools</td>\n</tr>\n<tr>\n<td>File Operations</td>\n<td><code>open()</code> with manual rotation</td>\n<td><code>logging.handlers.RotatingFileHandler</code> base</td>\n</tr>\n<tr>\n<td>Network Handlers</td>\n<td><code>urllib3</code> for HTTP requests</td>\n<td><code>asyncio</code> with <code>aiohttp</code> for async</td>\n</tr>\n<tr>\n<td>Correlation IDs</td>\n<td><code>uuid.uuid4()</code> generation</td>\n<td><code>contextvars</code> for async context propagation</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Dictionary-based config</td>\n<td><code>pydantic</code> models for validation</td>\n</tr>\n</tbody></table>\n<h4 id=\"complete-infrastructure-starter-code\">Complete Infrastructure Starter Code</h4>\n<p><strong>Thread-Safe Data Structures (<code>utils/thread_safety.py</code>)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Thread-safe data structures for concurrent logging operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeCounter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe counter for handler statistics and correlation ID generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, initial_value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> initial_value</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> increment</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Increment counter and return new value.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current counter value.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeDict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe dictionary for shared logger registry and context storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RWMutex()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get value with read lock.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock.reader_lock():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.get(key, default)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set value with write lock.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock.writer_lock():</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> update</span><span style=\"color:#E1E4E8\">(self, other: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update multiple values atomically.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock.writer_lock():</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data.update(other)</span></span></code></pre></div>\n\n<p><strong>Safe JSON Serialization (<code>utils/serialization.py</code>)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Safe JSON serialization handling non-serializable objects and circular references.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> decimal </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Decimal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, date</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SafeJSONEncoder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">json</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JSONEncoder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Custom JSON encoder that safely handles non-serializable types.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">ensure_ascii</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_depth</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._visited: Set[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> default</span><span style=\"color:#E1E4E8\">(self, obj: Any) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert non-serializable objects to string representations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (datetime, date)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, Decimal):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__dict__'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;</span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(obj).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\"> object>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_serialize</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Safely serialize dictionary to JSON string with circular reference protection.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        data: Dictionary to serialize</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        max_depth: Maximum nesting depth to prevent infinite recursion</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        JSON string representation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Raises:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        ValueError: If data cannot be serialized even with safety measures</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps(data, </span><span style=\"color:#FFAB70\">cls</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SafeJSONEncoder, </span><span style=\"color:#FFAB70\">max_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_depth)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">TypeError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">ValueError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">RecursionError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Fallback: serialize with string conversion</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        safe_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {k: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(v) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> data.items()}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps(safe_data, </span><span style=\"color:#FFAB70\">ensure_ascii</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> estimate_serialized_size</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Estimate serialized JSON size without full serialization.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    This is faster than full serialization for size checking.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Simple heuristic: sum of key lengths + estimated value lengths</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # Opening and closing braces</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> key, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> data.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(key)) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#6A737D\">  # Key + quotes and colon</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(value) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # String + quotes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, (</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(value))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(value, (</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 50</span><span style=\"color:#6A737D\">  # Rough estimate for collections</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#6A737D\">  # Default estimate for other types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> size</span></span></code></pre></div>\n\n<p><strong>Safe Function Execution (<code>utils/validation.py</code>)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Validation utilities and safe function execution for error handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> functools</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> traceback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Callable, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_call</span><span style=\"color:#E1E4E8\">(func: Callable, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Safely execute function with exception handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        func: Function to execute</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        *args: Positional arguments</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        default: Default return value if function fails</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        **kwargs: Keyword arguments</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Function result or default value on exception</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # In a production system, you might want to log this error</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # But we need to be careful not to create recursive logging</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Safe call failed for </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">func.</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">file</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">sys.stderr)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> default</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> should_log</span><span style=\"color:#E1E4E8\">(message_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, configured_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Determine if message should be logged based on level filtering.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        message_level: Severity level of the message</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        configured_level: Minimum level configured for the logger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        True if message should be processed, False if it should be filtered</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> message_level </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> configured_level</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeletons\">Core Logic Skeletons</h4>\n<p><strong>Logger Implementation (<code>logger.py</code>)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Core Logger and LogRecord classes - implement these according to the milestone requirements.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .utils.validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> should_log, safe_call</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .context </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_current_context</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Log level constants - use these exact values</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">WARN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FATAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 50</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LogRecord</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Structured log record containing all information about a logging event.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, timestamp: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 logger_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timestamp</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.level </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> level</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.message </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> message</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logger_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_dict</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert log record to dictionary for JSON serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create base dictionary with timestamp, level, message, logger_name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add context fields to the dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure consistent field ordering for predictable output</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle any non-serializable values in context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Logger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Main logging interface with hierarchy support and handler dispatch.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    This class implements the core logging functionality including level filtering,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    context enrichment, and handler dispatch to multiple output destinations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> INFO</span><span style=\"color:#E1E4E8\">, parent: Optional[</span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.level </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> level</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.parent </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parent</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.handlers: List[Handler] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.children: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Logger] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log</span><span style=\"color:#E1E4E8\">(self, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Main logging entry point with filtering and dispatch.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            level: Severity level of the message</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            message: Human-readable description of the event</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            **context: Additional key-value pairs for structured data</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if message should be logged using should_log function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Get current timestamp in ISO 8601 format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Retrieve current context from context manager and merge with **context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create LogRecord object with all information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Dispatch record to all configured handlers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: If no handlers on this logger, propagate to parent logger</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use threading.RLock to ensure thread safety during handler iteration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> debug</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log message at DEBUG level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log with DEBUG level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> info</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log message at INFO level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log with INFO level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> warn</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log message at WARN level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log with WARN level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> error</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log message at ERROR level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log with ERROR level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fatal</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log message at FATAL level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call self.log with FATAL level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_handler</span><span style=\"color:#E1E4E8\">(self, handler) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add handler to this logger's dispatch list.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire lock for thread safety</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add handler to handlers list if not already present</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Initialize handler if needed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_child</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get or create child logger with inherited configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if child already exists in self.children</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If not, create new Logger with self as parent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Inherit level and handlers from parent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store in children dictionary and return</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Child logger name should be f\"{self.name}.{name}\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global logger registry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_logger_registry: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Logger] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_registry_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_logger</span><span style=\"color:#E1E4E8\">(name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Logger:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Get or create logger instance with the given name.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        name: Hierarchical logger name (e.g., \"app.database.connection\")</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Logger instance for the given name</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if logger already exists in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If not, create logger hierarchy based on name (split by '.')</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure parent loggers are created first</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store new loggers in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return requested logger</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use _registry_lock for thread safety</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Handler Base Class (<code>handlers/__init__.py</code>)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Base handler class and common handler utilities.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..logger </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Handler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Abstract base class for all log handlers.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.formatter: Optional[</span><span style=\"color:#9ECBFF\">'Formatter'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> emit</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Process and output a single log record.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            record: LogRecord to be processed and output</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> flush</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Ensure all buffered records are written to destination.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Default implementation does nothing - override if handler buffers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> close</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Release resources and perform cleanup.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Default implementation does nothing - override if handler has resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_formatter</span><span style=\"color:#E1E4E8\">(self, formatter) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Configure formatter for this handler.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.formatter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> formatter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> format_record</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Format record using configured formatter.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.formatter:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.formatter.format(record)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Default formatting if no formatter configured</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"[</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record.timestamp</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">] </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record.level</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record.message</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<h4 id=\"file-structure-setup\">File Structure Setup</h4>\n<p>Create the recommended directory structure with these commands:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">mkdir</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#9ECBFF\"> structured_logging/{handlers,formatters,context,utils,config,tests/{unit,integration,performance}}</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">touch</span><span style=\"color:#9ECBFF\"> structured_logging/__init__.py</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">touch</span><span style=\"color:#9ECBFF\"> structured_logging/{logger,handlers,formatters,context,utils,config}/__init__.py</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Checkpoint - Logger Core</strong>\nAfter implementing the core logger functionality:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic logging functionality</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from structured_logging import get_logger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = get_logger('test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('Test message', user_id=123)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.error('Error occurred', error_code='E001')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Messages should appear on console (if console handler configured)</li>\n<li>DEBUG messages should be filtered out when logger level is INFO or higher</li>\n<li>Context fields (user_id, error_code) should be included in output</li>\n<li>Multiple threads calling logger methods should not corrupt output</li>\n</ul>\n<p><strong>Milestone 2 Checkpoint - Structured Output</strong>\nAfter implementing JSON formatting:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test JSON output formatting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> structured_logging </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_logger</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> structured_logging.formatters.json </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> JSONFormatter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> structured_logging.handlers.console </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ConsoleHandler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ConsoleHandler()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">handler.set_formatter(JSONFormatter())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.add_handler(handler)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.info(</span><span style=\"color:#9ECBFF\">'User action'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">action</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'login'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">user_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">123</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>Expected output (single line JSON):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">json</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">\"timestamp\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"2024-01-15T10:30:45.123456Z\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"level\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"message\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"User action\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"logger_name\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"test\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"action\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"login\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"user_id\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#79B8FF\">123</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"success\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#79B8FF\">true</span><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone 3 Checkpoint - Context &amp; Correlation</strong>\nAfter implementing context propagation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test context propagation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> structured_logging </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_logger, with_context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> structured_logging.context </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> correlation_id</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">with</span><span style=\"color:#E1E4E8\"> with_context(</span><span style=\"color:#FFAB70\">request_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">correlation_id(), </span><span style=\"color:#FFAB70\">user_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">456</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.info(</span><span style=\"color:#9ECBFF\">'Processing request'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> nested_function</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.info(</span><span style=\"color:#9ECBFF\">'Inside nested function'</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should inherit context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    nested_function()</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Both log messages should contain the same request_id and user_id</li>\n<li>Context should propagate through nested function calls without explicit passing</li>\n<li>Each request should have a unique correlation ID</li>\n</ul>\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<ul>\n<li>Use <code>threading.RLock()</code> instead of <code>Lock()</code> for reentrant locking in logger hierarchy</li>\n<li><code>datetime.utcnow().isoformat() + &#39;Z&#39;</code> provides ISO 8601 timestamps</li>\n<li><code>**dict1, **dict2</code> syntax merges dictionaries in Python 3.5+</li>\n<li><code>threading.local()</code> provides thread-local storage for context propagation</li>\n<li><code>contextvars</code> module (Python 3.7+) handles async context better than threading.local</li>\n<li><code>sys.stderr.write()</code> avoids recursive logging when reporting logging system errors</li>\n<li>Use <code>json.dumps(separators=(&#39;,&#39;, &#39;:&#39;))</code> for compact JSON output</li>\n<li><code>functools.wraps</code> preserves function metadata in decorators for context managers</li>\n</ul>\n<h4 id=\"common-debugging-issues\">Common Debugging Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No log output appears</td>\n<td>No handlers configured or wrong level</td>\n<td>Add console handler, check logger.level vs message level</td>\n</tr>\n<tr>\n<td>Thread safety errors</td>\n<td>Missing locks around shared data</td>\n<td>Use threading.RLock around handler lists and logger registry</td>\n</tr>\n<tr>\n<td>Context not propagating</td>\n<td>Thread-local storage not inherited</td>\n<td>Implement proper context copying in nested calls</td>\n</tr>\n<tr>\n<td>JSON serialization errors</td>\n<td>Non-serializable objects in context</td>\n<td>Use SafeJSONEncoder and safe_serialize function</td>\n</tr>\n<tr>\n<td>Performance degradation</td>\n<td>Synchronous I/O in handlers</td>\n<td>Implement async handlers or background thread dispatch</td>\n</tr>\n</tbody></table>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section defines the foundational data structures used across all three milestones, with LogRecord and LogLevel supporting Milestone 1 (Logger Core), structured output requirements for Milestone 2 (Structured Output), and Context objects enabling Milestone 3 (Context &amp; Correlation).</p>\n</blockquote>\n<p>The data model forms the backbone of our structured logging system, defining how log information is represented, organized, and processed throughout the entire logging pipeline. Think of the data model as the <strong>blueprint for a filing system</strong> in a busy law firm - every piece of information has a specific place, format, and relationship to other pieces, ensuring that when thousands of documents (log records) flow through the system daily, they can be efficiently organized, searched, and correlated.</p>\n<p>Just as a law firm needs consistent document formats to handle cases involving multiple lawyers, departments, and time periods, our logging system needs consistent data structures to handle log messages from multiple threads, services, and request contexts. The data model ensures that whether a log record originates from a background task, an HTTP request handler, or an async coroutine, it follows the same structure and can be processed uniformly by formatters and handlers.</p>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fdata-model-relationships.svg\" alt=\"Data Model Relationships\"></p>\n<p>The three core data structures - <code>LogRecord</code>, <code>LogLevel</code>, and <code>Context</code> - work together to provide a complete logging solution. The <code>LogRecord</code> serves as the central container for all log information, the <code>LogLevel</code> provides a hierarchy for filtering and prioritization, and the <code>Context</code> enables correlation and enrichment across related operations.</p>\n<blockquote>\n<p><strong>Design Principle</strong>: Every piece of log data has a well-defined structure and type, enabling consistent processing, serialization, and querying regardless of the log&#39;s origin or destination.</p>\n</blockquote>\n<h3 id=\"logrecord-structure\">LogRecord Structure</h3>\n<p>The <code>LogRecord</code> represents a single log entry in our system, containing all the information necessary to understand what happened, when it happened, where it happened, and under what circumstances. Think of a <code>LogRecord</code> as a <strong>standardized incident report form</strong> that emergency responders fill out - it has specific fields for date, time, location, severity, description, and context, ensuring that no matter who creates the report or where it&#39;s processed, all the essential information is captured in a consistent format.</p>\n<p>The <code>LogRecord</code> structure balances completeness with performance, including only the fields necessary for effective debugging and monitoring while remaining lightweight enough for high-volume logging scenarios.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>timestamp</code></td>\n<td><code>str</code></td>\n<td>ISO 8601 formatted timestamp indicating when the log record was created, with microsecond precision</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td><code>int</code></td>\n<td>Numeric log level (10-50) indicating the severity and importance of the message</td>\n</tr>\n<tr>\n<td><code>message</code></td>\n<td><code>str</code></td>\n<td>Human-readable description of the logged event, formatted with any provided arguments</td>\n</tr>\n<tr>\n<td><code>logger_name</code></td>\n<td><code>str</code></td>\n<td>Hierarchical name of the logger that created this record (e.g., &quot;app.database.connection&quot;)</td>\n</tr>\n<tr>\n<td><code>context</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Key-value pairs providing additional structured information about the logged event</td>\n</tr>\n</tbody></table>\n<p>The <code>timestamp</code> field uses ISO 8601 format (e.g., &quot;2023-10-15T14:30:45.123456Z&quot;) to ensure consistent parsing across different systems and time zones. This format is chosen over Unix timestamps because it&#39;s human-readable in log files while remaining machine-parseable for aggregation systems.</p>\n<p>The <code>level</code> field stores the numeric representation of the log level rather than the string name for efficient filtering operations. Converting &quot;DEBUG&quot; string comparisons to integer comparisons (10 &lt; 20) provides significant performance benefits when processing high volumes of log messages.</p>\n<p>The <code>logger_name</code> captures the complete hierarchical path of the logger, enabling log aggregation and filtering by component or subsystem. For example, &quot;app.web.auth.login&quot; indicates this log came from the login component of the authentication subsystem of the web layer.</p>\n<blockquote>\n<p><strong>Decision: Flat LogRecord Structure</strong></p>\n<ul>\n<li><strong>Context</strong>: We need to balance query flexibility with serialization performance and cross-language compatibility.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Nested object structure with separate metadata objects</li>\n<li>Flat structure with all fields at the top level</li>\n<li>Extensible structure with custom field registration</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Flat structure with fixed core fields and flexible context dictionary</li>\n<li><strong>Rationale</strong>: Flat structures serialize faster to JSON, are easier to query in log aggregation systems, and avoid the complexity of nested object validation while still providing extensibility through the context field</li>\n<li><strong>Consequences</strong>: Enables fast JSON serialization and simple log queries, but requires discipline to avoid context field name conflicts</li>\n</ul>\n</blockquote>\n<p>The <code>context</code> field serves as the extensibility point for the <code>LogRecord</code>, allowing arbitrary structured data to be attached to log entries without modifying the core structure. This field supports the correlation and enrichment patterns needed in distributed systems.</p>\n<p><strong>Context Field Usage Patterns:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Usage Pattern</th>\n<th>Example Keys</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Correlation</td>\n<td><code>request_id</code>, <code>trace_id</code>, <code>span_id</code></td>\n<td>Identifiers linking related log entries across service boundaries</td>\n</tr>\n<tr>\n<td>User Context</td>\n<td><code>user_id</code>, <code>session_id</code>, <code>organization_id</code></td>\n<td>Identity information for access correlation and debugging</td>\n</tr>\n<tr>\n<td>Performance Metrics</td>\n<td><code>duration_ms</code>, <code>query_time</code>, <code>cache_hit</code></td>\n<td>Timing and performance data for monitoring and optimization</td>\n</tr>\n<tr>\n<td>Error Details</td>\n<td><code>error_code</code>, <code>stack_trace</code>, <code>retry_count</code></td>\n<td>Structured error information for debugging and alerting</td>\n</tr>\n<tr>\n<td>Business Context</td>\n<td><code>order_id</code>, <code>product_id</code>, <code>workflow_step</code></td>\n<td>Domain-specific identifiers for business logic debugging</td>\n</tr>\n</tbody></table>\n<p>The <code>LogRecord</code> design emphasizes <strong>immutability</strong> - once created, a log record should not be modified. This prevents race conditions in multi-threaded environments and ensures that log records remain consistent as they flow through the handler dispatch system.</p>\n<h3 id=\"log-level-hierarchy\">Log Level Hierarchy</h3>\n<p>The log level hierarchy provides a standardized way to categorize log messages by importance and urgency, enabling runtime filtering and appropriate routing of messages to different output destinations. Think of log levels as a <strong>hospital triage system</strong> - just as medical staff categorize patients by urgency (critical, urgent, standard, routine) to ensure the most important cases receive immediate attention, log levels categorize messages so that critical errors are never missed while verbose debug information can be filtered out in production.</p>\n<p>The five-level hierarchy balances granularity with simplicity, providing enough categories to enable meaningful filtering without creating confusion about which level to choose for a given message.</p>\n<table>\n<thead>\n<tr>\n<th>Level Name</th>\n<th>Numeric Value</th>\n<th>Usage Guidelines</th>\n<th>Production Visibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>DEBUG</code></td>\n<td>10</td>\n<td>Detailed diagnostic information for development troubleshooting</td>\n<td>Typically filtered out</td>\n</tr>\n<tr>\n<td><code>INFO</code></td>\n<td>20</td>\n<td>General application flow and business logic milestones</td>\n<td>Selectively logged</td>\n</tr>\n<tr>\n<td><code>WARN</code></td>\n<td>30</td>\n<td>Warning conditions that don&#39;t prevent operation but may indicate problems</td>\n<td>Always logged</td>\n</tr>\n<tr>\n<td><code>ERROR</code></td>\n<td>40</td>\n<td>Error conditions that prevent specific operations but don&#39;t crash the application</td>\n<td>Always logged and monitored</td>\n</tr>\n<tr>\n<td><code>FATAL</code></td>\n<td>50</td>\n<td>Critical errors that may cause application shutdown or data corruption</td>\n<td>Always logged, triggers alerts</td>\n</tr>\n</tbody></table>\n<p>The numeric values are spaced by 10 to allow for future intermediate levels if needed, following the convention established by systems like Python&#39;s logging module. This spacing provides flexibility while maintaining the core five-level structure.</p>\n<p><strong>Level Filtering Behavior:</strong></p>\n<p>The log level filtering follows a simple rule: messages are processed only if their level is greater than or equal to the configured minimum level. For example, a logger configured at <code>INFO</code> level (20) will process <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>, and <code>FATAL</code> messages while filtering out <code>DEBUG</code> messages.</p>\n<table>\n<thead>\n<tr>\n<th>Configured Level</th>\n<th>DEBUG (10)</th>\n<th>INFO (20)</th>\n<th>WARN (30)</th>\n<th>ERROR (40)</th>\n<th>FATAL (50)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>DEBUG (10)</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n</tr>\n<tr>\n<td>INFO (20)</td>\n<td>✗ Filter</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n</tr>\n<tr>\n<td>WARN (30)</td>\n<td>✗ Filter</td>\n<td>✗ Filter</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n</tr>\n<tr>\n<td>ERROR (40)</td>\n<td>✗ Filter</td>\n<td>✗ Filter</td>\n<td>✗ Filter</td>\n<td>✓ Process</td>\n<td>✓ Process</td>\n</tr>\n<tr>\n<td>FATAL (50)</td>\n<td>✗ Filter</td>\n<td>✗ Filter</td>\n<td>✗ Filter</td>\n<td>✗ Filter</td>\n<td>✓ Process</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Numeric Log Levels with Fixed Hierarchy</strong></p>\n<ul>\n<li><strong>Context</strong>: We need efficient runtime filtering and clear severity ordering for both humans and machines.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>String-based levels with runtime string comparison</li>\n<li>Numeric levels with fixed integer values</li>\n<li>Configurable custom level hierarchies</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Fixed numeric hierarchy with standard five levels</li>\n<li><strong>Rationale</strong>: Integer comparison (<code>message_level &gt;= configured_level</code>) is faster than string comparison, fixed hierarchy prevents configuration errors and ensures consistent behavior across environments, five levels provide sufficient granularity without decision paralysis</li>\n<li><strong>Consequences</strong>: Enables fast filtering operations and consistent cross-team usage, but prevents custom level definitions for specialized use cases</li>\n</ul>\n</blockquote>\n<p>The level hierarchy supports <strong>inheritance</strong> in logger hierarchies - child loggers inherit the minimum level from their parent unless explicitly overridden. This enables configuration patterns where an entire subsystem&#39;s logging level can be controlled by setting the parent logger&#39;s level.</p>\n<p><strong>Runtime Level Changes:</strong></p>\n<p>Log levels can be modified at runtime without requiring application restart, enabling dynamic debugging and troubleshooting. This capability is essential for production environments where restarting applications to enable debug logging is not feasible.</p>\n<p>The level change operation must be thread-safe and atomic to prevent inconsistent filtering behavior. Changes take effect immediately for new log messages, but do not affect log records already in the processing pipeline.</p>\n<h3 id=\"context-data-model\">Context Data Model</h3>\n<p>The context data model enables <strong>correlation and enrichment</strong> of log records with structured metadata that flows through the application execution context. Think of the context as a <strong>digital breadcrumb trail</strong> that follows a request or operation through the system - as the request moves from HTTP parsing to database queries to external API calls, each component can add relevant information to the trail while benefiting from information added by previous components.</p>\n<p>Context propagation is essential for debugging distributed systems and understanding the relationships between log entries that may be separated by time, threads, or even service boundaries.</p>\n<p><strong>Context Structure and Semantics:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Implementation</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Storage</td>\n<td><code>Dict[str, Any]</code></td>\n<td>Key-value pairs with string keys and arbitrary JSON-serializable values</td>\n</tr>\n<tr>\n<td>Inheritance</td>\n<td>Parent → Child</td>\n<td>Child contexts inherit all key-value pairs from their parent context</td>\n</tr>\n<tr>\n<td>Scope</td>\n<td>Thread/Task Local</td>\n<td>Context is automatically scoped to the current execution thread or async task</td>\n</tr>\n<tr>\n<td>Lifecycle</td>\n<td>Request Bounded</td>\n<td>Context typically created at request start and cleaned up at request end</td>\n</tr>\n<tr>\n<td>Propagation</td>\n<td>Automatic</td>\n<td>Context flows through function calls without explicit parameter passing</td>\n</tr>\n</tbody></table>\n<p>The context data model supports several inheritance and propagation patterns that enable both automatic context flow and explicit context management.</p>\n<p><strong>Context Inheritance Patterns:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Pattern</th>\n<th>Use Case</th>\n<th>Behavior</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Automatic Inheritance</td>\n<td>HTTP request processing</td>\n<td>Child operations inherit request ID and user context</td>\n<td>Request handler → Database call → Cache lookup</td>\n</tr>\n<tr>\n<td>Explicit Context Addition</td>\n<td>Component-specific metadata</td>\n<td>Components add their own context while preserving parent context</td>\n<td>Authentication adds user ID, database adds query time</td>\n</tr>\n<tr>\n<td>Context Isolation</td>\n<td>Background tasks</td>\n<td>New context created for background operations</td>\n<td>Async task spawned with empty context</td>\n</tr>\n<tr>\n<td>Context Override</td>\n<td>Error handling</td>\n<td>Specific fields can be overridden in child contexts</td>\n<td>Retry logic overrides attempt count</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Thread-Local Context Storage with Async Bridge</strong></p>\n<ul>\n<li><strong>Context</strong>: We need context to propagate automatically through function calls while supporting both synchronous and asynchronous execution models.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Explicit context parameter passing through all function calls</li>\n<li>Thread-local storage for synchronous code only</li>\n<li>Thread-local storage with async context variable bridge</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Thread-local storage with automatic async context preservation</li>\n<li><strong>Rationale</strong>: Thread-local storage eliminates the need to modify all function signatures while providing automatic propagation, async context variables ensure context survives task switches and coroutine boundaries, combination supports both sync and async patterns without code changes</li>\n<li><strong>Consequences</strong>: Enables seamless context propagation and cleaner function signatures, but requires careful lifecycle management to prevent context leaks</li>\n</ul>\n</blockquote>\n<p><strong>Context Lifecycle Management:</strong></p>\n<p>Context objects follow a clear lifecycle to prevent memory leaks and ensure proper isolation between different operations:</p>\n<ol>\n<li><strong>Creation</strong>: New context created at operation boundary (HTTP request, background task, etc.)</li>\n<li><strong>Population</strong>: Initial context fields added (request ID, user information, etc.)</li>\n<li><strong>Inheritance</strong>: Child operations inherit context and may add additional fields</li>\n<li><strong>Propagation</strong>: Context flows through synchronous calls via thread-local storage</li>\n<li><strong>Async Bridge</strong>: Context preserved across async/await boundaries using context variables</li>\n<li><strong>Cleanup</strong>: Context cleared at operation completion to prevent memory leaks</li>\n</ol>\n<p><strong>Context Field Naming Conventions:</strong></p>\n<p>To prevent field name conflicts and enable consistent querying, context fields follow standardized naming patterns:</p>\n<table>\n<thead>\n<tr>\n<th>Field Category</th>\n<th>Naming Pattern</th>\n<th>Examples</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Correlation IDs</td>\n<td><code>{scope}_id</code></td>\n<td><code>request_id</code>, <code>trace_id</code>, <code>span_id</code></td>\n<td>Linking related log entries</td>\n</tr>\n<tr>\n<td>User Context</td>\n<td><code>user_{attribute}</code></td>\n<td><code>user_id</code>, <code>user_role</code>, <code>user_org</code></td>\n<td>Identity and authorization context</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td><code>{metric}_{unit}</code></td>\n<td><code>duration_ms</code>, <code>memory_mb</code>, <code>cpu_percent</code></td>\n<td>Performance monitoring data</td>\n</tr>\n<tr>\n<td>Business Data</td>\n<td><code>{domain}_{entity}</code></td>\n<td><code>order_id</code>, <code>product_sku</code>, <code>workflow_step</code></td>\n<td>Business logic context</td>\n</tr>\n<tr>\n<td>Component Info</td>\n<td><code>{component}_{detail}</code></td>\n<td><code>db_query</code>, <code>api_endpoint</code>, <code>cache_key</code></td>\n<td>Component-specific information</td>\n</tr>\n</tbody></table>\n<p><strong>Context Serialization and Size Limits:</strong></p>\n<p>Context data must remain JSON-serializable to support structured output formats. The context system includes size estimation and circular reference detection to prevent serialization failures and excessive memory usage.</p>\n<table>\n<thead>\n<tr>\n<th>Constraint</th>\n<th>Limit</th>\n<th>Behavior When Exceeded</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Maximum Fields</td>\n<td>50</td>\n<td>Additional fields logged as warning, oldest fields preserved</td>\n</tr>\n<tr>\n<td>Maximum Field Size</td>\n<td>1KB per field</td>\n<td>Large fields truncated with indication of truncation</td>\n</tr>\n<tr>\n<td>Maximum Total Size</td>\n<td>10KB per context</td>\n<td>Context pruned starting with newest non-correlation fields</td>\n</tr>\n<tr>\n<td>Serialization Depth</td>\n<td>10 levels</td>\n<td>Deep nested objects flattened or truncated</td>\n</tr>\n<tr>\n<td>Circular References</td>\n<td>Not allowed</td>\n<td>Detected and replaced with reference marker</td>\n</tr>\n</tbody></table>\n<p>The context data model enables powerful correlation and debugging capabilities while maintaining performance and reliability constraints necessary for production logging systems.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This subsection provides concrete implementation patterns and starter code for the core data structures, focusing on thread safety, serialization, and performance considerations that junior developers commonly struggle with.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Timestamp Generation</td>\n<td><code>datetime.utcnow().isoformat()</code></td>\n<td><code>time.time_ns()</code> with custom ISO formatter</td>\n</tr>\n<tr>\n<td>JSON Serialization</td>\n<td><code>json.dumps()</code> with custom encoder</td>\n<td><code>orjson</code> or <code>ujson</code> for performance</td>\n</tr>\n<tr>\n<td>Thread-Local Storage</td>\n<td><code>threading.local()</code></td>\n<td><code>contextvars</code> for async support</td>\n</tr>\n<tr>\n<td>Context Size Estimation</td>\n<td><code>len(json.dumps())</code></td>\n<td>Custom recursive size calculator</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended Module Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n  core/\n    __init__.py           ← exports LogRecord, LogLevel constants\n    log_record.py         ← LogRecord class and factory functions\n    log_level.py          ← log level constants and filtering utilities\n    context.py            ← context management and propagation\n  utils/\n    serialization.py      ← safe JSON encoding and size estimation\n    thread_safety.py      ← thread-safe data structures\n  tests/\n    test_log_record.py    ← LogRecord creation and serialization tests\n    test_context.py       ← context propagation and inheritance tests</code></pre></div>\n\n<p><strong>Infrastructure Starter Code:</strong></p>\n<p>Complete implementation of thread-safe utilities and serialization helpers:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># utils/serialization.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> decimal </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Decimal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, date</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SafeJSONEncoder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">json</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JSONEncoder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Custom JSON encoder that handles non-serializable types safely.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> default</span><span style=\"color:#E1E4E8\">(self, obj: Any) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (datetime, date)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, Decimal):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__dict__'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">obj.</span><span style=\"color:#79B8FF\">__class__</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\"> object>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__str__'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;non-serializable: </span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(obj).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_serialize</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely serialize dictionary to JSON with circular reference protection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _check_depth</span><span style=\"color:#E1E4E8\">(obj, current_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> current_depth </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> max_depth:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;max_depth_exceeded: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">max_depth</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {k: _check_depth(v, current_depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj.items()}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, (</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> [_check_depth(item, current_depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> item </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> obj]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        safe_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> _check_depth(data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps(safe_data, </span><span style=\"color:#FFAB70\">cls</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SafeJSONEncoder, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">TypeError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">ValueError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps({</span><span style=\"color:#9ECBFF\">\"serialization_error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e)}, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> estimate_serialized_size</span><span style=\"color:#E1E4E8\">(data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Estimate JSON size without full serialization for performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Implement recursive size estimation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle strings, numbers, booleans with known sizes  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Estimate dict/list overhead (brackets, commas, quotes)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return estimated byte count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use sys.getsizeof() as baseline, add JSON syntax overhead</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># utils/thread_safety.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeDict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe dictionary wrapper for shared logging context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()  </span><span style=\"color:#6A737D\"># Re-entrant lock for nested access</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.get(key, default)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> update</span><span style=\"color:#E1E4E8\">(self, other: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data.update(other)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> copy</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.copy()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data.clear()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeCounter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe counter for generating unique IDs.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, initial_value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> initial_value</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> next</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># core/log_level.py</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">WARN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FATAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 50</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Level name mappings for display</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">LEVEL_NAMES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEBUG</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"DEBUG\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INFO</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"INFO\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARN</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"WARN\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"ERROR\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FATAL</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"FATAL\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> should_log</span><span style=\"color:#E1E4E8\">(message_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, configured_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Determine if message should be logged based on level filtering.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compare message_level against configured_level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return True if message_level >= configured_level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle invalid level values (default to allowing the message)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Simple integer comparison, but validate inputs first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># core/log_record.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .log_level </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> LEVEL_NAMES</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LogRecord</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Immutable log record containing all information for a single log entry.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, timestamp: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 logger_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store all parameters as instance attributes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Make context a copy to ensure immutability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate that level is a known log level value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure timestamp is ISO 8601 format string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use context.copy() to prevent external modification</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_dict</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert log record to dictionary for JSON serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create dictionary with all core fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add level_name field for human readability  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Merge in context fields at top level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return complete dictionary ready for JSON serialization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use LEVEL_NAMES mapping to get level_name from numeric level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create</span><span style=\"color:#E1E4E8\">(cls, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, logger_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">               context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'LogRecord'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Factory method to create LogRecord with current timestamp.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate ISO 8601 timestamp string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle None context by providing empty dict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create and return LogRecord instance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Consider timezone handling for timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use datetime.utcnow().isoformat() + 'Z' for UTC timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># core/context.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextvars</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Context variable for async context preservation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_context_var: contextvars.ContextVar[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> contextvars.ContextVar(</span><span style=\"color:#9ECBFF\">'log_context'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{})</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Thread-local storage for sync context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_thread_local </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.local()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LoggingContext</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages logging context with thread-local and async support.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_current</span><span style=\"color:#E1E4E8\">() -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current logging context, trying async context first.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Try to get context from contextvars (for async)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Fall back to thread-local storage (for sync)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return empty dict if no context is set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle AttributeError from thread-local access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use try/except for both contextvar and thread-local access</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_current</span><span style=\"color:#E1E4E8\">(context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set current logging context in both async and sync storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Set context in contextvars for async compatibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set context in thread-local storage for sync compatibility  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle case where context is None</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure context is copied to prevent external modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Set both _context_var and _thread_local.context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_fields</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">fields: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add fields to current context without replacing existing context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get current context dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create new context with existing fields plus new fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Set the updated context as current</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle case where no current context exists</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use get_current(), update with new fields, call set_current()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clear current logging context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clear contextvars context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clear thread-local context  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle AttributeError if thread-local not initialized</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure both storage mechanisms are cleared</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Set empty dict in both storage locations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Language-Specific Implementation Hints:</strong></p>\n<ul>\n<li><strong>Thread Safety</strong>: Use <code>threading.RLock()</code> instead of <code>Lock()</code> for context management to allow re-entrant access within the same thread</li>\n<li><strong>Async Context</strong>: Python&#39;s <code>contextvars</code> automatically handles async context preservation across <code>await</code> boundaries</li>\n<li><strong>JSON Serialization</strong>: The <code>json</code> module&#39;s <code>separators=(&#39;,&#39;, &#39;:&#39;)</code> parameter eliminates whitespace for compact output</li>\n<li><strong>Immutability</strong>: Use <code>context.copy()</code> in LogRecord constructor to prevent external modification of context data</li>\n<li><strong>Performance</strong>: Consider <code>__slots__</code> on LogRecord class to reduce memory overhead for high-volume logging</li>\n</ul>\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the data model:</p>\n<ol>\n<li><strong>Run Unit Tests</strong>: <code>python -m pytest tests/test_log_record.py tests/test_context.py -v</code></li>\n<li><strong>Expected Output</strong>: All tests pass, demonstrating LogRecord creation, serialization, and context propagation</li>\n<li><strong>Manual Verification</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">   from</span><span style=\"color:#E1E4E8\"> core.log_record </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">   from</span><span style=\"color:#E1E4E8\"> core.context </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LoggingContext</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Test LogRecord creation and serialization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   record </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> LogRecord.create(</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Test message\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"test.logger\"</span><span style=\"color:#E1E4E8\">, {</span><span style=\"color:#9ECBFF\">\"user_id\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">123</span><span style=\"color:#E1E4E8\">})</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">   print</span><span style=\"color:#E1E4E8\">(record.to_dict())  </span><span style=\"color:#6A737D\"># Should show structured dictionary</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Test context propagation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   LoggingContext.set_current({</span><span style=\"color:#9ECBFF\">\"request_id\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"abc123\"</span><span style=\"color:#E1E4E8\">})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> LoggingContext.get_current()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">   print</span><span style=\"color:#E1E4E8\">(context)  </span><span style=\"color:#6A737D\"># Should show {\"request_id\": \"abc123\"}</span></span></code></pre></div>\n\n<ol start=\"4\">\n<li><strong>Signs of Problems</strong>:<ul>\n<li><strong>Serialization failures</strong>: Check SafeJSONEncoder implementation and circular reference handling  </li>\n<li><strong>Context not propagating</strong>: Verify both contextvars and thread-local storage are being set</li>\n<li><strong>Thread safety issues</strong>: Add logging to identify race conditions in concurrent tests</li>\n<li><strong>Memory leaks</strong>: Ensure context.clear() is called and contexts are properly scoped</li>\n</ul>\n</li>\n</ol>\n<p>The data model implementation provides the foundation for all subsequent logging functionality, ensuring consistent data representation and thread-safe operations across the entire system.</p>\n<h2 id=\"logger-core-design\">Logger Core Design</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section primarily addresses Milestone 1 (Logger Core) by defining the central logging infrastructure, hierarchy system, level filtering, thread safety mechanisms, and handler dispatch patterns that form the foundation for all subsequent structured logging capabilities.</p>\n</blockquote>\n<h3 id=\"mental-model-the-news-organization\">Mental Model: The News Organization</h3>\n<p>Think of the logging system as a large news organization with multiple departments and bureaus. The <strong>logger hierarchy</strong> works like the organizational chart — the main newsroom (<code>root</code> logger) oversees regional bureaus (<code>child</code> loggers), which in turn manage local reporters (<code>leaf</code> loggers). Each level inherits editorial standards and distribution channels from above, but can add their own specific context and formatting.</p>\n<p><strong>Log level filtering</strong> operates like editorial decisions about what stories make it to print. A DEBUG message is like a reporter&#39;s personal note — interesting for development but filtered out in production. An ERROR message is like breaking news that must reach every output channel immediately. The <strong>handler dispatch system</strong> functions like the news distribution network — the same story (log record) gets formatted appropriately and sent to newspapers (console), archives (files), and wire services (remote collectors) simultaneously.</p>\n<p>This mental model helps understand why thread safety matters (multiple reporters filing stories concurrently), why context propagation is essential (maintaining story lineage), and why handler failure recovery is critical (ensuring important news reaches at least one destination).</p>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<h3 id=\"logger-hierarchy-system\">Logger Hierarchy System</h3>\n<p>The logger hierarchy provides a tree-structured namespace that mirrors application architecture while enabling configuration inheritance and context flow. This design allows fine-grained control over logging behavior at different application layers without requiring explicit configuration at every level.</p>\n<h4 id=\"hierarchy-structure-and-naming\">Hierarchy Structure and Naming</h4>\n<p>The logger hierarchy follows a dot-separated naming convention that reflects application structure. The root logger sits at the top with an empty name, while child loggers use qualified names like <code>web</code>, <code>web.auth</code>, <code>web.auth.jwt</code>, and <code>database.connection.pool</code>. This naming strategy provides intuitive organization and enables powerful inheritance patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Logger Name</th>\n<th>Parent</th>\n<th>Level Inherited</th>\n<th>Handlers Inherited</th>\n<th>Context Inherited</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>`` (root)</td>\n<td>None</td>\n<td>INFO (default)</td>\n<td>[ConsoleHandler]</td>\n<td>{}</td>\n</tr>\n<tr>\n<td><code>web</code></td>\n<td>root</td>\n<td>INFO</td>\n<td>[ConsoleHandler]</td>\n<td>{service: &quot;web&quot;}</td>\n</tr>\n<tr>\n<td><code>web.auth</code></td>\n<td>web</td>\n<td>INFO</td>\n<td>[ConsoleHandler]</td>\n<td>{service: &quot;web&quot;, component: &quot;auth&quot;}</td>\n</tr>\n<tr>\n<td><code>web.auth.jwt</code></td>\n<td>web.auth</td>\n<td>DEBUG (overridden)</td>\n<td>[ConsoleHandler, FileHandler]</td>\n<td>{service: &quot;web&quot;, component: &quot;auth&quot;, module: &quot;jwt&quot;}</td>\n</tr>\n<tr>\n<td><code>database</code></td>\n<td>root</td>\n<td>WARN (overridden)</td>\n<td>[ConsoleHandler, RemoteHandler]</td>\n<td>{service: &quot;database&quot;}</td>\n</tr>\n</tbody></table>\n<p>Each logger maintains references to its parent and children, creating a bidirectional tree structure that supports both top-down configuration propagation and bottom-up context enrichment. The <code>Logger</code> type encapsulates this relationship:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>name</code></td>\n<td>str</td>\n<td>Dot-separated qualified name identifying this logger&#39;s position in hierarchy</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td>int</td>\n<td>Minimum log level for this logger (DEBUG=10, INFO=20, WARN=30, ERROR=40, FATAL=50)</td>\n</tr>\n<tr>\n<td><code>parent</code></td>\n<td>Logger</td>\n<td>Reference to parent logger for inheritance, None only for root logger</td>\n</tr>\n<tr>\n<td><code>handlers</code></td>\n<td>List[Handler]</td>\n<td>Output destinations specific to this logger, combined with inherited handlers</td>\n</tr>\n<tr>\n<td><code>children</code></td>\n<td>Dict[str, Logger]</td>\n<td>Map of child logger names to Logger instances for hierarchy navigation</td>\n</tr>\n<tr>\n<td><code>context</code></td>\n<td>Dict[str, Any]</td>\n<td>Key-value pairs automatically attached to all log records from this logger</td>\n</tr>\n<tr>\n<td><code>propagate</code></td>\n<td>bool</td>\n<td>Whether log records should bubble up to parent handlers (default True)</td>\n</tr>\n</tbody></table>\n<h4 id=\"configuration-inheritance-behavior\">Configuration Inheritance Behavior</h4>\n<p>Configuration inheritance flows down the hierarchy, with child loggers inheriting level, handlers, and context from their parents while maintaining the ability to override or extend these settings. This inheritance mechanism reduces configuration duplication while preserving flexibility for special cases.</p>\n<p><strong>Level inheritance</strong> follows a &quot;most specific wins&quot; pattern. If a logger doesn&#39;t have an explicitly configured level, it inherits from its parent, walking up the hierarchy until it finds a configured level or reaches the root (which defaults to INFO). This approach ensures predictable behavior while minimizing configuration overhead.</p>\n<p><strong>Handler inheritance</strong> combines parent and child handlers unless explicitly disabled. When a log record is generated, it gets dispatched to the logger&#39;s own handlers plus all inherited handlers from parent loggers. The <code>propagate</code> flag controls whether records bubble up to parent handlers, enabling scenarios where sensitive components log only to specific destinations.</p>\n<p><strong>Context inheritance</strong> merges parent context fields with child-specific fields, with child values taking precedence for duplicate keys. This creates a natural layering where service-level context (like <code>service: &quot;web&quot;</code>) gets automatically combined with component-level context (like <code>component: &quot;auth&quot;</code>) and request-specific context (like <code>request_id: &quot;abc123&quot;</code>).</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The inheritance model balances convenience with control. Most loggers inherit sensible defaults, reducing boilerplate configuration, while performance-critical or security-sensitive components can override settings precisely where needed.</p>\n</blockquote>\n<h4 id=\"logger-factory-and-lifecycle\">Logger Factory and Lifecycle</h4>\n<p>The logger hierarchy uses a factory pattern to ensure singleton behavior and proper parent-child linking. The <code>get_logger(name)</code> function serves as the single entry point for logger creation, maintaining a global registry to prevent duplicate instances and ensure consistent hierarchy structure.</p>\n<p><strong>Logger Creation Process</strong>:</p>\n<ol>\n<li>Parse the requested logger name to identify hierarchy path components</li>\n<li>Walk the hierarchy from root to target, creating any missing intermediate loggers</li>\n<li>Link each new logger to its parent and register it in the parent&#39;s children dictionary</li>\n<li>Initialize the new logger with inherited configuration from its parent</li>\n<li>Register the logger in the global name-to-instance mapping for future lookups</li>\n<li>Return the logger instance (creating or retrieving existing)</li>\n</ol>\n<p>The factory maintains thread safety through a global lock during logger creation, ensuring that concurrent requests for the same logger name return the same instance without race conditions. Once created, loggers are immutable in their hierarchy relationships but mutable in their configuration to support runtime level changes.</p>\n<blockquote>\n<p><strong>Architecture Decision: Singleton Logger Instances</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple parts of an application may request loggers with the same name</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Create new logger instances for each request</li>\n<li>Use singleton pattern with global registry</li>\n<li>Require explicit logger instance passing</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Singleton pattern with global registry</li>\n<li><strong>Rationale</strong>: Ensures consistent configuration and context across all usage sites, eliminates need for dependency injection of logger instances, simplifies logger hierarchy management</li>\n<li><strong>Consequences</strong>: Global state requires thread safety, enables convenient logger access but reduces testability, configuration changes affect all code using the same logger name</li>\n</ul>\n</blockquote>\n<h3 id=\"log-level-filtering\">Log Level Filtering</h3>\n<p>Log level filtering provides the primary mechanism for controlling logging verbosity in different environments. The filtering system must be efficient enough for hot code paths while supporting runtime reconfiguration without application restart.</p>\n<h4 id=\"level-hierarchy-and-numeric-ordering\">Level Hierarchy and Numeric Ordering</h4>\n<p>The log level system uses numeric values to enable efficient comparison and filtering. Higher numbers indicate higher severity, making the filtering logic a simple numeric comparison rather than complex string matching or lookup operations.</p>\n<table>\n<thead>\n<tr>\n<th>Level Name</th>\n<th>Numeric Value</th>\n<th>Typical Usage</th>\n<th>Production Visibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>DEBUG</code></td>\n<td>10</td>\n<td>Detailed diagnostic information</td>\n<td>Hidden</td>\n</tr>\n<tr>\n<td><code>INFO</code></td>\n<td>20</td>\n<td>General application flow</td>\n<td>Visible</td>\n</tr>\n<tr>\n<td><code>WARN</code></td>\n<td>30</td>\n<td>Unusual but handled conditions</td>\n<td>Visible</td>\n</tr>\n<tr>\n<td><code>ERROR</code></td>\n<td>40</td>\n<td>Error conditions requiring attention</td>\n<td>Always visible</td>\n</tr>\n<tr>\n<td><code>FATAL</code></td>\n<td>50</td>\n<td>Critical errors causing termination</td>\n<td>Always visible</td>\n</tr>\n</tbody></table>\n<p>The <code>should_log(message_level, configured_level)</code> function implements the core filtering logic with a simple comparison: <code>message_level &gt;= configured_level</code>. This design ensures that setting a logger to WARN level will include WARN, ERROR, and FATAL messages while filtering out DEBUG and INFO messages.</p>\n<h4 id=\"efficient-level-checking\">Efficient Level Checking</h4>\n<p>The level filtering system optimizes for the common case where messages are filtered out. The <code>log()</code> method performs level checking before any expensive operations like string formatting, context gathering, or handler dispatch. This early-exit pattern prevents performance degradation when verbose logging is enabled in hot code paths.</p>\n<p><strong>Level Check Optimization Strategy</strong>:</p>\n<ol>\n<li>Check message level against logger&#39;s configured level using simple integer comparison</li>\n<li>Exit immediately if message should be filtered, avoiding all downstream processing</li>\n<li>Only proceed with LogRecord creation, formatting, and handler dispatch for messages that pass filtering</li>\n<li>Cache the logger&#39;s effective level to avoid walking parent hierarchy on every message</li>\n</ol>\n<p>The effective level calculation walks up the logger hierarchy to find the nearest explicitly configured level, but this traversal only occurs when the logger&#39;s level changes, not on every log message. The result gets cached in the logger instance until configuration changes invalidate the cache.</p>\n<h4 id=\"runtime-level-reconfiguration\">Runtime Level Reconfiguration</h4>\n<p>The logging system supports runtime level changes without application restart, enabling dynamic debugging and troubleshooting in production environments. Level changes propagate through the hierarchy using a cache invalidation mechanism that ensures consistent behavior across all loggers.</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Thread Safety</th>\n<th>Propagation</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>set_level(level)</code></td>\n<td>Write lock on logger</td>\n<td>Invalidates child caches</td>\n<td>O(1) for single logger</td>\n</tr>\n<tr>\n<td><code>get_effective_level()</code></td>\n<td>Read lock on hierarchy</td>\n<td>Walks up parent chain</td>\n<td>O(depth) cached result</td>\n</tr>\n<tr>\n<td><code>should_log(level)</code></td>\n<td>Read-only comparison</td>\n<td>No propagation needed</td>\n<td>O(1) cached lookup</td>\n</tr>\n</tbody></table>\n<p><strong>Level Change Propagation</strong>:</p>\n<ol>\n<li>Acquire write lock on target logger to prevent concurrent modifications</li>\n<li>Update logger&#39;s configured level and invalidate its cached effective level</li>\n<li>Walk all descendant loggers and invalidate their cached effective levels</li>\n<li>Release locks and allow normal logging operations to resume</li>\n<li>Next log operation on each affected logger recalculates effective level as needed</li>\n</ol>\n<blockquote>\n<p><strong>Design Insight</strong>: Runtime level changes are intentionally rare operations that can afford more expensive propagation logic. The common case of level checking during normal logging remains highly optimized with cached effective levels.</p>\n</blockquote>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Flogger-hierarchy.svg\" alt=\"Logger Hierarchy Structure\"></p>\n<h3 id=\"thread-safety-design\">Thread Safety Design</h3>\n<p>The logging system must handle concurrent access from multiple threads without corrupting output, losing messages, or introducing race conditions. The thread safety design balances correctness with performance, ensuring that logging operations remain fast in single-threaded scenarios while providing strong guarantees in multi-threaded environments.</p>\n<h4 id=\"locking-strategy-and-granularity\">Locking Strategy and Granularity</h4>\n<p>The thread safety design employs a multi-level locking strategy with different granularity for different operations. This approach minimizes contention while ensuring data consistency across concurrent operations.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Lock Type</th>\n<th>Granularity</th>\n<th>Protected Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logger Registry</td>\n<td>RWLock</td>\n<td>Global</td>\n<td>Logger creation, hierarchy modification</td>\n</tr>\n<tr>\n<td>Logger Instance</td>\n<td>RWLock</td>\n<td>Per-logger</td>\n<td>Level changes, handler modification</td>\n</tr>\n<tr>\n<td>Handler Collection</td>\n<td>RWLock</td>\n<td>Per-logger</td>\n<td>Handler list modification</td>\n</tr>\n<tr>\n<td>Log Record Creation</td>\n<td>No lock</td>\n<td>Thread-local</td>\n<td>Timestamp, context capture</td>\n</tr>\n<tr>\n<td>Handler Dispatch</td>\n<td>Read lock</td>\n<td>Per-handler</td>\n<td>Output writing, formatting</td>\n</tr>\n</tbody></table>\n<p><strong>Hierarchical Locking Protocol</strong>:</p>\n<ol>\n<li>Global registry lock protects logger creation and hierarchy modifications</li>\n<li>Per-logger locks protect configuration changes like level and handler updates</li>\n<li>Handler dispatch uses read locks to allow concurrent logging while preventing configuration changes</li>\n<li>Lock ordering follows hierarchy depth to prevent deadlocks (parent before child)</li>\n<li>Operations acquire minimal lock scope and release as quickly as possible</li>\n</ol>\n<p>The locking protocol ensures that common operations (logging messages) require only read locks or no locks, while rare operations (configuration changes, logger creation) use write locks for consistency. This design maximizes concurrency for the typical workload while providing strong consistency guarantees.</p>\n<h4 id=\"handler-dispatch-concurrency\">Handler Dispatch Concurrency</h4>\n<p>Handler dispatch presents unique concurrency challenges because multiple threads may attempt to write to the same output destination simultaneously. The design provides thread safety at the handler level while allowing parallel dispatch to different handlers.</p>\n<p><strong>Concurrent Dispatch Strategy</strong>:</p>\n<ol>\n<li>Each handler maintains its own internal synchronization for thread-safe writing</li>\n<li>Multiple threads can dispatch to different handlers simultaneously</li>\n<li>Handlers implement internal buffering and atomic write operations</li>\n<li>Handler failure in one thread doesn&#39;t affect logging success in other threads</li>\n<li>Error handling and retry logic operate independently per handler per thread</li>\n</ol>\n<p>The <code>Handler</code> interface contract specifies that implementations must be thread-safe, allowing the logger to dispatch to multiple handlers concurrently without additional synchronization. This design pushes the thread safety responsibility to the component best positioned to handle it efficiently.</p>\n<h4 id=\"memory-consistency-and-visibility\">Memory Consistency and Visibility</h4>\n<p>Thread safety extends beyond locks to include memory consistency guarantees. The logging system ensures that configuration changes made by one thread become visible to other threads promptly and consistently.</p>\n<table>\n<thead>\n<tr>\n<th>Memory Concern</th>\n<th>Solution</th>\n<th>Guarantee</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Level changes</td>\n<td>Write barriers in setters</td>\n<td>New levels visible before lock release</td>\n</tr>\n<tr>\n<td>Handler modifications</td>\n<td>Copy-on-write collections</td>\n<td>Atomic handler list updates</td>\n</tr>\n<tr>\n<td>Context propagation</td>\n<td>Thread-local storage</td>\n<td>Per-thread context isolation</td>\n</tr>\n<tr>\n<td>Logger hierarchy</td>\n<td>Immutable parent references</td>\n<td>Safe concurrent hierarchy traversal</td>\n</tr>\n<tr>\n<td>Cached effective levels</td>\n<td>Volatile flags for invalidation</td>\n<td>Cache invalidation visible across threads</td>\n</tr>\n</tbody></table>\n<p>The memory consistency design uses a combination of proper locking, volatile flags for cache invalidation, and copy-on-write collections for handler lists. This approach ensures that all threads observe consistent state without requiring global synchronization for read-heavy operations.</p>\n<blockquote>\n<p><strong>Architecture Decision: Fine-Grained Locking vs. Global Synchronization</strong></p>\n<ul>\n<li><strong>Context</strong>: Logging occurs frequently and from many threads, requiring high-performance thread safety</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Single global lock for all logging operations</li>\n<li>Per-logger locks with hierarchical ordering</li>\n<li>Lock-free algorithms with atomic operations</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Per-logger locks with read-write separation</li>\n<li><strong>Rationale</strong>: Global lock would serialize all logging operations hurting performance, lock-free algorithms are complex and error-prone, per-logger locks allow maximum concurrency while maintaining correctness</li>\n<li><strong>Consequences</strong>: Enables high-throughput concurrent logging, requires careful lock ordering to prevent deadlocks, adds complexity to configuration change operations</li>\n</ul>\n</blockquote>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Flog-processing-flow.svg\" alt=\"Log Processing Data Flow\"></p>\n<h3 id=\"handler-dispatch-mechanism\">Handler Dispatch Mechanism</h3>\n<p>The handler dispatch system routes log records to multiple output destinations while providing error isolation, failure recovery, and performance optimization. This multi-destination approach enables comprehensive logging strategies where the same message appears in local files, remote collectors, and console output simultaneously.</p>\n<h4 id=\"multi-destination-routing\">Multi-Destination Routing</h4>\n<p>Handler dispatch implements a fan-out pattern where each log record gets sent to all configured handlers for the logger and its ancestors (unless propagation is disabled). This design ensures comprehensive coverage while allowing different handlers to apply their own filtering, formatting, and delivery mechanisms.</p>\n<p><strong>Dispatch Routing Process</strong>:</p>\n<ol>\n<li>Collect all applicable handlers from logger and ancestor chain</li>\n<li>Create immutable LogRecord with timestamp, level, message, and context</li>\n<li>Dispatch record to each handler concurrently (when possible)</li>\n<li>Aggregate results from all handler operations</li>\n<li>Handle failures according to configured error policies</li>\n<li>Return success if at least one handler succeeded (or all failed)</li>\n</ol>\n<p>The handler collection process walks up the logger hierarchy, gathering handlers from each ancestor until it reaches the root or encounters a logger with <code>propagate=False</code>. This creates a comprehensive handler list that respects hierarchy while allowing fine-grained control over propagation.</p>\n<table>\n<thead>\n<tr>\n<th>Handler Type</th>\n<th>Purpose</th>\n<th>Concurrency</th>\n<th>Failure Tolerance</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ConsoleHandler</td>\n<td>Developer feedback</td>\n<td>Thread-safe writes</td>\n<td>Never fails</td>\n</tr>\n<tr>\n<td>FileHandler</td>\n<td>Local persistence</td>\n<td>Buffered writes</td>\n<td>Fails on disk full</td>\n</tr>\n<tr>\n<td>RemoteHandler</td>\n<td>Centralized logging</td>\n<td>Async network calls</td>\n<td>Fails on network issues</td>\n</tr>\n<tr>\n<td>SyslogHandler</td>\n<td>System integration</td>\n<td>UDP fire-and-forget</td>\n<td>Network failures ignored</td>\n</tr>\n</tbody></table>\n<h4 id=\"error-isolation-and-recovery\">Error Isolation and Recovery</h4>\n<p>Handler failures must not prevent other handlers from receiving log records or cause the logging operation to fail completely. The dispatch system implements error isolation to ensure that a failed file handler doesn&#39;t prevent console output or remote logging from succeeding.</p>\n<p><strong>Error Isolation Strategy</strong>:</p>\n<ol>\n<li>Each handler dispatch occurs within its own exception boundary</li>\n<li>Handler failures get logged to a separate error logger (avoiding recursion)</li>\n<li>Failed handlers can be marked as temporarily disabled with exponential backoff</li>\n<li>Dispatch continues to remaining handlers even after individual failures</li>\n<li>Success threshold determines overall operation success (e.g., &quot;at least one handler succeeded&quot;)</li>\n</ol>\n<p>The error isolation mechanism prevents cascading failures while providing visibility into handler health. A special error logger handles handler failures without using the same handlers that might be failing, typically writing to a simple file or console output.</p>\n<p><strong>Handler Failure Recovery</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Detection</th>\n<th>Recovery Action</th>\n<th>Backoff Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Network timeout</td>\n<td>Exception during send</td>\n<td>Retry with exponential backoff</td>\n<td>1s, 2s, 4s, up to 60s</td>\n</tr>\n<tr>\n<td>Disk full</td>\n<td>Write operation failure</td>\n<td>Disable temporarily, retry periodically</td>\n<td>Check every 30 seconds</td>\n</tr>\n<tr>\n<td>Permission denied</td>\n<td>File access error</td>\n<td>Log error, disable permanently</td>\n<td>No retry</td>\n</tr>\n<tr>\n<td>Memory exhaustion</td>\n<td>Buffer allocation failure</td>\n<td>Drop buffered messages, continue</td>\n<td>Immediate retry with smaller buffer</td>\n</tr>\n</tbody></table>\n<h4 id=\"asynchronous-handler-support\">Asynchronous Handler Support</h4>\n<p>High-throughput applications require asynchronous handler dispatch to prevent slow output destinations from blocking application threads. The handler system supports both synchronous and asynchronous handlers through a unified interface with different execution strategies.</p>\n<p><strong>Asynchronous Dispatch Architecture</strong>:</p>\n<ol>\n<li>Synchronous handlers execute immediately on the calling thread</li>\n<li>Asynchronous handlers queue log records for background processing</li>\n<li>Background worker threads process queued records with batching optimization</li>\n<li>Queue overflow protection prevents memory exhaustion during traffic spikes</li>\n<li>Graceful shutdown ensures all queued records get processed before exit</li>\n</ol>\n<p>The asynchronous handler implementation uses bounded queues with overflow policies to handle traffic spikes. When queues fill up, the system can either block the calling thread, drop the oldest records, or drop the newest records based on configured policy.</p>\n<table>\n<thead>\n<tr>\n<th>Queue Policy</th>\n<th>Behavior</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Block</td>\n<td>Wait for queue space</td>\n<td>Critical logs that must not be lost</td>\n</tr>\n<tr>\n<td>Drop Oldest</td>\n<td>Remove old records for new ones</td>\n<td>Real-time monitoring where recent data matters</td>\n</tr>\n<tr>\n<td>Drop Newest</td>\n<td>Reject new records when full</td>\n<td>Batch processing where old data has value</td>\n</tr>\n<tr>\n<td>Best Effort</td>\n<td>Try async, fall back to sync</td>\n<td>Development and testing scenarios</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-optimization\">Performance Optimization</h4>\n<p>Handler dispatch performance directly affects application throughput, especially for high-frequency logging. The system implements several optimizations to minimize latency and maximize throughput while maintaining correctness.</p>\n<p><strong>Dispatch Performance Optimizations</strong>:</p>\n<ol>\n<li><strong>Handler Filtering</strong>: Handlers can implement level filtering to avoid expensive formatting for filtered messages</li>\n<li><strong>Lazy Formatting</strong>: Message formatting occurs only when handlers need the formatted output</li>\n<li><strong>Batching</strong>: Asynchronous handlers batch multiple records to amortize network and I/O costs</li>\n<li><strong>Connection Pooling</strong>: Network handlers reuse connections to reduce setup overhead</li>\n<li><strong>Memory Pooling</strong>: LogRecord objects use object pools to reduce garbage collection pressure</li>\n</ol>\n<p>The lazy formatting optimization proves particularly valuable when handlers have different formatting requirements. The structured LogRecord contains raw data, while handlers request formatted output only when needed for their specific destination.</p>\n<blockquote>\n<p><strong>Performance Insight</strong>: The dispatch mechanism optimizes for the common case where all handlers succeed quickly. Error handling and recovery logic are designed to add minimal overhead in the success path while providing comprehensive recovery in failure scenarios.</p>\n</blockquote>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fhandler-dispatch-sequence.svg\" alt=\"Handler Dispatch Sequence\"></p>\n<h4 id=\"common-pitfalls\">Common Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Handler Deadlock in Error Logging</strong>\nWhen handler error logging uses the same logger hierarchy, a failure in the error logger can cause recursive calls and deadlocks. For example, if the file handler fails and tries to log the error to a logger that also uses the file handler, the system can deadlock. <strong>Fix</strong>: Use a separate error logging path that writes only to console or a dedicated error file, never routing through the normal handler system.</p>\n<p>⚠️ <strong>Pitfall: Unbounded Handler Queues</strong>\nAsynchronous handlers with unbounded queues can consume unlimited memory during traffic spikes, leading to out-of-memory crashes. Without queue limits, a slow remote handler can accumulate millions of pending records. <strong>Fix</strong>: Use bounded queues with explicit overflow policies, monitor queue depth, and implement backpressure mechanisms that slow down logging when queues approach capacity.</p>\n<p>⚠️ <strong>Pitfall: Synchronous Network Handlers in Hot Paths</strong>\nUsing synchronous network handlers in performance-critical code paths causes application latency to directly depend on network latency. A slow remote logging service can make the entire application unresponsive. <strong>Fix</strong>: Use asynchronous handlers for all network destinations, or implement timeout limits with fallback to local handlers when remote services are slow.</p>\n<p>⚠️ <strong>Pitfall: Handler State Corruption Under Concurrency</strong>\nStateful handlers that don&#39;t properly synchronize internal state can corrupt output when accessed from multiple threads. File handlers that maintain internal buffers without proper locking can interleave output from different threads. <strong>Fix</strong>: Ensure all handler implementations are internally thread-safe, use atomic operations for simple state, and employ proper locking for complex state management.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Threading</td>\n<td><code>threading.RLock</code> for logger locks</td>\n<td><code>concurrent.futures.ThreadPoolExecutor</code> for async handlers</td>\n</tr>\n<tr>\n<td>Logger Registry</td>\n<td><code>dict</code> with global lock</td>\n<td><code>weakref.WeakValueDictionary</code> for automatic cleanup</td>\n</tr>\n<tr>\n<td>Handler Queues</td>\n<td><code>queue.Queue</code> for async handlers</td>\n<td><code>multiprocessing.Queue</code> for cross-process logging</td>\n</tr>\n<tr>\n<td>Context Storage</td>\n<td><code>threading.local()</code> for per-thread context</td>\n<td><code>contextvars</code> for async-aware context</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td><code>json.dumps()</code> for LogRecord conversion</td>\n<td><code>orjson</code> or <code>ujson</code> for high-performance serialization</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>logging-system/\n  core/\n    __init__.py              ← Public API exports\n    logger.py                ← Logger class and hierarchy management\n    record.py                ← LogRecord data structure\n    levels.py                ← Level constants and utilities\n    registry.py              ← Global logger registry and factory\n  handlers/\n    __init__.py              ← Handler base class and common handlers\n    console.py               ← ConsoleHandler implementation\n    file.py                  ← FileHandler with rotation\n    remote.py                ← RemoteHandler for network logging\n    async_handler.py         ← Asynchronous handler wrapper\n  formatters/\n    __init__.py              ← Formatter base class\n    json_formatter.py        ← JSON formatting implementation\n  context/\n    __init__.py              ← Context propagation system\n    storage.py               ← Thread-local and async context storage\n  tests/\n    test_logger.py           ← Logger hierarchy and level tests\n    test_handlers.py         ← Handler dispatch and error tests\n    test_concurrency.py      ← Thread safety and race condition tests</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Level Constants and Utilities</strong> (<code>levels.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Complete level management system</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">WARN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 40</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">FATAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 50</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">LEVEL_NAMES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEBUG</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'DEBUG'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INFO</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'INFO'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARN</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'WARN'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'ERROR'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FATAL</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'FATAL'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">NAME_TO_LEVEL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {name: level </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> level, name </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> LEVEL_NAMES</span><span style=\"color:#E1E4E8\">.items()}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> should_log</span><span style=\"color:#E1E4E8\">(message_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, configured_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Determine if message should be logged based on level filtering.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> message_level </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> configured_level</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> level_name</span><span style=\"color:#E1E4E8\">(level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Convert numeric level to string name.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> LEVEL_NAMES</span><span style=\"color:#E1E4E8\">.get(level, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'LEVEL-</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">level</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> parse_level</span><span style=\"color:#E1E4E8\">(level_input) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Parse string or integer level input to numeric level.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(level_input, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> level_input</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(level_input, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NAME_TO_LEVEL</span><span style=\"color:#E1E4E8\">.get(level_input.upper(), </span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> INFO</span></span></code></pre></div>\n\n<p><strong>Thread-Safe Collections</strong> (<code>utils.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> weakref</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeDict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe dictionary with read-write locking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, default: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data.get(key, default)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._data[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> delete</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> key </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                del</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._data[key]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> keys</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._data.keys())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LoggerRegistry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Global registry for logger instances with thread safety.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._loggers: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_or_create</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, factory_func) -> </span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> name </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._loggers:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._loggers[name]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> factory_func(name)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._loggers[name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logger</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._loggers.get(name)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clear all loggers - primarily for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._loggers.clear()</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton\">Core Logic Skeleton</h4>\n<p><strong>Logger Class Core</strong> (<code>logger.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .levels </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> should_log, </span><span style=\"color:#79B8FF\">INFO</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .record </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Logger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Core logger implementation with hierarchy and thread safety.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, parent: Optional[</span><span style=\"color:#9ECBFF\">'Logger'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.parent </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parent</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.children: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Logger] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.handlers: List[</span><span style=\"color:#9ECBFF\">'Handler'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.propagate </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._level: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._effective_level: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log</span><span style=\"color:#E1E4E8\">(self, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Main logging entry point with filtering and dispatch.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if message should be logged using should_log()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create LogRecord with current timestamp and merged context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Collect all applicable handlers from self and ancestors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Dispatch record to each handler with error isolation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle propagation up the hierarchy if enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use early return for filtered messages to optimize performance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_effective_level</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get the effective level, walking up hierarchy if needed.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if we have a cached effective level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If not cached, walk up parent chain to find configured level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Cache the result for future calls</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return the found level or default to INFO</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use self._lock for thread safety when updating cache</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_level</span><span style=\"color:#E1E4E8\">(self, level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set logger level and invalidate caches.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire write lock to prevent concurrent access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set self._level to new value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Invalidate self._effective_level cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Walk all descendants and invalidate their caches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Release lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Cache invalidation prevents stale level inheritance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_handler</span><span style=\"color:#E1E4E8\">(self, handler: </span><span style=\"color:#9ECBFF\">'Handler'</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add handler to this logger's handler list.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire lock for thread-safe handler list modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if handler is already in list to avoid duplicates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Append handler to self.handlers list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Release lock</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> collect_handlers</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#9ECBFF\">'Handler'</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Collect all applicable handlers from hierarchy.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Start with empty handler list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add all handlers from self.handlers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If propagate is True, walk up parent chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add handlers from each ancestor until root or propagate=False</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return combined handler list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Check propagate flag at each level, not just current logger</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Convenience methods for specific levels</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> debug</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log(</span><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#E1E4E8\">, message, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> info</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log(</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">, message, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> warn</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log(</span><span style=\"color:#79B8FF\">WARN</span><span style=\"color:#E1E4E8\">, message, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> error</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log(</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">, message, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> fatal</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log(</span><span style=\"color:#79B8FF\">FATAL</span><span style=\"color:#E1E4E8\">, message, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">context)</span></span></code></pre></div>\n\n<p><strong>Logger Factory Function</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">_registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> LoggerRegistry()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_logger</span><span style=\"color:#E1E4E8\">(name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> ''</span><span style=\"color:#E1E4E8\">) -> Logger:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Get or create logger with proper hierarchy setup.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use registry to get existing logger or signal creation needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If creating new logger, parse name to find parent path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure parent loggers exist, creating them recursively</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create new logger with proper parent reference</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add new logger to parent's children dict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Initialize logger with inherited configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Register logger in global registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return logger instance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Split name on '.' to build hierarchy path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the Logger Core, verify these behaviors:</p>\n<p><strong>Level Filtering Test</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.set_level(</span><span style=\"color:#79B8FF\">WARN</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.debug(</span><span style=\"color:#9ECBFF\">\"Should not appear\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Filtered out</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.warn(</span><span style=\"color:#9ECBFF\">\"Should appear\"</span><span style=\"color:#E1E4E8\">)       </span><span style=\"color:#6A737D\"># Visible</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.error(</span><span style=\"color:#9ECBFF\">\"Should appear\"</span><span style=\"color:#E1E4E8\">)      </span><span style=\"color:#6A737D\"># Visible</span></span></code></pre></div>\n\n<p><strong>Hierarchy Test</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">parent </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'parent'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">child </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'parent.child'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">parent.set_level(</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> child.get_effective_level() </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> ERROR</span><span style=\"color:#6A737D\">  # Inherits from parent</span></span></code></pre></div>\n\n<p><strong>Thread Safety Test</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> concurrent.futures</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> log_messages</span><span style=\"color:#E1E4E8\">(logger, thread_id):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Message </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> from thread </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'concurrent'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">with</span><span style=\"color:#E1E4E8\"> concurrent.futures.ThreadPoolExecutor(</span><span style=\"color:#FFAB70\">max_workers</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> executor:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    futures </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [executor.submit(log_messages, logger, i) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Should complete without deadlock or corrupted output</span></span></code></pre></div>\n\n<p><strong>Handler Dispatch Test</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'dispatch'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.add_handler(ConsoleHandler())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger.info(</span><span style=\"color:#9ECBFF\">\"Test message\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should appear on console without errors</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<ul>\n<li>Use <code>threading.RLock()</code> instead of <code>Lock()</code> to allow recursive locking within the same thread</li>\n<li><code>time.time()</code> provides sufficient timestamp precision for most logging use cases  </li>\n<li><code>sys.stderr.write()</code> is thread-safe and faster than <code>print()</code> for console handlers</li>\n<li>Use <code>**kwargs</code> for context parameters to provide clean API for arbitrary fields</li>\n<li><code>weakref.WeakValueDictionary</code> can help prevent memory leaks in logger registry for long-running applications</li>\n<li>Consider using <code>__slots__</code> in LogRecord class to reduce memory overhead for high-volume logging</li>\n</ul>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Messages not appearing</td>\n<td>Level filtering too restrictive</td>\n<td>Check <code>get_effective_level()</code> vs message level</td>\n<td>Lower logger level or use higher level messages</td>\n</tr>\n<tr>\n<td>Duplicate log messages</td>\n<td>Handler added multiple times</td>\n<td>Inspect <code>logger.handlers</code> list</td>\n<td>Check for duplicate handler addition</td>\n</tr>\n<tr>\n<td>Deadlock on level change</td>\n<td>Lock ordering violation</td>\n<td>Thread dump showing lock contention</td>\n<td>Acquire locks in consistent order (parent before child)</td>\n</tr>\n<tr>\n<td>Context not inheriting</td>\n<td>Parent-child relationship broken</td>\n<td>Verify <code>logger.parent</code> references</td>\n<td>Fix logger hierarchy creation in factory</td>\n</tr>\n<tr>\n<td>Memory leak in long-running app</td>\n<td>Logger registry holding references</td>\n<td>Monitor logger count over time</td>\n<td>Use WeakValueDictionary for registry storage</td>\n</tr>\n</tbody></table>\n<h2 id=\"structured-output-design\">Structured Output Design</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section primarily addresses Milestone 2 (Structured Output) by defining JSON formatting, custom formatters, timestamp handling, and developer-friendly pretty printing. It builds on the Logger Core from Milestone 1 and prepares the foundation for context propagation in Milestone 3.</p>\n</blockquote>\n<p>Think of structured logging output like a restaurant&#39;s order system. Traditional string-based logs are like servers shouting orders across a noisy kitchen — &quot;Medium rare steak, extra sauce!&quot; The information is there, but it&#39;s hard to parse, search, or aggregate. Structured JSON output is like a modern point-of-sale system that sends precise, machine-readable orders to each station: <code>{&quot;item&quot;: &quot;steak&quot;, &quot;doneness&quot;: &quot;medium_rare&quot;, &quot;modifications&quot;: [&quot;extra_sauce&quot;], &quot;table&quot;: 7, &quot;timestamp&quot;: &quot;2024-01-15T18:30:00Z&quot;}</code>. Every piece of information has its designated place, making it trivial for kitchen display systems, inventory tracking, and analytics to process the data automatically.</p>\n<p>The structured output system transforms the rich <code>LogRecord</code> objects from our logger core into various serialized formats suitable for different consumption scenarios. While the logger hierarchy and level filtering ensure the right messages reach the formatting stage, the output system determines how those messages appear to developers, monitoring systems, and log aggregation platforms.</p>\n<h3 id=\"json-formatter\">JSON Formatter</h3>\n<p>The JSON formatter serves as the primary structured output format, converting <code>LogRecord</code> objects into single-line JSON strings that maintain consistent field ordering and handle complex serialization scenarios gracefully.</p>\n<blockquote>\n<p><strong>Decision: Single-Line JSON Output</strong></p>\n<ul>\n<li><strong>Context</strong>: Log aggregation systems and streaming processors expect one JSON object per line to enable efficient parsing and processing of large log files</li>\n<li><strong>Options Considered</strong>: Multi-line pretty JSON, single-line compact JSON, custom delimited format</li>\n<li><strong>Decision</strong>: Single-line JSON with consistent field ordering</li>\n<li><strong>Rationale</strong>: Single-line format enables stream processing, consistent ordering aids debugging, and standard JSON ensures compatibility with existing tooling</li>\n<li><strong>Consequences</strong>: Enables efficient log processing but reduces human readability in raw form (addressed by separate pretty-print formatter)</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>JSON Field</th>\n<th>Type</th>\n<th>Source</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>timestamp</code></td>\n<td>string</td>\n<td><code>LogRecord.timestamp</code></td>\n<td>ISO 8601 formatted timestamp with timezone</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td>string</td>\n<td><code>LogRecord.level</code> mapped via <code>LEVEL_NAMES</code></td>\n<td>Human-readable level name (DEBUG, INFO, WARN, ERROR, FATAL)</td>\n</tr>\n<tr>\n<td><code>message</code></td>\n<td>string</td>\n<td><code>LogRecord.message</code></td>\n<td>Primary log message content</td>\n</tr>\n<tr>\n<td><code>logger</code></td>\n<td>string</td>\n<td><code>LogRecord.logger_name</code></td>\n<td>Hierarchical logger name (e.g., &quot;api.auth.login&quot;)</td>\n</tr>\n<tr>\n<td><code>context</code></td>\n<td>object</td>\n<td><code>LogRecord.context</code></td>\n<td>Key-value pairs with request context and metadata</td>\n</tr>\n</tbody></table>\n<p>The JSON formatter implements several sophisticated serialization strategies to handle edge cases that commonly break logging systems in production:</p>\n<p><strong>Circular Reference Protection</strong>: The <code>safe_serialize</code> function maintains a recursion depth counter and visited object set to detect circular references before they cause stack overflows. When a circular reference is detected, the formatter replaces the problematic object with a placeholder string <code>&quot;&lt;circular_reference&gt;&quot;</code>, allowing logging to continue rather than crashing the application.</p>\n<p><strong>Non-Serializable Object Handling</strong>: The <code>SafeJSONEncoder</code> extends Python&#39;s standard JSON encoder to handle common non-serializable types encountered in production logging. DateTime objects convert to ISO 8601 strings, Decimal objects serialize as strings to preserve precision, and custom objects fall back to their string representation via <code>str()</code>.</p>\n<p><strong>Size-Based Truncation</strong>: The <code>estimate_serialized_size</code> function provides fast size estimation without full serialization, enabling the formatter to truncate oversized context objects before they consume excessive memory or exceed log destination limits. Objects exceeding configurable size thresholds are replaced with summary metadata indicating the original type and truncated size.</p>\n<table>\n<thead>\n<tr>\n<th>Method Name</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>format</code></td>\n<td><code>record: LogRecord</code></td>\n<td><code>str</code></td>\n<td>Convert LogRecord to single-line JSON string</td>\n</tr>\n<tr>\n<td><code>safe_serialize</code></td>\n<td><code>data: Any, max_depth: int = 10</code></td>\n<td><code>str</code></td>\n<td>Serialize with circular reference protection</td>\n</tr>\n<tr>\n<td><code>estimate_serialized_size</code></td>\n<td><code>data: Any</code></td>\n<td><code>int</code></td>\n<td>Fast size estimation without full serialization</td>\n</tr>\n<tr>\n<td><code>to_dict</code></td>\n<td><code>record: LogRecord</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Convert LogRecord to dictionary for JSON serialization</td>\n</tr>\n</tbody></table>\n<p><strong>Field Ordering Strategy</strong>: The formatter uses Python&#39;s <code>collections.OrderedDict</code> or dictionary insertion ordering (Python 3.7+) to ensure consistent field appearance across all log records. This deterministic ordering significantly improves developer experience when scanning logs manually and ensures that text-based diff tools can meaningfully compare log files.</p>\n<p>Consider a concrete example where an authentication service logs a failed login attempt:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">text</span><pre class=\"arch-pre shiki-highlighted\"><code>Input LogRecord:\n  timestamp: &quot;2024-01-15T18:30:45.123456Z&quot;\n  level: 40 (ERROR)\n  message: &quot;Authentication failed&quot;\n  logger_name: &quot;api.auth.login&quot;\n  context: {&quot;user_id&quot;: &quot;user_123&quot;, &quot;ip_address&quot;: &quot;192.168.1.100&quot;, &quot;attempt_count&quot;: 3}\n\nOutput JSON:\n{&quot;timestamp&quot;:&quot;2024-01-15T18:30:45.123456Z&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;message&quot;:&quot;Authentication failed&quot;,&quot;logger&quot;:&quot;api.auth.login&quot;,&quot;context&quot;:{&quot;user_id&quot;:&quot;user_123&quot;,&quot;ip_address&quot;:&quot;192.168.1.100&quot;,&quot;attempt_count&quot;:3}}</code></pre></div>\n\n<p>The single-line output enables log aggregation systems to process each line as a discrete event while maintaining all the structured context necessary for querying and analysis.</p>\n<h3 id=\"formatter-plugin-system\">Formatter Plugin System</h3>\n<p>The formatter plugin system provides extensibility for custom output formats while maintaining a consistent interface that integrates seamlessly with the handler dispatch mechanism.</p>\n<p>Think of the formatter plugin system like a universal printer driver architecture. Just as applications can send documents to any printer through a standard interface (regardless of whether it&#39;s an inkjet, laser, or plotter), the logging system can format records for any destination through a standard formatter interface. The application code doesn&#39;t need to know whether logs are going to JSON files, syslog servers, or custom monitoring dashboards — it just hands the <code>LogRecord</code> to the appropriate formatter.</p>\n<blockquote>\n<p><strong>Decision: Registry-Based Plugin Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Different output destinations require different formatting (JSON for aggregation, colored text for development, structured formats for monitoring systems)</li>\n<li><strong>Options Considered</strong>: Inheritance-based formatters, function-based formatters, registry-based plugins</li>\n<li><strong>Decision</strong>: Registry-based plugin system with standard formatter interface</li>\n<li><strong>Rationale</strong>: Registry enables runtime formatter selection, standard interface ensures consistent behavior, and plugins can be distributed as separate packages</li>\n<li><strong>Consequences</strong>: Enables formatter extensibility and runtime configuration but adds complexity compared to fixed formatters</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Formatter Component</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Registration Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>BaseFormatter</code></td>\n<td>Abstract Class</td>\n<td>Defines standard interface for all formatters</td>\n<td>N/A (base class)</td>\n</tr>\n<tr>\n<td><code>JSONFormatter</code></td>\n<td>Concrete Class</td>\n<td>Single-line JSON output for log aggregation</td>\n<td><code>register_formatter(&quot;json&quot;, JSONFormatter())</code></td>\n</tr>\n<tr>\n<td><code>PrettyFormatter</code></td>\n<td>Concrete Class</td>\n<td>Human-readable colored output for development</td>\n<td><code>register_formatter(&quot;pretty&quot;, PrettyFormatter())</code></td>\n</tr>\n<tr>\n<td><code>SyslogFormatter</code></td>\n<td>Concrete Class</td>\n<td>RFC 3164 compatible syslog format</td>\n<td><code>register_formatter(&quot;syslog&quot;, SyslogFormatter())</code></td>\n</tr>\n<tr>\n<td><code>FormatterRegistry</code></td>\n<td>Registry Class</td>\n<td>Manages formatter registration and lookup</td>\n<td><code>get_formatter(name)</code>, <code>list_formatters()</code></td>\n</tr>\n</tbody></table>\n<p>The plugin registration process follows a simple two-step pattern that maintains type safety while enabling runtime flexibility:</p>\n<ol>\n<li><p><strong>Formatter Implementation</strong>: Custom formatters inherit from <code>BaseFormatter</code> and implement the required <code>format(record: LogRecord) -&gt; str</code> method along with optional configuration methods.</p>\n</li>\n<li><p><strong>Registry Registration</strong>: Formatters register themselves with the global <code>FormatterRegistry</code> using a unique string name, enabling selection via configuration files or runtime API calls.</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>BaseFormatter Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>format</code></td>\n<td><code>record: LogRecord</code></td>\n<td><code>str</code></td>\n<td>Abstract method that subclasses must implement</td>\n</tr>\n<tr>\n<td><code>configure</code></td>\n<td><code>options: Dict[str, Any]</code></td>\n<td><code>None</code></td>\n<td>Optional configuration method for formatter-specific settings</td>\n</tr>\n<tr>\n<td><code>supports_color</code></td>\n<td>None</td>\n<td><code>bool</code></td>\n<td>Indicates whether formatter supports color output</td>\n</tr>\n<tr>\n<td><code>get_name</code></td>\n<td>None</td>\n<td><code>str</code></td>\n<td>Returns the formatter&#39;s registration name</td>\n</tr>\n</tbody></table>\n<p><strong>Thread-Safe Registry Operations</strong>: The <code>FormatterRegistry</code> uses a read-write lock to ensure thread-safe registration and lookup operations. Formatter registration typically occurs during application startup, while lookups happen during log processing, making the read-heavy access pattern well-suited to RWLock optimization.</p>\n<p><strong>Configuration Integration</strong>: Formatters can accept configuration parameters through the <code>configure</code> method, enabling customization without requiring code changes. For example, the JSON formatter accepts parameters for timestamp format, field ordering preferences, and size limits, while the pretty formatter accepts color scheme and indentation preferences.</p>\n<p>Here&#39;s how the plugin system enables runtime formatter selection:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">text</span><pre class=\"arch-pre shiki-highlighted\"><code>Configuration-Driven Selection:\n  handlers:\n    - type: file\n      path: &quot;/var/log/app.json&quot;\n      formatter: &quot;json&quot;\n    - type: console  \n      formatter: &quot;pretty&quot;\n      \nRuntime Registration:\n  1. Application startup registers built-in formatters (json, pretty, syslog)\n  2. Custom formatter packages register additional formatters via plugin discovery\n  3. Configuration loading selects formatters by name for each handler\n  4. Handler dispatch uses assigned formatter for each destination</code></pre></div>\n\n<h3 id=\"timestamp-formatting\">Timestamp Formatting</h3>\n<p>Timestamp formatting provides the critical temporal context that enables log correlation, debugging, and audit trails across distributed systems. The timestamp system must balance precision, readability, and compatibility with various log processing systems.</p>\n<p>Think of timestamp formatting like international time zone coordination for airline schedules. Airlines need to display departure times in local time for passenger convenience (&quot;Flight 101 departs at 3:30 PM&quot;), but they also need UTC timestamps for air traffic control coordination and schedule optimization. Similarly, our logging system needs human-readable timestamps for developers scanning logs locally, but also needs precise, sortable timestamps for log aggregation systems that merge streams from multiple servers across different time zones.</p>\n<blockquote>\n<p><strong>Decision: Multiple Timestamp Format Support</strong></p>\n<ul>\n<li><strong>Context</strong>: Different consumers need different timestamp formats (humans prefer readable formats, systems prefer sortable formats, legacy systems expect specific formats)</li>\n<li><strong>Options Considered</strong>: Single ISO 8601 format, Unix epoch only, configurable format per logger</li>\n<li><strong>Decision</strong>: Multiple timestamp formats with per-formatter configuration</li>\n<li><strong>Rationale</strong>: ISO 8601 provides precision and sortability, Unix epoch enables efficient processing, custom formats support legacy integration</li>\n<li><strong>Consequences</strong>: Enables format flexibility but requires careful timezone handling and format validation</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Timestamp Format</th>\n<th>Example Output</th>\n<th>Use Case</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ISO 8601 with Microseconds</td>\n<td><code>2024-01-15T18:30:45.123456Z</code></td>\n<td>Log aggregation, debugging</td>\n<td>Sortable, precise, timezone-aware</td>\n<td>Longer string length</td>\n</tr>\n<tr>\n<td>ISO 8601 Basic</td>\n<td><code>2024-01-15T18:30:45Z</code></td>\n<td>General structured logging</td>\n<td>Standard, readable, sortable</td>\n<td>Lower precision</td>\n</tr>\n<tr>\n<td>Unix Epoch</td>\n<td><code>1705344645.123456</code></td>\n<td>High-performance processing</td>\n<td>Compact, fast parsing, efficient storage</td>\n<td>Not human-readable</td>\n</tr>\n<tr>\n<td>Custom strftime</td>\n<td><code>2024-01-15 18:30:45 UTC</code></td>\n<td>Legacy system integration</td>\n<td>Flexible, familiar format</td>\n<td>Non-standard, parsing complexity</td>\n</tr>\n</tbody></table>\n<p><strong>Timezone Handling Strategy</strong>: All timestamps are captured in UTC to avoid daylight saving time transitions and timezone inconsistencies that plague distributed logging. The <code>LogRecord.create</code> factory method uses <code>datetime.utcnow()</code> to ensure consistent temporal ordering regardless of the server&#39;s local timezone configuration.</p>\n<p><strong>Precision Requirements</strong>: The default timestamp format includes microsecond precision to enable ordering of log events that occur within the same second. This precision level proves essential when debugging race conditions or analyzing high-frequency operations where millisecond timing matters.</p>\n<p><strong>Clock Synchronization Considerations</strong>: While the logging system cannot control server clock synchronization, it provides mechanisms to detect and warn about significant clock skew. The timestamp formatter can optionally include a monotonic clock offset that enables relative timing analysis even when system clocks drift.</p>\n<table>\n<thead>\n<tr>\n<th>Timestamp Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>format_timestamp</code></td>\n<td><code>timestamp: str, format_type: str</code></td>\n<td><code>str</code></td>\n<td>Convert ISO timestamp to specified format</td>\n</tr>\n<tr>\n<td><code>parse_timestamp</code></td>\n<td><code>timestamp_str: str</code></td>\n<td><code>datetime</code></td>\n<td>Parse timestamp string to datetime object</td>\n</tr>\n<tr>\n<td><code>get_current_timestamp</code></td>\n<td><code>precision: str = &quot;microsecond&quot;</code></td>\n<td><code>str</code></td>\n<td>Generate current UTC timestamp with specified precision</td>\n</tr>\n<tr>\n<td><code>validate_timestamp</code></td>\n<td><code>timestamp_str: str</code></td>\n<td><code>bool</code></td>\n<td>Validate timestamp string format</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Optimization</strong>: Timestamp formatting uses caching strategies to avoid repeated strftime operations on identical timestamps. The formatter maintains a small LRU cache of recently formatted timestamps, which significantly improves performance when processing bursts of log messages within the same second.</p>\n<p>Consider how different timestamp formats serve different operational needs:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">text</span><pre class=\"arch-pre shiki-highlighted\"><code>Development Scenario - Pretty Formatter:\n  Raw LogRecord: timestamp=&quot;2024-01-15T18:30:45.123456Z&quot;\n  Formatted Output: &quot;[18:30:45.123] ERROR api.auth: Authentication failed&quot;\n  \nProduction JSON - JSON Formatter:  \n  Raw LogRecord: timestamp=&quot;2024-01-15T18:30:45.123456Z&quot;\n  Formatted Output: {&quot;timestamp&quot;:&quot;2024-01-15T18:30:45.123456Z&quot;,&quot;level&quot;:&quot;ERROR&quot;,...}\n  \nLegacy Syslog Integration - Syslog Formatter:\n  Raw LogRecord: timestamp=&quot;2024-01-15T18:30:45.123456Z&quot;  \n  Formatted Output: &quot;Jan 15 18:30:45 hostname app[1234]: Authentication failed&quot;</code></pre></div>\n\n<h3 id=\"developer-friendly-pretty-print\">Developer-Friendly Pretty Print</h3>\n<p>The pretty print formatter transforms structured log data into human-readable, visually appealing output optimized for developer console environments and interactive debugging sessions.</p>\n<p>Think of pretty printing like the difference between reading raw HTML source code and viewing a rendered web page. While the JSON formatter produces machine-readable output equivalent to HTML source (precise, parseable, but dense), the pretty formatter acts like a web browser, transforming that structured data into a visually organized, color-coded display that humans can quickly scan and comprehend. Just as web browsers use typography, spacing, and color to highlight important information, the pretty formatter uses console colors, indentation, and visual hierarchy to make log data accessible to developers.</p>\n<blockquote>\n<p><strong>Decision: Console-Optimized Visual Formatting</strong></p>\n<ul>\n<li><strong>Context</strong>: Developers need quick visual scanning of log output during debugging and development, but JSON format is difficult to read in terminal environments</li>\n<li><strong>Options Considered</strong>: Colored JSON with indentation, table-based layout, custom visual format</li>\n<li><strong>Decision</strong>: Multi-line colored output with hierarchical indentation and visual separators</li>\n<li><strong>Rationale</strong>: Color coding enables quick level identification, indentation shows context hierarchy, and compact layout maximizes information density</li>\n<li><strong>Consequences</strong>: Dramatically improves developer experience but produces larger output unsuitable for production log aggregation</li>\n</ul>\n</blockquote>\n<p><strong>Color Scheme Strategy</strong>: The pretty formatter uses a carefully designed color palette that remains readable across different terminal backgrounds and accommodates common forms of color vision differences. Critical information uses high-contrast colors, while contextual information uses muted tones that don&#39;t compete for attention.</p>\n<table>\n<thead>\n<tr>\n<th>Log Level</th>\n<th>Color</th>\n<th>Terminal Code</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>DEBUG</td>\n<td>Cyan</td>\n<td><code>\\033[36m</code></td>\n<td>Cool color indicates low-priority information</td>\n</tr>\n<tr>\n<td>INFO</td>\n<td>Green</td>\n<td><code>\\033[32m</code></td>\n<td>Green suggests normal, healthy operation</td>\n</tr>\n<tr>\n<td>WARN</td>\n<td>Yellow</td>\n<td><code>\\033[33m</code></td>\n<td>Yellow universally signals caution</td>\n</tr>\n<tr>\n<td>ERROR</td>\n<td>Red</td>\n<td><code>\\033[31m</code></td>\n<td>Red immediately draws attention to problems</td>\n</tr>\n<tr>\n<td>FATAL</td>\n<td>Bright Red + Bold</td>\n<td><code>\\033[1;91m</code></td>\n<td>Maximum visual impact for critical issues</td>\n</tr>\n</tbody></table>\n<p><strong>Layout Design Principles</strong>: The pretty formatter uses consistent visual hierarchy to help developers quickly locate relevant information. Timestamps appear in muted colors to provide context without distraction, logger names use medium emphasis to show the source, and context fields are indented to clearly separate them from the primary message.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">text</span><pre class=\"arch-pre shiki-highlighted\"><code>Example Pretty Print Output Layout:\n\n[18:30:45.123] ERROR api.auth.login                          ← timestamp + level + logger\nAuthentication failed for user                               ← primary message  \n├── user_id: &quot;user_123&quot;                                     ← context fields with\n├── ip_address: &quot;192.168.1.100&quot;                             ← tree-style indentation\n├── attempt_count: 3                                        ← for visual hierarchy\n└── correlation_id: &quot;req_abc123def456&quot;                      \n                                                            ← blank line separator</code></pre></div>\n\n<p><strong>Context Field Rendering</strong>: The formatter intelligently handles different context field types with appropriate visual treatment. String values appear quoted, numbers display without decoration, nested objects use deeper indentation levels, and large values trigger truncation with expansion hints.</p>\n<table>\n<thead>\n<tr>\n<th>Context Field Type</th>\n<th>Rendering Strategy</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>String</td>\n<td>Quoted with escape handling</td>\n<td><code>user_name: &quot;john.doe&quot;</code></td>\n</tr>\n<tr>\n<td>Number</td>\n<td>Direct display</td>\n<td><code>response_time_ms: 245</code></td>\n</tr>\n<tr>\n<td>Boolean</td>\n<td>Lowercase display</td>\n<td><code>authenticated: true</code></td>\n</tr>\n<tr>\n<td>List</td>\n<td>Bracketed with item count</td>\n<td><code>permissions: [3 items]</code></td>\n</tr>\n<tr>\n<td>Dict</td>\n<td>Nested indentation</td>\n<td><code>metadata:</code> followed by indented key-value pairs</td>\n</tr>\n<tr>\n<td>Large Object</td>\n<td>Truncated with hint</td>\n<td><code>request_body: &lt;dict with 15 fields&gt;</code></td>\n</tr>\n</tbody></table>\n<p><strong>Terminal Capability Detection</strong>: The formatter detects terminal capabilities to gracefully degrade when color support is unavailable or when output is redirected to files. This detection prevents ANSI escape codes from polluting log files while maintaining rich formatting in interactive terminals.</p>\n<table>\n<thead>\n<tr>\n<th>PrettyFormatter Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>format</code></td>\n<td><code>record: LogRecord</code></td>\n<td><code>str</code></td>\n<td>Convert LogRecord to color-formatted multi-line string</td>\n</tr>\n<tr>\n<td><code>format_context</code></td>\n<td><code>context: Dict[str, Any], indent: int</code></td>\n<td><code>str</code></td>\n<td>Render context fields with tree-style indentation</td>\n</tr>\n<tr>\n<td><code>detect_terminal_caps</code></td>\n<td>None</td>\n<td><code>Dict[str, bool]</code></td>\n<td>Detect color support and terminal width</td>\n</tr>\n<tr>\n<td><code>colorize</code></td>\n<td><code>text: str, color: str</code></td>\n<td><code>str</code></td>\n<td>Apply color codes with terminal capability fallback</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Considerations</strong>: While pretty formatting is more expensive than simple JSON serialization, it&#39;s designed specifically for development environments where the performance cost is acceptable in exchange for improved developer productivity. The formatter caches color capability detection and reuses formatting objects to minimize overhead.</p>\n<p><strong>Width-Aware Formatting</strong>: The formatter detects terminal width and adjusts layout accordingly. On narrow terminals, it abbreviates logger names and wraps long messages intelligently. On wide terminals, it can display additional context inline rather than using vertical indentation.</p>\n<p>Consider how the same log record appears in different formatting contexts:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">text</span><pre class=\"arch-pre shiki-highlighted\"><code>JSON Formatter (Production):\n{&quot;timestamp&quot;:&quot;2024-01-15T18:30:45.123456Z&quot;,&quot;level&quot;:&quot;ERROR&quot;,&quot;message&quot;:&quot;Authentication failed&quot;,&quot;logger&quot;:&quot;api.auth.login&quot;,&quot;context&quot;:{&quot;user_id&quot;:&quot;user_123&quot;,&quot;ip_address&quot;:&quot;192.168.1.100&quot;,&quot;attempt_count&quot;:3}}\n\nPretty Formatter (Development):\n[18:30:45.123] ERROR api.auth.login\nAuthentication failed\n├── user_id: &quot;user_123&quot;  \n├── ip_address: &quot;192.168.1.100&quot;\n└── attempt_count: 3</code></pre></div>\n\n<p>The pretty formatter transforms dense, machine-readable data into an immediately comprehensible visual representation that enables developers to quickly identify patterns, spot anomalies, and understand the flow of execution through their applications.</p>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Flog-processing-flow.svg\" alt=\"Log Processing Data Flow\"></p>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fformatter-plugin-system.svg\" alt=\"Formatter Plugin Architecture\"></p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Non-Serializable Context Values</strong>\nDevelopers frequently add complex objects to logging context that cannot be serialized to JSON, such as database connections, file handles, or custom objects without <code>__dict__</code> methods. This causes the entire logging operation to fail with serialization exceptions, potentially masking the original issue being logged. The fix involves implementing the <code>SafeJSONEncoder</code> with fallback serialization that converts problematic objects to their string representation via <code>str()</code> or <code>repr()</code>, allowing logging to continue even with problematic context data.</p>\n<p>⚠️ <strong>Pitfall: Blocking I/O in Formatter</strong>\nSome custom formatters attempt to perform network requests or file I/O operations during the formatting phase, such as looking up additional metadata or validating data against external services. This introduces blocking operations directly in the logging hot path, causing application threads to stall while waiting for formatter completion. The solution involves moving all I/O operations to the handler level and keeping formatters as pure transformation functions that operate only on the provided <code>LogRecord</code> data.</p>\n<p>⚠️ <strong>Pitfall: Memory Exhaustion from Large Context Objects</strong>\nApplications sometimes log entire request payloads, response objects, or large data structures as context fields. When these objects contain megabytes of data, they can quickly exhaust available memory, especially under high logging volume. The <code>estimate_serialized_size</code> function provides protection by detecting oversized objects before serialization and replacing them with summary metadata, but this protection must be enabled and configured with appropriate thresholds.</p>\n<p>⚠️ <strong>Pitfall: Timezone Confusion in Timestamps</strong>\nMixing local time and UTC timestamps across different servers creates impossible-to-debug timing issues where log events appear to occur in the wrong order or at impossible times. Always use UTC for log timestamps and convert to local time only in presentation layers. The <code>get_current_timestamp</code> function ensures UTC consistency, but developers must avoid using <code>datetime.now()</code> or other local time functions when creating custom timestamp formats.</p>\n<p>⚠️ <strong>Pitfall: Circular References in Context</strong>\nWhen logging objects that contain references to parent objects or self-references, the JSON serialization process can enter infinite loops, eventually causing stack overflow errors. This commonly occurs when logging request objects that contain references to the application context or when debugging recursive data structures. The <code>safe_serialize</code> function with depth limiting and visited-object tracking prevents this issue, but it must be used consistently across all formatters.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JSON Serialization</td>\n<td><code>json</code> standard library</td>\n<td><code>orjson</code> for high-performance serialization</td>\n</tr>\n<tr>\n<td>Color Terminal Output</td>\n<td>ANSI escape codes</td>\n<td><code>colorama</code> for cross-platform color support</td>\n</tr>\n<tr>\n<td>Timestamp Parsing</td>\n<td><code>datetime.fromisoformat()</code></td>\n<td><code>dateutil.parser</code> for flexible format support</td>\n</tr>\n<tr>\n<td>Size Estimation</td>\n<td>String length approximation</td>\n<td><code>sys.getsizeof()</code> with recursive object traversal</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n├── formatters/\n│   ├── __init__.py              ← Formatter registry and base classes\n│   ├── json_formatter.py        ← JSON formatter implementation  \n│   ├── pretty_formatter.py      ← Developer console formatter\n│   └── base_formatter.py        ← Abstract base formatter\n├── utils/\n│   ├── serialization.py         ← SafeJSONEncoder and safe_serialize\n│   └── timestamps.py            ← Timestamp formatting utilities\n└── tests/\n    ├── test_json_formatter.py\n    ├── test_pretty_formatter.py\n    └── test_serialization.py</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code:</strong></p>\n<p><strong>SafeJSONEncoder (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> decimal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Set, Dict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SafeJSONEncoder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">json</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JSONEncoder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"JSON encoder that handles non-serializable types gracefully.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, max_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_depth</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._visited: Set[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._current_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode</span><span style=\"color:#E1E4E8\">(self, obj):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._visited.clear()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._current_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> super</span><span style=\"color:#E1E4E8\">().encode(obj)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> default</span><span style=\"color:#E1E4E8\">(self, obj):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle common non-serializable types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, datetime.datetime):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> obj.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(obj, decimal.Decimal):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(obj, </span><span style=\"color:#9ECBFF\">'__dict__'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;</span><span style=\"color:#79B8FF\">{type</span><span style=\"color:#E1E4E8\">(obj).</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\"> object>\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(obj)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_serialize</span><span style=\"color:#E1E4E8\">(data: Any, max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Serialize data to JSON with circular reference protection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SafeJSONEncoder(</span><span style=\"color:#FFAB70\">max_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_depth)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> encoder.encode(data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">TypeError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">ValueError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">RecursionError</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps({</span><span style=\"color:#9ECBFF\">\"serialization_error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e), </span><span style=\"color:#9ECBFF\">\"type\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">type</span><span style=\"color:#E1E4E8\">(data))})</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> estimate_serialized_size</span><span style=\"color:#E1E4E8\">(data: Any) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Estimate JSON size without full serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> data </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#6A737D\">  # \"null\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> data </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#6A737D\">  # \"true\" or \"false\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(data))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(data))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(data) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # Add quotes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, (</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">)):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(estimate_serialized_size(item) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> item </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> data) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(data) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(data, </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> key, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> data.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(key)) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # quoted key</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> estimate_serialized_size(value)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            size </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # colon and comma</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(data)) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#6A737D\">  # quoted string representation</span></span></code></pre></div>\n\n<p><strong>Timestamp Utilities (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_current_timestamp</span><span style=\"color:#E1E4E8\">(precision: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"microsecond\"</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate current UTC timestamp with specified precision.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    now </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.datetime.utcnow()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> precision </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"second\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> now.strftime(</span><span style=\"color:#9ECBFF\">\"%Y-%m-</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">T%H:%M:%SZ\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#E1E4E8\"> precision </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"microsecond\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> now.strftime(</span><span style=\"color:#9ECBFF\">\"%Y-%m-</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">T%H:%M:%S.</span><span style=\"color:#79B8FF\">%f</span><span style=\"color:#9ECBFF\">Z\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unsupported precision: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">precision</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_timestamp</span><span style=\"color:#E1E4E8\">(timestamp: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, format_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Convert ISO timestamp to specified format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dt </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.datetime.fromisoformat(timestamp.replace(</span><span style=\"color:#9ECBFF\">'Z'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'+00:00'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> format_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"iso\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#E1E4E8\"> format_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"epoch\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(dt.timestamp())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#E1E4E8\"> format_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"readable\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> dt.strftime(</span><span style=\"color:#9ECBFF\">\"%Y-%m-</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> %H:%M:%S UTC\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Assume custom strftime format</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> dt.strftime(format_type)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TimestampCache</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"LRU cache for formatted timestamps to improve performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._cache: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._access_order </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_formatted</span><span style=\"color:#E1E4E8\">(self, timestamp: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, format_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cache_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">timestamp</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">format_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> cache_key </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._cache:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Move to end (most recently used)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._access_order.remove(cache_key)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._access_order.append(cache_key)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._cache[cache_key]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Cache miss - format and store</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        formatted </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> format_timestamp(timestamp, format_type)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._cache[cache_key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> formatted</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._access_order.append(cache_key)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Evict oldest if over limit</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._cache) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_size:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            oldest </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._access_order.pop(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            del</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._cache[oldest]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> formatted</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeletons:</strong></p>\n<p><strong>JSONFormatter (Core Implementation Skeleton):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base_formatter </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseFormatter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.serialization </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> safe_serialize, estimate_serialized_size</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> JSONFormatter</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">BaseFormatter</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Formats log records as single-line JSON objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_context_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">, timestamp_format: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"iso\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_context_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_context_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp_format </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timestamp_format</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> format</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert LogRecord to single-line JSON string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Convert LogRecord to dictionary using to_dict method</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check context size using estimate_serialized_size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If context too large, replace with size summary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Format timestamp according to configured format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Serialize dictionary to JSON using safe_serialize</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return single-line JSON string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_dict</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert LogRecord to dictionary for JSON serialization.\"\"\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create base dictionary with timestamp, level, message, logger</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Map numeric level to string name using LEVEL_NAMES</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add context fields if present and not empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure consistent field ordering (timestamp, level, message, logger, context)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use collections.OrderedDict or rely on Python 3.7+ dict ordering</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>PrettyFormatter (Core Implementation Skeleton):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base_formatter </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseFormatter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PrettyFormatter</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">BaseFormatter</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Human-readable console formatter with colors and indentation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Color constants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    COLORS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'DEBUG'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\033</span><span style=\"color:#9ECBFF\">[36m'</span><span style=\"color:#E1E4E8\">,    </span><span style=\"color:#6A737D\"># Cyan</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'INFO'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\033</span><span style=\"color:#9ECBFF\">[32m'</span><span style=\"color:#E1E4E8\">,     </span><span style=\"color:#6A737D\"># Green  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'WARN'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\033</span><span style=\"color:#9ECBFF\">[33m'</span><span style=\"color:#E1E4E8\">,     </span><span style=\"color:#6A737D\"># Yellow</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'ERROR'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\033</span><span style=\"color:#9ECBFF\">[31m'</span><span style=\"color:#E1E4E8\">,    </span><span style=\"color:#6A737D\"># Red</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'FATAL'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\033</span><span style=\"color:#9ECBFF\">[1;91m'</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Bright Red + Bold</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'RESET'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\033</span><span style=\"color:#9ECBFF\">[0m'</span><span style=\"color:#6A737D\">      # Reset</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, use_colors: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.use_colors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> use_colors </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> use_colors </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._detect_color_support()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> format</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert LogRecord to colored multi-line string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Format timestamp as short time (HH:MM:SS.mmm)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Apply color to log level based on severity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create main line with timestamp, level, logger, and message</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Format context fields with tree-style indentation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Combine main line and context lines with proper spacing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Add blank line separator for visual grouping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use colorize method for color application with fallback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> format_context</span><span style=\"color:#E1E4E8\">(self, context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], indent_level: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Format context fields with tree-style indentation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: If context is empty, return empty list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create list to collect formatted lines  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Iterate through context items with enumerate for last-item detection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Use ├── for non-final items and └── for final item</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle nested dictionaries with recursive calls</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Truncate large values with summary hint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use \"├──\" and \"└──\" Unicode characters for tree structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> colorize</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, color: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Apply color with terminal capability detection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if colors are enabled and supported</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If not supported, return text without modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If supported, wrap text with color code and reset</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Always include RESET code after colored text</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _detect_color_support</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect if terminal supports color output.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if stdout is a TTY (not redirected to file)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check TERM environment variable for color capability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return True only if both conditions are met</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use os.isatty() and os.environ.get()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>FormatterRegistry (Core Implementation Skeleton):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Optional, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base_formatter </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseFormatter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FormatterRegistry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe registry for formatter plugins.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._formatters: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, BaseFormatter] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_formatter</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, formatter: BaseFormatter) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register a formatter with given name.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire write lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate formatter inherits from BaseFormatter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store formatter in registry with name as key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Release lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use isinstance() to check formatter type</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_formatter</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[BaseFormatter]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve formatter by name.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire read lock  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Look up formatter in registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return formatter or None if not found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Release lock</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> list_formatters</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"List all registered formatter names.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire read lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Get list of registered names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return sorted list of names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Release lock</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global registry instance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_formatter_registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FormatterRegistry()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> register_formatter</span><span style=\"color:#E1E4E8\">(name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, formatter: BaseFormatter) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Register formatter in global registry.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _formatter_registry.register_formatter(name, formatter)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_formatter</span><span style=\"color:#E1E4E8\">(name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[BaseFormatter]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Get formatter from global registry.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> _formatter_registry.get_formatter(name)</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<ul>\n<li>Use <code>json.dumps(separators=(&#39;,&#39;, &#39;:&#39;))</code> for compact single-line JSON output</li>\n<li><code>collections.OrderedDict</code> ensures consistent field ordering in Python versions before 3.7</li>\n<li><code>sys.getsizeof()</code> provides object size estimation for truncation decisions</li>\n<li><code>threading.RLock()</code> allows the same thread to acquire the lock multiple times</li>\n<li><code>os.isatty(sys.stdout.fileno())</code> detects if output is going to a terminal vs file</li>\n<li>Unicode characters like <code>├──</code> and <code>└──</code> create clean tree-style formatting</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong>\nAfter completing this milestone, test your structured output system:</p>\n<p><strong>Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_formatters.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_formatting_demo.py</span><span style=\"color:#6A737D\">  # Custom demo script</span></span></code></pre></div>\n\n<p><strong>Expected JSON Output:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">json</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">{</span><span style=\"color:#79B8FF\">\"timestamp\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"2024-01-15T18:30:45.123456Z\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"level\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"ERROR\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"message\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"Test message\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"logger\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"test.formatter\"</span><span style=\"color:#E1E4E8\">,</span><span style=\"color:#79B8FF\">\"context\"</span><span style=\"color:#E1E4E8\">:{</span><span style=\"color:#79B8FF\">\"key\"</span><span style=\"color:#E1E4E8\">:</span><span style=\"color:#9ECBFF\">\"value\"</span><span style=\"color:#E1E4E8\">}}</span></span></code></pre></div>\n\n<p><strong>Expected Pretty Output:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>[18:30:45.123] ERROR test.formatter\nTest message\n└── key: &quot;value&quot;</code></pre></div>\n\n<p><strong>Verification Steps:</strong></p>\n<ol>\n<li>JSON formatter produces valid single-line JSON parseable by <code>json.loads()</code></li>\n<li>Pretty formatter displays colors in terminal but plain text when redirected to file</li>\n<li>Context fields appear consistently across different formatters</li>\n<li>Large context objects are truncated appropriately</li>\n<li>Non-serializable objects don&#39;t crash the formatter</li>\n</ol>\n<p><strong>Common Issues to Check:</strong></p>\n<ul>\n<li>JSON output contains no newlines or pretty-printing</li>\n<li>Colors only appear in interactive terminals, not in log files</li>\n<li>Timestamp format matches configuration settings</li>\n<li>Context truncation prevents memory exhaustion</li>\n<li>Thread safety works under concurrent formatting load</li>\n</ul>\n<h2 id=\"context-and-correlation-design\">Context and Correlation Design</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section primarily addresses Milestone 3 (Context &amp; Correlation) by defining request tracing, correlation ID systems, context propagation mechanisms, and async boundary preservation. Some elements support all milestones through the context enrichment capabilities of LogRecord objects.</p>\n</blockquote>\n<p>Think of correlation IDs and context propagation like a <strong>relay race baton</strong>. In a relay race, runners must pass a physical baton from one runner to the next to maintain continuity and prove the race was completed legitimately. Similarly, in a distributed system handling requests, we need to pass a &quot;context baton&quot; containing correlation IDs and metadata from one function to the next, one service to the next, and even across async task boundaries. Without this baton-passing mechanism, we lose the ability to trace a request&#39;s journey through our system - it&#39;s like having runners complete their legs independently without proving they&#39;re part of the same race.</p>\n<p>The fundamental challenge in context and correlation design lies in maintaining this continuity across three distinct boundaries: <strong>function call boundaries</strong> (nested calls within a thread), <strong>thread boundaries</strong> (when work moves between threads), and <strong>async boundaries</strong> (when coroutines suspend and resume). Each boundary requires a different propagation strategy, yet the developer experience should remain seamless - they should be able to log with full context regardless of these underlying complexity layers.</p>\n<h3 id=\"correlation-id-system\">Correlation ID System</h3>\n<p>A <strong>correlation ID</strong> serves as the unique fingerprint for a request&#39;s journey through your system. Think of it like a <strong>shipping tracking number</strong> - just as you can trace a package&#39;s movement from warehouse to warehouse using its tracking number, you can trace a request&#39;s flow through services, functions, and async operations using its correlation ID. This identifier links all log entries related to the same logical operation, enabling you to reconstruct the complete story of what happened during request processing.</p>\n<p>The correlation ID system operates on four core principles: <strong>uniqueness</strong> (each request gets a globally unique identifier), <strong>persistence</strong> (the ID travels with the request context), <strong>automatic injection</strong> (developers don&#39;t manually add IDs to every log call), and <strong>boundary crossing</strong> (the ID survives function calls, thread switches, and async operations). These principles ensure that correlation works transparently without requiring constant developer intervention.</p>\n<blockquote>\n<p><strong>Decision: Correlation ID Generation Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need globally unique identifiers that are human-readable, sortable, and carry minimal overhead</li>\n<li><strong>Options Considered</strong>: UUID4 (random), UUID1 (timestamp-based), custom base62 format, request sequence numbers</li>\n<li><strong>Decision</strong>: UUID4 with optional prefix for service identification</li>\n<li><strong>Rationale</strong>: UUID4 provides strong uniqueness guarantees without coordination, has excellent library support across languages, and avoids potential timing attacks from timestamp-based IDs. Optional service prefixes (e.g., &quot;api-server-550e8400&quot;) improve readability while maintaining uniqueness</li>\n<li><strong>Consequences</strong>: 36-character overhead per log entry, but enables reliable request tracing across service boundaries without central coordination</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Key Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>CorrelationIDGenerator</code></td>\n<td>Generate unique request identifiers</td>\n<td>Creates UUID4 strings with optional service prefix, thread-safe generation</td>\n</tr>\n<tr>\n<td><code>RequestIDInjector</code></td>\n<td>Automatically add correlation IDs to new requests</td>\n<td>Detects missing correlation context, generates new IDs, preserves existing IDs</td>\n</tr>\n<tr>\n<td><code>ContextualLogger</code></td>\n<td>Enrich log records with correlation data</td>\n<td>Merges correlation ID with log message context, handles missing ID scenarios</td>\n</tr>\n<tr>\n<td><code>IDPropagator</code></td>\n<td>Carry correlation IDs across boundaries</td>\n<td>Maintains ID in thread-local and async-local storage, handles inheritance</td>\n</tr>\n</tbody></table>\n<p>The correlation ID lifecycle begins when a request enters your system. At the <strong>entry point</strong> (HTTP request handler, message queue consumer, scheduled job), the system either extracts an existing correlation ID from headers/metadata or generates a new one. This ID immediately becomes part of the request context and flows through all subsequent operations. When the request spawns child operations (database calls, service calls, async tasks), the correlation ID propagates to those contexts automatically.</p>\n<p><strong>Correlation ID propagation</strong> follows a specific priority order: First, check if the current context already contains a correlation ID and preserve it. Second, look for an incoming correlation ID from request headers, parent contexts, or message metadata. Third, generate a new correlation ID only if none exists. This priority ensures that correlation chains remain intact across service boundaries while preventing orphaned operations from lacking traceability.</p>\n<table>\n<thead>\n<tr>\n<th>Propagation Scenario</th>\n<th>Source</th>\n<th>Action Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Request with <code>X-Correlation-ID</code> header</td>\n<td>Request headers</td>\n<td>Extract and use existing ID</td>\n</tr>\n<tr>\n<td>HTTP Request without correlation header</td>\n<td>Request context</td>\n<td>Generate new UUID4 and set response header</td>\n</tr>\n<tr>\n<td>Nested function call within request</td>\n<td>Parent context</td>\n<td>Inherit ID from thread-local or async-local storage</td>\n</tr>\n<tr>\n<td>Background async task spawned from request</td>\n<td>Parent task context</td>\n<td>Copy ID to new task&#39;s context</td>\n</tr>\n<tr>\n<td>Database query from request handler</td>\n<td>Current context</td>\n<td>Include ID in query metadata/comments</td>\n</tr>\n<tr>\n<td>Inter-service call</td>\n<td>Current context</td>\n<td>Add ID to outgoing request headers</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Correlation ID Collision</strong>\nA common mistake is generating correlation IDs using timestamp-based schemes or sequential counters that can collide across service instances. This breaks request tracing because multiple unrelated requests share the same ID. Use UUID4 generation with proper entropy sources, and include service identifiers in the prefix if you need human-readable correlation IDs.</p>\n<p>The correlation ID must be <strong>automatically injected</strong> into every <code>LogRecord</code> without requiring developers to manually include it in each logging call. This happens through the context enrichment process - when a <code>LogRecord</code> is created, the system queries the current correlation context and merges the ID into the record&#39;s context fields. The injection process should be transparent and fail gracefully if no correlation ID exists (logging the message without correlation rather than failing).</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Field Name | Type | Description |\n|------------|------|-------------|\n| `correlation_id` | `str` | UUID4 identifier for request tracing |\n| `request_id` | `str` | Alias for correlation_id for backward compatibility |\n| `parent_id` | `str \\| None` | ID of parent operation for nested request tracing |\n| `operation_id` | `str \\| None` | Unique identifier for sub-operations within a request |\n| `session_id` | `str \\| None` | User session identifier for user journey tracing |</code></pre></div>\n\n<h3 id=\"context-propagation\">Context Propagation</h3>\n<p><strong>Context propagation</strong> is the mechanism that carries key-value pairs through nested function calls without requiring explicit parameter passing. Think of it like <strong>ambient lighting</strong> in a room - just as ambient light illuminates everything in the space without needing to shine a spotlight on each object individually, context propagation makes contextual information (user ID, request metadata, feature flags) available to all code within a request&#39;s execution scope.</p>\n<p>Context propagation solves the <strong>parameter drilling problem</strong> where contextual data must be passed as parameters through many layers of function calls, even when intermediate functions don&#39;t use the data. Without propagation, a user ID determined at the HTTP handler level would need explicit passing through business logic, data access, and utility functions just to reach a deep logging call. Context propagation makes this information ambient - available anywhere within the request scope without explicit passing.</p>\n<blockquote>\n<p><strong>Decision: Context Storage Mechanism</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to store context data that&#39;s accessible from any function within a request without parameter passing</li>\n<li><strong>Options Considered</strong>: Thread-local storage only, async-local storage only, hybrid approach with both mechanisms</li>\n<li><strong>Decision</strong>: Hybrid approach using both thread-local and async-local storage with automatic synchronization</li>\n<li><strong>Rationale</strong>: Thread-local handles synchronous code paths efficiently, async-local preserves context across await boundaries, hybrid approach provides complete coverage without forcing async/await everywhere</li>\n<li><strong>Consequences</strong>: Slight memory overhead from dual storage, but enables seamless context access in both sync and async codepaths</li>\n</ul>\n</blockquote>\n<p>The core of context propagation is the <code>LoggingContext</code> manager, which maintains a <strong>dual storage strategy</strong>. Thread-local storage handles synchronous execution paths where code runs on a single thread without interruption. Async-local storage (using asyncio context variables or equivalent) handles asynchronous execution where coroutines can suspend and resume on different threads. The context manager synchronizes between these storage mechanisms to provide a unified view.</p>\n<table>\n<thead>\n<tr>\n<th>Context Operation</th>\n<th>Thread-Local Behavior</th>\n<th>Async-Local Behavior</th>\n<th>Synchronization</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>get_current()</code></td>\n<td>Read from threading.local</td>\n<td>Read from contextvars.ContextVar</td>\n<td>Return union of both sources</td>\n</tr>\n<tr>\n<td><code>set_current(context)</code></td>\n<td>Write to threading.local</td>\n<td>Write to contextvars.ContextVar</td>\n<td>Update both storage locations</td>\n</tr>\n<tr>\n<td><code>add_fields(**fields)</code></td>\n<td>Merge with existing thread context</td>\n<td>Merge with existing async context</td>\n<td>Merge results and update both</td>\n</tr>\n<tr>\n<td><code>clear()</code></td>\n<td>Clear threading.local data</td>\n<td>Clear contextvars context</td>\n<td>Reset both storage mechanisms</td>\n</tr>\n</tbody></table>\n<p><strong>Context inheritance</strong> follows a layered approach where child contexts inherit all fields from their parent and can add additional fields without modifying the parent. This creates an <strong>inheritance chain</strong> similar to object-oriented inheritance - changes in child contexts are isolated from parents, but children automatically receive parent updates. The inheritance mechanism enables request-level context (user ID, correlation ID) to coexist with operation-level context (database transaction ID, cache keys) without conflicts.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Context Layer | Scope | Typical Fields | Inheritance Behavior |\n|---------------|--------|----------------|---------------------|\n| Request Level | Entire HTTP request | `user_id`, `correlation_id`, `request_method` | Inherited by all operations within request |\n| Operation Level | Business logic operation | `operation_name`, `feature_flags`, `tenant_id` | Inherits request context, adds operation-specific fields |\n| Function Level | Individual function call | `function_name`, `parameters`, `execution_id` | Inherits operation context, adds function-specific fields |\n| Error Level | Error handling block | `error_type`, `error_message`, `recovery_action` | Inherits function context, adds error-specific fields |</code></pre></div>\n\n<p>The <strong>context propagation algorithm</strong> follows these steps for each nested function call:</p>\n<ol>\n<li><strong>Context Capture</strong>: When entering a new execution context (function call, async task creation), capture the current context state from both thread-local and async-local storage</li>\n<li><strong>Context Inheritance</strong>: Create a new context object that inherits all fields from the captured parent context</li>\n<li><strong>Context Activation</strong>: Set the new context as current in both storage mechanisms, making it available to nested calls</li>\n<li><strong>Context Isolation</strong>: Ensure changes to the new context don&#39;t affect the parent context that will be restored later</li>\n<li><strong>Context Restoration</strong>: When exiting the execution context, restore the previous context state to both storage mechanisms</li>\n<li><strong>Context Cleanup</strong>: Remove any temporary context data that shouldn&#39;t persist beyond the current execution scope</li>\n</ol>\n<p><strong>Context field management</strong> requires careful handling of data types and serialization. Context fields must be serializable to JSON for inclusion in log records, but the context system should accept arbitrary Python objects and handle serialization gracefully. Non-serializable objects (file handles, database connections, lambda functions) should be converted to string representations rather than causing serialization failures.</p>\n<table>\n<thead>\n<tr>\n<th>Field Type</th>\n<th>Storage Approach</th>\n<th>Serialization Behavior</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Primitive types</td>\n<td>Store directly</td>\n<td>Serialize as-is</td>\n<td><code>&quot;user_id&quot;: &quot;12345&quot;</code>, <code>&quot;timeout&quot;: 30</code></td>\n</tr>\n<tr>\n<td>Collections</td>\n<td>Store directly if serializable</td>\n<td>Recursive serialization</td>\n<td><code>&quot;tags&quot;: [&quot;api&quot;, &quot;production&quot;]</code></td>\n</tr>\n<tr>\n<td>Custom objects</td>\n<td>Store string representation</td>\n<td>Convert to string before serialization</td>\n<td><code>&quot;database&quot;: &quot;&lt;Connection:localhost:5432&gt;&quot;</code></td>\n</tr>\n<tr>\n<td>Circular references</td>\n<td>Detect and replace with placeholder</td>\n<td>Replace with reference placeholder</td>\n<td><code>&quot;parent&quot;: &quot;&lt;CircularReference&gt;&quot;</code></td>\n</tr>\n<tr>\n<td>Large objects</td>\n<td>Truncate or summarize</td>\n<td>Limit size to prevent log bloat</td>\n<td><code>&quot;request_body&quot;: &quot;&lt;Data:1024 bytes&gt;&quot;</code></td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Context Memory Leaks</strong>\nA critical mistake is storing large objects or circular references in context without cleanup, leading to memory leaks. Context should contain only essential metadata (strings, numbers, small collections). Large objects like request bodies, database result sets, or file contents should be summarized or referenced by ID rather than stored directly in context.</p>\n<h3 id=\"async-context-bridge\">Async Context Bridge</h3>\n<p>The <strong>async context bridge</strong> solves the most complex problem in context propagation: preserving logging context when execution crosses async/await boundaries. Think of async operations like <strong>airline passengers changing planes</strong> during a layover. Just as passengers must carry their luggage and boarding passes from one plane to the next to maintain their journey&#39;s continuity, async operations must carry their logging context from one coroutine to the next to maintain request tracing.</p>\n<p>Async context preservation is challenging because <strong>coroutines can suspend and resume</strong> on different threads, traditional thread-local storage becomes unreliable, and <strong>multiple coroutines</strong> can run concurrently within the same request, each needing isolated context. The bridge mechanism ensures that when a coroutine suspends (awaits another operation), its logging context is preserved, and when it resumes, the same context is restored regardless of which thread it resumes on.</p>\n<blockquote>\n<p><strong>Decision: Async Context Storage Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Async operations suspend and resume across thread boundaries, making thread-local storage insufficient</li>\n<li><strong>Options Considered</strong>: Manual context passing, asyncio.current_task() storage, contextvars.ContextVar, custom async-local implementation</li>\n<li><strong>Decision</strong>: contextvars.ContextVar with automatic synchronization to thread-local storage</li>\n<li><strong>Rationale</strong>: contextvars provides language-level async context support, automatically handles suspend/resume cycles, and integrates well with asyncio task management. Synchronization with thread-local ensures compatibility with synchronous code</li>\n<li><strong>Consequences</strong>: Requires Python 3.7+ for contextvars, slight overhead from dual storage, but provides robust async context preservation</li>\n</ul>\n</blockquote>\n<p>The async context bridge operates through <strong>context variables</strong> that maintain their values across await boundaries. When an async function begins execution, it inherits the context variables from its caller. When it suspends on an await, the context variables are automatically preserved. When it resumes, the same context variables are restored, regardless of the underlying thread changes.</p>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fcontext-propagation-flow.svg\" alt=\"Context Propagation Flow\"></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Context State | Event | Next State | Actions Taken |\n|---------------|--------|------------|---------------|\n| `Active` | Function entry | `Active` | Inherit parent context, create child context |\n| `Active` | Await operation | `Suspended` | Store context in contextvars, suspend coroutine |\n| `Suspended` | Operation completion | `Active` | Restore context from contextvars, resume coroutine |\n| `Active` | Exception raised | `Error` | Preserve context for error logging, propagate exception |\n| `Error` | Exception handled | `Active` | Restore pre-exception context, continue execution |\n| `Active` | Function exit | `Cleaned` | Restore parent context, cleanup temporary fields |</code></pre></div>\n\n<p>The <strong>context bridge implementation</strong> requires careful coordination between async and sync storage mechanisms. The bridge maintains a <strong>bidirectional synchronization</strong> where changes to async context (via contextvars) are reflected in thread-local storage and vice versa. This ensures that code using either storage mechanism sees consistent context data.</p>\n<p><strong>Async task spawning</strong> is a critical point where context must be explicitly propagated. When creating new async tasks using <code>asyncio.create_task()</code>, <code>asyncio.gather()</code>, or similar mechanisms, the current context should be captured and passed to the new task. This prevents child tasks from losing their parent&#39;s logging context and enables proper correlation across parallel operations.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Async Operation | Context Propagation Strategy | Implementation Notes |\n|----------------|------------------------------|----------------------|\n| `await async_func()` | Automatic via contextvars | No manual intervention required |\n| `asyncio.create_task()` | Copy current context to new task | Use contextvars.copy_context() for explicit copying |\n| `asyncio.gather()` | Inherit context in each gathered operation | Each operation starts with caller's context |\n| `asyncio.wait_for()` | Preserve context across timeout | Context maintained even if operation times out |\n| Background tasks | Explicit context injection | Pass context as task parameter or use task-local storage |\n| Task cancellation | Context cleanup on cancellation | Restore parent context when task is cancelled |</code></pre></div>\n\n<p><strong>Context isolation</strong> between concurrent async operations is essential to prevent context pollution. When multiple async operations run concurrently (through <code>asyncio.gather()</code> or similar), each should maintain its own context copy. Changes to one operation&#39;s context shouldn&#39;t affect concurrent operations, even if they share the same parent context.</p>\n<p>⚠️ <strong>Pitfall: Context Not Surviving Async Boundaries</strong>\nA common mistake is assuming thread-local storage will work in async code. When an async function suspends and resumes, it might continue on a different thread, making thread-local data inaccessible. Always use contextvars.ContextVar for async operations and ensure proper synchronization with thread-local storage for mixed sync/async codebases.</p>\n<p>The <strong>context lifecycle management</strong> in async environments follows a specific pattern:</p>\n<ol>\n<li><strong>Context Inheritance</strong>: New async operations inherit context from their creator through contextvars propagation</li>\n<li><strong>Context Isolation</strong>: Each async operation gets its own context copy to prevent interference between concurrent operations</li>\n<li><strong>Context Synchronization</strong>: Changes to async context are reflected in thread-local storage for compatibility with sync code</li>\n<li><strong>Context Cleanup</strong>: When async operations complete, temporary context fields are cleaned up to prevent memory accumulation</li>\n<li><strong>Context Restoration</strong>: Parent context is restored after child async operations complete</li>\n<li><strong>Error Context</strong>: Exception handling preserves context for error logging before propagating failures</li>\n</ol>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fasync-context-states.svg\" alt=\"Async Context State Machine\"></p>\n<h3 id=\"request-context-middleware\">Request Context Middleware</h3>\n<p><strong>Request context middleware</strong> serves as the <strong>entry point orchestrator</strong> for the entire context and correlation system. Think of it as the <strong>hotel concierge</strong> who greets guests at the entrance, gathers their information, provides them with key cards and room service menus, and ensures they have everything needed for their stay. Similarly, request middleware greets incoming HTTP requests, extracts or generates correlation IDs, gathers request metadata, and establishes the logging context that will be available throughout request processing.</p>\n<p>The middleware operates at the <strong>HTTP framework level</strong>, intercepting requests before they reach business logic and responses before they&#39;re sent to clients. This positioning ensures that every request gets consistent context treatment regardless of which endpoint handles it, and that correlation data is properly extracted from incoming headers and injected into outgoing headers for distributed tracing.</p>\n<blockquote>\n<p><strong>Decision: Middleware Integration Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to integrate context setup with various HTTP frameworks (Flask, Django, FastAPI) without framework-specific implementations</li>\n<li><strong>Options Considered</strong>: Framework-specific middleware for each platform, WSGI/ASGI middleware for universal compatibility, decorator-based approach</li>\n<li><strong>Decision</strong>: WSGI/ASGI middleware with framework-specific convenience wrappers</li>\n<li><strong>Rationale</strong>: WSGI/ASGI middleware works across all Python web frameworks, provides consistent behavior, and allows framework-specific optimizations through optional wrappers. This approach maximizes compatibility while enabling framework-specific features</li>\n<li><strong>Consequences</strong>: Requires understanding of WSGI/ASGI interfaces, but provides universal compatibility and consistent context behavior across different web frameworks</li>\n</ul>\n</blockquote>\n<p>The <strong>request context extraction</strong> process follows a standardized approach for gathering contextual information from HTTP requests. The middleware examines request headers for existing correlation IDs, extracts user identification from authentication headers, captures request metadata (method, path, user agent), and determines request characteristics (content type, request size, client IP).</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Context Source | Header/Field Name | Extraction Logic | Fallback Behavior |\n|----------------|------------------|------------------|------------------|\n| Correlation ID | `X-Correlation-ID`, `X-Request-ID` | Use first found header value | Generate new UUID4 |\n| User Identity | `Authorization`, `X-User-ID` | Extract from JWT/token or direct header | Anonymous user context |\n| Request Method | HTTP method | Direct from request object | Required field, no fallback |\n| Request Path | URL path | Normalized path without query params | Required field, no fallback |\n| Client IP | `X-Forwarded-For`, `X-Real-IP` | Use leftmost IP from forwarded headers | Fall back to direct connection IP |\n| User Agent | `User-Agent` | Direct header value | 'Unknown' if header missing |</code></pre></div>\n\n<p><strong>Request metadata enrichment</strong> automatically captures standard request information that&#39;s valuable for logging and debugging. This metadata becomes part of the base request context that all subsequent operations inherit. The enrichment process captures both standard HTTP metadata and application-specific context that can be determined at request time.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Metadata Field | Data Type | Description | Example Value |\n|----------------|-----------|-------------|---------------|\n| `request_id` | `str` | Correlation ID for this request | `&quot;550e8400-e29b-41d4-a716-446655440000&quot;` |\n| `request_method` | `str` | HTTP method for the request | `&quot;POST&quot;` |\n| `request_path` | `str` | URL path without query parameters | `&quot;/api/users/123/orders&quot;` |\n| `request_size` | `int` | Content length in bytes | `1024` |\n| `user_id` | `str \\| None` | Authenticated user identifier | `&quot;user_789&quot;` |\n| `client_ip` | `str` | Client IP address (respecting proxies) | `&quot;192.168.1.100&quot;` |\n| `user_agent` | `str` | Client user agent string | `&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64)...&quot;` |\n| `content_type` | `str \\| None` | Request content type | `&quot;application/json&quot;` |\n| `request_start_time` | `str` | ISO timestamp when request processing began | `&quot;2024-01-15T10:30:45.123456Z&quot;` |</code></pre></div>\n\n<p>The <strong>context activation process</strong> sets up the complete logging environment for request processing. This involves creating the initial request context with extracted metadata, activating the context in both thread-local and async-local storage, configuring any request-specific logging behavior (debug mode for specific users, increased log levels for error investigation), and ensuring context propagation is ready for nested operations.</p>\n<p><strong>Context activation algorithm</strong>:</p>\n<ol>\n<li><strong>Extract incoming context</strong>: Parse correlation ID from headers, decode user information from authentication tokens, capture standard request metadata</li>\n<li><strong>Generate missing context</strong>: Create new correlation ID if none provided, set anonymous user context if unauthenticated, establish request timing information</li>\n<li><strong>Create request context</strong>: Combine extracted and generated context into a structured context object</li>\n<li><strong>Activate storage mechanisms</strong>: Set context in both thread-local storage (for sync code) and async-local storage (for async operations)</li>\n<li><strong>Configure request-specific logging</strong>: Apply any user-specific or path-specific logging configuration (debug mode, sampling rates)</li>\n<li><strong>Establish cleanup hooks</strong>: Register context cleanup functions to run after request completion</li>\n</ol>\n<p><strong>Response header injection</strong> ensures that correlation IDs and tracing information flow to downstream systems and clients. The middleware captures the final correlation ID from the request context and injects it into response headers. This enables client-side correlation and helps with distributed tracing when the client makes subsequent requests to other services.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Response Header | Content | Purpose |\n|----------------|---------|---------|\n| `X-Correlation-ID` | Current request correlation ID | Enable client-side request correlation |\n| `X-Request-Duration` | Request processing time in milliseconds | Provide timing information to clients |\n| `X-Response-Size` | Response content length | Complete request/response size tracking |</code></pre></div>\n\n<p>The <strong>middleware error handling</strong> ensures that context and correlation continue working even when request processing fails. When exceptions occur during request processing, the middleware captures error context (exception type, error message, stack trace ID) and includes it in the final log entries. The middleware also ensures that context cleanup happens regardless of whether the request succeeds or fails.</p>\n<p>⚠️ <strong>Pitfall: Context Leakage Between Requests</strong>\nA critical mistake is failing to clean up context between requests in applications that reuse threads (most web frameworks). Context from one request can leak into subsequent requests if cleanup isn&#39;t properly implemented. Always ensure context is cleared at the end of request processing and that new requests start with fresh context.</p>\n<p><strong>Framework integration patterns</strong> provide specific guidance for common Python web frameworks:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">table</span><pre class=\"arch-pre shiki-highlighted\"><code>| Framework | Integration Method | Key Considerations |\n|-----------|-------------------|-------------------|\n| Flask | Custom middleware or before_request/after_request hooks | Use Flask's application context for storage synchronization |\n| Django | Custom middleware inheriting from Django middleware base | Integrate with Django's request/response cycle and user authentication |\n| FastAPI | Dependency injection or custom middleware | Leverage FastAPI's async support and dependency injection for context setup |\n| Tornado | RequestHandler subclass or custom middleware | Handle Tornado's async request processing and ensure context preservation |\n| WSGI apps | WSGI middleware wrapping the application | Universal approach working with any WSGI-compatible framework |\n| ASGI apps | ASGI middleware for async applications | Handle async request processing and ensure context survives async boundaries |</code></pre></div>\n\n<p>The middleware also handles <strong>request context inheritance</strong> for applications that spawn background tasks or make inter-service calls during request processing. When the application creates background tasks, the middleware-established context should be available to those tasks. When making outbound HTTP requests, the correlation ID should be automatically included in request headers.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The context and correlation system requires careful coordination between multiple storage mechanisms and careful handling of async boundaries. This implementation guidance provides concrete patterns for building robust context propagation that works across both synchronous and asynchronous code paths.</p>\n<p><strong>A. Technology Recommendations Table:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Correlation ID Generation</td>\n<td>UUID4 with Python uuid module</td>\n<td>Custom base62 IDs with service prefixes</td>\n</tr>\n<tr>\n<td>Context Storage</td>\n<td>threading.local + contextvars.ContextVar</td>\n<td>Redis for distributed context sharing</td>\n</tr>\n<tr>\n<td>Async Context</td>\n<td>Python contextvars (3.7+)</td>\n<td>Custom async-local implementation</td>\n</tr>\n<tr>\n<td>HTTP Middleware</td>\n<td>Simple WSGI middleware</td>\n<td>Framework-specific middleware with optimizations</td>\n</tr>\n<tr>\n<td>Context Serialization</td>\n<td>JSON with custom encoder</td>\n<td>MessagePack for efficiency</td>\n</tr>\n<tr>\n<td>Context Cleanup</td>\n<td>Manual cleanup in finally blocks</td>\n<td>Automatic cleanup with context managers</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File/Module Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  logging_system/\n    context/\n      __init__.py              ← Public context API exports\n      correlation.py           ← Correlation ID generation and management\n      propagation.py           ← Thread-local and async context storage\n      async_bridge.py          ← Async context preservation mechanisms\n      middleware.py            ← HTTP request context middleware\n      storage.py               ← Context storage backends (thread-local, async-local)\n      serialization.py         ← Context serialization utilities\n    core/\n      logger.py                ← Logger class with context integration\n      record.py                ← LogRecord with context fields\n  tests/\n    context/\n      test_correlation.py      ← Correlation ID tests\n      test_propagation.py      ← Context propagation tests\n      test_async_bridge.py     ← Async context tests\n      test_middleware.py       ← Middleware integration tests</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code:</strong></p>\n<p>Complete correlation ID generation system:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># logging_system/context/correlation.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CorrelationIDGenerator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe correlation ID generator with optional service prefixes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, service_name: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.service_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> service_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate a new correlation ID with optional service prefix.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        correlation_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(uuid.uuid4())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.service_name:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.service_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">-</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">correlation_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> correlation_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_valid</span><span style=\"color:#E1E4E8\">(self, correlation_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate correlation ID format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.service_name:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> correlation_id.startswith(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.service_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">-\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            uuid_part </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> correlation_id[</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.service_name) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            uuid_part </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> correlation_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            uuid.UUID(uuid_part)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global generator instance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_default_generator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CorrelationIDGenerator()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> generate_correlation_id</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate a new correlation ID using the default generator.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> _default_generator.generate()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> set_service_name</span><span style=\"color:#E1E4E8\">(service_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Set service name for correlation ID generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    global</span><span style=\"color:#E1E4E8\"> _default_generator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _default_generator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CorrelationIDGenerator(service_name)</span></span></code></pre></div>\n\n<p>Complete context storage system:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># logging_system/context/storage.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextvars</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> copy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deepcopy</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ContextStorage</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Hybrid context storage using both thread-local and async-local mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._thread_local </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.local()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._async_var: contextvars.ContextVar </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> contextvars.ContextVar(</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'logging_context'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_context</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current context from both storage mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Get thread-local context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        thread_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> getattr</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._thread_local, </span><span style=\"color:#9ECBFF\">'context'</span><span style=\"color:#E1E4E8\">, {})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Get async context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        async_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._async_var.get({})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Merge contexts (async takes precedence)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        merged_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> thread_context.copy()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        merged_context.update(async_context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> merged_context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_context</span><span style=\"color:#E1E4E8\">(self, context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set context in both storage mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set in thread-local storage</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._thread_local.context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deepcopy(context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set in async storage</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._async_var.set(deepcopy(context))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_fields</span><span style=\"color:#E1E4E8\">(self, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">fields) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add fields to current context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.get_context()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_context.update(fields)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.set_context(current_context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear_context</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clear context from both storage mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Clear thread-local</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._thread_local, </span><span style=\"color:#9ECBFF\">'context'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            delattr</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._thread_local, </span><span style=\"color:#9ECBFF\">'context'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Clear async context</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._async_var.set({})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> copy_context</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create a deep copy of current context for task spawning.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> deepcopy(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.get_context())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global storage instance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_context_storage </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ContextStorage()</span></span></code></pre></div>\n\n<p>Complete request middleware foundation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># logging_system/context/middleware.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .correlation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> generate_correlation_id</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .storage </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> _context_storage</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RequestContextMiddleware</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"WSGI middleware for automatic request context setup.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, app: Callable, service_name: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.app </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> app</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.service_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> service_name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __call__</span><span style=\"color:#E1E4E8\">(self, environ: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], start_response: Callable):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract request context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        request_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._extract_request_context(environ)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set up context storage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        _context_storage.set_context(request_context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        request_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> enhanced_start_response</span><span style=\"color:#E1E4E8\">(status: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, headers: </span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">, exc_info</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Add correlation headers to response</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            headers.append((</span><span style=\"color:#9ECBFF\">'X-Correlation-ID'</span><span style=\"color:#E1E4E8\">, request_context[</span><span style=\"color:#9ECBFF\">'correlation_id'</span><span style=\"color:#E1E4E8\">]))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            request_duration </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">((time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> request_start) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            headers.append((</span><span style=\"color:#9ECBFF\">'X-Request-Duration'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(request_duration)))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> start_response(status, headers, exc_info)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Process request with context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.app(environ, enhanced_start_response)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Clean up context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            _context_storage.clear_context()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _extract_request_context</span><span style=\"color:#E1E4E8\">(self, environ: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract request context from WSGI environ.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract correlation ID from headers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        correlation_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            environ.get(</span><span style=\"color:#9ECBFF\">'HTTP_X_CORRELATION_ID'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">or</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            environ.get(</span><span style=\"color:#9ECBFF\">'HTTP_X_REQUEST_ID'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">or</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            generate_correlation_id()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract basic request metadata</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'correlation_id'</span><span style=\"color:#E1E4E8\">: correlation_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'request_method'</span><span style=\"color:#E1E4E8\">: environ.get(</span><span style=\"color:#9ECBFF\">'REQUEST_METHOD'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'UNKNOWN'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'request_path'</span><span style=\"color:#E1E4E8\">: environ.get(</span><span style=\"color:#9ECBFF\">'PATH_INFO'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'/'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'request_start_time'</span><span style=\"color:#E1E4E8\">: time.time(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'client_ip'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._get_client_ip(environ),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'user_agent'</span><span style=\"color:#E1E4E8\">: environ.get(</span><span style=\"color:#9ECBFF\">'HTTP_USER_AGENT'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Unknown'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Add service name if configured</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.service_name:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            context[</span><span style=\"color:#9ECBFF\">'service_name'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.service_name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_client_ip</span><span style=\"color:#E1E4E8\">(self, environ: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract client IP respecting proxy headers.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check for forwarded headers first</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        forwarded_for </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> environ.get(</span><span style=\"color:#9ECBFF\">'HTTP_X_FORWARDED_FOR'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> forwarded_for:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Take the first IP from the chain</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> forwarded_for.split(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">)[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">].strip()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        real_ip </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> environ.get(</span><span style=\"color:#9ECBFF\">'HTTP_X_REAL_IP'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> real_ip:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> real_ip</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Fall back to direct connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> environ.get(</span><span style=\"color:#9ECBFF\">'REMOTE_ADDR'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'unknown'</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<p>Context propagation system for implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># logging_system/context/propagation.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional, ContextManager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .storage </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> _context_storage</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LoggingContext</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for logging context propagation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_current</span><span style=\"color:#E1E4E8\">() -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current logging context from storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve context from hybrid storage mechanism</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle case where no context exists (return empty dict)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure returned context is a copy to prevent external modification</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_current</span><span style=\"color:#E1E4E8\">(context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set current logging context in storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate context is serializable (all values are JSON-compatible)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set context in both thread-local and async-local storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle storage errors gracefully (log warning, continue)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_fields</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">fields) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add fields to current context without replacing existing context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get current context from storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Merge new fields with existing context (new fields take precedence)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate merged context is still serializable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update storage with merged context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use dict.update() but handle potential serialization issues</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clear current logging context from all storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clear context from thread-local storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clear context from async-local storage  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle storage errors (don't raise exceptions from cleanup)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> inherit</span><span style=\"color:#E1E4E8\">(additional_context: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ContextManager[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager that inherits parent context and restores it on exit.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Capture current context as parent context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create child context by copying parent context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Merge additional_context into child context if provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Set child context as current context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Yield the child context to the with block</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: In finally block, restore parent context regardless of exceptions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use try/finally to ensure parent context is always restored</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> propagate_to_async_task</span><span style=\"color:#E1E4E8\">(task_func: </span><span style=\"color:#79B8FF\">callable</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Helper to propagate current context to a new async task.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Capture current context before task creation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create wrapper function that sets context before calling task_func</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return wrapped function that can be passed to asyncio.create_task()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: The wrapper should set context, call original function, then clean up</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p>Async context bridge for implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># logging_system/context/async_bridge.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextvars</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Awaitable, TypeVar</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .propagation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LoggingContext</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">T </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TypeVar(</span><span style=\"color:#9ECBFF\">'T'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> preserve_context</span><span style=\"color:#E1E4E8\">(coro: Awaitable[T]) -> T:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Ensure logging context is preserved across async operation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Capture current logging context before await</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Execute the coroutine and await its result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Restore logging context after coroutine completes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle exceptions by preserving context during error propagation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use try/finally to ensure context restoration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_task_with_context</span><span style=\"color:#E1E4E8\">(coro: Awaitable[T], context: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> asyncio.Task[T]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create async task with explicit context propagation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use context parameter or capture current context if None</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create wrapper coroutine that sets context before running original</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create asyncio task from wrapper coroutine</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return the created task</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use contextvars.copy_context() for proper async context copying</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> gather_with_context</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">coroutines: Awaitable) -> </span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Gather multiple coroutines while preserving context in each.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Capture current context to propagate to all coroutines</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Wrap each coroutine with context preservation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use asyncio.gather() on wrapped coroutines</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return results from asyncio.gather()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AsyncContextManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for async operations with logging context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, context: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store provided context or capture current context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize previous_context storage for restoration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#79B8FF\"> __aenter__</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Capture current context as previous_context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set self.context as current context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return the active context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#79B8FF\"> __aexit__</span><span style=\"color:#E1E4E8\">(self, exc_type, exc_val, exc_tb):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Restore previous_context as current context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle any storage errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Don't suppress exceptions unless they're context-related</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<ul>\n<li>Use <code>threading.local()</code> for thread-local storage in Python</li>\n<li>Use <code>contextvars.ContextVar</code> for async-local storage (requires Python 3.7+)</li>\n<li>Use <code>asyncio.current_task()</code> to get current task for task-local storage</li>\n<li>Use <code>copy.deepcopy()</code> to create isolated context copies</li>\n<li>Use <code>uuid.uuid4()</code> for correlation ID generation with strong uniqueness guarantees</li>\n<li>Use WSGI middleware pattern: <code>app(environ, start_response)</code> for universal framework compatibility</li>\n<li>Use <code>functools.wraps</code> when creating context wrapper functions to preserve function metadata</li>\n<li>Use <code>contextlib.contextmanager</code> decorator for simple context managers</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong></p>\n<p>After implementing Milestone 3, verify context and correlation functionality:</p>\n<p><strong>Command to run</strong>: <code>python -m pytest tests/context/ -v</code></p>\n<p><strong>Expected test output</strong>:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>test_correlation_id_generation ✓\ntest_context_propagation_sync ✓  \ntest_context_propagation_async ✓\ntest_async_context_bridge ✓\ntest_request_middleware_integration ✓</code></pre></div>\n\n<p><strong>Manual verification steps</strong>:</p>\n<ol>\n<li><strong>Start test web server</strong>: <code>python examples/web_app.py</code></li>\n<li><strong>Make request with correlation ID</strong>: <code>curl -H &quot;X-Correlation-ID: test-123&quot; localhost:8000/api/test</code></li>\n<li><strong>Verify logs contain correlation ID</strong>: All log entries should include <code>&quot;correlation_id&quot;: &quot;test-123&quot;</code></li>\n<li><strong>Make request without correlation ID</strong>: <code>curl localhost:8000/api/test</code>  </li>\n<li><strong>Verify generated correlation ID</strong>: Logs should contain auto-generated UUID4 correlation ID</li>\n<li><strong>Test nested function calls</strong>: All log entries from nested functions should inherit same correlation ID</li>\n<li><strong>Test async operations</strong>: Async tasks spawned during request should preserve correlation context</li>\n</ol>\n<p><strong>Signs something is wrong</strong>:</p>\n<ul>\n<li><strong>Logs missing correlation IDs</strong>: Context propagation not working, check storage mechanisms</li>\n<li><strong>Different correlation IDs within same request</strong>: Context not propagating properly across function calls</li>\n<li><strong>Context lost in async operations</strong>: Async context bridge not functioning, check contextvars usage</li>\n<li><strong>Context leaking between requests</strong>: Context cleanup not working, check middleware finally blocks</li>\n</ul>\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Correlation ID missing from logs</td>\n<td>Context not set or not propagating</td>\n<td>Add debug logging in context storage get/set methods</td>\n<td>Ensure context middleware runs before request processing</td>\n</tr>\n<tr>\n<td>Different correlation IDs in same request</td>\n<td>New IDs being generated instead of inheriting</td>\n<td>Check context inheritance in nested function calls</td>\n<td>Use LoggingContext.inherit() context manager</td>\n</tr>\n<tr>\n<td>Context lost in async operations</td>\n<td>Thread-local storage used in async code</td>\n<td>Add logging before/after async operations to track context</td>\n<td>Use contextvars.ContextVar for async operations</td>\n</tr>\n<tr>\n<td>Context leaking between requests</td>\n<td>Context not cleared after request completion</td>\n<td>Add request start/end logging with context state</td>\n<td>Ensure context.clear() in middleware finally block</td>\n</tr>\n<tr>\n<td>Memory usage growing over time</td>\n<td>Context objects not being garbage collected</td>\n<td>Monitor context storage size over time</td>\n<td>Check for circular references in context data</td>\n</tr>\n<tr>\n<td>Performance degradation</td>\n<td>Context copying overhead</td>\n<td>Profile context get/set operations</td>\n<td>Optimize context serialization, limit context size</td>\n</tr>\n</tbody></table>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides critical error handling patterns for all three milestones, with handler failure recovery supporting Milestone 1 (Logger Core), serialization edge cases affecting Milestone 2 (Structured Output), and context cleanup preventing memory issues in Milestone 3 (Context &amp; Correlation).</p>\n</blockquote>\n<h3 id=\"the-safety-net-analogy\">The Safety Net Analogy</h3>\n<p>Think of error handling in a logging system like the safety nets in a circus. When an acrobat performs dangerous stunts high above the ground, there are multiple layers of protection: primary safety harnesses, backup cables, and finally the net below. Similarly, our logging system must have multiple layers of protection because <strong>logging cannot be allowed to crash the main application</strong>. When a file system is full, when network connections fail, when objects contain circular references, the logging system must gracefully degrade rather than bringing down the entire service.</p>\n<p>The critical insight is that logging is a <strong>non-critical path operation</strong> from the application&#39;s perspective. If an e-commerce service cannot write logs, it should still process orders successfully. However, losing observability is serious, so we need sophisticated recovery mechanisms that maintain partial functionality while alerting operators to the underlying issues.</p>\n<h3 id=\"handler-failure-recovery\">Handler Failure Recovery</h3>\n<p>Handler failure recovery addresses the reality that output destinations are inherently unreliable. File systems can become full, network connections can timeout, and remote log aggregation services can become unavailable. The logging system must continue operating in these scenarios while providing mechanisms for recovery and alerting.</p>\n<blockquote>\n<p><strong>Decision: Multi-Handler Isolation</strong></p>\n<ul>\n<li><strong>Context</strong>: When one handler fails (e.g., network timeout), other handlers should continue working</li>\n<li><strong>Options Considered</strong>: Fail-fast on any handler error, retry all handlers together, isolate handler failures</li>\n<li><strong>Decision</strong>: Isolate handler failures so each handler&#39;s success/failure is independent</li>\n<li><strong>Rationale</strong>: A full disk shouldn&#39;t prevent console logging, and network issues shouldn&#39;t stop file logging</li>\n<li><strong>Consequences</strong>: Requires individual error handling per handler but maintains maximum availability</li>\n</ul>\n</blockquote>\n<p>The handler dispatch mechanism implements the <strong>Circuit Breaker Pattern</strong> for each handler type. When a handler experiences repeated failures, it transitions to a failed state and stops attempting operations for a configured time period. This prevents cascading failures and reduces resource consumption during outages.</p>\n<h4 id=\"handler-error-states\">Handler Error States</h4>\n<p>Each handler maintains state information to track its health and implement appropriate recovery strategies:</p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Description</th>\n<th>Behavior</th>\n<th>Recovery Trigger</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>HEALTHY</code></td>\n<td>Handler operating normally</td>\n<td>Process all log records immediately</td>\n<td>N/A - default state</td>\n</tr>\n<tr>\n<td><code>DEGRADED</code></td>\n<td>Experiencing intermittent failures</td>\n<td>Process records with retry logic</td>\n<td>Successful operation after failure</td>\n</tr>\n<tr>\n<td><code>FAILED</code></td>\n<td>Consecutive failures exceeded threshold</td>\n<td>Drop records or queue for later</td>\n<td>Manual reset or timeout period</td>\n</tr>\n<tr>\n<td><code>RECOVERING</code></td>\n<td>Attempting to return to service</td>\n<td>Test with low-priority records first</td>\n<td>Sustained successful operations</td>\n</tr>\n</tbody></table>\n<h4 id=\"failure-detection-and-response\">Failure Detection and Response</h4>\n<p>The logging system implements sophisticated failure detection that goes beyond simple exception catching. Different types of failures require different response strategies:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Detection Method</th>\n<th>Immediate Response</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File System Full</td>\n<td><code>OSError</code> with <code>errno.ENOSPC</code></td>\n<td>Switch to console handler, emit warning</td>\n<td>Monitor disk space, resume when available</td>\n</tr>\n<tr>\n<td>Permission Denied</td>\n<td><code>PermissionError</code> on file operations</td>\n<td>Attempt alternative file location</td>\n<td>Alert administrator, try alternative paths</td>\n</tr>\n<tr>\n<td>Network Timeout</td>\n<td>Socket timeout during remote handler</td>\n<td>Buffer records locally</td>\n<td>Exponential backoff retry, eventual discard</td>\n</tr>\n<tr>\n<td>Serialization Error</td>\n<td>JSON encoding exception</td>\n<td>Log error record instead</td>\n<td>Safe serialize with type conversion</td>\n</tr>\n</tbody></table>\n<p>The <strong>safe_call</strong> function provides the foundation for handler isolation:</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>func</code></td>\n<td><code>Callable</code></td>\n<td>The handler function to execute safely</td>\n</tr>\n<tr>\n<td><code>*args</code></td>\n<td><code>Any</code></td>\n<td>Positional arguments for the handler function</td>\n</tr>\n<tr>\n<td><code>default</code></td>\n<td><code>Any</code></td>\n<td>Default return value if function fails</td>\n</tr>\n<tr>\n<td><code>timeout</code></td>\n<td><code>float</code></td>\n<td>Maximum execution time before considering failed</td>\n</tr>\n<tr>\n<td><code>**kwargs</code></td>\n<td><code>Any</code></td>\n<td>Keyword arguments for the handler function</td>\n</tr>\n</tbody></table>\n<p>When a handler fails, the system follows this recovery procedure:</p>\n<ol>\n<li><strong>Immediate Isolation</strong>: The failing handler is marked as degraded and subsequent calls use defensive timeouts</li>\n<li><strong>Error Classification</strong>: The exception type determines whether the failure is likely temporary or permanent</li>\n<li><strong>Alternative Routing</strong>: If available, log records are routed to backup handlers of the same type</li>\n<li><strong>Graceful Degradation</strong>: Critical system information is logged to console as a fallback</li>\n<li><strong>Recovery Monitoring</strong>: Background health checks test handler availability without affecting main log flow</li>\n<li><strong>Automatic Restoration</strong>: Successful operations gradually restore the handler to healthy status</li>\n</ol>\n<blockquote>\n<p>The key insight is that logging failures should never propagate as exceptions to the calling application code. A failed log operation returns normally but may emit diagnostic information through alternative channels.</p>\n</blockquote>\n<h4 id=\"buffer-management-for-failed-handlers\">Buffer Management for Failed Handlers</h4>\n<p>When handlers fail, the system implements intelligent buffering to preserve critical log information without consuming unbounded memory:</p>\n<table>\n<thead>\n<tr>\n<th>Buffer Type</th>\n<th>Capacity</th>\n<th>Retention Policy</th>\n<th>Flush Trigger</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MEMORY_BUFFER</code></td>\n<td>1000 records</td>\n<td>FIFO replacement when full</td>\n<td>Handler recovery</td>\n</tr>\n<tr>\n<td><code>DISK_BUFFER</code></td>\n<td>100MB files</td>\n<td>Rotate when size limit reached</td>\n<td>Handler recovery or manual flush</td>\n</tr>\n<tr>\n<td><code>PRIORITY_BUFFER</code></td>\n<td>100 ERROR/FATAL records</td>\n<td>Never discard high-priority records</td>\n<td>Handler recovery only</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Unbounded Buffer Growth</strong>\nA common mistake is buffering failed log records indefinitely, which leads to memory leaks during prolonged outages. Always implement size limits and explicit discard policies for buffered data.</p>\n<h3 id=\"serialization-edge-cases\">Serialization Edge Cases</h3>\n<p>Structured logging&#39;s reliance on JSON serialization introduces complex edge cases that can cause runtime failures. The system must handle non-serializable Python objects, circular references, deeply nested structures, and objects with dynamic or sensitive content gracefully.</p>\n<blockquote>\n<p><strong>Decision: Safe Serialization with Fallback</strong></p>\n<ul>\n<li><strong>Context</strong>: User code may pass any Python object as context, including non-serializable types</li>\n<li><strong>Options Considered</strong>: Reject non-serializable objects, convert everything to strings, selective type conversion</li>\n<li><strong>Decision</strong>: Implement custom JSON encoder with intelligent type conversion and circular reference detection</li>\n<li><strong>Rationale</strong>: Preserves maximum information while ensuring JSON output is always valid</li>\n<li><strong>Consequences</strong>: Requires custom encoder logic but provides robust handling of edge cases</li>\n</ul>\n</blockquote>\n<h4 id=\"non-serializable-object-handling\">Non-Serializable Object Handling</h4>\n<p>The <code>SafeJSONEncoder</code> provides intelligent conversion for Python objects that don&#39;t have native JSON representations:</p>\n<table>\n<thead>\n<tr>\n<th>Object Type</th>\n<th>Conversion Strategy</th>\n<th>Example Input</th>\n<th>Example Output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>datetime</code></td>\n<td>ISO 8601 string conversion</td>\n<td><code>datetime(2023, 12, 25)</code></td>\n<td><code>&quot;2023-12-25T00:00:00Z&quot;</code></td>\n</tr>\n<tr>\n<td><code>Decimal</code></td>\n<td>String conversion preserving precision</td>\n<td><code>Decimal(&quot;123.456&quot;)</code></td>\n<td><code>&quot;123.456&quot;</code></td>\n</tr>\n<tr>\n<td><code>UUID</code></td>\n<td>String conversion</td>\n<td><code>UUID(&#39;123e4567-e89b-12d3-a456-426614174000&#39;)</code></td>\n<td><code>&quot;123e4567-e89b-12d3-a456-426614174000&quot;</code></td>\n</tr>\n<tr>\n<td><code>Exception</code></td>\n<td>Type and message extraction</td>\n<td><code>ValueError(&quot;Invalid input&quot;)</code></td>\n<td><code>{&quot;type&quot;: &quot;ValueError&quot;, &quot;message&quot;: &quot;Invalid input&quot;}</code></td>\n</tr>\n<tr>\n<td><code>Custom Objects</code></td>\n<td>Repr string with type information</td>\n<td><code>MyClass(value=42)</code></td>\n<td><code>{&quot;type&quot;: &quot;MyClass&quot;, &quot;repr&quot;: &quot;MyClass(value=42)&quot;}</code></td>\n</tr>\n</tbody></table>\n<p>The serialization process follows a defensive strategy that prioritizes successful log output over perfect representation:</p>\n<ol>\n<li><strong>Primary Serialization Attempt</strong>: Use standard JSON encoder for basic types (str, int, float, bool, list, dict)</li>\n<li><strong>Custom Type Conversion</strong>: Apply type-specific converters for known problematic types like datetime and UUID</li>\n<li><strong>Repr Fallback</strong>: For unknown custom objects, capture the string representation and type information</li>\n<li><strong>Error Isolation</strong>: If individual fields fail serialization, replace with error markers rather than failing entire record</li>\n<li><strong>Size Estimation</strong>: Before full serialization, estimate the output size to prevent memory exhaustion</li>\n</ol>\n<h4 id=\"circular-reference-protection\">Circular Reference Protection</h4>\n<p>Circular references occur when objects contain references to themselves, either directly or through a chain of references. Without protection, JSON serialization would enter infinite loops and eventually crash with stack overflow errors.</p>\n<p>The <strong>safe_serialize</strong> function implements circular reference detection using a tracking set:</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>data</code></td>\n<td><code>Any</code></td>\n<td>The object to serialize, typically a dictionary</td>\n</tr>\n<tr>\n<td><code>max_depth</code></td>\n<td><code>int</code></td>\n<td>Maximum nesting depth before truncation (default: 10)</td>\n</tr>\n<tr>\n<td><code>seen_objects</code></td>\n<td><code>Set[int]</code></td>\n<td>Set of object IDs already being processed</td>\n</tr>\n<tr>\n<td><code>current_depth</code></td>\n<td><code>int</code></td>\n<td>Current recursion depth for stack protection</td>\n</tr>\n</tbody></table>\n<p>The circular reference detection algorithm works as follows:</p>\n<ol>\n<li><strong>Object Identity Tracking</strong>: For each object encountered, record its <code>id()</code> in the <code>seen_objects</code> set</li>\n<li><strong>Reference Check</strong>: Before processing any object, check if its ID is already in the tracking set</li>\n<li><strong>Circular Reference Marker</strong>: If a circular reference is detected, replace with a marker: <code>{&quot;_circular_ref&quot;: &quot;object_type_at_depth_N&quot;}</code></li>\n<li><strong>Depth Limiting</strong>: Even without circular references, stop recursion at maximum depth to prevent stack overflow</li>\n<li><strong>Cleanup</strong>: Remove object IDs from tracking set when exiting their scope to allow repeated references</li>\n</ol>\n<h4 id=\"large-object-handling\">Large Object Handling</h4>\n<p>Large objects in logging context can consume excessive memory and make log records unreadable. The system implements size-based truncation and sampling strategies:</p>\n<table>\n<thead>\n<tr>\n<th>Size Threshold</th>\n<th>Handling Strategy</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&lt; 1KB</td>\n<td>Serialize completely</td>\n<td>Small dictionaries, short strings</td>\n</tr>\n<tr>\n<td>1KB - 10KB</td>\n<td>Serialize with truncation warning</td>\n<td>Medium configuration objects</td>\n</tr>\n<tr>\n<td>10KB - 100KB</td>\n<td>Serialize keys only, with size information</td>\n<td>Large data structures</td>\n</tr>\n<tr>\n<td>&gt; 100KB</td>\n<td>Replace with summary metadata</td>\n<td>Database query results, file contents</td>\n</tr>\n</tbody></table>\n<p>The <strong>estimate_serialized_size</strong> function provides efficient size estimation without full serialization:</p>\n<ol>\n<li><strong>Type-Based Estimation</strong>: Use heuristics for common types (strings: byte length, lists: sum of elements, etc.)</li>\n<li><strong>Sampling</strong>: For large containers, sample first N elements and extrapolate total size</li>\n<li><strong>Early Termination</strong>: Stop estimation when size threshold is clearly exceeded</li>\n<li><strong>Memory Protection</strong>: Never allocate memory proportional to estimated size during estimation</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Sensitive Data in Logs</strong>\nAlways implement field filtering for sensitive information like passwords, tokens, and personal data. Consider using a configurable blacklist of field names that should be redacted during serialization.</p>\n<h4 id=\"encoding-error-recovery\">Encoding Error Recovery</h4>\n<p>When serialization fails despite all protective measures, the system implements progressive degradation:</p>\n<ol>\n<li><strong>Field-Level Recovery</strong>: If individual context fields fail, replace them with error descriptions and continue</li>\n<li><strong>Message Preservation</strong>: Always preserve the primary log message, even if all context fails serialization</li>\n<li><strong>Diagnostic Information</strong>: Include serialization error details in a special <code>_serialization_errors</code> field</li>\n<li><strong>Raw Fallback</strong>: As a last resort, convert the entire context to a string representation</li>\n<li><strong>Error Logging</strong>: Use a separate error channel to log serialization failures for debugging</li>\n</ol>\n<h3 id=\"context-cleanup-and-memory-management\">Context Cleanup and Memory Management</h3>\n<p>Context management in a structured logging system introduces subtle memory management challenges, particularly in long-running services with high request volumes. Without proper cleanup, context objects can accumulate indefinitely, leading to memory leaks and degraded performance.</p>\n<blockquote>\n<p><strong>Decision: Scoped Context with Automatic Cleanup</strong></p>\n<ul>\n<li><strong>Context</strong>: Context objects must be cleaned up when requests complete, but manual cleanup is error-prone</li>\n<li><strong>Options Considered</strong>: Manual cleanup in application code, reference counting, scoped context managers</li>\n<li><strong>Decision</strong>: Implement context managers with automatic cleanup and weak references for orphan detection</li>\n<li><strong>Rationale</strong>: Reduces developer burden while providing deterministic cleanup semantics</li>\n<li><strong>Consequences</strong>: Requires careful design of context inheritance and async context bridging</li>\n</ul>\n</blockquote>\n<h4 id=\"context-lifecycle-management\">Context Lifecycle Management</h4>\n<p>The logging context follows a strict lifecycle that ensures proper resource management across different execution models:</p>\n<table>\n<thead>\n<tr>\n<th>Lifecycle Phase</th>\n<th>Thread-Local Context</th>\n<th>Async Context</th>\n<th>Cleanup Actions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Creation</strong></td>\n<td>Store in <code>threading.local</code></td>\n<td>Set <code>contextvars.ContextVar</code></td>\n<td>Initialize parent reference</td>\n</tr>\n<tr>\n<td><strong>Inheritance</strong></td>\n<td>Copy parent context to child</td>\n<td><code>contextvars.copy_context()</code></td>\n<td>Establish parent-child relationship</td>\n</tr>\n<tr>\n<td><strong>Modification</strong></td>\n<td>Update thread-local storage</td>\n<td>Create new context with changes</td>\n<td>Preserve immutability of parent</td>\n</tr>\n<tr>\n<td><strong>Propagation</strong></td>\n<td>Manual passing between threads</td>\n<td>Automatic with async tasks</td>\n<td>Sync both storage mechanisms</td>\n</tr>\n<tr>\n<td><strong>Cleanup</strong></td>\n<td>Clear on request completion</td>\n<td>Automatic scope exit</td>\n<td>Remove circular references</td>\n</tr>\n</tbody></table>\n<p>The dual storage strategy ensures context availability regardless of execution model:</p>\n<table>\n<thead>\n<tr>\n<th>Storage Type</th>\n<th>Use Case</th>\n<th>Advantages</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>threading.local</code></td>\n<td>Synchronous request processing</td>\n<td>Simple access, no parameter passing</td>\n<td>Manual cleanup required</td>\n</tr>\n<tr>\n<td><code>contextvars.ContextVar</code></td>\n<td>Async/await operations</td>\n<td>Automatic task isolation</td>\n<td>Python 3.7+ only</td>\n</tr>\n<tr>\n<td><strong>Hybrid Approach</strong></td>\n<td>Mixed sync/async applications</td>\n<td>Best of both worlds</td>\n<td>Requires synchronization logic</td>\n</tr>\n</tbody></table>\n<h4 id=\"memory-leak-prevention\">Memory Leak Prevention</h4>\n<p>Context objects can cause memory leaks through several mechanisms that require active prevention:</p>\n<p><strong>Circular Reference Prevention:</strong></p>\n<ol>\n<li><strong>Weak Parent References</strong>: Child contexts hold weak references to parents to break reference cycles</li>\n<li><strong>Context Isolation</strong>: Changes in child contexts create new objects rather than modifying parents</li>\n<li><strong>Explicit Cleanup</strong>: Context managers ensure deterministic cleanup even when exceptions occur</li>\n<li><strong>Orphan Detection</strong>: Background monitoring identifies contexts that haven&#39;t been properly cleaned up</li>\n</ol>\n<p><strong>Context Size Management:</strong>\nThe system implements several strategies to prevent context objects from growing unboundedly:</p>\n<table>\n<thead>\n<tr>\n<th>Strategy</th>\n<th>Implementation</th>\n<th>Trigger</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Field Count Limit</strong></td>\n<td>Maximum 50 context fields</td>\n<td>On context modification</td>\n<td>Remove oldest fields (LRU)</td>\n</tr>\n<tr>\n<td><strong>Value Size Limit</strong></td>\n<td>Maximum 1KB per field value</td>\n<td>On field assignment</td>\n<td>Truncate with warning marker</td>\n</tr>\n<tr>\n<td><strong>Total Size Limit</strong></td>\n<td>Maximum 10KB per context</td>\n<td>On context serialization</td>\n<td>Summarize large fields</td>\n</tr>\n<tr>\n<td><strong>Depth Limit</strong></td>\n<td>Maximum 10 inheritance levels</td>\n<td>On child context creation</td>\n<td>Flatten inheritance chain</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Context Accumulation in Long-Running Tasks</strong>\nIn long-running background tasks, context fields can accumulate over time if not properly scoped. Always use context managers or explicit cleanup in loops and long-running operations.</p>\n<h4 id=\"async-context-bridge-implementation\">Async Context Bridge Implementation</h4>\n<p>The async context bridge ensures that logging context is preserved across async/await boundaries, which is critical for maintaining request tracing in async applications:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Implementation Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>AsyncContextManager</code></td>\n<td>Preserve context across await points</td>\n<td>Copy context before async operations</td>\n</tr>\n<tr>\n<td><code>TaskContextPropagator</code></td>\n<td>Inject context into new tasks</td>\n<td>Wrap task functions with context restoration</td>\n</tr>\n<tr>\n<td><code>CoroutineContextWrapper</code></td>\n<td>Maintain context in coroutines</td>\n<td>Use <code>contextvars</code> for automatic propagation</td>\n</tr>\n</tbody></table>\n<p>The context preservation algorithm for async operations:</p>\n<ol>\n<li><strong>Pre-Async Capture</strong>: Before any async operation, capture the current context from both storage mechanisms</li>\n<li><strong>Context Packaging</strong>: Create a context snapshot that includes all current fields and correlation IDs</li>\n<li><strong>Async Task Wrapping</strong>: Wrap the async function to restore context when the task begins execution</li>\n<li><strong>Context Restoration</strong>: When the async task starts, restore the captured context to both storage types</li>\n<li><strong>Cleanup Registration</strong>: Register cleanup callbacks to clear context when the task completes</li>\n<li><strong>Exception Handling</strong>: Ensure context cleanup occurs even when async operations raise exceptions</li>\n</ol>\n<h4 id=\"context-memory-monitoring\">Context Memory Monitoring</h4>\n<p>The system provides monitoring and debugging capabilities for context memory usage:</p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Collection Method</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>active_context_count</code></td>\n<td>Track context creation/destruction</td>\n<td>Detect context leaks</td>\n</tr>\n<tr>\n<td><code>average_context_size</code></td>\n<td>Measure serialized context size</td>\n<td>Identify oversized contexts</td>\n</tr>\n<tr>\n<td><code>context_inheritance_depth</code></td>\n<td>Track parent-child relationships</td>\n<td>Prevent deep inheritance chains</td>\n</tr>\n<tr>\n<td><code>cleanup_failure_count</code></td>\n<td>Count failed cleanup operations</td>\n<td>Monitor cleanup effectiveness</td>\n</tr>\n</tbody></table>\n<p><strong>Context Debugging Tools:</strong></p>\n<ol>\n<li><strong>Context Dump</strong>: Function to serialize and display all active contexts for debugging</li>\n<li><strong>Leak Detection</strong>: Periodic scanning for contexts that haven&#39;t been accessed recently</li>\n<li><strong>Size Analysis</strong>: Breakdown of context memory usage by field type and size</li>\n<li><strong>Inheritance Visualization</strong>: Display parent-child relationships for complex context hierarchies</li>\n</ol>\n<p>The context cleanup process implements several safety mechanisms:</p>\n<ol>\n<li><strong>Timeout-Based Cleanup</strong>: Contexts older than a configured age are automatically cleaned up</li>\n<li><strong>Reference Counting</strong>: Track how many active operations reference each context</li>\n<li><strong>Graceful Degradation</strong>: If cleanup fails, mark contexts as stale rather than leaving them indefinitely</li>\n<li><strong>Background Monitoring</strong>: Separate thread monitors context health and performs maintenance</li>\n<li><strong>Emergency Cleanup</strong>: When memory pressure is detected, aggressively clean up non-essential contexts</li>\n</ol>\n<blockquote>\n<p>The fundamental principle is that context management should be invisible to application developers while providing robust memory management and debugging capabilities for production operations.</p>\n</blockquote>\n<p><img src=\"/api/project/logging-structured/architecture-doc/asset?path=diagrams%2Fhandler-dispatch-sequence.svg\" alt=\"Handler Dispatch Sequence\"></p>\n<h3 id=\"common-pitfalls-in-error-handling\">Common Pitfalls in Error Handling</h3>\n<p>⚠️ <strong>Pitfall: Logging Errors That Break Application Flow</strong>\nThe most critical mistake is allowing logging operations to throw exceptions that propagate to application code. Always wrap logging operations in try-catch blocks and provide default behaviors for all failure scenarios.</p>\n<p>⚠️ <strong>Pitfall: Synchronous I/O in High-Performance Paths</strong>\nUsing synchronous file or network I/O for logging in request processing threads can significantly impact application performance. Consider async handlers or background thread dispatching for high-throughput scenarios.</p>\n<p>⚠️ <strong>Pitfall: Retrying Failed Operations Indefinitely</strong>\nWithout proper backoff and circuit breaking, failed log handlers can consume CPU and network resources indefinitely. Implement exponential backoff and maximum retry limits.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Handler Configuration Validation</strong>\nInvalid handler configurations (non-existent file paths, invalid network addresses) should be detected at startup rather than causing runtime failures. Implement configuration validation during logger initialization.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Error Recovery</td>\n<td>Basic try/except with logging</td>\n<td>Circuit breaker pattern with metrics</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td>Custom JSON encoder</td>\n<td>Protocol Buffers with fallback</td>\n</tr>\n<tr>\n<td>Context Storage</td>\n<td>Threading.local only</td>\n<td>Hybrid threading.local + contextvars</td>\n</tr>\n<tr>\n<td>Buffer Management</td>\n<td>In-memory lists</td>\n<td>Persistent disk-backed queues</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Simple counters</td>\n<td>Prometheus metrics with alerting</td>\n</tr>\n</tbody></table>\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> weakref</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, List, Optional, Set, Union</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextvars</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HandlerState</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HEALTHY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"healthy\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEGRADED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"degraded\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FAILED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"failed\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    RECOVERING</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"recovering\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SafeJSONEncoder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">json</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">JSONEncoder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Custom JSON encoder that handles non-serializable objects gracefully.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._seen_objects </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._current_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> kwargs.get(</span><span style=\"color:#9ECBFF\">'max_depth'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">MAX_DEPTH</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> default</span><span style=\"color:#E1E4E8\">(self, obj):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement type-specific conversion for datetime, UUID, Decimal, Exception</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add circular reference detection using object id tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement depth limiting to prevent stack overflow</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add fallback string conversion for unknown types</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ThreadSafeCounter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe counter for tracking handler failures.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, initial_value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> initial_value</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> increment</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> reset</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._value </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> value</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreaker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Circuit breaker for handler failure isolation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, failure_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, timeout_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60.0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.failure_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> failure_threshold</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timeout_seconds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timeout_seconds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._failure_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ThreadSafeCounter()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._last_failure_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HandlerState.</span><span style=\"color:#79B8FF\">HEALTHY</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> call</span><span style=\"color:#E1E4E8\">(self, func, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check circuit breaker state before allowing call</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Execute function and handle success/failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update failure count and state based on result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement timeout logic for failed state recovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ContextBuffer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Memory-managed buffer for failed log records.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">, max_memory_mb: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_memory_bytes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_memory_mb </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._current_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_record</span><span style=\"color:#E1E4E8\">(self, record: </span><span style=\"color:#9ECBFF\">'LogRecord'</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Estimate record memory size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if adding record would exceed limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Remove old records if necessary (FIFO)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add record to buffer and update memory tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> flush_to_handler</span><span style=\"color:#E1E4E8\">(self, handler: </span><span style=\"color:#9ECBFF\">'Handler'</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Attempt to send buffered records to recovered handler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Remove successfully sent records from buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return count of successfully flushed records</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_serialize</span><span style=\"color:#E1E4E8\">(data: Any, max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> MAX_DEPTH</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Serialize data to JSON with circular reference and size protection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create SafeJSONEncoder instance with depth limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement size estimation before full serialization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle serialization exceptions gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return valid JSON string even on partial failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> estimate_serialized_size</span><span style=\"color:#E1E4E8\">(data: Any) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Estimate JSON serialization size without full serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement type-based size estimation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Sample large containers to avoid O(n) computation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return conservative size estimate in bytes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> safe_call</span><span style=\"color:#E1E4E8\">(func, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">DEFAULT_TIMEOUT</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Safely execute function with timeout and exception handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement timeout mechanism using threading.Timer or signal</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Catch and log exceptions without propagating</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return default value on failure or timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log diagnostic information about failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"core-error-handling-skeleton\">Core Error Handling Skeleton</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BaseHandler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for all log output handlers with error recovery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._circuit_breaker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreaker()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ContextBuffer()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HandlerState.</span><span style=\"color:#79B8FF\">HEALTHY</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._last_success_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check circuit breaker state - return False if failed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt to send record using _write_record method</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle success case - update circuit breaker, flush buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle failure case - add to buffer, update circuit breaker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return True if handled (success or buffered), False if dropped</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_record</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Subclasses implement actual output logic here</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This method should raise exceptions for failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Subclasses must implement _write_record\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> recover</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test handler availability with a dummy record</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If successful, attempt to flush buffered records</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update handler state based on recovery success</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return True if handler is now operational</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FileHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">BaseHandler</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"File output handler with disk space and permission error handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, file_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"file:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">file_path</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.file_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> file_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._file_handle </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_record</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if file handle is open, open if necessary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Format record using configured formatter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Write formatted record to file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Flush to ensure data is written (consider sync vs async)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle specific errors: disk full, permission denied, etc.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ContextStorage</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Dual storage for thread-local and async context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._thread_local </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.local()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._async_var </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> contextvars.ContextVar(</span><span style=\"color:#9ECBFF\">'logging_context'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{})</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._active_contexts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> weakref.WeakSet()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_current</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Try to get context from async storage (contextvars)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Fall back to thread-local storage if async not available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return empty dict if no context is set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Track context access for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_current</span><span style=\"color:#E1E4E8\">(self, context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate context size and field count limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set context in both storage mechanisms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Register context for cleanup monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle storage failures gracefully</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cleanup_orphaned_contexts</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Identify contexts not accessed recently</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if contexts have active references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Clean up orphaned contexts from storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return count of cleaned up contexts for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> preserve_context_async</span><span style=\"color:#E1E4E8\">(coro):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Decorator to preserve logging context across async operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Capture current context before async operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create wrapper that restores context when async function starts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure context cleanup on async completion or exception</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle nested async calls and context inheritance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n  core/\n    __init__.py\n    logger.py                   ← Logger, LoggerRegistry\n    record.py                   ← LogRecord, LogLevel constants\n    handlers/\n      __init__.py\n      base.py                   ← BaseHandler, error recovery\n      file_handler.py           ← FileHandler with disk error handling\n      console_handler.py        ← ConsoleHandler with color/encoding errors\n      remote_handler.py         ← NetworkHandler with timeout/retry logic\n  formatters/\n    __init__.py\n    base.py                     ← BaseFormatter interface\n    json_formatter.py           ← JSONFormatter with SafeJSONEncoder\n    pretty_formatter.py         ← PrettyFormatter for development\n  context/\n    __init__.py\n    storage.py                  ← ContextStorage, cleanup logic\n    correlation.py              ← CorrelationIDGenerator\n    middleware.py               ← RequestContextMiddleware\n  utils/\n    __init__.py\n    serialization.py            ← safe_serialize, estimate_serialized_size\n    safety.py                   ← safe_call, CircuitBreaker\n    monitoring.py               ← Context monitoring and leak detection\n  tests/\n    test_error_handling.py      ← Handler failure scenarios\n    test_serialization.py       ← Edge case serialization tests\n    test_context_cleanup.py     ← Memory leak and cleanup tests</code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Checkpoint 1: Handler Failure Recovery</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test file handler with disk full simulation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_error_handling.py::test_file_handler_disk_full</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Handler switches to degraded state, logs continue to console</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Signs of issues: Exceptions propagate to application, logs are lost entirely</span></span></code></pre></div>\n\n<p><strong>Checkpoint 2: Serialization Edge Cases</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test circular reference handling</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import logging_system</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = logging_system.get_logger('test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">obj = {'self': None}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">obj['self'] = obj</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('Test circular ref', context_obj=obj)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: JSON output with circular reference marker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Signs of issues: RecursionError, stack overflow, or malformed JSON</span></span></code></pre></div>\n\n<p><strong>Checkpoint 3: Context Cleanup</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test context cleanup under load</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> tests/stress_test_context.py</span><span style=\"color:#79B8FF\"> --requests=10000</span><span style=\"color:#79B8FF\"> --async-tasks=100</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Stable memory usage, no growth over time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Signs of issues: Memory usage grows linearly, eventual OutOfMemoryError</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>Python Error Handling:</strong></p>\n<ul>\n<li>Use <code>errno</code> module constants instead of hardcoded error codes: <code>errno.ENOSPC</code> for disk full</li>\n<li><code>threading.local()</code> provides thread-isolated storage for synchronous contexts</li>\n<li><code>contextvars.ContextVar</code> automatically handles async context isolation in Python 3.7+</li>\n<li>Use <code>weakref.WeakSet()</code> to track context objects without preventing garbage collection</li>\n<li><code>json.JSONEncoder.default()</code> method is the proper override point for custom serialization</li>\n</ul>\n<p><strong>Memory Management:</strong></p>\n<ul>\n<li><code>sys.getsizeof()</code> provides memory size estimation for Python objects</li>\n<li><code>gc.collect()</code> can be called explicitly when cleaning up large numbers of contexts</li>\n<li>Use <code>__slots__</code> in frequently created classes to reduce memory overhead</li>\n<li><code>deque</code> from collections provides efficient FIFO operations for buffering</li>\n</ul>\n<p><strong>Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Application crashes with JSON errors</td>\n<td>Circular references in context</td>\n<td>Add debug logging in SafeJSONEncoder</td>\n<td>Implement proper circular reference detection</td>\n</tr>\n<tr>\n<td>Memory usage grows over time</td>\n<td>Context objects not cleaned up</td>\n<td>Monitor <code>_active_contexts</code> size</td>\n<td>Add explicit cleanup in finally blocks</td>\n</tr>\n<tr>\n<td>Logs missing during high load</td>\n<td>Handler failures not recovered</td>\n<td>Check handler state and buffer sizes</td>\n<td>Implement proper circuit breaker recovery</td>\n</tr>\n<tr>\n<td>Context not propagating to async tasks</td>\n<td>Missing contextvars setup</td>\n<td>Add trace logging in context bridge</td>\n<td>Use <code>contextvars.copy_context()</code> correctly</td>\n</tr>\n<tr>\n<td>File handler stops working</td>\n<td>Disk full or permission errors</td>\n<td>Check handler error logs and disk space</td>\n<td>Implement fallback handlers and monitoring</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides comprehensive testing patterns for all three milestones, with unit testing supporting individual component validation in Milestone 1 (Logger Core), integration scenarios verifying cross-component behavior in Milestone 2 (Structured Output), and end-to-end testing ensuring complete system functionality in Milestone 3 (Context &amp; Correlation).</p>\n</blockquote>\n<p>Think of testing a structured logging system like conducting a symphony orchestra rehearsal. Just as a conductor must verify that individual musicians can play their parts correctly (unit testing), that sections can harmonize together (integration testing), and that the complete orchestra produces the intended musical experience (end-to-end testing), our logging system requires systematic validation at multiple levels. Each test layer reveals different types of issues: unit tests catch logic errors in individual components, integration tests expose interaction problems between subsystems, and milestone checkpoints verify that the complete system meets production requirements.</p>\n<p>The testing strategy for a production-grade logging system presents unique challenges compared to typical application testing. Logging systems must handle concurrent access from multiple threads, preserve context across asynchronous boundaries, and maintain performance under heavy load while gracefully degrading when output destinations fail. Traditional testing approaches often miss these concerns because they focus on single-threaded, synchronous execution paths. Our comprehensive testing strategy addresses these real-world complexities by systematically validating thread safety, async context preservation, error recovery, and performance characteristics.</p>\n<h3 id=\"unit-testing-approach\">Unit Testing Approach</h3>\n<p>Unit testing for structured logging components requires isolation of individual subsystems while simulating the complex interactions they will encounter in production. Unlike typical business logic testing, logging component tests must verify thread safety guarantees, memory management correctness, and graceful handling of malformed data. Each component operates within strict performance constraints since logging should never become the bottleneck in application execution.</p>\n<p>The <strong>formatter testing strategy</strong> focuses on serialization correctness under edge cases that commonly break JSON output in production systems. Formatters must handle circular references, non-serializable objects, extremely large data structures, and malformed Unicode strings without throwing exceptions that could crash the application. Test cases should include deeply nested objects that exceed the maximum serialization depth, objects containing datetime instances and custom classes, dictionaries with non-string keys, and data structures containing binary data or control characters.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Input Type</th>\n<th>Expected Behavior</th>\n<th>Failure Mode to Verify</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Circular References</td>\n<td>Object referencing itself</td>\n<td>Truncated serialization with warning</td>\n<td>Infinite recursion crash</td>\n</tr>\n<tr>\n<td>Non-Serializable Objects</td>\n<td>Custom class instances</td>\n<td>String representation fallback</td>\n<td>JSON serialization exception</td>\n</tr>\n<tr>\n<td>Maximum Depth Exceeded</td>\n<td>Nested dict 20 levels deep</td>\n<td>Truncation at MAX_DEPTH=10</td>\n<td>Stack overflow from recursion</td>\n</tr>\n<tr>\n<td>Large Data Structures</td>\n<td>Dict with 10,000 key-value pairs</td>\n<td>Size estimation and truncation</td>\n<td>Memory exhaustion or timeout</td>\n</tr>\n<tr>\n<td>Unicode Edge Cases</td>\n<td>Strings with control characters</td>\n<td>Escaped JSON output</td>\n<td>Malformed JSON structure</td>\n</tr>\n<tr>\n<td>Binary Data</td>\n<td>Byte arrays in context fields</td>\n<td>Base64 encoding or hex representation</td>\n<td>Encoding errors</td>\n</tr>\n</tbody></table>\n<p>The <code>JSONFormatter</code> testing requires verification that output always produces valid single-line JSON regardless of input complexity. Test the <code>safe_serialize</code> method with objects containing functions, lambda expressions, open file handles, and thread locks. Verify that the <code>estimate_serialized_size</code> function accurately predicts memory usage before full serialization to prevent memory exhaustion attacks. Test timestamp formatting with various precision levels and timezone configurations.</p>\n<p><strong>Handler testing strategy</strong> emphasizes failure isolation and recovery behavior since handlers represent external dependencies that will inevitably fail in production. Each handler type requires different failure simulation techniques. File handlers need tests for filesystem permission errors, disk space exhaustion, and network filesystem disconnections. Network handlers require simulation of connection timeouts, DNS resolution failures, and temporary service unavailability.</p>\n<table>\n<thead>\n<tr>\n<th>Handler Type</th>\n<th>Failure Scenarios</th>\n<th>Recovery Verification</th>\n<th>Buffer Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>FileHandler</td>\n<td>Permission denied, disk full</td>\n<td>Automatic retry with backoff</td>\n<td>Buffer records until disk space available</td>\n</tr>\n<tr>\n<td>NetworkHandler</td>\n<td>Connection timeout, DNS failure</td>\n<td>Circuit breaker activation</td>\n<td>Queue records for batch retry</td>\n</tr>\n<tr>\n<td>StdoutHandler</td>\n<td>Broken pipe, process termination</td>\n<td>Graceful degradation</td>\n<td>Immediate failure, no buffering</td>\n</tr>\n<tr>\n<td>RemoteHandler</td>\n<td>Service unavailable, auth failure</td>\n<td>Exponential backoff retry</td>\n<td>Persistent queue with size limits</td>\n</tr>\n</tbody></table>\n<p>The <code>CircuitBreaker</code> component requires time-based testing that verifies state transitions occur at the correct intervals. Mock the system clock to control timeout behavior and verify that the circuit breaker correctly transitions from HEALTHY to DEGRADED to FAILED states based on consecutive failure counts. Test the recovery mechanism by simulating successful operations after the timeout period expires.</p>\n<p><strong>Context management testing</strong> focuses on thread safety and memory leak prevention since context storage maintains state that could accumulate indefinitely. The <code>ContextStorage</code> component must handle concurrent access from multiple threads while preserving isolation between different execution contexts. Test scenarios should include rapid context creation and cleanup, nested context inheritance, and cleanup of orphaned contexts when threads terminate unexpectedly.</p>\n<table>\n<thead>\n<tr>\n<th>Test Scenario</th>\n<th>Thread Pattern</th>\n<th>Context Behavior</th>\n<th>Memory Verification</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Concurrent Context Creation</td>\n<td>50 threads creating contexts simultaneously</td>\n<td>No data corruption or lost updates</td>\n<td>All contexts properly isolated</td>\n</tr>\n<tr>\n<td>Nested Context Inheritance</td>\n<td>Parent context with 5 levels of children</td>\n<td>Child inherits all parent fields</td>\n<td>Changes in children don&#39;t affect parents</td>\n</tr>\n<tr>\n<td>Orphaned Context Cleanup</td>\n<td>Thread exits without calling clear()</td>\n<td>Automatic cleanup after timeout</td>\n<td>No memory leaks detected</td>\n</tr>\n<tr>\n<td>Context Size Limits</td>\n<td>Context with 1MB of data</td>\n<td>Truncation to prevent memory issues</td>\n<td>Graceful size limiting</td>\n</tr>\n</tbody></table>\n<p>The <code>ThreadSafeCounter</code> and <code>ThreadSafeDict</code> utility classes require stress testing under high concurrency to verify that lock contention doesn&#39;t create deadlocks or performance bottlenecks. Use property-based testing to generate random sequences of operations and verify that the final state matches expected results.</p>\n<p><strong>Logger hierarchy testing</strong> verifies that configuration inheritance and level filtering work correctly across complex parent-child relationships. Create logger hierarchies with multiple levels and verify that level changes propagate to children, context inheritance works correctly, and handler collection follows the expected traversal order.</p>\n<table>\n<thead>\n<tr>\n<th>Hierarchy Pattern</th>\n<th>Level Configuration</th>\n<th>Expected Behavior</th>\n<th>Edge Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Root → App → Module</td>\n<td>Root: INFO, App: DEBUG, Module: unset</td>\n<td>Module effective level = DEBUG</td>\n<td>Level inheritance through chain</td>\n</tr>\n<tr>\n<td>Root → Service1/Service2</td>\n<td>Root: WARN, Services: unset</td>\n<td>Both services inherit WARN</td>\n<td>Sibling isolation</td>\n</tr>\n<tr>\n<td>Deep Nesting (5 levels)</td>\n<td>Alternating DEBUG/INFO levels</td>\n<td>Correct effective level calculation</td>\n<td>Performance of level resolution</td>\n</tr>\n<tr>\n<td>Handler Propagation</td>\n<td>Handlers at root and middle levels</td>\n<td>Records reach all applicable handlers</td>\n<td>No duplicate output</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Incomplete Thread Safety Testing</strong>\nMany developers test thread safety by running multi-threaded code and checking for obvious crashes, but this misses subtle race conditions that only appear under specific timing conditions. Race conditions in logging systems can cause corrupted log output, lost log records, or deadlocks that freeze the entire application. Instead of just running concurrent code, use tools like Python&#39;s <code>threading.Barrier</code> to synchronize thread execution and force specific interleavings. Test with thread counts that exceed CPU core counts to verify behavior under thread starvation.</p>\n<h3 id=\"integration-testing-scenarios\">Integration Testing Scenarios</h3>\n<p>Integration testing for structured logging systems must verify that component interactions work correctly under realistic production conditions. Unlike unit tests that isolate individual components, integration tests exercise complete workflows that span multiple subsystems and expose emergent behaviors that only appear when components interact.</p>\n<p><strong>Multi-threaded logging integration</strong> represents one of the most critical test scenarios since logging systems must handle concurrent access from web server request handlers, background processing tasks, and periodic maintenance jobs simultaneously. The integration test creates a realistic multi-threaded environment that simulates actual application patterns rather than artificial concurrent access.</p>\n<p>The test scenario establishes multiple thread pools representing different application subsystems: web request handlers generating high-frequency INFO and DEBUG messages with request context, background task processors generating periodic WARN and ERROR messages with job context, and system monitoring threads generating FATAL messages during simulated failures. Each thread type uses different loggers in the hierarchy and attaches different context fields to verify that the system correctly isolates and routes messages.</p>\n<table>\n<thead>\n<tr>\n<th>Thread Type</th>\n<th>Message Frequency</th>\n<th>Log Levels</th>\n<th>Context Fields</th>\n<th>Handler Destinations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Web Requests</td>\n<td>100 messages/second</td>\n<td>DEBUG, INFO</td>\n<td>request_id, user_id, endpoint</td>\n<td>stdout, file, metrics</td>\n</tr>\n<tr>\n<td>Background Tasks</td>\n<td>10 messages/second</td>\n<td>INFO, WARN</td>\n<td>job_id, task_type, duration</td>\n<td>file, remote collector</td>\n</tr>\n<tr>\n<td>System Monitor</td>\n<td>1 message/second</td>\n<td>ERROR, FATAL</td>\n<td>component, health_status</td>\n<td>file, alerting system</td>\n</tr>\n<tr>\n<td>Maintenance Jobs</td>\n<td>0.1 messages/second</td>\n<td>DEBUG, INFO</td>\n<td>job_name, resource_usage</td>\n<td>file only</td>\n</tr>\n</tbody></table>\n<p>The integration test runs for a sustained period (60 seconds minimum) while monitoring for several failure modes. Output file corruption indicates insufficient locking around file writes. Missing log records suggest race conditions in handler dispatch. Incorrect context propagation shows thread-local storage issues. Memory leaks indicate improper cleanup of thread-specific context storage.</p>\n<p>Verification requires parsing output files to confirm that all expected log records were written correctly, context fields are properly isolated between threads, timestamps show realistic ordering within reasonable bounds, and no partial JSON records appear in the output. Memory monitoring should show stable memory usage without continuous growth that would indicate context leaks.</p>\n<p><strong>Async context preservation integration</strong> tests the most complex aspect of modern logging systems: maintaining request context across asynchronous task boundaries. Python&#39;s asyncio, JavaScript&#39;s Promise chains, and similar async frameworks create execution contexts that don&#39;t follow traditional thread-local storage patterns. The logging system must preserve context when tasks are created, paused, resumed, and completed.</p>\n<p>The integration test creates a realistic async web application scenario with nested async operations that simulate database queries, external API calls, and background processing. Each operation should inherit context from its parent and add its own contextual information without affecting sibling operations or the parent context.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Request Handler (correlation_id=123, user_id=456)\n├── Database Query (operation=user_lookup, table=users)\n├── External API Call (service=auth, endpoint=/validate)\n└── Background Task (task=audit_log, priority=low)\n    ├── Database Write (operation=insert, table=audit)\n    └── Cache Update (operation=invalidate, key=user:456)</code></pre></div>\n\n<p>Each async operation writes log messages at different points in its execution lifecycle: before starting the operation, during processing, and after completion. The test verifies that context propagation works correctly across await boundaries, context isolation prevents interference between concurrent tasks, nested operations inherit parent context correctly, and context cleanup occurs when tasks complete or fail.</p>\n<table>\n<thead>\n<tr>\n<th>Async Pattern</th>\n<th>Context Behavior</th>\n<th>Test Verification</th>\n<th>Common Failure</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sequential await</td>\n<td>Context preserved across each await</td>\n<td>All messages contain full context chain</td>\n<td>Context lost after first await</td>\n</tr>\n<tr>\n<td>Concurrent tasks</td>\n<td>Independent context for each task</td>\n<td>No context bleeding between tasks</td>\n<td>Shared mutable context state</td>\n</tr>\n<tr>\n<td>Nested async calls</td>\n<td>Child inherits parent + adds own fields</td>\n<td>Proper context hierarchy in logs</td>\n<td>Child modifications affect parent</td>\n</tr>\n<tr>\n<td>Exception handling</td>\n<td>Context preserved through exception unwinding</td>\n<td>Error logs contain full request context</td>\n<td>Context cleared on exception</td>\n</tr>\n</tbody></table>\n<p><strong>End-to-end request tracing integration</strong> demonstrates the complete correlation ID lifecycle from request ingress through all internal operations to final response. This test simulates a realistic microservice interaction where a user request triggers operations across multiple internal services, each adding their own contextual information while preserving the original correlation ID.</p>\n<p>The test creates a mock web application with request middleware that extracts or generates correlation IDs, establishes request-scoped context, and ensures cleanup when requests complete. Multiple request handlers simulate different application endpoints with varying complexity: simple operations that complete synchronously, complex operations that spawn multiple async tasks, and error scenarios that require proper context preservation during exception handling.</p>\n<table>\n<thead>\n<tr>\n<th>Request Type</th>\n<th>Operations Triggered</th>\n<th>Expected Context Fields</th>\n<th>Correlation Tracking</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>User Login</td>\n<td>Auth service, user lookup, session creation</td>\n<td>correlation_id, user_id, client_ip, user_agent</td>\n<td>Single ID through all operations</td>\n</tr>\n<tr>\n<td>Data Query</td>\n<td>Query parser, database, result formatter</td>\n<td>correlation_id, query_id, table, execution_time</td>\n<td>Nested operation IDs</td>\n</tr>\n<tr>\n<td>File Upload</td>\n<td>Validation, storage, thumbnail generation</td>\n<td>correlation_id, file_id, size, processing_status</td>\n<td>Background task correlation</td>\n</tr>\n<tr>\n<td>Error Scenario</td>\n<td>Failed validation, error logging, cleanup</td>\n<td>correlation_id, error_code, failed_operation</td>\n<td>Error context preservation</td>\n</tr>\n</tbody></table>\n<p>The integration test sends concurrent requests with different correlation ID patterns: requests with existing correlation IDs from upstream services, requests without correlation IDs that require generation, and requests with malformed correlation IDs that need sanitization. The test verifies that correlation IDs are properly preserved across all async operations, each request maintains independent context isolation, background tasks spawned by requests maintain correlation linkage, and error scenarios preserve context for debugging.</p>\n<p>Verification involves parsing log output to construct correlation traces showing the complete lifecycle of each request. Each correlation ID should appear in log records from request start to completion, with proper nesting of operation-specific context and no correlation ID pollution between concurrent requests.</p>\n<p>⚠️ <strong>Pitfall: Unrealistic Test Conditions</strong>\nMany integration tests use artificial scenarios that don&#39;t reflect production behavior, such as perfect network conditions, unlimited memory, and immediate I/O operations. Real production environments have variable latency, intermittent failures, and resource constraints that can expose bugs not visible in idealized test conditions. Include realistic failure injection in integration tests: introduce random network delays for remote handlers, simulate disk pressure that slows file I/O, and test under memory pressure that triggers garbage collection pauses.</p>\n<h3 id=\"milestone-checkpoints\">Milestone Checkpoints</h3>\n<p>Milestone checkpoints provide concrete verification criteria for each stage of system implementation, ensuring that learners build foundational capabilities correctly before advancing to more complex features. Each checkpoint includes specific behavioral requirements, observable outputs, and diagnostic techniques for identifying common implementation errors.</p>\n<p><strong>Milestone 1 Checkpoint: Logger Core</strong>\nThe Logger Core milestone establishes the foundational logging infrastructure with proper level filtering, thread safety, and handler dispatch. The checkpoint verification ensures that these core capabilities work correctly under both normal operations and stress conditions.</p>\n<p>The primary verification test creates multiple logger instances in a hierarchy and verifies that level filtering works correctly at each node. Create loggers for <code>root</code>, <code>app</code>, <code>app.database</code>, and <code>app.api</code> with different level configurations. Set the root logger to INFO, leave app unset (inheriting INFO), set app.database to DEBUG, and set app.api to WARN. Send messages at all log levels to each logger and verify that only appropriate messages appear in the output.</p>\n<table>\n<thead>\n<tr>\n<th>Logger Name</th>\n<th>Configured Level</th>\n<th>Effective Level</th>\n<th>DEBUG Visible</th>\n<th>INFO Visible</th>\n<th>WARN Visible</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>root</td>\n<td>INFO</td>\n<td>INFO</td>\n<td>No</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>app</td>\n<td>(unset)</td>\n<td>INFO (inherited)</td>\n<td>No</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>app.database</td>\n<td>DEBUG</td>\n<td>DEBUG</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td>app.api</td>\n<td>WARN</td>\n<td>WARN</td>\n<td>No</td>\n<td>No</td>\n<td>Yes</td>\n</tr>\n</tbody></table>\n<p>Thread safety verification requires running the logging system under concurrent load while monitoring for output corruption. Create 10 threads that simultaneously write 1000 log messages each to the same logger instance. Each thread should use a unique thread identifier in its log messages. After completion, parse the output file and verify that all 10,000 messages are present, no partial messages appear (indicating corruption during writes), messages from different threads don&#39;t have interleaved content within single records, and thread identifiers are correctly preserved in each message.</p>\n<p>Handler dispatch verification tests that log records reach multiple output destinations correctly and that handler failures don&#39;t prevent delivery to other handlers. Configure a logger with three handlers: stdout, file, and a mock network handler that can be programmatically failed. Write log messages while the mock handler is healthy, then trigger a failure in the mock handler and continue writing messages. Verify that messages continue to reach stdout and file handlers despite the network handler failure.</p>\n<p><strong>Expected Behavior After Milestone 1:</strong></p>\n<ul>\n<li>Logger creation: <code>get_logger(&quot;app.module&quot;)</code> creates hierarchy automatically</li>\n<li>Level filtering: Only messages at or above configured level appear in output</li>\n<li>Thread safety: No output corruption under concurrent access from multiple threads</li>\n<li>Handler dispatch: Messages reach all configured handlers, with graceful failure handling</li>\n<li>Runtime reconfiguration: Level changes take effect immediately without restart</li>\n</ul>\n<p><strong>Diagnostic Commands for Milestone 1:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic functionality</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import logging_system</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = logging_system.get_logger('test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.set_level(logging_system.INFO)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.debug('This should not appear')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('This should appear')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test thread safety</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_thread_safety.py</span><span style=\"color:#79B8FF\"> --threads=10</span><span style=\"color:#79B8FF\"> --messages=1000</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test handler dispatch</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_handlers.py</span><span style=\"color:#79B8FF\"> --with-failure-simulation</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Checkpoint: Structured Output</strong>\nThe Structured Output milestone adds JSON formatting, timestamp handling, and custom formatter support. The checkpoint verification focuses on output format correctness and formatter extensibility.</p>\n<p>JSON format verification requires testing serialization behavior with complex data structures that commonly cause problems in production. Create log records with context containing nested dictionaries, arrays, datetime objects, and custom class instances. Verify that the JSON output is valid single-line JSON (no embedded newlines), contains all expected fields in consistent order, handles non-serializable objects gracefully with string representations, and includes properly formatted timestamps.</p>\n<table>\n<thead>\n<tr>\n<th>Context Data Type</th>\n<th>Serialization Behavior</th>\n<th>Expected JSON Output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Nested Dict (3 levels)</td>\n<td>Full serialization</td>\n<td>Complete nested structure</td>\n</tr>\n<tr>\n<td>Datetime Object</td>\n<td>ISO 8601 conversion</td>\n<td>&quot;2024-01-15T10:30:45.123Z&quot;</td>\n</tr>\n<tr>\n<td>Custom Class Instance</td>\n<td>String representation</td>\n<td>&quot;MyClass(id=123, name=&#39;test&#39;)&quot;</td>\n</tr>\n<tr>\n<td>Circular Reference</td>\n<td>Truncation with warning</td>\n<td>&quot;[Circular Reference Detected]&quot;</td>\n</tr>\n<tr>\n<td>Large Array (1000 items)</td>\n<td>Size-based truncation</td>\n<td>First N items + &quot;[...truncated]&quot;</td>\n</tr>\n</tbody></table>\n<p>Timestamp format verification tests that timestamps are generated correctly for different precision requirements and timezone configurations. Configure the timestamp formatter for ISO 8601 format and verify that all log records contain valid timestamps that are properly ordered chronologically. Test timezone handling by configuring UTC output and verifying that timestamps are consistent regardless of local system timezone.</p>\n<p>Custom formatter verification tests the plugin system by registering a test formatter that produces CSV output instead of JSON. Create a custom formatter that outputs log records in comma-separated format with quoted fields. Register the formatter with the system and configure a logger to use it. Verify that log messages are formatted correctly in CSV format and that multiple formatters can coexist without interference.</p>\n<p><strong>Expected Behavior After Milestone 2:</strong></p>\n<ul>\n<li>JSON output: Valid single-line JSON for every log record</li>\n<li>Timestamp formatting: Consistent ISO 8601 timestamps with millisecond precision</li>\n<li>Custom formatters: Ability to register and use custom output formats</li>\n<li>Pretty printing: Human-readable colored output for development console</li>\n<li>Serialization safety: Graceful handling of non-serializable objects</li>\n</ul>\n<p><strong>Milestone 3 Checkpoint: Context &amp; Correlation</strong>\nThe Context &amp; Correlation milestone adds request tracing, correlation ID generation, and context propagation across async boundaries. The checkpoint verification ensures that context is properly maintained throughout complex execution flows.</p>\n<p>Correlation ID verification tests that unique identifiers are generated for each request and properly propagated through all operations. Create a mock request handler that generates a correlation ID and performs multiple nested operations: database query, external API call, and background task. Verify that all log records contain the same correlation ID, nested operations inherit the correlation ID correctly, concurrent requests have independent correlation IDs, and correlation IDs follow the expected format (service prefix + timestamp + random component).</p>\n<table>\n<thead>\n<tr>\n<th>Operation Type</th>\n<th>Correlation ID Presence</th>\n<th>Context Inheritance</th>\n<th>Isolation Verification</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Start</td>\n<td>New correlation ID generated</td>\n<td>Initial request context</td>\n<td>Independent from other requests</td>\n</tr>\n<tr>\n<td>Database Query</td>\n<td>Same correlation ID</td>\n<td>Request context + query metadata</td>\n<td>No interference between queries</td>\n</tr>\n<tr>\n<td>API Call</td>\n<td>Same correlation ID</td>\n<td>Request context + API metadata</td>\n<td>Async operation isolation</td>\n</tr>\n<tr>\n<td>Background Task</td>\n<td>Same correlation ID</td>\n<td>Request context + task metadata</td>\n<td>Proper async context bridge</td>\n</tr>\n</tbody></table>\n<p>Context propagation verification tests that context fields are properly inherited and isolated across different scopes. Create nested context scopes where each level adds additional fields while preserving parent context. Verify that child contexts inherit all parent fields, child context modifications don&#39;t affect parent contexts, context cleanup occurs when scopes exit, and memory usage remains stable during context creation/cleanup cycles.</p>\n<p>Async context preservation verification tests the most complex scenario: maintaining context across asyncio task boundaries. Create an async request handler that spawns multiple concurrent tasks, each performing operations that add context fields. Verify that each async task maintains its own context isolation, context is properly inherited when tasks are created, await boundaries preserve context correctly, and context cleanup occurs when async tasks complete.</p>\n<p><strong>Expected Behavior After Milestone 3:</strong></p>\n<ul>\n<li>Correlation ID generation: Unique IDs for each request with proper format</li>\n<li>Context propagation: Seamless context inheritance through nested function calls</li>\n<li>Async context preservation: Correct context maintenance across await boundaries</li>\n<li>Request middleware: Automatic context establishment for incoming requests</li>\n<li>Memory management: No context leaks during long-running operations</li>\n</ul>\n<p><strong>Integration Verification Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test complete request flow</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#9ECBFF\"> \"X-Correlation-ID: test-123\"</span><span style=\"color:#9ECBFF\"> http://localhost:8080/api/test</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify logs show correlation ID throughout request processing</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test async context preservation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_async_context.py</span><span style=\"color:#79B8FF\"> --concurrent-requests=50</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test context isolation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_context_isolation.py</span><span style=\"color:#79B8FF\"> --nested-levels=5</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Stress test complete system</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> stress_test.py</span><span style=\"color:#79B8FF\"> --duration=300</span><span style=\"color:#79B8FF\"> --rps=100</span></span></code></pre></div>\n\n<p>The milestone checkpoints provide a systematic progression that ensures each capability is solid before building additional complexity. This approach prevents the common problem of advanced features failing due to inadequate foundations, and provides clear diagnostic criteria when troubleshooting implementation issues.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>A. Technology Recommendations Table:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unit Testing Framework</td>\n<td><code>unittest</code> (Python standard library)</td>\n<td><code>pytest</code> with fixtures and parameterization</td>\n</tr>\n<tr>\n<td>Thread Safety Testing</td>\n<td><code>threading.Thread</code> with manual synchronization</td>\n<td><code>concurrent.futures</code> with ThreadPoolExecutor</td>\n</tr>\n<tr>\n<td>Async Testing</td>\n<td><code>asyncio.run()</code> with manual event loop</td>\n<td><code>pytest-asyncio</code> with async test fixtures</td>\n</tr>\n<tr>\n<td>Mock Objects</td>\n<td><code>unittest.mock</code> for handler simulation</td>\n<td><code>responses</code> library for HTTP handler mocking</td>\n</tr>\n<tr>\n<td>Performance Testing</td>\n<td>Manual timing with <code>time.time()</code></td>\n<td><code>cProfile</code> and <code>memory_profiler</code> for detailed analysis</td>\n</tr>\n<tr>\n<td>Output Validation</td>\n<td>String parsing with <code>json.loads()</code></td>\n<td>JSON Schema validation with <code>jsonschema</code></td>\n</tr>\n<tr>\n<td>Concurrency Testing</td>\n<td>Manual thread creation</td>\n<td>Property-based testing with <code>hypothesis</code></td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File/Module Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured-logging/\n  src/logging_system/           ← main package\n    __init__.py\n    logger.py                   ← Logger, LoggerRegistry\n    handlers.py                 ← Handler implementations\n    formatters.py              ← JSON/Pretty formatters\n    context.py                 ← Context management\n  tests/                       ← test suite\n    unit/                      ← component isolation tests\n      test_logger.py           ← Logger hierarchy tests\n      test_handlers.py         ← Handler failure/recovery tests\n      test_formatters.py       ← Serialization edge cases\n      test_context.py          ← Context isolation tests\n    integration/               ← cross-component tests\n      test_threading.py        ← Multi-threaded scenarios\n      test_async.py           ← Async context preservation\n      test_end_to_end.py      ← Complete request tracing\n    checkpoints/              ← milestone verification\n      test_milestone1.py       ← Logger core verification\n      test_milestone2.py       ← Structured output verification  \n      test_milestone3.py       ← Context correlation verification\n    fixtures/                ← shared test utilities\n      mock_handlers.py         ← Controllable handler mocks\n      context_helpers.py       ← Context setup utilities\n      data_generators.py       ← Test data creation</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/fixtures/mock_handlers.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Mock handlers for controlled failure testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> logging_system.handlers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseHandler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> logging_system.data_model </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ControllableHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">BaseHandler</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handler with programmable failure behavior for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(name)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.records: List[LogRecord] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.should_fail </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.failure_delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.call_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_record</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.call_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.should_fail:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.failure_delay </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    time.sleep(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.failure_delay)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                raise</span><span style=\"color:#79B8FF\"> IOError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Simulated failure in </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.records.append(record)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> simulate_failure</span><span style=\"color:#E1E4E8\">(self, should_fail: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, delay: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Control handler failure behavior for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.should_fail </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> should_fail</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.failure_delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> delay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_records</span><span style=\"color:#E1E4E8\">(self) -> List[LogRecord]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Thread-safe access to captured records.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.records.copy()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear_records</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Reset captured records for next test.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.records.clear()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.call_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># tests/fixtures/data_generators.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Test data generators for edge case testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, Dict, List</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircularReferenceObject</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Object that references itself for serialization testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.self_ref </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.nested </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'circular'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> NonSerializableObject</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Custom object that cannot be JSON serialized.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, value: Any):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.function </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> lambda</span><span style=\"color:#E1E4E8\"> x: x </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __repr__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"NonSerializableObject(</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.value</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">)\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> generate_complex_context</span><span style=\"color:#E1E4E8\">() -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate context with various data types for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'string_field'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'test_value'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'numeric_field'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">42</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'datetime_field'</span><span style=\"color:#E1E4E8\">: datetime.datetime.now(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'nested_dict'</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'level1'</span><span style=\"color:#E1E4E8\">: {</span><span style=\"color:#9ECBFF\">'level2'</span><span style=\"color:#E1E4E8\">: {</span><span style=\"color:#9ECBFF\">'level3'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'deep_value'</span><span style=\"color:#E1E4E8\">}},</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'array'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'mixed'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        },</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'circular_ref'</span><span style=\"color:#E1E4E8\">: CircularReferenceObject(</span><span style=\"color:#9ECBFF\">'test'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'non_serializable'</span><span style=\"color:#E1E4E8\">: NonSerializableObject(</span><span style=\"color:#79B8FF\">123</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'large_array'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'unicode_data'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'Special chars: 🚀 💡 ∑ ∆'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> generate_correlation_id</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate test correlation ID with realistic format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"test-</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">uuid.uuid4().hex[:</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">-</span><span style=\"color:#79B8FF\">{int</span><span style=\"color:#E1E4E8\">(time.time())</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/unit/test_logger.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Unit tests for Logger hierarchy and level filtering.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> unittest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> logging_system </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_logger, LogLevel</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> tests.fixtures.mock_handlers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ControllableHandler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestLoggerCore</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">unittest</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">TestCase</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test Logger hierarchy, level filtering, and thread safety.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_level_filtering</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify that only messages at or above configured level are processed.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create logger with INFO level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attach mock handler to capture output</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Send DEBUG message - verify not processed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Send INFO message - verify processed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Send ERROR message - verify processed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Change level to DEBUG - verify DEBUG now processed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_logger_hierarchy_inheritance</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test that child loggers inherit configuration from parents.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create root logger with WARN level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create child logger 'app.database' - verify inherits WARN</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Set child to DEBUG - verify uses DEBUG, not inherited WARN</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Clear child level - verify inherits WARN again</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Test deep hierarchy: root.app.module.component</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_thread_safety_concurrent_logging</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify no output corruption under concurrent access.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'thread_test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ControllableHandler(</span><span style=\"color:#9ECBFF\">'test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.add_handler(handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> worker_thread</span><span style=\"color:#E1E4E8\">(thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, message_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Log message_count messages from this thread</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Include thread_id in each message for verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use different log levels randomly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add context fields unique to this thread</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Start 10 worker threads with 100 messages each</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Wait for all threads to complete</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Verify all 1000 messages captured correctly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Verify no message corruption (partial records)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Verify thread isolation (no mixed content)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># tests/integration/test_async_context.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Integration tests for async context preservation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> unittest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> logging_system </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> get_logger, LoggingContext</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> tests.fixtures.mock_handlers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ControllableHandler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestAsyncContextPreservation</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">unittest</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#B392F0\">TestCase</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test context preservation across async boundaries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> test_async_context_inheritance</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify context preserved across await boundaries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> get_logger(</span><span style=\"color:#9ECBFF\">'async_test'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ControllableHandler(</span><span style=\"color:#9ECBFF\">'async'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.add_handler(handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> database_operation</span><span style=\"color:#E1E4E8\">(user_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add database-specific context fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Log start of database operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Simulate async database call with asyncio.sleep()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Log completion with query results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return operation results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> api_request_handler</span><span style=\"color:#E1E4E8\">(request_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, user_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Set initial request context (correlation_id, user_id)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Log request start</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Call database_operation - verify context preserved</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Log request completion with timing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Run multiple concurrent requests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 11: Verify each request has independent context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 12: Verify nested operations inherit parent context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 13: Verify no context bleeding between requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_concurrent_async_requests</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test context isolation under concurrent async load.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create async request handlers with different correlation IDs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Run 50 concurrent requests with unique context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Each request spawns multiple async subtasks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify correlation IDs properly isolated</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify no context pollution between requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<ul>\n<li><strong>Thread Safety</strong>: Use <code>threading.RLock</code> for components that need recursive locking (loggers calling other loggers). Use <code>threading.Lock</code> for simple mutual exclusion in counters and caches.</li>\n<li><strong>Async Context</strong>: Use <code>contextvars.ContextVar</code> for async-local storage that preserves across await boundaries. Combine with <code>threading.local</code> for thread-local fallback.</li>\n<li><strong>JSON Serialization</strong>: Override <code>json.JSONEncoder.default()</code> method to handle non-serializable objects. Use <code>json.dumps(separators=(&#39;,&#39;, &#39;:&#39;))</code> for compact single-line output.</li>\n<li><strong>File I/O Testing</strong>: Use <code>tempfile.NamedTemporaryFile()</code> for isolated file handler testing. Call <code>file.flush()</code> and <code>os.fsync()</code> to ensure data written before verification.</li>\n<li><strong>Memory Testing</strong>: Use <code>tracemalloc.start()</code> to monitor memory usage during context lifecycle tests. Check for linear growth that indicates memory leaks.</li>\n<li><strong>Time Mocking</strong>: Use <code>unittest.mock.patch(&#39;time.time&#39;)</code> to control timestamp generation for deterministic testing.</li>\n</ul>\n<p><strong>F. Milestone Checkpoints:</strong></p>\n<p><strong>Checkpoint 1 - Logger Core Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run core logger tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/unit/test_logger.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output shows:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - test_level_filtering PASSED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - test_logger_hierarchy_inheritance PASSED  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - test_thread_safety_concurrent_logging PASSED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - No output corruption warnings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - All 1000 test messages captured correctly</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import logging_system</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger = logging_system.get_logger('manual_test')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.set_level(logging_system.INFO)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.debug('Should not see this')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">logger.info('Should see this')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Output should show only INFO message</span></span></code></pre></div>\n\n<p><strong>Checkpoint 2 - Structured Output Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test JSON formatting</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/unit/test_formatters.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify JSON output format:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_json_output.py</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should produce valid single-line JSON like:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># {\"timestamp\":\"2024-01-15T10:30:45.123Z\",\"level\":20,\"message\":\"test\",\"logger_name\":\"test\",\"context\":{\"key\":\"value\"}}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test custom formatter registration:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_custom_formatter.py</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should show CSV output: 2024-01-15T10:30:45.123Z,INFO,test,test,\"key=value\"</span></span></code></pre></div>\n\n<p><strong>Checkpoint 3 - Context &amp; Correlation Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test complete context flow</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/integration/test_end_to_end.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test request tracing:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> simulate_request.py</span><span style=\"color:#79B8FF\"> --correlation-id=test-123</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># All log output should contain: \"correlation_id\":\"test-123\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test async context preservation:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> test_async_flow.py</span><span style=\"color:#79B8FF\"> --concurrent-requests=10</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Each request should maintain independent context throughout async operations</span></span></code></pre></div>\n\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Thread safety test fails randomly</td>\n<td>Race condition in handler dispatch</td>\n<td>Add debug logging around lock acquisition</td>\n<td>Use RLock instead of Lock for recursive calls</td>\n</tr>\n<tr>\n<td>Context not preserved across await</td>\n<td>Missing contextvars setup</td>\n<td>Check if ContextVar is properly copied</td>\n<td>Use contextvars.copy_context() for task creation</td>\n</tr>\n<tr>\n<td>JSON output contains newlines</td>\n<td>Embedded newlines in log messages</td>\n<td>Search for \\n characters in test output</td>\n<td>Strip newlines from message content before formatting</td>\n</tr>\n<tr>\n<td>Memory usage grows during tests</td>\n<td>Context cleanup not called</td>\n<td>Monitor context storage size during test</td>\n<td>Add explicit cleanup in test teardown</td>\n</tr>\n<tr>\n<td>Async tests hang indefinitely</td>\n<td>Deadlock in async context manager</td>\n<td>Check for blocking operations in async code</td>\n<td>Replace time.sleep() with asyncio.sleep()</td>\n</tr>\n<tr>\n<td>Handler dispatch fails silently</td>\n<td>Exception swallowed in handler</td>\n<td>Add try/catch logging around handler calls</td>\n<td>Check handler circuit breaker state</td>\n</tr>\n<tr>\n<td>Correlation IDs not unique</td>\n<td>Timestamp resolution too low</td>\n<td>Print generated IDs to check for duplicates</td>\n<td>Add random component to ID generation</td>\n</tr>\n<tr>\n<td>Context bleeds between threads</td>\n<td>Shared mutable context objects</td>\n<td>Verify each thread gets independent context</td>\n<td>Use copy.deepcopy() when inheriting context</td>\n</tr>\n</tbody></table>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides essential debugging patterns for all three milestones, with race condition debugging supporting Milestone 1 (Logger Core), serialization issue diagnosis supporting Milestone 2 (Structured Output), and context propagation debugging supporting Milestone 3 (Context &amp; Correlation).</p>\n</blockquote>\n<p>Think of debugging a structured logging system like troubleshooting a complex telephone switchboard. When calls don&#39;t connect properly, the problem could be in the routing logic (level filtering), the switching mechanism (handler dispatch), the line quality (serialization), or the directory service (context propagation). Each type of failure has distinct symptoms, and skilled operators develop systematic approaches to isolate and resolve issues quickly.</p>\n<p>The complexity of a production logging system creates multiple failure modes that can interact in subtle ways. A race condition in the logger hierarchy might only manifest under high concurrency, while context propagation issues may only appear in specific async execution patterns. Memory leaks can accumulate slowly until they cause cascading failures across the entire application. This debugging guide provides systematic approaches to identify, isolate, and resolve the most common issues learners encounter when implementing structured logging systems.</p>\n<h3 id=\"common-implementation-pitfalls\">Common Implementation Pitfalls</h3>\n<p>The most frequent implementation mistakes in structured logging systems fall into four categories: concurrency issues that corrupt shared state, context management problems that lose request correlation, blocking operations that degrade performance, and resource management failures that cause memory leaks. Each category requires different debugging approaches and prevention strategies.</p>\n<h4 id=\"race-conditions-in-logger-hierarchy\">Race Conditions in Logger Hierarchy</h4>\n<p>Race conditions in logger hierarchy management represent one of the most subtle and dangerous pitfalls in structured logging implementation. The logger hierarchy is a shared data structure accessed concurrently by multiple threads, and improper synchronization can lead to corrupted state, lost configuration changes, or inconsistent behavior that only manifests under high load.</p>\n<p>⚠️ <strong>Pitfall: Unsynchronized Logger Registry Access</strong></p>\n<p>The most common race condition occurs when multiple threads simultaneously access the <code>LoggerRegistry._loggers</code> dictionary without proper locking. Consider a scenario where Thread A calls <code>get_logger(&quot;com.example.service&quot;)</code> while Thread B calls <code>get_logger(&quot;com.example.service.auth&quot;)</code>. Both threads may attempt to create parent loggers simultaneously, leading to duplicate entries, lost references, or partially initialized logger objects.</p>\n<p>The symptom appears as intermittent failures where loggers seem to lose their configuration, handlers disappear randomly, or context fields vanish from log records. These issues are particularly insidious because they may not appear during development with single-threaded access patterns but emerge under production load.</p>\n<p>The underlying problem is that dictionary operations in most languages are not atomic across multiple operations. Creating a logger hierarchy involves: checking if parent loggers exist, creating missing parents, establishing parent-child relationships, and updating the registry. Without proper synchronization, these operations can interleave in ways that corrupt the data structure.</p>\n<table>\n<thead>\n<tr>\n<th>Race Condition Scenario</th>\n<th>Thread A Action</th>\n<th>Thread B Action</th>\n<th>Corruption Result</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Simultaneous parent creation</td>\n<td>Creates <code>com.example</code> logger</td>\n<td>Creates <code>com.example</code> logger</td>\n<td>Duplicate parent with different configurations</td>\n</tr>\n<tr>\n<td>Hierarchy modification</td>\n<td>Sets <code>com.example.service</code> level</td>\n<td>Adds handler to <code>com.example.service</code></td>\n<td>Handler added to wrong logger instance</td>\n</tr>\n<tr>\n<td>Context inheritance</td>\n<td>Modifies parent context</td>\n<td>Reads child effective context</td>\n<td>Child sees inconsistent parent context</td>\n</tr>\n<tr>\n<td>Level propagation</td>\n<td>Changes parent level</td>\n<td>Calculates child effective level</td>\n<td>Child uses stale level cache</td>\n</tr>\n</tbody></table>\n<p>The correct solution requires using a <code>RLock</code> (reader-writer lock) in the <code>LoggerRegistry</code> to protect all registry operations. Read operations like logger lookup can share the lock, while write operations like logger creation require exclusive access. Additionally, each individual <code>Logger</code> needs its own lock to protect configuration changes and context modifications.</p>\n<p>⚠️ <strong>Pitfall: Level Cache Invalidation Race</strong></p>\n<p>Another subtle race condition occurs in the effective level calculation system. The <code>Logger._effective_level</code> cache improves performance by avoiding repeated hierarchy traversal, but invalidating this cache safely across multiple threads requires careful coordination.</p>\n<p>When a parent logger&#39;s level changes, all descendant loggers must invalidate their cached effective levels. If this invalidation is not synchronized properly, a logger might use a stale cached level while its parent&#39;s configuration has changed, leading to incorrect level filtering behavior.</p>\n<p>The symptom appears as messages that should be filtered continuing to appear, or messages that should be logged being incorrectly suppressed. The issue is timing-dependent and may only occur during configuration changes under load.</p>\n<p>⚠️ <strong>Pitfall: Handler List Modification During Iteration</strong></p>\n<p>A particularly dangerous race condition occurs when one thread modifies a logger&#39;s handler list while another thread iterates over that list for message dispatch. This can cause handler dispatch to skip handlers, duplicate messages, or access deallocated handler objects leading to crashes.</p>\n<p>The iteration happens in the <code>log()</code> method when collecting handlers from the logger hierarchy, while modification occurs when configuration changes add or remove handlers. Without proper synchronization, the iterator can become invalid mid-traversal.</p>\n<h4 id=\"context-propagation-failures\">Context Propagation Failures</h4>\n<p>Context propagation failures are among the most frustrating debugging challenges because they break the fundamental promise of structured logging: that related log entries can be correlated across service boundaries. When context propagation fails, correlation IDs disappear, request metadata is lost, and distributed tracing becomes impossible.</p>\n<p>⚠️ <strong>Pitfall: Thread-Local Context Not Propagating to New Threads</strong></p>\n<p>The most common context propagation failure occurs when application code creates new threads without explicitly propagating the logging context. Thread-local storage isolates context between threads by design, so newly created threads start with empty context even if the parent thread has rich contextual information.</p>\n<p>This manifests as correlation IDs and request metadata suddenly disappearing from log entries generated by background tasks, worker threads, or async operations. The symptoms are subtle because the logging system continues to function correctly—it simply loses the contextual information that makes logs useful for debugging distributed systems.</p>\n<p>Consider a web request handler that spawns a background task to process uploaded data. The main request thread has correlation ID <code>req-12345</code> and user context <code>user_id: alice</code>, but the background thread starts with empty context. All log entries from the background processing lose this critical correlation information.</p>\n<table>\n<thead>\n<tr>\n<th>Context Propagation Scenario</th>\n<th>Parent Thread Context</th>\n<th>Child Thread Context</th>\n<th>Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Background task creation</td>\n<td><code>{&quot;correlation_id&quot;: &quot;req-12345&quot;, &quot;user_id&quot;: &quot;alice&quot;}</code></td>\n<td><code>{}</code> (empty)</td>\n<td>Background processing logs cannot be correlated to original request</td>\n</tr>\n<tr>\n<td>Thread pool execution</td>\n<td><code>{&quot;request_id&quot;: &quot;order-456&quot;, &quot;operation&quot;: &quot;checkout&quot;}</code></td>\n<td>Previous task&#39;s context</td>\n<td>Worker thread sees stale context from previous task</td>\n</tr>\n<tr>\n<td>Async task spawning</td>\n<td><code>{&quot;trace_id&quot;: &quot;abc123&quot;, &quot;span_id&quot;: &quot;def456&quot;}</code></td>\n<td><code>{}</code> (empty)</td>\n<td>Distributed tracing chain broken</td>\n</tr>\n</tbody></table>\n<p>The solution requires explicitly capturing context from the parent thread and setting it in the child thread before any logging occurs. This can be automated through context-aware thread creation utilities or manual context transfer at task boundaries.</p>\n<p>⚠️ <strong>Pitfall: Async Context Not Preserved Across Await Boundaries</strong></p>\n<p>In async programming environments, context can be lost across <code>await</code> boundaries when the execution context switches between different async tasks or coroutines. This is particularly problematic in languages with cooperative multitasking where multiple async tasks share the same thread.</p>\n<p>The symptom appears as correlation IDs and context fields randomly changing or disappearing in the middle of async function execution. A function might start with correlation ID <code>req-789</code> but after awaiting a database operation, find itself with a different correlation ID from another concurrent request.</p>\n<p>This occurs because async runtimes may resume awaited tasks on different logical execution contexts, and the logging context storage mechanism fails to properly bridge these context switches. The issue is intermittent and load-dependent, making it particularly difficult to diagnose.</p>\n<p>⚠️ <strong>Pitfall: Context Memory Leaks in Long-Running Services</strong></p>\n<p>Context storage systems that don&#39;t properly clean up unused contexts can accumulate memory over time, eventually causing out-of-memory errors in long-running services. This typically occurs when context storage uses strong references to context objects that should be garbage collected after request completion.</p>\n<p>The symptom starts as gradually increasing memory usage that doesn&#39;t correspond to application load. Over days or weeks, memory consumption grows until the service becomes unstable. Memory profiling reveals large numbers of abandoned context objects still referenced by the logging system.</p>\n<h4 id=\"blocking-io-in-log-handler-hot-path\">Blocking I/O in Log Handler Hot Path</h4>\n<p>Blocking I/O operations in the logging hot path represent a critical performance and reliability pitfall that can bring entire applications to a standstill. When log handlers perform synchronous file writes or network operations directly in the application&#39;s main execution thread, they introduce latency spikes and potential deadlocks that cascade through the entire system.</p>\n<p>⚠️ <strong>Pitfall: Synchronous File Writes Without Buffering</strong></p>\n<p>The most common blocking I/O mistake is implementing file handlers that perform synchronous writes for every log record. When application code calls <code>logger.info(&quot;Processing user request&quot;)</code>, the thread blocks until the file write completes, including potential disk seeks, buffer flushes, and filesystem metadata updates.</p>\n<p>Under normal conditions, this might add only microseconds of latency per log statement. However, during disk contention, filesystem cache pressure, or storage system degradation, each log write can block for milliseconds or seconds. In high-throughput applications generating thousands of log entries per second, this blocking behavior creates a performance cliff where logging overhead overwhelms application processing.</p>\n<p>The symptom appears as application response times that correlate with logging volume rather than business logic complexity. Performance profiling reveals significant time spent in file system calls within logging code paths. Applications may appear to &quot;freeze&quot; during bursts of log activity.</p>\n<table>\n<thead>\n<tr>\n<th>Blocking I/O Scenario</th>\n<th>Normal Latency</th>\n<th>Degraded Latency</th>\n<th>Application Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Single log statement per request</td>\n<td>50μs</td>\n<td>10ms</td>\n<td>200x slowdown in request processing</td>\n</tr>\n<tr>\n<td>Burst logging during error conditions</td>\n<td>1ms total</td>\n<td>500ms total</td>\n<td>Request timeouts and cascading failures</td>\n</tr>\n<tr>\n<td>High-frequency debug logging</td>\n<td>10ms/second overhead</td>\n<td>5s/second overhead</td>\n<td>Complete application stall</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Network Handler Timeouts Without Circuit Breakers</strong></p>\n<p>Network-based log handlers that send records to remote aggregation systems introduce even more severe blocking risks. Network operations can timeout, experience packet loss, or encounter service unavailability. Without proper timeout configuration and circuit breaker patterns, application threads can block indefinitely waiting for network log delivery.</p>\n<p>This pitfall is particularly dangerous because it couples application availability to logging infrastructure availability. If the remote log aggregation service becomes slow or unavailable, the entire application performance degrades proportionally. In the worst case, all application threads become blocked waiting for log delivery, creating a complete service outage caused by logging infrastructure failure.</p>\n<p>⚠️ <strong>Pitfall: Lock Contention in Shared File Handles</strong></p>\n<p>Even when file I/O is buffered and optimized, shared file handles can create lock contention bottlenecks. If multiple threads write to the same log file through a single <code>FileHandler</code> instance, the handler must serialize writes to maintain log record integrity. Under high concurrency, threads queue up waiting for file write access, creating a serialization bottleneck.</p>\n<h4 id=\"memory-leaks-in-context-management\">Memory Leaks in Context Management</h4>\n<p>Memory leaks in context management systems create insidious performance degradation that compounds over time. Unlike immediate failures that are quickly detected and resolved, memory leaks accumulate slowly and may not manifest symptoms until applications have been running for days or weeks under production load.</p>\n<p>⚠️ <strong>Pitfall: Context References in Thread-Local Storage</strong></p>\n<p>The most common memory leak occurs when thread-local context storage maintains strong references to context objects beyond their useful lifetime. In long-running applications with thread pools, worker threads may be reused across many requests without properly clearing their thread-local context state.</p>\n<p>Each request adds context fields like correlation IDs, user information, and request metadata to the thread-local storage. If this context is not explicitly cleared at request completion, the thread retains references to all context objects from every request it has ever processed. In a busy web server, a single worker thread might accumulate context from thousands of requests over its lifetime.</p>\n<p>The symptom appears as steadily increasing memory usage in long-running services, with memory profiling revealing large numbers of abandoned context objects still reachable through thread-local storage. The leak rate correlates with request volume, and memory usage never decreases even during idle periods.</p>\n<p>⚠️ <strong>Pitfall: Circular References in Context Inheritance</strong></p>\n<p>Context inheritance systems that allow arbitrary object nesting can inadvertently create circular references that prevent garbage collection. This typically occurs when context objects contain references to application objects that themselves hold logging context references.</p>\n<p>For example, a request context might contain a reference to the current user object for logging purposes. If that user object maintains a reference back to the request context (perhaps through an embedded logger), a circular reference prevents both objects from being garbage collected even after the request completes.</p>\n<p>⚠️ <strong>Pitfall: Unbounded Context Field Accumulation</strong></p>\n<p>Context systems that allow unlimited field accumulation without size limits can experience memory leaks when application code repeatedly adds context fields without bounds checking. This often occurs in long-running background tasks that add diagnostic information to context throughout their execution lifecycle.</p>\n<p>A data processing job might add context fields for each processed record: <code>processing_record_1</code>, <code>processing_record_2</code>, etc. Over hours of execution, the context object grows to contain thousands of fields, consuming significant memory and degrading context access performance.</p>\n<h3 id=\"debugging-techniques\">Debugging Techniques</h3>\n<p>Effective debugging of structured logging systems requires systematic approaches that can isolate issues across the multiple layers of abstraction involved in log processing. Unlike simple debugging scenarios with clear cause-and-effect relationships, logging system bugs often involve subtle interactions between concurrent operations, context propagation mechanisms, and external I/O systems.</p>\n<h4 id=\"adding-trace-logging-for-internal-operations\">Adding Trace Logging for Internal Operations</h4>\n<p>Trace logging provides visibility into the internal operation of the logging system itself, creating a meta-logging capability that reveals how log records flow through the system architecture. This technique is particularly valuable for diagnosing issues in handler dispatch, level filtering, and context propagation where the symptoms are indirect effects of internal system state.</p>\n<p>The key insight behind trace logging is creating a separate, simpler logging channel that operates independently of the main logging system being debugged. This trace system should be minimal and robust, avoiding the complex features that might themselves be the source of bugs in the main system.</p>\n<p><strong>Internal Logger State Tracing</strong></p>\n<p>Implementing trace logging for logger state changes reveals how the logger hierarchy evolves during application execution. This is particularly valuable for diagnosing race conditions in logger creation and configuration that only manifest under specific timing conditions.</p>\n<p>The trace system should log every significant state change with enough detail to reconstruct the sequence of operations that led to the current state. Key events to trace include logger creation, parent-child relationship establishment, level changes, handler additions and removals, and context modifications.</p>\n<table>\n<thead>\n<tr>\n<th>Trace Event Type</th>\n<th>Information Logged</th>\n<th>Debugging Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logger creation</td>\n<td>Logger name, parent name, thread ID, timestamp</td>\n<td>Reveals duplicate logger creation and hierarchy building order</td>\n</tr>\n<tr>\n<td>Level changes</td>\n<td>Logger name, old level, new level, effective level recalculation</td>\n<td>Shows level inheritance and cache invalidation behavior</td>\n</tr>\n<tr>\n<td>Handler operations</td>\n<td>Handler add/remove, logger name, handler type, thread ID</td>\n<td>Reveals handler configuration race conditions</td>\n</tr>\n<tr>\n<td>Context modifications</td>\n<td>Context field changes, inheritance relationships, thread boundaries</td>\n<td>Shows context propagation and cleanup behavior</td>\n</tr>\n</tbody></table>\n<p>The trace output should include thread identifiers and high-precision timestamps to reveal concurrency issues. For example, trace logs might show two threads simultaneously creating the same parent logger, or level changes that don&#39;t properly invalidate descendant logger caches.</p>\n<p><strong>Handler Dispatch Flow Tracing</strong></p>\n<p>Handler dispatch tracing reveals how log records flow through the handler selection and output generation process. This is essential for debugging issues where log records are lost, duplicated, or sent to incorrect destinations.</p>\n<p>The trace system should log each step of the dispatch process: level filtering decisions, handler collection from the logger hierarchy, formatter invocation, and final output destination. When handlers fail, the trace logs show exactly which handlers were attempted and what errors occurred.</p>\n<p><strong>Context Propagation Tracing</strong></p>\n<p>Context propagation is one of the most difficult aspects of logging systems to debug because problems often manifest far from their root cause. A context field might be lost during async task creation but not discovered until much later when correlation fails during error investigation.</p>\n<p>Effective context tracing logs every context operation: context creation, field additions, inheritance operations, thread boundary crossings, and cleanup operations. The trace includes context snapshots before and after each operation, making it possible to identify exactly where context corruption or loss occurs.</p>\n<h4 id=\"inspecting-context-state\">Inspecting Context State</h4>\n<p>Context state inspection provides real-time visibility into the current state of logging context across all active execution contexts. This technique is essential for debugging context propagation issues where the symptoms (missing correlation information) are distant from the cause (failed context inheritance).</p>\n<p><strong>Context Storage Dump Utilities</strong></p>\n<p>Building utilities to dump the current state of all context storage mechanisms reveals inconsistencies between thread-local and async-local context storage. These utilities should be callable from debugger sessions or triggered by special debug endpoints in web applications.</p>\n<p>The dump output should show the complete context hierarchy for each active execution context, including inheritance relationships, field values, and storage mechanism details. Comparing context state across different storage mechanisms can reveal synchronization issues or failed context propagation.</p>\n<table>\n<thead>\n<tr>\n<th>Context Storage View</th>\n<th>Information Displayed</th>\n<th>Debugging Application</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Thread-local contexts</td>\n<td>Thread ID, context fields, inheritance chain</td>\n<td>Reveals thread context isolation and cleanup issues</td>\n</tr>\n<tr>\n<td>Async-local contexts</td>\n<td>Task ID, context fields, parent task relationships</td>\n<td>Shows async context propagation and coroutine switching</td>\n</tr>\n<tr>\n<td>Global context registry</td>\n<td>All active contexts, reference counts, cleanup status</td>\n<td>Identifies memory leaks and orphaned contexts</td>\n</tr>\n<tr>\n<td>Context inheritance tree</td>\n<td>Parent-child relationships, field inheritance, override behavior</td>\n<td>Reveals context inheritance logic errors</td>\n</tr>\n</tbody></table>\n<p><strong>Context Field History Tracking</strong></p>\n<p>Implementing context field history tracking maintains a record of how each context field was added, modified, or removed throughout request processing. This technique is particularly valuable for debugging cases where context fields have unexpected values or disappear mysteriously during processing.</p>\n<p>The history tracker records not just field values but the stack trace or operation context where each change occurred. When debugging correlation failures, the history reveals exactly where correlation IDs were lost or overwritten with incorrect values.</p>\n<p><strong>Context Boundary Verification</strong></p>\n<p>Context boundary verification systematically checks that context propagation works correctly across all types of execution boundaries in the application. This includes thread creation, async task spawning, callback invocation, and external service calls.</p>\n<p>The verification system can be implemented as assertions that automatically check context consistency at known boundary points, or as explicit verification calls inserted during debugging sessions. When context propagation fails, these checks identify the specific boundary where propagation broke down.</p>\n<h4 id=\"testing-thread-safety\">Testing Thread Safety</h4>\n<p>Thread safety testing for logging systems requires techniques that can reliably reproduce concurrency issues that may only manifest under specific timing conditions. Unlike functional testing where deterministic inputs produce predictable outputs, concurrency testing must deal with the inherent non-determinism of multi-threaded execution.</p>\n<p><strong>Concurrent Logger Operation Testing</strong></p>\n<p>Effective thread safety testing subjects the logger hierarchy to intensive concurrent operations that stress-test all synchronization mechanisms. This includes simultaneous logger creation, configuration changes, level modifications, and message logging across multiple threads.</p>\n<p>The test framework should use barriers and coordination mechanisms to maximize the probability of race conditions occurring. Rather than simply launching multiple threads and hoping for conflicts, the tests should synchronize thread execution to create maximum contention at critical sections.</p>\n<table>\n<thead>\n<tr>\n<th>Concurrency Test Scenario</th>\n<th>Thread A Operations</th>\n<th>Thread B Operations</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Simultaneous logger creation</td>\n<td>Create logger <code>com.example.service</code></td>\n<td>Create logger <code>com.example.service.auth</code></td>\n<td>Both loggers created with correct parent-child relationship</td>\n</tr>\n<tr>\n<td>Configuration race</td>\n<td>Set logger level to DEBUG</td>\n<td>Add handler to same logger</td>\n<td>Both operations complete without corruption</td>\n</tr>\n<tr>\n<td>Context modification</td>\n<td>Add field <code>user_id: alice</code> to logger context</td>\n<td>Read effective context from child logger</td>\n<td>Child sees consistent context state</td>\n</tr>\n<tr>\n<td>Handler dispatch</td>\n<td>Log ERROR message</td>\n<td>Remove handler from logger</td>\n<td>Message logged to handlers present at start of operation</td>\n</tr>\n</tbody></table>\n<p><strong>Memory Consistency Verification</strong></p>\n<p>Memory consistency verification ensures that changes made by one thread are properly visible to other threads according to the memory model of the target language. This is particularly important for logging systems where configuration changes must be immediately visible to all threads performing logging operations.</p>\n<p>The verification tests should check that level changes, handler modifications, and context updates made by one thread are immediately visible to other threads without requiring explicit synchronization in the application code. Memory consistency bugs often manifest as stale configuration being used intermittently under load.</p>\n<p><strong>Stress Testing Under Realistic Load</strong></p>\n<p>Realistic load testing subjects the logging system to conditions similar to production environments, including high message volume, frequent configuration changes, and mixed patterns of concurrent access. This type of testing often reveals performance bottlenecks and race conditions that only appear under sustained load.</p>\n<p>The stress tests should monitor not just correctness but also performance characteristics under load. Thread contention, lock acquisition times, and message throughput should remain stable even under extreme concurrency levels.</p>\n<h3 id=\"symptom-cause-fix-troubleshooting\">Symptom-Cause-Fix Troubleshooting</h3>\n<p>Systematic troubleshooting of structured logging systems requires mapping observable symptoms to their underlying causes and providing specific, actionable fixes. The challenge lies in the fact that logging system issues often have subtle symptoms that appear far from their root causes, and multiple independent issues can interact to create complex failure modes.</p>\n<h4 id=\"thread-safety-and-concurrency-issues\">Thread Safety and Concurrency Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logger configuration randomly reverts to defaults</td>\n<td>Race condition in logger registry during concurrent logger creation</td>\n<td>Add trace logging to logger creation and configuration methods. Check for duplicate logger instances with different configurations.</td>\n<td>Implement proper locking in <code>LoggerRegistry</code> with <code>RLock</code> for reads and exclusive lock for writes. Ensure atomic logger creation and configuration.</td>\n</tr>\n<tr>\n<td>Log messages occasionally missing from output</td>\n<td>Handler list modified during iteration in concurrent threads</td>\n<td>Add assertion to verify handler list stability during dispatch. Use concurrent logging load tests to reproduce.</td>\n<td>Use copy-on-write pattern for handler lists or lock handler list during iteration and modification.</td>\n</tr>\n<tr>\n<td>Inconsistent log levels applied to same logger</td>\n<td>Effective level cache invalidation race condition</td>\n<td>Monitor <code>_effective_level</code> cache values across threads. Add logging to level change and cache invalidation operations.</td>\n<td>Implement atomic cache invalidation with proper memory barriers. Use versioning to detect stale cache entries.</td>\n</tr>\n<tr>\n<td>Log records contain mixed context from different requests</td>\n<td>Thread pool reusing threads without context cleanup</td>\n<td>Inspect thread-local context storage at request boundaries. Check for context cleanup in thread pool management code.</td>\n<td>Implement automatic context cleanup using request lifecycle hooks or context managers that clear state on exit.</td>\n</tr>\n<tr>\n<td>Occasional crashes during high-volume logging</td>\n<td>Memory corruption from unsynchronized data structure access</td>\n<td>Use thread sanitizers or memory debugging tools. Add lock verification assertions in critical sections.</td>\n<td>Add comprehensive locking to all shared data structures. Use lock ordering to prevent deadlocks.</td>\n</tr>\n</tbody></table>\n<h4 id=\"context-propagation-problems\">Context Propagation Problems</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Correlation IDs disappear in background tasks</td>\n<td>Thread-local context not propagated to new threads</td>\n<td>Trace context state before and after thread creation. Check context inheritance in task spawning code.</td>\n<td>Implement context-aware thread creation utilities that capture parent context and set it in child threads.</td>\n</tr>\n<tr>\n<td>Context fields randomly change during async operations</td>\n<td>Async context not preserved across await boundaries</td>\n<td>Add context state logging before and after each await operation. Monitor context during coroutine switches.</td>\n<td>Use async-local storage with proper context copying across task boundaries. Implement async context managers.</td>\n</tr>\n<tr>\n<td>Memory usage grows continuously in long-running services</td>\n<td>Context objects not being garbage collected</td>\n<td>Use memory profilers to identify context object accumulation. Check for circular references and strong reference chains.</td>\n<td>Implement weak references in context storage. Add automatic context cleanup based on access time or reference counting.</td>\n</tr>\n<tr>\n<td>Child logger context missing parent fields</td>\n<td>Context inheritance not working correctly</td>\n<td>Compare parent and child context objects. Trace context inheritance during logger hierarchy traversal.</td>\n<td>Fix context inheritance logic to properly merge parent context with local context. Ensure inheritance occurs at access time, not creation time.</td>\n</tr>\n<tr>\n<td>Context lost after exception handling</td>\n<td>Exception unwinding clears context without restoration</td>\n<td>Add context state logging in exception handlers. Check context cleanup in finally blocks and exception handling code.</td>\n<td>Use context managers that automatically restore previous context state even when exceptions occur during processing.</td>\n</tr>\n</tbody></table>\n<h4 id=\"serialization-and-formatting-issues\">Serialization and Formatting Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Log output contains <code>[Object object]</code> or similar placeholder text</td>\n<td>Non-serializable objects in context or log parameters</td>\n<td>Add type checking to context field additions. Test serialization of all context objects before logging.</td>\n<td>Implement <code>safe_serialize()</code> with fallback representations for non-serializable objects. Add type validation for context fields.</td>\n</tr>\n<tr>\n<td>JSON output malformed or contains invalid characters</td>\n<td>Circular references or special characters not being escaped properly</td>\n<td>Validate JSON output with strict parsers. Check for circular object references in context data.</td>\n<td>Use custom JSON encoder with circular reference detection and proper character escaping. Limit serialization depth.</td>\n</tr>\n<tr>\n<td>Log timestamps inconsistent or incorrect format</td>\n<td>Timestamp generation not thread-safe or using wrong timezone</td>\n<td>Compare timestamps across threads and verify timezone handling. Check timestamp generation under concurrent load.</td>\n<td>Use thread-safe timestamp generation with proper UTC handling. Implement timestamp caching for performance.</td>\n</tr>\n<tr>\n<td>Pretty-printed logs missing colors or formatting</td>\n<td>Terminal detection not working or color codes not supported</td>\n<td>Test color output in different terminal environments. Check terminal capability detection logic.</td>\n<td>Implement robust terminal capability detection with graceful fallback to plain text when colors not supported.</td>\n</tr>\n<tr>\n<td>Large context objects cause out-of-memory errors</td>\n<td>Context serialization creating oversized JSON objects</td>\n<td>Monitor memory usage during serialization. Set limits on context object size and nesting depth.</td>\n<td>Implement context size limits and truncation. Add <code>estimate_serialized_size()</code> checks before full serialization.</td>\n</tr>\n</tbody></table>\n<h4 id=\"handler-and-output-destination-problems\">Handler and Output Destination Problems</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Application hangs during log output</td>\n<td>Blocking I/O in handlers without timeouts</td>\n<td>Profile application during hang to identify blocked threads. Check file and network I/O patterns in handlers.</td>\n<td>Implement non-blocking handlers with background queues. Add timeouts to all I/O operations. Use circuit breakers for unreliable destinations.</td>\n</tr>\n<tr>\n<td>Log messages lost during handler failures</td>\n<td>Handler exceptions not properly caught and recovered</td>\n<td>Add error logging to handler dispatch. Monitor handler success/failure rates. Check exception handling in handler code.</td>\n<td>Implement comprehensive exception handling in handler dispatch. Add handler health monitoring and automatic recovery.</td>\n</tr>\n<tr>\n<td>Duplicate log messages in output</td>\n<td>Handler dispatch calling same handler multiple times</td>\n<td>Trace handler collection and dispatch logic. Check for duplicate handlers in logger hierarchy.</td>\n<td>Fix handler collection to remove duplicates. Implement handler identity checking based on handler configuration.</td>\n</tr>\n<tr>\n<td>Log files not being rotated or growing unbounded</td>\n<td>File handler not implementing rotation or size limits</td>\n<td>Monitor file sizes and rotation behavior. Check file handler configuration and rotation logic.</td>\n<td>Implement proper file rotation with size and time-based triggers. Add monitoring for file handler disk usage.</td>\n</tr>\n<tr>\n<td>Network handlers causing application instability</td>\n<td>Network handlers blocking application threads on failures</td>\n<td>Monitor network handler performance and failure rates. Check timeout and retry configuration.</td>\n<td>Implement asynchronous network handlers with connection pooling. Add circuit breakers and exponential backoff for failed connections.</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-and-resource-issues\">Performance and Resource Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Application response time degrades with log volume</td>\n<td>Logging operations blocking application threads</td>\n<td>Profile application performance vs. logging volume. Measure time spent in logging operations.</td>\n<td>Implement asynchronous logging with background processing queues. Optimize hot path operations and reduce lock contention.</td>\n</tr>\n<tr>\n<td>Memory usage increases proportionally to log volume</td>\n<td>Context or handler buffers accumulating without bounds</td>\n<td>Monitor memory allocation patterns in logging code. Check for unbounded buffers or caches.</td>\n<td>Implement buffer size limits and periodic cleanup. Add memory pressure detection and adaptive behavior.</td>\n</tr>\n<tr>\n<td>CPU usage high during logging operations</td>\n<td>Inefficient serialization or formatting algorithms</td>\n<td>Profile CPU usage in logging hot paths. Identify expensive operations like JSON serialization or string formatting.</td>\n<td>Optimize serialization with object pooling and caching. Use efficient formatting algorithms and reduce object allocation.</td>\n</tr>\n<tr>\n<td>Disk I/O spikes causing system instability</td>\n<td>Synchronous file writes without buffering or batching</td>\n<td>Monitor disk I/O patterns and correlate with logging activity. Check file write patterns in handlers.</td>\n<td>Implement write batching and buffering. Use asynchronous I/O or background writer threads. Add disk pressure detection.</td>\n</tr>\n<tr>\n<td>Logger creation very slow under load</td>\n<td>Logger registry lock contention or inefficient hierarchy traversal</td>\n<td>Profile logger creation performance. Monitor lock acquisition times and registry operation costs.</td>\n<td>Optimize logger registry with better data structures. Use read-write locks to reduce contention. Cache hierarchy traversal results.</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance provides concrete debugging infrastructure and techniques specifically tailored for Python-based structured logging systems. The focus is on building debugging tools that can be integrated into the logging system itself and used during development and troubleshooting.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Trace Logging</td>\n<td>Python <code>logging</code> module with separate logger</td>\n<td>Custom trace system with structured output</td>\n</tr>\n<tr>\n<td>Thread Safety Testing</td>\n<td><code>threading.Thread</code> with manual barriers</td>\n<td><code>concurrent.futures</code> with systematic test framework</td>\n</tr>\n<tr>\n<td>Memory Debugging</td>\n<td>Built-in <code>tracemalloc</code> and <code>gc</code> modules</td>\n<td>External tools like <code>objgraph</code> and <code>memory_profiler</code></td>\n</tr>\n<tr>\n<td>Concurrency Testing</td>\n<td>Simple thread spawning with <code>threading</code></td>\n<td>Advanced concurrency testing with <code>pytest-xdist</code></td>\n</tr>\n<tr>\n<td>Context Inspection</td>\n<td>Manual context dumps with <code>pprint</code></td>\n<td>Rich context visualization with custom formatters</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-module-structure\">Recommended Module Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>structured_logging/\n├── core/\n│   ├── logger.py              ← Logger, LoggerRegistry classes\n│   ├── handlers.py            ← Handler implementations\n│   ├── formatters.py          ← JSON and pretty formatters\n│   └── context.py             ← Context management and propagation\n├── debugging/\n│   ├── __init__.py\n│   ├── trace_logger.py        ← Internal tracing system\n│   ├── context_inspector.py   ← Context state inspection utilities\n│   ├── thread_safety_test.py  ← Concurrency testing framework\n│   └── memory_tracker.py      ← Memory leak detection utilities\n├── tests/\n│   ├── test_race_conditions.py ← Systematic concurrency tests\n│   ├── test_context_propagation.py ← Context boundary tests\n│   └── test_memory_leaks.py    ← Long-running memory tests\n└── examples/\n    ├── debug_concurrent_app.py ← Example debugging setup\n    └── trace_context_flow.py   ← Context propagation examples</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete Trace Logging System</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timezone</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> weakref</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TraceLogger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Independent trace logging system for debugging the main logging infrastructure.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Uses simple, robust mechanisms to avoid circular dependencies or complexity</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    that might itself introduce bugs.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, output_file: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, max_records: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._records </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_records)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._output_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output_file</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> trace</span><span style=\"color:#E1E4E8\">(self, event_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, details: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log a trace event with high-precision timing and thread information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            record </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'timestamp'</span><span style=\"color:#E1E4E8\">: datetime.now(timezone.utc).isoformat(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'elapsed_ms'</span><span style=\"color:#E1E4E8\">: (time.perf_counter() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'thread_id'</span><span style=\"color:#E1E4E8\">: threading.get_ident(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'thread_name'</span><span style=\"color:#E1E4E8\">: threading.current_thread().name,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'event_type'</span><span style=\"color:#E1E4E8\">: event_type,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'details'</span><span style=\"color:#E1E4E8\">: details.copy()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._records.append(record)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Immediate output for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._output_file:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">._write_to_file(record)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">._write_to_stderr(record)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_to_file</span><span style=\"color:#E1E4E8\">(self, record: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write trace record to file with immediate flush.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._output_file, </span><span style=\"color:#9ECBFF\">'a'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">encoding</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                f.write(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                f.flush()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Fallback to stderr if file write fails</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sys.stderr.write(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"TraceLogger file error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._write_to_stderr(record)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_to_stderr</span><span style=\"color:#E1E4E8\">(self, record: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write trace record to stderr for immediate visibility.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sys.stderr.write(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"TRACE[</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record[</span><span style=\"color:#9ECBFF\">'thread_name'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">]: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record[</span><span style=\"color:#9ECBFF\">'event_type'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">record[</span><span style=\"color:#9ECBFF\">'details'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sys.stderr.flush()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_records</span><span style=\"color:#E1E4E8\">(self, event_type: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                   thread_id: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Retrieve trace records with optional filtering.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            records </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._records)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> event_type:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            records </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [r </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> r </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> records </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> r[</span><span style=\"color:#9ECBFF\">'event_type'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> event_type]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> thread_id:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            records </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [r </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> r </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> records </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> r[</span><span style=\"color:#9ECBFF\">'thread_id'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> thread_id]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> records</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> dump_summary</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate human-readable summary of trace activity.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            records </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._records)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> records:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> \"No trace records available\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        summary_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Trace Summary (</span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(records)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> records)\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        summary_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Time range: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">records[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">][</span><span style=\"color:#9ECBFF\">'elapsed_ms'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">records[</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">][</span><span style=\"color:#9ECBFF\">'elapsed_ms'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Event type frequency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        event_counts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> record </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> records:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            event_counts[record[</span><span style=\"color:#9ECBFF\">'event_type'</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> event_counts.get(record[</span><span style=\"color:#9ECBFF\">'event_type'</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        summary_lines.append(</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">Event Types:\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> event_type, count </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(event_counts.items()):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            summary_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">event_type</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Thread activity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        thread_counts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> record </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> records:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            thread_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> record[</span><span style=\"color:#9ECBFF\">'thread_id'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            thread_counts[thread_id] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> thread_counts.get(thread_id, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        summary_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">Thread Activity (</span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(thread_counts)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> threads):\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> thread_id, count </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(thread_counts.items()):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            summary_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Thread </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> events\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.join(summary_lines)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global trace logger instance for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_debug_tracer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TraceLogger()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> trace_event</span><span style=\"color:#E1E4E8\">(event_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">details) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Convenience function for logging trace events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _debug_tracer.trace(event_type, details)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_trace_summary</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Get debugging trace summary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> _debug_tracer.dump_summary()</span></span></code></pre></div>\n\n<p><strong>Context State Inspector</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextvars</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> weakref</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, List, Set, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ContextInspector</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Utility for inspecting and debugging context state across all storage mechanisms.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provides visibility into context propagation, inheritance, and cleanup behavior.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._inspection_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._context_history: List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._active_contexts: weakref.WeakSet </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> weakref.WeakSet()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_context</span><span style=\"color:#E1E4E8\">(self, context_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context_data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        storage_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register a context for inspection tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._inspection_lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._context_history.append({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'timestamp'</span><span style=\"color:#E1E4E8\">: datetime.now().isoformat(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'action'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'register'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'context_id'</span><span style=\"color:#E1E4E8\">: context_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'storage_type'</span><span style=\"color:#E1E4E8\">: storage_type,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'thread_id'</span><span style=\"color:#E1E4E8\">: threading.get_ident(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'data_snapshot'</span><span style=\"color:#E1E4E8\">: context_data.copy(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'field_count'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(context_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> snapshot_all_contexts</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Take a complete snapshot of all context storage mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        snapshot </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'timestamp'</span><span style=\"color:#E1E4E8\">: datetime.now().isoformat(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'thread_local_contexts'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._snapshot_thread_local(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'async_contexts'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._snapshot_async_contexts(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'active_context_count'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._active_contexts),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'history_length'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._context_history)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> snapshot</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _snapshot_thread_local</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Snapshot all thread-local context storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This would integrate with the actual ContextStorage implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        thread_contexts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Iterate through all active threads and capture their context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> thread </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> threading.enumerate():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # This assumes the ContextStorage has a method to get context by thread</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # In real implementation, this would access the actual thread-local storage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                thread_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_thread_context(thread.ident)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> thread_context:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    thread_contexts[</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"thread_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread.ident</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        'thread_name'</span><span style=\"color:#E1E4E8\">: thread.name,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        'context'</span><span style=\"color:#E1E4E8\">: thread_context,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        'field_count'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(thread_context)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                thread_contexts[</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"thread_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread.ident</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e)}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> thread_contexts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _snapshot_async_contexts</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Snapshot async context variables.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        async_contexts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Capture current async context if available</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> contextvars.copy_context()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            context_vars </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # This would iterate through actual context variables in use</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # In real implementation, this would access the ContextStorage async variables</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> var, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> current_context.items():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> hasattr</span><span style=\"color:#E1E4E8\">(var, </span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">and</span><span style=\"color:#9ECBFF\"> 'logging'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> var.name:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    context_vars[var.name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            async_contexts[</span><span style=\"color:#9ECBFF\">'current_task'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'context_vars'</span><span style=\"color:#E1E4E8\">: context_vars,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'var_count'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(context_vars)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            async_contexts[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(e)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> async_contexts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_thread_context</span><span style=\"color:#E1E4E8\">(self, thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get context for specific thread - placeholder for actual implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # In real implementation, this would access the ContextStorage._thread_local</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> find_context_inconsistencies</span><span style=\"color:#E1E4E8\">(self) -> List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Identify inconsistencies between different context storage mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        inconsistencies </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        snapshot </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.snapshot_all_contexts()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Compare thread-local and async contexts for current thread</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_thread_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.get_ident()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        thread_context_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"thread_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">current_thread_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        thread_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> snapshot[</span><span style=\"color:#9ECBFF\">'thread_local_contexts'</span><span style=\"color:#E1E4E8\">].get(thread_context_key, {}).get(</span><span style=\"color:#9ECBFF\">'context'</span><span style=\"color:#E1E4E8\">, {})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        async_context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> snapshot[</span><span style=\"color:#9ECBFF\">'async_contexts'</span><span style=\"color:#E1E4E8\">].get(</span><span style=\"color:#9ECBFF\">'current_task'</span><span style=\"color:#E1E4E8\">, {}).get(</span><span style=\"color:#9ECBFF\">'context_vars'</span><span style=\"color:#E1E4E8\">, {})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check for missing fields</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> field </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> thread_context:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> field </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> async_context:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                inconsistencies.append({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'missing_in_async'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'field'</span><span style=\"color:#E1E4E8\">: field,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'thread_value'</span><span style=\"color:#E1E4E8\">: thread_context[field],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'thread_id'</span><span style=\"color:#E1E4E8\">: current_thread_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> field </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> async_context:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> field </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> thread_context:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                inconsistencies.append({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'missing_in_thread_local'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'field'</span><span style=\"color:#E1E4E8\">: field,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'async_value'</span><span style=\"color:#E1E4E8\">: async_context[field],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'thread_id'</span><span style=\"color:#E1E4E8\">: current_thread_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check for value mismatches</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> field </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(thread_context.keys()) </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(async_context.keys()):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> thread_context[field] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> async_context[field]:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                inconsistencies.append({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'value_mismatch'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'field'</span><span style=\"color:#E1E4E8\">: field,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'thread_value'</span><span style=\"color:#E1E4E8\">: thread_context[field],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'async_value'</span><span style=\"color:#E1E4E8\">: async_context[field],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'thread_id'</span><span style=\"color:#E1E4E8\">: current_thread_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> inconsistencies</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_context_report</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate comprehensive context debugging report.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        snapshot </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.snapshot_all_contexts()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        inconsistencies </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.find_context_inconsistencies()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        report_lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"=== Context State Debugging Report ===\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Generated at: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">snapshot[</span><span style=\"color:#9ECBFF\">'timestamp'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"Active contexts: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">snapshot[</span><span style=\"color:#9ECBFF\">'active_context_count'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"History entries: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">snapshot[</span><span style=\"color:#9ECBFF\">'history_length'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Thread-local context summary</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        report_lines.append(</span><span style=\"color:#9ECBFF\">\"Thread-Local Contexts:\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> thread_key, context_info </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> snapshot[</span><span style=\"color:#9ECBFF\">'thread_local_contexts'</span><span style=\"color:#E1E4E8\">].items():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#9ECBFF\"> 'error'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> context_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread_key</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: ERROR - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">context_info[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                field_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context_info.get(</span><span style=\"color:#9ECBFF\">'field_count'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                thread_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context_info.get(</span><span style=\"color:#9ECBFF\">'thread_name'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'unknown'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread_key</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> (</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">thread_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">): </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">field_count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> fields\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Show context fields if not too many</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> field_count </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    for</span><span style=\"color:#E1E4E8\"> field, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> context_info.get(</span><span style=\"color:#9ECBFF\">'context'</span><span style=\"color:#E1E4E8\">, {}).items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"    </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">field</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">value</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        report_lines.append(</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Async context summary</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        report_lines.append(</span><span style=\"color:#9ECBFF\">\"Async Contexts:\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        async_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> snapshot[</span><span style=\"color:#9ECBFF\">'async_contexts'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> 'error'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> async_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  ERROR: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">async_info[</span><span style=\"color:#9ECBFF\">'error'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_task </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> async_info.get(</span><span style=\"color:#9ECBFF\">'current_task'</span><span style=\"color:#E1E4E8\">, {})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            var_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_task.get(</span><span style=\"color:#9ECBFF\">'var_count'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Current task: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">var_count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> context variables\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> var_name, value </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> current_task.get(</span><span style=\"color:#9ECBFF\">'context_vars'</span><span style=\"color:#E1E4E8\">, {}).items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"    </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">var_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">value</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        report_lines.append(</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Inconsistencies</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> inconsistencies:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Context Inconsistencies (</span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(inconsistencies)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> found):\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> inconsistency </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> inconsistencies:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">inconsistency[</span><span style=\"color:#9ECBFF\">'type'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">inconsistency[</span><span style=\"color:#9ECBFF\">'field'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#9ECBFF\"> 'thread_value'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> inconsistency:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"    Thread-local: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">inconsistency[</span><span style=\"color:#9ECBFF\">'thread_value'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#9ECBFF\"> 'async_value'</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> inconsistency:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    report_lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"    Async: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">inconsistency[</span><span style=\"color:#9ECBFF\">'async_value'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            report_lines.append(</span><span style=\"color:#9ECBFF\">\"No context inconsistencies detected.\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.join(report_lines)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global context inspector for debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">_context_inspector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ContextInspector()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> snapshot_contexts</span><span style=\"color:#E1E4E8\">() -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Take snapshot of all context state for debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> _context_inspector.snapshot_all_contexts()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> generate_context_debug_report</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generate comprehensive context debugging report.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> _context_inspector.generate_context_report()</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Thread Safety Testing Framework</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> concurrent.futures </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ThreadPoolExecutor, as_completed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Callable, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> queue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConcurrencyTestFramework</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Framework for systematic testing of thread safety in logging components.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provides utilities for coordinated multi-threaded testing with barrier synchronization.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_workers: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_workers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_workers</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_results: List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.results_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_coordinated_test</span><span style=\"color:#E1E4E8\">(self, test_func: Callable, num_threads: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           iterations: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">, coordination_delay: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.001</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Run coordinated multi-threaded test with barrier synchronization.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            test_func: Function to test - should accept (thread_id, iteration, barrier)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            num_threads: Number of concurrent threads</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            iterations: Number of iterations per thread</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            coordination_delay: Delay to maximize contention probability</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create barrier for thread coordination</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create results collection mechanism</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Launch threads with coordinated start</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Collect results and analyze for race conditions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return summary with success/failure counts and timing information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use threading.Barrier to synchronize thread starts</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_logger_hierarchy_creation</span><span style=\"color:#E1E4E8\">(self, logger_factory: Callable) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Test concurrent logger creation for race conditions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            logger_factory: Function that creates loggers - get_logger(name)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Define logger names that should create hierarchy conflicts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create test function that creates loggers with barrier coordination</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Run coordinated test with multiple threads creating same hierarchies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify no duplicate loggers or corrupted hierarchies were created</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check parent-child relationships are correct after concurrent creation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Test names like [\"com.example\", \"com.example.service\", \"com.example.service.auth\"]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_concurrent_configuration_changes</span><span style=\"color:#E1E4E8\">(self, logger_registry) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Test concurrent logger configuration changes.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            logger_registry: Registry containing loggers to test</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create test scenarios mixing level changes and handler additions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Coordinate threads to make changes at same time using barrier</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify final configuration state is consistent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check that effective level caches were properly invalidated</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Ensure no configuration was lost or corrupted during changes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_context_propagation_race_conditions</span><span style=\"color:#E1E4E8\">(self, context_manager) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Test context propagation under concurrent access.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            context_manager: ContextStorage instance to test</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create test that sets different context in multiple threads</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add child context inheritance operations during concurrent updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify context isolation between threads</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check that context inheritance works correctly under contention</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Ensure no context corruption or cross-thread contamination</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Usage example for milestone checkpoints</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> run_thread_safety_checkpoint</span><span style=\"color:#E1E4E8\">(logger_system) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Run comprehensive thread safety tests for milestone verification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns True if all tests pass, False if race conditions detected.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    framework </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ConcurrencyTestFramework()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Test logger creation under contention</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    creation_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> framework.test_logger_hierarchy_creation(logger_system.get_logger)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Test configuration changes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> framework.test_concurrent_configuration_changes(logger_system.registry)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Test context propagation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> framework.test_context_propagation_race_conditions(logger_system.context_manager)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Analyze results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    all_passed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        creation_results.get(</span><span style=\"color:#9ECBFF\">'failures'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> and</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config_results.get(</span><span style=\"color:#9ECBFF\">'failures'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> and</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        context_results.get(</span><span style=\"color:#9ECBFF\">'failures'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> all_passed:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Thread safety test failures detected:\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Logger creation: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">creation_results.get(</span><span style=\"color:#9ECBFF\">'failures'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> failures\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Configuration: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">config_results.get(</span><span style=\"color:#9ECBFF\">'failures'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> failures\"</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Context propagation: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">context_results.get(</span><span style=\"color:#9ECBFF\">'failures'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> failures\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> all_passed</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1: Logger Core Thread Safety Verification</strong></p>\n<p>After implementing the logger core, run these verification steps:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run basic thread safety tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_race_conditions.py::test_concurrent_logger_creation</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output should show no race conditions:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_concurrent_logger_creation PASSED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_concurrent_level_changes PASSED  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_concurrent_handler_dispatch PASSED</span></span></code></pre></div>\n\n<p>Verify thread safety manually:</p>\n<ol>\n<li>Start Python interpreter</li>\n<li>Create logger registry and spawn 10 threads simultaneously creating loggers</li>\n<li>Check that logger hierarchy is consistent and no duplicate loggers exist</li>\n<li>Verify that all loggers have correct parent-child relationships</li>\n</ol>\n<p><strong>Milestone 2: Structured Output Serialization Testing</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test JSON serialization under load</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_serialization.py::test_concurrent_json_formatting</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test with problematic objects</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/test_serialization_edge_cases.py</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>All JSON output should be valid single-line JSON</li>\n<li>No serialization errors even with circular references</li>\n<li>Memory usage should remain stable during high-volume serialization</li>\n</ul>\n<p><strong>Milestone 3: Context Propagation Verification</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test async context preservation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_context_propagation.py::test_async_context_preservation</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test thread-local context isolation  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/test_context_boundaries.py</span></span></code></pre></div>\n\n<p>Manual verification:</p>\n<ol>\n<li>Create request with correlation ID in main thread</li>\n<li>Spawn background task and verify correlation ID is present</li>\n<li>Modify context in background task and verify main thread context unchanged</li>\n<li>Check that context cleanup occurs after request completion</li>\n</ol>\n<h4 id=\"language-specific-python-debugging-tips\">Language-Specific Python Debugging Tips</h4>\n<ul>\n<li>Use <code>threading.get_ident()</code> to identify which thread is executing logging operations</li>\n<li><code>threading.current_thread().name</code> provides human-readable thread identification</li>\n<li><code>tracemalloc.start()</code> at application startup enables memory leak detection</li>\n<li><code>gc.get_objects()</code> can find leaked context objects by type filtering  </li>\n<li><code>weakref.WeakSet</code> prevents circular references in context tracking</li>\n<li><code>contextvars.copy_context()</code> captures complete async context state</li>\n<li><code>sys.stderr.write()</code> provides immediate debug output that bypasses the main logging system</li>\n<li>Use <code>threading.RLock()</code> instead of <code>Lock()</code> for recursive logger operations</li>\n<li><code>time.perf_counter()</code> provides high-resolution timing for race condition detection</li>\n<li><code>concurrent.futures.ThreadPoolExecutor</code> simplifies coordinated multi-threaded testing</li>\n</ul>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section outlines potential enhancements beyond the three core milestones that the current design accommodates. While Milestones 1-3 establish the foundation, these extensions represent production-scale optimizations and enterprise-level features that can be added incrementally.</p>\n</blockquote>\n<p>Think of this logging system as a highway infrastructure. The three core milestones build the essential roads, traffic signals, and basic navigation systems that handle normal traffic flow. These future extensions are like adding express lanes for high-volume traffic (performance optimizations), connecting to airports and shipping ports (advanced output destinations), and installing smart traffic management systems that adapt to changing conditions (configuration management). Each extension leverages the solid foundation established by the core milestones while adding sophisticated capabilities for production environments.</p>\n<p>The architectural decisions made in the core design deliberately accommodate these extensions without requiring fundamental restructuring. The handler dispatch mechanism supports pluggable output destinations, the context propagation system enables sampling decisions, and the thread-safe registry pattern allows dynamic reconfiguration. This forward-looking design ensures that organizations can start with the essential logging capabilities and scale up to enterprise requirements as their needs evolve.</p>\n<h3 id=\"performance-optimizations\">Performance Optimizations</h3>\n<p>Production logging systems must handle massive throughput while maintaining low latency for application threads. Think of performance optimizations as traffic management systems for a busy highway. During rush hour, you need express lanes for priority traffic (log sampling), speed limits to prevent accidents (rate limiting), and efficient on/off ramps that don&#39;t block the main flow (async handler dispatch). These optimizations ensure that logging enhances observability without degrading application performance.</p>\n<p>The core design&#39;s thread-safe architecture and handler abstraction pattern provide the foundation for these performance enhancements. The <code>Handler</code> base class can be extended with buffering and batching capabilities, while the <code>LoggingContext</code> system enables sampling decisions based on request characteristics. The <code>CircuitBreaker</code> pattern already implemented for error handling extends naturally to performance protection by temporarily disabling expensive operations under load.</p>\n<blockquote>\n<p><strong>Decision: Log Sampling Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: High-throughput applications generate millions of log entries per second, overwhelming storage and network capacity while providing diminishing observability value</li>\n<li><strong>Options Considered</strong>: Random sampling, adaptive sampling, structured sampling</li>\n<li><strong>Decision</strong>: Implement adaptive sampling with context-aware rate limiting</li>\n<li><strong>Rationale</strong>: Adaptive sampling maintains full fidelity for errors and important events while reducing volume for routine operations. Context-aware decisions ensure complete request traces are preserved even when individual log entries are sampled</li>\n<li><strong>Consequences</strong>: Enables high-throughput logging with bounded resource usage while preserving debugging capability for critical scenarios</li>\n</ul>\n</blockquote>\n<p><strong>Adaptive Sampling Architecture</strong></p>\n<p>Adaptive sampling makes intelligent decisions about which log entries to preserve based on current system load, log entry importance, and correlation context. The sampling system operates at multiple levels: per-logger sampling rates, per-request sampling decisions, and global backpressure handling. This multi-layered approach ensures that critical information is never lost while routine operations can be sampled aggressively during high-load periods.</p>\n<p>The <code>SamplingHandler</code> wraps existing handlers and makes sampling decisions before expensive operations like network transmission or disk writes. Sampling decisions are made deterministically based on correlation IDs, ensuring that when a request is selected for sampling, all related log entries are preserved together. This correlation-aware sampling maintains complete request traces while reducing overall volume.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Purpose</th>\n<th>Key Responsibilities</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>AdaptiveSampler</code></td>\n<td>Core sampling logic</td>\n<td>Rate calculation, decision caching, context awareness</td>\n</tr>\n<tr>\n<td><code>SamplingHandler</code></td>\n<td>Handler wrapper</td>\n<td>Pre-filtering, correlation tracking, metrics collection</td>\n</tr>\n<tr>\n<td><code>SamplingConfig</code></td>\n<td>Configuration model</td>\n<td>Rate limits, importance rules, adaptation parameters</td>\n</tr>\n<tr>\n<td><code>LoadMonitor</code></td>\n<td>System monitoring</td>\n<td>CPU/memory tracking, backpressure detection, rate adjustment</td>\n</tr>\n<tr>\n<td><code>SampleDecisionCache</code></td>\n<td>Decision storage</td>\n<td>Correlation ID mapping, TTL management, memory bounds</td>\n</tr>\n</tbody></table>\n<p><strong>Rate Limiting Implementation</strong></p>\n<p>Rate limiting protects the logging system and downstream consumers from overload by enforcing maximum throughput limits. Think of rate limiting as traffic lights that meter the flow of vehicles onto a highway, preventing congestion that would slow down all traffic. The rate limiting system operates at multiple granularities: global limits prevent system-wide overload, per-logger limits prevent individual components from monopolizing resources, and per-level limits ensure that verbose debug logging doesn&#39;t crowd out important error messages.</p>\n<p>The <code>TokenBucketRateLimiter</code> provides smooth rate limiting with burst capacity, allowing applications to handle traffic spikes while maintaining average rate limits. Token buckets are maintained per logger and per level, with hierarchical inheritance ensuring that child loggers respect parent limits. The rate limiter integrates with the sampling system to gracefully degrade service rather than dropping log entries randomly.</p>\n<table>\n<thead>\n<tr>\n<th>Rate Limiter Type</th>\n<th>Use Case</th>\n<th>Configuration Parameters</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>GlobalRateLimiter</code></td>\n<td>System-wide protection</td>\n<td>tokens_per_second, burst_capacity, backpressure_threshold</td>\n</tr>\n<tr>\n<td><code>LoggerRateLimiter</code></td>\n<td>Per-component limits</td>\n<td>logger_name, max_rate, inheritance_factor</td>\n</tr>\n<tr>\n<td><code>LevelRateLimiter</code></td>\n<td>Per-severity limits</td>\n<td>log_level, rate_multiplier, priority_boost</td>\n</tr>\n<tr>\n<td><code>CorrelationRateLimiter</code></td>\n<td>Per-request limits</td>\n<td>correlation_pattern, request_budget, spillover_handling</td>\n</tr>\n</tbody></table>\n<p><strong>Asynchronous Handler Dispatch</strong></p>\n<p>Asynchronous handler dispatch decouples log entry processing from application thread execution, preventing slow output destinations from blocking application performance. Think of async dispatch as a restaurant kitchen where orders are placed on a queue and prepared by dedicated cooks, allowing waiters to continue serving customers without waiting for each dish to be completed. This architectural pattern ensures that logging operations never block application threads, even when writing to slow destinations like remote collectors or network file systems.</p>\n<p>The <code>AsyncHandler</code> maintains internal queues for each output destination and uses dedicated worker threads to process log entries in the background. Queue sizing and backpressure handling prevent memory exhaustion during traffic spikes, while priority queues ensure that high-severity log entries are processed first during congestion. The async system preserves ordering guarantees within each correlation context while allowing parallel processing across different requests.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: Async dispatch introduces complexity around system shutdown and error propagation. The shutdown sequence must drain queues gracefully while the error handling system needs to surface async failures without blocking the main application flow.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Async Component</th>\n<th>Threading Model</th>\n<th>Queue Management</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>AsyncHandler</code></td>\n<td>Single worker per handler</td>\n<td>Bounded blocking queue, overflow to disk</td>\n</tr>\n<tr>\n<td><code>BatchingHandler</code></td>\n<td>Periodic flush thread</td>\n<td>Time and size-based batching, compression</td>\n</tr>\n<tr>\n<td><code>PriorityHandler</code></td>\n<td>Priority queue worker</td>\n<td>Level-based ordering, starvation prevention</td>\n</tr>\n<tr>\n<td><code>ShutdownManager</code></td>\n<td>Graceful termination</td>\n<td>Queue draining, timeout handling, force shutdown</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Queue Memory Explosion</strong>\nUnder extreme load, async queues can consume unbounded memory if not properly configured. Implement overflow-to-disk mechanisms and queue size limits with backpressure signaling to prevent out-of-memory conditions. Monitor queue depths and implement alerting when queues approach capacity limits.</p>\n<h3 id=\"advanced-output-destinations\">Advanced Output Destinations</h3>\n<p>Production logging systems must integrate with enterprise infrastructure including search engines, metrics systems, and distributed tracing platforms. Think of advanced output destinations as specialized delivery services: while basic handlers are like local mail delivery, these advanced destinations are like express shipping to international locations with customs processing and tracking integration. Each destination has unique requirements for data format, authentication, batching, and error handling.</p>\n<p>The <code>Handler</code> abstraction established in the core design provides a clean integration point for these advanced destinations. Each advanced handler implements the same <code>handle(record)</code> interface while internally managing the complexity of external system integration. This consistency ensures that advanced destinations can be mixed and matched with basic handlers, allowing applications to send the same log stream to multiple destinations simultaneously.</p>\n<p><strong>Elasticsearch Integration</strong></p>\n<p>Elasticsearch integration transforms the logging system into a powerful search and analytics platform by indexing log entries for real-time querying and dashboard visualization. Think of Elasticsearch as a library cataloging system that not only stores books but also creates detailed indexes by subject, author, and keyword, enabling researchers to find exactly what they need instantly. The Elasticsearch handler maps structured log entries to JSON documents with appropriate field mappings and index lifecycle management.</p>\n<p>The <code>ElasticsearchHandler</code> batches log entries into bulk index operations to maximize throughput while managing index templates and field mappings automatically. Index rotation strategies partition log data by time period, enabling efficient storage management and query performance. The handler integrates with the circuit breaker pattern to handle Elasticsearch cluster outages gracefully while buffering entries for retry when connectivity is restored.</p>\n<table>\n<thead>\n<tr>\n<th>Elasticsearch Component</th>\n<th>Purpose</th>\n<th>Configuration Options</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ElasticsearchHandler</code></td>\n<td>Bulk indexing</td>\n<td>batch_size, flush_interval, index_template</td>\n</tr>\n<tr>\n<td><code>IndexManager</code></td>\n<td>Lifecycle management</td>\n<td>rotation_policy, retention_days, shard_count</td>\n</tr>\n<tr>\n<td><code>MappingGenerator</code></td>\n<td>Schema creation</td>\n<td>field_types, analyzers, dynamic_mapping</td>\n</tr>\n<tr>\n<td><code>BulkProcessor</code></td>\n<td>Batch optimization</td>\n<td>max_batch_bytes, concurrent_requests, retry_policy</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Index Rotation Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Log data accumulates rapidly and requires different retention policies based on age and importance</li>\n<li><strong>Options Considered</strong>: Single large index, daily rotation, size-based rotation</li>\n<li><strong>Decision</strong>: Implement daily index rotation with configurable retention policies</li>\n<li><strong>Rationale</strong>: Daily rotation provides optimal balance between query performance and operational simplicity, while enabling different retention policies for different log levels</li>\n<li><strong>Consequences</strong>: Enables efficient storage management and fast query performance while requiring index template management and automated cleanup processes</li>\n</ul>\n</blockquote>\n<p><strong>Metrics Integration</strong></p>\n<p>Metrics integration extracts quantitative signals from log entries to populate time-series databases and alerting systems. Think of metrics integration as transforming narrative log entries into numerical health indicators, similar to how a doctor extracts vital signs from patient observations. The metrics system counts log entries by level and logger, measures request durations from correlation context, and creates custom metrics from structured log fields.</p>\n<p>The <code>MetricsHandler</code> analyzes log entries in real-time to emit counter, gauge, and histogram metrics to systems like Prometheus, StatsD, or CloudWatch. Metric extraction rules are configurable, allowing applications to define custom metrics based on log content without modifying application code. The metrics system provides immediate visibility into application health and performance trends that complement the detailed log analysis capabilities.</p>\n<table>\n<thead>\n<tr>\n<th>Metrics Component</th>\n<th>Metric Types</th>\n<th>Export Destinations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MetricsExtractor</code></td>\n<td>Counter, Gauge, Histogram</td>\n<td>Field parsing, aggregation rules, labeling strategy</td>\n</tr>\n<tr>\n<td><code>PrometheusHandler</code></td>\n<td>Time-series metrics</td>\n<td>/metrics endpoint, push gateway, service discovery</td>\n</tr>\n<tr>\n<td><code>StatsDHandler</code></td>\n<td>Real-time metrics</td>\n<td>UDP transport, metric namespacing, sampling support</td>\n</tr>\n<tr>\n<td><code>CloudWatchHandler</code></td>\n<td>Cloud metrics</td>\n<td>AWS API integration, custom namespaces, dimension mapping</td>\n</tr>\n</tbody></table>\n<p><strong>Distributed Tracing Integration</strong></p>\n<p>Distributed tracing integration connects log entries to trace spans and enables correlation across service boundaries in microservice architectures. Think of distributed tracing as creating a GPS tracking system for requests as they travel through multiple services, with log entries serving as detailed checkpoints along the journey. The tracing integration adds span context to log entries and creates trace annotations from log content.</p>\n<p>The <code>TracingHandler</code> extracts trace context from correlation IDs and injects trace metadata into log entries for cross-system correlation. When integrated with systems like Jaeger or Zipkin, log entries become searchable annotations within trace visualizations, providing detailed context for performance analysis and debugging. The handler creates trace spans for long-running operations identified through log patterns and correlation timing.</p>\n<table>\n<thead>\n<tr>\n<th>Tracing Component</th>\n<th>Integration Method</th>\n<th>Context Propagation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>OpenTelemetryHandler</code></td>\n<td>OTEL protocol</td>\n<td>W3C trace context, baggage propagation</td>\n</tr>\n<tr>\n<td><code>JaegerHandler</code></td>\n<td>Jaeger client</td>\n<td>Uber trace header, span annotations</td>\n</tr>\n<tr>\n<td><code>ZipkinHandler</code></td>\n<td>Zipkin protocol</td>\n<td>B3 propagation, span creation from logs</td>\n</tr>\n<tr>\n<td><code>TraceContextManager</code></td>\n<td>Context injection</td>\n<td>Cross-service correlation, timing extraction</td>\n</tr>\n</tbody></table>\n<h3 id=\"configuration-management\">Configuration Management</h3>\n<p>Production logging systems require sophisticated configuration management to adapt to changing operational requirements without service restarts. Think of configuration management as the control tower for an airport, continuously adjusting flight paths, runway assignments, and traffic patterns based on weather, equipment status, and traffic volume. The configuration system must handle real-time updates, environment-specific settings, and complex inheritance hierarchies while maintaining system stability.</p>\n<p>The core design&#39;s registry pattern and hierarchical structure provide the foundation for advanced configuration capabilities. The <code>LoggerRegistry</code> can be extended to support dynamic reconfiguration, while the inheritance system enables sophisticated configuration layering. Configuration changes propagate through the logger hierarchy automatically while preserving thread safety and avoiding configuration drift between components.</p>\n<blockquote>\n<p><strong>Decision: Configuration Hot-Reload Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Production systems require configuration changes without service restart to handle incidents and adjust verbosity dynamically</li>\n<li><strong>Options Considered</strong>: File watching, API endpoints, configuration service polling</li>\n<li><strong>Decision</strong>: Implement multi-source configuration with API-driven hot reload and file watching fallback</li>\n<li><strong>Rationale</strong>: API endpoints enable programmatic configuration during incidents while file watching provides declarative configuration management for normal operations</li>\n<li><strong>Consequences</strong>: Enables rapid response to production issues while requiring additional API security and configuration validation logic</li>\n</ul>\n</blockquote>\n<p><strong>Dynamic Reconfiguration System</strong></p>\n<p>Dynamic reconfiguration allows logging behavior to change at runtime without service restarts, enabling rapid response to production incidents and performance optimization. The reconfiguration system validates configuration changes before applying them, ensuring that invalid configurations don&#39;t disrupt logging operations. Configuration changes are applied atomically across all affected loggers to prevent inconsistent states during transitions.</p>\n<p>The <code>ConfigurationManager</code> coordinates configuration updates across multiple sources and applies changes through a phased rollout process. Validation rules prevent configurations that would cause performance problems or break system invariants. The system maintains configuration history and rollback capabilities to recover from problematic changes quickly.</p>\n<table>\n<thead>\n<tr>\n<th>Configuration Component</th>\n<th>Responsibility</th>\n<th>Validation Rules</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ConfigurationManager</code></td>\n<td>Change coordination</td>\n<td>Atomicity, consistency, rollback support</td>\n</tr>\n<tr>\n<td><code>ValidationEngine</code></td>\n<td>Safety checking</td>\n<td>Level hierarchy, handler validity, resource limits</td>\n</tr>\n<tr>\n<td><code>ChangeApplicator</code></td>\n<td>Update execution</td>\n<td>Logger traversal, handler reconfiguration, cache invalidation</td>\n</tr>\n<tr>\n<td><code>ConfigurationHistory</code></td>\n<td>Audit trail</td>\n<td>Change tracking, rollback support, compliance logging</td>\n</tr>\n</tbody></table>\n<p><strong>Environment-Based Configuration</strong></p>\n<p>Environment-based configuration adapts logging behavior automatically based on deployment context, ensuring that development, staging, and production environments have appropriate logging policies without manual configuration management. The environment system detects deployment context through environment variables, service discovery, or configuration files and applies environment-specific overlays to base configurations.</p>\n<p>Different environments have fundamentally different logging needs: development requires verbose output with pretty formatting, staging needs production-like structured logging with extended retention, and production requires optimized performance with security-conscious field filtering. The environment system manages these differences through layered configuration that inherits base settings while overriding environment-specific concerns.</p>\n<table>\n<thead>\n<tr>\n<th>Environment Type</th>\n<th>Configuration Priorities</th>\n<th>Typical Settings</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Development</code></td>\n<td>Readability, debugging</td>\n<td>Pretty formatting, DEBUG level, console output</td>\n</tr>\n<tr>\n<td><code>Staging</code></td>\n<td>Production simulation</td>\n<td>JSON formatting, INFO level, file + remote</td>\n</tr>\n<tr>\n<td><code>Production</code></td>\n<td>Performance, security</td>\n<td>Optimized JSON, WARN level, filtered fields</td>\n</tr>\n<tr>\n<td><code>Testing</code></td>\n<td>Determinism, isolation</td>\n<td>Structured output, captured handlers, no external systems</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Configuration Drift</strong>\nEnvironment-specific configurations can drift over time, leading to difficult-to-reproduce issues where bugs only appear in specific environments. Implement configuration validation tests that verify environment configurations produce expected behavior and maintain configuration documentation that explains environment-specific choices.</p>\n<p><strong>Configuration File Formats</strong></p>\n<p>Configuration file support enables declarative logging setup through YAML, JSON, or TOML files that define logger hierarchies, handler configurations, and formatter settings. Configuration files provide version-controlled logging policies that can be reviewed, tested, and deployed through standard infrastructure processes. The file format supports templating and environment variable substitution for flexible deployment scenarios.</p>\n<p>The configuration parser validates file syntax and semantic correctness before applying changes, preventing invalid configurations from disrupting logging operations. Configuration files support includes and inheritance, enabling modular configuration that can be composed for different deployment scenarios. The system watches configuration files for changes and applies updates automatically when files are modified.</p>\n<table>\n<thead>\n<tr>\n<th>Format</th>\n<th>Strengths</th>\n<th>Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>YAML</code></td>\n<td>Human-readable, comments</td>\n<td>Development configuration, documentation</td>\n</tr>\n<tr>\n<td><code>JSON</code></td>\n<td>Machine-readable, validation</td>\n<td>API-driven configuration, service discovery</td>\n</tr>\n<tr>\n<td><code>TOML</code></td>\n<td>Type-safe, structured</td>\n<td>Production configuration, complex hierarchies</td>\n</tr>\n<tr>\n<td><code>Environment Variables</code></td>\n<td>Container-friendly, simple</td>\n<td>Docker deployment, cloud platforms</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Advanced Configuration Architecture</strong>: The configuration system supports layered composition where base configurations provide common settings and environment-specific overlays add contextual modifications. This pattern enables maintainable configuration that avoids duplication while supporting diverse deployment requirements.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The future extensions build upon the solid foundation established in the core milestones while adding sophisticated capabilities for production environments. These extensions demonstrate the value of forward-looking architectural design that anticipates growth requirements without over-engineering the initial implementation.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Extension Category</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Performance Monitoring</td>\n<td>Built-in metrics collection</td>\n<td>Prometheus + Grafana integration</td>\n</tr>\n<tr>\n<td>Elasticsearch Integration</td>\n<td>HTTP client + JSON serialization</td>\n<td>Official Elasticsearch Python client</td>\n</tr>\n<tr>\n<td>Configuration Management</td>\n<td>File watching + JSON parsing</td>\n<td>etcd/Consul + configuration service</td>\n</tr>\n<tr>\n<td>Async Processing</td>\n<td>Threading module + queues</td>\n<td>asyncio + aiohttp for async handlers</td>\n</tr>\n<tr>\n<td>Load Testing</td>\n<td>Manual threading tests</td>\n<td>Locust or Artillery for realistic load</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended Module Structure</strong></p>\n<p>These extensions integrate cleanly into the existing project structure while maintaining clear separation of concerns:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n├── core/\n│   ├── logger.py              ← Core logger from Milestone 1\n│   ├── formatters.py          ← JSON formatters from Milestone 2\n│   └── context.py             ← Context system from Milestone 3\n├── handlers/\n│   ├── basic.py               ← File/Console handlers from core milestones\n│   ├── elasticsearch.py      ← Elasticsearch integration\n│   ├── metrics.py             ← Metrics extraction handlers\n│   └── tracing.py             ← Distributed tracing integration\n├── performance/\n│   ├── sampling.py            ← Adaptive sampling logic\n│   ├── rate_limiting.py       ← Token bucket rate limiters\n│   └── async_dispatch.py      ← Asynchronous handler dispatch\n├── config/\n│   ├── manager.py             ← Dynamic configuration management\n│   ├── validation.py          ← Configuration safety checking\n│   └── environments.py       ← Environment-specific configuration\n└── extensions/\n    ├── load_testing.py        ← Performance testing utilities\n    └── monitoring.py          ← Extension health monitoring</code></pre></div>\n\n<p><strong>Performance Optimization Starter Code</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.handlers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseHandler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.records </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SamplingConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for adaptive sampling behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    base_sample_rate: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_sample_rate: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_sample_rate: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.01</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    adaptation_window: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    importance_boost: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.importance_boost </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.importance_boost </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'ERROR'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">10.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'FATAL'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">100.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'WARN'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">2.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TokenBucketRateLimiter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe token bucket rate limiter for smooth rate limiting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, tokens_per_second: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, burst_capacity: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.tokens_per_second </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> tokens_per_second</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.burst_capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> burst_capacity</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._tokens </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(burst_capacity)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._last_update </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> acquire</span><span style=\"color:#E1E4E8\">(self, tokens: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Attempt to acquire the specified number of tokens.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if tokens were acquired, False if rate limited.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            now </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate tokens to add based on time elapsed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add tokens to bucket without exceeding burst capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if enough tokens available for request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Deduct tokens if available and return success</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return False if insufficient tokens (rate limited)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AdaptiveSampler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Intelligent sampling that adapts to load and preserves important events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: SamplingConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._current_rate </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config.base_sample_rate</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._decision_cache: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._load_monitor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> LoadMonitor()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> should_sample</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Determine if this log record should be sampled (kept).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Uses correlation ID for consistent sampling decisions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if correlation ID already has cached decision</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate importance multiplier based on log level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Get current system load from load monitor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Adjust sampling rate based on load and importance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Make deterministic decision based on correlation ID hash</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Cache decision for correlation ID consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return sampling decision</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _calculate_adaptive_rate</span><span style=\"color:#E1E4E8\">(self, base_importance: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, system_load: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate sampling rate based on importance and system load.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement adaptive rate calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Higher load should reduce sampling rate, higher importance should increase it</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LoadMonitor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Monitor system load to inform sampling decisions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, measurement_window: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.measurement_window </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> measurement_window</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._cpu_samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._memory_samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._monitoring </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_current_load</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current system load metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Collect current CPU usage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Collect current memory usage  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate average over measurement window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return normalized load values (0.0 to 1.0)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Elasticsearch Handler Infrastructure</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timezone</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, asdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.handlers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseHandler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.records </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LogRecord</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ElasticsearchConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for Elasticsearch integration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hosts: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index_prefix: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"logs\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    batch_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    flush_interval: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_retries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timeout: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BulkProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Efficient bulk processing for Elasticsearch indexing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: ElasticsearchConfig, client):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._batch_buffer: List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._batch_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._last_flush </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_document</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add log record to batch buffer for bulk indexing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        document </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            '_index'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._generate_index_name(record),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            '_source'</span><span style=\"color:#E1E4E8\">: record.to_dict()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._batch_lock:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add document to batch buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if batch is full or flush interval exceeded</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Trigger flush if either condition met</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle buffer overflow protection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_index_name</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate time-based index name for log record.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create index name like \"logs-app-2023-12-01\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use record timestamp and config.index_prefix</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> flush_batch</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Flush current batch to Elasticsearch.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._batch_lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._batch_buffer:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Copy current batch and clear buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Execute bulk index operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle partial failures and retries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update last flush timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return success status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ElasticsearchHandler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">BaseHandler</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handler that indexes log records to Elasticsearch for search and analytics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: ElasticsearchConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">name</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"elasticsearch\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._client </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize Elasticsearch client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._bulk_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> BulkProcessor(config, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._client)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _write_record</span><span style=\"color:#E1E4E8\">(self, record: LogRecord) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Write log record to Elasticsearch via bulk processor.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate Elasticsearch client connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add record to bulk processor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle connection errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Implement circuit breaker logic for outages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Configuration Management Core</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> yaml</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.logger </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> LoggerRegistry</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConfigurationChange</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a configuration change with validation and rollback info.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    change_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    changes: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    previous_values: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    source: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">  # \"file\", \"api\", \"environment\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConfigurationValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validates configuration changes before applying them.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._validation_rules: List[Callable[[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]], List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._register_default_rules()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_configuration</span><span style=\"color:#E1E4E8\">(self, config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Validate configuration and return list of errors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Empty list means configuration is valid.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Run all validation rules against configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Collect all validation errors from rules</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check for configuration consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate resource limits and constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return comprehensive error list</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _register_default_rules</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register built-in validation rules.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add validation rules for log levels, handler configs, etc.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConfigurationManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages dynamic configuration updates with validation and rollback.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, logger_registry: LoggerRegistry):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger_registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logger_registry</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._current_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._config_history: List[ConfigurationChange] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._validator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ConfigurationValidator()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> apply_configuration</span><span style=\"color:#E1E4E8\">(self, new_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], source: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"api\"</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Apply new configuration with validation and rollback support.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if configuration was applied successfully.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate new configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create configuration change record</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply changes atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update logger registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle rollback on failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update configuration history</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> rollback_to_previous</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Rollback to the previous configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find most recent configuration change</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Apply previous values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate rollback configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update logger registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Record rollback in history</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints</strong></p>\n<p>After implementing performance optimizations:</p>\n<ul>\n<li>Run <code>python -m performance.load_test</code> to generate high log volume</li>\n<li>Verify that sampling reduces output volume proportionally</li>\n<li>Check that rate limiting prevents resource exhaustion</li>\n<li>Confirm async dispatch doesn&#39;t block application threads</li>\n</ul>\n<p>After implementing Elasticsearch integration:</p>\n<ul>\n<li>Start local Elasticsearch instance</li>\n<li>Send log entries through <code>ElasticsearchHandler</code></li>\n<li>Query Elasticsearch to verify proper indexing and field mapping</li>\n<li>Test index rotation and retention policies</li>\n</ul>\n<p>After implementing configuration management:</p>\n<ul>\n<li>Modify configuration files and verify hot reload</li>\n<li>Use API to change log levels without restart</li>\n<li>Test configuration validation with invalid settings</li>\n<li>Verify rollback functionality restores previous behavior</li>\n</ul>\n<p><strong>Common Extension Pitfalls</strong></p>\n<p>⚠️ <strong>Pitfall: Elasticsearch Connection Pooling</strong>\nElasticsearch handlers can exhaust connection pools under high load. Implement proper connection pooling with limits and timeouts. Use circuit breakers to prevent cascade failures when Elasticsearch is unavailable.</p>\n<p>⚠️ <strong>Pitfall: Configuration Race Conditions</strong>\nConcurrent configuration updates can create inconsistent states. Use proper locking and atomic updates. Validate that configuration changes don&#39;t conflict with ongoing operations.</p>\n<p>⚠️ <strong>Pitfall: Async Queue Memory Leaks</strong>\nUnbounded async queues consume memory indefinitely under sustained load. Implement queue size limits, overflow handling, and backpressure mechanisms. Monitor queue depths and implement alerting.</p>\n<p>⚠️ <strong>Pitfall: Sampling Bias</strong>\nPoor sampling strategies can lose critical debugging information. Ensure error logs are never sampled, maintain complete traces for sampled requests, and implement importance-based sampling that preserves context around failures.</p>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides essential terminology definitions that support all three milestones, with foundational terms like structured logging and log levels supporting Milestone 1 (Logger Core), JSON formatting and serialization terms supporting Milestone 2 (Structured Output), and correlation ID and context propagation terms supporting Milestone 3 (Context &amp; Correlation).</p>\n</blockquote>\n<p>This glossary provides precise definitions of all key terms used throughout the structured logging system design. Think of this glossary as the shared vocabulary that enables clear communication between team members - just as air traffic controllers use standardized terminology to prevent miscommunication during critical operations, we need consistent definitions to avoid ambiguity when discussing logging system components and behaviors.</p>\n<p>Each term is defined with its specific meaning within the context of this logging system, including how it relates to other components and what behaviors it encompasses. The definitions progress from foundational concepts to more specialized terminology, building a comprehensive understanding of the system&#39;s vocabulary.</p>\n<h3 id=\"core-logging-concepts\">Core Logging Concepts</h3>\n<p><strong>Structured Logging</strong>: A logging approach that produces machine-readable output with consistent, queryable field structure rather than free-form text messages. Unlike traditional string-based logging where information is embedded in unstructured text, structured logging separates message content from contextual metadata, enabling automated log analysis, filtering, and correlation. Each log record contains well-defined fields such as timestamp, level, message, and arbitrary context data serialized in a standardized format like JSON.</p>\n<p><strong>Log Level</strong>: A numeric severity indicator that determines the importance and urgency of a log message. The system uses five standard levels with specific numeric values: <code>DEBUG</code> (10) for detailed diagnostic information useful during development, <code>INFO</code> (20) for general informational messages about normal system operation, <code>WARN</code> (30) for potentially problematic situations that don&#39;t prevent continued operation, <code>ERROR</code> (40) for error conditions that affect specific operations but don&#39;t halt the entire system, and <code>FATAL</code> (50) for critical errors that may cause system shutdown. Log levels enable filtering where messages below a configured threshold are suppressed to reduce noise.</p>\n<p><strong>Log Level Filtering</strong>: The mechanism for suppressing log messages below a configured severity threshold to control output volume and focus on relevant information. When a logger&#39;s minimum level is set to <code>WARN</code>, for example, only messages at <code>WARN</code>, <code>ERROR</code>, and <code>FATAL</code> levels are processed, while <code>DEBUG</code> and <code>INFO</code> messages are discarded before any formatting or output processing occurs. This filtering happens early in the logging pipeline to minimize performance impact from unwanted messages.</p>\n<p><strong>Logger</strong>: The primary interface through which application code generates log messages, maintaining configuration such as name, minimum level, output handlers, and contextual information. Loggers are organized in a hierarchical tree structure where child loggers inherit configuration from their parents unless explicitly overridden. Each logger processes incoming messages by checking level thresholds, enriching records with context, applying formatting, and dispatching to configured output destinations.</p>\n<p><strong>Logger Hierarchy</strong>: A tree structure of parent-child logger relationships that enables organized configuration management and context inheritance. Loggers are typically named using dot-separated paths like <code>com.example.service.database</code> where each segment represents a level in the hierarchy. Child loggers automatically inherit configuration settings like minimum level and output handlers from their parents, but can override these settings locally. This hierarchy prevents configuration duplication and provides logical organization matching application structure.</p>\n<h3 id=\"data-structures-and-records\">Data Structures and Records</h3>\n<p><strong>LogRecord</strong>: The fundamental data structure representing a single log event, containing all information needed to format and output the message. A LogRecord includes the timestamp when the event occurred, the numeric log level, the primary message text, the name of the originating logger, and a dictionary of contextual key-value pairs. LogRecords are immutable once created to ensure consistency across multiple output handlers and prevent accidental modification during processing.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>timestamp</code></td>\n<td>str</td>\n<td>ISO 8601 formatted UTC timestamp when the log event occurred</td>\n</tr>\n<tr>\n<td><code>level</code></td>\n<td>int</td>\n<td>Numeric log level indicating message severity (10-50 range)</td>\n</tr>\n<tr>\n<td><code>message</code></td>\n<td>str</td>\n<td>Primary descriptive text explaining what happened</td>\n</tr>\n<tr>\n<td><code>logger_name</code></td>\n<td>str</td>\n<td>Hierarchical name of the logger that created this record</td>\n</tr>\n<tr>\n<td><code>context</code></td>\n<td>Dict[str, Any]</td>\n<td>Additional key-value pairs providing contextual information</td>\n</tr>\n</tbody></table>\n<p><strong>Context</strong>: A dictionary of key-value pairs that provides additional contextual information about the environment, request, or operation when a log event occurs. Context data automatically propagates through nested function calls and is inherited by child loggers, eliminating the need to manually pass contextual information through method parameters. Context fields commonly include correlation IDs, user identifiers, request URLs, database connection details, and business-specific metadata that aids in log analysis and debugging.</p>\n<p><strong>Correlation ID</strong>: A unique identifier that links related log entries across service boundaries, function calls, and asynchronous operations within the same logical request or transaction. Correlation IDs are typically generated at request entry points and automatically injected into every log record within that request scope. This enables distributed tracing where logs from multiple services, components, or threads can be correlated to understand the complete flow of a user request through the system.</p>\n<h3 id=\"output-and-formatting\">Output and Formatting</h3>\n<p><strong>Handler</strong>: An abstract component responsible for delivering formatted log records to a specific output destination such as standard output, files, remote logging services, or databases. Each handler operates independently with its own error recovery, buffering, and retry logic to ensure that failures in one output destination don&#39;t affect others. Handlers can filter records based on level or content, apply destination-specific formatting, and implement circuit breaker patterns to handle temporary outages gracefully.</p>\n<p><strong>Handler Dispatch</strong>: The routing mechanism that delivers log records to one or more configured output handlers, ensuring that each handler receives a copy of the record for independent processing. The dispatch system handles concurrent access safely, manages handler failures through circuit breakers, and maintains buffer queues for temporary storage when handlers are unavailable. Failed handlers are automatically retried with exponential backoff while continuing to serve working destinations.</p>\n<p><strong>Formatter</strong>: A component that converts LogRecord objects into formatted strings suitable for output to specific destinations. Formatters implement different output styles such as single-line JSON for machine processing, colored console output for human readability during development, or custom formats required by specific log aggregation systems. The formatter system supports pluggable architecture where custom formatters can be registered and selected by name.</p>\n<p><strong>JSON Formatter</strong>: A concrete formatter implementation that serializes LogRecord objects as single-line JSON strings with consistent field ordering and proper handling of complex data types. The JSON formatter includes circular reference protection to prevent infinite loops when serializing objects that reference themselves, automatic timestamp formatting, and configurable field inclusion/exclusion. Output is optimized for log aggregation systems that expect one JSON object per line.</p>\n<p><strong>Pretty Formatter</strong>: A human-readable formatter designed for development and debugging that produces colored, indented output optimized for console viewing. Pretty formatters automatically detect terminal color capabilities, apply syntax highlighting to different log levels, format timestamps in human-friendly formats, and optionally pretty-print JSON context data with indentation. This formatter prioritizes readability over machine processing efficiency.</p>\n<h3 id=\"context-management-and-propagation\">Context Management and Propagation</h3>\n<p><strong>Context Propagation</strong>: The mechanism for automatically carrying contextual information through nested function calls, asynchronous operations, and service boundaries without requiring explicit parameter passing. Context propagation uses thread-local storage for synchronous code and async-local storage for asynchronous operations, ensuring that context fields set at request entry points are available throughout the entire request processing pipeline.</p>\n<p><strong>Ambient Context</strong>: Contextual information that is automatically available anywhere within the current execution scope without being explicitly passed through method parameters. Ambient context includes correlation IDs, user session data, request metadata, and business context that was established earlier in the call chain. This pattern eliminates the need to modify function signatures throughout the codebase when adding new contextual information.</p>\n<p><strong>Context Inheritance</strong>: The behavior where child contexts automatically inherit all key-value pairs from their parent contexts and can add additional fields without affecting the parent. When a function creates a nested logging context, it receives all fields from the current context plus any new fields it adds locally. Changes made in child contexts are isolated and don&#39;t propagate back to parent contexts, ensuring proper scoping and preventing side effects.</p>\n<p><strong>Async Context Bridge</strong>: Infrastructure that preserves logging context when crossing asynchronous operation boundaries such as task creation, coroutine execution, and callback invocation. The bridge automatically captures the current context when async operations are initiated and restores that context when the async code executes, ensuring that correlation IDs and contextual information remain available throughout the entire request processing flow regardless of thread switches or event loop scheduling.</p>\n<h3 id=\"thread-safety-and-concurrency\">Thread Safety and Concurrency</h3>\n<p><strong>Thread Safety</strong>: The property that logging operations produce correct results when called concurrently from multiple threads without external synchronization. Thread-safe logging ensures that log records are not corrupted, context information is not mixed between threads, and internal data structures remain consistent under concurrent access. This is achieved through careful locking, immutable data structures, and atomic operations on shared state.</p>\n<p><strong>Race Condition</strong>: A concurrency bug where the correctness of logging operations depends on the relative timing of thread execution, potentially leading to corrupted output, mixed log records, or inconsistent context information. Common race conditions in logging systems include context corruption when multiple threads modify shared context simultaneously, interleaved output when multiple threads write to the same destination, and inconsistent state when logger configuration changes occur concurrently with logging operations.</p>\n<p><strong>Immutability</strong>: The design principle where LogRecord objects and context dictionaries cannot be modified after creation, preventing accidental changes that could corrupt logs or create race conditions. Immutable objects can be safely shared between multiple handlers and threads without synchronization overhead. When context changes are needed, new immutable objects are created rather than modifying existing ones.</p>\n<h3 id=\"error-handling-and-recovery\">Error Handling and Recovery</h3>\n<p><strong>Circuit Breaker Pattern</strong>: An error handling mechanism that prevents cascade failures by automatically disabling failed handlers and periodically attempting recovery. When a handler experiences consecutive failures exceeding a configured threshold, the circuit breaker opens and stops sending records to that handler while allowing other handlers to continue operating normally. The circuit breaker periodically attempts to close by testing the failed handler, automatically resuming normal operation when the handler recovers.</p>\n<p><strong>Graceful Degradation</strong>: The system&#39;s ability to maintain partial functionality when individual components fail, ensuring that logging continues to work even when some output destinations are unavailable. Failed file handlers fall back to console output, failed network handlers buffer records locally for later retry, and serialization failures are logged with simplified fallback representations rather than crashing the application.</p>\n<p><strong>Handler Isolation</strong>: The design principle that failures in one output handler do not affect the operation of other handlers or the logging system as a whole. Each handler maintains independent error state, recovery logic, and buffer management. When one handler fails, other handlers continue processing records normally, and the failed handler can recover independently without affecting system-wide logging operation.</p>\n<p><strong>Safe Serialization</strong>: JSON encoding with protection against edge cases that could cause failures or infinite loops, including circular references, non-serializable objects, and excessively large data structures. Safe serialization detects circular references and replaces them with reference markers, converts non-serializable objects to string representations, and truncates large objects to prevent memory exhaustion while preserving essential information.</p>\n<h3 id=\"performance-and-optimization\">Performance and Optimization</h3>\n<p><strong>Buffer Management</strong>: Intelligent queuing of log records when output handlers are temporarily unavailable, with configurable size limits and memory usage controls to prevent unbounded growth. Buffered records are automatically delivered when handlers recover, with oldest records discarded if buffer limits are exceeded. Buffer management includes both in-memory queues for short-term outages and persistent storage for longer-term handler failures.</p>\n<p><strong>Level Filtering Optimization</strong>: Early rejection of log messages below the configured threshold before expensive operations like context enrichment, formatting, or serialization occur. Level filtering uses numeric comparison for efficiency and caches effective levels after walking the logger hierarchy to avoid repeated parent traversal. This optimization ensures that disabled log levels have minimal performance impact.</p>\n<p><strong>Lazy Evaluation</strong>: Deferring expensive operations like complex context serialization, timestamp formatting, or message string formatting until they are actually needed by an active handler. If no handlers are configured or all handlers reject a message due to level filtering, expensive formatting operations are skipped entirely, improving performance for disabled log levels.</p>\n<h3 id=\"testing-and-debugging\">Testing and Debugging</h3>\n<p><strong>Milestone Checkpoints</strong>: Concrete verification criteria that validate correct implementation after completing each development stage. Checkpoints specify expected behavior, output formats, performance characteristics, and error handling that should be observed when testing the implemented functionality. Each checkpoint includes specific test commands, expected results, and troubleshooting guidance for common implementation issues.</p>\n<p><strong>Integration Testing</strong>: Comprehensive testing that verifies correct interaction between logging system components under realistic production conditions, including concurrent access, handler failures, context propagation across async boundaries, and end-to-end request tracing. Integration tests simulate real-world scenarios like network outages, disk full conditions, and high-concurrency load to ensure robust system behavior.</p>\n<p><strong>Trace Logging</strong>: An internal debugging system that records the behavior of the logging infrastructure itself, providing visibility into handler dispatch, context propagation, error recovery, and performance characteristics. Trace logging helps diagnose issues like why certain log messages are not appearing, how context flows through the system, and where performance bottlenecks occur during high-volume logging.</p>\n<h3 id=\"advanced-features\">Advanced Features</h3>\n<p><strong>Adaptive Sampling</strong>: Intelligent sampling that automatically adjusts log retention rates based on system load, message importance, and available resources to maintain performance while preserving critical information. Adaptive sampling uses algorithms that increase sampling rates for error conditions and correlation contexts while reducing rates for routine operational messages during high-load periods.</p>\n<p><strong>Rate Limiting</strong>: Controlling logging throughput to prevent system overload during high-volume scenarios, using algorithms like token bucket rate limiting that allow burst capacity while maintaining sustainable average rates. Rate limiting can be applied per logger, per level, or per context to prevent specific components from overwhelming the logging system.</p>\n<p><strong>Dynamic Reconfiguration</strong>: The ability to change logging behavior at runtime without restarting the application, including adjusting log levels, adding or removing handlers, modifying formatter settings, and updating context propagation rules. Dynamic reconfiguration enables responsive troubleshooting and performance tuning in production environments without service interruption.</p>\n<p><strong>Bulk Indexing</strong>: Batching multiple log records into single operations for efficient delivery to external systems like Elasticsearch or database storage, reducing network overhead and improving throughput for high-volume logging scenarios. Bulk indexing includes automatic flushing based on time intervals or batch sizes, with retry logic for partial failures.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The terminology defined above forms the foundation for implementing a production-grade structured logging system. Understanding these concepts and their relationships is essential for making correct design decisions and avoiding common implementation pitfalls.</p>\n<p><strong>Key Term Relationships:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Primary Term</th>\n<th>Related Terms</th>\n<th>Relationship Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>LogRecord</code></td>\n<td><code>Context</code>, <code>LogLevel</code>, <code>Formatter</code></td>\n<td>LogRecord contains Context data, has a LogLevel, processed by Formatters</td>\n</tr>\n<tr>\n<td><code>Logger</code></td>\n<td><code>Logger Hierarchy</code>, <code>Handler Dispatch</code>, <code>Level Filtering</code></td>\n<td>Logger participates in hierarchy, dispatches to handlers, filters by level</td>\n</tr>\n<tr>\n<td><code>Context</code></td>\n<td><code>Context Propagation</code>, <code>Correlation ID</code>, <code>Context Inheritance</code></td>\n<td>Context propagates through calls, contains correlation ID, supports inheritance</td>\n</tr>\n<tr>\n<td><code>Handler</code></td>\n<td><code>Circuit Breaker</code>, <code>Buffer Management</code>, <code>Safe Serialization</code></td>\n<td>Handler uses circuit breaker, manages buffers, performs safe serialization</td>\n</tr>\n<tr>\n<td><code>Formatter</code></td>\n<td><code>JSON Formatter</code>, <code>Pretty Formatter</code>, <code>Safe Serialization</code></td>\n<td>Formatters are concrete implementations using safe serialization techniques</td>\n</tr>\n</tbody></table>\n<p><strong>Common Terminology Mistakes:</strong></p>\n<p>⚠️ <strong>Pitfall: Confusing &quot;Context&quot; with &quot;Configuration&quot;</strong>\nContext refers to runtime key-value data that describes the current execution environment (correlation IDs, user session, request metadata), while configuration refers to static settings that control logging behavior (minimum levels, handler settings, formatter choices). Context flows through application execution and changes frequently, while configuration is typically set at startup and changes infrequently.</p>\n<p>⚠️ <strong>Pitfall: Misunderstanding &quot;Thread Safety&quot; vs &quot;Concurrent Performance&quot;</strong>\nThread safety means operations produce correct results under concurrent access, which is a correctness requirement. Concurrent performance refers to how well the system scales under concurrent load, which is an efficiency consideration. A system can be thread-safe but perform poorly under concurrency due to excessive locking, or can have good concurrent performance but be thread-unsafe due to race conditions.</p>\n<p>⚠️ <strong>Pitfall: Conflating &quot;Structured Logging&quot; with &quot;JSON Format&quot;</strong>\nStructured logging is the architectural approach of separating message content from contextual metadata in consistent, queryable field structure. JSON is one possible serialization format for structured logs, but structured logging can also use formats like XML, Protocol Buffers, or custom binary formats. The key is consistent field structure, not the specific serialization mechanism.</p>\n<p>This glossary provides the vocabulary foundation needed to understand, implement, and maintain the structured logging system. Refer back to these definitions when encountering unfamiliar terms in other sections of the design document.</p>\n","toc":[{"level":1,"text":"Structured Logging System: Design Document","id":"structured-logging-system-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"The Airport Control Tower Analogy","id":"the-airport-control-tower-analogy"},{"level":3,"text":"Traditional vs Structured Logging","id":"traditional-vs-structured-logging"},{"level":3,"text":"Production Environment Challenges","id":"production-environment-challenges"},{"level":4,"text":"Thread Safety and Concurrent Access","id":"thread-safety-and-concurrent-access"},{"level":4,"text":"Performance at Scale","id":"performance-at-scale"},{"level":4,"text":"Distributed Correlation Across Services","id":"distributed-correlation-across-services"},{"level":4,"text":"Log Aggregation and Operational Requirements","id":"log-aggregation-and-operational-requirements"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"A. Technology Recommendations","id":"a-technology-recommendations"},{"level":4,"text":"B. Recommended File/Module Structure","id":"b-recommended-filemodule-structure"},{"level":4,"text":"C. Infrastructure Starter Code","id":"c-infrastructure-starter-code"},{"level":4,"text":"D. Core Logic Skeleton Code","id":"d-core-logic-skeleton-code"},{"level":4,"text":"E. Language-Specific Hints","id":"e-language-specific-hints"},{"level":4,"text":"F. Milestone Checkpoint","id":"f-milestone-checkpoint"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Functional Requirements","id":"functional-requirements"},{"level":3,"text":"Non-Functional Requirements","id":"non-functional-requirements"},{"level":3,"text":"Explicit Non-Goals","id":"explicit-non-goals"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Component Overview: Core Components: Logger, LogRecord, Handlers, Formatters, and Context Manager","id":"component-overview-core-components-logger-logrecord-handlers-formatters-and-context-manager"},{"level":4,"text":"Logger Component","id":"logger-component"},{"level":4,"text":"LogRecord Structure","id":"logrecord-structure"},{"level":4,"text":"Handler Dispatch System","id":"handler-dispatch-system"},{"level":4,"text":"Formatter Plugin System","id":"formatter-plugin-system"},{"level":4,"text":"Context Manager","id":"context-manager"},{"level":3,"text":"Data Flow Pipeline: How log messages flow from application code through formatters to output destinations","id":"data-flow-pipeline-how-log-messages-flow-from-application-code-through-formatters-to-output-destinations"},{"level":4,"text":"Stage 1: Message Creation and Level Filtering","id":"stage-1-message-creation-and-level-filtering"},{"level":4,"text":"Stage 2: LogRecord Construction and Context Enrichment","id":"stage-2-logrecord-construction-and-context-enrichment"},{"level":4,"text":"Stage 3: Handler Dispatch and Parallel Processing","id":"stage-3-handler-dispatch-and-parallel-processing"},{"level":4,"text":"Stage 4: Formatting and Serialization","id":"stage-4-formatting-and-serialization"},{"level":4,"text":"Stage 5: Output Delivery and Error Recovery","id":"stage-5-output-delivery-and-error-recovery"},{"level":3,"text":"Recommended Module Structure: File organization and package layout for clean separation of concerns","id":"recommended-module-structure-file-organization-and-package-layout-for-clean-separation-of-concerns"},{"level":4,"text":"Root Package Structure","id":"root-package-structure"},{"level":4,"text":"Core Module Responsibilities","id":"core-module-responsibilities"},{"level":4,"text":"Milestone-Aligned Development Structure","id":"milestone-aligned-development-structure"},{"level":4,"text":"Testing Structure Alignment","id":"testing-structure-alignment"},{"level":4,"text":"Import Strategy and Public APIs","id":"import-strategy-and-public-apis"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Complete Infrastructure Starter Code","id":"complete-infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeletons","id":"core-logic-skeletons"},{"level":4,"text":"File Structure Setup","id":"file-structure-setup"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Common Debugging Issues","id":"common-debugging-issues"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"LogRecord Structure","id":"logrecord-structure"},{"level":3,"text":"Log Level Hierarchy","id":"log-level-hierarchy"},{"level":3,"text":"Context Data Model","id":"context-data-model"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Logger Core Design","id":"logger-core-design"},{"level":3,"text":"Mental Model: The News Organization","id":"mental-model-the-news-organization"},{"level":3,"text":"Logger Hierarchy System","id":"logger-hierarchy-system"},{"level":4,"text":"Hierarchy Structure and Naming","id":"hierarchy-structure-and-naming"},{"level":4,"text":"Configuration Inheritance Behavior","id":"configuration-inheritance-behavior"},{"level":4,"text":"Logger Factory and Lifecycle","id":"logger-factory-and-lifecycle"},{"level":3,"text":"Log Level Filtering","id":"log-level-filtering"},{"level":4,"text":"Level Hierarchy and Numeric Ordering","id":"level-hierarchy-and-numeric-ordering"},{"level":4,"text":"Efficient Level Checking","id":"efficient-level-checking"},{"level":4,"text":"Runtime Level Reconfiguration","id":"runtime-level-reconfiguration"},{"level":3,"text":"Thread Safety Design","id":"thread-safety-design"},{"level":4,"text":"Locking Strategy and Granularity","id":"locking-strategy-and-granularity"},{"level":4,"text":"Handler Dispatch Concurrency","id":"handler-dispatch-concurrency"},{"level":4,"text":"Memory Consistency and Visibility","id":"memory-consistency-and-visibility"},{"level":3,"text":"Handler Dispatch Mechanism","id":"handler-dispatch-mechanism"},{"level":4,"text":"Multi-Destination Routing","id":"multi-destination-routing"},{"level":4,"text":"Error Isolation and Recovery","id":"error-isolation-and-recovery"},{"level":4,"text":"Asynchronous Handler Support","id":"asynchronous-handler-support"},{"level":4,"text":"Performance Optimization","id":"performance-optimization"},{"level":4,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton","id":"core-logic-skeleton"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Structured Output Design","id":"structured-output-design"},{"level":3,"text":"JSON Formatter","id":"json-formatter"},{"level":3,"text":"Formatter Plugin System","id":"formatter-plugin-system"},{"level":3,"text":"Timestamp Formatting","id":"timestamp-formatting"},{"level":3,"text":"Developer-Friendly Pretty Print","id":"developer-friendly-pretty-print"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Context and Correlation Design","id":"context-and-correlation-design"},{"level":3,"text":"Correlation ID System","id":"correlation-id-system"},{"level":3,"text":"Context Propagation","id":"context-propagation"},{"level":3,"text":"Async Context Bridge","id":"async-context-bridge"},{"level":3,"text":"Request Context Middleware","id":"request-context-middleware"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"The Safety Net Analogy","id":"the-safety-net-analogy"},{"level":3,"text":"Handler Failure Recovery","id":"handler-failure-recovery"},{"level":4,"text":"Handler Error States","id":"handler-error-states"},{"level":4,"text":"Failure Detection and Response","id":"failure-detection-and-response"},{"level":4,"text":"Buffer Management for Failed Handlers","id":"buffer-management-for-failed-handlers"},{"level":3,"text":"Serialization Edge Cases","id":"serialization-edge-cases"},{"level":4,"text":"Non-Serializable Object Handling","id":"non-serializable-object-handling"},{"level":4,"text":"Circular Reference Protection","id":"circular-reference-protection"},{"level":4,"text":"Large Object Handling","id":"large-object-handling"},{"level":4,"text":"Encoding Error Recovery","id":"encoding-error-recovery"},{"level":3,"text":"Context Cleanup and Memory Management","id":"context-cleanup-and-memory-management"},{"level":4,"text":"Context Lifecycle Management","id":"context-lifecycle-management"},{"level":4,"text":"Memory Leak Prevention","id":"memory-leak-prevention"},{"level":4,"text":"Async Context Bridge Implementation","id":"async-context-bridge-implementation"},{"level":4,"text":"Context Memory Monitoring","id":"context-memory-monitoring"},{"level":3,"text":"Common Pitfalls in Error Handling","id":"common-pitfalls-in-error-handling"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Error Handling Skeleton","id":"core-error-handling-skeleton"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Unit Testing Approach","id":"unit-testing-approach"},{"level":3,"text":"Integration Testing Scenarios","id":"integration-testing-scenarios"},{"level":3,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Common Implementation Pitfalls","id":"common-implementation-pitfalls"},{"level":4,"text":"Race Conditions in Logger Hierarchy","id":"race-conditions-in-logger-hierarchy"},{"level":4,"text":"Context Propagation Failures","id":"context-propagation-failures"},{"level":4,"text":"Blocking I/O in Log Handler Hot Path","id":"blocking-io-in-log-handler-hot-path"},{"level":4,"text":"Memory Leaks in Context Management","id":"memory-leaks-in-context-management"},{"level":3,"text":"Debugging Techniques","id":"debugging-techniques"},{"level":4,"text":"Adding Trace Logging for Internal Operations","id":"adding-trace-logging-for-internal-operations"},{"level":4,"text":"Inspecting Context State","id":"inspecting-context-state"},{"level":4,"text":"Testing Thread Safety","id":"testing-thread-safety"},{"level":3,"text":"Symptom-Cause-Fix Troubleshooting","id":"symptom-cause-fix-troubleshooting"},{"level":4,"text":"Thread Safety and Concurrency Issues","id":"thread-safety-and-concurrency-issues"},{"level":4,"text":"Context Propagation Problems","id":"context-propagation-problems"},{"level":4,"text":"Serialization and Formatting Issues","id":"serialization-and-formatting-issues"},{"level":4,"text":"Handler and Output Destination Problems","id":"handler-and-output-destination-problems"},{"level":4,"text":"Performance and Resource Issues","id":"performance-and-resource-issues"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Module Structure","id":"recommended-module-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Language-Specific Python Debugging Tips","id":"language-specific-python-debugging-tips"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Performance Optimizations","id":"performance-optimizations"},{"level":3,"text":"Advanced Output Destinations","id":"advanced-output-destinations"},{"level":3,"text":"Configuration Management","id":"configuration-management"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Core Logging Concepts","id":"core-logging-concepts"},{"level":3,"text":"Data Structures and Records","id":"data-structures-and-records"},{"level":3,"text":"Output and Formatting","id":"output-and-formatting"},{"level":3,"text":"Context Management and Propagation","id":"context-management-and-propagation"},{"level":3,"text":"Thread Safety and Concurrency","id":"thread-safety-and-concurrency"},{"level":3,"text":"Error Handling and Recovery","id":"error-handling-and-recovery"},{"level":3,"text":"Performance and Optimization","id":"performance-and-optimization"},{"level":3,"text":"Testing and Debugging","id":"testing-and-debugging"},{"level":3,"text":"Advanced Features","id":"advanced-features"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"}],"title":"Structured Logging System: Design Document","markdown":"# Structured Logging System: Design Document\n\n\n## Overview\n\nA production-grade structured logging system that provides thread-safe, multi-level logging with JSON output and distributed request tracing. The key architectural challenge is designing a flexible handler dispatch system that maintains performance while supporting context propagation across async boundaries.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** This section provides foundational context for all milestones by establishing why structured logging is essential and what challenges it solves in production environments.\n\n### The Airport Control Tower Analogy\n\nThink of traditional logging in software systems like early aviation communication — pilots would occasionally radio in their status using informal, unstructured messages: \"Approaching from the southeast, low on fuel, weather looks rough.\" This worked when there were only a few planes in the sky, but as air traffic grew exponentially, this ad-hoc communication created chaos. Controllers couldn't quickly filter messages by urgency, correlate related communications from the same flight, or efficiently route information to the right teams.\n\nModern air traffic control solved this through **structured communication protocols**. Every radio transmission follows a standardized format: aircraft identification, location coordinates, altitude, heading, fuel status, and request type — all in predictable fields that controllers can instantly parse, filter, and route. A controller can immediately spot all \"low fuel\" situations, trace the complete journey of flight AA1234, or correlate weather reports with affected routes.\n\nThis transformation mirrors exactly what happens when software systems evolve from traditional logging to structured logging. In small applications with a single developer, informal log messages work fine: \"User login failed\", \"Database connection lost\", \"Processing order 12345\". But in production environments with hundreds of services, millions of requests, and distributed teams, these unstructured logs become as chaotic as those early aviation radio calls.\n\n**Structured logging** transforms each log entry into a standardized \"flight plan\" with consistent fields: timestamp, severity level, service name, request ID, user ID, operation type, and contextual metadata. Operations teams can instantly filter by error severity, trace all actions for a specific user request, correlate events across multiple services, and route alerts to the appropriate team — just like air traffic controllers managing complex airspace.\n\nThe analogy extends to **correlation IDs** (like flight numbers that persist across different control zones), **log levels** (like priority codes for emergency vs. routine communications), and **context propagation** (like flight plans that follow aircraft across multiple control centers). Without this structure, debugging production issues becomes like searching for a specific airplane in busy airspace using only fragments of overheard conversations.\n\n### Traditional vs Structured Logging\n\nThe fundamental difference between traditional and structured logging lies in **queryability** and **context preservation**. Traditional logging treats each log message as an opaque string, while structured logging treats it as a data record with well-defined fields that can be indexed, filtered, and aggregated.\n\n| Aspect | Traditional String Logs | Structured JSON Logs | Impact on Operations |\n|--------|------------------------|---------------------|---------------------|\n| **Format** | `\"2024-01-15 ERROR: Login failed for user john_doe\"` | `{\"timestamp\": \"2024-01-15T10:30:00Z\", \"level\": \"ERROR\", \"event\": \"login_failed\", \"user_id\": \"john_doe\", \"ip_address\": \"192.168.1.100\"}` | Structured logs enable precise queries like \"all login failures from IP range X\" |\n| **Parsing** | Requires regex patterns, brittle text parsing | Direct JSON deserialization into typed objects | 10x faster log ingestion, no parsing errors |\n| **Searchability** | Full-text search only: `grep \"Login failed\" logfile` | Field-specific queries: `level:ERROR AND event:login_failed` | Precise filtering reduces noise from millions of log entries |\n| **Context Linking** | Manual correlation using scattered string fragments | Automatic correlation via request_id field | Complete request trace across 20+ microservices |\n| **Alerting Rules** | Complex regex patterns: `/ERROR.*database.*timeout/` | Simple field matching: `level:ERROR AND component:database AND error_type:timeout` | Fewer false positives, faster alert setup |\n| **Aggregation** | Impossible without custom parsing scripts | Built-in: `GROUP BY error_type`, `COUNT by user_id` | Real-time dashboards showing error trends |\n| **Multi-line Handling** | Stack traces break log parsers, require special handling | Stack trace stored as structured field, never breaks parsing | Reliable log shipping even with complex Java exceptions |\n| **Performance** | String concatenation, formatting overhead | Direct object serialization, minimal string operations | 50% reduction in logging CPU overhead |\n| **Schema Evolution** | Adding fields breaks existing parsers | New fields automatically available, backward compatible | Zero-downtime log format improvements |\n| **Debugging Workflow** | `grep` → `awk` → manual correlation → spreadsheet analysis | Direct database queries → automatic correlation → interactive dashboards | 5 minutes instead of 2 hours to diagnose issues |\n\nThe transition from traditional to structured logging parallels the evolution from manually parsing log files to treating logs as a **time-series database**. Each log entry becomes a data point with dimensions (service, user, operation) and metrics (response time, error rate, resource usage) that can be aggregated, visualized, and analyzed in real-time.\n\n> **Critical Insight**: The value of structured logging grows exponentially with system complexity. A monolithic application with 100 daily requests might not benefit significantly, but a microservices architecture handling 10,000 requests per second across 50 services becomes impossible to debug without structured, correlated logs.\n\n### Production Environment Challenges\n\nProduction logging systems face four critical challenges that simple print statements or basic file logging cannot address: **thread safety**, **performance at scale**, **distributed correlation**, and **operational reliability**. Each challenge requires specific architectural decisions that shape the entire logging system design.\n\n#### Thread Safety and Concurrent Access\n\nIn production environments, multiple threads simultaneously generate log messages, creating **race conditions** that can corrupt output, interleave partial messages, or cause deadlocks. The challenge extends beyond simple file writing to include context management, formatter state, and handler dispatch.\n\n| Challenge | Manifestation | Technical Requirement |\n|-----------|---------------|----------------------|\n| **Interleaved Output** | Two threads writing \"User login\" and \"Database query\" produce garbled output: `\"User Datalogbase quin\"` | Atomic write operations with message-level locking |\n| **Corrupted JSON** | Concurrent JSON serialization creates invalid output: `{\"level\":\"INFO\"\"level\":\"ERROR\"}` | Thread-safe formatter instances or per-thread serialization buffers |\n| **Context Confusion** | Thread A's user_id appears in Thread B's log messages | Thread-local context storage with proper isolation boundaries |\n| **Handler State** | File handles, network connections shared unsafely between threads | Synchronized handler operations or thread-safe I/O abstractions |\n| **Deadlock Risk** | Complex locking hierarchies between logger, handlers, and formatters | Careful lock ordering and non-blocking dispatch patterns |\n\nThe thread safety challenge is compounded by **async/await patterns** in modern applications. When an async task yields control, its logging context must be preserved and restored correctly, even when the task resumes on a different thread. This requires sophisticated context propagation mechanisms that go beyond simple thread-local storage.\n\n#### Performance at Scale\n\nProduction logging systems must handle thousands of log messages per second while adding minimal overhead to application performance. The challenge involves both **computational efficiency** (CPU cycles for formatting and serialization) and **I/O efficiency** (disk writes and network transmission).\n\n| Scale Factor | Performance Requirement | Design Implication |\n|--------------|------------------------|-------------------|\n| **Message Volume** | 10,000+ messages/second per service | Non-blocking handler dispatch, async I/O operations |\n| **Context Size** | 50+ fields per message (user, request, trace data) | Efficient context merging, lazy field evaluation |\n| **Handler Count** | 5+ destinations per message (file, stdout, metrics, remote) | Parallel handler execution, failure isolation |\n| **Memory Pressure** | Minimal allocation in hot logging path | Object pooling, pre-allocated buffers, zero-copy serialization |\n| **Latency Sensitivity** | <1ms added latency to business logic | Background processing, batched network operations |\n\nThe performance challenge creates tension between **completeness** and **speed**. Adding rich context improves debugging capability but increases serialization cost. The solution requires **lazy evaluation** strategies where expensive operations (like stack trace capture or large object serialization) only occur when the log level threshold is met.\n\n> **Design Principle**: The hot path for logging (from application call to handler dispatch) must remain synchronous and fast, while expensive operations (network transmission, disk syncing, complex formatting) should be asynchronous and non-blocking.\n\n#### Distributed Correlation Across Services\n\nModern applications span multiple services, each generating independent log streams. The critical challenge is **correlating related events** across service boundaries to reconstruct complete user request flows or diagnose cross-service failures.\n\n| Correlation Scenario | Technical Challenge | Required Infrastructure |\n|---------------------|-------------------|------------------------|\n| **User Request Trace** | HTTP request flows through 8 services, each logs independently | Correlation ID propagation via HTTP headers and message queues |\n| **Database Transaction** | Single transaction touches 3 services, fails in service 2 | Transaction ID preservation across service calls and rollbacks |\n| **Background Job Chain** | Job spawns 5 child jobs across different workers | Parent-child job ID relationships with hierarchical context |\n| **Error Cascade** | Timeout in service A causes errors in services B, C, D | Temporal correlation with root cause identification |\n| **Performance Investigation** | Slow response affects multiple upstream services | Request timing correlation with service dependency mapping |\n\nThe correlation challenge requires **context propagation protocols** that work across different transport mechanisms (HTTP headers, message queue properties, gRPC metadata) and programming languages. The logging system must automatically extract correlation IDs from incoming requests and inject them into outgoing requests without requiring explicit developer intervention.\n\n#### Log Aggregation and Operational Requirements\n\nProduction environments generate terabytes of log data daily, requiring **reliable collection**, **efficient transport**, and **fault-tolerant storage**. The logging system must handle network failures, disk space exhaustion, and downstream service outages without losing critical diagnostic information.\n\n| Operational Challenge | Failure Mode | Recovery Mechanism |\n|-----------------------|--------------|-------------------|\n| **Network Partition** | Remote log collector becomes unreachable for 30 minutes | Local buffering with disk spillover, automatic retry with exponential backoff |\n| **Disk Space Exhaustion** | Log files consume all available disk space | Automatic log rotation, compression, oldest-first deletion with retention policies |\n| **Handler Failure** | Elasticsearch cluster goes down, losing audit logs | Multi-destination dispatch with independent failure domains |\n| **Configuration Errors** | Invalid JSON formatter crashes logging pipeline | Graceful degradation to plain text output, error isolation per handler |\n| **Memory Pressure** | Log buffering consumes excessive memory during bursts | Backpressure mechanisms, emergency log level elevation, buffer size limits |\n\nThe aggregation challenge extends to **log format evolution**. Production systems must support gradual rollouts of new log fields without breaking existing parsing infrastructure. This requires **schema compatibility strategies** and **version negotiation protocols** between log producers and consumers.\n\n> **Operational Reality**: In production environments, the logging system itself becomes a critical piece of infrastructure that must be monitored, alerted on, and maintained. Logger failures can mask application issues, making robust error handling and self-monitoring essential design requirements.\n\nThese production challenges drive the architectural decisions throughout the logging system design. **Thread safety** requirements shape the locking strategy and context isolation mechanisms. **Performance constraints** determine the handler dispatch architecture and serialization approaches. **Correlation needs** influence the context propagation design and metadata extraction patterns. **Operational requirements** drive error handling strategies and configuration management approaches.\n\nThe next sections will show how each challenge translates into specific design decisions, with Architecture Decision Records (ADRs) documenting the rationale behind each choice and the trade-offs involved.\n\n### Implementation Guidance\n\nThis implementation guidance provides practical foundations for building the structured logging system, including technology recommendations and starter infrastructure that supports the design principles established above.\n\n#### A. Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Rationale |\n|-----------|---------------|-----------------|-----------|\n| **JSON Serialization** | `json` standard library | `orjson` or `ujson` for performance | Standard library provides reliability; advanced options needed for >1000 msgs/sec |\n| **Thread Safety** | `threading.Lock()` with context managers | `concurrent.futures` with thread pools | Simple locks work for basic scenarios; thread pools handle async dispatch better |\n| **Context Storage** | `threading.local()` for thread contexts | `contextvars` for async-compatible contexts | Thread-local sufficient for sync apps; contextvars required for asyncio applications |\n| **File I/O** | Built-in `open()` with manual rotation | `logging.handlers.RotatingFileHandler` adapted | Manual control for learning; existing handlers provide production-ready features |\n| **Network Transport** | `requests` library for HTTP endpoints | `aiohttp` for async network operations | Synchronous requests for simple cases; async required for non-blocking performance |\n| **Configuration** | Python dictionaries and environment variables | `pydantic` for validated configuration schemas | Dict-based config sufficient for core functionality; validation prevents runtime errors |\n\n#### B. Recommended File/Module Structure\n\nOrganize the logging system with clear separation of concerns, making each component testable and maintainable:\n\n```\nstructured_logging/\n├── __init__.py                    # Public API exports\n├── core/\n│   ├── __init__.py\n│   ├── logger.py                  # Logger class and hierarchy management\n│   ├── levels.py                  # Log level definitions and filtering\n│   ├── records.py                 # LogRecord data structure and factory\n│   └── registry.py                # Logger registry and configuration\n├── handlers/\n│   ├── __init__.py\n│   ├── base.py                    # Abstract handler interface\n│   ├── console.py                 # Stdout/stderr output handlers\n│   ├── file.py                    # File-based output with rotation\n│   └── remote.py                  # HTTP/network destination handlers\n├── formatters/\n│   ├── __init__.py\n│   ├── base.py                    # Abstract formatter interface\n│   ├── json_formatter.py          # Single-line JSON output\n│   └── pretty_formatter.py        # Human-readable colored output\n├── context/\n│   ├── __init__.py\n│   ├── manager.py                 # Context storage and propagation\n│   ├── correlation.py             # Correlation ID generation and tracking\n│   └── middleware.py              # Request context extraction\n├── utils/\n│   ├── __init__.py\n│   ├── serialization.py           # Safe JSON serialization utilities\n│   └── threading_utils.py         # Thread-safe helper functions\n└── tests/\n    ├── unit/                      # Component-specific tests\n    ├── integration/               # Multi-component scenarios\n    └── performance/               # Scalability and benchmark tests\n```\n\n#### C. Infrastructure Starter Code\n\n**Thread-Safe Utilities (`utils/threading_utils.py`):**\n\n```python\nimport threading\nimport time\nfrom typing import Any, Dict, Optional, Callable\nfrom contextlib import contextmanager\n\nclass ThreadSafeCounter:\n    \"\"\"Thread-safe counter for correlation ID generation.\"\"\"\n    \n    def __init__(self, start: int = 0):\n        self._value = start\n        self._lock = threading.Lock()\n    \n    def next(self) -> int:\n        with self._lock:\n            self._value += 1\n            return self._value\n\nclass ThreadSafeDict:\n    \"\"\"Thread-safe dictionary wrapper for shared logger registry.\"\"\"\n    \n    def __init__(self):\n        self._data: Dict[str, Any] = {}\n        self._lock = threading.RWLock() if hasattr(threading, 'RWLock') else threading.Lock()\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        with self._lock:\n            return self._data.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        with self._lock:\n            self._data[key] = value\n    \n    def keys(self):\n        with self._lock:\n            return list(self._data.keys())\n\n@contextmanager\ndef timeout_context(seconds: float):\n    \"\"\"Context manager for operations that must complete within timeout.\"\"\"\n    start_time = time.time()\n    try:\n        yield\n    finally:\n        elapsed = time.time() - start_time\n        if elapsed > seconds:\n            print(f\"Warning: Operation took {elapsed:.3f}s (timeout: {seconds}s)\")\n\ndef safe_call(func: Callable, *args, default: Any = None, **kwargs) -> Any:\n    \"\"\"Safely call function, returning default on any exception.\"\"\"\n    try:\n        return func(*args, **kwargs)\n    except Exception:\n        return default\n```\n\n**JSON Serialization Utilities (`utils/serialization.py`):**\n\n```python\nimport json\nimport datetime\nimport uuid\nfrom typing import Any, Dict, Set\nfrom decimal import Decimal\n\nclass SafeJSONEncoder(json.JSONEncoder):\n    \"\"\"JSON encoder that handles common non-serializable types safely.\"\"\"\n    \n    def default(self, obj: Any) -> Any:\n        if isinstance(obj, datetime.datetime):\n            return obj.isoformat()\n        elif isinstance(obj, datetime.date):\n            return obj.isoformat()\n        elif isinstance(obj, uuid.UUID):\n            return str(obj)\n        elif isinstance(obj, Decimal):\n            return float(obj)\n        elif hasattr(obj, '__dict__'):\n            # Custom objects - serialize their __dict__\n            return obj.__dict__\n        elif isinstance(obj, Exception):\n            # Exception objects - capture essential info\n            return {\n                'type': obj.__class__.__name__,\n                'message': str(obj),\n                'args': obj.args\n            }\n        else:\n            # Fallback to string representation\n            return str(obj)\n\ndef safe_serialize(data: Dict[str, Any], max_depth: int = 10) -> str:\n    \"\"\"\n    Safely serialize dictionary to JSON, handling circular references\n    and limiting depth to prevent infinite recursion.\n    \"\"\"\n    def clean_dict(obj: Any, depth: int = 0, seen: Set[id] = None) -> Any:\n        if seen is None:\n            seen = set()\n        \n        if depth > max_depth:\n            return f\"<max_depth_exceeded:{type(obj).__name__}>\"\n        \n        if id(obj) in seen:\n            return f\"<circular_reference:{type(obj).__name__}>\"\n        \n        if isinstance(obj, dict):\n            seen.add(id(obj))\n            result = {}\n            for k, v in obj.items():\n                try:\n                    result[str(k)] = clean_dict(v, depth + 1, seen.copy())\n                except Exception:\n                    result[str(k)] = f\"<serialization_error:{type(v).__name__}>\"\n            return result\n        elif isinstance(obj, (list, tuple)):\n            seen.add(id(obj))\n            return [clean_dict(item, depth + 1, seen.copy()) for item in obj]\n        else:\n            return obj\n    \n    cleaned_data = clean_dict(data)\n    return json.dumps(cleaned_data, cls=SafeJSONEncoder, separators=(',', ':'))\n\ndef estimate_serialized_size(data: Dict[str, Any]) -> int:\n    \"\"\"Estimate JSON size without full serialization (for performance).\"\"\"\n    # Quick size estimation for memory management\n    size = 2  # Opening and closing braces\n    for key, value in data.items():\n        size += len(str(key)) + 4  # Key + quotes + colon + comma\n        if isinstance(value, str):\n            size += len(value) + 2  # String + quotes\n        elif isinstance(value, (int, float)):\n            size += len(str(value))\n        elif isinstance(value, dict):\n            size += estimate_serialized_size(value)\n        else:\n            size += 20  # Rough estimate for other types\n    return size\n```\n\n#### D. Core Logic Skeleton Code\n\n**Base Logger Class (`core/logger.py`):**\n\n```python\nfrom typing import Any, Dict, List, Optional, Union\nfrom threading import Lock\nimport time\n\nclass Logger:\n    \"\"\"\n    Core logger class that handles message filtering, context enrichment,\n    and dispatch to multiple handlers.\n    \"\"\"\n    \n    def __init__(self, name: str, level: int = 20, parent: Optional['Logger'] = None):\n        self.name = name\n        self.level = level\n        self.parent = parent\n        self.handlers: List['Handler'] = []\n        self.children: Dict[str, 'Logger'] = {}\n        self._lock = Lock()\n    \n    def log(self, level: int, message: str, **context) -> None:\n        \"\"\"\n        Main logging method that processes and dispatches log records.\n        \n        Args:\n            level: Numeric log level (DEBUG=10, INFO=20, etc.)\n            message: Human-readable log message\n            **context: Additional key-value pairs to include in log record\n        \"\"\"\n        # TODO 1: Check if this log level meets the minimum threshold\n        #   Compare 'level' parameter against self.level\n        #   If level < self.level, return early (message filtered out)\n        \n        # TODO 2: Create LogRecord object with all required fields\n        #   Include: timestamp, level, message, logger_name, context\n        #   Use time.time() for timestamp, convert to ISO format\n        \n        # TODO 3: Enrich record with context from parent loggers\n        #   Walk up parent chain, merging context from each level\n        #   Child context should override parent context for same keys\n        \n        # TODO 4: Enrich record with thread-local context\n        #   Get current thread's context from ContextManager\n        #   Merge with record context (record context takes precedence)\n        \n        # TODO 5: Dispatch record to all handlers (thread-safely)\n        #   Acquire self._lock before accessing self.handlers\n        #   Call handle() method on each handler\n        #   Continue dispatching even if some handlers fail\n        \n        # TODO 6: If no handlers at this level, propagate to parent\n        #   Check if self.handlers is empty and self.parent exists\n        #   Call self.parent.handle_record(record) to propagate up\n        \n        pass  # Implementation goes here\n    \n    def debug(self, message: str, **context) -> None:\n        \"\"\"Log DEBUG level message.\"\"\"\n        # TODO: Call self.log() with DEBUG level (value: 10)\n        pass\n    \n    def info(self, message: str, **context) -> None:\n        \"\"\"Log INFO level message.\"\"\" \n        # TODO: Call self.log() with INFO level (value: 20)\n        pass\n    \n    def warn(self, message: str, **context) -> None:\n        \"\"\"Log WARN level message.\"\"\"\n        # TODO: Call self.log() with WARN level (value: 30)\n        pass\n    \n    def error(self, message: str, **context) -> None:\n        \"\"\"Log ERROR level message.\"\"\"\n        # TODO: Call self.log() with ERROR level (value: 40)\n        pass\n    \n    def fatal(self, message: str, **context) -> None:\n        \"\"\"Log FATAL level message.\"\"\"\n        # TODO: Call self.log() with FATAL level (value: 50)\n        pass\n```\n\n#### E. Language-Specific Hints\n\n**Python-Specific Implementation Tips:**\n\n- **Thread Safety**: Use `threading.Lock()` with `with` statements for automatic lock management: `with self._lock: # critical section`\n- **Context Variables**: For async compatibility, prefer `contextvars.ContextVar` over `threading.local()` when targeting Python 3.7+\n- **JSON Performance**: The standard `json` library is sufficient for most cases. Use `separators=(',', ':')` to eliminate whitespace in output\n- **Time Formatting**: Use `datetime.utcnow().isoformat() + 'Z'` for ISO 8601 timestamps with UTC timezone\n- **Exception Handling**: Wrap handler calls in `try/except` blocks to prevent one failing handler from stopping others\n- **Type Hints**: Use `typing` module extensively for better IDE support: `from typing import Dict, List, Optional, Any`\n- **Environment Variables**: Use `os.environ.get('LOG_LEVEL', 'INFO')` for configuration with sensible defaults\n\n**Performance Considerations:**\n\n- **String Formatting**: Use f-strings for message formatting: `f\"User {user_id} performed {action}\"` (fastest in Python 3.6+)\n- **Dictionary Merging**: Use `{**parent_context, **child_context}` for efficient context merging\n- **Level Checking**: Implement early return for filtered messages to avoid expensive context gathering\n- **Object Pooling**: For high-throughput scenarios, consider reusing LogRecord objects to reduce garbage collection pressure\n\n#### F. Milestone Checkpoint\n\nAfter implementing the basic logging foundation, verify correct behavior with these checkpoints:\n\n**Checkpoint 1: Basic Logging Works**\n```bash\npython -c \"\nfrom structured_logging import get_logger\nlogger = get_logger('test')\nlogger.info('Hello, structured logging!', user_id=123)\n\"\n```\nExpected output (to stdout):\n```json\n{\"timestamp\":\"2024-01-15T10:30:00.123Z\",\"level\":\"INFO\",\"logger\":\"test\",\"message\":\"Hello, structured logging!\",\"user_id\":123}\n```\n\n**Checkpoint 2: Level Filtering Works**\n```python\nlogger = get_logger('test')\nlogger.set_level('WARN')  # Should filter out DEBUG and INFO\nlogger.debug('This should not appear')\nlogger.info('This should not appear') \nlogger.warn('This should appear')\n```\nExpected: Only the WARN message appears in output.\n\n**Checkpoint 3: Thread Safety Works**\n```python\nimport threading\nlogger = get_logger('thread_test')\n\ndef log_worker(worker_id):\n    for i in range(100):\n        logger.info(f'Message {i}', worker_id=worker_id)\n\nthreads = [threading.Thread(target=log_worker, args=[i]) for i in range(5)]\nfor t in threads:\n    t.start()\nfor t in threads:\n    t.join()\n```\nExpected: All 500 messages appear as valid JSON (no interleaved/corrupted output).\n\n**Signs Something Is Wrong:**\n\n| Symptom | Likely Cause | What to Check |\n|---------|--------------|---------------|\n| No output appears | Handler not attached or level too high | Verify handler registration and log level settings |\n| Garbled JSON output | Thread safety issues | Check that handler writes are atomic and properly locked |\n| Missing context fields | Context not properly merged | Verify context propagation from parents and thread-local storage |\n| Performance degradation | Blocking I/O in handlers | Move file/network operations to background threads |\n| Import errors | Circular dependencies | Review module import structure, use delayed imports if needed |\n\nThis foundation provides the infrastructure needed to implement the core logging system while maintaining the thread safety, performance, and reliability requirements established in the problem statement.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** This section defines the scope and success criteria for all three milestones, establishing clear boundaries for what the logging system must accomplish and what it deliberately excludes.\n\nBefore diving into technical requirements, it's essential to establish a clear mental model for what we're building. Think of our structured logging system as **the nervous system of a distributed application**. Just as your nervous system carries signals from every part of your body to your brain, providing context about what's happening and allowing you to respond appropriately, our logging system carries structured information from every component of our application to monitoring systems, providing the observability needed to understand, debug, and optimize system behavior.\n\nUnlike traditional logging, which is like having a collection of disconnected sensors that each speak their own language, structured logging creates a unified communication protocol. Every log message follows the same format, carries consistent metadata, and can be correlated with related messages across the entire system. This transforms debugging from archaeological excavation through text files into surgical precision with queryable, contextual data.\n\nThe challenge in defining goals for a logging system lies in balancing comprehensiveness with focus. Logging touches every aspect of application development—from local debugging to production monitoring, from performance analysis to security auditing. We must be precise about what problems we're solving while explicitly acknowledging what we're not building to avoid scope creep and maintain architectural clarity.\n\n### Functional Requirements\n\nThe functional requirements define **what** our logging system must do—the concrete behaviors and capabilities that users will interact with directly. These requirements map directly to our three milestones and form the acceptance criteria for successful implementation.\n\n**Log Level Management and Filtering** forms the foundation of our system. The logging system must support five distinct log levels with numeric ordering: `DEBUG` (10), `INFO` (20), `WARN` (30), `ERROR` (40), and `FATAL` (50). This hierarchical system allows developers to control the verbosity of their applications by setting a minimum log level threshold. When a logger is configured with level `WARN`, it suppresses all `DEBUG` and `INFO` messages while allowing `WARN`, `ERROR`, and `FATAL` messages to pass through.\n\nThe system must support **runtime configuration changes** without requiring application restarts. A production service running with `INFO` level should be able to dynamically switch to `DEBUG` level when troubleshooting issues, then return to `INFO` level to reduce log volume. This capability is crucial for production debugging scenarios where restarting the application would eliminate the problematic state we're trying to diagnose.\n\n| Log Level | Numeric Value | Purpose | Typical Volume |\n|-----------|---------------|---------|----------------|\n| `DEBUG` | 10 | Detailed diagnostic information for development | Very High |\n| `INFO` | 20 | General application flow and state changes | Moderate |\n| `WARN` | 30 | Potentially problematic situations | Low |\n| `ERROR` | 40 | Error conditions that don't stop the application | Very Low |\n| `FATAL` | 50 | Critical errors that may cause application termination | Extremely Rare |\n\n**Structured JSON Output** transforms traditional string-based logging into queryable, machine-readable data. Every log record must serialize as valid, single-line JSON containing consistent field names and data types. This structured format enables powerful querying capabilities in log aggregation systems—instead of searching for text patterns, operators can filter by exact field values, perform numeric comparisons on timestamps, and aggregate data across multiple dimensions.\n\nThe JSON output must include these mandatory fields in every log record:\n\n| Field Name | Data Type | Description | Example |\n|------------|-----------|-------------|---------|\n| `timestamp` | string | ISO 8601 formatted timestamp with millisecond precision | \"2024-01-15T14:30:25.123Z\" |\n| `level` | string | Human-readable log level name | \"ERROR\" |\n| `message` | string | Primary log message content | \"Database connection failed\" |\n| `logger_name` | string | Hierarchical name identifying the logger | \"service.database.connection\" |\n| `context` | object | Key-value pairs providing additional metadata | {\"user_id\": \"12345\", \"request_id\": \"req_abc123\"} |\n\n**Multi-Destination Handler Dispatch** enables log records to flow simultaneously to multiple output destinations. A single log statement might write to local stdout for immediate developer feedback, append to a rotating file for local persistence, and transmit to a remote log collector for centralized aggregation. Each destination operates independently—a failure in one handler must not affect others or block the logging operation.\n\nThe handler dispatch mechanism must support these core handler types:\n\n| Handler Type | Purpose | Failure Behavior | Configuration |\n|-------------|---------|------------------|---------------|\n| Console Handler | Real-time output to stdout/stderr | Log to stderr and continue | Format selection (JSON/pretty) |\n| File Handler | Local file persistence with rotation | Create fallback file and continue | File path, rotation size, retention |\n| Network Handler | Remote transmission to log collectors | Buffer locally and retry | Endpoint URL, timeout, retry policy |\n| Memory Handler | In-process buffering for testing | Drop oldest entries when full | Buffer size, overflow behavior |\n\n**Context Propagation and Correlation** addresses the critical challenge of connecting related log entries across distributed operations. When a user request spans multiple services, functions, and async operations, the logging system must automatically carry contextual information that allows operators to trace the complete request flow.\n\nThe system must implement **correlation ID injection**, where a unique identifier is automatically attached to every log record within a request scope. This correlation ID propagates through function calls, async operations, and even across network boundaries when properly configured. Additionally, the context system must support arbitrary key-value pairs that provide additional metadata—user IDs, session tokens, feature flags, or any other contextual information that aids in debugging and analysis.\n\nContext propagation must handle these scenarios:\n\n| Scenario | Context Behavior | Implementation Challenge |\n|----------|------------------|--------------------------|\n| Synchronous function calls | Context inherits from caller | Thread-local storage management |\n| Asynchronous operations | Context copies to new task | Async context boundary preservation |\n| Child logger creation | Context inherits from parent | Logger hierarchy traversal |\n| Request boundary crossing | Context resets or inherits from headers | HTTP middleware integration |\n\n> **Design Insight**: The correlation ID system transforms distributed debugging from impossible puzzle-solving into systematic investigation. Instead of manually correlating timestamps across multiple log files, operators can query for a single correlation ID and see the complete request flow.\n\n### Non-Functional Requirements\n\nNon-functional requirements define **how well** our system must perform—the quality attributes and constraints that ensure the logging system operates reliably in production environments without becoming a bottleneck or source of problems itself.\n\n**Performance Requirements** demand that logging operations impose minimal overhead on the host application. The primary performance constraint is **latency**—individual log statements must complete in microseconds, not milliseconds. Applications often generate hundreds or thousands of log entries per second, and each logging operation occurs in the critical path of business logic.\n\nThe system must achieve these performance targets:\n\n| Metric | Target | Measurement Method | Degradation Impact |\n|--------|--------|--------------------|-------------------|\n| Log statement latency | < 50 microseconds (P99) | Benchmark with no I/O handlers | Slows application request processing |\n| Memory allocation | < 1KB per log record | Memory profiling during load testing | Increases garbage collection pressure |\n| CPU overhead | < 2% of application CPU | Performance profiling under sustained load | Reduces application throughput |\n| Handler dispatch | < 100 microseconds (P99) | End-to-end logging pipeline timing | Blocks application threads |\n\nTo achieve these targets, the system must avoid blocking I/O operations in the critical path. File writes, network transmissions, and other potentially slow operations must occur asynchronously or in background threads. The log record creation and dispatch mechanism must minimize memory allocations and avoid expensive serialization operations until absolutely necessary.\n\n**Thread Safety Requirements** ensure correct behavior when multiple threads simultaneously invoke logging operations. Modern applications extensively use concurrent programming, and the logging system must handle simultaneous log statements without data corruption, race conditions, or deadlocks.\n\nThe thread safety model must protect these shared resources:\n\n| Shared Resource | Concurrency Pattern | Protection Mechanism | Performance Impact |\n|----------------|-------------------|---------------------|-------------------|\n| Logger configuration | Read-heavy, rare writes | Reader-writer locks | Minimal—most operations read-only |\n| Log record dispatch | High-frequency writes | Lock-free queues or fine-grained locking | Must not serialize all logging operations |\n| Context storage | Thread-local access | Thread-local storage with inheritance | No contention between threads |\n| Handler state | Handler-specific access patterns | Handler-managed synchronization | Varies by handler implementation |\n\n**Configurability Requirements** enable the logging system to adapt to different environments and operational needs without code changes. The same application binary must support development logging (verbose, pretty-printed) and production logging (structured, filtered) through configuration alone.\n\nConfiguration must support these operational scenarios:\n\n| Environment | Log Level | Output Format | Destinations | Context Fields |\n|-------------|-----------|---------------|--------------|----------------|\n| Development | `DEBUG` | Pretty-printed JSON with colors | Console only | All available context |\n| Testing | `WARN` | Single-line JSON | Memory buffer | Minimal context for speed |\n| Staging | `INFO` | Single-line JSON | File + Remote collector | Full production context |\n| Production | `INFO` | Single-line JSON | Remote collector only | Security-filtered context |\n\n**Async Compatibility Requirements** ensure the logging system functions correctly in applications using modern async/await programming patterns. Python's asyncio, JavaScript's Promise-based code, and similar patterns create execution contexts that traditional thread-local storage cannot handle properly.\n\nThe system must preserve logging context across these async boundaries:\n\n| Async Pattern | Context Challenge | Required Behavior |\n|--------------|-------------------|-------------------|\n| `async def` function calls | Context inheritance from caller | Context automatically flows to async functions |\n| `await` operations | Context preservation across yield points | Context remains available after await resumes |\n| Task creation (`asyncio.create_task`) | Context copying to new task | New task inherits current context |\n| Concurrent execution (`asyncio.gather`) | Context isolation between tasks | Each task maintains independent context |\n\n> **Architecture Decision: Async Context Strategy**\n> - **Context**: Modern applications heavily use async/await patterns, but traditional thread-local storage fails across await boundaries\n> - **Options Considered**: \n>   1. Ignore async compatibility—require manual context passing\n>   2. Use language-specific async context mechanisms\n>   3. Build custom context propagation system\n> - **Decision**: Use language-specific async context mechanisms (Python's `contextvars`, etc.)\n> - **Rationale**: Language async context systems are specifically designed for this problem and integrate seamlessly with async runtimes\n> - **Consequences**: Simpler implementation and better performance, but requires different implementation strategies per language\n\n### Explicit Non-Goals\n\nClearly defining what our logging system does **not** do is crucial for maintaining focus and preventing scope creep. These non-goals represent important functionality that could theoretically be added but would fundamentally change the nature and complexity of our system.\n\n**Log Storage and Persistence Management** falls outside our scope. Our logging system produces structured log records and dispatches them to configured destinations, but it does not implement log storage backends, retention policies, or data lifecycle management. We provide file handlers that can write to local files, but we do not build distributed storage systems, implement log rotation policies, or manage disk space consumption.\n\nThis boundary means our system interfaces with but does not replace dedicated log management solutions:\n\n| Storage Concern | Our Responsibility | External System Responsibility |\n|----------------|-------------------|-------------------------------|\n| Log record format | Produce structured JSON records | Store and index records efficiently |\n| Local file writing | Write records to specified files | Implement file rotation and compression |\n| Network transmission | Send records to remote endpoints | Receive, route, and persist records |\n| Data retention | Continue producing records | Implement age-based deletion policies |\n\n**Search and Analytics Capabilities** represent a completely different problem domain. While our structured JSON output enables powerful searching and analysis, we do not build query engines, indexing systems, or analytical dashboards. Our role ends when log records reach their configured destinations—whether those destinations provide search capabilities is beyond our scope.\n\n**Real-Time Alerting and Monitoring** requires complex event processing, threshold management, and notification systems. Although our log records contain the data needed for alerting (error rates, performance metrics, business events), we do not implement alert rules, notification channels, or monitoring dashboards. We focus on reliable log record production and dispatch.\n\n**Log Sampling and Rate Limiting** represents advanced operational features that could compromise our core reliability guarantees. While production systems often need these capabilities to manage log volume and costs, implementing them requires complex policy engines and could introduce scenarios where critical log records are dropped. We choose to generate all requested log records and leave volume management to downstream systems.\n\n**Dynamic Schema Management** involves automatically detecting and managing changes in log record structure over time. While our JSON output naturally accommodates additional fields, we do not implement schema registries, version management, or compatibility checking between different log record formats.\n\n**Security and Access Control** for log content remains the responsibility of storage and analysis systems. We do not implement field-level encryption, access control policies, or data masking capabilities. Our context filtering allows removing sensitive fields before serialization, but comprehensive security requires purpose-built security infrastructure.\n\n> **Design Principle**: Single Responsibility\n> Our logging system excels at one thing: reliably producing structured, contextual log records and dispatching them to configured destinations. By explicitly avoiding adjacent problem domains, we can focus on making our core functionality extremely reliable, performant, and easy to integrate.\n\nThese non-goals create clear integration points where our logging system connects with specialized external systems:\n\n| Integration Point | Our Output | External System Input | Example Tools |\n|------------------|------------|----------------------|---------------|\n| Log Aggregation | JSON records via network handlers | Structured log ingestion APIs | Elasticsearch, Splunk, Datadog |\n| File Management | Raw log files via file handlers | File monitoring and rotation | logrotate, fluentd, filebeat |\n| Monitoring | Structured records with metrics | Log-based metric extraction | Prometheus, Grafana, custom dashboards |\n| Alerting | Error/warning records with context | Event pattern recognition | PagerDuty, AlertManager, custom systems |\n\n⚠️ **Pitfall: Scope Creep Through \"Simple\" Features**\nLearners often want to add \"just a simple search feature\" or \"basic alerting\" to their logging system. These features seem simple but require fundamentally different architectural patterns (indexing, query processing, event detection) that would dominate the system design. Resist the temptation to build a \"logging platform\"—focus on building an excellent logging library that integrates with existing platforms.\n\n### Implementation Guidance\n\n**A. Technology Recommendations Table:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| JSON Serialization | `json` standard library with custom encoder | `orjson` or `ujson` for performance |\n| Thread Safety | `threading.Lock` with context managers | `queue.Queue` for lock-free dispatch |\n| Async Context | `contextvars` module (Python 3.7+) | Custom context propagation framework |\n| Configuration | Environment variables + dataclasses | YAML/TOML files with validation |\n| Network Handlers | `urllib3` or `requests` for HTTP | `aiohttp` for async network operations |\n| File Operations | Built-in `open()` with manual rotation | `logging.handlers.RotatingFileHandler` adaptation |\n\n**B. Recommended File/Module Structure:**\n\n```\nstructured_logging/\n├── __init__.py                  ← Public API exports\n├── core/\n│   ├── __init__.py\n│   ├── logger.py               ← Logger hierarchy and main API\n│   ├── record.py               ← LogRecord data structure\n│   ├── levels.py               ← Log level constants and utilities\n│   └── context.py              ← Context propagation system\n├── handlers/\n│   ├── __init__.py\n│   ├── base.py                 ← Abstract Handler base class\n│   ├── console.py              ← Console/stdout handler\n│   ├── file.py                 ← File writing handler\n│   └── network.py              ← HTTP/network handlers\n├── formatters/\n│   ├── __init__.py\n│   ├── json_formatter.py       ← JSON serialization\n│   ├── pretty_formatter.py     ← Development-friendly output\n│   └── registry.py             ← Formatter plugin system\n├── utils/\n│   ├── __init__.py\n│   ├── serialization.py        ← Safe JSON encoding utilities\n│   ├── threading.py            ← Thread-safe data structures\n│   └── async_utils.py          ← Async context bridge utilities\n└── tests/\n    ├── test_core/\n    ├── test_handlers/\n    ├── test_formatters/\n    └── integration/\n```\n\n**C. Infrastructure Starter Code (COMPLETE):**\n\n```python\n# utils/threading.py - Complete thread-safe utilities\nimport threading\nfrom typing import Any, Dict, Optional\n\nclass ThreadSafeDict:\n    \"\"\"Thread-safe dictionary wrapper for shared logger configuration.\"\"\"\n    \n    def __init__(self):\n        self._data: Dict[str, Any] = {}\n        self._lock = threading.RLock()  # Reentrant lock for nested access\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        with self._lock:\n            return self._data.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        with self._lock:\n            self._data[key] = value\n    \n    def update(self, updates: Dict[str, Any]) -> None:\n        with self._lock:\n            self._data.update(updates)\n    \n    def copy(self) -> Dict[str, Any]:\n        with self._lock:\n            return self._data.copy()\n\n\nclass ThreadSafeCounter:\n    \"\"\"Thread-safe counter for generating correlation IDs.\"\"\"\n    \n    def __init__(self, initial_value: int = 0):\n        self._value = initial_value\n        self._lock = threading.Lock()\n    \n    def next(self) -> int:\n        with self._lock:\n            self._value += 1\n            return self._value\n    \n    def get(self) -> int:\n        with self._lock:\n            return self._value\n```\n\n```python\n# utils/serialization.py - Complete JSON serialization utilities\nimport json\nimport sys\nfrom typing import Any, Dict, Set\nfrom decimal import Decimal\nfrom datetime import datetime, date\n\nclass SafeJSONEncoder(json.JSONEncoder):\n    \"\"\"JSON encoder that handles non-serializable types safely.\"\"\"\n    \n    def default(self, obj: Any) -> Any:\n        # Handle common non-serializable types\n        if isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return float(obj)\n        elif hasattr(obj, '__dict__'):\n            return f\"<{obj.__class__.__name__} object>\"\n        elif callable(obj):\n            return f\"<function {getattr(obj, '__name__', 'unknown')}>\"\n        else:\n            return f\"<{type(obj).__name__}>\"\n\ndef safe_serialize(data: Dict[str, Any], max_depth: int = 10) -> str:\n    \"\"\"Safely serialize dictionary to JSON with circular reference protection.\"\"\"\n    try:\n        return json.dumps(data, cls=SafeJSONEncoder, separators=(',', ':'))\n    except (TypeError, ValueError, RecursionError):\n        # Fallback: create safe representation\n        safe_data = _make_serializable(data, max_depth, set())\n        return json.dumps(safe_data, separators=(',', ':'))\n\ndef _make_serializable(obj: Any, max_depth: int, seen_objects: Set[int]) -> Any:\n    \"\"\"Recursively make object serializable, handling circular references.\"\"\"\n    if max_depth <= 0:\n        return \"<max_depth_reached>\"\n    \n    obj_id = id(obj)\n    if obj_id in seen_objects:\n        return \"<circular_reference>\"\n    \n    if isinstance(obj, (str, int, float, bool, type(None))):\n        return obj\n    elif isinstance(obj, dict):\n        seen_objects.add(obj_id)\n        result = {\n            str(k): _make_serializable(v, max_depth - 1, seen_objects.copy())\n            for k, v in obj.items()\n        }\n        seen_objects.remove(obj_id)\n        return result\n    elif isinstance(obj, (list, tuple)):\n        seen_objects.add(obj_id)\n        result = [\n            _make_serializable(item, max_depth - 1, seen_objects.copy())\n            for item in obj\n        ]\n        seen_objects.remove(obj_id)\n        return result\n    else:\n        return SafeJSONEncoder().default(obj)\n\ndef estimate_serialized_size(data: Dict[str, Any]) -> int:\n    \"\"\"Estimate JSON size without full serialization for performance.\"\"\"\n    # Quick estimation based on data structure\n    size = 2  # Opening and closing braces\n    for key, value in data.items():\n        size += len(str(key)) + 3  # Key + quotes + colon\n        if isinstance(value, str):\n            size += len(value) + 2  # Value + quotes\n        elif isinstance(value, (int, float)):\n            size += len(str(value))\n        elif isinstance(value, dict):\n            size += estimate_serialized_size(value)\n        else:\n            size += 20  # Conservative estimate for other types\n        size += 1  # Comma separator\n    return size\n```\n\n**D. Core Logic Skeleton Code:**\n\n```python\n# core/levels.py - Log level management (SKELETON)\nfrom typing import Dict\n\n# Log level constants\nDEBUG = 10\nINFO = 20\nWARN = 30\nERROR = 40\nFATAL = 50\n\nLEVEL_NAMES: Dict[int, str] = {\n    DEBUG: \"DEBUG\",\n    INFO: \"INFO\", \n    WARN: \"WARN\",\n    ERROR: \"ERROR\",\n    FATAL: \"FATAL\"\n}\n\ndef should_log(message_level: int, configured_level: int) -> bool:\n    \"\"\"Determine if a message should be logged based on level filtering.\"\"\"\n    # TODO 1: Compare message_level with configured_level\n    # TODO 2: Return True if message_level >= configured_level\n    # TODO 3: Return False otherwise (message should be filtered out)\n    # Hint: Higher numeric values represent more severe log levels\n    pass\n\ndef level_name_to_value(level_name: str) -> int:\n    \"\"\"Convert string level name to numeric value.\"\"\"\n    # TODO 1: Create reverse mapping from LEVEL_NAMES\n    # TODO 2: Look up level_name in reverse mapping\n    # TODO 3: Return numeric value or raise ValueError for invalid names\n    # TODO 4: Handle case-insensitive matching (convert to uppercase)\n    pass\n```\n\n```python\n# core/record.py - Log record data structure (SKELETON)\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nimport uuid\n\nclass LogRecord:\n    \"\"\"Structured log record containing all message data and metadata.\"\"\"\n    \n    def __init__(self, level: int, message: str, logger_name: str, \n                 context: Optional[Dict[str, Any]] = None):\n        # TODO 1: Store the provided parameters as instance attributes\n        # TODO 2: Generate timestamp using datetime.utcnow().isoformat()\n        # TODO 3: Initialize context as empty dict if None provided\n        # TODO 4: Ensure context is a copy to prevent external mutation\n        # Hint: Use dict(context) or context.copy() to create defensive copy\n        pass\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert log record to dictionary for JSON serialization.\"\"\"\n        # TODO 1: Create dictionary with timestamp, level, message, logger_name\n        # TODO 2: Add context fields to the dictionary\n        # TODO 3: Convert numeric level to string using LEVEL_NAMES\n        # TODO 4: Return complete dictionary ready for JSON serialization\n        # Hint: Use LEVEL_NAMES from levels.py to convert level number to string\n        pass\n    \n    def add_context(self, key: str, value: Any) -> None:\n        \"\"\"Add a context field to this log record.\"\"\"\n        # TODO 1: Add key-value pair to context dictionary\n        # TODO 2: Handle the case where key already exists (overwrite vs. error?)\n        # Design decision: Should duplicate keys overwrite or raise an error?\n        pass\n```\n\n**E. Language-Specific Hints:**\n\n- **Thread Safety**: Use `threading.RLock()` (reentrant locks) for logger hierarchy access since child loggers may need to access parent configuration during the same operation\n- **Async Context**: Import `contextvars` for Python 3.7+ async context propagation—use `contextvars.ContextVar` to store correlation IDs and context data\n- **JSON Performance**: The built-in `json` module is sufficient for learning, but consider `orjson` for production use if serialization becomes a bottleneck\n- **Memory Management**: Use `__slots__` in `LogRecord` class to reduce memory overhead when creating many log records\n- **Exception Handling**: Use `safe_call()` pattern for handler dispatch—if one handler fails, continue with remaining handlers\n- **File I/O**: Use `os.fsync()` after writing critical log records to ensure durability, but be aware this impacts performance\n\n**F. Milestone Checkpoint:**\n\nAfter implementing the goals and requirements defined in this section:\n\n**What to verify after Milestone 1 (Logger Core):**\n```bash\npython -c \"\nfrom structured_logging import Logger\nlogger = Logger('test', level=INFO)\nlogger.info('Test message', user_id=12345)\nlogger.debug('Debug message')  # Should be filtered out\n\"\n```\n\nExpected behavior:\n- INFO message appears with JSON format including timestamp, level, message, and user_id context\n- DEBUG message does not appear (filtered by level)\n- No exceptions or thread safety issues when called from multiple threads\n\n**What to verify after Milestone 2 (Structured Output):**\n```bash\npython -c \"\nimport json\nfrom structured_logging import Logger\nlogger = Logger('test')\nlogger.info('Test message', request_id='req_123')\n# Verify output is valid JSON by parsing it\n\"\n```\n\nExpected behavior:\n- Output is valid single-line JSON that can be parsed\n- All required fields present: timestamp, level, message, logger_name, context\n- Context fields properly nested under 'context' key\n\n**What to verify after Milestone 3 (Context & Correlation):**\n```bash\npython -c \"\nfrom structured_logging import Logger, with_correlation_id\nlogger = Logger('test')\nwith with_correlation_id():\n    logger.info('Message 1')\n    logger.info('Message 2')\n\"\n```\n\nExpected behavior:\n- Both messages contain the same correlation_id in their context\n- Correlation ID is automatically generated and unique per context scope\n- Context properly propagates through nested function calls\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|----------------|-----|\n| Log messages not appearing | Level filtering too restrictive | Check logger level vs. message level | Set logger level to DEBUG temporarily |\n| JSON serialization errors | Non-serializable objects in context | Try serializing context manually | Use SafeJSONEncoder or filter context values |\n| Context not propagating | Thread-local storage issues | Print context at each function level | Use contextvars instead of threading.local |\n| Performance degradation | Blocking I/O in handlers | Profile handler execution times | Move I/O operations to background threads |\n| Race conditions in output | Multiple threads writing simultaneously | Look for interleaved output characters | Add proper locking in handlers |\n\n\n## High-Level Architecture\n\n> **Milestone(s):** This section provides the architectural foundation for all three milestones by defining the core components, their relationships, and the data flow that enables structured logging with context propagation.\n\n### Component Overview: Core Components: Logger, LogRecord, Handlers, Formatters, and Context Manager\n\nThink of the structured logging system as a **broadcasting studio with multiple output channels**. Just as a news studio takes raw content, formats it for different audiences (TV, radio, web), and broadcasts simultaneously to multiple destinations, our logging system takes application events, structures them consistently, and dispatches them to various outputs like console, files, and remote collectors. The studio has specialized equipment for each step: cameras capture content, editors format it, and transmitters send it to different channels. Similarly, our logging system has specialized components for capturing, formatting, and dispatching log messages.\n\nThe structured logging architecture consists of five core components that work together to provide a complete logging solution. Each component has a distinct responsibility and well-defined interfaces that enable flexible composition and extensibility.\n\n#### Logger Component\n\nThe `Logger` serves as the primary interface between application code and the logging infrastructure. Think of it as the **control panel** in our broadcasting studio analogy - it's where producers decide what content gets recorded, at what quality level, and which channels receive the broadcast. Each logger maintains its own identity and configuration while participating in a hierarchical organization that enables inheritance and scoped behavior.\n\nEvery logger instance maintains several critical pieces of state that determine its behavior and capabilities:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `name` | `str` | Hierarchical identifier (e.g., \"app.database.connection\") that determines logger's position in the tree |\n| `level` | `int` | Minimum severity threshold - messages below this level are filtered out before processing |\n| `parent` | `Logger` | Reference to parent logger for configuration inheritance and context propagation |\n| `handlers` | `List[Handler]` | Collection of output destinations that will receive log records from this logger |\n| `children` | `Dict[str, Logger]` | Map of child loggers created under this logger's namespace |\n\nThe logger hierarchy enables powerful inheritance patterns where child loggers automatically inherit their parent's configuration, handlers, and context fields while allowing selective overrides for specialized behavior. For example, a database connection logger might inherit the application's general configuration but add specialized handlers for database-specific monitoring.\n\n#### LogRecord Structure\n\nThe `LogRecord` represents a single log event in its structured form. This is the fundamental data unit that flows through the entire logging pipeline. Think of it as a **standardized news report template** that ensures every piece of information contains the same essential elements regardless of who created it or where it's going.\n\nThe LogRecord structure captures all essential information about a logging event in a consistent, queryable format:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `timestamp` | `str` | ISO 8601 formatted timestamp indicating when the log event occurred |\n| `level` | `int` | Numeric severity level (DEBUG=10, INFO=20, WARN=30, ERROR=40, FATAL=50) |\n| `message` | `str` | Human-readable description of the event or situation being logged |\n| `logger_name` | `str` | Fully qualified name of the logger that created this record |\n| `context` | `Dict[str, Any]` | Key-value pairs providing additional structured data about the event |\n\nThe context dictionary is where the \"structured\" aspect of structured logging becomes most apparent. Instead of embedding variable data into string messages, applications attach meaningful key-value pairs that can be queried, filtered, and aggregated by log analysis tools. For example, rather than logging \"User john@example.com failed login attempt from IP 192.168.1.100\", the system would log a message \"User login failed\" with context fields `{\"user_email\": \"john@example.com\", \"client_ip\": \"192.168.1.100\", \"login_attempt\": \"failed\"}`.\n\n#### Handler Dispatch System\n\nHandlers are the **output channels** in our broadcasting analogy. Each handler knows how to deliver log records to a specific destination, whether that's stdout for development debugging, rotating files for long-term storage, or remote collectors for centralized analysis. The handler system enables simultaneous dispatch to multiple destinations without requiring application code to manage the complexity.\n\nThe abstract `Handler` interface defines the contract that all output destinations must implement:\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `emit` | `record: LogRecord` | `None` | Process and output a single log record to this handler's destination |\n| `flush` | `None` | `None` | Ensure all buffered records are written to the underlying destination |\n| `close` | `None` | `None` | Release resources and perform cleanup when handler is no longer needed |\n| `set_formatter` | `formatter: Formatter` | `None` | Configure the formatter used to render log records for output |\n\nEach handler implementation specializes the abstract interface for its specific destination. A file handler manages file rotation, buffering, and disk I/O. A remote handler manages network connections, retry logic, and serialization for transmission. A console handler manages terminal output, color coding, and user-friendly formatting.\n\nThe dispatch mechanism routes each log record to all configured handlers simultaneously. This enables powerful patterns like writing structured JSON to files for analysis while simultaneously displaying pretty-printed, colorized output to the developer console during debugging.\n\n#### Formatter Plugin System\n\nFormatters transform `LogRecord` objects into the final output representation. Think of formatters as **template engines** that take structured data and render it into specific output formats optimized for different consumers. The plugin system allows applications to register custom formatters and select them by name, enabling consistent formatting across different parts of an application.\n\nThe formatter interface provides the contract for all output renderers:\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `format` | `record: LogRecord` | `str` | Convert a log record into formatted string output ready for display or transmission |\n| `configure` | `options: Dict[str, Any]` | `None` | Apply configuration options specific to this formatter implementation |\n\nCommon formatter implementations include the JSON formatter for structured output, the pretty-print formatter for human-readable console output, and custom formatters that integrate with specific monitoring or analysis tools. The plugin system allows applications to register formatters by name and configure different handlers to use different formatters based on their intended audience.\n\n#### Context Manager\n\nThe Context Manager handles the complex task of **context propagation** - ensuring that relevant contextual information flows through nested function calls and across async boundaries without requiring explicit parameter passing. Think of it as the **continuity coordinator** in our broadcasting studio, ensuring that related segments maintain consistent information and branding elements throughout the production.\n\nThe context system maintains thread-local storage and manages inheritance patterns that allow contextual information to flow naturally through application execution:\n\n| Component | Purpose | Key Behaviors |\n|-----------|---------|---------------|\n| Thread-Local Storage | Maintains context state per execution thread | Isolates context between concurrent requests, automatically inherits parent context |\n| Correlation ID Generator | Creates unique identifiers for request tracing | Generates UUIDs, injects into log context, propagates across service boundaries |\n| Async Context Bridge | Preserves context across async/await boundaries | Captures context at task creation, restores context during task execution |\n| Context Inheritance | Manages parent-child context relationships | Child contexts inherit parent fields, can override or add new fields |\n\nThe context manager ensures that once a correlation ID or other contextual information is established (typically at request boundaries), it automatically appears in every log record created within that execution scope, even deep within nested function calls or across async task switches.\n\n> **Design Insight**: The separation of concerns between Logger (message creation), Handler (output dispatch), Formatter (rendering), and Context Manager (state propagation) creates a highly flexible system where each aspect can be configured and extended independently. This modularity is essential for accommodating the diverse requirements of different deployment environments and use cases.\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n### Data Flow Pipeline: How log messages flow from application code through formatters to output destinations\n\nUnderstanding the complete journey of a log message from application code to final output destinations reveals how the components work together to provide structured logging capabilities. This pipeline demonstrates the transformation and enrichment that occurs at each stage, showing how raw application events become structured, contextualized, and properly formatted log records.\n\n#### Stage 1: Message Creation and Level Filtering\n\nThe logging pipeline begins when application code calls one of the logging methods (`debug`, `info`, `warn`, `error`, or `fatal`). The first critical decision point occurs immediately: **level filtering**. Think of this as a **security checkpoint** that only allows messages of sufficient importance to proceed through the expensive processing pipeline.\n\nThe level filtering process follows this sequence:\n\n1. Application code calls `logger.info(\"User authenticated\", user_id=\"12345\", session_id=\"abc-def\")`\n2. Logger retrieves its configured minimum level (inherited from parent if not explicitly set)\n3. The `should_log` function compares the message level against the configured threshold\n4. If the message level is below the threshold, processing stops immediately - no LogRecord is created, no handlers are called, no formatting occurs\n5. If the message passes the level check, processing continues to record creation\n\nThis early filtering is crucial for performance. In production systems, DEBUG level messages might be completely disabled, and the filtering prevents any overhead from creating LogRecord objects or processing context for messages that will never be output.\n\n#### Stage 2: LogRecord Construction and Context Enrichment\n\nOnce a message passes level filtering, the system creates a `LogRecord` object and enriches it with contextual information. This stage transforms a simple message and parameters into a fully structured log event with all relevant metadata.\n\nThe record construction process involves several enrichment steps:\n\n1. **Timestamp Generation**: The system captures the current time with microsecond precision and formats it according to the configured timestamp format (typically ISO 8601)\n2. **Context Aggregation**: The context manager retrieves all active context fields from thread-local storage, including correlation IDs, user information, and request metadata\n3. **Logger Context Inheritance**: Any context fields attached to the logger or its parents are merged with the active context\n4. **Parameter Integration**: Keyword arguments passed to the logging method are merged into the context dictionary\n5. **Record Assembly**: All components are combined into a complete LogRecord with timestamp, level, message, logger name, and enriched context\n\nThe context enrichment stage is where structured logging shows its power. A simple log call might result in a LogRecord with dozens of contextual fields that provide rich information about the application state when the event occurred.\n\n#### Stage 3: Handler Dispatch and Parallel Processing\n\nWith a complete LogRecord created, the system enters the handler dispatch phase. This stage demonstrates the **fan-out pattern** where a single log event triggers parallel processing to multiple output destinations. Think of this as a **broadcasting transmitter** that simultaneously sends the same content to radio, television, and internet streams.\n\nThe dispatch mechanism follows this parallel processing pattern:\n\n1. The logger iterates through its list of configured handlers\n2. For each handler, the system makes an independent `emit` call with the LogRecord\n3. Each handler processes the record according to its specific requirements:\n   - Console handlers might check if output should be colorized\n   - File handlers might check if log rotation is needed\n   - Remote handlers might check network connectivity and queue records if offline\n4. Handler failures are isolated - if one handler fails, others continue processing\n5. Each handler applies its configured formatter to render the LogRecord into final output format\n\nThis parallel processing enables powerful deployment patterns. During development, logs might go to a colorized console for immediate feedback. In staging, the same logs might go to both files for debugging and a remote collector for integration testing. In production, logs might go to high-performance local files, metrics aggregators, and centralized logging infrastructure simultaneously.\n\n#### Stage 4: Formatting and Serialization\n\nEach handler applies its configured formatter to transform the structured LogRecord into the appropriate output representation. This stage handles the complex task of serialization while preserving the structured nature of the data and handling edge cases like circular references or non-serializable objects.\n\nThe formatting process addresses several challenges:\n\n1. **Serialization Safety**: The `safe_serialize` function handles objects that can't be directly serialized to JSON, converting them to string representations or filtering them out entirely\n2. **Circular Reference Detection**: The serializer detects and breaks circular references to prevent infinite recursion during JSON generation\n3. **Size Estimation**: For performance, the system can estimate serialized size without full serialization to decide whether to truncate large context objects\n4. **Field Ordering**: JSON output uses consistent field ordering to improve readability and enable text-based diffing of log files\n5. **Pretty Printing**: Development formatters add indentation, color coding, and human-friendly formatting while preserving the underlying structured data\n\nDifferent handlers might apply different formatters to the same LogRecord. A file handler might use compact, single-line JSON for efficient storage and parsing, while a console handler might use pretty-printed, colorized output for developer readability.\n\n#### Stage 5: Output Delivery and Error Recovery\n\nThe final stage handles actual output delivery to the configured destinations. This stage must handle various failure modes gracefully while maintaining the reliability that production logging systems require. Think of this as the **final mile delivery** where packages must reach their destinations despite traffic, weather, or infrastructure problems.\n\nOutput delivery involves several reliability mechanisms:\n\n1. **Buffering Strategy**: Handlers may buffer records for efficiency, but must balance performance with the risk of losing logs during crashes\n2. **Failure Recovery**: When output operations fail (disk full, network unreachable, permissions denied), handlers must decide whether to retry, queue for later, or drop records\n3. **Resource Management**: File handles, network connections, and buffers must be managed carefully to prevent resource leaks\n4. **Graceful Degradation**: When primary output destinations fail, the system should attempt to log error information to alternative destinations rather than crashing the application\n\nThe error recovery mechanisms ensure that logging problems don't become application problems. If a remote logging service becomes unavailable, the application continues running and attempts to log the issue to local files or console output.\n\n> **Design Insight**: The pipeline architecture enables **loose coupling** between stages. Application code doesn't need to know about formatters, formatters don't need to know about output destinations, and handlers don't need to know about context propagation. This separation allows each stage to be optimized, configured, and extended independently.\n\nThe complete data flow pipeline demonstrates how structured logging transforms simple application events into rich, contextualized, and properly formatted log records delivered to multiple destinations with reliability and performance guarantees.\n\n![Log Processing Data Flow](./diagrams/log-processing-flow.svg)\n\n### Recommended Module Structure: File organization and package layout for clean separation of concerns\n\nA well-organized module structure is crucial for maintaining clean separation of concerns and enabling teams to work on different aspects of the logging system independently. Think of the module structure as **organizing a professional kitchen** - each station has specific responsibilities, specialized tools, and clear interfaces with other stations, allowing multiple chefs to work efficiently without interfering with each other.\n\nThe recommended structure follows the principle of **bounded contexts** where each module encapsulates related functionality and exposes minimal, well-defined interfaces to other modules. This organization supports both the learning progression through the three milestones and the maintainability requirements of production systems.\n\n#### Root Package Structure\n\nThe top-level package organization reflects the major architectural boundaries and provides clear entry points for different aspects of the system:\n\n```\nstructured_logging/\n├── __init__.py                    # Public API exports\n├── logger.py                      # Core Logger and LogRecord classes\n├── handlers/                      # Output destination implementations\n│   ├── __init__.py               # Handler base class and common utilities\n│   ├── console.py                # Console/stdout handler\n│   ├── file.py                   # File-based handlers with rotation\n│   └── remote.py                 # Network-based handlers\n├── formatters/                    # Output format implementations\n│   ├── __init__.py               # Formatter base class and registry\n│   ├── json.py                   # JSON formatter with serialization safety\n│   └── pretty.py                 # Human-readable console formatter\n├── context/                       # Context propagation and correlation\n│   ├── __init__.py               # Context manager and public interfaces\n│   ├── storage.py                # Thread-local context storage\n│   ├── correlation.py            # Correlation ID generation and injection\n│   └── async_bridge.py           # Async context preservation\n├── utils/                         # Shared utilities and helpers\n│   ├── __init__.py               # Common utility exports\n│   ├── serialization.py          # Safe JSON serialization functions\n│   ├── thread_safety.py          # Thread-safe data structures\n│   └── validation.py             # Input validation and sanitization\n├── config/                        # Configuration management\n│   ├── __init__.py               # Configuration loading and validation\n│   └── schema.py                 # Configuration schema definitions\n└── tests/                         # Comprehensive test suite\n    ├── unit/                      # Unit tests for individual components\n    ├── integration/               # Integration tests across components\n    └── performance/               # Performance and load testing\n```\n\n#### Core Module Responsibilities\n\nEach module has clearly defined responsibilities that align with the architectural components and enable independent development and testing.\n\n**Logger Module (`logger.py`)**\nThis module contains the central `Logger` class and `LogRecord` data structure that form the heart of the logging system. It should be the most stable module since other components depend on its interfaces:\n\n| Class/Function | Purpose | Key Dependencies |\n|----------------|---------|------------------|\n| `Logger` | Main logging interface with hierarchy support | Handlers, Context Manager, Level utilities |\n| `LogRecord` | Structured log event representation | Serialization utilities, Timestamp formatting |\n| `LoggerFactory` | Factory for creating and managing logger instances | Configuration system, Logger hierarchy |\n| `get_logger` | Primary entry point for obtaining logger instances | LoggerFactory, Thread-safe caching |\n\n**Handlers Module (`handlers/`)**\nThe handlers package encapsulates all output destination logic. Each handler type gets its own module to enable independent development and specialized dependencies:\n\n| Module | Handler Types | Key Considerations |\n|---------|---------------|-------------------|\n| `console.py` | Stdout, stderr handlers | Color coding, terminal detection, Unicode support |\n| `file.py` | File, rotating file handlers | File locking, atomic writes, disk space monitoring |\n| `remote.py` | HTTP, TCP, UDP handlers | Connection pooling, retry logic, serialization formats |\n\nThe handler base class in `handlers/__init__.py` provides common functionality like formatter management, error handling patterns, and resource cleanup protocols that all handler implementations can inherit.\n\n**Formatters Module (`formatters/`)**\nThe formatters package handles the transformation from structured `LogRecord` objects to formatted output strings. This separation allows the same log data to be rendered differently for various audiences:\n\n| Module | Formatter Types | Output Characteristics |\n|---------|----------------|------------------------|\n| `json.py` | Compact JSON, pretty JSON | Machine-readable, consistent field ordering, size optimization |\n| `pretty.py` | Console, colored console | Human-readable, color coding, selective field display |\n\nThe formatter registry in `formatters/__init__.py` enables dynamic formatter selection and supports custom formatter registration for specialized output requirements.\n\n**Context Module (`context/`)**\nThe context package manages the complex requirements of context propagation across different execution models (synchronous, threaded, async). This is separated into multiple modules due to the different challenges each execution model presents:\n\n| Module | Responsibilities | Key Challenges |\n|---------|-----------------|----------------|\n| `storage.py` | Thread-local context storage | Thread isolation, inheritance patterns, memory cleanup |\n| `correlation.py` | Correlation ID management | UUID generation, injection points, cross-service propagation |\n| `async_bridge.py` | Async context preservation | Context copying, task boundaries, coroutine lifecycle |\n\n#### Milestone-Aligned Development Structure\n\nThe module structure supports incremental development through the three project milestones, allowing learners to build functionality progressively without requiring massive refactoring between milestones:\n\n**Milestone 1 Structure (Logger Core)**\nInitial implementation focuses on the core modules with basic implementations:\n- `logger.py`: Complete Logger and LogRecord implementation\n- `handlers/__init__.py`: Base Handler class and console handler\n- `utils/thread_safety.py`: Thread-safe data structures\n- `utils/validation.py`: Level validation and basic input sanitization\n\n**Milestone 2 Extensions (Structured Output)**\nMilestone 2 adds formatter infrastructure without changing existing modules:\n- `formatters/`: Complete formatter package with JSON and pretty-print implementations\n- `utils/serialization.py`: Safe JSON serialization with circular reference protection\n- Enhanced handlers with formatter integration\n\n**Milestone 3 Extensions (Context & Correlation)**\nMilestone 3 adds the context package while maintaining backward compatibility:\n- `context/`: Complete context propagation package\n- Integration points in `logger.py` for context injection\n- Extended handler and formatter support for correlation IDs\n\n#### Testing Structure Alignment\n\nThe testing structure mirrors the module organization and supports both component-level testing and cross-cutting integration scenarios:\n\n```\ntests/\n├── unit/\n│   ├── test_logger.py             # Logger class behavior, hierarchy, level filtering\n│   ├── test_handlers/             # Handler-specific unit tests\n│   │   ├── test_console.py        # Console output, color coding, error handling\n│   │   ├── test_file.py           # File operations, rotation, locking\n│   │   └── test_remote.py         # Network operations, retry, serialization\n│   ├── test_formatters/           # Formatter unit tests\n│   │   ├── test_json.py           # JSON serialization, field ordering, safety\n│   │   └── test_pretty.py         # Pretty printing, color codes, truncation\n│   └── test_context/              # Context propagation unit tests\n│       ├── test_storage.py        # Thread-local storage, inheritance\n│       ├── test_correlation.py    # ID generation, injection\n│       └── test_async_bridge.py   # Async context preservation\n├── integration/\n│   ├── test_end_to_end.py         # Complete logging pipeline tests\n│   ├── test_multi_handler.py     # Multiple handler coordination\n│   ├── test_context_flow.py      # Context propagation across components\n│   └── test_async_logging.py     # Async/await context preservation\n└── performance/\n    ├── test_throughput.py         # Message processing performance\n    ├── test_memory_usage.py       # Memory footprint and leak detection\n    └── test_concurrent_logging.py # Multi-threaded performance and safety\n```\n\n> **Design Insight**: The module structure balances **cohesion** (related functionality grouped together) with **loose coupling** (minimal dependencies between modules). Each module can be understood, tested, and modified independently while contributing to the overall system functionality. This structure particularly benefits learning environments where students can focus on one architectural layer at a time.\n\n#### Import Strategy and Public APIs\n\nThe package design uses a clear import strategy that exposes high-level APIs while keeping implementation details internal:\n\n**Public API (`__init__.py`)**\nThe root package exposes only the essential interfaces that application code needs:\n\n```python\n# Public exports - these are the stable API\nfrom .logger import get_logger, Logger, LogRecord\nfrom .context import with_context, correlation_id\nfrom .config import configure_logging\n\n# Internal modules should not be imported directly by applications\n```\n\n**Internal Module Imports**\nInternal modules use relative imports and depend only on the interfaces they need:\n\n```python\n# handlers/console.py\nfrom ..formatters import get_formatter\nfrom ..utils.thread_safety import ThreadSafeCounter\nfrom .base import Handler  # Relative import within handlers package\n```\n\nThis import strategy ensures that refactoring internal implementation doesn't break application code and makes the learning progression clearer by highlighting the distinction between public APIs and implementation details.\n\nThe module structure provides a solid foundation for building the structured logging system incrementally while maintaining clean separation of concerns and supporting both learning objectives and production requirements.\n\n### Implementation Guidance\n\nThe implementation of the structured logging system requires careful attention to Python-specific patterns, thread safety considerations, and performance optimizations. This guidance provides complete starter code for infrastructure components and detailed skeletons for core learning components.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| JSON Serialization | `json` module with custom encoder | `orjson` or `ujson` for high performance |\n| Thread Safety | `threading.RLock` and `threading.local` | `concurrent.futures` with thread pools |\n| File Operations | `open()` with manual rotation | `logging.handlers.RotatingFileHandler` base |\n| Network Handlers | `urllib3` for HTTP requests | `asyncio` with `aiohttp` for async |\n| Correlation IDs | `uuid.uuid4()` generation | `contextvars` for async context propagation |\n| Configuration | Dictionary-based config | `pydantic` models for validation |\n\n#### Complete Infrastructure Starter Code\n\n**Thread-Safe Data Structures (`utils/thread_safety.py`)**\n```python\n\"\"\"Thread-safe data structures for concurrent logging operations.\"\"\"\nimport threading\nfrom typing import Any, Dict, Optional\n\n\nclass ThreadSafeCounter:\n    \"\"\"Thread-safe counter for handler statistics and correlation ID generation.\"\"\"\n    \n    def __init__(self, initial_value: int = 0):\n        self._value = initial_value\n        self._lock = threading.RLock()\n    \n    def increment(self) -> int:\n        \"\"\"Increment counter and return new value.\"\"\"\n        with self._lock:\n            self._value += 1\n            return self._value\n    \n    def get(self) -> int:\n        \"\"\"Get current counter value.\"\"\"\n        with self._lock:\n            return self._value\n\n\nclass ThreadSafeDict:\n    \"\"\"Thread-safe dictionary for shared logger registry and context storage.\"\"\"\n    \n    def __init__(self):\n        self._data: Dict[str, Any] = {}\n        self._lock = threading.RWMutex()\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get value with read lock.\"\"\"\n        with self._lock.reader_lock():\n            return self._data.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        \"\"\"Set value with write lock.\"\"\"\n        with self._lock.writer_lock():\n            self._data[key] = value\n    \n    def update(self, other: Dict[str, Any]) -> None:\n        \"\"\"Update multiple values atomically.\"\"\"\n        with self._lock.writer_lock():\n            self._data.update(other)\n```\n\n**Safe JSON Serialization (`utils/serialization.py`)**\n```python\n\"\"\"Safe JSON serialization handling non-serializable objects and circular references.\"\"\"\nimport json\nimport sys\nfrom typing import Any, Dict, Set\nfrom decimal import Decimal\nfrom datetime import datetime, date\n\n\nclass SafeJSONEncoder(json.JSONEncoder):\n    \"\"\"Custom JSON encoder that safely handles non-serializable types.\"\"\"\n    \n    def __init__(self, max_depth: int = 10, max_size: int = 1024 * 1024):\n        super().__init__(ensure_ascii=False, separators=(',', ':'))\n        self.max_depth = max_depth\n        self.max_size = max_size\n        self._visited: Set[int] = set()\n    \n    def default(self, obj: Any) -> Any:\n        \"\"\"Convert non-serializable objects to string representations.\"\"\"\n        if isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return float(obj)\n        elif hasattr(obj, '__dict__'):\n            return f\"<{type(obj).__name__} object>\"\n        else:\n            return str(obj)\n\n\ndef safe_serialize(data: Dict[str, Any], max_depth: int = 10) -> str:\n    \"\"\"\n    Safely serialize dictionary to JSON string with circular reference protection.\n    \n    Args:\n        data: Dictionary to serialize\n        max_depth: Maximum nesting depth to prevent infinite recursion\n        \n    Returns:\n        JSON string representation\n        \n    Raises:\n        ValueError: If data cannot be serialized even with safety measures\n    \"\"\"\n    try:\n        return json.dumps(data, cls=SafeJSONEncoder, max_depth=max_depth)\n    except (TypeError, ValueError, RecursionError) as e:\n        # Fallback: serialize with string conversion\n        safe_data = {k: str(v) for k, v in data.items()}\n        return json.dumps(safe_data, ensure_ascii=False)\n\n\ndef estimate_serialized_size(data: Dict[str, Any]) -> int:\n    \"\"\"\n    Estimate serialized JSON size without full serialization.\n    \n    This is faster than full serialization for size checking.\n    \"\"\"\n    # Simple heuristic: sum of key lengths + estimated value lengths\n    size = 2  # Opening and closing braces\n    for key, value in data.items():\n        size += len(str(key)) + 4  # Key + quotes and colon\n        if isinstance(value, str):\n            size += len(value) + 2  # String + quotes\n        elif isinstance(value, (int, float)):\n            size += len(str(value))\n        elif isinstance(value, (list, dict)):\n            size += 50  # Rough estimate for collections\n        else:\n            size += 20  # Default estimate for other types\n    return size\n```\n\n**Safe Function Execution (`utils/validation.py`)**\n```python\n\"\"\"Validation utilities and safe function execution for error handling.\"\"\"\nimport functools\nimport traceback\nfrom typing import Any, Callable, Optional\n\n\ndef safe_call(func: Callable, *args, default: Any = None, **kwargs) -> Any:\n    \"\"\"\n    Safely execute function with exception handling.\n    \n    Args:\n        func: Function to execute\n        *args: Positional arguments\n        default: Default return value if function fails\n        **kwargs: Keyword arguments\n        \n    Returns:\n        Function result or default value on exception\n    \"\"\"\n    try:\n        return func(*args, **kwargs)\n    except Exception as e:\n        # In a production system, you might want to log this error\n        # But we need to be careful not to create recursive logging\n        print(f\"Safe call failed for {func.__name__}: {e}\", file=sys.stderr)\n        return default\n\n\ndef should_log(message_level: int, configured_level: int) -> bool:\n    \"\"\"\n    Determine if message should be logged based on level filtering.\n    \n    Args:\n        message_level: Severity level of the message\n        configured_level: Minimum level configured for the logger\n        \n    Returns:\n        True if message should be processed, False if it should be filtered\n    \"\"\"\n    return message_level >= configured_level\n```\n\n#### Core Logic Skeletons\n\n**Logger Implementation (`logger.py`)**\n```python\n\"\"\"Core Logger and LogRecord classes - implement these according to the milestone requirements.\"\"\"\nimport threading\nimport time\nfrom typing import Any, Dict, List, Optional\nfrom .utils.validation import should_log, safe_call\nfrom .context import get_current_context\n\n\n# Log level constants - use these exact values\nDEBUG = 10\nINFO = 20\nWARN = 30\nERROR = 40\nFATAL = 50\n\n\nclass LogRecord:\n    \"\"\"Structured log record containing all information about a logging event.\"\"\"\n    \n    def __init__(self, timestamp: str, level: int, message: str, \n                 logger_name: str, context: Dict[str, Any]):\n        self.timestamp = timestamp\n        self.level = level\n        self.message = message\n        self.logger_name = logger_name\n        self.context = context\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert log record to dictionary for JSON serialization.\"\"\"\n        # TODO 1: Create base dictionary with timestamp, level, message, logger_name\n        # TODO 2: Add context fields to the dictionary\n        # TODO 3: Ensure consistent field ordering for predictable output\n        # TODO 4: Handle any non-serializable values in context\n        pass\n\n\nclass Logger:\n    \"\"\"\n    Main logging interface with hierarchy support and handler dispatch.\n    \n    This class implements the core logging functionality including level filtering,\n    context enrichment, and handler dispatch to multiple output destinations.\n    \"\"\"\n    \n    def __init__(self, name: str, level: int = INFO, parent: Optional['Logger'] = None):\n        self.name = name\n        self.level = level\n        self.parent = parent\n        self.handlers: List[Handler] = []\n        self.children: Dict[str, Logger] = {}\n        self._lock = threading.RLock()\n    \n    def log(self, level: int, message: str, **context) -> None:\n        \"\"\"\n        Main logging entry point with filtering and dispatch.\n        \n        Args:\n            level: Severity level of the message\n            message: Human-readable description of the event\n            **context: Additional key-value pairs for structured data\n        \"\"\"\n        # TODO 1: Check if message should be logged using should_log function\n        # TODO 2: Get current timestamp in ISO 8601 format\n        # TODO 3: Retrieve current context from context manager and merge with **context\n        # TODO 4: Create LogRecord object with all information\n        # TODO 5: Dispatch record to all configured handlers\n        # TODO 6: If no handlers on this logger, propagate to parent logger\n        # Hint: Use threading.RLock to ensure thread safety during handler iteration\n        pass\n    \n    def debug(self, message: str, **context) -> None:\n        \"\"\"Log message at DEBUG level.\"\"\"\n        # TODO: Call self.log with DEBUG level\n        pass\n    \n    def info(self, message: str, **context) -> None:\n        \"\"\"Log message at INFO level.\"\"\"\n        # TODO: Call self.log with INFO level\n        pass\n    \n    def warn(self, message: str, **context) -> None:\n        \"\"\"Log message at WARN level.\"\"\"\n        # TODO: Call self.log with WARN level\n        pass\n    \n    def error(self, message: str, **context) -> None:\n        \"\"\"Log message at ERROR level.\"\"\"\n        # TODO: Call self.log with ERROR level\n        pass\n    \n    def fatal(self, message: str, **context) -> None:\n        \"\"\"Log message at FATAL level.\"\"\"\n        # TODO: Call self.log with FATAL level\n        pass\n    \n    def add_handler(self, handler) -> None:\n        \"\"\"Add handler to this logger's dispatch list.\"\"\"\n        # TODO 1: Acquire lock for thread safety\n        # TODO 2: Add handler to handlers list if not already present\n        # TODO 3: Initialize handler if needed\n        pass\n    \n    def get_child(self, name: str) -> 'Logger':\n        \"\"\"Get or create child logger with inherited configuration.\"\"\"\n        # TODO 1: Check if child already exists in self.children\n        # TODO 2: If not, create new Logger with self as parent\n        # TODO 3: Inherit level and handlers from parent\n        # TODO 4: Store in children dictionary and return\n        # Hint: Child logger name should be f\"{self.name}.{name}\"\n        pass\n\n\n# Global logger registry\n_logger_registry: Dict[str, Logger] = {}\n_registry_lock = threading.RLock()\n\n\ndef get_logger(name: str) -> Logger:\n    \"\"\"\n    Get or create logger instance with the given name.\n    \n    Args:\n        name: Hierarchical logger name (e.g., \"app.database.connection\")\n        \n    Returns:\n        Logger instance for the given name\n    \"\"\"\n    # TODO 1: Check if logger already exists in registry\n    # TODO 2: If not, create logger hierarchy based on name (split by '.')\n    # TODO 3: Ensure parent loggers are created first\n    # TODO 4: Store new loggers in registry\n    # TODO 5: Return requested logger\n    # Hint: Use _registry_lock for thread safety\n    pass\n```\n\n**Handler Base Class (`handlers/__init__.py`)**\n```python\n\"\"\"Base handler class and common handler utilities.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Optional\nfrom ..logger import LogRecord\n\n\nclass Handler(ABC):\n    \"\"\"Abstract base class for all log handlers.\"\"\"\n    \n    def __init__(self):\n        self.formatter: Optional['Formatter'] = None\n    \n    @abstractmethod\n    def emit(self, record: LogRecord) -> None:\n        \"\"\"\n        Process and output a single log record.\n        \n        Args:\n            record: LogRecord to be processed and output\n        \"\"\"\n        pass\n    \n    def flush(self) -> None:\n        \"\"\"Ensure all buffered records are written to destination.\"\"\"\n        # Default implementation does nothing - override if handler buffers\n        pass\n    \n    def close(self) -> None:\n        \"\"\"Release resources and perform cleanup.\"\"\"\n        # Default implementation does nothing - override if handler has resources\n        pass\n    \n    def set_formatter(self, formatter) -> None:\n        \"\"\"Configure formatter for this handler.\"\"\"\n        self.formatter = formatter\n    \n    def format_record(self, record: LogRecord) -> str:\n        \"\"\"Format record using configured formatter.\"\"\"\n        if self.formatter:\n            return self.formatter.format(record)\n        else:\n            # Default formatting if no formatter configured\n            return f\"[{record.timestamp}] {record.level}: {record.message}\"\n```\n\n#### File Structure Setup\n\nCreate the recommended directory structure with these commands:\n\n```bash\nmkdir -p structured_logging/{handlers,formatters,context,utils,config,tests/{unit,integration,performance}}\ntouch structured_logging/__init__.py\ntouch structured_logging/{logger,handlers,formatters,context,utils,config}/__init__.py\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Checkpoint - Logger Core**\nAfter implementing the core logger functionality:\n\n```bash\n# Test basic logging functionality\npython -c \"\nfrom structured_logging import get_logger\nlogger = get_logger('test')\nlogger.info('Test message', user_id=123)\nlogger.error('Error occurred', error_code='E001')\n\"\n```\n\nExpected behavior:\n- Messages should appear on console (if console handler configured)\n- DEBUG messages should be filtered out when logger level is INFO or higher\n- Context fields (user_id, error_code) should be included in output\n- Multiple threads calling logger methods should not corrupt output\n\n**Milestone 2 Checkpoint - Structured Output**\nAfter implementing JSON formatting:\n\n```python\n# Test JSON output formatting\nfrom structured_logging import get_logger\nfrom structured_logging.formatters.json import JSONFormatter\nfrom structured_logging.handlers.console import ConsoleHandler\n\nlogger = get_logger('test')\nhandler = ConsoleHandler()\nhandler.set_formatter(JSONFormatter())\nlogger.add_handler(handler)\n\nlogger.info('User action', action='login', user_id=123, success=True)\n```\n\nExpected output (single line JSON):\n```json\n{\"timestamp\":\"2024-01-15T10:30:45.123456Z\",\"level\":20,\"message\":\"User action\",\"logger_name\":\"test\",\"action\":\"login\",\"user_id\":123,\"success\":true}\n```\n\n**Milestone 3 Checkpoint - Context & Correlation**\nAfter implementing context propagation:\n\n```python\n# Test context propagation\nfrom structured_logging import get_logger, with_context\nfrom structured_logging.context import correlation_id\n\nlogger = get_logger('test')\n\nwith with_context(request_id=correlation_id(), user_id=456):\n    logger.info('Processing request')\n    \n    def nested_function():\n        logger.info('Inside nested function')  # Should inherit context\n    \n    nested_function()\n```\n\nExpected behavior:\n- Both log messages should contain the same request_id and user_id\n- Context should propagate through nested function calls without explicit passing\n- Each request should have a unique correlation ID\n\n#### Language-Specific Hints\n\n- Use `threading.RLock()` instead of `Lock()` for reentrant locking in logger hierarchy\n- `datetime.utcnow().isoformat() + 'Z'` provides ISO 8601 timestamps\n- `**dict1, **dict2` syntax merges dictionaries in Python 3.5+\n- `threading.local()` provides thread-local storage for context propagation\n- `contextvars` module (Python 3.7+) handles async context better than threading.local\n- `sys.stderr.write()` avoids recursive logging when reporting logging system errors\n- Use `json.dumps(separators=(',', ':'))` for compact JSON output\n- `functools.wraps` preserves function metadata in decorators for context managers\n\n#### Common Debugging Issues\n\n| Symptom | Likely Cause | Fix |\n|---------|-------------|-----|\n| No log output appears | No handlers configured or wrong level | Add console handler, check logger.level vs message level |\n| Thread safety errors | Missing locks around shared data | Use threading.RLock around handler lists and logger registry |\n| Context not propagating | Thread-local storage not inherited | Implement proper context copying in nested calls |\n| JSON serialization errors | Non-serializable objects in context | Use SafeJSONEncoder and safe_serialize function |\n| Performance degradation | Synchronous I/O in handlers | Implement async handlers or background thread dispatch |\n\n\n## Data Model\n\n> **Milestone(s):** This section defines the foundational data structures used across all three milestones, with LogRecord and LogLevel supporting Milestone 1 (Logger Core), structured output requirements for Milestone 2 (Structured Output), and Context objects enabling Milestone 3 (Context & Correlation).\n\nThe data model forms the backbone of our structured logging system, defining how log information is represented, organized, and processed throughout the entire logging pipeline. Think of the data model as the **blueprint for a filing system** in a busy law firm - every piece of information has a specific place, format, and relationship to other pieces, ensuring that when thousands of documents (log records) flow through the system daily, they can be efficiently organized, searched, and correlated.\n\nJust as a law firm needs consistent document formats to handle cases involving multiple lawyers, departments, and time periods, our logging system needs consistent data structures to handle log messages from multiple threads, services, and request contexts. The data model ensures that whether a log record originates from a background task, an HTTP request handler, or an async coroutine, it follows the same structure and can be processed uniformly by formatters and handlers.\n\n![Data Model Relationships](./diagrams/data-model-relationships.svg)\n\nThe three core data structures - `LogRecord`, `LogLevel`, and `Context` - work together to provide a complete logging solution. The `LogRecord` serves as the central container for all log information, the `LogLevel` provides a hierarchy for filtering and prioritization, and the `Context` enables correlation and enrichment across related operations.\n\n> **Design Principle**: Every piece of log data has a well-defined structure and type, enabling consistent processing, serialization, and querying regardless of the log's origin or destination.\n\n### LogRecord Structure\n\nThe `LogRecord` represents a single log entry in our system, containing all the information necessary to understand what happened, when it happened, where it happened, and under what circumstances. Think of a `LogRecord` as a **standardized incident report form** that emergency responders fill out - it has specific fields for date, time, location, severity, description, and context, ensuring that no matter who creates the report or where it's processed, all the essential information is captured in a consistent format.\n\nThe `LogRecord` structure balances completeness with performance, including only the fields necessary for effective debugging and monitoring while remaining lightweight enough for high-volume logging scenarios.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `timestamp` | `str` | ISO 8601 formatted timestamp indicating when the log record was created, with microsecond precision |\n| `level` | `int` | Numeric log level (10-50) indicating the severity and importance of the message |\n| `message` | `str` | Human-readable description of the logged event, formatted with any provided arguments |\n| `logger_name` | `str` | Hierarchical name of the logger that created this record (e.g., \"app.database.connection\") |\n| `context` | `Dict[str, Any]` | Key-value pairs providing additional structured information about the logged event |\n\nThe `timestamp` field uses ISO 8601 format (e.g., \"2023-10-15T14:30:45.123456Z\") to ensure consistent parsing across different systems and time zones. This format is chosen over Unix timestamps because it's human-readable in log files while remaining machine-parseable for aggregation systems.\n\nThe `level` field stores the numeric representation of the log level rather than the string name for efficient filtering operations. Converting \"DEBUG\" string comparisons to integer comparisons (10 < 20) provides significant performance benefits when processing high volumes of log messages.\n\nThe `logger_name` captures the complete hierarchical path of the logger, enabling log aggregation and filtering by component or subsystem. For example, \"app.web.auth.login\" indicates this log came from the login component of the authentication subsystem of the web layer.\n\n> **Decision: Flat LogRecord Structure**\n> - **Context**: We need to balance query flexibility with serialization performance and cross-language compatibility.\n> - **Options Considered**: \n>   1. Nested object structure with separate metadata objects\n>   2. Flat structure with all fields at the top level\n>   3. Extensible structure with custom field registration\n> - **Decision**: Flat structure with fixed core fields and flexible context dictionary\n> - **Rationale**: Flat structures serialize faster to JSON, are easier to query in log aggregation systems, and avoid the complexity of nested object validation while still providing extensibility through the context field\n> - **Consequences**: Enables fast JSON serialization and simple log queries, but requires discipline to avoid context field name conflicts\n\nThe `context` field serves as the extensibility point for the `LogRecord`, allowing arbitrary structured data to be attached to log entries without modifying the core structure. This field supports the correlation and enrichment patterns needed in distributed systems.\n\n**Context Field Usage Patterns:**\n\n| Usage Pattern | Example Keys | Description |\n|---------------|--------------|-------------|\n| Request Correlation | `request_id`, `trace_id`, `span_id` | Identifiers linking related log entries across service boundaries |\n| User Context | `user_id`, `session_id`, `organization_id` | Identity information for access correlation and debugging |\n| Performance Metrics | `duration_ms`, `query_time`, `cache_hit` | Timing and performance data for monitoring and optimization |\n| Error Details | `error_code`, `stack_trace`, `retry_count` | Structured error information for debugging and alerting |\n| Business Context | `order_id`, `product_id`, `workflow_step` | Domain-specific identifiers for business logic debugging |\n\nThe `LogRecord` design emphasizes **immutability** - once created, a log record should not be modified. This prevents race conditions in multi-threaded environments and ensures that log records remain consistent as they flow through the handler dispatch system.\n\n### Log Level Hierarchy\n\nThe log level hierarchy provides a standardized way to categorize log messages by importance and urgency, enabling runtime filtering and appropriate routing of messages to different output destinations. Think of log levels as a **hospital triage system** - just as medical staff categorize patients by urgency (critical, urgent, standard, routine) to ensure the most important cases receive immediate attention, log levels categorize messages so that critical errors are never missed while verbose debug information can be filtered out in production.\n\nThe five-level hierarchy balances granularity with simplicity, providing enough categories to enable meaningful filtering without creating confusion about which level to choose for a given message.\n\n| Level Name | Numeric Value | Usage Guidelines | Production Visibility |\n|------------|---------------|------------------|----------------------|\n| `DEBUG` | 10 | Detailed diagnostic information for development troubleshooting | Typically filtered out |\n| `INFO` | 20 | General application flow and business logic milestones | Selectively logged |\n| `WARN` | 30 | Warning conditions that don't prevent operation but may indicate problems | Always logged |\n| `ERROR` | 40 | Error conditions that prevent specific operations but don't crash the application | Always logged and monitored |\n| `FATAL` | 50 | Critical errors that may cause application shutdown or data corruption | Always logged, triggers alerts |\n\nThe numeric values are spaced by 10 to allow for future intermediate levels if needed, following the convention established by systems like Python's logging module. This spacing provides flexibility while maintaining the core five-level structure.\n\n**Level Filtering Behavior:**\n\nThe log level filtering follows a simple rule: messages are processed only if their level is greater than or equal to the configured minimum level. For example, a logger configured at `INFO` level (20) will process `INFO`, `WARN`, `ERROR`, and `FATAL` messages while filtering out `DEBUG` messages.\n\n| Configured Level | DEBUG (10) | INFO (20) | WARN (30) | ERROR (40) | FATAL (50) |\n|------------------|------------|-----------|-----------|-----------|------------|\n| DEBUG (10) | ✓ Process | ✓ Process | ✓ Process | ✓ Process | ✓ Process |\n| INFO (20) | ✗ Filter | ✓ Process | ✓ Process | ✓ Process | ✓ Process |\n| WARN (30) | ✗ Filter | ✗ Filter | ✓ Process | ✓ Process | ✓ Process |\n| ERROR (40) | ✗ Filter | ✗ Filter | ✗ Filter | ✓ Process | ✓ Process |\n| FATAL (50) | ✗ Filter | ✗ Filter | ✗ Filter | ✗ Filter | ✓ Process |\n\n> **Decision: Numeric Log Levels with Fixed Hierarchy**\n> - **Context**: We need efficient runtime filtering and clear severity ordering for both humans and machines.\n> - **Options Considered**: \n>   1. String-based levels with runtime string comparison\n>   2. Numeric levels with fixed integer values\n>   3. Configurable custom level hierarchies\n> - **Decision**: Fixed numeric hierarchy with standard five levels\n> - **Rationale**: Integer comparison (`message_level >= configured_level`) is faster than string comparison, fixed hierarchy prevents configuration errors and ensures consistent behavior across environments, five levels provide sufficient granularity without decision paralysis\n> - **Consequences**: Enables fast filtering operations and consistent cross-team usage, but prevents custom level definitions for specialized use cases\n\nThe level hierarchy supports **inheritance** in logger hierarchies - child loggers inherit the minimum level from their parent unless explicitly overridden. This enables configuration patterns where an entire subsystem's logging level can be controlled by setting the parent logger's level.\n\n**Runtime Level Changes:**\n\nLog levels can be modified at runtime without requiring application restart, enabling dynamic debugging and troubleshooting. This capability is essential for production environments where restarting applications to enable debug logging is not feasible.\n\nThe level change operation must be thread-safe and atomic to prevent inconsistent filtering behavior. Changes take effect immediately for new log messages, but do not affect log records already in the processing pipeline.\n\n### Context Data Model\n\nThe context data model enables **correlation and enrichment** of log records with structured metadata that flows through the application execution context. Think of the context as a **digital breadcrumb trail** that follows a request or operation through the system - as the request moves from HTTP parsing to database queries to external API calls, each component can add relevant information to the trail while benefiting from information added by previous components.\n\nContext propagation is essential for debugging distributed systems and understanding the relationships between log entries that may be separated by time, threads, or even service boundaries.\n\n**Context Structure and Semantics:**\n\n| Aspect | Implementation | Description |\n|---------|----------------|-------------|\n| Storage | `Dict[str, Any]` | Key-value pairs with string keys and arbitrary JSON-serializable values |\n| Inheritance | Parent → Child | Child contexts inherit all key-value pairs from their parent context |\n| Scope | Thread/Task Local | Context is automatically scoped to the current execution thread or async task |\n| Lifecycle | Request Bounded | Context typically created at request start and cleaned up at request end |\n| Propagation | Automatic | Context flows through function calls without explicit parameter passing |\n\nThe context data model supports several inheritance and propagation patterns that enable both automatic context flow and explicit context management.\n\n**Context Inheritance Patterns:**\n\n| Pattern | Use Case | Behavior | Example |\n|---------|----------|----------|---------|\n| Automatic Inheritance | HTTP request processing | Child operations inherit request ID and user context | Request handler → Database call → Cache lookup |\n| Explicit Context Addition | Component-specific metadata | Components add their own context while preserving parent context | Authentication adds user ID, database adds query time |\n| Context Isolation | Background tasks | New context created for background operations | Async task spawned with empty context |\n| Context Override | Error handling | Specific fields can be overridden in child contexts | Retry logic overrides attempt count |\n\n> **Decision: Thread-Local Context Storage with Async Bridge**\n> - **Context**: We need context to propagate automatically through function calls while supporting both synchronous and asynchronous execution models.\n> - **Options Considered**: \n>   1. Explicit context parameter passing through all function calls\n>   2. Thread-local storage for synchronous code only\n>   3. Thread-local storage with async context variable bridge\n> - **Decision**: Thread-local storage with automatic async context preservation\n> - **Rationale**: Thread-local storage eliminates the need to modify all function signatures while providing automatic propagation, async context variables ensure context survives task switches and coroutine boundaries, combination supports both sync and async patterns without code changes\n> - **Consequences**: Enables seamless context propagation and cleaner function signatures, but requires careful lifecycle management to prevent context leaks\n\n**Context Lifecycle Management:**\n\nContext objects follow a clear lifecycle to prevent memory leaks and ensure proper isolation between different operations:\n\n1. **Creation**: New context created at operation boundary (HTTP request, background task, etc.)\n2. **Population**: Initial context fields added (request ID, user information, etc.)\n3. **Inheritance**: Child operations inherit context and may add additional fields\n4. **Propagation**: Context flows through synchronous calls via thread-local storage\n5. **Async Bridge**: Context preserved across async/await boundaries using context variables\n6. **Cleanup**: Context cleared at operation completion to prevent memory leaks\n\n**Context Field Naming Conventions:**\n\nTo prevent field name conflicts and enable consistent querying, context fields follow standardized naming patterns:\n\n| Field Category | Naming Pattern | Examples | Purpose |\n|----------------|----------------|----------|----------|\n| Correlation IDs | `{scope}_id` | `request_id`, `trace_id`, `span_id` | Linking related log entries |\n| User Context | `user_{attribute}` | `user_id`, `user_role`, `user_org` | Identity and authorization context |\n| Performance | `{metric}_{unit}` | `duration_ms`, `memory_mb`, `cpu_percent` | Performance monitoring data |\n| Business Data | `{domain}_{entity}` | `order_id`, `product_sku`, `workflow_step` | Business logic context |\n| Component Info | `{component}_{detail}` | `db_query`, `api_endpoint`, `cache_key` | Component-specific information |\n\n**Context Serialization and Size Limits:**\n\nContext data must remain JSON-serializable to support structured output formats. The context system includes size estimation and circular reference detection to prevent serialization failures and excessive memory usage.\n\n| Constraint | Limit | Behavior When Exceeded |\n|------------|--------|------------------------|\n| Maximum Fields | 50 | Additional fields logged as warning, oldest fields preserved |\n| Maximum Field Size | 1KB per field | Large fields truncated with indication of truncation |\n| Maximum Total Size | 10KB per context | Context pruned starting with newest non-correlation fields |\n| Serialization Depth | 10 levels | Deep nested objects flattened or truncated |\n| Circular References | Not allowed | Detected and replaced with reference marker |\n\nThe context data model enables powerful correlation and debugging capabilities while maintaining performance and reliability constraints necessary for production logging systems.\n\n### Implementation Guidance\n\nThis subsection provides concrete implementation patterns and starter code for the core data structures, focusing on thread safety, serialization, and performance considerations that junior developers commonly struggle with.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Timestamp Generation | `datetime.utcnow().isoformat()` | `time.time_ns()` with custom ISO formatter |\n| JSON Serialization | `json.dumps()` with custom encoder | `orjson` or `ujson` for performance |\n| Thread-Local Storage | `threading.local()` | `contextvars` for async support |\n| Context Size Estimation | `len(json.dumps())` | Custom recursive size calculator |\n\n**Recommended Module Structure:**\n\n```\nstructured_logging/\n  core/\n    __init__.py           ← exports LogRecord, LogLevel constants\n    log_record.py         ← LogRecord class and factory functions\n    log_level.py          ← log level constants and filtering utilities\n    context.py            ← context management and propagation\n  utils/\n    serialization.py      ← safe JSON encoding and size estimation\n    thread_safety.py      ← thread-safe data structures\n  tests/\n    test_log_record.py    ← LogRecord creation and serialization tests\n    test_context.py       ← context propagation and inheritance tests\n```\n\n**Infrastructure Starter Code:**\n\nComplete implementation of thread-safe utilities and serialization helpers:\n\n```python\n# utils/serialization.py\nimport json\nimport sys\nfrom typing import Any, Dict\nfrom decimal import Decimal\nfrom datetime import datetime, date\n\nclass SafeJSONEncoder(json.JSONEncoder):\n    \"\"\"Custom JSON encoder that handles non-serializable types safely.\"\"\"\n    \n    def default(self, obj: Any) -> Any:\n        if isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n        elif isinstance(obj, Decimal):\n            return float(obj)\n        elif hasattr(obj, '__dict__'):\n            return f\"<{obj.__class__.__name__} object>\"\n        elif hasattr(obj, '__str__'):\n            return str(obj)\n        else:\n            return f\"<non-serializable: {type(obj).__name__}>\"\n\ndef safe_serialize(data: Dict[str, Any], max_depth: int = 10) -> str:\n    \"\"\"Safely serialize dictionary to JSON with circular reference protection.\"\"\"\n    def _check_depth(obj, current_depth=0):\n        if current_depth >= max_depth:\n            return f\"<max_depth_exceeded: {max_depth}>\"\n        \n        if isinstance(obj, dict):\n            return {k: _check_depth(v, current_depth + 1) for k, v in obj.items()}\n        elif isinstance(obj, (list, tuple)):\n            return [_check_depth(item, current_depth + 1) for item in obj]\n        else:\n            return obj\n    \n    try:\n        safe_data = _check_depth(data)\n        return json.dumps(safe_data, cls=SafeJSONEncoder, separators=(',', ':'))\n    except (TypeError, ValueError) as e:\n        return json.dumps({\"serialization_error\": str(e)}, separators=(',', ':'))\n\ndef estimate_serialized_size(data: Dict[str, Any]) -> int:\n    \"\"\"Estimate JSON size without full serialization for performance.\"\"\"\n    # TODO 1: Implement recursive size estimation\n    # TODO 2: Handle strings, numbers, booleans with known sizes  \n    # TODO 3: Estimate dict/list overhead (brackets, commas, quotes)\n    # TODO 4: Return estimated byte count\n    # Hint: Use sys.getsizeof() as baseline, add JSON syntax overhead\n    pass\n\n# utils/thread_safety.py\nimport threading\nfrom typing import Any, Dict\n\nclass ThreadSafeDict:\n    \"\"\"Thread-safe dictionary wrapper for shared logging context.\"\"\"\n    \n    def __init__(self):\n        self._data: Dict[str, Any] = {}\n        self._lock = threading.RLock()  # Re-entrant lock for nested access\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        with self._lock:\n            return self._data.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        with self._lock:\n            self._data[key] = value\n    \n    def update(self, other: Dict[str, Any]) -> None:\n        with self._lock:\n            self._data.update(other)\n    \n    def copy(self) -> Dict[str, Any]:\n        with self._lock:\n            return self._data.copy()\n    \n    def clear(self) -> None:\n        with self._lock:\n            self._data.clear()\n\nclass ThreadSafeCounter:\n    \"\"\"Thread-safe counter for generating unique IDs.\"\"\"\n    \n    def __init__(self, initial_value: int = 0):\n        self._value = initial_value\n        self._lock = threading.Lock()\n    \n    def next(self) -> int:\n        with self._lock:\n            self._value += 1\n            return self._value\n```\n\n**Core Logic Skeleton Code:**\n\n```python\n# core/log_level.py\nDEBUG = 10\nINFO = 20  \nWARN = 30\nERROR = 40\nFATAL = 50\n\n# Level name mappings for display\nLEVEL_NAMES = {\n    DEBUG: \"DEBUG\",\n    INFO: \"INFO\", \n    WARN: \"WARN\",\n    ERROR: \"ERROR\",\n    FATAL: \"FATAL\"\n}\n\ndef should_log(message_level: int, configured_level: int) -> bool:\n    \"\"\"Determine if message should be logged based on level filtering.\"\"\"\n    # TODO 1: Compare message_level against configured_level\n    # TODO 2: Return True if message_level >= configured_level\n    # TODO 3: Handle invalid level values (default to allowing the message)\n    # Hint: Simple integer comparison, but validate inputs first\n    pass\n\n# core/log_record.py\nfrom datetime import datetime\nfrom typing import Dict, Any\nfrom .log_level import LEVEL_NAMES\n\nclass LogRecord:\n    \"\"\"Immutable log record containing all information for a single log entry.\"\"\"\n    \n    def __init__(self, timestamp: str, level: int, message: str, \n                 logger_name: str, context: Dict[str, Any]):\n        # TODO 1: Store all parameters as instance attributes\n        # TODO 2: Make context a copy to ensure immutability\n        # TODO 3: Validate that level is a known log level value\n        # TODO 4: Ensure timestamp is ISO 8601 format string\n        # Hint: Use context.copy() to prevent external modification\n        pass\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert log record to dictionary for JSON serialization.\"\"\"\n        # TODO 1: Create dictionary with all core fields\n        # TODO 2: Add level_name field for human readability  \n        # TODO 3: Merge in context fields at top level\n        # TODO 4: Return complete dictionary ready for JSON serialization\n        # Hint: Use LEVEL_NAMES mapping to get level_name from numeric level\n        pass\n    \n    @classmethod\n    def create(cls, level: int, message: str, logger_name: str, \n               context: Dict[str, Any] = None) -> 'LogRecord':\n        \"\"\"Factory method to create LogRecord with current timestamp.\"\"\"\n        # TODO 1: Generate ISO 8601 timestamp string\n        # TODO 2: Handle None context by providing empty dict\n        # TODO 3: Create and return LogRecord instance\n        # TODO 4: Consider timezone handling for timestamp\n        # Hint: Use datetime.utcnow().isoformat() + 'Z' for UTC timestamp\n        pass\n\n# core/context.py\nimport threading\nimport contextvars\nfrom typing import Dict, Any, Optional\n\n# Context variable for async context preservation\n_context_var: contextvars.ContextVar[Dict[str, Any]] = contextvars.ContextVar('log_context', default={})\n\n# Thread-local storage for sync context\n_thread_local = threading.local()\n\nclass LoggingContext:\n    \"\"\"Manages logging context with thread-local and async support.\"\"\"\n    \n    @staticmethod\n    def get_current() -> Dict[str, Any]:\n        \"\"\"Get current logging context, trying async context first.\"\"\"\n        # TODO 1: Try to get context from contextvars (for async)\n        # TODO 2: Fall back to thread-local storage (for sync)\n        # TODO 3: Return empty dict if no context is set\n        # TODO 4: Handle AttributeError from thread-local access\n        # Hint: Use try/except for both contextvar and thread-local access\n        pass\n    \n    @staticmethod  \n    def set_current(context: Dict[str, Any]) -> None:\n        \"\"\"Set current logging context in both async and sync storage.\"\"\"\n        # TODO 1: Set context in contextvars for async compatibility\n        # TODO 2: Set context in thread-local storage for sync compatibility  \n        # TODO 3: Handle case where context is None\n        # TODO 4: Ensure context is copied to prevent external modification\n        # Hint: Set both _context_var and _thread_local.context\n        pass\n    \n    @staticmethod\n    def add_fields(**fields: Any) -> None:\n        \"\"\"Add fields to current context without replacing existing context.\"\"\"\n        # TODO 1: Get current context dictionary\n        # TODO 2: Create new context with existing fields plus new fields\n        # TODO 3: Set the updated context as current\n        # TODO 4: Handle case where no current context exists\n        # Hint: Use get_current(), update with new fields, call set_current()\n        pass\n    \n    @staticmethod\n    def clear() -> None:\n        \"\"\"Clear current logging context.\"\"\"\n        # TODO 1: Clear contextvars context\n        # TODO 2: Clear thread-local context  \n        # TODO 3: Handle AttributeError if thread-local not initialized\n        # TODO 4: Ensure both storage mechanisms are cleared\n        # Hint: Set empty dict in both storage locations\n        pass\n```\n\n**Language-Specific Implementation Hints:**\n\n- **Thread Safety**: Use `threading.RLock()` instead of `Lock()` for context management to allow re-entrant access within the same thread\n- **Async Context**: Python's `contextvars` automatically handles async context preservation across `await` boundaries\n- **JSON Serialization**: The `json` module's `separators=(',', ':')` parameter eliminates whitespace for compact output\n- **Immutability**: Use `context.copy()` in LogRecord constructor to prevent external modification of context data\n- **Performance**: Consider `__slots__` on LogRecord class to reduce memory overhead for high-volume logging\n\n**Milestone Checkpoint:**\n\nAfter implementing the data model:\n\n1. **Run Unit Tests**: `python -m pytest tests/test_log_record.py tests/test_context.py -v`\n2. **Expected Output**: All tests pass, demonstrating LogRecord creation, serialization, and context propagation\n3. **Manual Verification**:\n   ```python\n   from core.log_record import LogRecord\n   from core.context import LoggingContext\n   \n   # Test LogRecord creation and serialization\n   record = LogRecord.create(INFO, \"Test message\", \"test.logger\", {\"user_id\": 123})\n   print(record.to_dict())  # Should show structured dictionary\n   \n   # Test context propagation\n   LoggingContext.set_current({\"request_id\": \"abc123\"})\n   context = LoggingContext.get_current()\n   print(context)  # Should show {\"request_id\": \"abc123\"}\n   ```\n\n4. **Signs of Problems**:\n   - **Serialization failures**: Check SafeJSONEncoder implementation and circular reference handling  \n   - **Context not propagating**: Verify both contextvars and thread-local storage are being set\n   - **Thread safety issues**: Add logging to identify race conditions in concurrent tests\n   - **Memory leaks**: Ensure context.clear() is called and contexts are properly scoped\n\nThe data model implementation provides the foundation for all subsequent logging functionality, ensuring consistent data representation and thread-safe operations across the entire system.\n\n\n## Logger Core Design\n\n> **Milestone(s):** This section primarily addresses Milestone 1 (Logger Core) by defining the central logging infrastructure, hierarchy system, level filtering, thread safety mechanisms, and handler dispatch patterns that form the foundation for all subsequent structured logging capabilities.\n\n### Mental Model: The News Organization\n\nThink of the logging system as a large news organization with multiple departments and bureaus. The **logger hierarchy** works like the organizational chart — the main newsroom (`root` logger) oversees regional bureaus (`child` loggers), which in turn manage local reporters (`leaf` loggers). Each level inherits editorial standards and distribution channels from above, but can add their own specific context and formatting.\n\n**Log level filtering** operates like editorial decisions about what stories make it to print. A DEBUG message is like a reporter's personal note — interesting for development but filtered out in production. An ERROR message is like breaking news that must reach every output channel immediately. The **handler dispatch system** functions like the news distribution network — the same story (log record) gets formatted appropriately and sent to newspapers (console), archives (files), and wire services (remote collectors) simultaneously.\n\nThis mental model helps understand why thread safety matters (multiple reporters filing stories concurrently), why context propagation is essential (maintaining story lineage), and why handler failure recovery is critical (ensuring important news reaches at least one destination).\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n### Logger Hierarchy System\n\nThe logger hierarchy provides a tree-structured namespace that mirrors application architecture while enabling configuration inheritance and context flow. This design allows fine-grained control over logging behavior at different application layers without requiring explicit configuration at every level.\n\n#### Hierarchy Structure and Naming\n\nThe logger hierarchy follows a dot-separated naming convention that reflects application structure. The root logger sits at the top with an empty name, while child loggers use qualified names like `web`, `web.auth`, `web.auth.jwt`, and `database.connection.pool`. This naming strategy provides intuitive organization and enables powerful inheritance patterns.\n\n| Logger Name | Parent | Level Inherited | Handlers Inherited | Context Inherited |\n|-------------|--------|-----------------|-------------------|-------------------|\n| `` (root) | None | INFO (default) | [ConsoleHandler] | {} |\n| `web` | root | INFO | [ConsoleHandler] | {service: \"web\"} |\n| `web.auth` | web | INFO | [ConsoleHandler] | {service: \"web\", component: \"auth\"} |\n| `web.auth.jwt` | web.auth | DEBUG (overridden) | [ConsoleHandler, FileHandler] | {service: \"web\", component: \"auth\", module: \"jwt\"} |\n| `database` | root | WARN (overridden) | [ConsoleHandler, RemoteHandler] | {service: \"database\"} |\n\nEach logger maintains references to its parent and children, creating a bidirectional tree structure that supports both top-down configuration propagation and bottom-up context enrichment. The `Logger` type encapsulates this relationship:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `name` | str | Dot-separated qualified name identifying this logger's position in hierarchy |\n| `level` | int | Minimum log level for this logger (DEBUG=10, INFO=20, WARN=30, ERROR=40, FATAL=50) |\n| `parent` | Logger | Reference to parent logger for inheritance, None only for root logger |\n| `handlers` | List[Handler] | Output destinations specific to this logger, combined with inherited handlers |\n| `children` | Dict[str, Logger] | Map of child logger names to Logger instances for hierarchy navigation |\n| `context` | Dict[str, Any] | Key-value pairs automatically attached to all log records from this logger |\n| `propagate` | bool | Whether log records should bubble up to parent handlers (default True) |\n\n#### Configuration Inheritance Behavior\n\nConfiguration inheritance flows down the hierarchy, with child loggers inheriting level, handlers, and context from their parents while maintaining the ability to override or extend these settings. This inheritance mechanism reduces configuration duplication while preserving flexibility for special cases.\n\n**Level inheritance** follows a \"most specific wins\" pattern. If a logger doesn't have an explicitly configured level, it inherits from its parent, walking up the hierarchy until it finds a configured level or reaches the root (which defaults to INFO). This approach ensures predictable behavior while minimizing configuration overhead.\n\n**Handler inheritance** combines parent and child handlers unless explicitly disabled. When a log record is generated, it gets dispatched to the logger's own handlers plus all inherited handlers from parent loggers. The `propagate` flag controls whether records bubble up to parent handlers, enabling scenarios where sensitive components log only to specific destinations.\n\n**Context inheritance** merges parent context fields with child-specific fields, with child values taking precedence for duplicate keys. This creates a natural layering where service-level context (like `service: \"web\"`) gets automatically combined with component-level context (like `component: \"auth\"`) and request-specific context (like `request_id: \"abc123\"`).\n\n> **Design Insight**: The inheritance model balances convenience with control. Most loggers inherit sensible defaults, reducing boilerplate configuration, while performance-critical or security-sensitive components can override settings precisely where needed.\n\n#### Logger Factory and Lifecycle\n\nThe logger hierarchy uses a factory pattern to ensure singleton behavior and proper parent-child linking. The `get_logger(name)` function serves as the single entry point for logger creation, maintaining a global registry to prevent duplicate instances and ensure consistent hierarchy structure.\n\n**Logger Creation Process**:\n1. Parse the requested logger name to identify hierarchy path components\n2. Walk the hierarchy from root to target, creating any missing intermediate loggers\n3. Link each new logger to its parent and register it in the parent's children dictionary\n4. Initialize the new logger with inherited configuration from its parent\n5. Register the logger in the global name-to-instance mapping for future lookups\n6. Return the logger instance (creating or retrieving existing)\n\nThe factory maintains thread safety through a global lock during logger creation, ensuring that concurrent requests for the same logger name return the same instance without race conditions. Once created, loggers are immutable in their hierarchy relationships but mutable in their configuration to support runtime level changes.\n\n> **Architecture Decision: Singleton Logger Instances**\n> - **Context**: Multiple parts of an application may request loggers with the same name\n> - **Options Considered**: \n>   1. Create new logger instances for each request\n>   2. Use singleton pattern with global registry\n>   3. Require explicit logger instance passing\n> - **Decision**: Singleton pattern with global registry\n> - **Rationale**: Ensures consistent configuration and context across all usage sites, eliminates need for dependency injection of logger instances, simplifies logger hierarchy management\n> - **Consequences**: Global state requires thread safety, enables convenient logger access but reduces testability, configuration changes affect all code using the same logger name\n\n### Log Level Filtering\n\nLog level filtering provides the primary mechanism for controlling logging verbosity in different environments. The filtering system must be efficient enough for hot code paths while supporting runtime reconfiguration without application restart.\n\n#### Level Hierarchy and Numeric Ordering\n\nThe log level system uses numeric values to enable efficient comparison and filtering. Higher numbers indicate higher severity, making the filtering logic a simple numeric comparison rather than complex string matching or lookup operations.\n\n| Level Name | Numeric Value | Typical Usage | Production Visibility |\n|------------|---------------|---------------|----------------------|\n| `DEBUG` | 10 | Detailed diagnostic information | Hidden |\n| `INFO` | 20 | General application flow | Visible |\n| `WARN` | 30 | Unusual but handled conditions | Visible |\n| `ERROR` | 40 | Error conditions requiring attention | Always visible |\n| `FATAL` | 50 | Critical errors causing termination | Always visible |\n\nThe `should_log(message_level, configured_level)` function implements the core filtering logic with a simple comparison: `message_level >= configured_level`. This design ensures that setting a logger to WARN level will include WARN, ERROR, and FATAL messages while filtering out DEBUG and INFO messages.\n\n#### Efficient Level Checking\n\nThe level filtering system optimizes for the common case where messages are filtered out. The `log()` method performs level checking before any expensive operations like string formatting, context gathering, or handler dispatch. This early-exit pattern prevents performance degradation when verbose logging is enabled in hot code paths.\n\n**Level Check Optimization Strategy**:\n1. Check message level against logger's configured level using simple integer comparison\n2. Exit immediately if message should be filtered, avoiding all downstream processing\n3. Only proceed with LogRecord creation, formatting, and handler dispatch for messages that pass filtering\n4. Cache the logger's effective level to avoid walking parent hierarchy on every message\n\nThe effective level calculation walks up the logger hierarchy to find the nearest explicitly configured level, but this traversal only occurs when the logger's level changes, not on every log message. The result gets cached in the logger instance until configuration changes invalidate the cache.\n\n#### Runtime Level Reconfiguration\n\nThe logging system supports runtime level changes without application restart, enabling dynamic debugging and troubleshooting in production environments. Level changes propagate through the hierarchy using a cache invalidation mechanism that ensures consistent behavior across all loggers.\n\n| Operation | Thread Safety | Propagation | Performance Impact |\n|-----------|---------------|-------------|-------------------|\n| `set_level(level)` | Write lock on logger | Invalidates child caches | O(1) for single logger |\n| `get_effective_level()` | Read lock on hierarchy | Walks up parent chain | O(depth) cached result |\n| `should_log(level)` | Read-only comparison | No propagation needed | O(1) cached lookup |\n\n**Level Change Propagation**:\n1. Acquire write lock on target logger to prevent concurrent modifications\n2. Update logger's configured level and invalidate its cached effective level\n3. Walk all descendant loggers and invalidate their cached effective levels\n4. Release locks and allow normal logging operations to resume\n5. Next log operation on each affected logger recalculates effective level as needed\n\n> **Design Insight**: Runtime level changes are intentionally rare operations that can afford more expensive propagation logic. The common case of level checking during normal logging remains highly optimized with cached effective levels.\n\n![Logger Hierarchy Structure](./diagrams/logger-hierarchy.svg)\n\n### Thread Safety Design\n\nThe logging system must handle concurrent access from multiple threads without corrupting output, losing messages, or introducing race conditions. The thread safety design balances correctness with performance, ensuring that logging operations remain fast in single-threaded scenarios while providing strong guarantees in multi-threaded environments.\n\n#### Locking Strategy and Granularity\n\nThe thread safety design employs a multi-level locking strategy with different granularity for different operations. This approach minimizes contention while ensuring data consistency across concurrent operations.\n\n| Component | Lock Type | Granularity | Protected Operations |\n|-----------|-----------|-------------|---------------------|\n| Logger Registry | RWLock | Global | Logger creation, hierarchy modification |\n| Logger Instance | RWLock | Per-logger | Level changes, handler modification |\n| Handler Collection | RWLock | Per-logger | Handler list modification |\n| Log Record Creation | No lock | Thread-local | Timestamp, context capture |\n| Handler Dispatch | Read lock | Per-handler | Output writing, formatting |\n\n**Hierarchical Locking Protocol**:\n1. Global registry lock protects logger creation and hierarchy modifications\n2. Per-logger locks protect configuration changes like level and handler updates\n3. Handler dispatch uses read locks to allow concurrent logging while preventing configuration changes\n4. Lock ordering follows hierarchy depth to prevent deadlocks (parent before child)\n5. Operations acquire minimal lock scope and release as quickly as possible\n\nThe locking protocol ensures that common operations (logging messages) require only read locks or no locks, while rare operations (configuration changes, logger creation) use write locks for consistency. This design maximizes concurrency for the typical workload while providing strong consistency guarantees.\n\n#### Handler Dispatch Concurrency\n\nHandler dispatch presents unique concurrency challenges because multiple threads may attempt to write to the same output destination simultaneously. The design provides thread safety at the handler level while allowing parallel dispatch to different handlers.\n\n**Concurrent Dispatch Strategy**:\n1. Each handler maintains its own internal synchronization for thread-safe writing\n2. Multiple threads can dispatch to different handlers simultaneously\n3. Handlers implement internal buffering and atomic write operations\n4. Handler failure in one thread doesn't affect logging success in other threads\n5. Error handling and retry logic operate independently per handler per thread\n\nThe `Handler` interface contract specifies that implementations must be thread-safe, allowing the logger to dispatch to multiple handlers concurrently without additional synchronization. This design pushes the thread safety responsibility to the component best positioned to handle it efficiently.\n\n#### Memory Consistency and Visibility\n\nThread safety extends beyond locks to include memory consistency guarantees. The logging system ensures that configuration changes made by one thread become visible to other threads promptly and consistently.\n\n| Memory Concern | Solution | Guarantee |\n|----------------|----------|-----------|\n| Level changes | Write barriers in setters | New levels visible before lock release |\n| Handler modifications | Copy-on-write collections | Atomic handler list updates |\n| Context propagation | Thread-local storage | Per-thread context isolation |\n| Logger hierarchy | Immutable parent references | Safe concurrent hierarchy traversal |\n| Cached effective levels | Volatile flags for invalidation | Cache invalidation visible across threads |\n\nThe memory consistency design uses a combination of proper locking, volatile flags for cache invalidation, and copy-on-write collections for handler lists. This approach ensures that all threads observe consistent state without requiring global synchronization for read-heavy operations.\n\n> **Architecture Decision: Fine-Grained Locking vs. Global Synchronization**\n> - **Context**: Logging occurs frequently and from many threads, requiring high-performance thread safety\n> - **Options Considered**:\n>   1. Single global lock for all logging operations\n>   2. Per-logger locks with hierarchical ordering\n>   3. Lock-free algorithms with atomic operations\n> - **Decision**: Per-logger locks with read-write separation\n> - **Rationale**: Global lock would serialize all logging operations hurting performance, lock-free algorithms are complex and error-prone, per-logger locks allow maximum concurrency while maintaining correctness\n> - **Consequences**: Enables high-throughput concurrent logging, requires careful lock ordering to prevent deadlocks, adds complexity to configuration change operations\n\n![Log Processing Data Flow](./diagrams/log-processing-flow.svg)\n\n### Handler Dispatch Mechanism\n\nThe handler dispatch system routes log records to multiple output destinations while providing error isolation, failure recovery, and performance optimization. This multi-destination approach enables comprehensive logging strategies where the same message appears in local files, remote collectors, and console output simultaneously.\n\n#### Multi-Destination Routing\n\nHandler dispatch implements a fan-out pattern where each log record gets sent to all configured handlers for the logger and its ancestors (unless propagation is disabled). This design ensures comprehensive coverage while allowing different handlers to apply their own filtering, formatting, and delivery mechanisms.\n\n**Dispatch Routing Process**:\n1. Collect all applicable handlers from logger and ancestor chain\n2. Create immutable LogRecord with timestamp, level, message, and context\n3. Dispatch record to each handler concurrently (when possible)\n4. Aggregate results from all handler operations\n5. Handle failures according to configured error policies\n6. Return success if at least one handler succeeded (or all failed)\n\nThe handler collection process walks up the logger hierarchy, gathering handlers from each ancestor until it reaches the root or encounters a logger with `propagate=False`. This creates a comprehensive handler list that respects hierarchy while allowing fine-grained control over propagation.\n\n| Handler Type | Purpose | Concurrency | Failure Tolerance |\n|--------------|---------|-------------|------------------|\n| ConsoleHandler | Developer feedback | Thread-safe writes | Never fails |\n| FileHandler | Local persistence | Buffered writes | Fails on disk full |\n| RemoteHandler | Centralized logging | Async network calls | Fails on network issues |\n| SyslogHandler | System integration | UDP fire-and-forget | Network failures ignored |\n\n#### Error Isolation and Recovery\n\nHandler failures must not prevent other handlers from receiving log records or cause the logging operation to fail completely. The dispatch system implements error isolation to ensure that a failed file handler doesn't prevent console output or remote logging from succeeding.\n\n**Error Isolation Strategy**:\n1. Each handler dispatch occurs within its own exception boundary\n2. Handler failures get logged to a separate error logger (avoiding recursion)\n3. Failed handlers can be marked as temporarily disabled with exponential backoff\n4. Dispatch continues to remaining handlers even after individual failures\n5. Success threshold determines overall operation success (e.g., \"at least one handler succeeded\")\n\nThe error isolation mechanism prevents cascading failures while providing visibility into handler health. A special error logger handles handler failures without using the same handlers that might be failing, typically writing to a simple file or console output.\n\n**Handler Failure Recovery**:\n\n| Failure Type | Detection | Recovery Action | Backoff Strategy |\n|--------------|-----------|----------------|------------------|\n| Network timeout | Exception during send | Retry with exponential backoff | 1s, 2s, 4s, up to 60s |\n| Disk full | Write operation failure | Disable temporarily, retry periodically | Check every 30 seconds |\n| Permission denied | File access error | Log error, disable permanently | No retry |\n| Memory exhaustion | Buffer allocation failure | Drop buffered messages, continue | Immediate retry with smaller buffer |\n\n#### Asynchronous Handler Support\n\nHigh-throughput applications require asynchronous handler dispatch to prevent slow output destinations from blocking application threads. The handler system supports both synchronous and asynchronous handlers through a unified interface with different execution strategies.\n\n**Asynchronous Dispatch Architecture**:\n1. Synchronous handlers execute immediately on the calling thread\n2. Asynchronous handlers queue log records for background processing\n3. Background worker threads process queued records with batching optimization\n4. Queue overflow protection prevents memory exhaustion during traffic spikes\n5. Graceful shutdown ensures all queued records get processed before exit\n\nThe asynchronous handler implementation uses bounded queues with overflow policies to handle traffic spikes. When queues fill up, the system can either block the calling thread, drop the oldest records, or drop the newest records based on configured policy.\n\n| Queue Policy | Behavior | Use Case |\n|--------------|----------|----------|\n| Block | Wait for queue space | Critical logs that must not be lost |\n| Drop Oldest | Remove old records for new ones | Real-time monitoring where recent data matters |\n| Drop Newest | Reject new records when full | Batch processing where old data has value |\n| Best Effort | Try async, fall back to sync | Development and testing scenarios |\n\n#### Performance Optimization\n\nHandler dispatch performance directly affects application throughput, especially for high-frequency logging. The system implements several optimizations to minimize latency and maximize throughput while maintaining correctness.\n\n**Dispatch Performance Optimizations**:\n1. **Handler Filtering**: Handlers can implement level filtering to avoid expensive formatting for filtered messages\n2. **Lazy Formatting**: Message formatting occurs only when handlers need the formatted output\n3. **Batching**: Asynchronous handlers batch multiple records to amortize network and I/O costs\n4. **Connection Pooling**: Network handlers reuse connections to reduce setup overhead\n5. **Memory Pooling**: LogRecord objects use object pools to reduce garbage collection pressure\n\nThe lazy formatting optimization proves particularly valuable when handlers have different formatting requirements. The structured LogRecord contains raw data, while handlers request formatted output only when needed for their specific destination.\n\n> **Performance Insight**: The dispatch mechanism optimizes for the common case where all handlers succeed quickly. Error handling and recovery logic are designed to add minimal overhead in the success path while providing comprehensive recovery in failure scenarios.\n\n![Handler Dispatch Sequence](./diagrams/handler-dispatch-sequence.svg)\n\n#### Common Pitfalls\n\n⚠️ **Pitfall: Handler Deadlock in Error Logging**\nWhen handler error logging uses the same logger hierarchy, a failure in the error logger can cause recursive calls and deadlocks. For example, if the file handler fails and tries to log the error to a logger that also uses the file handler, the system can deadlock. **Fix**: Use a separate error logging path that writes only to console or a dedicated error file, never routing through the normal handler system.\n\n⚠️ **Pitfall: Unbounded Handler Queues**\nAsynchronous handlers with unbounded queues can consume unlimited memory during traffic spikes, leading to out-of-memory crashes. Without queue limits, a slow remote handler can accumulate millions of pending records. **Fix**: Use bounded queues with explicit overflow policies, monitor queue depth, and implement backpressure mechanisms that slow down logging when queues approach capacity.\n\n⚠️ **Pitfall: Synchronous Network Handlers in Hot Paths**\nUsing synchronous network handlers in performance-critical code paths causes application latency to directly depend on network latency. A slow remote logging service can make the entire application unresponsive. **Fix**: Use asynchronous handlers for all network destinations, or implement timeout limits with fallback to local handlers when remote services are slow.\n\n⚠️ **Pitfall: Handler State Corruption Under Concurrency**\nStateful handlers that don't properly synchronize internal state can corrupt output when accessed from multiple threads. File handlers that maintain internal buffers without proper locking can interleave output from different threads. **Fix**: Ensure all handler implementations are internally thread-safe, use atomic operations for simple state, and employ proper locking for complex state management.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Threading | `threading.RLock` for logger locks | `concurrent.futures.ThreadPoolExecutor` for async handlers |\n| Logger Registry | `dict` with global lock | `weakref.WeakValueDictionary` for automatic cleanup |\n| Handler Queues | `queue.Queue` for async handlers | `multiprocessing.Queue` for cross-process logging |\n| Context Storage | `threading.local()` for per-thread context | `contextvars` for async-aware context |\n| Serialization | `json.dumps()` for LogRecord conversion | `orjson` or `ujson` for high-performance serialization |\n\n#### Recommended File Structure\n\n```\nlogging-system/\n  core/\n    __init__.py              ← Public API exports\n    logger.py                ← Logger class and hierarchy management\n    record.py                ← LogRecord data structure\n    levels.py                ← Level constants and utilities\n    registry.py              ← Global logger registry and factory\n  handlers/\n    __init__.py              ← Handler base class and common handlers\n    console.py               ← ConsoleHandler implementation\n    file.py                  ← FileHandler with rotation\n    remote.py                ← RemoteHandler for network logging\n    async_handler.py         ← Asynchronous handler wrapper\n  formatters/\n    __init__.py              ← Formatter base class\n    json_formatter.py        ← JSON formatting implementation\n  context/\n    __init__.py              ← Context propagation system\n    storage.py               ← Thread-local and async context storage\n  tests/\n    test_logger.py           ← Logger hierarchy and level tests\n    test_handlers.py         ← Handler dispatch and error tests\n    test_concurrency.py      ← Thread safety and race condition tests\n```\n\n#### Infrastructure Starter Code\n\n**Level Constants and Utilities** (`levels.py`):\n```python\n# Complete level management system\nDEBUG = 10\nINFO = 20\nWARN = 30\nERROR = 40\nFATAL = 50\n\nLEVEL_NAMES = {\n    DEBUG: 'DEBUG',\n    INFO: 'INFO',\n    WARN: 'WARN',\n    ERROR: 'ERROR',\n    FATAL: 'FATAL'\n}\n\nNAME_TO_LEVEL = {name: level for level, name in LEVEL_NAMES.items()}\n\ndef should_log(message_level: int, configured_level: int) -> bool:\n    \"\"\"Determine if message should be logged based on level filtering.\"\"\"\n    return message_level >= configured_level\n\ndef level_name(level: int) -> str:\n    \"\"\"Convert numeric level to string name.\"\"\"\n    return LEVEL_NAMES.get(level, f'LEVEL-{level}')\n\ndef parse_level(level_input) -> int:\n    \"\"\"Parse string or integer level input to numeric level.\"\"\"\n    if isinstance(level_input, int):\n        return level_input\n    if isinstance(level_input, str):\n        return NAME_TO_LEVEL.get(level_input.upper(), INFO)\n    return INFO\n```\n\n**Thread-Safe Collections** (`utils.py`):\n```python\nimport threading\nfrom typing import Dict, Any, Optional, List\nimport weakref\n\nclass ThreadSafeDict:\n    \"\"\"Thread-safe dictionary with read-write locking.\"\"\"\n    \n    def __init__(self):\n        self._data: Dict[str, Any] = {}\n        self._lock = threading.RLock()\n    \n    def get(self, key: str, default: Any = None) -> Any:\n        with self._lock:\n            return self._data.get(key, default)\n    \n    def set(self, key: str, value: Any) -> None:\n        with self._lock:\n            self._data[key] = value\n    \n    def delete(self, key: str) -> bool:\n        with self._lock:\n            if key in self._data:\n                del self._data[key]\n                return True\n            return False\n    \n    def keys(self) -> List[str]:\n        with self._lock:\n            return list(self._data.keys())\n\nclass LoggerRegistry:\n    \"\"\"Global registry for logger instances with thread safety.\"\"\"\n    \n    def __init__(self):\n        self._loggers: Dict[str, 'Logger'] = {}\n        self._lock = threading.RLock()\n    \n    def get_or_create(self, name: str, factory_func) -> 'Logger':\n        with self._lock:\n            if name in self._loggers:\n                return self._loggers[name]\n            \n            logger = factory_func(name)\n            self._loggers[name] = logger\n            return logger\n    \n    def get(self, name: str) -> Optional['Logger']:\n        with self._lock:\n            return self._loggers.get(name)\n    \n    def clear(self) -> None:\n        \"\"\"Clear all loggers - primarily for testing.\"\"\"\n        with self._lock:\n            self._loggers.clear()\n```\n\n#### Core Logic Skeleton\n\n**Logger Class Core** (`logger.py`):\n```python\nfrom typing import List, Dict, Any, Optional\nimport threading\nfrom .levels import should_log, INFO\nfrom .record import LogRecord\n\nclass Logger:\n    \"\"\"Core logger implementation with hierarchy and thread safety.\"\"\"\n    \n    def __init__(self, name: str, parent: Optional['Logger'] = None):\n        self.name = name\n        self.parent = parent\n        self.children: Dict[str, Logger] = {}\n        self.handlers: List['Handler'] = []\n        self.context: Dict[str, Any] = {}\n        self.propagate = True\n        \n        self._level: Optional[int] = None\n        self._effective_level: Optional[int] = None\n        self._lock = threading.RLock()\n    \n    def log(self, level: int, message: str, **context) -> None:\n        \"\"\"Main logging entry point with filtering and dispatch.\"\"\"\n        # TODO 1: Check if message should be logged using should_log()\n        # TODO 2: Create LogRecord with current timestamp and merged context\n        # TODO 3: Collect all applicable handlers from self and ancestors\n        # TODO 4: Dispatch record to each handler with error isolation\n        # TODO 5: Handle propagation up the hierarchy if enabled\n        # Hint: Use early return for filtered messages to optimize performance\n        pass\n    \n    def get_effective_level(self) -> int:\n        \"\"\"Get the effective level, walking up hierarchy if needed.\"\"\"\n        # TODO 1: Check if we have a cached effective level\n        # TODO 2: If not cached, walk up parent chain to find configured level\n        # TODO 3: Cache the result for future calls\n        # TODO 4: Return the found level or default to INFO\n        # Hint: Use self._lock for thread safety when updating cache\n        pass\n    \n    def set_level(self, level: int) -> None:\n        \"\"\"Set logger level and invalidate caches.\"\"\"\n        # TODO 1: Acquire write lock to prevent concurrent access\n        # TODO 2: Set self._level to new value\n        # TODO 3: Invalidate self._effective_level cache\n        # TODO 4: Walk all descendants and invalidate their caches\n        # TODO 5: Release lock\n        # Hint: Cache invalidation prevents stale level inheritance\n        pass\n    \n    def add_handler(self, handler: 'Handler') -> None:\n        \"\"\"Add handler to this logger's handler list.\"\"\"\n        # TODO 1: Acquire lock for thread-safe handler list modification\n        # TODO 2: Check if handler is already in list to avoid duplicates\n        # TODO 3: Append handler to self.handlers list\n        # TODO 4: Release lock\n        pass\n    \n    def collect_handlers(self) -> List['Handler']:\n        \"\"\"Collect all applicable handlers from hierarchy.\"\"\"\n        # TODO 1: Start with empty handler list\n        # TODO 2: Add all handlers from self.handlers\n        # TODO 3: If propagate is True, walk up parent chain\n        # TODO 4: Add handlers from each ancestor until root or propagate=False\n        # TODO 5: Return combined handler list\n        # Hint: Check propagate flag at each level, not just current logger\n        pass\n\n    # Convenience methods for specific levels\n    def debug(self, message: str, **context) -> None:\n        self.log(DEBUG, message, **context)\n    \n    def info(self, message: str, **context) -> None:\n        self.log(INFO, message, **context)\n    \n    def warn(self, message: str, **context) -> None:\n        self.log(WARN, message, **context)\n    \n    def error(self, message: str, **context) -> None:\n        self.log(ERROR, message, **context)\n    \n    def fatal(self, message: str, **context) -> None:\n        self.log(FATAL, message, **context)\n```\n\n**Logger Factory Function**:\n```python\n_registry = LoggerRegistry()\n\ndef get_logger(name: str = '') -> Logger:\n    \"\"\"Get or create logger with proper hierarchy setup.\"\"\"\n    # TODO 1: Use registry to get existing logger or signal creation needed\n    # TODO 2: If creating new logger, parse name to find parent path\n    # TODO 3: Ensure parent loggers exist, creating them recursively\n    # TODO 4: Create new logger with proper parent reference\n    # TODO 5: Add new logger to parent's children dict\n    # TODO 6: Initialize logger with inherited configuration\n    # TODO 7: Register logger in global registry\n    # TODO 8: Return logger instance\n    # Hint: Split name on '.' to build hierarchy path\n    pass\n```\n\n#### Milestone Checkpoint\n\nAfter implementing the Logger Core, verify these behaviors:\n\n**Level Filtering Test**:\n```python\nlogger = get_logger('test')\nlogger.set_level(WARN)\n\nlogger.debug(\"Should not appear\")  # Filtered out\nlogger.warn(\"Should appear\")       # Visible\nlogger.error(\"Should appear\")      # Visible\n```\n\n**Hierarchy Test**:\n```python\nparent = get_logger('parent')\nchild = get_logger('parent.child')\n\nparent.set_level(ERROR)\nassert child.get_effective_level() == ERROR  # Inherits from parent\n```\n\n**Thread Safety Test**:\n```python\nimport concurrent.futures\n\ndef log_messages(logger, thread_id):\n    for i in range(100):\n        logger.info(f\"Message {i} from thread {thread_id}\")\n\nlogger = get_logger('concurrent')\nwith concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n    futures = [executor.submit(log_messages, logger, i) for i in range(10)]\n    # Should complete without deadlock or corrupted output\n```\n\n**Handler Dispatch Test**:\n```python\nlogger = get_logger('dispatch')\nlogger.add_handler(ConsoleHandler())\n\nlogger.info(\"Test message\")\n# Should appear on console without errors\n```\n\n#### Language-Specific Hints\n\n- Use `threading.RLock()` instead of `Lock()` to allow recursive locking within the same thread\n- `time.time()` provides sufficient timestamp precision for most logging use cases  \n- `sys.stderr.write()` is thread-safe and faster than `print()` for console handlers\n- Use `**kwargs` for context parameters to provide clean API for arbitrary fields\n- `weakref.WeakValueDictionary` can help prevent memory leaks in logger registry for long-running applications\n- Consider using `__slots__` in LogRecord class to reduce memory overhead for high-volume logging\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Messages not appearing | Level filtering too restrictive | Check `get_effective_level()` vs message level | Lower logger level or use higher level messages |\n| Duplicate log messages | Handler added multiple times | Inspect `logger.handlers` list | Check for duplicate handler addition |\n| Deadlock on level change | Lock ordering violation | Thread dump showing lock contention | Acquire locks in consistent order (parent before child) |\n| Context not inheriting | Parent-child relationship broken | Verify `logger.parent` references | Fix logger hierarchy creation in factory |\n| Memory leak in long-running app | Logger registry holding references | Monitor logger count over time | Use WeakValueDictionary for registry storage |\n\n\n## Structured Output Design\n\n> **Milestone(s):** This section primarily addresses Milestone 2 (Structured Output) by defining JSON formatting, custom formatters, timestamp handling, and developer-friendly pretty printing. It builds on the Logger Core from Milestone 1 and prepares the foundation for context propagation in Milestone 3.\n\nThink of structured logging output like a restaurant's order system. Traditional string-based logs are like servers shouting orders across a noisy kitchen — \"Medium rare steak, extra sauce!\" The information is there, but it's hard to parse, search, or aggregate. Structured JSON output is like a modern point-of-sale system that sends precise, machine-readable orders to each station: `{\"item\": \"steak\", \"doneness\": \"medium_rare\", \"modifications\": [\"extra_sauce\"], \"table\": 7, \"timestamp\": \"2024-01-15T18:30:00Z\"}`. Every piece of information has its designated place, making it trivial for kitchen display systems, inventory tracking, and analytics to process the data automatically.\n\nThe structured output system transforms the rich `LogRecord` objects from our logger core into various serialized formats suitable for different consumption scenarios. While the logger hierarchy and level filtering ensure the right messages reach the formatting stage, the output system determines how those messages appear to developers, monitoring systems, and log aggregation platforms.\n\n### JSON Formatter\n\nThe JSON formatter serves as the primary structured output format, converting `LogRecord` objects into single-line JSON strings that maintain consistent field ordering and handle complex serialization scenarios gracefully.\n\n> **Decision: Single-Line JSON Output**\n> - **Context**: Log aggregation systems and streaming processors expect one JSON object per line to enable efficient parsing and processing of large log files\n> - **Options Considered**: Multi-line pretty JSON, single-line compact JSON, custom delimited format\n> - **Decision**: Single-line JSON with consistent field ordering\n> - **Rationale**: Single-line format enables stream processing, consistent ordering aids debugging, and standard JSON ensures compatibility with existing tooling\n> - **Consequences**: Enables efficient log processing but reduces human readability in raw form (addressed by separate pretty-print formatter)\n\n| JSON Field | Type | Source | Description |\n|------------|------|--------|-------------|\n| `timestamp` | string | `LogRecord.timestamp` | ISO 8601 formatted timestamp with timezone |\n| `level` | string | `LogRecord.level` mapped via `LEVEL_NAMES` | Human-readable level name (DEBUG, INFO, WARN, ERROR, FATAL) |\n| `message` | string | `LogRecord.message` | Primary log message content |\n| `logger` | string | `LogRecord.logger_name` | Hierarchical logger name (e.g., \"api.auth.login\") |\n| `context` | object | `LogRecord.context` | Key-value pairs with request context and metadata |\n\nThe JSON formatter implements several sophisticated serialization strategies to handle edge cases that commonly break logging systems in production:\n\n**Circular Reference Protection**: The `safe_serialize` function maintains a recursion depth counter and visited object set to detect circular references before they cause stack overflows. When a circular reference is detected, the formatter replaces the problematic object with a placeholder string `\"<circular_reference>\"`, allowing logging to continue rather than crashing the application.\n\n**Non-Serializable Object Handling**: The `SafeJSONEncoder` extends Python's standard JSON encoder to handle common non-serializable types encountered in production logging. DateTime objects convert to ISO 8601 strings, Decimal objects serialize as strings to preserve precision, and custom objects fall back to their string representation via `str()`.\n\n**Size-Based Truncation**: The `estimate_serialized_size` function provides fast size estimation without full serialization, enabling the formatter to truncate oversized context objects before they consume excessive memory or exceed log destination limits. Objects exceeding configurable size thresholds are replaced with summary metadata indicating the original type and truncated size.\n\n| Method Name | Parameters | Returns | Description |\n|-------------|------------|---------|-------------|\n| `format` | `record: LogRecord` | `str` | Convert LogRecord to single-line JSON string |\n| `safe_serialize` | `data: Any, max_depth: int = 10` | `str` | Serialize with circular reference protection |\n| `estimate_serialized_size` | `data: Any` | `int` | Fast size estimation without full serialization |\n| `to_dict` | `record: LogRecord` | `Dict[str, Any]` | Convert LogRecord to dictionary for JSON serialization |\n\n**Field Ordering Strategy**: The formatter uses Python's `collections.OrderedDict` or dictionary insertion ordering (Python 3.7+) to ensure consistent field appearance across all log records. This deterministic ordering significantly improves developer experience when scanning logs manually and ensures that text-based diff tools can meaningfully compare log files.\n\nConsider a concrete example where an authentication service logs a failed login attempt:\n\n```text\nInput LogRecord:\n  timestamp: \"2024-01-15T18:30:45.123456Z\"\n  level: 40 (ERROR)\n  message: \"Authentication failed\"\n  logger_name: \"api.auth.login\"\n  context: {\"user_id\": \"user_123\", \"ip_address\": \"192.168.1.100\", \"attempt_count\": 3}\n\nOutput JSON:\n{\"timestamp\":\"2024-01-15T18:30:45.123456Z\",\"level\":\"ERROR\",\"message\":\"Authentication failed\",\"logger\":\"api.auth.login\",\"context\":{\"user_id\":\"user_123\",\"ip_address\":\"192.168.1.100\",\"attempt_count\":3}}\n```\n\nThe single-line output enables log aggregation systems to process each line as a discrete event while maintaining all the structured context necessary for querying and analysis.\n\n### Formatter Plugin System\n\nThe formatter plugin system provides extensibility for custom output formats while maintaining a consistent interface that integrates seamlessly with the handler dispatch mechanism.\n\nThink of the formatter plugin system like a universal printer driver architecture. Just as applications can send documents to any printer through a standard interface (regardless of whether it's an inkjet, laser, or plotter), the logging system can format records for any destination through a standard formatter interface. The application code doesn't need to know whether logs are going to JSON files, syslog servers, or custom monitoring dashboards — it just hands the `LogRecord` to the appropriate formatter.\n\n> **Decision: Registry-Based Plugin Architecture**\n> - **Context**: Different output destinations require different formatting (JSON for aggregation, colored text for development, structured formats for monitoring systems)\n> - **Options Considered**: Inheritance-based formatters, function-based formatters, registry-based plugins\n> - **Decision**: Registry-based plugin system with standard formatter interface\n> - **Rationale**: Registry enables runtime formatter selection, standard interface ensures consistent behavior, and plugins can be distributed as separate packages\n> - **Consequences**: Enables formatter extensibility and runtime configuration but adds complexity compared to fixed formatters\n\n| Formatter Component | Type | Purpose | Registration Method |\n|---------------------|------|---------|-------------------|\n| `BaseFormatter` | Abstract Class | Defines standard interface for all formatters | N/A (base class) |\n| `JSONFormatter` | Concrete Class | Single-line JSON output for log aggregation | `register_formatter(\"json\", JSONFormatter())` |\n| `PrettyFormatter` | Concrete Class | Human-readable colored output for development | `register_formatter(\"pretty\", PrettyFormatter())` |\n| `SyslogFormatter` | Concrete Class | RFC 3164 compatible syslog format | `register_formatter(\"syslog\", SyslogFormatter())` |\n| `FormatterRegistry` | Registry Class | Manages formatter registration and lookup | `get_formatter(name)`, `list_formatters()` |\n\nThe plugin registration process follows a simple two-step pattern that maintains type safety while enabling runtime flexibility:\n\n1. **Formatter Implementation**: Custom formatters inherit from `BaseFormatter` and implement the required `format(record: LogRecord) -> str` method along with optional configuration methods.\n\n2. **Registry Registration**: Formatters register themselves with the global `FormatterRegistry` using a unique string name, enabling selection via configuration files or runtime API calls.\n\n| BaseFormatter Method | Parameters | Returns | Description |\n|---------------------|------------|---------|-------------|\n| `format` | `record: LogRecord` | `str` | Abstract method that subclasses must implement |\n| `configure` | `options: Dict[str, Any]` | `None` | Optional configuration method for formatter-specific settings |\n| `supports_color` | None | `bool` | Indicates whether formatter supports color output |\n| `get_name` | None | `str` | Returns the formatter's registration name |\n\n**Thread-Safe Registry Operations**: The `FormatterRegistry` uses a read-write lock to ensure thread-safe registration and lookup operations. Formatter registration typically occurs during application startup, while lookups happen during log processing, making the read-heavy access pattern well-suited to RWLock optimization.\n\n**Configuration Integration**: Formatters can accept configuration parameters through the `configure` method, enabling customization without requiring code changes. For example, the JSON formatter accepts parameters for timestamp format, field ordering preferences, and size limits, while the pretty formatter accepts color scheme and indentation preferences.\n\nHere's how the plugin system enables runtime formatter selection:\n\n```text\nConfiguration-Driven Selection:\n  handlers:\n    - type: file\n      path: \"/var/log/app.json\"\n      formatter: \"json\"\n    - type: console  \n      formatter: \"pretty\"\n      \nRuntime Registration:\n  1. Application startup registers built-in formatters (json, pretty, syslog)\n  2. Custom formatter packages register additional formatters via plugin discovery\n  3. Configuration loading selects formatters by name for each handler\n  4. Handler dispatch uses assigned formatter for each destination\n```\n\n### Timestamp Formatting\n\nTimestamp formatting provides the critical temporal context that enables log correlation, debugging, and audit trails across distributed systems. The timestamp system must balance precision, readability, and compatibility with various log processing systems.\n\nThink of timestamp formatting like international time zone coordination for airline schedules. Airlines need to display departure times in local time for passenger convenience (\"Flight 101 departs at 3:30 PM\"), but they also need UTC timestamps for air traffic control coordination and schedule optimization. Similarly, our logging system needs human-readable timestamps for developers scanning logs locally, but also needs precise, sortable timestamps for log aggregation systems that merge streams from multiple servers across different time zones.\n\n> **Decision: Multiple Timestamp Format Support**\n> - **Context**: Different consumers need different timestamp formats (humans prefer readable formats, systems prefer sortable formats, legacy systems expect specific formats)\n> - **Options Considered**: Single ISO 8601 format, Unix epoch only, configurable format per logger\n> - **Decision**: Multiple timestamp formats with per-formatter configuration\n> - **Rationale**: ISO 8601 provides precision and sortability, Unix epoch enables efficient processing, custom formats support legacy integration\n> - **Consequences**: Enables format flexibility but requires careful timezone handling and format validation\n\n| Timestamp Format | Example Output | Use Case | Pros | Cons |\n|------------------|----------------|----------|------|------|\n| ISO 8601 with Microseconds | `2024-01-15T18:30:45.123456Z` | Log aggregation, debugging | Sortable, precise, timezone-aware | Longer string length |\n| ISO 8601 Basic | `2024-01-15T18:30:45Z` | General structured logging | Standard, readable, sortable | Lower precision |\n| Unix Epoch | `1705344645.123456` | High-performance processing | Compact, fast parsing, efficient storage | Not human-readable |\n| Custom strftime | `2024-01-15 18:30:45 UTC` | Legacy system integration | Flexible, familiar format | Non-standard, parsing complexity |\n\n**Timezone Handling Strategy**: All timestamps are captured in UTC to avoid daylight saving time transitions and timezone inconsistencies that plague distributed logging. The `LogRecord.create` factory method uses `datetime.utcnow()` to ensure consistent temporal ordering regardless of the server's local timezone configuration.\n\n**Precision Requirements**: The default timestamp format includes microsecond precision to enable ordering of log events that occur within the same second. This precision level proves essential when debugging race conditions or analyzing high-frequency operations where millisecond timing matters.\n\n**Clock Synchronization Considerations**: While the logging system cannot control server clock synchronization, it provides mechanisms to detect and warn about significant clock skew. The timestamp formatter can optionally include a monotonic clock offset that enables relative timing analysis even when system clocks drift.\n\n| Timestamp Method | Parameters | Returns | Description |\n|------------------|------------|---------|-------------|\n| `format_timestamp` | `timestamp: str, format_type: str` | `str` | Convert ISO timestamp to specified format |\n| `parse_timestamp` | `timestamp_str: str` | `datetime` | Parse timestamp string to datetime object |\n| `get_current_timestamp` | `precision: str = \"microsecond\"` | `str` | Generate current UTC timestamp with specified precision |\n| `validate_timestamp` | `timestamp_str: str` | `bool` | Validate timestamp string format |\n\n**Performance Optimization**: Timestamp formatting uses caching strategies to avoid repeated strftime operations on identical timestamps. The formatter maintains a small LRU cache of recently formatted timestamps, which significantly improves performance when processing bursts of log messages within the same second.\n\nConsider how different timestamp formats serve different operational needs:\n\n```text\nDevelopment Scenario - Pretty Formatter:\n  Raw LogRecord: timestamp=\"2024-01-15T18:30:45.123456Z\"\n  Formatted Output: \"[18:30:45.123] ERROR api.auth: Authentication failed\"\n  \nProduction JSON - JSON Formatter:  \n  Raw LogRecord: timestamp=\"2024-01-15T18:30:45.123456Z\"\n  Formatted Output: {\"timestamp\":\"2024-01-15T18:30:45.123456Z\",\"level\":\"ERROR\",...}\n  \nLegacy Syslog Integration - Syslog Formatter:\n  Raw LogRecord: timestamp=\"2024-01-15T18:30:45.123456Z\"  \n  Formatted Output: \"Jan 15 18:30:45 hostname app[1234]: Authentication failed\"\n```\n\n### Developer-Friendly Pretty Print\n\nThe pretty print formatter transforms structured log data into human-readable, visually appealing output optimized for developer console environments and interactive debugging sessions.\n\nThink of pretty printing like the difference between reading raw HTML source code and viewing a rendered web page. While the JSON formatter produces machine-readable output equivalent to HTML source (precise, parseable, but dense), the pretty formatter acts like a web browser, transforming that structured data into a visually organized, color-coded display that humans can quickly scan and comprehend. Just as web browsers use typography, spacing, and color to highlight important information, the pretty formatter uses console colors, indentation, and visual hierarchy to make log data accessible to developers.\n\n> **Decision: Console-Optimized Visual Formatting**\n> - **Context**: Developers need quick visual scanning of log output during debugging and development, but JSON format is difficult to read in terminal environments\n> - **Options Considered**: Colored JSON with indentation, table-based layout, custom visual format\n> - **Decision**: Multi-line colored output with hierarchical indentation and visual separators\n> - **Rationale**: Color coding enables quick level identification, indentation shows context hierarchy, and compact layout maximizes information density\n> - **Consequences**: Dramatically improves developer experience but produces larger output unsuitable for production log aggregation\n\n**Color Scheme Strategy**: The pretty formatter uses a carefully designed color palette that remains readable across different terminal backgrounds and accommodates common forms of color vision differences. Critical information uses high-contrast colors, while contextual information uses muted tones that don't compete for attention.\n\n| Log Level | Color | Terminal Code | Rationale |\n|-----------|-------|---------------|-----------|\n| DEBUG | Cyan | `\\033[36m` | Cool color indicates low-priority information |\n| INFO | Green | `\\033[32m` | Green suggests normal, healthy operation |\n| WARN | Yellow | `\\033[33m` | Yellow universally signals caution |\n| ERROR | Red | `\\033[31m` | Red immediately draws attention to problems |\n| FATAL | Bright Red + Bold | `\\033[1;91m` | Maximum visual impact for critical issues |\n\n**Layout Design Principles**: The pretty formatter uses consistent visual hierarchy to help developers quickly locate relevant information. Timestamps appear in muted colors to provide context without distraction, logger names use medium emphasis to show the source, and context fields are indented to clearly separate them from the primary message.\n\n```text\nExample Pretty Print Output Layout:\n\n[18:30:45.123] ERROR api.auth.login                          ← timestamp + level + logger\nAuthentication failed for user                               ← primary message  \n├── user_id: \"user_123\"                                     ← context fields with\n├── ip_address: \"192.168.1.100\"                             ← tree-style indentation\n├── attempt_count: 3                                        ← for visual hierarchy\n└── correlation_id: \"req_abc123def456\"                      \n                                                            ← blank line separator\n```\n\n**Context Field Rendering**: The formatter intelligently handles different context field types with appropriate visual treatment. String values appear quoted, numbers display without decoration, nested objects use deeper indentation levels, and large values trigger truncation with expansion hints.\n\n| Context Field Type | Rendering Strategy | Example |\n|-------------------|-------------------|---------|\n| String | Quoted with escape handling | `user_name: \"john.doe\"` |\n| Number | Direct display | `response_time_ms: 245` |\n| Boolean | Lowercase display | `authenticated: true` |\n| List | Bracketed with item count | `permissions: [3 items]` |\n| Dict | Nested indentation | `metadata:` followed by indented key-value pairs |\n| Large Object | Truncated with hint | `request_body: <dict with 15 fields>` |\n\n**Terminal Capability Detection**: The formatter detects terminal capabilities to gracefully degrade when color support is unavailable or when output is redirected to files. This detection prevents ANSI escape codes from polluting log files while maintaining rich formatting in interactive terminals.\n\n| PrettyFormatter Method | Parameters | Returns | Description |\n|------------------------|------------|---------|-------------|\n| `format` | `record: LogRecord` | `str` | Convert LogRecord to color-formatted multi-line string |\n| `format_context` | `context: Dict[str, Any], indent: int` | `str` | Render context fields with tree-style indentation |\n| `detect_terminal_caps` | None | `Dict[str, bool]` | Detect color support and terminal width |\n| `colorize` | `text: str, color: str` | `str` | Apply color codes with terminal capability fallback |\n\n**Performance Considerations**: While pretty formatting is more expensive than simple JSON serialization, it's designed specifically for development environments where the performance cost is acceptable in exchange for improved developer productivity. The formatter caches color capability detection and reuses formatting objects to minimize overhead.\n\n**Width-Aware Formatting**: The formatter detects terminal width and adjusts layout accordingly. On narrow terminals, it abbreviates logger names and wraps long messages intelligently. On wide terminals, it can display additional context inline rather than using vertical indentation.\n\nConsider how the same log record appears in different formatting contexts:\n\n```text\nJSON Formatter (Production):\n{\"timestamp\":\"2024-01-15T18:30:45.123456Z\",\"level\":\"ERROR\",\"message\":\"Authentication failed\",\"logger\":\"api.auth.login\",\"context\":{\"user_id\":\"user_123\",\"ip_address\":\"192.168.1.100\",\"attempt_count\":3}}\n\nPretty Formatter (Development):\n[18:30:45.123] ERROR api.auth.login\nAuthentication failed\n├── user_id: \"user_123\"  \n├── ip_address: \"192.168.1.100\"\n└── attempt_count: 3\n```\n\nThe pretty formatter transforms dense, machine-readable data into an immediately comprehensible visual representation that enables developers to quickly identify patterns, spot anomalies, and understand the flow of execution through their applications.\n\n![Log Processing Data Flow](./diagrams/log-processing-flow.svg)\n\n![Formatter Plugin Architecture](./diagrams/formatter-plugin-system.svg)\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Non-Serializable Context Values**\nDevelopers frequently add complex objects to logging context that cannot be serialized to JSON, such as database connections, file handles, or custom objects without `__dict__` methods. This causes the entire logging operation to fail with serialization exceptions, potentially masking the original issue being logged. The fix involves implementing the `SafeJSONEncoder` with fallback serialization that converts problematic objects to their string representation via `str()` or `repr()`, allowing logging to continue even with problematic context data.\n\n⚠️ **Pitfall: Blocking I/O in Formatter**\nSome custom formatters attempt to perform network requests or file I/O operations during the formatting phase, such as looking up additional metadata or validating data against external services. This introduces blocking operations directly in the logging hot path, causing application threads to stall while waiting for formatter completion. The solution involves moving all I/O operations to the handler level and keeping formatters as pure transformation functions that operate only on the provided `LogRecord` data.\n\n⚠️ **Pitfall: Memory Exhaustion from Large Context Objects**\nApplications sometimes log entire request payloads, response objects, or large data structures as context fields. When these objects contain megabytes of data, they can quickly exhaust available memory, especially under high logging volume. The `estimate_serialized_size` function provides protection by detecting oversized objects before serialization and replacing them with summary metadata, but this protection must be enabled and configured with appropriate thresholds.\n\n⚠️ **Pitfall: Timezone Confusion in Timestamps**\nMixing local time and UTC timestamps across different servers creates impossible-to-debug timing issues where log events appear to occur in the wrong order or at impossible times. Always use UTC for log timestamps and convert to local time only in presentation layers. The `get_current_timestamp` function ensures UTC consistency, but developers must avoid using `datetime.now()` or other local time functions when creating custom timestamp formats.\n\n⚠️ **Pitfall: Circular References in Context**\nWhen logging objects that contain references to parent objects or self-references, the JSON serialization process can enter infinite loops, eventually causing stack overflow errors. This commonly occurs when logging request objects that contain references to the application context or when debugging recursive data structures. The `safe_serialize` function with depth limiting and visited-object tracking prevents this issue, but it must be used consistently across all formatters.\n\n### Implementation Guidance\n\n**A. Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| JSON Serialization | `json` standard library | `orjson` for high-performance serialization |\n| Color Terminal Output | ANSI escape codes | `colorama` for cross-platform color support |\n| Timestamp Parsing | `datetime.fromisoformat()` | `dateutil.parser` for flexible format support |\n| Size Estimation | String length approximation | `sys.getsizeof()` with recursive object traversal |\n\n**B. Recommended File Structure:**\n```\nstructured_logging/\n├── formatters/\n│   ├── __init__.py              ← Formatter registry and base classes\n│   ├── json_formatter.py        ← JSON formatter implementation  \n│   ├── pretty_formatter.py      ← Developer console formatter\n│   └── base_formatter.py        ← Abstract base formatter\n├── utils/\n│   ├── serialization.py         ← SafeJSONEncoder and safe_serialize\n│   └── timestamps.py            ← Timestamp formatting utilities\n└── tests/\n    ├── test_json_formatter.py\n    ├── test_pretty_formatter.py\n    └── test_serialization.py\n```\n\n**C. Infrastructure Starter Code:**\n\n**SafeJSONEncoder (Complete Implementation):**\n```python\nimport json\nimport decimal\nimport datetime\nfrom typing import Any, Set, Dict\n\nclass SafeJSONEncoder(json.JSONEncoder):\n    \"\"\"JSON encoder that handles non-serializable types gracefully.\"\"\"\n    \n    def __init__(self, max_depth=10, max_size=10000):\n        super().__init__()\n        self.max_depth = max_depth\n        self.max_size = max_size\n        self._visited: Set[int] = set()\n        self._current_depth = 0\n    \n    def encode(self, obj):\n        self._visited.clear()\n        self._current_depth = 0\n        return super().encode(obj)\n    \n    def default(self, obj):\n        # Handle common non-serializable types\n        if isinstance(obj, datetime.datetime):\n            return obj.isoformat()\n        elif isinstance(obj, decimal.Decimal):\n            return str(obj)\n        elif hasattr(obj, '__dict__'):\n            return f\"<{type(obj).__name__} object>\"\n        else:\n            return str(obj)\n\ndef safe_serialize(data: Any, max_depth: int = 10) -> str:\n    \"\"\"Serialize data to JSON with circular reference protection.\"\"\"\n    try:\n        encoder = SafeJSONEncoder(max_depth=max_depth)\n        return encoder.encode(data)\n    except (TypeError, ValueError, RecursionError) as e:\n        return json.dumps({\"serialization_error\": str(e), \"type\": str(type(data))})\n\ndef estimate_serialized_size(data: Any) -> int:\n    \"\"\"Estimate JSON size without full serialization.\"\"\"\n    if data is None:\n        return 4  # \"null\"\n    elif isinstance(data, bool):\n        return 4 if data else 5  # \"true\" or \"false\"\n    elif isinstance(data, int):\n        return len(str(data))\n    elif isinstance(data, float):\n        return len(str(data))\n    elif isinstance(data, str):\n        return len(data) + 2  # Add quotes\n    elif isinstance(data, (list, tuple)):\n        return sum(estimate_serialized_size(item) for item in data) + len(data) + 1\n    elif isinstance(data, dict):\n        size = 2  # {}\n        for key, value in data.items():\n            size += len(str(key)) + 2  # quoted key\n            size += estimate_serialized_size(value)\n            size += 2  # colon and comma\n        return size\n    else:\n        return len(str(data)) + 2  # quoted string representation\n```\n\n**Timestamp Utilities (Complete Implementation):**\n```python\nimport datetime\nfrom typing import Optional\n\ndef get_current_timestamp(precision: str = \"microsecond\") -> str:\n    \"\"\"Generate current UTC timestamp with specified precision.\"\"\"\n    now = datetime.datetime.utcnow()\n    if precision == \"second\":\n        return now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n    elif precision == \"microsecond\":\n        return now.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n    else:\n        raise ValueError(f\"Unsupported precision: {precision}\")\n\ndef format_timestamp(timestamp: str, format_type: str) -> str:\n    \"\"\"Convert ISO timestamp to specified format.\"\"\"\n    dt = datetime.datetime.fromisoformat(timestamp.replace('Z', '+00:00'))\n    \n    if format_type == \"iso\":\n        return timestamp\n    elif format_type == \"epoch\":\n        return str(dt.timestamp())\n    elif format_type == \"readable\":\n        return dt.strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n    else:\n        # Assume custom strftime format\n        return dt.strftime(format_type)\n\nclass TimestampCache:\n    \"\"\"LRU cache for formatted timestamps to improve performance.\"\"\"\n    \n    def __init__(self, max_size: int = 100):\n        self.max_size = max_size\n        self._cache: Dict[str, str] = {}\n        self._access_order = []\n    \n    def get_formatted(self, timestamp: str, format_type: str) -> str:\n        cache_key = f\"{timestamp}:{format_type}\"\n        \n        if cache_key in self._cache:\n            # Move to end (most recently used)\n            self._access_order.remove(cache_key)\n            self._access_order.append(cache_key)\n            return self._cache[cache_key]\n        \n        # Cache miss - format and store\n        formatted = format_timestamp(timestamp, format_type)\n        self._cache[cache_key] = formatted\n        self._access_order.append(cache_key)\n        \n        # Evict oldest if over limit\n        if len(self._cache) > self.max_size:\n            oldest = self._access_order.pop(0)\n            del self._cache[oldest]\n        \n        return formatted\n```\n\n**D. Core Logic Skeletons:**\n\n**JSONFormatter (Core Implementation Skeleton):**\n```python\nfrom typing import Dict, Any\nfrom .base_formatter import BaseFormatter\nfrom ..models import LogRecord\nfrom ..utils.serialization import safe_serialize, estimate_serialized_size\n\nclass JSONFormatter(BaseFormatter):\n    \"\"\"Formats log records as single-line JSON objects.\"\"\"\n    \n    def __init__(self, max_context_size: int = 10000, timestamp_format: str = \"iso\"):\n        self.max_context_size = max_context_size\n        self.timestamp_format = timestamp_format\n        \n    def format(self, record: LogRecord) -> str:\n        \"\"\"Convert LogRecord to single-line JSON string.\"\"\"\n        # TODO 1: Convert LogRecord to dictionary using to_dict method\n        # TODO 2: Check context size using estimate_serialized_size\n        # TODO 3: If context too large, replace with size summary\n        # TODO 4: Format timestamp according to configured format\n        # TODO 5: Serialize dictionary to JSON using safe_serialize\n        # TODO 6: Return single-line JSON string\n        pass\n    \n    def to_dict(self, record: LogRecord) -> Dict[str, Any]:\n        \"\"\"Convert LogRecord to dictionary for JSON serialization.\"\"\"  \n        # TODO 1: Create base dictionary with timestamp, level, message, logger\n        # TODO 2: Map numeric level to string name using LEVEL_NAMES\n        # TODO 3: Add context fields if present and not empty\n        # TODO 4: Ensure consistent field ordering (timestamp, level, message, logger, context)\n        # Hint: Use collections.OrderedDict or rely on Python 3.7+ dict ordering\n        pass\n```\n\n**PrettyFormatter (Core Implementation Skeleton):**\n```python\nimport os\nfrom typing import Dict, Any, List\nfrom .base_formatter import BaseFormatter\nfrom ..models import LogRecord\n\nclass PrettyFormatter(BaseFormatter):\n    \"\"\"Human-readable console formatter with colors and indentation.\"\"\"\n    \n    # Color constants\n    COLORS = {\n        'DEBUG': '\\033[36m',    # Cyan\n        'INFO': '\\033[32m',     # Green  \n        'WARN': '\\033[33m',     # Yellow\n        'ERROR': '\\033[31m',    # Red\n        'FATAL': '\\033[1;91m',  # Bright Red + Bold\n        'RESET': '\\033[0m'      # Reset\n    }\n    \n    def __init__(self, use_colors: bool = None):\n        self.use_colors = use_colors if use_colors is not None else self._detect_color_support()\n        \n    def format(self, record: LogRecord) -> str:\n        \"\"\"Convert LogRecord to colored multi-line string.\"\"\"\n        # TODO 1: Format timestamp as short time (HH:MM:SS.mmm)\n        # TODO 2: Apply color to log level based on severity\n        # TODO 3: Create main line with timestamp, level, logger, and message\n        # TODO 4: Format context fields with tree-style indentation\n        # TODO 5: Combine main line and context lines with proper spacing\n        # TODO 6: Add blank line separator for visual grouping\n        # Hint: Use colorize method for color application with fallback\n        pass\n        \n    def format_context(self, context: Dict[str, Any], indent_level: int = 1) -> List[str]:\n        \"\"\"Format context fields with tree-style indentation.\"\"\"\n        # TODO 1: If context is empty, return empty list\n        # TODO 2: Create list to collect formatted lines  \n        # TODO 3: Iterate through context items with enumerate for last-item detection\n        # TODO 4: Use ├── for non-final items and └── for final item\n        # TODO 5: Handle nested dictionaries with recursive calls\n        # TODO 6: Truncate large values with summary hint\n        # Hint: Use \"├──\" and \"└──\" Unicode characters for tree structure\n        pass\n    \n    def colorize(self, text: str, color: str) -> str:\n        \"\"\"Apply color with terminal capability detection.\"\"\"\n        # TODO 1: Check if colors are enabled and supported\n        # TODO 2: If not supported, return text without modification\n        # TODO 3: If supported, wrap text with color code and reset\n        # Hint: Always include RESET code after colored text\n        pass\n    \n    def _detect_color_support(self) -> bool:\n        \"\"\"Detect if terminal supports color output.\"\"\" \n        # TODO 1: Check if stdout is a TTY (not redirected to file)\n        # TODO 2: Check TERM environment variable for color capability\n        # TODO 3: Return True only if both conditions are met\n        # Hint: Use os.isatty() and os.environ.get()\n        pass\n```\n\n**FormatterRegistry (Core Implementation Skeleton):**\n```python\nimport threading\nfrom typing import Dict, Optional, List\nfrom .base_formatter import BaseFormatter\n\nclass FormatterRegistry:\n    \"\"\"Thread-safe registry for formatter plugins.\"\"\"\n    \n    def __init__(self):\n        self._formatters: Dict[str, BaseFormatter] = {}\n        self._lock = threading.RLock()\n        \n    def register_formatter(self, name: str, formatter: BaseFormatter) -> None:\n        \"\"\"Register a formatter with given name.\"\"\"\n        # TODO 1: Acquire write lock\n        # TODO 2: Validate formatter inherits from BaseFormatter\n        # TODO 3: Store formatter in registry with name as key\n        # TODO 4: Release lock\n        # Hint: Use isinstance() to check formatter type\n        pass\n        \n    def get_formatter(self, name: str) -> Optional[BaseFormatter]:\n        \"\"\"Retrieve formatter by name.\"\"\"\n        # TODO 1: Acquire read lock  \n        # TODO 2: Look up formatter in registry\n        # TODO 3: Return formatter or None if not found\n        # TODO 4: Release lock\n        pass\n        \n    def list_formatters(self) -> List[str]:\n        \"\"\"List all registered formatter names.\"\"\"\n        # TODO 1: Acquire read lock\n        # TODO 2: Get list of registered names\n        # TODO 3: Return sorted list of names\n        # TODO 4: Release lock\n        pass\n\n# Global registry instance\n_formatter_registry = FormatterRegistry()\n\ndef register_formatter(name: str, formatter: BaseFormatter) -> None:\n    \"\"\"Register formatter in global registry.\"\"\"\n    _formatter_registry.register_formatter(name, formatter)\n\ndef get_formatter(name: str) -> Optional[BaseFormatter]:\n    \"\"\"Get formatter from global registry.\"\"\"\n    return _formatter_registry.get_formatter(name)\n```\n\n**E. Language-Specific Hints:**\n- Use `json.dumps(separators=(',', ':'))` for compact single-line JSON output\n- `collections.OrderedDict` ensures consistent field ordering in Python versions before 3.7\n- `sys.getsizeof()` provides object size estimation for truncation decisions\n- `threading.RLock()` allows the same thread to acquire the lock multiple times\n- `os.isatty(sys.stdout.fileno())` detects if output is going to a terminal vs file\n- Unicode characters like `├──` and `└──` create clean tree-style formatting\n\n**F. Milestone Checkpoint:**\nAfter completing this milestone, test your structured output system:\n\n**Test Commands:**\n```bash\npython -m pytest tests/test_formatters.py -v\npython test_formatting_demo.py  # Custom demo script\n```\n\n**Expected JSON Output:**\n```json\n{\"timestamp\":\"2024-01-15T18:30:45.123456Z\",\"level\":\"ERROR\",\"message\":\"Test message\",\"logger\":\"test.formatter\",\"context\":{\"key\":\"value\"}}\n```\n\n**Expected Pretty Output:**\n```\n[18:30:45.123] ERROR test.formatter\nTest message\n└── key: \"value\"\n\n```\n\n**Verification Steps:**\n1. JSON formatter produces valid single-line JSON parseable by `json.loads()`\n2. Pretty formatter displays colors in terminal but plain text when redirected to file\n3. Context fields appear consistently across different formatters\n4. Large context objects are truncated appropriately\n5. Non-serializable objects don't crash the formatter\n\n**Common Issues to Check:**\n- JSON output contains no newlines or pretty-printing\n- Colors only appear in interactive terminals, not in log files\n- Timestamp format matches configuration settings\n- Context truncation prevents memory exhaustion\n- Thread safety works under concurrent formatting load\n\n\n## Context and Correlation Design\n\n> **Milestone(s):** This section primarily addresses Milestone 3 (Context & Correlation) by defining request tracing, correlation ID systems, context propagation mechanisms, and async boundary preservation. Some elements support all milestones through the context enrichment capabilities of LogRecord objects.\n\nThink of correlation IDs and context propagation like a **relay race baton**. In a relay race, runners must pass a physical baton from one runner to the next to maintain continuity and prove the race was completed legitimately. Similarly, in a distributed system handling requests, we need to pass a \"context baton\" containing correlation IDs and metadata from one function to the next, one service to the next, and even across async task boundaries. Without this baton-passing mechanism, we lose the ability to trace a request's journey through our system - it's like having runners complete their legs independently without proving they're part of the same race.\n\nThe fundamental challenge in context and correlation design lies in maintaining this continuity across three distinct boundaries: **function call boundaries** (nested calls within a thread), **thread boundaries** (when work moves between threads), and **async boundaries** (when coroutines suspend and resume). Each boundary requires a different propagation strategy, yet the developer experience should remain seamless - they should be able to log with full context regardless of these underlying complexity layers.\n\n### Correlation ID System\n\nA **correlation ID** serves as the unique fingerprint for a request's journey through your system. Think of it like a **shipping tracking number** - just as you can trace a package's movement from warehouse to warehouse using its tracking number, you can trace a request's flow through services, functions, and async operations using its correlation ID. This identifier links all log entries related to the same logical operation, enabling you to reconstruct the complete story of what happened during request processing.\n\nThe correlation ID system operates on four core principles: **uniqueness** (each request gets a globally unique identifier), **persistence** (the ID travels with the request context), **automatic injection** (developers don't manually add IDs to every log call), and **boundary crossing** (the ID survives function calls, thread switches, and async operations). These principles ensure that correlation works transparently without requiring constant developer intervention.\n\n> **Decision: Correlation ID Generation Strategy**\n> - **Context**: Need globally unique identifiers that are human-readable, sortable, and carry minimal overhead\n> - **Options Considered**: UUID4 (random), UUID1 (timestamp-based), custom base62 format, request sequence numbers\n> - **Decision**: UUID4 with optional prefix for service identification\n> - **Rationale**: UUID4 provides strong uniqueness guarantees without coordination, has excellent library support across languages, and avoids potential timing attacks from timestamp-based IDs. Optional service prefixes (e.g., \"api-server-550e8400\") improve readability while maintaining uniqueness\n> - **Consequences**: 36-character overhead per log entry, but enables reliable request tracing across service boundaries without central coordination\n\n| Component | Responsibility | Key Behavior |\n|-----------|---------------|--------------|\n| `CorrelationIDGenerator` | Generate unique request identifiers | Creates UUID4 strings with optional service prefix, thread-safe generation |\n| `RequestIDInjector` | Automatically add correlation IDs to new requests | Detects missing correlation context, generates new IDs, preserves existing IDs |\n| `ContextualLogger` | Enrich log records with correlation data | Merges correlation ID with log message context, handles missing ID scenarios |\n| `IDPropagator` | Carry correlation IDs across boundaries | Maintains ID in thread-local and async-local storage, handles inheritance |\n\nThe correlation ID lifecycle begins when a request enters your system. At the **entry point** (HTTP request handler, message queue consumer, scheduled job), the system either extracts an existing correlation ID from headers/metadata or generates a new one. This ID immediately becomes part of the request context and flows through all subsequent operations. When the request spawns child operations (database calls, service calls, async tasks), the correlation ID propagates to those contexts automatically.\n\n**Correlation ID propagation** follows a specific priority order: First, check if the current context already contains a correlation ID and preserve it. Second, look for an incoming correlation ID from request headers, parent contexts, or message metadata. Third, generate a new correlation ID only if none exists. This priority ensures that correlation chains remain intact across service boundaries while preventing orphaned operations from lacking traceability.\n\n| Propagation Scenario | Source | Action Taken |\n|---------------------|---------|--------------|\n| HTTP Request with `X-Correlation-ID` header | Request headers | Extract and use existing ID |\n| HTTP Request without correlation header | Request context | Generate new UUID4 and set response header |\n| Nested function call within request | Parent context | Inherit ID from thread-local or async-local storage |\n| Background async task spawned from request | Parent task context | Copy ID to new task's context |\n| Database query from request handler | Current context | Include ID in query metadata/comments |\n| Inter-service call | Current context | Add ID to outgoing request headers |\n\n⚠️ **Pitfall: Correlation ID Collision**\nA common mistake is generating correlation IDs using timestamp-based schemes or sequential counters that can collide across service instances. This breaks request tracing because multiple unrelated requests share the same ID. Use UUID4 generation with proper entropy sources, and include service identifiers in the prefix if you need human-readable correlation IDs.\n\nThe correlation ID must be **automatically injected** into every `LogRecord` without requiring developers to manually include it in each logging call. This happens through the context enrichment process - when a `LogRecord` is created, the system queries the current correlation context and merges the ID into the record's context fields. The injection process should be transparent and fail gracefully if no correlation ID exists (logging the message without correlation rather than failing).\n\n```table\n| Field Name | Type | Description |\n|------------|------|-------------|\n| `correlation_id` | `str` | UUID4 identifier for request tracing |\n| `request_id` | `str` | Alias for correlation_id for backward compatibility |\n| `parent_id` | `str \\| None` | ID of parent operation for nested request tracing |\n| `operation_id` | `str \\| None` | Unique identifier for sub-operations within a request |\n| `session_id` | `str \\| None` | User session identifier for user journey tracing |\n```\n\n### Context Propagation\n\n**Context propagation** is the mechanism that carries key-value pairs through nested function calls without requiring explicit parameter passing. Think of it like **ambient lighting** in a room - just as ambient light illuminates everything in the space without needing to shine a spotlight on each object individually, context propagation makes contextual information (user ID, request metadata, feature flags) available to all code within a request's execution scope.\n\nContext propagation solves the **parameter drilling problem** where contextual data must be passed as parameters through many layers of function calls, even when intermediate functions don't use the data. Without propagation, a user ID determined at the HTTP handler level would need explicit passing through business logic, data access, and utility functions just to reach a deep logging call. Context propagation makes this information ambient - available anywhere within the request scope without explicit passing.\n\n> **Decision: Context Storage Mechanism**\n> - **Context**: Need to store context data that's accessible from any function within a request without parameter passing\n> - **Options Considered**: Thread-local storage only, async-local storage only, hybrid approach with both mechanisms\n> - **Decision**: Hybrid approach using both thread-local and async-local storage with automatic synchronization\n> - **Rationale**: Thread-local handles synchronous code paths efficiently, async-local preserves context across await boundaries, hybrid approach provides complete coverage without forcing async/await everywhere\n> - **Consequences**: Slight memory overhead from dual storage, but enables seamless context access in both sync and async codepaths\n\nThe core of context propagation is the `LoggingContext` manager, which maintains a **dual storage strategy**. Thread-local storage handles synchronous execution paths where code runs on a single thread without interruption. Async-local storage (using asyncio context variables or equivalent) handles asynchronous execution where coroutines can suspend and resume on different threads. The context manager synchronizes between these storage mechanisms to provide a unified view.\n\n| Context Operation | Thread-Local Behavior | Async-Local Behavior | Synchronization |\n|------------------|----------------------|---------------------|-----------------|\n| `get_current()` | Read from threading.local | Read from contextvars.ContextVar | Return union of both sources |\n| `set_current(context)` | Write to threading.local | Write to contextvars.ContextVar | Update both storage locations |\n| `add_fields(**fields)` | Merge with existing thread context | Merge with existing async context | Merge results and update both |\n| `clear()` | Clear threading.local data | Clear contextvars context | Reset both storage mechanisms |\n\n**Context inheritance** follows a layered approach where child contexts inherit all fields from their parent and can add additional fields without modifying the parent. This creates an **inheritance chain** similar to object-oriented inheritance - changes in child contexts are isolated from parents, but children automatically receive parent updates. The inheritance mechanism enables request-level context (user ID, correlation ID) to coexist with operation-level context (database transaction ID, cache keys) without conflicts.\n\n```table\n| Context Layer | Scope | Typical Fields | Inheritance Behavior |\n|---------------|--------|----------------|---------------------|\n| Request Level | Entire HTTP request | `user_id`, `correlation_id`, `request_method` | Inherited by all operations within request |\n| Operation Level | Business logic operation | `operation_name`, `feature_flags`, `tenant_id` | Inherits request context, adds operation-specific fields |\n| Function Level | Individual function call | `function_name`, `parameters`, `execution_id` | Inherits operation context, adds function-specific fields |\n| Error Level | Error handling block | `error_type`, `error_message`, `recovery_action` | Inherits function context, adds error-specific fields |\n```\n\nThe **context propagation algorithm** follows these steps for each nested function call:\n\n1. **Context Capture**: When entering a new execution context (function call, async task creation), capture the current context state from both thread-local and async-local storage\n2. **Context Inheritance**: Create a new context object that inherits all fields from the captured parent context\n3. **Context Activation**: Set the new context as current in both storage mechanisms, making it available to nested calls\n4. **Context Isolation**: Ensure changes to the new context don't affect the parent context that will be restored later\n5. **Context Restoration**: When exiting the execution context, restore the previous context state to both storage mechanisms\n6. **Context Cleanup**: Remove any temporary context data that shouldn't persist beyond the current execution scope\n\n**Context field management** requires careful handling of data types and serialization. Context fields must be serializable to JSON for inclusion in log records, but the context system should accept arbitrary Python objects and handle serialization gracefully. Non-serializable objects (file handles, database connections, lambda functions) should be converted to string representations rather than causing serialization failures.\n\n| Field Type | Storage Approach | Serialization Behavior | Example |\n|------------|-----------------|----------------------|---------|\n| Primitive types | Store directly | Serialize as-is | `\"user_id\": \"12345\"`, `\"timeout\": 30` |\n| Collections | Store directly if serializable | Recursive serialization | `\"tags\": [\"api\", \"production\"]` |\n| Custom objects | Store string representation | Convert to string before serialization | `\"database\": \"<Connection:localhost:5432>\"` |\n| Circular references | Detect and replace with placeholder | Replace with reference placeholder | `\"parent\": \"<CircularReference>\"` |\n| Large objects | Truncate or summarize | Limit size to prevent log bloat | `\"request_body\": \"<Data:1024 bytes>\"` |\n\n⚠️ **Pitfall: Context Memory Leaks**\nA critical mistake is storing large objects or circular references in context without cleanup, leading to memory leaks. Context should contain only essential metadata (strings, numbers, small collections). Large objects like request bodies, database result sets, or file contents should be summarized or referenced by ID rather than stored directly in context.\n\n### Async Context Bridge\n\nThe **async context bridge** solves the most complex problem in context propagation: preserving logging context when execution crosses async/await boundaries. Think of async operations like **airline passengers changing planes** during a layover. Just as passengers must carry their luggage and boarding passes from one plane to the next to maintain their journey's continuity, async operations must carry their logging context from one coroutine to the next to maintain request tracing.\n\nAsync context preservation is challenging because **coroutines can suspend and resume** on different threads, traditional thread-local storage becomes unreliable, and **multiple coroutines** can run concurrently within the same request, each needing isolated context. The bridge mechanism ensures that when a coroutine suspends (awaits another operation), its logging context is preserved, and when it resumes, the same context is restored regardless of which thread it resumes on.\n\n> **Decision: Async Context Storage Strategy**\n> - **Context**: Async operations suspend and resume across thread boundaries, making thread-local storage insufficient\n> - **Options Considered**: Manual context passing, asyncio.current_task() storage, contextvars.ContextVar, custom async-local implementation\n> - **Decision**: contextvars.ContextVar with automatic synchronization to thread-local storage\n> - **Rationale**: contextvars provides language-level async context support, automatically handles suspend/resume cycles, and integrates well with asyncio task management. Synchronization with thread-local ensures compatibility with synchronous code\n> - **Consequences**: Requires Python 3.7+ for contextvars, slight overhead from dual storage, but provides robust async context preservation\n\nThe async context bridge operates through **context variables** that maintain their values across await boundaries. When an async function begins execution, it inherits the context variables from its caller. When it suspends on an await, the context variables are automatically preserved. When it resumes, the same context variables are restored, regardless of the underlying thread changes.\n\n![Context Propagation Flow](./diagrams/context-propagation-flow.svg)\n\n```table\n| Context State | Event | Next State | Actions Taken |\n|---------------|--------|------------|---------------|\n| `Active` | Function entry | `Active` | Inherit parent context, create child context |\n| `Active` | Await operation | `Suspended` | Store context in contextvars, suspend coroutine |\n| `Suspended` | Operation completion | `Active` | Restore context from contextvars, resume coroutine |\n| `Active` | Exception raised | `Error` | Preserve context for error logging, propagate exception |\n| `Error` | Exception handled | `Active` | Restore pre-exception context, continue execution |\n| `Active` | Function exit | `Cleaned` | Restore parent context, cleanup temporary fields |\n```\n\nThe **context bridge implementation** requires careful coordination between async and sync storage mechanisms. The bridge maintains a **bidirectional synchronization** where changes to async context (via contextvars) are reflected in thread-local storage and vice versa. This ensures that code using either storage mechanism sees consistent context data.\n\n**Async task spawning** is a critical point where context must be explicitly propagated. When creating new async tasks using `asyncio.create_task()`, `asyncio.gather()`, or similar mechanisms, the current context should be captured and passed to the new task. This prevents child tasks from losing their parent's logging context and enables proper correlation across parallel operations.\n\n```table\n| Async Operation | Context Propagation Strategy | Implementation Notes |\n|----------------|------------------------------|----------------------|\n| `await async_func()` | Automatic via contextvars | No manual intervention required |\n| `asyncio.create_task()` | Copy current context to new task | Use contextvars.copy_context() for explicit copying |\n| `asyncio.gather()` | Inherit context in each gathered operation | Each operation starts with caller's context |\n| `asyncio.wait_for()` | Preserve context across timeout | Context maintained even if operation times out |\n| Background tasks | Explicit context injection | Pass context as task parameter or use task-local storage |\n| Task cancellation | Context cleanup on cancellation | Restore parent context when task is cancelled |\n```\n\n**Context isolation** between concurrent async operations is essential to prevent context pollution. When multiple async operations run concurrently (through `asyncio.gather()` or similar), each should maintain its own context copy. Changes to one operation's context shouldn't affect concurrent operations, even if they share the same parent context.\n\n⚠️ **Pitfall: Context Not Surviving Async Boundaries**\nA common mistake is assuming thread-local storage will work in async code. When an async function suspends and resumes, it might continue on a different thread, making thread-local data inaccessible. Always use contextvars.ContextVar for async operations and ensure proper synchronization with thread-local storage for mixed sync/async codebases.\n\nThe **context lifecycle management** in async environments follows a specific pattern:\n\n1. **Context Inheritance**: New async operations inherit context from their creator through contextvars propagation\n2. **Context Isolation**: Each async operation gets its own context copy to prevent interference between concurrent operations\n3. **Context Synchronization**: Changes to async context are reflected in thread-local storage for compatibility with sync code\n4. **Context Cleanup**: When async operations complete, temporary context fields are cleaned up to prevent memory accumulation\n5. **Context Restoration**: Parent context is restored after child async operations complete\n6. **Error Context**: Exception handling preserves context for error logging before propagating failures\n\n![Async Context State Machine](./diagrams/async-context-states.svg)\n\n### Request Context Middleware\n\n**Request context middleware** serves as the **entry point orchestrator** for the entire context and correlation system. Think of it as the **hotel concierge** who greets guests at the entrance, gathers their information, provides them with key cards and room service menus, and ensures they have everything needed for their stay. Similarly, request middleware greets incoming HTTP requests, extracts or generates correlation IDs, gathers request metadata, and establishes the logging context that will be available throughout request processing.\n\nThe middleware operates at the **HTTP framework level**, intercepting requests before they reach business logic and responses before they're sent to clients. This positioning ensures that every request gets consistent context treatment regardless of which endpoint handles it, and that correlation data is properly extracted from incoming headers and injected into outgoing headers for distributed tracing.\n\n> **Decision: Middleware Integration Strategy**\n> - **Context**: Need to integrate context setup with various HTTP frameworks (Flask, Django, FastAPI) without framework-specific implementations\n> - **Options Considered**: Framework-specific middleware for each platform, WSGI/ASGI middleware for universal compatibility, decorator-based approach\n> - **Decision**: WSGI/ASGI middleware with framework-specific convenience wrappers\n> - **Rationale**: WSGI/ASGI middleware works across all Python web frameworks, provides consistent behavior, and allows framework-specific optimizations through optional wrappers. This approach maximizes compatibility while enabling framework-specific features\n> - **Consequences**: Requires understanding of WSGI/ASGI interfaces, but provides universal compatibility and consistent context behavior across different web frameworks\n\nThe **request context extraction** process follows a standardized approach for gathering contextual information from HTTP requests. The middleware examines request headers for existing correlation IDs, extracts user identification from authentication headers, captures request metadata (method, path, user agent), and determines request characteristics (content type, request size, client IP).\n\n```table\n| Context Source | Header/Field Name | Extraction Logic | Fallback Behavior |\n|----------------|------------------|------------------|------------------|\n| Correlation ID | `X-Correlation-ID`, `X-Request-ID` | Use first found header value | Generate new UUID4 |\n| User Identity | `Authorization`, `X-User-ID` | Extract from JWT/token or direct header | Anonymous user context |\n| Request Method | HTTP method | Direct from request object | Required field, no fallback |\n| Request Path | URL path | Normalized path without query params | Required field, no fallback |\n| Client IP | `X-Forwarded-For`, `X-Real-IP` | Use leftmost IP from forwarded headers | Fall back to direct connection IP |\n| User Agent | `User-Agent` | Direct header value | 'Unknown' if header missing |\n```\n\n**Request metadata enrichment** automatically captures standard request information that's valuable for logging and debugging. This metadata becomes part of the base request context that all subsequent operations inherit. The enrichment process captures both standard HTTP metadata and application-specific context that can be determined at request time.\n\n```table\n| Metadata Field | Data Type | Description | Example Value |\n|----------------|-----------|-------------|---------------|\n| `request_id` | `str` | Correlation ID for this request | `\"550e8400-e29b-41d4-a716-446655440000\"` |\n| `request_method` | `str` | HTTP method for the request | `\"POST\"` |\n| `request_path` | `str` | URL path without query parameters | `\"/api/users/123/orders\"` |\n| `request_size` | `int` | Content length in bytes | `1024` |\n| `user_id` | `str \\| None` | Authenticated user identifier | `\"user_789\"` |\n| `client_ip` | `str` | Client IP address (respecting proxies) | `\"192.168.1.100\"` |\n| `user_agent` | `str` | Client user agent string | `\"Mozilla/5.0 (Windows NT 10.0; Win64; x64)...\"` |\n| `content_type` | `str \\| None` | Request content type | `\"application/json\"` |\n| `request_start_time` | `str` | ISO timestamp when request processing began | `\"2024-01-15T10:30:45.123456Z\"` |\n```\n\nThe **context activation process** sets up the complete logging environment for request processing. This involves creating the initial request context with extracted metadata, activating the context in both thread-local and async-local storage, configuring any request-specific logging behavior (debug mode for specific users, increased log levels for error investigation), and ensuring context propagation is ready for nested operations.\n\n**Context activation algorithm**:\n\n1. **Extract incoming context**: Parse correlation ID from headers, decode user information from authentication tokens, capture standard request metadata\n2. **Generate missing context**: Create new correlation ID if none provided, set anonymous user context if unauthenticated, establish request timing information\n3. **Create request context**: Combine extracted and generated context into a structured context object\n4. **Activate storage mechanisms**: Set context in both thread-local storage (for sync code) and async-local storage (for async operations)\n5. **Configure request-specific logging**: Apply any user-specific or path-specific logging configuration (debug mode, sampling rates)\n6. **Establish cleanup hooks**: Register context cleanup functions to run after request completion\n\n**Response header injection** ensures that correlation IDs and tracing information flow to downstream systems and clients. The middleware captures the final correlation ID from the request context and injects it into response headers. This enables client-side correlation and helps with distributed tracing when the client makes subsequent requests to other services.\n\n```table\n| Response Header | Content | Purpose |\n|----------------|---------|---------|\n| `X-Correlation-ID` | Current request correlation ID | Enable client-side request correlation |\n| `X-Request-Duration` | Request processing time in milliseconds | Provide timing information to clients |\n| `X-Response-Size` | Response content length | Complete request/response size tracking |\n```\n\nThe **middleware error handling** ensures that context and correlation continue working even when request processing fails. When exceptions occur during request processing, the middleware captures error context (exception type, error message, stack trace ID) and includes it in the final log entries. The middleware also ensures that context cleanup happens regardless of whether the request succeeds or fails.\n\n⚠️ **Pitfall: Context Leakage Between Requests**\nA critical mistake is failing to clean up context between requests in applications that reuse threads (most web frameworks). Context from one request can leak into subsequent requests if cleanup isn't properly implemented. Always ensure context is cleared at the end of request processing and that new requests start with fresh context.\n\n**Framework integration patterns** provide specific guidance for common Python web frameworks:\n\n```table\n| Framework | Integration Method | Key Considerations |\n|-----------|-------------------|-------------------|\n| Flask | Custom middleware or before_request/after_request hooks | Use Flask's application context for storage synchronization |\n| Django | Custom middleware inheriting from Django middleware base | Integrate with Django's request/response cycle and user authentication |\n| FastAPI | Dependency injection or custom middleware | Leverage FastAPI's async support and dependency injection for context setup |\n| Tornado | RequestHandler subclass or custom middleware | Handle Tornado's async request processing and ensure context preservation |\n| WSGI apps | WSGI middleware wrapping the application | Universal approach working with any WSGI-compatible framework |\n| ASGI apps | ASGI middleware for async applications | Handle async request processing and ensure context survives async boundaries |\n```\n\nThe middleware also handles **request context inheritance** for applications that spawn background tasks or make inter-service calls during request processing. When the application creates background tasks, the middleware-established context should be available to those tasks. When making outbound HTTP requests, the correlation ID should be automatically included in request headers.\n\n### Implementation Guidance\n\nThe context and correlation system requires careful coordination between multiple storage mechanisms and careful handling of async boundaries. This implementation guidance provides concrete patterns for building robust context propagation that works across both synchronous and asynchronous code paths.\n\n**A. Technology Recommendations Table:**\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Correlation ID Generation | UUID4 with Python uuid module | Custom base62 IDs with service prefixes |\n| Context Storage | threading.local + contextvars.ContextVar | Redis for distributed context sharing |\n| Async Context | Python contextvars (3.7+) | Custom async-local implementation |\n| HTTP Middleware | Simple WSGI middleware | Framework-specific middleware with optimizations |\n| Context Serialization | JSON with custom encoder | MessagePack for efficiency |\n| Context Cleanup | Manual cleanup in finally blocks | Automatic cleanup with context managers |\n\n**B. Recommended File/Module Structure:**\n```\nproject-root/\n  logging_system/\n    context/\n      __init__.py              ← Public context API exports\n      correlation.py           ← Correlation ID generation and management\n      propagation.py           ← Thread-local and async context storage\n      async_bridge.py          ← Async context preservation mechanisms\n      middleware.py            ← HTTP request context middleware\n      storage.py               ← Context storage backends (thread-local, async-local)\n      serialization.py         ← Context serialization utilities\n    core/\n      logger.py                ← Logger class with context integration\n      record.py                ← LogRecord with context fields\n  tests/\n    context/\n      test_correlation.py      ← Correlation ID tests\n      test_propagation.py      ← Context propagation tests\n      test_async_bridge.py     ← Async context tests\n      test_middleware.py       ← Middleware integration tests\n```\n\n**C. Infrastructure Starter Code:**\n\nComplete correlation ID generation system:\n\n```python\n# logging_system/context/correlation.py\nimport uuid\nimport threading\nfrom typing import Optional\n\nclass CorrelationIDGenerator:\n    \"\"\"Thread-safe correlation ID generator with optional service prefixes.\"\"\"\n    \n    def __init__(self, service_name: Optional[str] = None):\n        self.service_name = service_name\n        self._lock = threading.Lock()\n    \n    def generate(self) -> str:\n        \"\"\"Generate a new correlation ID with optional service prefix.\"\"\"\n        correlation_id = str(uuid.uuid4())\n        if self.service_name:\n            return f\"{self.service_name}-{correlation_id}\"\n        return correlation_id\n    \n    def is_valid(self, correlation_id: str) -> bool:\n        \"\"\"Validate correlation ID format.\"\"\"\n        if self.service_name:\n            if not correlation_id.startswith(f\"{self.service_name}-\"):\n                return False\n            uuid_part = correlation_id[len(self.service_name) + 1:]\n        else:\n            uuid_part = correlation_id\n        \n        try:\n            uuid.UUID(uuid_part)\n            return True\n        except ValueError:\n            return False\n\n# Global generator instance\n_default_generator = CorrelationIDGenerator()\n\ndef generate_correlation_id() -> str:\n    \"\"\"Generate a new correlation ID using the default generator.\"\"\"\n    return _default_generator.generate()\n\ndef set_service_name(service_name: str) -> None:\n    \"\"\"Set service name for correlation ID generation.\"\"\"\n    global _default_generator\n    _default_generator = CorrelationIDGenerator(service_name)\n```\n\nComplete context storage system:\n\n```python\n# logging_system/context/storage.py\nimport threading\nimport contextvars\nfrom typing import Dict, Any, Optional\nfrom copy import deepcopy\n\nclass ContextStorage:\n    \"\"\"Hybrid context storage using both thread-local and async-local mechanisms.\"\"\"\n    \n    def __init__(self):\n        self._thread_local = threading.local()\n        self._async_var: contextvars.ContextVar = contextvars.ContextVar(\n            'logging_context', \n            default={}\n        )\n    \n    def get_context(self) -> Dict[str, Any]:\n        \"\"\"Get current context from both storage mechanisms.\"\"\"\n        # Get thread-local context\n        thread_context = getattr(self._thread_local, 'context', {})\n        \n        # Get async context\n        async_context = self._async_var.get({})\n        \n        # Merge contexts (async takes precedence)\n        merged_context = thread_context.copy()\n        merged_context.update(async_context)\n        \n        return merged_context\n    \n    def set_context(self, context: Dict[str, Any]) -> None:\n        \"\"\"Set context in both storage mechanisms.\"\"\"\n        # Set in thread-local storage\n        self._thread_local.context = deepcopy(context)\n        \n        # Set in async storage\n        self._async_var.set(deepcopy(context))\n    \n    def add_fields(self, **fields) -> None:\n        \"\"\"Add fields to current context.\"\"\"\n        current_context = self.get_context()\n        current_context.update(fields)\n        self.set_context(current_context)\n    \n    def clear_context(self) -> None:\n        \"\"\"Clear context from both storage mechanisms.\"\"\"\n        # Clear thread-local\n        if hasattr(self._thread_local, 'context'):\n            delattr(self._thread_local, 'context')\n        \n        # Clear async context\n        self._async_var.set({})\n    \n    def copy_context(self) -> Dict[str, Any]:\n        \"\"\"Create a deep copy of current context for task spawning.\"\"\"\n        return deepcopy(self.get_context())\n\n# Global storage instance\n_context_storage = ContextStorage()\n```\n\nComplete request middleware foundation:\n\n```python\n# logging_system/context/middleware.py\nimport time\nfrom typing import Dict, Any, Optional, Callable\nfrom .correlation import generate_correlation_id\nfrom .storage import _context_storage\n\nclass RequestContextMiddleware:\n    \"\"\"WSGI middleware for automatic request context setup.\"\"\"\n    \n    def __init__(self, app: Callable, service_name: Optional[str] = None):\n        self.app = app\n        self.service_name = service_name\n    \n    def __call__(self, environ: Dict[str, Any], start_response: Callable):\n        # Extract request context\n        request_context = self._extract_request_context(environ)\n        \n        # Set up context storage\n        _context_storage.set_context(request_context)\n        \n        request_start = time.time()\n        \n        def enhanced_start_response(status: str, headers: list, exc_info=None):\n            # Add correlation headers to response\n            headers.append(('X-Correlation-ID', request_context['correlation_id']))\n            \n            request_duration = int((time.time() - request_start) * 1000)\n            headers.append(('X-Request-Duration', str(request_duration)))\n            \n            return start_response(status, headers, exc_info)\n        \n        try:\n            # Process request with context\n            return self.app(environ, enhanced_start_response)\n        finally:\n            # Clean up context\n            _context_storage.clear_context()\n    \n    def _extract_request_context(self, environ: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract request context from WSGI environ.\"\"\"\n        # Extract correlation ID from headers\n        correlation_id = (\n            environ.get('HTTP_X_CORRELATION_ID') or\n            environ.get('HTTP_X_REQUEST_ID') or\n            generate_correlation_id()\n        )\n        \n        # Extract basic request metadata\n        context = {\n            'correlation_id': correlation_id,\n            'request_method': environ.get('REQUEST_METHOD', 'UNKNOWN'),\n            'request_path': environ.get('PATH_INFO', '/'),\n            'request_start_time': time.time(),\n            'client_ip': self._get_client_ip(environ),\n            'user_agent': environ.get('HTTP_USER_AGENT', 'Unknown'),\n        }\n        \n        # Add service name if configured\n        if self.service_name:\n            context['service_name'] = self.service_name\n        \n        return context\n    \n    def _get_client_ip(self, environ: Dict[str, Any]) -> str:\n        \"\"\"Extract client IP respecting proxy headers.\"\"\"\n        # Check for forwarded headers first\n        forwarded_for = environ.get('HTTP_X_FORWARDED_FOR')\n        if forwarded_for:\n            # Take the first IP from the chain\n            return forwarded_for.split(',')[0].strip()\n        \n        real_ip = environ.get('HTTP_X_REAL_IP')\n        if real_ip:\n            return real_ip\n        \n        # Fall back to direct connection\n        return environ.get('REMOTE_ADDR', 'unknown')\n```\n\n**D. Core Logic Skeleton Code:**\n\nContext propagation system for implementation:\n\n```python\n# logging_system/context/propagation.py\nfrom typing import Dict, Any, Optional, ContextManager\nfrom contextlib import contextmanager\nfrom .storage import _context_storage\n\nclass LoggingContext:\n    \"\"\"Context manager for logging context propagation.\"\"\"\n    \n    @staticmethod\n    def get_current() -> Dict[str, Any]:\n        \"\"\"Get current logging context from storage.\"\"\"\n        # TODO 1: Retrieve context from hybrid storage mechanism\n        # TODO 2: Handle case where no context exists (return empty dict)\n        # TODO 3: Ensure returned context is a copy to prevent external modification\n        pass\n    \n    @staticmethod\n    def set_current(context: Dict[str, Any]) -> None:\n        \"\"\"Set current logging context in storage.\"\"\"\n        # TODO 1: Validate context is serializable (all values are JSON-compatible)\n        # TODO 2: Set context in both thread-local and async-local storage\n        # TODO 3: Handle storage errors gracefully (log warning, continue)\n        pass\n    \n    @staticmethod\n    def add_fields(**fields) -> None:\n        \"\"\"Add fields to current context without replacing existing context.\"\"\"\n        # TODO 1: Get current context from storage\n        # TODO 2: Merge new fields with existing context (new fields take precedence)\n        # TODO 3: Validate merged context is still serializable\n        # TODO 4: Update storage with merged context\n        # Hint: Use dict.update() but handle potential serialization issues\n        pass\n    \n    @staticmethod\n    def clear() -> None:\n        \"\"\"Clear current logging context from all storage.\"\"\"\n        # TODO 1: Clear context from thread-local storage\n        # TODO 2: Clear context from async-local storage  \n        # TODO 3: Handle storage errors (don't raise exceptions from cleanup)\n        pass\n    \n    @staticmethod\n    @contextmanager\n    def inherit(additional_context: Optional[Dict[str, Any]] = None) -> ContextManager[Dict[str, Any]]:\n        \"\"\"Context manager that inherits parent context and restores it on exit.\"\"\"\n        # TODO 1: Capture current context as parent context\n        # TODO 2: Create child context by copying parent context\n        # TODO 3: Merge additional_context into child context if provided\n        # TODO 4: Set child context as current context\n        # TODO 5: Yield the child context to the with block\n        # TODO 6: In finally block, restore parent context regardless of exceptions\n        # Hint: Use try/finally to ensure parent context is always restored\n        pass\n\ndef propagate_to_async_task(task_func: callable, *args, **kwargs):\n    \"\"\"Helper to propagate current context to a new async task.\"\"\"\n    # TODO 1: Capture current context before task creation\n    # TODO 2: Create wrapper function that sets context before calling task_func\n    # TODO 3: Return wrapped function that can be passed to asyncio.create_task()\n    # Hint: The wrapper should set context, call original function, then clean up\n    pass\n```\n\nAsync context bridge for implementation:\n\n```python\n# logging_system/context/async_bridge.py\nimport asyncio\nimport contextvars\nfrom typing import Dict, Any, Awaitable, TypeVar\nfrom .propagation import LoggingContext\n\nT = TypeVar('T')\n\nasync def preserve_context(coro: Awaitable[T]) -> T:\n    \"\"\"Ensure logging context is preserved across async operation.\"\"\"\n    # TODO 1: Capture current logging context before await\n    # TODO 2: Execute the coroutine and await its result\n    # TODO 3: Restore logging context after coroutine completes\n    # TODO 4: Handle exceptions by preserving context during error propagation\n    # Hint: Use try/finally to ensure context restoration\n    pass\n\ndef create_task_with_context(coro: Awaitable[T], context: Optional[Dict[str, Any]] = None) -> asyncio.Task[T]:\n    \"\"\"Create async task with explicit context propagation.\"\"\"\n    # TODO 1: Use context parameter or capture current context if None\n    # TODO 2: Create wrapper coroutine that sets context before running original\n    # TODO 3: Create asyncio task from wrapper coroutine\n    # TODO 4: Return the created task\n    # Hint: Use contextvars.copy_context() for proper async context copying\n    pass\n\nasync def gather_with_context(*coroutines: Awaitable) -> list:\n    \"\"\"Gather multiple coroutines while preserving context in each.\"\"\"\n    # TODO 1: Capture current context to propagate to all coroutines\n    # TODO 2: Wrap each coroutine with context preservation\n    # TODO 3: Use asyncio.gather() on wrapped coroutines\n    # TODO 4: Return results from asyncio.gather()\n    pass\n\nclass AsyncContextManager:\n    \"\"\"Context manager for async operations with logging context.\"\"\"\n    \n    def __init__(self, context: Optional[Dict[str, Any]] = None):\n        # TODO 1: Store provided context or capture current context\n        # TODO 2: Initialize previous_context storage for restoration\n        pass\n    \n    async def __aenter__(self) -> Dict[str, Any]:\n        # TODO 1: Capture current context as previous_context\n        # TODO 2: Set self.context as current context\n        # TODO 3: Return the active context\n        pass\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        # TODO 1: Restore previous_context as current context\n        # TODO 2: Handle any storage errors gracefully\n        # TODO 3: Don't suppress exceptions unless they're context-related\n        pass\n```\n\n**E. Language-Specific Hints:**\n\n- Use `threading.local()` for thread-local storage in Python\n- Use `contextvars.ContextVar` for async-local storage (requires Python 3.7+)\n- Use `asyncio.current_task()` to get current task for task-local storage\n- Use `copy.deepcopy()` to create isolated context copies\n- Use `uuid.uuid4()` for correlation ID generation with strong uniqueness guarantees\n- Use WSGI middleware pattern: `app(environ, start_response)` for universal framework compatibility\n- Use `functools.wraps` when creating context wrapper functions to preserve function metadata\n- Use `contextlib.contextmanager` decorator for simple context managers\n\n**F. Milestone Checkpoint:**\n\nAfter implementing Milestone 3, verify context and correlation functionality:\n\n**Command to run**: `python -m pytest tests/context/ -v`\n\n**Expected test output**:\n```\ntest_correlation_id_generation ✓\ntest_context_propagation_sync ✓  \ntest_context_propagation_async ✓\ntest_async_context_bridge ✓\ntest_request_middleware_integration ✓\n```\n\n**Manual verification steps**:\n1. **Start test web server**: `python examples/web_app.py`\n2. **Make request with correlation ID**: `curl -H \"X-Correlation-ID: test-123\" localhost:8000/api/test`\n3. **Verify logs contain correlation ID**: All log entries should include `\"correlation_id\": \"test-123\"`\n4. **Make request without correlation ID**: `curl localhost:8000/api/test`  \n5. **Verify generated correlation ID**: Logs should contain auto-generated UUID4 correlation ID\n6. **Test nested function calls**: All log entries from nested functions should inherit same correlation ID\n7. **Test async operations**: Async tasks spawned during request should preserve correlation context\n\n**Signs something is wrong**:\n- **Logs missing correlation IDs**: Context propagation not working, check storage mechanisms\n- **Different correlation IDs within same request**: Context not propagating properly across function calls\n- **Context lost in async operations**: Async context bridge not functioning, check contextvars usage\n- **Context leaking between requests**: Context cleanup not working, check middleware finally blocks\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|----------------|-----|\n| Correlation ID missing from logs | Context not set or not propagating | Add debug logging in context storage get/set methods | Ensure context middleware runs before request processing |\n| Different correlation IDs in same request | New IDs being generated instead of inheriting | Check context inheritance in nested function calls | Use LoggingContext.inherit() context manager |\n| Context lost in async operations | Thread-local storage used in async code | Add logging before/after async operations to track context | Use contextvars.ContextVar for async operations |\n| Context leaking between requests | Context not cleared after request completion | Add request start/end logging with context state | Ensure context.clear() in middleware finally block |\n| Memory usage growing over time | Context objects not being garbage collected | Monitor context storage size over time | Check for circular references in context data |\n| Performance degradation | Context copying overhead | Profile context get/set operations | Optimize context serialization, limit context size |\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** This section provides critical error handling patterns for all three milestones, with handler failure recovery supporting Milestone 1 (Logger Core), serialization edge cases affecting Milestone 2 (Structured Output), and context cleanup preventing memory issues in Milestone 3 (Context & Correlation).\n\n### The Safety Net Analogy\n\nThink of error handling in a logging system like the safety nets in a circus. When an acrobat performs dangerous stunts high above the ground, there are multiple layers of protection: primary safety harnesses, backup cables, and finally the net below. Similarly, our logging system must have multiple layers of protection because **logging cannot be allowed to crash the main application**. When a file system is full, when network connections fail, when objects contain circular references, the logging system must gracefully degrade rather than bringing down the entire service.\n\nThe critical insight is that logging is a **non-critical path operation** from the application's perspective. If an e-commerce service cannot write logs, it should still process orders successfully. However, losing observability is serious, so we need sophisticated recovery mechanisms that maintain partial functionality while alerting operators to the underlying issues.\n\n### Handler Failure Recovery\n\nHandler failure recovery addresses the reality that output destinations are inherently unreliable. File systems can become full, network connections can timeout, and remote log aggregation services can become unavailable. The logging system must continue operating in these scenarios while providing mechanisms for recovery and alerting.\n\n> **Decision: Multi-Handler Isolation**\n> - **Context**: When one handler fails (e.g., network timeout), other handlers should continue working\n> - **Options Considered**: Fail-fast on any handler error, retry all handlers together, isolate handler failures\n> - **Decision**: Isolate handler failures so each handler's success/failure is independent\n> - **Rationale**: A full disk shouldn't prevent console logging, and network issues shouldn't stop file logging\n> - **Consequences**: Requires individual error handling per handler but maintains maximum availability\n\nThe handler dispatch mechanism implements the **Circuit Breaker Pattern** for each handler type. When a handler experiences repeated failures, it transitions to a failed state and stops attempting operations for a configured time period. This prevents cascading failures and reduces resource consumption during outages.\n\n#### Handler Error States\n\nEach handler maintains state information to track its health and implement appropriate recovery strategies:\n\n| State | Description | Behavior | Recovery Trigger |\n|-------|-------------|----------|------------------|\n| `HEALTHY` | Handler operating normally | Process all log records immediately | N/A - default state |\n| `DEGRADED` | Experiencing intermittent failures | Process records with retry logic | Successful operation after failure |\n| `FAILED` | Consecutive failures exceeded threshold | Drop records or queue for later | Manual reset or timeout period |\n| `RECOVERING` | Attempting to return to service | Test with low-priority records first | Sustained successful operations |\n\n#### Failure Detection and Response\n\nThe logging system implements sophisticated failure detection that goes beyond simple exception catching. Different types of failures require different response strategies:\n\n| Failure Type | Detection Method | Immediate Response | Recovery Strategy |\n|--------------|------------------|-------------------|-------------------|\n| File System Full | `OSError` with `errno.ENOSPC` | Switch to console handler, emit warning | Monitor disk space, resume when available |\n| Permission Denied | `PermissionError` on file operations | Attempt alternative file location | Alert administrator, try alternative paths |\n| Network Timeout | Socket timeout during remote handler | Buffer records locally | Exponential backoff retry, eventual discard |\n| Serialization Error | JSON encoding exception | Log error record instead | Safe serialize with type conversion |\n\nThe **safe_call** function provides the foundation for handler isolation:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `func` | `Callable` | The handler function to execute safely |\n| `*args` | `Any` | Positional arguments for the handler function |\n| `default` | `Any` | Default return value if function fails |\n| `timeout` | `float` | Maximum execution time before considering failed |\n| `**kwargs` | `Any` | Keyword arguments for the handler function |\n\nWhen a handler fails, the system follows this recovery procedure:\n\n1. **Immediate Isolation**: The failing handler is marked as degraded and subsequent calls use defensive timeouts\n2. **Error Classification**: The exception type determines whether the failure is likely temporary or permanent\n3. **Alternative Routing**: If available, log records are routed to backup handlers of the same type\n4. **Graceful Degradation**: Critical system information is logged to console as a fallback\n5. **Recovery Monitoring**: Background health checks test handler availability without affecting main log flow\n6. **Automatic Restoration**: Successful operations gradually restore the handler to healthy status\n\n> The key insight is that logging failures should never propagate as exceptions to the calling application code. A failed log operation returns normally but may emit diagnostic information through alternative channels.\n\n#### Buffer Management for Failed Handlers\n\nWhen handlers fail, the system implements intelligent buffering to preserve critical log information without consuming unbounded memory:\n\n| Buffer Type | Capacity | Retention Policy | Flush Trigger |\n|-------------|----------|------------------|---------------|\n| `MEMORY_BUFFER` | 1000 records | FIFO replacement when full | Handler recovery |\n| `DISK_BUFFER` | 100MB files | Rotate when size limit reached | Handler recovery or manual flush |\n| `PRIORITY_BUFFER` | 100 ERROR/FATAL records | Never discard high-priority records | Handler recovery only |\n\n⚠️ **Pitfall: Unbounded Buffer Growth**\nA common mistake is buffering failed log records indefinitely, which leads to memory leaks during prolonged outages. Always implement size limits and explicit discard policies for buffered data.\n\n### Serialization Edge Cases\n\nStructured logging's reliance on JSON serialization introduces complex edge cases that can cause runtime failures. The system must handle non-serializable Python objects, circular references, deeply nested structures, and objects with dynamic or sensitive content gracefully.\n\n> **Decision: Safe Serialization with Fallback**\n> - **Context**: User code may pass any Python object as context, including non-serializable types\n> - **Options Considered**: Reject non-serializable objects, convert everything to strings, selective type conversion\n> - **Decision**: Implement custom JSON encoder with intelligent type conversion and circular reference detection\n> - **Rationale**: Preserves maximum information while ensuring JSON output is always valid\n> - **Consequences**: Requires custom encoder logic but provides robust handling of edge cases\n\n#### Non-Serializable Object Handling\n\nThe `SafeJSONEncoder` provides intelligent conversion for Python objects that don't have native JSON representations:\n\n| Object Type | Conversion Strategy | Example Input | Example Output |\n|-------------|-------------------|---------------|----------------|\n| `datetime` | ISO 8601 string conversion | `datetime(2023, 12, 25)` | `\"2023-12-25T00:00:00Z\"` |\n| `Decimal` | String conversion preserving precision | `Decimal(\"123.456\")` | `\"123.456\"` |\n| `UUID` | String conversion | `UUID('123e4567-e89b-12d3-a456-426614174000')` | `\"123e4567-e89b-12d3-a456-426614174000\"` |\n| `Exception` | Type and message extraction | `ValueError(\"Invalid input\")` | `{\"type\": \"ValueError\", \"message\": \"Invalid input\"}` |\n| `Custom Objects` | Repr string with type information | `MyClass(value=42)` | `{\"type\": \"MyClass\", \"repr\": \"MyClass(value=42)\"}` |\n\nThe serialization process follows a defensive strategy that prioritizes successful log output over perfect representation:\n\n1. **Primary Serialization Attempt**: Use standard JSON encoder for basic types (str, int, float, bool, list, dict)\n2. **Custom Type Conversion**: Apply type-specific converters for known problematic types like datetime and UUID\n3. **Repr Fallback**: For unknown custom objects, capture the string representation and type information\n4. **Error Isolation**: If individual fields fail serialization, replace with error markers rather than failing entire record\n5. **Size Estimation**: Before full serialization, estimate the output size to prevent memory exhaustion\n\n#### Circular Reference Protection\n\nCircular references occur when objects contain references to themselves, either directly or through a chain of references. Without protection, JSON serialization would enter infinite loops and eventually crash with stack overflow errors.\n\nThe **safe_serialize** function implements circular reference detection using a tracking set:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `data` | `Any` | The object to serialize, typically a dictionary |\n| `max_depth` | `int` | Maximum nesting depth before truncation (default: 10) |\n| `seen_objects` | `Set[int]` | Set of object IDs already being processed |\n| `current_depth` | `int` | Current recursion depth for stack protection |\n\nThe circular reference detection algorithm works as follows:\n\n1. **Object Identity Tracking**: For each object encountered, record its `id()` in the `seen_objects` set\n2. **Reference Check**: Before processing any object, check if its ID is already in the tracking set\n3. **Circular Reference Marker**: If a circular reference is detected, replace with a marker: `{\"_circular_ref\": \"object_type_at_depth_N\"}`\n4. **Depth Limiting**: Even without circular references, stop recursion at maximum depth to prevent stack overflow\n5. **Cleanup**: Remove object IDs from tracking set when exiting their scope to allow repeated references\n\n#### Large Object Handling\n\nLarge objects in logging context can consume excessive memory and make log records unreadable. The system implements size-based truncation and sampling strategies:\n\n| Size Threshold | Handling Strategy | Example |\n|---------------|------------------|---------|\n| < 1KB | Serialize completely | Small dictionaries, short strings |\n| 1KB - 10KB | Serialize with truncation warning | Medium configuration objects |\n| 10KB - 100KB | Serialize keys only, with size information | Large data structures |\n| > 100KB | Replace with summary metadata | Database query results, file contents |\n\nThe **estimate_serialized_size** function provides efficient size estimation without full serialization:\n\n1. **Type-Based Estimation**: Use heuristics for common types (strings: byte length, lists: sum of elements, etc.)\n2. **Sampling**: For large containers, sample first N elements and extrapolate total size\n3. **Early Termination**: Stop estimation when size threshold is clearly exceeded\n4. **Memory Protection**: Never allocate memory proportional to estimated size during estimation\n\n⚠️ **Pitfall: Sensitive Data in Logs**\nAlways implement field filtering for sensitive information like passwords, tokens, and personal data. Consider using a configurable blacklist of field names that should be redacted during serialization.\n\n#### Encoding Error Recovery\n\nWhen serialization fails despite all protective measures, the system implements progressive degradation:\n\n1. **Field-Level Recovery**: If individual context fields fail, replace them with error descriptions and continue\n2. **Message Preservation**: Always preserve the primary log message, even if all context fails serialization\n3. **Diagnostic Information**: Include serialization error details in a special `_serialization_errors` field\n4. **Raw Fallback**: As a last resort, convert the entire context to a string representation\n5. **Error Logging**: Use a separate error channel to log serialization failures for debugging\n\n### Context Cleanup and Memory Management\n\nContext management in a structured logging system introduces subtle memory management challenges, particularly in long-running services with high request volumes. Without proper cleanup, context objects can accumulate indefinitely, leading to memory leaks and degraded performance.\n\n> **Decision: Scoped Context with Automatic Cleanup**\n> - **Context**: Context objects must be cleaned up when requests complete, but manual cleanup is error-prone\n> - **Options Considered**: Manual cleanup in application code, reference counting, scoped context managers\n> - **Decision**: Implement context managers with automatic cleanup and weak references for orphan detection\n> - **Rationale**: Reduces developer burden while providing deterministic cleanup semantics\n> - **Consequences**: Requires careful design of context inheritance and async context bridging\n\n#### Context Lifecycle Management\n\nThe logging context follows a strict lifecycle that ensures proper resource management across different execution models:\n\n| Lifecycle Phase | Thread-Local Context | Async Context | Cleanup Actions |\n|-----------------|---------------------|---------------|-----------------|\n| **Creation** | Store in `threading.local` | Set `contextvars.ContextVar` | Initialize parent reference |\n| **Inheritance** | Copy parent context to child | `contextvars.copy_context()` | Establish parent-child relationship |\n| **Modification** | Update thread-local storage | Create new context with changes | Preserve immutability of parent |\n| **Propagation** | Manual passing between threads | Automatic with async tasks | Sync both storage mechanisms |\n| **Cleanup** | Clear on request completion | Automatic scope exit | Remove circular references |\n\nThe dual storage strategy ensures context availability regardless of execution model:\n\n| Storage Type | Use Case | Advantages | Limitations |\n|--------------|----------|------------|-------------|\n| `threading.local` | Synchronous request processing | Simple access, no parameter passing | Manual cleanup required |\n| `contextvars.ContextVar` | Async/await operations | Automatic task isolation | Python 3.7+ only |\n| **Hybrid Approach** | Mixed sync/async applications | Best of both worlds | Requires synchronization logic |\n\n#### Memory Leak Prevention\n\nContext objects can cause memory leaks through several mechanisms that require active prevention:\n\n**Circular Reference Prevention:**\n1. **Weak Parent References**: Child contexts hold weak references to parents to break reference cycles\n2. **Context Isolation**: Changes in child contexts create new objects rather than modifying parents\n3. **Explicit Cleanup**: Context managers ensure deterministic cleanup even when exceptions occur\n4. **Orphan Detection**: Background monitoring identifies contexts that haven't been properly cleaned up\n\n**Context Size Management:**\nThe system implements several strategies to prevent context objects from growing unboundedly:\n\n| Strategy | Implementation | Trigger | Action |\n|----------|----------------|---------|--------|\n| **Field Count Limit** | Maximum 50 context fields | On context modification | Remove oldest fields (LRU) |\n| **Value Size Limit** | Maximum 1KB per field value | On field assignment | Truncate with warning marker |\n| **Total Size Limit** | Maximum 10KB per context | On context serialization | Summarize large fields |\n| **Depth Limit** | Maximum 10 inheritance levels | On child context creation | Flatten inheritance chain |\n\n⚠️ **Pitfall: Context Accumulation in Long-Running Tasks**\nIn long-running background tasks, context fields can accumulate over time if not properly scoped. Always use context managers or explicit cleanup in loops and long-running operations.\n\n#### Async Context Bridge Implementation\n\nThe async context bridge ensures that logging context is preserved across async/await boundaries, which is critical for maintaining request tracing in async applications:\n\n| Component | Responsibility | Implementation Strategy |\n|-----------|----------------|------------------------|\n| `AsyncContextManager` | Preserve context across await points | Copy context before async operations |\n| `TaskContextPropagator` | Inject context into new tasks | Wrap task functions with context restoration |\n| `CoroutineContextWrapper` | Maintain context in coroutines | Use `contextvars` for automatic propagation |\n\nThe context preservation algorithm for async operations:\n\n1. **Pre-Async Capture**: Before any async operation, capture the current context from both storage mechanisms\n2. **Context Packaging**: Create a context snapshot that includes all current fields and correlation IDs\n3. **Async Task Wrapping**: Wrap the async function to restore context when the task begins execution\n4. **Context Restoration**: When the async task starts, restore the captured context to both storage types\n5. **Cleanup Registration**: Register cleanup callbacks to clear context when the task completes\n6. **Exception Handling**: Ensure context cleanup occurs even when async operations raise exceptions\n\n#### Context Memory Monitoring\n\nThe system provides monitoring and debugging capabilities for context memory usage:\n\n| Metric | Collection Method | Purpose |\n|--------|------------------|---------|\n| `active_context_count` | Track context creation/destruction | Detect context leaks |\n| `average_context_size` | Measure serialized context size | Identify oversized contexts |\n| `context_inheritance_depth` | Track parent-child relationships | Prevent deep inheritance chains |\n| `cleanup_failure_count` | Count failed cleanup operations | Monitor cleanup effectiveness |\n\n**Context Debugging Tools:**\n\n1. **Context Dump**: Function to serialize and display all active contexts for debugging\n2. **Leak Detection**: Periodic scanning for contexts that haven't been accessed recently\n3. **Size Analysis**: Breakdown of context memory usage by field type and size\n4. **Inheritance Visualization**: Display parent-child relationships for complex context hierarchies\n\nThe context cleanup process implements several safety mechanisms:\n\n1. **Timeout-Based Cleanup**: Contexts older than a configured age are automatically cleaned up\n2. **Reference Counting**: Track how many active operations reference each context\n3. **Graceful Degradation**: If cleanup fails, mark contexts as stale rather than leaving them indefinitely\n4. **Background Monitoring**: Separate thread monitors context health and performs maintenance\n5. **Emergency Cleanup**: When memory pressure is detected, aggressively clean up non-essential contexts\n\n> The fundamental principle is that context management should be invisible to application developers while providing robust memory management and debugging capabilities for production operations.\n\n![Handler Dispatch Sequence](./diagrams/handler-dispatch-sequence.svg)\n\n### Common Pitfalls in Error Handling\n\n⚠️ **Pitfall: Logging Errors That Break Application Flow**\nThe most critical mistake is allowing logging operations to throw exceptions that propagate to application code. Always wrap logging operations in try-catch blocks and provide default behaviors for all failure scenarios.\n\n⚠️ **Pitfall: Synchronous I/O in High-Performance Paths**\nUsing synchronous file or network I/O for logging in request processing threads can significantly impact application performance. Consider async handlers or background thread dispatching for high-throughput scenarios.\n\n⚠️ **Pitfall: Retrying Failed Operations Indefinitely**\nWithout proper backoff and circuit breaking, failed log handlers can consume CPU and network resources indefinitely. Implement exponential backoff and maximum retry limits.\n\n⚠️ **Pitfall: Ignoring Handler Configuration Validation**\nInvalid handler configurations (non-existent file paths, invalid network addresses) should be detected at startup rather than causing runtime failures. Implement configuration validation during logger initialization.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Error Recovery | Basic try/except with logging | Circuit breaker pattern with metrics |\n| Serialization | Custom JSON encoder | Protocol Buffers with fallback |\n| Context Storage | Threading.local only | Hybrid threading.local + contextvars |\n| Buffer Management | In-memory lists | Persistent disk-backed queues |\n| Monitoring | Simple counters | Prometheus metrics with alerting |\n\n#### Infrastructure Starter Code\n\n```python\nimport json\nimport threading\nimport time\nimport weakref\nfrom typing import Any, Dict, List, Optional, Set, Union\nfrom collections import deque\nfrom enum import Enum\nimport contextvars\n\nclass HandlerState(Enum):\n    HEALTHY = \"healthy\"\n    DEGRADED = \"degraded\"\n    FAILED = \"failed\"\n    RECOVERING = \"recovering\"\n\nclass SafeJSONEncoder(json.JSONEncoder):\n    \"\"\"Custom JSON encoder that handles non-serializable objects gracefully.\"\"\"\n    \n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._seen_objects = set()\n        self._current_depth = 0\n        self.max_depth = kwargs.get('max_depth', MAX_DEPTH)\n    \n    def default(self, obj):\n        # TODO: Implement type-specific conversion for datetime, UUID, Decimal, Exception\n        # TODO: Add circular reference detection using object id tracking\n        # TODO: Implement depth limiting to prevent stack overflow\n        # TODO: Add fallback string conversion for unknown types\n        pass\n\nclass ThreadSafeCounter:\n    \"\"\"Thread-safe counter for tracking handler failures.\"\"\"\n    \n    def __init__(self, initial_value: int = 0):\n        self._value = initial_value\n        self._lock = threading.Lock()\n    \n    def increment(self) -> int:\n        with self._lock:\n            self._value += 1\n            return self._value\n    \n    def reset(self) -> None:\n        with self._lock:\n            self._value = 0\n    \n    @property\n    def value(self) -> int:\n        with self._lock:\n            return self._value\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker for handler failure isolation.\"\"\"\n    \n    def __init__(self, failure_threshold: int = 5, timeout_seconds: float = 60.0):\n        self.failure_threshold = failure_threshold\n        self.timeout_seconds = timeout_seconds\n        self._failure_count = ThreadSafeCounter()\n        self._last_failure_time = None\n        self._state = HandlerState.HEALTHY\n        self._lock = threading.RLock()\n    \n    def call(self, func, *args, **kwargs):\n        # TODO: Check circuit breaker state before allowing call\n        # TODO: Execute function and handle success/failure\n        # TODO: Update failure count and state based on result\n        # TODO: Implement timeout logic for failed state recovery\n        pass\n\nclass ContextBuffer:\n    \"\"\"Memory-managed buffer for failed log records.\"\"\"\n    \n    def __init__(self, max_size: int = 1000, max_memory_mb: int = 10):\n        self.max_size = max_size\n        self.max_memory_bytes = max_memory_mb * 1024 * 1024\n        self._buffer = deque()\n        self._current_memory = 0\n        self._lock = threading.RLock()\n    \n    def add_record(self, record: 'LogRecord') -> bool:\n        # TODO: Estimate record memory size\n        # TODO: Check if adding record would exceed limits\n        # TODO: Remove old records if necessary (FIFO)\n        # TODO: Add record to buffer and update memory tracking\n        pass\n    \n    def flush_to_handler(self, handler: 'Handler') -> int:\n        # TODO: Attempt to send buffered records to recovered handler\n        # TODO: Remove successfully sent records from buffer\n        # TODO: Return count of successfully flushed records\n        pass\n\ndef safe_serialize(data: Any, max_depth: int = MAX_DEPTH) -> str:\n    \"\"\"Serialize data to JSON with circular reference and size protection.\"\"\"\n    # TODO: Create SafeJSONEncoder instance with depth limit\n    # TODO: Implement size estimation before full serialization\n    # TODO: Handle serialization exceptions gracefully\n    # TODO: Return valid JSON string even on partial failures\n    pass\n\ndef estimate_serialized_size(data: Any) -> int:\n    \"\"\"Estimate JSON serialization size without full serialization.\"\"\"\n    # TODO: Implement type-based size estimation\n    # TODO: Sample large containers to avoid O(n) computation\n    # TODO: Return conservative size estimate in bytes\n    pass\n\ndef safe_call(func, *args, default=None, timeout=DEFAULT_TIMEOUT, **kwargs):\n    \"\"\"Safely execute function with timeout and exception handling.\"\"\"\n    # TODO: Implement timeout mechanism using threading.Timer or signal\n    # TODO: Catch and log exceptions without propagating\n    # TODO: Return default value on failure or timeout\n    # TODO: Log diagnostic information about failures\n    pass\n```\n\n#### Core Error Handling Skeleton\n\n```python\nclass BaseHandler:\n    \"\"\"Base class for all log output handlers with error recovery.\"\"\"\n    \n    def __init__(self, name: str):\n        self.name = name\n        self._circuit_breaker = CircuitBreaker()\n        self._buffer = ContextBuffer()\n        self._state = HandlerState.HEALTHY\n        self._last_success_time = time.time()\n    \n    def handle(self, record: LogRecord) -> bool:\n        # TODO 1: Check circuit breaker state - return False if failed\n        # TODO 2: Attempt to send record using _write_record method\n        # TODO 3: Handle success case - update circuit breaker, flush buffer\n        # TODO 4: Handle failure case - add to buffer, update circuit breaker\n        # TODO 5: Return True if handled (success or buffered), False if dropped\n        pass\n    \n    def _write_record(self, record: LogRecord) -> None:\n        # TODO: Subclasses implement actual output logic here\n        # This method should raise exceptions for failures\n        raise NotImplementedError(\"Subclasses must implement _write_record\")\n    \n    def recover(self) -> bool:\n        # TODO 1: Test handler availability with a dummy record\n        # TODO 2: If successful, attempt to flush buffered records\n        # TODO 3: Update handler state based on recovery success\n        # TODO 4: Return True if handler is now operational\n        pass\n\nclass FileHandler(BaseHandler):\n    \"\"\"File output handler with disk space and permission error handling.\"\"\"\n    \n    def __init__(self, file_path: str):\n        super().__init__(f\"file:{file_path}\")\n        self.file_path = file_path\n        self._file_handle = None\n    \n    def _write_record(self, record: LogRecord) -> None:\n        # TODO 1: Check if file handle is open, open if necessary\n        # TODO 2: Format record using configured formatter\n        # TODO 3: Write formatted record to file\n        # TODO 4: Flush to ensure data is written (consider sync vs async)\n        # TODO 5: Handle specific errors: disk full, permission denied, etc.\n        pass\n\nclass ContextStorage:\n    \"\"\"Dual storage for thread-local and async context.\"\"\"\n    \n    def __init__(self):\n        self._thread_local = threading.local()\n        self._async_var = contextvars.ContextVar('logging_context', default={})\n        self._active_contexts = weakref.WeakSet()\n        self._lock = threading.RLock()\n    \n    def get_current(self) -> Dict[str, Any]:\n        # TODO 1: Try to get context from async storage (contextvars)\n        # TODO 2: Fall back to thread-local storage if async not available\n        # TODO 3: Return empty dict if no context is set\n        # TODO 4: Track context access for monitoring\n        pass\n    \n    def set_current(self, context: Dict[str, Any]) -> None:\n        # TODO 1: Validate context size and field count limits\n        # TODO 2: Set context in both storage mechanisms\n        # TODO 3: Register context for cleanup monitoring\n        # TODO 4: Handle storage failures gracefully\n        pass\n    \n    def cleanup_orphaned_contexts(self) -> int:\n        # TODO 1: Identify contexts not accessed recently\n        # TODO 2: Check if contexts have active references\n        # TODO 3: Clean up orphaned contexts from storage\n        # TODO 4: Return count of cleaned up contexts for monitoring\n        pass\n\ndef preserve_context_async(coro):\n    \"\"\"Decorator to preserve logging context across async operations.\"\"\"\n    # TODO 1: Capture current context before async operation\n    # TODO 2: Create wrapper that restores context when async function starts\n    # TODO 3: Ensure context cleanup on async completion or exception\n    # TODO 4: Handle nested async calls and context inheritance\n    pass\n```\n\n#### Recommended File Structure\n\n```\nstructured_logging/\n  core/\n    __init__.py\n    logger.py                   ← Logger, LoggerRegistry\n    record.py                   ← LogRecord, LogLevel constants\n    handlers/\n      __init__.py\n      base.py                   ← BaseHandler, error recovery\n      file_handler.py           ← FileHandler with disk error handling\n      console_handler.py        ← ConsoleHandler with color/encoding errors\n      remote_handler.py         ← NetworkHandler with timeout/retry logic\n  formatters/\n    __init__.py\n    base.py                     ← BaseFormatter interface\n    json_formatter.py           ← JSONFormatter with SafeJSONEncoder\n    pretty_formatter.py         ← PrettyFormatter for development\n  context/\n    __init__.py\n    storage.py                  ← ContextStorage, cleanup logic\n    correlation.py              ← CorrelationIDGenerator\n    middleware.py               ← RequestContextMiddleware\n  utils/\n    __init__.py\n    serialization.py            ← safe_serialize, estimate_serialized_size\n    safety.py                   ← safe_call, CircuitBreaker\n    monitoring.py               ← Context monitoring and leak detection\n  tests/\n    test_error_handling.py      ← Handler failure scenarios\n    test_serialization.py       ← Edge case serialization tests\n    test_context_cleanup.py     ← Memory leak and cleanup tests\n```\n\n#### Milestone Checkpoints\n\n**Checkpoint 1: Handler Failure Recovery**\n```bash\n# Test file handler with disk full simulation\npython -m pytest tests/test_error_handling.py::test_file_handler_disk_full\n\n# Expected: Handler switches to degraded state, logs continue to console\n# Signs of issues: Exceptions propagate to application, logs are lost entirely\n```\n\n**Checkpoint 2: Serialization Edge Cases**\n```bash\n# Test circular reference handling\npython -c \"\nimport logging_system\nlogger = logging_system.get_logger('test')\nobj = {'self': None}\nobj['self'] = obj\nlogger.info('Test circular ref', context_obj=obj)\n\"\n\n# Expected: JSON output with circular reference marker\n# Signs of issues: RecursionError, stack overflow, or malformed JSON\n```\n\n**Checkpoint 3: Context Cleanup**\n```bash\n# Test context cleanup under load\npython tests/stress_test_context.py --requests=10000 --async-tasks=100\n\n# Expected: Stable memory usage, no growth over time\n# Signs of issues: Memory usage grows linearly, eventual OutOfMemoryError\n```\n\n#### Language-Specific Hints\n\n**Python Error Handling:**\n- Use `errno` module constants instead of hardcoded error codes: `errno.ENOSPC` for disk full\n- `threading.local()` provides thread-isolated storage for synchronous contexts\n- `contextvars.ContextVar` automatically handles async context isolation in Python 3.7+\n- Use `weakref.WeakSet()` to track context objects without preventing garbage collection\n- `json.JSONEncoder.default()` method is the proper override point for custom serialization\n\n**Memory Management:**\n- `sys.getsizeof()` provides memory size estimation for Python objects\n- `gc.collect()` can be called explicitly when cleaning up large numbers of contexts\n- Use `__slots__` in frequently created classes to reduce memory overhead\n- `deque` from collections provides efficient FIFO operations for buffering\n\n**Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Application crashes with JSON errors | Circular references in context | Add debug logging in SafeJSONEncoder | Implement proper circular reference detection |\n| Memory usage grows over time | Context objects not cleaned up | Monitor `_active_contexts` size | Add explicit cleanup in finally blocks |\n| Logs missing during high load | Handler failures not recovered | Check handler state and buffer sizes | Implement proper circuit breaker recovery |\n| Context not propagating to async tasks | Missing contextvars setup | Add trace logging in context bridge | Use `contextvars.copy_context()` correctly |\n| File handler stops working | Disk full or permission errors | Check handler error logs and disk space | Implement fallback handlers and monitoring |\n\n\n## Testing Strategy\n\n> **Milestone(s):** This section provides comprehensive testing patterns for all three milestones, with unit testing supporting individual component validation in Milestone 1 (Logger Core), integration scenarios verifying cross-component behavior in Milestone 2 (Structured Output), and end-to-end testing ensuring complete system functionality in Milestone 3 (Context & Correlation).\n\nThink of testing a structured logging system like conducting a symphony orchestra rehearsal. Just as a conductor must verify that individual musicians can play their parts correctly (unit testing), that sections can harmonize together (integration testing), and that the complete orchestra produces the intended musical experience (end-to-end testing), our logging system requires systematic validation at multiple levels. Each test layer reveals different types of issues: unit tests catch logic errors in individual components, integration tests expose interaction problems between subsystems, and milestone checkpoints verify that the complete system meets production requirements.\n\nThe testing strategy for a production-grade logging system presents unique challenges compared to typical application testing. Logging systems must handle concurrent access from multiple threads, preserve context across asynchronous boundaries, and maintain performance under heavy load while gracefully degrading when output destinations fail. Traditional testing approaches often miss these concerns because they focus on single-threaded, synchronous execution paths. Our comprehensive testing strategy addresses these real-world complexities by systematically validating thread safety, async context preservation, error recovery, and performance characteristics.\n\n### Unit Testing Approach\n\nUnit testing for structured logging components requires isolation of individual subsystems while simulating the complex interactions they will encounter in production. Unlike typical business logic testing, logging component tests must verify thread safety guarantees, memory management correctness, and graceful handling of malformed data. Each component operates within strict performance constraints since logging should never become the bottleneck in application execution.\n\nThe **formatter testing strategy** focuses on serialization correctness under edge cases that commonly break JSON output in production systems. Formatters must handle circular references, non-serializable objects, extremely large data structures, and malformed Unicode strings without throwing exceptions that could crash the application. Test cases should include deeply nested objects that exceed the maximum serialization depth, objects containing datetime instances and custom classes, dictionaries with non-string keys, and data structures containing binary data or control characters.\n\n| Test Category | Input Type | Expected Behavior | Failure Mode to Verify |\n|---------------|-----------|------------------|------------------------|\n| Circular References | Object referencing itself | Truncated serialization with warning | Infinite recursion crash |\n| Non-Serializable Objects | Custom class instances | String representation fallback | JSON serialization exception |\n| Maximum Depth Exceeded | Nested dict 20 levels deep | Truncation at MAX_DEPTH=10 | Stack overflow from recursion |\n| Large Data Structures | Dict with 10,000 key-value pairs | Size estimation and truncation | Memory exhaustion or timeout |\n| Unicode Edge Cases | Strings with control characters | Escaped JSON output | Malformed JSON structure |\n| Binary Data | Byte arrays in context fields | Base64 encoding or hex representation | Encoding errors |\n\nThe `JSONFormatter` testing requires verification that output always produces valid single-line JSON regardless of input complexity. Test the `safe_serialize` method with objects containing functions, lambda expressions, open file handles, and thread locks. Verify that the `estimate_serialized_size` function accurately predicts memory usage before full serialization to prevent memory exhaustion attacks. Test timestamp formatting with various precision levels and timezone configurations.\n\n**Handler testing strategy** emphasizes failure isolation and recovery behavior since handlers represent external dependencies that will inevitably fail in production. Each handler type requires different failure simulation techniques. File handlers need tests for filesystem permission errors, disk space exhaustion, and network filesystem disconnections. Network handlers require simulation of connection timeouts, DNS resolution failures, and temporary service unavailability.\n\n| Handler Type | Failure Scenarios | Recovery Verification | Buffer Behavior |\n|--------------|------------------|---------------------|-----------------|\n| FileHandler | Permission denied, disk full | Automatic retry with backoff | Buffer records until disk space available |\n| NetworkHandler | Connection timeout, DNS failure | Circuit breaker activation | Queue records for batch retry |\n| StdoutHandler | Broken pipe, process termination | Graceful degradation | Immediate failure, no buffering |\n| RemoteHandler | Service unavailable, auth failure | Exponential backoff retry | Persistent queue with size limits |\n\nThe `CircuitBreaker` component requires time-based testing that verifies state transitions occur at the correct intervals. Mock the system clock to control timeout behavior and verify that the circuit breaker correctly transitions from HEALTHY to DEGRADED to FAILED states based on consecutive failure counts. Test the recovery mechanism by simulating successful operations after the timeout period expires.\n\n**Context management testing** focuses on thread safety and memory leak prevention since context storage maintains state that could accumulate indefinitely. The `ContextStorage` component must handle concurrent access from multiple threads while preserving isolation between different execution contexts. Test scenarios should include rapid context creation and cleanup, nested context inheritance, and cleanup of orphaned contexts when threads terminate unexpectedly.\n\n| Test Scenario | Thread Pattern | Context Behavior | Memory Verification |\n|---------------|---------------|------------------|-------------------|\n| Concurrent Context Creation | 50 threads creating contexts simultaneously | No data corruption or lost updates | All contexts properly isolated |\n| Nested Context Inheritance | Parent context with 5 levels of children | Child inherits all parent fields | Changes in children don't affect parents |\n| Orphaned Context Cleanup | Thread exits without calling clear() | Automatic cleanup after timeout | No memory leaks detected |\n| Context Size Limits | Context with 1MB of data | Truncation to prevent memory issues | Graceful size limiting |\n\nThe `ThreadSafeCounter` and `ThreadSafeDict` utility classes require stress testing under high concurrency to verify that lock contention doesn't create deadlocks or performance bottlenecks. Use property-based testing to generate random sequences of operations and verify that the final state matches expected results.\n\n**Logger hierarchy testing** verifies that configuration inheritance and level filtering work correctly across complex parent-child relationships. Create logger hierarchies with multiple levels and verify that level changes propagate to children, context inheritance works correctly, and handler collection follows the expected traversal order.\n\n| Hierarchy Pattern | Level Configuration | Expected Behavior | Edge Case |\n|------------------|-------------------|------------------|-----------|\n| Root → App → Module | Root: INFO, App: DEBUG, Module: unset | Module effective level = DEBUG | Level inheritance through chain |\n| Root → Service1/Service2 | Root: WARN, Services: unset | Both services inherit WARN | Sibling isolation |\n| Deep Nesting (5 levels) | Alternating DEBUG/INFO levels | Correct effective level calculation | Performance of level resolution |\n| Handler Propagation | Handlers at root and middle levels | Records reach all applicable handlers | No duplicate output |\n\n⚠️ **Pitfall: Incomplete Thread Safety Testing**\nMany developers test thread safety by running multi-threaded code and checking for obvious crashes, but this misses subtle race conditions that only appear under specific timing conditions. Race conditions in logging systems can cause corrupted log output, lost log records, or deadlocks that freeze the entire application. Instead of just running concurrent code, use tools like Python's `threading.Barrier` to synchronize thread execution and force specific interleavings. Test with thread counts that exceed CPU core counts to verify behavior under thread starvation.\n\n### Integration Testing Scenarios\n\nIntegration testing for structured logging systems must verify that component interactions work correctly under realistic production conditions. Unlike unit tests that isolate individual components, integration tests exercise complete workflows that span multiple subsystems and expose emergent behaviors that only appear when components interact.\n\n**Multi-threaded logging integration** represents one of the most critical test scenarios since logging systems must handle concurrent access from web server request handlers, background processing tasks, and periodic maintenance jobs simultaneously. The integration test creates a realistic multi-threaded environment that simulates actual application patterns rather than artificial concurrent access.\n\nThe test scenario establishes multiple thread pools representing different application subsystems: web request handlers generating high-frequency INFO and DEBUG messages with request context, background task processors generating periodic WARN and ERROR messages with job context, and system monitoring threads generating FATAL messages during simulated failures. Each thread type uses different loggers in the hierarchy and attaches different context fields to verify that the system correctly isolates and routes messages.\n\n| Thread Type | Message Frequency | Log Levels | Context Fields | Handler Destinations |\n|-------------|------------------|------------|----------------|-------------------|\n| Web Requests | 100 messages/second | DEBUG, INFO | request_id, user_id, endpoint | stdout, file, metrics |\n| Background Tasks | 10 messages/second | INFO, WARN | job_id, task_type, duration | file, remote collector |\n| System Monitor | 1 message/second | ERROR, FATAL | component, health_status | file, alerting system |\n| Maintenance Jobs | 0.1 messages/second | DEBUG, INFO | job_name, resource_usage | file only |\n\nThe integration test runs for a sustained period (60 seconds minimum) while monitoring for several failure modes. Output file corruption indicates insufficient locking around file writes. Missing log records suggest race conditions in handler dispatch. Incorrect context propagation shows thread-local storage issues. Memory leaks indicate improper cleanup of thread-specific context storage.\n\nVerification requires parsing output files to confirm that all expected log records were written correctly, context fields are properly isolated between threads, timestamps show realistic ordering within reasonable bounds, and no partial JSON records appear in the output. Memory monitoring should show stable memory usage without continuous growth that would indicate context leaks.\n\n**Async context preservation integration** tests the most complex aspect of modern logging systems: maintaining request context across asynchronous task boundaries. Python's asyncio, JavaScript's Promise chains, and similar async frameworks create execution contexts that don't follow traditional thread-local storage patterns. The logging system must preserve context when tasks are created, paused, resumed, and completed.\n\nThe integration test creates a realistic async web application scenario with nested async operations that simulate database queries, external API calls, and background processing. Each operation should inherit context from its parent and add its own contextual information without affecting sibling operations or the parent context.\n\n```\nRequest Handler (correlation_id=123, user_id=456)\n├── Database Query (operation=user_lookup, table=users)\n├── External API Call (service=auth, endpoint=/validate)\n└── Background Task (task=audit_log, priority=low)\n    ├── Database Write (operation=insert, table=audit)\n    └── Cache Update (operation=invalidate, key=user:456)\n```\n\nEach async operation writes log messages at different points in its execution lifecycle: before starting the operation, during processing, and after completion. The test verifies that context propagation works correctly across await boundaries, context isolation prevents interference between concurrent tasks, nested operations inherit parent context correctly, and context cleanup occurs when tasks complete or fail.\n\n| Async Pattern | Context Behavior | Test Verification | Common Failure |\n|---------------|------------------|------------------|----------------|\n| Sequential await | Context preserved across each await | All messages contain full context chain | Context lost after first await |\n| Concurrent tasks | Independent context for each task | No context bleeding between tasks | Shared mutable context state |\n| Nested async calls | Child inherits parent + adds own fields | Proper context hierarchy in logs | Child modifications affect parent |\n| Exception handling | Context preserved through exception unwinding | Error logs contain full request context | Context cleared on exception |\n\n**End-to-end request tracing integration** demonstrates the complete correlation ID lifecycle from request ingress through all internal operations to final response. This test simulates a realistic microservice interaction where a user request triggers operations across multiple internal services, each adding their own contextual information while preserving the original correlation ID.\n\nThe test creates a mock web application with request middleware that extracts or generates correlation IDs, establishes request-scoped context, and ensures cleanup when requests complete. Multiple request handlers simulate different application endpoints with varying complexity: simple operations that complete synchronously, complex operations that spawn multiple async tasks, and error scenarios that require proper context preservation during exception handling.\n\n| Request Type | Operations Triggered | Expected Context Fields | Correlation Tracking |\n|--------------|-------------------|----------------------|-------------------|\n| User Login | Auth service, user lookup, session creation | correlation_id, user_id, client_ip, user_agent | Single ID through all operations |\n| Data Query | Query parser, database, result formatter | correlation_id, query_id, table, execution_time | Nested operation IDs |\n| File Upload | Validation, storage, thumbnail generation | correlation_id, file_id, size, processing_status | Background task correlation |\n| Error Scenario | Failed validation, error logging, cleanup | correlation_id, error_code, failed_operation | Error context preservation |\n\nThe integration test sends concurrent requests with different correlation ID patterns: requests with existing correlation IDs from upstream services, requests without correlation IDs that require generation, and requests with malformed correlation IDs that need sanitization. The test verifies that correlation IDs are properly preserved across all async operations, each request maintains independent context isolation, background tasks spawned by requests maintain correlation linkage, and error scenarios preserve context for debugging.\n\nVerification involves parsing log output to construct correlation traces showing the complete lifecycle of each request. Each correlation ID should appear in log records from request start to completion, with proper nesting of operation-specific context and no correlation ID pollution between concurrent requests.\n\n⚠️ **Pitfall: Unrealistic Test Conditions**\nMany integration tests use artificial scenarios that don't reflect production behavior, such as perfect network conditions, unlimited memory, and immediate I/O operations. Real production environments have variable latency, intermittent failures, and resource constraints that can expose bugs not visible in idealized test conditions. Include realistic failure injection in integration tests: introduce random network delays for remote handlers, simulate disk pressure that slows file I/O, and test under memory pressure that triggers garbage collection pauses.\n\n### Milestone Checkpoints\n\nMilestone checkpoints provide concrete verification criteria for each stage of system implementation, ensuring that learners build foundational capabilities correctly before advancing to more complex features. Each checkpoint includes specific behavioral requirements, observable outputs, and diagnostic techniques for identifying common implementation errors.\n\n**Milestone 1 Checkpoint: Logger Core**\nThe Logger Core milestone establishes the foundational logging infrastructure with proper level filtering, thread safety, and handler dispatch. The checkpoint verification ensures that these core capabilities work correctly under both normal operations and stress conditions.\n\nThe primary verification test creates multiple logger instances in a hierarchy and verifies that level filtering works correctly at each node. Create loggers for `root`, `app`, `app.database`, and `app.api` with different level configurations. Set the root logger to INFO, leave app unset (inheriting INFO), set app.database to DEBUG, and set app.api to WARN. Send messages at all log levels to each logger and verify that only appropriate messages appear in the output.\n\n| Logger Name | Configured Level | Effective Level | DEBUG Visible | INFO Visible | WARN Visible |\n|-------------|------------------|----------------|---------------|--------------|--------------|\n| root | INFO | INFO | No | Yes | Yes |\n| app | (unset) | INFO (inherited) | No | Yes | Yes |\n| app.database | DEBUG | DEBUG | Yes | Yes | Yes |\n| app.api | WARN | WARN | No | No | Yes |\n\nThread safety verification requires running the logging system under concurrent load while monitoring for output corruption. Create 10 threads that simultaneously write 1000 log messages each to the same logger instance. Each thread should use a unique thread identifier in its log messages. After completion, parse the output file and verify that all 10,000 messages are present, no partial messages appear (indicating corruption during writes), messages from different threads don't have interleaved content within single records, and thread identifiers are correctly preserved in each message.\n\nHandler dispatch verification tests that log records reach multiple output destinations correctly and that handler failures don't prevent delivery to other handlers. Configure a logger with three handlers: stdout, file, and a mock network handler that can be programmatically failed. Write log messages while the mock handler is healthy, then trigger a failure in the mock handler and continue writing messages. Verify that messages continue to reach stdout and file handlers despite the network handler failure.\n\n**Expected Behavior After Milestone 1:**\n- Logger creation: `get_logger(\"app.module\")` creates hierarchy automatically\n- Level filtering: Only messages at or above configured level appear in output\n- Thread safety: No output corruption under concurrent access from multiple threads\n- Handler dispatch: Messages reach all configured handlers, with graceful failure handling\n- Runtime reconfiguration: Level changes take effect immediately without restart\n\n**Diagnostic Commands for Milestone 1:**\n```bash\n# Test basic functionality\npython -c \"\nimport logging_system\nlogger = logging_system.get_logger('test')\nlogger.set_level(logging_system.INFO)\nlogger.debug('This should not appear')\nlogger.info('This should appear')\n\"\n\n# Test thread safety\npython test_thread_safety.py --threads=10 --messages=1000\n\n# Test handler dispatch\npython test_handlers.py --with-failure-simulation\n```\n\n**Milestone 2 Checkpoint: Structured Output**\nThe Structured Output milestone adds JSON formatting, timestamp handling, and custom formatter support. The checkpoint verification focuses on output format correctness and formatter extensibility.\n\nJSON format verification requires testing serialization behavior with complex data structures that commonly cause problems in production. Create log records with context containing nested dictionaries, arrays, datetime objects, and custom class instances. Verify that the JSON output is valid single-line JSON (no embedded newlines), contains all expected fields in consistent order, handles non-serializable objects gracefully with string representations, and includes properly formatted timestamps.\n\n| Context Data Type | Serialization Behavior | Expected JSON Output |\n|------------------|----------------------|-------------------|\n| Nested Dict (3 levels) | Full serialization | Complete nested structure |\n| Datetime Object | ISO 8601 conversion | \"2024-01-15T10:30:45.123Z\" |\n| Custom Class Instance | String representation | \"MyClass(id=123, name='test')\" |\n| Circular Reference | Truncation with warning | \"[Circular Reference Detected]\" |\n| Large Array (1000 items) | Size-based truncation | First N items + \"[...truncated]\" |\n\nTimestamp format verification tests that timestamps are generated correctly for different precision requirements and timezone configurations. Configure the timestamp formatter for ISO 8601 format and verify that all log records contain valid timestamps that are properly ordered chronologically. Test timezone handling by configuring UTC output and verifying that timestamps are consistent regardless of local system timezone.\n\nCustom formatter verification tests the plugin system by registering a test formatter that produces CSV output instead of JSON. Create a custom formatter that outputs log records in comma-separated format with quoted fields. Register the formatter with the system and configure a logger to use it. Verify that log messages are formatted correctly in CSV format and that multiple formatters can coexist without interference.\n\n**Expected Behavior After Milestone 2:**\n- JSON output: Valid single-line JSON for every log record\n- Timestamp formatting: Consistent ISO 8601 timestamps with millisecond precision\n- Custom formatters: Ability to register and use custom output formats\n- Pretty printing: Human-readable colored output for development console\n- Serialization safety: Graceful handling of non-serializable objects\n\n**Milestone 3 Checkpoint: Context & Correlation**\nThe Context & Correlation milestone adds request tracing, correlation ID generation, and context propagation across async boundaries. The checkpoint verification ensures that context is properly maintained throughout complex execution flows.\n\nCorrelation ID verification tests that unique identifiers are generated for each request and properly propagated through all operations. Create a mock request handler that generates a correlation ID and performs multiple nested operations: database query, external API call, and background task. Verify that all log records contain the same correlation ID, nested operations inherit the correlation ID correctly, concurrent requests have independent correlation IDs, and correlation IDs follow the expected format (service prefix + timestamp + random component).\n\n| Operation Type | Correlation ID Presence | Context Inheritance | Isolation Verification |\n|----------------|----------------------|-------------------|----------------------|\n| Request Start | New correlation ID generated | Initial request context | Independent from other requests |\n| Database Query | Same correlation ID | Request context + query metadata | No interference between queries |\n| API Call | Same correlation ID | Request context + API metadata | Async operation isolation |\n| Background Task | Same correlation ID | Request context + task metadata | Proper async context bridge |\n\nContext propagation verification tests that context fields are properly inherited and isolated across different scopes. Create nested context scopes where each level adds additional fields while preserving parent context. Verify that child contexts inherit all parent fields, child context modifications don't affect parent contexts, context cleanup occurs when scopes exit, and memory usage remains stable during context creation/cleanup cycles.\n\nAsync context preservation verification tests the most complex scenario: maintaining context across asyncio task boundaries. Create an async request handler that spawns multiple concurrent tasks, each performing operations that add context fields. Verify that each async task maintains its own context isolation, context is properly inherited when tasks are created, await boundaries preserve context correctly, and context cleanup occurs when async tasks complete.\n\n**Expected Behavior After Milestone 3:**\n- Correlation ID generation: Unique IDs for each request with proper format\n- Context propagation: Seamless context inheritance through nested function calls\n- Async context preservation: Correct context maintenance across await boundaries\n- Request middleware: Automatic context establishment for incoming requests\n- Memory management: No context leaks during long-running operations\n\n**Integration Verification Commands:**\n```bash\n# Test complete request flow\ncurl -H \"X-Correlation-ID: test-123\" http://localhost:8080/api/test\n# Verify logs show correlation ID throughout request processing\n\n# Test async context preservation\npython test_async_context.py --concurrent-requests=50\n\n# Test context isolation\npython test_context_isolation.py --nested-levels=5\n\n# Stress test complete system\npython stress_test.py --duration=300 --rps=100\n```\n\nThe milestone checkpoints provide a systematic progression that ensures each capability is solid before building additional complexity. This approach prevents the common problem of advanced features failing due to inadequate foundations, and provides clear diagnostic criteria when troubleshooting implementation issues.\n\n### Implementation Guidance\n\n**A. Technology Recommendations Table:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Unit Testing Framework | `unittest` (Python standard library) | `pytest` with fixtures and parameterization |\n| Thread Safety Testing | `threading.Thread` with manual synchronization | `concurrent.futures` with ThreadPoolExecutor |\n| Async Testing | `asyncio.run()` with manual event loop | `pytest-asyncio` with async test fixtures |\n| Mock Objects | `unittest.mock` for handler simulation | `responses` library for HTTP handler mocking |\n| Performance Testing | Manual timing with `time.time()` | `cProfile` and `memory_profiler` for detailed analysis |\n| Output Validation | String parsing with `json.loads()` | JSON Schema validation with `jsonschema` |\n| Concurrency Testing | Manual thread creation | Property-based testing with `hypothesis` |\n\n**B. Recommended File/Module Structure:**\n\n```\nstructured-logging/\n  src/logging_system/           ← main package\n    __init__.py\n    logger.py                   ← Logger, LoggerRegistry\n    handlers.py                 ← Handler implementations\n    formatters.py              ← JSON/Pretty formatters\n    context.py                 ← Context management\n  tests/                       ← test suite\n    unit/                      ← component isolation tests\n      test_logger.py           ← Logger hierarchy tests\n      test_handlers.py         ← Handler failure/recovery tests\n      test_formatters.py       ← Serialization edge cases\n      test_context.py          ← Context isolation tests\n    integration/               ← cross-component tests\n      test_threading.py        ← Multi-threaded scenarios\n      test_async.py           ← Async context preservation\n      test_end_to_end.py      ← Complete request tracing\n    checkpoints/              ← milestone verification\n      test_milestone1.py       ← Logger core verification\n      test_milestone2.py       ← Structured output verification  \n      test_milestone3.py       ← Context correlation verification\n    fixtures/                ← shared test utilities\n      mock_handlers.py         ← Controllable handler mocks\n      context_helpers.py       ← Context setup utilities\n      data_generators.py       ← Test data creation\n```\n\n**C. Infrastructure Starter Code:**\n\n```python\n# tests/fixtures/mock_handlers.py\n\"\"\"Mock handlers for controlled failure testing.\"\"\"\nimport threading\nimport time\nfrom typing import List, Optional\nfrom logging_system.handlers import BaseHandler\nfrom logging_system.data_model import LogRecord\n\nclass ControllableHandler(BaseHandler):\n    \"\"\"Handler with programmable failure behavior for testing.\"\"\"\n    \n    def __init__(self, name: str):\n        super().__init__(name)\n        self.records: List[LogRecord] = []\n        self.should_fail = False\n        self.failure_delay = 0.0\n        self.call_count = 0\n        self._lock = threading.RLock()\n    \n    def _write_record(self, record: LogRecord) -> None:\n        with self._lock:\n            self.call_count += 1\n            if self.should_fail:\n                if self.failure_delay > 0:\n                    time.sleep(self.failure_delay)\n                raise IOError(f\"Simulated failure in {self.name}\")\n            self.records.append(record)\n    \n    def simulate_failure(self, should_fail: bool, delay: float = 0.0):\n        \"\"\"Control handler failure behavior for testing.\"\"\"\n        with self._lock:\n            self.should_fail = should_fail\n            self.failure_delay = delay\n    \n    def get_records(self) -> List[LogRecord]:\n        \"\"\"Thread-safe access to captured records.\"\"\"\n        with self._lock:\n            return self.records.copy()\n    \n    def clear_records(self):\n        \"\"\"Reset captured records for next test.\"\"\"\n        with self._lock:\n            self.records.clear()\n            self.call_count = 0\n\n# tests/fixtures/data_generators.py\n\"\"\"Test data generators for edge case testing.\"\"\"\nimport datetime\nimport uuid\nfrom typing import Any, Dict, List\n\nclass CircularReferenceObject:\n    \"\"\"Object that references itself for serialization testing.\"\"\"\n    def __init__(self, name: str):\n        self.name = name\n        self.self_ref = self\n        self.nested = {'circular': self}\n\nclass NonSerializableObject:\n    \"\"\"Custom object that cannot be JSON serialized.\"\"\"\n    def __init__(self, value: Any):\n        self.value = value\n        self.function = lambda x: x * 2\n    \n    def __repr__(self):\n        return f\"NonSerializableObject({self.value})\"\n\ndef generate_complex_context() -> Dict[str, Any]:\n    \"\"\"Generate context with various data types for testing.\"\"\"\n    return {\n        'string_field': 'test_value',\n        'numeric_field': 42,\n        'datetime_field': datetime.datetime.now(),\n        'nested_dict': {\n            'level1': {'level2': {'level3': 'deep_value'}},\n            'array': [1, 2, 3, 'mixed', True]\n        },\n        'circular_ref': CircularReferenceObject('test'),\n        'non_serializable': NonSerializableObject(123),\n        'large_array': list(range(1000)),\n        'unicode_data': 'Special chars: 🚀 💡 ∑ ∆'\n    }\n\ndef generate_correlation_id() -> str:\n    \"\"\"Generate test correlation ID with realistic format.\"\"\"\n    return f\"test-{uuid.uuid4().hex[:8]}-{int(time.time())}\"\n```\n\n**D. Core Logic Skeleton Code:**\n\n```python\n# tests/unit/test_logger.py\n\"\"\"Unit tests for Logger hierarchy and level filtering.\"\"\"\nimport unittest\nimport threading\nimport time\nfrom logging_system import get_logger, LogLevel\nfrom tests.fixtures.mock_handlers import ControllableHandler\n\nclass TestLoggerCore(unittest.TestCase):\n    \"\"\"Test Logger hierarchy, level filtering, and thread safety.\"\"\"\n    \n    def test_level_filtering(self):\n        \"\"\"Verify that only messages at or above configured level are processed.\"\"\"\n        # TODO 1: Create logger with INFO level\n        # TODO 2: Attach mock handler to capture output\n        # TODO 3: Send DEBUG message - verify not processed\n        # TODO 4: Send INFO message - verify processed\n        # TODO 5: Send ERROR message - verify processed\n        # TODO 6: Change level to DEBUG - verify DEBUG now processed\n        pass\n    \n    def test_logger_hierarchy_inheritance(self):\n        \"\"\"Test that child loggers inherit configuration from parents.\"\"\"\n        # TODO 1: Create root logger with WARN level\n        # TODO 2: Create child logger 'app.database' - verify inherits WARN\n        # TODO 3: Set child to DEBUG - verify uses DEBUG, not inherited WARN\n        # TODO 4: Clear child level - verify inherits WARN again\n        # TODO 5: Test deep hierarchy: root.app.module.component\n        pass\n    \n    def test_thread_safety_concurrent_logging(self):\n        \"\"\"Verify no output corruption under concurrent access.\"\"\"\n        logger = get_logger('thread_test')\n        handler = ControllableHandler('test')\n        logger.add_handler(handler)\n        \n        def worker_thread(thread_id: int, message_count: int):\n            # TODO 1: Log message_count messages from this thread\n            # TODO 2: Include thread_id in each message for verification\n            # TODO 3: Use different log levels randomly\n            # TODO 4: Add context fields unique to this thread\n            pass\n        \n        # TODO 5: Start 10 worker threads with 100 messages each\n        # TODO 6: Wait for all threads to complete\n        # TODO 7: Verify all 1000 messages captured correctly\n        # TODO 8: Verify no message corruption (partial records)\n        # TODO 9: Verify thread isolation (no mixed content)\n        pass\n\n# tests/integration/test_async_context.py\n\"\"\"Integration tests for async context preservation.\"\"\"\nimport asyncio\nimport unittest\nfrom logging_system import get_logger, LoggingContext\nfrom tests.fixtures.mock_handlers import ControllableHandler\n\nclass TestAsyncContextPreservation(unittest.TestCase):\n    \"\"\"Test context preservation across async boundaries.\"\"\"\n    \n    async def test_async_context_inheritance(self):\n        \"\"\"Verify context preserved across await boundaries.\"\"\"\n        logger = get_logger('async_test')\n        handler = ControllableHandler('async')\n        logger.add_handler(handler)\n        \n        async def database_operation(user_id: int):\n            # TODO 1: Add database-specific context fields\n            # TODO 2: Log start of database operation\n            # TODO 3: Simulate async database call with asyncio.sleep()\n            # TODO 4: Log completion with query results\n            # TODO 5: Return operation results\n            pass\n        \n        async def api_request_handler(request_id: str, user_id: int):\n            # TODO 6: Set initial request context (correlation_id, user_id)\n            # TODO 7: Log request start\n            # TODO 8: Call database_operation - verify context preserved\n            # TODO 9: Log request completion with timing\n            pass\n        \n        # TODO 10: Run multiple concurrent requests\n        # TODO 11: Verify each request has independent context\n        # TODO 12: Verify nested operations inherit parent context\n        # TODO 13: Verify no context bleeding between requests\n        pass\n    \n    def test_concurrent_async_requests(self):\n        \"\"\"Test context isolation under concurrent async load.\"\"\"\n        # TODO 1: Create async request handlers with different correlation IDs\n        # TODO 2: Run 50 concurrent requests with unique context\n        # TODO 3: Each request spawns multiple async subtasks\n        # TODO 4: Verify correlation IDs properly isolated\n        # TODO 5: Verify no context pollution between requests\n        pass\n```\n\n**E. Language-Specific Hints:**\n\n- **Thread Safety**: Use `threading.RLock` for components that need recursive locking (loggers calling other loggers). Use `threading.Lock` for simple mutual exclusion in counters and caches.\n- **Async Context**: Use `contextvars.ContextVar` for async-local storage that preserves across await boundaries. Combine with `threading.local` for thread-local fallback.\n- **JSON Serialization**: Override `json.JSONEncoder.default()` method to handle non-serializable objects. Use `json.dumps(separators=(',', ':'))` for compact single-line output.\n- **File I/O Testing**: Use `tempfile.NamedTemporaryFile()` for isolated file handler testing. Call `file.flush()` and `os.fsync()` to ensure data written before verification.\n- **Memory Testing**: Use `tracemalloc.start()` to monitor memory usage during context lifecycle tests. Check for linear growth that indicates memory leaks.\n- **Time Mocking**: Use `unittest.mock.patch('time.time')` to control timestamp generation for deterministic testing.\n\n**F. Milestone Checkpoints:**\n\n**Checkpoint 1 - Logger Core Verification:**\n```bash\n# Run core logger tests\npython -m pytest tests/unit/test_logger.py -v\n\n# Expected output shows:\n# - test_level_filtering PASSED\n# - test_logger_hierarchy_inheritance PASSED  \n# - test_thread_safety_concurrent_logging PASSED\n# - No output corruption warnings\n# - All 1000 test messages captured correctly\n\n# Manual verification:\npython -c \"\nimport logging_system\nlogger = logging_system.get_logger('manual_test')\nlogger.set_level(logging_system.INFO)\nlogger.debug('Should not see this')\nlogger.info('Should see this')\n\"\n# Output should show only INFO message\n```\n\n**Checkpoint 2 - Structured Output Verification:**\n```bash\n# Test JSON formatting\npython -m pytest tests/unit/test_formatters.py -v\n\n# Verify JSON output format:\npython test_json_output.py\n# Should produce valid single-line JSON like:\n# {\"timestamp\":\"2024-01-15T10:30:45.123Z\",\"level\":20,\"message\":\"test\",\"logger_name\":\"test\",\"context\":{\"key\":\"value\"}}\n\n# Test custom formatter registration:\npython test_custom_formatter.py\n# Should show CSV output: 2024-01-15T10:30:45.123Z,INFO,test,test,\"key=value\"\n```\n\n**Checkpoint 3 - Context & Correlation Verification:**\n```bash\n# Test complete context flow\npython -m pytest tests/integration/test_end_to_end.py -v\n\n# Test request tracing:\npython simulate_request.py --correlation-id=test-123\n# All log output should contain: \"correlation_id\":\"test-123\"\n\n# Test async context preservation:\npython test_async_flow.py --concurrent-requests=10\n# Each request should maintain independent context throughout async operations\n```\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Thread safety test fails randomly | Race condition in handler dispatch | Add debug logging around lock acquisition | Use RLock instead of Lock for recursive calls |\n| Context not preserved across await | Missing contextvars setup | Check if ContextVar is properly copied | Use contextvars.copy_context() for task creation |\n| JSON output contains newlines | Embedded newlines in log messages | Search for \\n characters in test output | Strip newlines from message content before formatting |\n| Memory usage grows during tests | Context cleanup not called | Monitor context storage size during test | Add explicit cleanup in test teardown |\n| Async tests hang indefinitely | Deadlock in async context manager | Check for blocking operations in async code | Replace time.sleep() with asyncio.sleep() |\n| Handler dispatch fails silently | Exception swallowed in handler | Add try/catch logging around handler calls | Check handler circuit breaker state |\n| Correlation IDs not unique | Timestamp resolution too low | Print generated IDs to check for duplicates | Add random component to ID generation |\n| Context bleeds between threads | Shared mutable context objects | Verify each thread gets independent context | Use copy.deepcopy() when inheriting context |\n\n\n## Debugging Guide\n\n> **Milestone(s):** This section provides essential debugging patterns for all three milestones, with race condition debugging supporting Milestone 1 (Logger Core), serialization issue diagnosis supporting Milestone 2 (Structured Output), and context propagation debugging supporting Milestone 3 (Context & Correlation).\n\nThink of debugging a structured logging system like troubleshooting a complex telephone switchboard. When calls don't connect properly, the problem could be in the routing logic (level filtering), the switching mechanism (handler dispatch), the line quality (serialization), or the directory service (context propagation). Each type of failure has distinct symptoms, and skilled operators develop systematic approaches to isolate and resolve issues quickly.\n\nThe complexity of a production logging system creates multiple failure modes that can interact in subtle ways. A race condition in the logger hierarchy might only manifest under high concurrency, while context propagation issues may only appear in specific async execution patterns. Memory leaks can accumulate slowly until they cause cascading failures across the entire application. This debugging guide provides systematic approaches to identify, isolate, and resolve the most common issues learners encounter when implementing structured logging systems.\n\n### Common Implementation Pitfalls\n\nThe most frequent implementation mistakes in structured logging systems fall into four categories: concurrency issues that corrupt shared state, context management problems that lose request correlation, blocking operations that degrade performance, and resource management failures that cause memory leaks. Each category requires different debugging approaches and prevention strategies.\n\n#### Race Conditions in Logger Hierarchy\n\nRace conditions in logger hierarchy management represent one of the most subtle and dangerous pitfalls in structured logging implementation. The logger hierarchy is a shared data structure accessed concurrently by multiple threads, and improper synchronization can lead to corrupted state, lost configuration changes, or inconsistent behavior that only manifests under high load.\n\n⚠️ **Pitfall: Unsynchronized Logger Registry Access**\n\nThe most common race condition occurs when multiple threads simultaneously access the `LoggerRegistry._loggers` dictionary without proper locking. Consider a scenario where Thread A calls `get_logger(\"com.example.service\")` while Thread B calls `get_logger(\"com.example.service.auth\")`. Both threads may attempt to create parent loggers simultaneously, leading to duplicate entries, lost references, or partially initialized logger objects.\n\nThe symptom appears as intermittent failures where loggers seem to lose their configuration, handlers disappear randomly, or context fields vanish from log records. These issues are particularly insidious because they may not appear during development with single-threaded access patterns but emerge under production load.\n\nThe underlying problem is that dictionary operations in most languages are not atomic across multiple operations. Creating a logger hierarchy involves: checking if parent loggers exist, creating missing parents, establishing parent-child relationships, and updating the registry. Without proper synchronization, these operations can interleave in ways that corrupt the data structure.\n\n| Race Condition Scenario | Thread A Action | Thread B Action | Corruption Result |\n|-------------------------|-----------------|-----------------|-------------------|\n| Simultaneous parent creation | Creates `com.example` logger | Creates `com.example` logger | Duplicate parent with different configurations |\n| Hierarchy modification | Sets `com.example.service` level | Adds handler to `com.example.service` | Handler added to wrong logger instance |\n| Context inheritance | Modifies parent context | Reads child effective context | Child sees inconsistent parent context |\n| Level propagation | Changes parent level | Calculates child effective level | Child uses stale level cache |\n\nThe correct solution requires using a `RLock` (reader-writer lock) in the `LoggerRegistry` to protect all registry operations. Read operations like logger lookup can share the lock, while write operations like logger creation require exclusive access. Additionally, each individual `Logger` needs its own lock to protect configuration changes and context modifications.\n\n⚠️ **Pitfall: Level Cache Invalidation Race**\n\nAnother subtle race condition occurs in the effective level calculation system. The `Logger._effective_level` cache improves performance by avoiding repeated hierarchy traversal, but invalidating this cache safely across multiple threads requires careful coordination.\n\nWhen a parent logger's level changes, all descendant loggers must invalidate their cached effective levels. If this invalidation is not synchronized properly, a logger might use a stale cached level while its parent's configuration has changed, leading to incorrect level filtering behavior.\n\nThe symptom appears as messages that should be filtered continuing to appear, or messages that should be logged being incorrectly suppressed. The issue is timing-dependent and may only occur during configuration changes under load.\n\n⚠️ **Pitfall: Handler List Modification During Iteration**\n\nA particularly dangerous race condition occurs when one thread modifies a logger's handler list while another thread iterates over that list for message dispatch. This can cause handler dispatch to skip handlers, duplicate messages, or access deallocated handler objects leading to crashes.\n\nThe iteration happens in the `log()` method when collecting handlers from the logger hierarchy, while modification occurs when configuration changes add or remove handlers. Without proper synchronization, the iterator can become invalid mid-traversal.\n\n#### Context Propagation Failures\n\nContext propagation failures are among the most frustrating debugging challenges because they break the fundamental promise of structured logging: that related log entries can be correlated across service boundaries. When context propagation fails, correlation IDs disappear, request metadata is lost, and distributed tracing becomes impossible.\n\n⚠️ **Pitfall: Thread-Local Context Not Propagating to New Threads**\n\nThe most common context propagation failure occurs when application code creates new threads without explicitly propagating the logging context. Thread-local storage isolates context between threads by design, so newly created threads start with empty context even if the parent thread has rich contextual information.\n\nThis manifests as correlation IDs and request metadata suddenly disappearing from log entries generated by background tasks, worker threads, or async operations. The symptoms are subtle because the logging system continues to function correctly—it simply loses the contextual information that makes logs useful for debugging distributed systems.\n\nConsider a web request handler that spawns a background task to process uploaded data. The main request thread has correlation ID `req-12345` and user context `user_id: alice`, but the background thread starts with empty context. All log entries from the background processing lose this critical correlation information.\n\n| Context Propagation Scenario | Parent Thread Context | Child Thread Context | Impact |\n|------------------------------|----------------------|---------------------|---------|\n| Background task creation | `{\"correlation_id\": \"req-12345\", \"user_id\": \"alice\"}` | `{}` (empty) | Background processing logs cannot be correlated to original request |\n| Thread pool execution | `{\"request_id\": \"order-456\", \"operation\": \"checkout\"}` | Previous task's context | Worker thread sees stale context from previous task |\n| Async task spawning | `{\"trace_id\": \"abc123\", \"span_id\": \"def456\"}` | `{}` (empty) | Distributed tracing chain broken |\n\nThe solution requires explicitly capturing context from the parent thread and setting it in the child thread before any logging occurs. This can be automated through context-aware thread creation utilities or manual context transfer at task boundaries.\n\n⚠️ **Pitfall: Async Context Not Preserved Across Await Boundaries**\n\nIn async programming environments, context can be lost across `await` boundaries when the execution context switches between different async tasks or coroutines. This is particularly problematic in languages with cooperative multitasking where multiple async tasks share the same thread.\n\nThe symptom appears as correlation IDs and context fields randomly changing or disappearing in the middle of async function execution. A function might start with correlation ID `req-789` but after awaiting a database operation, find itself with a different correlation ID from another concurrent request.\n\nThis occurs because async runtimes may resume awaited tasks on different logical execution contexts, and the logging context storage mechanism fails to properly bridge these context switches. The issue is intermittent and load-dependent, making it particularly difficult to diagnose.\n\n⚠️ **Pitfall: Context Memory Leaks in Long-Running Services**\n\nContext storage systems that don't properly clean up unused contexts can accumulate memory over time, eventually causing out-of-memory errors in long-running services. This typically occurs when context storage uses strong references to context objects that should be garbage collected after request completion.\n\nThe symptom starts as gradually increasing memory usage that doesn't correspond to application load. Over days or weeks, memory consumption grows until the service becomes unstable. Memory profiling reveals large numbers of abandoned context objects still referenced by the logging system.\n\n#### Blocking I/O in Log Handler Hot Path\n\nBlocking I/O operations in the logging hot path represent a critical performance and reliability pitfall that can bring entire applications to a standstill. When log handlers perform synchronous file writes or network operations directly in the application's main execution thread, they introduce latency spikes and potential deadlocks that cascade through the entire system.\n\n⚠️ **Pitfall: Synchronous File Writes Without Buffering**\n\nThe most common blocking I/O mistake is implementing file handlers that perform synchronous writes for every log record. When application code calls `logger.info(\"Processing user request\")`, the thread blocks until the file write completes, including potential disk seeks, buffer flushes, and filesystem metadata updates.\n\nUnder normal conditions, this might add only microseconds of latency per log statement. However, during disk contention, filesystem cache pressure, or storage system degradation, each log write can block for milliseconds or seconds. In high-throughput applications generating thousands of log entries per second, this blocking behavior creates a performance cliff where logging overhead overwhelms application processing.\n\nThe symptom appears as application response times that correlate with logging volume rather than business logic complexity. Performance profiling reveals significant time spent in file system calls within logging code paths. Applications may appear to \"freeze\" during bursts of log activity.\n\n| Blocking I/O Scenario | Normal Latency | Degraded Latency | Application Impact |\n|----------------------|----------------|------------------|-------------------|\n| Single log statement per request | 50μs | 10ms | 200x slowdown in request processing |\n| Burst logging during error conditions | 1ms total | 500ms total | Request timeouts and cascading failures |\n| High-frequency debug logging | 10ms/second overhead | 5s/second overhead | Complete application stall |\n\n⚠️ **Pitfall: Network Handler Timeouts Without Circuit Breakers**\n\nNetwork-based log handlers that send records to remote aggregation systems introduce even more severe blocking risks. Network operations can timeout, experience packet loss, or encounter service unavailability. Without proper timeout configuration and circuit breaker patterns, application threads can block indefinitely waiting for network log delivery.\n\nThis pitfall is particularly dangerous because it couples application availability to logging infrastructure availability. If the remote log aggregation service becomes slow or unavailable, the entire application performance degrades proportionally. In the worst case, all application threads become blocked waiting for log delivery, creating a complete service outage caused by logging infrastructure failure.\n\n⚠️ **Pitfall: Lock Contention in Shared File Handles**\n\nEven when file I/O is buffered and optimized, shared file handles can create lock contention bottlenecks. If multiple threads write to the same log file through a single `FileHandler` instance, the handler must serialize writes to maintain log record integrity. Under high concurrency, threads queue up waiting for file write access, creating a serialization bottleneck.\n\n#### Memory Leaks in Context Management\n\nMemory leaks in context management systems create insidious performance degradation that compounds over time. Unlike immediate failures that are quickly detected and resolved, memory leaks accumulate slowly and may not manifest symptoms until applications have been running for days or weeks under production load.\n\n⚠️ **Pitfall: Context References in Thread-Local Storage**\n\nThe most common memory leak occurs when thread-local context storage maintains strong references to context objects beyond their useful lifetime. In long-running applications with thread pools, worker threads may be reused across many requests without properly clearing their thread-local context state.\n\nEach request adds context fields like correlation IDs, user information, and request metadata to the thread-local storage. If this context is not explicitly cleared at request completion, the thread retains references to all context objects from every request it has ever processed. In a busy web server, a single worker thread might accumulate context from thousands of requests over its lifetime.\n\nThe symptom appears as steadily increasing memory usage in long-running services, with memory profiling revealing large numbers of abandoned context objects still reachable through thread-local storage. The leak rate correlates with request volume, and memory usage never decreases even during idle periods.\n\n⚠️ **Pitfall: Circular References in Context Inheritance**\n\nContext inheritance systems that allow arbitrary object nesting can inadvertently create circular references that prevent garbage collection. This typically occurs when context objects contain references to application objects that themselves hold logging context references.\n\nFor example, a request context might contain a reference to the current user object for logging purposes. If that user object maintains a reference back to the request context (perhaps through an embedded logger), a circular reference prevents both objects from being garbage collected even after the request completes.\n\n⚠️ **Pitfall: Unbounded Context Field Accumulation**\n\nContext systems that allow unlimited field accumulation without size limits can experience memory leaks when application code repeatedly adds context fields without bounds checking. This often occurs in long-running background tasks that add diagnostic information to context throughout their execution lifecycle.\n\nA data processing job might add context fields for each processed record: `processing_record_1`, `processing_record_2`, etc. Over hours of execution, the context object grows to contain thousands of fields, consuming significant memory and degrading context access performance.\n\n### Debugging Techniques\n\nEffective debugging of structured logging systems requires systematic approaches that can isolate issues across the multiple layers of abstraction involved in log processing. Unlike simple debugging scenarios with clear cause-and-effect relationships, logging system bugs often involve subtle interactions between concurrent operations, context propagation mechanisms, and external I/O systems.\n\n#### Adding Trace Logging for Internal Operations\n\nTrace logging provides visibility into the internal operation of the logging system itself, creating a meta-logging capability that reveals how log records flow through the system architecture. This technique is particularly valuable for diagnosing issues in handler dispatch, level filtering, and context propagation where the symptoms are indirect effects of internal system state.\n\nThe key insight behind trace logging is creating a separate, simpler logging channel that operates independently of the main logging system being debugged. This trace system should be minimal and robust, avoiding the complex features that might themselves be the source of bugs in the main system.\n\n**Internal Logger State Tracing**\n\nImplementing trace logging for logger state changes reveals how the logger hierarchy evolves during application execution. This is particularly valuable for diagnosing race conditions in logger creation and configuration that only manifest under specific timing conditions.\n\nThe trace system should log every significant state change with enough detail to reconstruct the sequence of operations that led to the current state. Key events to trace include logger creation, parent-child relationship establishment, level changes, handler additions and removals, and context modifications.\n\n| Trace Event Type | Information Logged | Debugging Value |\n|------------------|-------------------|-----------------|\n| Logger creation | Logger name, parent name, thread ID, timestamp | Reveals duplicate logger creation and hierarchy building order |\n| Level changes | Logger name, old level, new level, effective level recalculation | Shows level inheritance and cache invalidation behavior |\n| Handler operations | Handler add/remove, logger name, handler type, thread ID | Reveals handler configuration race conditions |\n| Context modifications | Context field changes, inheritance relationships, thread boundaries | Shows context propagation and cleanup behavior |\n\nThe trace output should include thread identifiers and high-precision timestamps to reveal concurrency issues. For example, trace logs might show two threads simultaneously creating the same parent logger, or level changes that don't properly invalidate descendant logger caches.\n\n**Handler Dispatch Flow Tracing**\n\nHandler dispatch tracing reveals how log records flow through the handler selection and output generation process. This is essential for debugging issues where log records are lost, duplicated, or sent to incorrect destinations.\n\nThe trace system should log each step of the dispatch process: level filtering decisions, handler collection from the logger hierarchy, formatter invocation, and final output destination. When handlers fail, the trace logs show exactly which handlers were attempted and what errors occurred.\n\n**Context Propagation Tracing**\n\nContext propagation is one of the most difficult aspects of logging systems to debug because problems often manifest far from their root cause. A context field might be lost during async task creation but not discovered until much later when correlation fails during error investigation.\n\nEffective context tracing logs every context operation: context creation, field additions, inheritance operations, thread boundary crossings, and cleanup operations. The trace includes context snapshots before and after each operation, making it possible to identify exactly where context corruption or loss occurs.\n\n#### Inspecting Context State\n\nContext state inspection provides real-time visibility into the current state of logging context across all active execution contexts. This technique is essential for debugging context propagation issues where the symptoms (missing correlation information) are distant from the cause (failed context inheritance).\n\n**Context Storage Dump Utilities**\n\nBuilding utilities to dump the current state of all context storage mechanisms reveals inconsistencies between thread-local and async-local context storage. These utilities should be callable from debugger sessions or triggered by special debug endpoints in web applications.\n\nThe dump output should show the complete context hierarchy for each active execution context, including inheritance relationships, field values, and storage mechanism details. Comparing context state across different storage mechanisms can reveal synchronization issues or failed context propagation.\n\n| Context Storage View | Information Displayed | Debugging Application |\n|---------------------|----------------------|----------------------|\n| Thread-local contexts | Thread ID, context fields, inheritance chain | Reveals thread context isolation and cleanup issues |\n| Async-local contexts | Task ID, context fields, parent task relationships | Shows async context propagation and coroutine switching |\n| Global context registry | All active contexts, reference counts, cleanup status | Identifies memory leaks and orphaned contexts |\n| Context inheritance tree | Parent-child relationships, field inheritance, override behavior | Reveals context inheritance logic errors |\n\n**Context Field History Tracking**\n\nImplementing context field history tracking maintains a record of how each context field was added, modified, or removed throughout request processing. This technique is particularly valuable for debugging cases where context fields have unexpected values or disappear mysteriously during processing.\n\nThe history tracker records not just field values but the stack trace or operation context where each change occurred. When debugging correlation failures, the history reveals exactly where correlation IDs were lost or overwritten with incorrect values.\n\n**Context Boundary Verification**\n\nContext boundary verification systematically checks that context propagation works correctly across all types of execution boundaries in the application. This includes thread creation, async task spawning, callback invocation, and external service calls.\n\nThe verification system can be implemented as assertions that automatically check context consistency at known boundary points, or as explicit verification calls inserted during debugging sessions. When context propagation fails, these checks identify the specific boundary where propagation broke down.\n\n#### Testing Thread Safety\n\nThread safety testing for logging systems requires techniques that can reliably reproduce concurrency issues that may only manifest under specific timing conditions. Unlike functional testing where deterministic inputs produce predictable outputs, concurrency testing must deal with the inherent non-determinism of multi-threaded execution.\n\n**Concurrent Logger Operation Testing**\n\nEffective thread safety testing subjects the logger hierarchy to intensive concurrent operations that stress-test all synchronization mechanisms. This includes simultaneous logger creation, configuration changes, level modifications, and message logging across multiple threads.\n\nThe test framework should use barriers and coordination mechanisms to maximize the probability of race conditions occurring. Rather than simply launching multiple threads and hoping for conflicts, the tests should synchronize thread execution to create maximum contention at critical sections.\n\n| Concurrency Test Scenario | Thread A Operations | Thread B Operations | Expected Behavior |\n|---------------------------|--------------------|--------------------|-------------------|\n| Simultaneous logger creation | Create logger `com.example.service` | Create logger `com.example.service.auth` | Both loggers created with correct parent-child relationship |\n| Configuration race | Set logger level to DEBUG | Add handler to same logger | Both operations complete without corruption |\n| Context modification | Add field `user_id: alice` to logger context | Read effective context from child logger | Child sees consistent context state |\n| Handler dispatch | Log ERROR message | Remove handler from logger | Message logged to handlers present at start of operation |\n\n**Memory Consistency Verification**\n\nMemory consistency verification ensures that changes made by one thread are properly visible to other threads according to the memory model of the target language. This is particularly important for logging systems where configuration changes must be immediately visible to all threads performing logging operations.\n\nThe verification tests should check that level changes, handler modifications, and context updates made by one thread are immediately visible to other threads without requiring explicit synchronization in the application code. Memory consistency bugs often manifest as stale configuration being used intermittently under load.\n\n**Stress Testing Under Realistic Load**\n\nRealistic load testing subjects the logging system to conditions similar to production environments, including high message volume, frequent configuration changes, and mixed patterns of concurrent access. This type of testing often reveals performance bottlenecks and race conditions that only appear under sustained load.\n\nThe stress tests should monitor not just correctness but also performance characteristics under load. Thread contention, lock acquisition times, and message throughput should remain stable even under extreme concurrency levels.\n\n### Symptom-Cause-Fix Troubleshooting\n\nSystematic troubleshooting of structured logging systems requires mapping observable symptoms to their underlying causes and providing specific, actionable fixes. The challenge lies in the fact that logging system issues often have subtle symptoms that appear far from their root causes, and multiple independent issues can interact to create complex failure modes.\n\n#### Thread Safety and Concurrency Issues\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Logger configuration randomly reverts to defaults | Race condition in logger registry during concurrent logger creation | Add trace logging to logger creation and configuration methods. Check for duplicate logger instances with different configurations. | Implement proper locking in `LoggerRegistry` with `RLock` for reads and exclusive lock for writes. Ensure atomic logger creation and configuration. |\n| Log messages occasionally missing from output | Handler list modified during iteration in concurrent threads | Add assertion to verify handler list stability during dispatch. Use concurrent logging load tests to reproduce. | Use copy-on-write pattern for handler lists or lock handler list during iteration and modification. |\n| Inconsistent log levels applied to same logger | Effective level cache invalidation race condition | Monitor `_effective_level` cache values across threads. Add logging to level change and cache invalidation operations. | Implement atomic cache invalidation with proper memory barriers. Use versioning to detect stale cache entries. |\n| Log records contain mixed context from different requests | Thread pool reusing threads without context cleanup | Inspect thread-local context storage at request boundaries. Check for context cleanup in thread pool management code. | Implement automatic context cleanup using request lifecycle hooks or context managers that clear state on exit. |\n| Occasional crashes during high-volume logging | Memory corruption from unsynchronized data structure access | Use thread sanitizers or memory debugging tools. Add lock verification assertions in critical sections. | Add comprehensive locking to all shared data structures. Use lock ordering to prevent deadlocks. |\n\n#### Context Propagation Problems\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Correlation IDs disappear in background tasks | Thread-local context not propagated to new threads | Trace context state before and after thread creation. Check context inheritance in task spawning code. | Implement context-aware thread creation utilities that capture parent context and set it in child threads. |\n| Context fields randomly change during async operations | Async context not preserved across await boundaries | Add context state logging before and after each await operation. Monitor context during coroutine switches. | Use async-local storage with proper context copying across task boundaries. Implement async context managers. |\n| Memory usage grows continuously in long-running services | Context objects not being garbage collected | Use memory profilers to identify context object accumulation. Check for circular references and strong reference chains. | Implement weak references in context storage. Add automatic context cleanup based on access time or reference counting. |\n| Child logger context missing parent fields | Context inheritance not working correctly | Compare parent and child context objects. Trace context inheritance during logger hierarchy traversal. | Fix context inheritance logic to properly merge parent context with local context. Ensure inheritance occurs at access time, not creation time. |\n| Context lost after exception handling | Exception unwinding clears context without restoration | Add context state logging in exception handlers. Check context cleanup in finally blocks and exception handling code. | Use context managers that automatically restore previous context state even when exceptions occur during processing. |\n\n#### Serialization and Formatting Issues\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Log output contains `[Object object]` or similar placeholder text | Non-serializable objects in context or log parameters | Add type checking to context field additions. Test serialization of all context objects before logging. | Implement `safe_serialize()` with fallback representations for non-serializable objects. Add type validation for context fields. |\n| JSON output malformed or contains invalid characters | Circular references or special characters not being escaped properly | Validate JSON output with strict parsers. Check for circular object references in context data. | Use custom JSON encoder with circular reference detection and proper character escaping. Limit serialization depth. |\n| Log timestamps inconsistent or incorrect format | Timestamp generation not thread-safe or using wrong timezone | Compare timestamps across threads and verify timezone handling. Check timestamp generation under concurrent load. | Use thread-safe timestamp generation with proper UTC handling. Implement timestamp caching for performance. |\n| Pretty-printed logs missing colors or formatting | Terminal detection not working or color codes not supported | Test color output in different terminal environments. Check terminal capability detection logic. | Implement robust terminal capability detection with graceful fallback to plain text when colors not supported. |\n| Large context objects cause out-of-memory errors | Context serialization creating oversized JSON objects | Monitor memory usage during serialization. Set limits on context object size and nesting depth. | Implement context size limits and truncation. Add `estimate_serialized_size()` checks before full serialization. |\n\n#### Handler and Output Destination Problems\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Application hangs during log output | Blocking I/O in handlers without timeouts | Profile application during hang to identify blocked threads. Check file and network I/O patterns in handlers. | Implement non-blocking handlers with background queues. Add timeouts to all I/O operations. Use circuit breakers for unreliable destinations. |\n| Log messages lost during handler failures | Handler exceptions not properly caught and recovered | Add error logging to handler dispatch. Monitor handler success/failure rates. Check exception handling in handler code. | Implement comprehensive exception handling in handler dispatch. Add handler health monitoring and automatic recovery. |\n| Duplicate log messages in output | Handler dispatch calling same handler multiple times | Trace handler collection and dispatch logic. Check for duplicate handlers in logger hierarchy. | Fix handler collection to remove duplicates. Implement handler identity checking based on handler configuration. |\n| Log files not being rotated or growing unbounded | File handler not implementing rotation or size limits | Monitor file sizes and rotation behavior. Check file handler configuration and rotation logic. | Implement proper file rotation with size and time-based triggers. Add monitoring for file handler disk usage. |\n| Network handlers causing application instability | Network handlers blocking application threads on failures | Monitor network handler performance and failure rates. Check timeout and retry configuration. | Implement asynchronous network handlers with connection pooling. Add circuit breakers and exponential backoff for failed connections. |\n\n#### Performance and Resource Issues\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Application response time degrades with log volume | Logging operations blocking application threads | Profile application performance vs. logging volume. Measure time spent in logging operations. | Implement asynchronous logging with background processing queues. Optimize hot path operations and reduce lock contention. |\n| Memory usage increases proportionally to log volume | Context or handler buffers accumulating without bounds | Monitor memory allocation patterns in logging code. Check for unbounded buffers or caches. | Implement buffer size limits and periodic cleanup. Add memory pressure detection and adaptive behavior. |\n| CPU usage high during logging operations | Inefficient serialization or formatting algorithms | Profile CPU usage in logging hot paths. Identify expensive operations like JSON serialization or string formatting. | Optimize serialization with object pooling and caching. Use efficient formatting algorithms and reduce object allocation. |\n| Disk I/O spikes causing system instability | Synchronous file writes without buffering or batching | Monitor disk I/O patterns and correlate with logging activity. Check file write patterns in handlers. | Implement write batching and buffering. Use asynchronous I/O or background writer threads. Add disk pressure detection. |\n| Logger creation very slow under load | Logger registry lock contention or inefficient hierarchy traversal | Profile logger creation performance. Monitor lock acquisition times and registry operation costs. | Optimize logger registry with better data structures. Use read-write locks to reduce contention. Cache hierarchy traversal results. |\n\n### Implementation Guidance\n\nThis implementation guidance provides concrete debugging infrastructure and techniques specifically tailored for Python-based structured logging systems. The focus is on building debugging tools that can be integrated into the logging system itself and used during development and troubleshooting.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Trace Logging | Python `logging` module with separate logger | Custom trace system with structured output |\n| Thread Safety Testing | `threading.Thread` with manual barriers | `concurrent.futures` with systematic test framework |\n| Memory Debugging | Built-in `tracemalloc` and `gc` modules | External tools like `objgraph` and `memory_profiler` |\n| Concurrency Testing | Simple thread spawning with `threading` | Advanced concurrency testing with `pytest-xdist` |\n| Context Inspection | Manual context dumps with `pprint` | Rich context visualization with custom formatters |\n\n#### Recommended Module Structure\n\n```\nstructured_logging/\n├── core/\n│   ├── logger.py              ← Logger, LoggerRegistry classes\n│   ├── handlers.py            ← Handler implementations\n│   ├── formatters.py          ← JSON and pretty formatters\n│   └── context.py             ← Context management and propagation\n├── debugging/\n│   ├── __init__.py\n│   ├── trace_logger.py        ← Internal tracing system\n│   ├── context_inspector.py   ← Context state inspection utilities\n│   ├── thread_safety_test.py  ← Concurrency testing framework\n│   └── memory_tracker.py      ← Memory leak detection utilities\n├── tests/\n│   ├── test_race_conditions.py ← Systematic concurrency tests\n│   ├── test_context_propagation.py ← Context boundary tests\n│   └── test_memory_leaks.py    ← Long-running memory tests\n└── examples/\n    ├── debug_concurrent_app.py ← Example debugging setup\n    └── trace_context_flow.py   ← Context propagation examples\n```\n\n#### Infrastructure Starter Code\n\n**Complete Trace Logging System**\n\n```python\nimport threading\nimport time\nimport sys\nfrom typing import Dict, List, Any, Optional\nfrom datetime import datetime, timezone\nfrom collections import deque\nimport weakref\n\nclass TraceLogger:\n    \"\"\"\n    Independent trace logging system for debugging the main logging infrastructure.\n    Uses simple, robust mechanisms to avoid circular dependencies or complexity\n    that might itself introduce bugs.\n    \"\"\"\n    \n    def __init__(self, output_file: Optional[str] = None, max_records: int = 10000):\n        self._lock = threading.Lock()\n        self._records = deque(maxlen=max_records)\n        self._output_file = output_file\n        self._start_time = time.perf_counter()\n        \n    def trace(self, event_type: str, details: Dict[str, Any]) -> None:\n        \"\"\"Log a trace event with high-precision timing and thread information.\"\"\"\n        with self._lock:\n            record = {\n                'timestamp': datetime.now(timezone.utc).isoformat(),\n                'elapsed_ms': (time.perf_counter() - self._start_time) * 1000,\n                'thread_id': threading.get_ident(),\n                'thread_name': threading.current_thread().name,\n                'event_type': event_type,\n                'details': details.copy()\n            }\n            self._records.append(record)\n            \n            # Immediate output for debugging\n            if self._output_file:\n                self._write_to_file(record)\n            else:\n                self._write_to_stderr(record)\n    \n    def _write_to_file(self, record: Dict[str, Any]) -> None:\n        \"\"\"Write trace record to file with immediate flush.\"\"\"\n        try:\n            with open(self._output_file, 'a', encoding='utf-8') as f:\n                f.write(f\"{record}\\n\")\n                f.flush()\n        except Exception as e:\n            # Fallback to stderr if file write fails\n            sys.stderr.write(f\"TraceLogger file error: {e}\\n\")\n            self._write_to_stderr(record)\n    \n    def _write_to_stderr(self, record: Dict[str, Any]) -> None:\n        \"\"\"Write trace record to stderr for immediate visibility.\"\"\"\n        sys.stderr.write(f\"TRACE[{record['thread_name']}]: {record['event_type']} - {record['details']}\\n\")\n        sys.stderr.flush()\n    \n    def get_records(self, event_type: Optional[str] = None, \n                   thread_id: Optional[int] = None) -> List[Dict[str, Any]]:\n        \"\"\"Retrieve trace records with optional filtering.\"\"\"\n        with self._lock:\n            records = list(self._records)\n            \n        if event_type:\n            records = [r for r in records if r['event_type'] == event_type]\n        if thread_id:\n            records = [r for r in records if r['thread_id'] == thread_id]\n            \n        return records\n    \n    def dump_summary(self) -> str:\n        \"\"\"Generate human-readable summary of trace activity.\"\"\"\n        with self._lock:\n            records = list(self._records)\n        \n        if not records:\n            return \"No trace records available\"\n        \n        summary_lines = [f\"Trace Summary ({len(records)} records)\"]\n        summary_lines.append(f\"Time range: {records[0]['elapsed_ms']:.2f}ms - {records[-1]['elapsed_ms']:.2f}ms\")\n        \n        # Event type frequency\n        event_counts = {}\n        for record in records:\n            event_counts[record['event_type']] = event_counts.get(record['event_type'], 0) + 1\n        \n        summary_lines.append(\"\\nEvent Types:\")\n        for event_type, count in sorted(event_counts.items()):\n            summary_lines.append(f\"  {event_type}: {count}\")\n        \n        # Thread activity\n        thread_counts = {}\n        for record in records:\n            thread_id = record['thread_id']\n            thread_counts[thread_id] = thread_counts.get(thread_id, 0) + 1\n        \n        summary_lines.append(f\"\\nThread Activity ({len(thread_counts)} threads):\")\n        for thread_id, count in sorted(thread_counts.items()):\n            summary_lines.append(f\"  Thread {thread_id}: {count} events\")\n        \n        return \"\\n\".join(summary_lines)\n\n# Global trace logger instance for debugging\n_debug_tracer = TraceLogger()\n\ndef trace_event(event_type: str, **details) -> None:\n    \"\"\"Convenience function for logging trace events.\"\"\"\n    _debug_tracer.trace(event_type, details)\n\ndef get_trace_summary() -> str:\n    \"\"\"Get debugging trace summary.\"\"\"\n    return _debug_tracer.dump_summary()\n```\n\n**Context State Inspector**\n\n```python\nimport threading\nimport contextvars\nimport weakref\nfrom typing import Dict, Any, List, Set, Optional\nimport json\nfrom datetime import datetime\n\nclass ContextInspector:\n    \"\"\"\n    Utility for inspecting and debugging context state across all storage mechanisms.\n    Provides visibility into context propagation, inheritance, and cleanup behavior.\n    \"\"\"\n    \n    def __init__(self):\n        self._inspection_lock = threading.Lock()\n        self._context_history: List[Dict[str, Any]] = []\n        self._active_contexts: weakref.WeakSet = weakref.WeakSet()\n    \n    def register_context(self, context_id: str, context_data: Dict[str, Any], \n                        storage_type: str) -> None:\n        \"\"\"Register a context for inspection tracking.\"\"\"\n        with self._inspection_lock:\n            self._context_history.append({\n                'timestamp': datetime.now().isoformat(),\n                'action': 'register',\n                'context_id': context_id,\n                'storage_type': storage_type,\n                'thread_id': threading.get_ident(),\n                'data_snapshot': context_data.copy(),\n                'field_count': len(context_data)\n            })\n    \n    def snapshot_all_contexts(self) -> Dict[str, Any]:\n        \"\"\"Take a complete snapshot of all context storage mechanisms.\"\"\"\n        snapshot = {\n            'timestamp': datetime.now().isoformat(),\n            'thread_local_contexts': self._snapshot_thread_local(),\n            'async_contexts': self._snapshot_async_contexts(),\n            'active_context_count': len(self._active_contexts),\n            'history_length': len(self._context_history)\n        }\n        return snapshot\n    \n    def _snapshot_thread_local(self) -> Dict[str, Any]:\n        \"\"\"Snapshot all thread-local context storage.\"\"\"\n        # This would integrate with the actual ContextStorage implementation\n        thread_contexts = {}\n        \n        # Iterate through all active threads and capture their context\n        for thread in threading.enumerate():\n            try:\n                # This assumes the ContextStorage has a method to get context by thread\n                # In real implementation, this would access the actual thread-local storage\n                thread_context = self._get_thread_context(thread.ident)\n                if thread_context:\n                    thread_contexts[f\"thread_{thread.ident}\"] = {\n                        'thread_name': thread.name,\n                        'context': thread_context,\n                        'field_count': len(thread_context)\n                    }\n            except Exception as e:\n                thread_contexts[f\"thread_{thread.ident}\"] = {'error': str(e)}\n        \n        return thread_contexts\n    \n    def _snapshot_async_contexts(self) -> Dict[str, Any]:\n        \"\"\"Snapshot async context variables.\"\"\"\n        async_contexts = {}\n        \n        try:\n            # Capture current async context if available\n            current_context = contextvars.copy_context()\n            context_vars = {}\n            \n            # This would iterate through actual context variables in use\n            # In real implementation, this would access the ContextStorage async variables\n            for var, value in current_context.items():\n                if hasattr(var, 'name') and 'logging' in var.name:\n                    context_vars[var.name] = value\n            \n            async_contexts['current_task'] = {\n                'context_vars': context_vars,\n                'var_count': len(context_vars)\n            }\n            \n        except Exception as e:\n            async_contexts['error'] = str(e)\n        \n        return async_contexts\n    \n    def _get_thread_context(self, thread_id: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Get context for specific thread - placeholder for actual implementation.\"\"\"\n        # In real implementation, this would access the ContextStorage._thread_local\n        return None\n    \n    def find_context_inconsistencies(self) -> List[Dict[str, Any]]:\n        \"\"\"Identify inconsistencies between different context storage mechanisms.\"\"\"\n        inconsistencies = []\n        snapshot = self.snapshot_all_contexts()\n        \n        # Compare thread-local and async contexts for current thread\n        current_thread_id = threading.get_ident()\n        thread_context_key = f\"thread_{current_thread_id}\"\n        \n        thread_context = snapshot['thread_local_contexts'].get(thread_context_key, {}).get('context', {})\n        async_context = snapshot['async_contexts'].get('current_task', {}).get('context_vars', {})\n        \n        # Check for missing fields\n        for field in thread_context:\n            if field not in async_context:\n                inconsistencies.append({\n                    'type': 'missing_in_async',\n                    'field': field,\n                    'thread_value': thread_context[field],\n                    'thread_id': current_thread_id\n                })\n        \n        for field in async_context:\n            if field not in thread_context:\n                inconsistencies.append({\n                    'type': 'missing_in_thread_local',\n                    'field': field,\n                    'async_value': async_context[field],\n                    'thread_id': current_thread_id\n                })\n        \n        # Check for value mismatches\n        for field in set(thread_context.keys()) & set(async_context.keys()):\n            if thread_context[field] != async_context[field]:\n                inconsistencies.append({\n                    'type': 'value_mismatch',\n                    'field': field,\n                    'thread_value': thread_context[field],\n                    'async_value': async_context[field],\n                    'thread_id': current_thread_id\n                })\n        \n        return inconsistencies\n    \n    def generate_context_report(self) -> str:\n        \"\"\"Generate comprehensive context debugging report.\"\"\"\n        snapshot = self.snapshot_all_contexts()\n        inconsistencies = self.find_context_inconsistencies()\n        \n        report_lines = [\n            \"=== Context State Debugging Report ===\",\n            f\"Generated at: {snapshot['timestamp']}\",\n            f\"Active contexts: {snapshot['active_context_count']}\",\n            f\"History entries: {snapshot['history_length']}\",\n            \"\"\n        ]\n        \n        # Thread-local context summary\n        report_lines.append(\"Thread-Local Contexts:\")\n        for thread_key, context_info in snapshot['thread_local_contexts'].items():\n            if 'error' in context_info:\n                report_lines.append(f\"  {thread_key}: ERROR - {context_info['error']}\")\n            else:\n                field_count = context_info.get('field_count', 0)\n                thread_name = context_info.get('thread_name', 'unknown')\n                report_lines.append(f\"  {thread_key} ({thread_name}): {field_count} fields\")\n                \n                # Show context fields if not too many\n                if field_count <= 10:\n                    for field, value in context_info.get('context', {}).items():\n                        report_lines.append(f\"    {field}: {value}\")\n        \n        report_lines.append(\"\")\n        \n        # Async context summary\n        report_lines.append(\"Async Contexts:\")\n        async_info = snapshot['async_contexts']\n        if 'error' in async_info:\n            report_lines.append(f\"  ERROR: {async_info['error']}\")\n        else:\n            current_task = async_info.get('current_task', {})\n            var_count = current_task.get('var_count', 0)\n            report_lines.append(f\"  Current task: {var_count} context variables\")\n            \n            for var_name, value in current_task.get('context_vars', {}).items():\n                report_lines.append(f\"    {var_name}: {value}\")\n        \n        report_lines.append(\"\")\n        \n        # Inconsistencies\n        if inconsistencies:\n            report_lines.append(f\"Context Inconsistencies ({len(inconsistencies)} found):\")\n            for inconsistency in inconsistencies:\n                report_lines.append(f\"  {inconsistency['type']}: {inconsistency['field']}\")\n                if 'thread_value' in inconsistency:\n                    report_lines.append(f\"    Thread-local: {inconsistency['thread_value']}\")\n                if 'async_value' in inconsistency:\n                    report_lines.append(f\"    Async: {inconsistency['async_value']}\")\n        else:\n            report_lines.append(\"No context inconsistencies detected.\")\n        \n        return \"\\n\".join(report_lines)\n\n# Global context inspector for debugging\n_context_inspector = ContextInspector()\n\ndef snapshot_contexts() -> Dict[str, Any]:\n    \"\"\"Take snapshot of all context state for debugging.\"\"\"\n    return _context_inspector.snapshot_all_contexts()\n\ndef generate_context_debug_report() -> str:\n    \"\"\"Generate comprehensive context debugging report.\"\"\"\n    return _context_inspector.generate_context_report()\n```\n\n#### Core Logic Skeleton Code\n\n**Thread Safety Testing Framework**\n\n```python\nimport threading\nimport time\nimport random\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom typing import List, Callable, Dict, Any\nimport queue\n\nclass ConcurrencyTestFramework:\n    \"\"\"\n    Framework for systematic testing of thread safety in logging components.\n    Provides utilities for coordinated multi-threaded testing with barrier synchronization.\n    \"\"\"\n    \n    def __init__(self, max_workers: int = 10):\n        self.max_workers = max_workers\n        self.test_results: List[Dict[str, Any]] = []\n        self.results_lock = threading.Lock()\n    \n    def run_coordinated_test(self, test_func: Callable, num_threads: int = 5, \n                           iterations: int = 100, coordination_delay: float = 0.001) -> Dict[str, Any]:\n        \"\"\"\n        Run coordinated multi-threaded test with barrier synchronization.\n        \n        Args:\n            test_func: Function to test - should accept (thread_id, iteration, barrier)\n            num_threads: Number of concurrent threads\n            iterations: Number of iterations per thread\n            coordination_delay: Delay to maximize contention probability\n        \"\"\"\n        # TODO 1: Create barrier for thread coordination\n        # TODO 2: Create results collection mechanism\n        # TODO 3: Launch threads with coordinated start\n        # TODO 4: Collect results and analyze for race conditions\n        # TODO 5: Return summary with success/failure counts and timing information\n        # Hint: Use threading.Barrier to synchronize thread starts\n        pass\n    \n    def test_logger_hierarchy_creation(self, logger_factory: Callable) -> Dict[str, Any]:\n        \"\"\"\n        Test concurrent logger creation for race conditions.\n        \n        Args:\n            logger_factory: Function that creates loggers - get_logger(name)\n        \"\"\"\n        # TODO 1: Define logger names that should create hierarchy conflicts\n        # TODO 2: Create test function that creates loggers with barrier coordination\n        # TODO 3: Run coordinated test with multiple threads creating same hierarchies\n        # TODO 4: Verify no duplicate loggers or corrupted hierarchies were created\n        # TODO 5: Check parent-child relationships are correct after concurrent creation\n        # Hint: Test names like [\"com.example\", \"com.example.service\", \"com.example.service.auth\"]\n        pass\n    \n    def test_concurrent_configuration_changes(self, logger_registry) -> Dict[str, Any]:\n        \"\"\"\n        Test concurrent logger configuration changes.\n        \n        Args:\n            logger_registry: Registry containing loggers to test\n        \"\"\"\n        # TODO 1: Create test scenarios mixing level changes and handler additions\n        # TODO 2: Coordinate threads to make changes at same time using barrier\n        # TODO 3: Verify final configuration state is consistent\n        # TODO 4: Check that effective level caches were properly invalidated\n        # TODO 5: Ensure no configuration was lost or corrupted during changes\n        pass\n    \n    def test_context_propagation_race_conditions(self, context_manager) -> Dict[str, Any]:\n        \"\"\"\n        Test context propagation under concurrent access.\n        \n        Args:\n            context_manager: ContextStorage instance to test\n        \"\"\"\n        # TODO 1: Create test that sets different context in multiple threads\n        # TODO 2: Add child context inheritance operations during concurrent updates\n        # TODO 3: Verify context isolation between threads\n        # TODO 4: Check that context inheritance works correctly under contention\n        # TODO 5: Ensure no context corruption or cross-thread contamination\n        pass\n\n# Usage example for milestone checkpoints\ndef run_thread_safety_checkpoint(logger_system) -> bool:\n    \"\"\"\n    Run comprehensive thread safety tests for milestone verification.\n    Returns True if all tests pass, False if race conditions detected.\n    \"\"\"\n    framework = ConcurrencyTestFramework()\n    \n    # Test logger creation under contention\n    creation_results = framework.test_logger_hierarchy_creation(logger_system.get_logger)\n    \n    # Test configuration changes\n    config_results = framework.test_concurrent_configuration_changes(logger_system.registry)\n    \n    # Test context propagation\n    context_results = framework.test_context_propagation_race_conditions(logger_system.context_manager)\n    \n    # Analyze results\n    all_passed = (\n        creation_results.get('failures', 0) == 0 and\n        config_results.get('failures', 0) == 0 and\n        context_results.get('failures', 0) == 0\n    )\n    \n    if not all_passed:\n        print(\"Thread safety test failures detected:\")\n        print(f\"Logger creation: {creation_results.get('failures', 0)} failures\")\n        print(f\"Configuration: {config_results.get('failures', 0)} failures\") \n        print(f\"Context propagation: {context_results.get('failures', 0)} failures\")\n    \n    return all_passed\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1: Logger Core Thread Safety Verification**\n\nAfter implementing the logger core, run these verification steps:\n\n```bash\n# Run basic thread safety tests\npython -m pytest tests/test_race_conditions.py::test_concurrent_logger_creation -v\n\n# Expected output should show no race conditions:\n# test_concurrent_logger_creation PASSED\n# test_concurrent_level_changes PASSED  \n# test_concurrent_handler_dispatch PASSED\n```\n\nVerify thread safety manually:\n1. Start Python interpreter\n2. Create logger registry and spawn 10 threads simultaneously creating loggers\n3. Check that logger hierarchy is consistent and no duplicate loggers exist\n4. Verify that all loggers have correct parent-child relationships\n\n**Milestone 2: Structured Output Serialization Testing**\n\n```bash\n# Test JSON serialization under load\npython -m pytest tests/test_serialization.py::test_concurrent_json_formatting -v\n\n# Test with problematic objects\npython examples/test_serialization_edge_cases.py\n```\n\nExpected behavior:\n- All JSON output should be valid single-line JSON\n- No serialization errors even with circular references\n- Memory usage should remain stable during high-volume serialization\n\n**Milestone 3: Context Propagation Verification**\n\n```bash\n# Test async context preservation\npython -m pytest tests/test_context_propagation.py::test_async_context_preservation -v\n\n# Test thread-local context isolation  \npython examples/test_context_boundaries.py\n```\n\nManual verification:\n1. Create request with correlation ID in main thread\n2. Spawn background task and verify correlation ID is present\n3. Modify context in background task and verify main thread context unchanged\n4. Check that context cleanup occurs after request completion\n\n#### Language-Specific Python Debugging Tips\n\n- Use `threading.get_ident()` to identify which thread is executing logging operations\n- `threading.current_thread().name` provides human-readable thread identification\n- `tracemalloc.start()` at application startup enables memory leak detection\n- `gc.get_objects()` can find leaked context objects by type filtering  \n- `weakref.WeakSet` prevents circular references in context tracking\n- `contextvars.copy_context()` captures complete async context state\n- `sys.stderr.write()` provides immediate debug output that bypasses the main logging system\n- Use `threading.RLock()` instead of `Lock()` for recursive logger operations\n- `time.perf_counter()` provides high-resolution timing for race condition detection\n- `concurrent.futures.ThreadPoolExecutor` simplifies coordinated multi-threaded testing\n\n\n## Future Extensions\n\n> **Milestone(s):** This section outlines potential enhancements beyond the three core milestones that the current design accommodates. While Milestones 1-3 establish the foundation, these extensions represent production-scale optimizations and enterprise-level features that can be added incrementally.\n\nThink of this logging system as a highway infrastructure. The three core milestones build the essential roads, traffic signals, and basic navigation systems that handle normal traffic flow. These future extensions are like adding express lanes for high-volume traffic (performance optimizations), connecting to airports and shipping ports (advanced output destinations), and installing smart traffic management systems that adapt to changing conditions (configuration management). Each extension leverages the solid foundation established by the core milestones while adding sophisticated capabilities for production environments.\n\nThe architectural decisions made in the core design deliberately accommodate these extensions without requiring fundamental restructuring. The handler dispatch mechanism supports pluggable output destinations, the context propagation system enables sampling decisions, and the thread-safe registry pattern allows dynamic reconfiguration. This forward-looking design ensures that organizations can start with the essential logging capabilities and scale up to enterprise requirements as their needs evolve.\n\n### Performance Optimizations\n\nProduction logging systems must handle massive throughput while maintaining low latency for application threads. Think of performance optimizations as traffic management systems for a busy highway. During rush hour, you need express lanes for priority traffic (log sampling), speed limits to prevent accidents (rate limiting), and efficient on/off ramps that don't block the main flow (async handler dispatch). These optimizations ensure that logging enhances observability without degrading application performance.\n\nThe core design's thread-safe architecture and handler abstraction pattern provide the foundation for these performance enhancements. The `Handler` base class can be extended with buffering and batching capabilities, while the `LoggingContext` system enables sampling decisions based on request characteristics. The `CircuitBreaker` pattern already implemented for error handling extends naturally to performance protection by temporarily disabling expensive operations under load.\n\n> **Decision: Log Sampling Strategy**\n> - **Context**: High-throughput applications generate millions of log entries per second, overwhelming storage and network capacity while providing diminishing observability value\n> - **Options Considered**: Random sampling, adaptive sampling, structured sampling\n> - **Decision**: Implement adaptive sampling with context-aware rate limiting\n> - **Rationale**: Adaptive sampling maintains full fidelity for errors and important events while reducing volume for routine operations. Context-aware decisions ensure complete request traces are preserved even when individual log entries are sampled\n> - **Consequences**: Enables high-throughput logging with bounded resource usage while preserving debugging capability for critical scenarios\n\n**Adaptive Sampling Architecture**\n\nAdaptive sampling makes intelligent decisions about which log entries to preserve based on current system load, log entry importance, and correlation context. The sampling system operates at multiple levels: per-logger sampling rates, per-request sampling decisions, and global backpressure handling. This multi-layered approach ensures that critical information is never lost while routine operations can be sampled aggressively during high-load periods.\n\nThe `SamplingHandler` wraps existing handlers and makes sampling decisions before expensive operations like network transmission or disk writes. Sampling decisions are made deterministically based on correlation IDs, ensuring that when a request is selected for sampling, all related log entries are preserved together. This correlation-aware sampling maintains complete request traces while reducing overall volume.\n\n| Component | Purpose | Key Responsibilities |\n|-----------|---------|---------------------|\n| `AdaptiveSampler` | Core sampling logic | Rate calculation, decision caching, context awareness |\n| `SamplingHandler` | Handler wrapper | Pre-filtering, correlation tracking, metrics collection |\n| `SamplingConfig` | Configuration model | Rate limits, importance rules, adaptation parameters |\n| `LoadMonitor` | System monitoring | CPU/memory tracking, backpressure detection, rate adjustment |\n| `SampleDecisionCache` | Decision storage | Correlation ID mapping, TTL management, memory bounds |\n\n**Rate Limiting Implementation**\n\nRate limiting protects the logging system and downstream consumers from overload by enforcing maximum throughput limits. Think of rate limiting as traffic lights that meter the flow of vehicles onto a highway, preventing congestion that would slow down all traffic. The rate limiting system operates at multiple granularities: global limits prevent system-wide overload, per-logger limits prevent individual components from monopolizing resources, and per-level limits ensure that verbose debug logging doesn't crowd out important error messages.\n\nThe `TokenBucketRateLimiter` provides smooth rate limiting with burst capacity, allowing applications to handle traffic spikes while maintaining average rate limits. Token buckets are maintained per logger and per level, with hierarchical inheritance ensuring that child loggers respect parent limits. The rate limiter integrates with the sampling system to gracefully degrade service rather than dropping log entries randomly.\n\n| Rate Limiter Type | Use Case | Configuration Parameters |\n|-------------------|----------|-------------------------|\n| `GlobalRateLimiter` | System-wide protection | tokens_per_second, burst_capacity, backpressure_threshold |\n| `LoggerRateLimiter` | Per-component limits | logger_name, max_rate, inheritance_factor |\n| `LevelRateLimiter` | Per-severity limits | log_level, rate_multiplier, priority_boost |\n| `CorrelationRateLimiter` | Per-request limits | correlation_pattern, request_budget, spillover_handling |\n\n**Asynchronous Handler Dispatch**\n\nAsynchronous handler dispatch decouples log entry processing from application thread execution, preventing slow output destinations from blocking application performance. Think of async dispatch as a restaurant kitchen where orders are placed on a queue and prepared by dedicated cooks, allowing waiters to continue serving customers without waiting for each dish to be completed. This architectural pattern ensures that logging operations never block application threads, even when writing to slow destinations like remote collectors or network file systems.\n\nThe `AsyncHandler` maintains internal queues for each output destination and uses dedicated worker threads to process log entries in the background. Queue sizing and backpressure handling prevent memory exhaustion during traffic spikes, while priority queues ensure that high-severity log entries are processed first during congestion. The async system preserves ordering guarantees within each correlation context while allowing parallel processing across different requests.\n\n> **Critical Design Insight**: Async dispatch introduces complexity around system shutdown and error propagation. The shutdown sequence must drain queues gracefully while the error handling system needs to surface async failures without blocking the main application flow.\n\n| Async Component | Threading Model | Queue Management |\n|-----------------|-----------------|------------------|\n| `AsyncHandler` | Single worker per handler | Bounded blocking queue, overflow to disk |\n| `BatchingHandler` | Periodic flush thread | Time and size-based batching, compression |\n| `PriorityHandler` | Priority queue worker | Level-based ordering, starvation prevention |\n| `ShutdownManager` | Graceful termination | Queue draining, timeout handling, force shutdown |\n\n⚠️ **Pitfall: Queue Memory Explosion**\nUnder extreme load, async queues can consume unbounded memory if not properly configured. Implement overflow-to-disk mechanisms and queue size limits with backpressure signaling to prevent out-of-memory conditions. Monitor queue depths and implement alerting when queues approach capacity limits.\n\n### Advanced Output Destinations\n\nProduction logging systems must integrate with enterprise infrastructure including search engines, metrics systems, and distributed tracing platforms. Think of advanced output destinations as specialized delivery services: while basic handlers are like local mail delivery, these advanced destinations are like express shipping to international locations with customs processing and tracking integration. Each destination has unique requirements for data format, authentication, batching, and error handling.\n\nThe `Handler` abstraction established in the core design provides a clean integration point for these advanced destinations. Each advanced handler implements the same `handle(record)` interface while internally managing the complexity of external system integration. This consistency ensures that advanced destinations can be mixed and matched with basic handlers, allowing applications to send the same log stream to multiple destinations simultaneously.\n\n**Elasticsearch Integration**\n\nElasticsearch integration transforms the logging system into a powerful search and analytics platform by indexing log entries for real-time querying and dashboard visualization. Think of Elasticsearch as a library cataloging system that not only stores books but also creates detailed indexes by subject, author, and keyword, enabling researchers to find exactly what they need instantly. The Elasticsearch handler maps structured log entries to JSON documents with appropriate field mappings and index lifecycle management.\n\nThe `ElasticsearchHandler` batches log entries into bulk index operations to maximize throughput while managing index templates and field mappings automatically. Index rotation strategies partition log data by time period, enabling efficient storage management and query performance. The handler integrates with the circuit breaker pattern to handle Elasticsearch cluster outages gracefully while buffering entries for retry when connectivity is restored.\n\n| Elasticsearch Component | Purpose | Configuration Options |\n|-------------------------|---------|---------------------|\n| `ElasticsearchHandler` | Bulk indexing | batch_size, flush_interval, index_template |\n| `IndexManager` | Lifecycle management | rotation_policy, retention_days, shard_count |\n| `MappingGenerator` | Schema creation | field_types, analyzers, dynamic_mapping |\n| `BulkProcessor` | Batch optimization | max_batch_bytes, concurrent_requests, retry_policy |\n\n> **Decision: Index Rotation Strategy**\n> - **Context**: Log data accumulates rapidly and requires different retention policies based on age and importance\n> - **Options Considered**: Single large index, daily rotation, size-based rotation\n> - **Decision**: Implement daily index rotation with configurable retention policies\n> - **Rationale**: Daily rotation provides optimal balance between query performance and operational simplicity, while enabling different retention policies for different log levels\n> - **Consequences**: Enables efficient storage management and fast query performance while requiring index template management and automated cleanup processes\n\n**Metrics Integration**\n\nMetrics integration extracts quantitative signals from log entries to populate time-series databases and alerting systems. Think of metrics integration as transforming narrative log entries into numerical health indicators, similar to how a doctor extracts vital signs from patient observations. The metrics system counts log entries by level and logger, measures request durations from correlation context, and creates custom metrics from structured log fields.\n\nThe `MetricsHandler` analyzes log entries in real-time to emit counter, gauge, and histogram metrics to systems like Prometheus, StatsD, or CloudWatch. Metric extraction rules are configurable, allowing applications to define custom metrics based on log content without modifying application code. The metrics system provides immediate visibility into application health and performance trends that complement the detailed log analysis capabilities.\n\n| Metrics Component | Metric Types | Export Destinations |\n|-------------------|--------------|-------------------|\n| `MetricsExtractor` | Counter, Gauge, Histogram | Field parsing, aggregation rules, labeling strategy |\n| `PrometheusHandler` | Time-series metrics | /metrics endpoint, push gateway, service discovery |\n| `StatsDHandler` | Real-time metrics | UDP transport, metric namespacing, sampling support |\n| `CloudWatchHandler` | Cloud metrics | AWS API integration, custom namespaces, dimension mapping |\n\n**Distributed Tracing Integration**\n\nDistributed tracing integration connects log entries to trace spans and enables correlation across service boundaries in microservice architectures. Think of distributed tracing as creating a GPS tracking system for requests as they travel through multiple services, with log entries serving as detailed checkpoints along the journey. The tracing integration adds span context to log entries and creates trace annotations from log content.\n\nThe `TracingHandler` extracts trace context from correlation IDs and injects trace metadata into log entries for cross-system correlation. When integrated with systems like Jaeger or Zipkin, log entries become searchable annotations within trace visualizations, providing detailed context for performance analysis and debugging. The handler creates trace spans for long-running operations identified through log patterns and correlation timing.\n\n| Tracing Component | Integration Method | Context Propagation |\n|-------------------|-------------------|-------------------|\n| `OpenTelemetryHandler` | OTEL protocol | W3C trace context, baggage propagation |\n| `JaegerHandler` | Jaeger client | Uber trace header, span annotations |\n| `ZipkinHandler` | Zipkin protocol | B3 propagation, span creation from logs |\n| `TraceContextManager` | Context injection | Cross-service correlation, timing extraction |\n\n### Configuration Management\n\nProduction logging systems require sophisticated configuration management to adapt to changing operational requirements without service restarts. Think of configuration management as the control tower for an airport, continuously adjusting flight paths, runway assignments, and traffic patterns based on weather, equipment status, and traffic volume. The configuration system must handle real-time updates, environment-specific settings, and complex inheritance hierarchies while maintaining system stability.\n\nThe core design's registry pattern and hierarchical structure provide the foundation for advanced configuration capabilities. The `LoggerRegistry` can be extended to support dynamic reconfiguration, while the inheritance system enables sophisticated configuration layering. Configuration changes propagate through the logger hierarchy automatically while preserving thread safety and avoiding configuration drift between components.\n\n> **Decision: Configuration Hot-Reload Strategy**\n> - **Context**: Production systems require configuration changes without service restart to handle incidents and adjust verbosity dynamically\n> - **Options Considered**: File watching, API endpoints, configuration service polling\n> - **Decision**: Implement multi-source configuration with API-driven hot reload and file watching fallback\n> - **Rationale**: API endpoints enable programmatic configuration during incidents while file watching provides declarative configuration management for normal operations\n> - **Consequences**: Enables rapid response to production issues while requiring additional API security and configuration validation logic\n\n**Dynamic Reconfiguration System**\n\nDynamic reconfiguration allows logging behavior to change at runtime without service restarts, enabling rapid response to production incidents and performance optimization. The reconfiguration system validates configuration changes before applying them, ensuring that invalid configurations don't disrupt logging operations. Configuration changes are applied atomically across all affected loggers to prevent inconsistent states during transitions.\n\nThe `ConfigurationManager` coordinates configuration updates across multiple sources and applies changes through a phased rollout process. Validation rules prevent configurations that would cause performance problems or break system invariants. The system maintains configuration history and rollback capabilities to recover from problematic changes quickly.\n\n| Configuration Component | Responsibility | Validation Rules |\n|------------------------|----------------|------------------|\n| `ConfigurationManager` | Change coordination | Atomicity, consistency, rollback support |\n| `ValidationEngine` | Safety checking | Level hierarchy, handler validity, resource limits |\n| `ChangeApplicator` | Update execution | Logger traversal, handler reconfiguration, cache invalidation |\n| `ConfigurationHistory` | Audit trail | Change tracking, rollback support, compliance logging |\n\n**Environment-Based Configuration**\n\nEnvironment-based configuration adapts logging behavior automatically based on deployment context, ensuring that development, staging, and production environments have appropriate logging policies without manual configuration management. The environment system detects deployment context through environment variables, service discovery, or configuration files and applies environment-specific overlays to base configurations.\n\nDifferent environments have fundamentally different logging needs: development requires verbose output with pretty formatting, staging needs production-like structured logging with extended retention, and production requires optimized performance with security-conscious field filtering. The environment system manages these differences through layered configuration that inherits base settings while overriding environment-specific concerns.\n\n| Environment Type | Configuration Priorities | Typical Settings |\n|------------------|-------------------------|------------------|\n| `Development` | Readability, debugging | Pretty formatting, DEBUG level, console output |\n| `Staging` | Production simulation | JSON formatting, INFO level, file + remote |\n| `Production` | Performance, security | Optimized JSON, WARN level, filtered fields |\n| `Testing` | Determinism, isolation | Structured output, captured handlers, no external systems |\n\n⚠️ **Pitfall: Configuration Drift**\nEnvironment-specific configurations can drift over time, leading to difficult-to-reproduce issues where bugs only appear in specific environments. Implement configuration validation tests that verify environment configurations produce expected behavior and maintain configuration documentation that explains environment-specific choices.\n\n**Configuration File Formats**\n\nConfiguration file support enables declarative logging setup through YAML, JSON, or TOML files that define logger hierarchies, handler configurations, and formatter settings. Configuration files provide version-controlled logging policies that can be reviewed, tested, and deployed through standard infrastructure processes. The file format supports templating and environment variable substitution for flexible deployment scenarios.\n\nThe configuration parser validates file syntax and semantic correctness before applying changes, preventing invalid configurations from disrupting logging operations. Configuration files support includes and inheritance, enabling modular configuration that can be composed for different deployment scenarios. The system watches configuration files for changes and applies updates automatically when files are modified.\n\n| Format | Strengths | Use Cases |\n|--------|-----------|-----------|\n| `YAML` | Human-readable, comments | Development configuration, documentation |\n| `JSON` | Machine-readable, validation | API-driven configuration, service discovery |\n| `TOML` | Type-safe, structured | Production configuration, complex hierarchies |\n| `Environment Variables` | Container-friendly, simple | Docker deployment, cloud platforms |\n\n> **Advanced Configuration Architecture**: The configuration system supports layered composition where base configurations provide common settings and environment-specific overlays add contextual modifications. This pattern enables maintainable configuration that avoids duplication while supporting diverse deployment requirements.\n\n### Implementation Guidance\n\nThe future extensions build upon the solid foundation established in the core milestones while adding sophisticated capabilities for production environments. These extensions demonstrate the value of forward-looking architectural design that anticipates growth requirements without over-engineering the initial implementation.\n\n**Technology Recommendations**\n\n| Extension Category | Simple Option | Advanced Option |\n|-------------------|---------------|-----------------|\n| Performance Monitoring | Built-in metrics collection | Prometheus + Grafana integration |\n| Elasticsearch Integration | HTTP client + JSON serialization | Official Elasticsearch Python client |\n| Configuration Management | File watching + JSON parsing | etcd/Consul + configuration service |\n| Async Processing | Threading module + queues | asyncio + aiohttp for async handlers |\n| Load Testing | Manual threading tests | Locust or Artillery for realistic load |\n\n**Recommended Module Structure**\n\nThese extensions integrate cleanly into the existing project structure while maintaining clear separation of concerns:\n\n```\nproject-root/\n├── core/\n│   ├── logger.py              ← Core logger from Milestone 1\n│   ├── formatters.py          ← JSON formatters from Milestone 2\n│   └── context.py             ← Context system from Milestone 3\n├── handlers/\n│   ├── basic.py               ← File/Console handlers from core milestones\n│   ├── elasticsearch.py      ← Elasticsearch integration\n│   ├── metrics.py             ← Metrics extraction handlers\n│   └── tracing.py             ← Distributed tracing integration\n├── performance/\n│   ├── sampling.py            ← Adaptive sampling logic\n│   ├── rate_limiting.py       ← Token bucket rate limiters\n│   └── async_dispatch.py      ← Asynchronous handler dispatch\n├── config/\n│   ├── manager.py             ← Dynamic configuration management\n│   ├── validation.py          ← Configuration safety checking\n│   └── environments.py       ← Environment-specific configuration\n└── extensions/\n    ├── load_testing.py        ← Performance testing utilities\n    └── monitoring.py          ← Extension health monitoring\n```\n\n**Performance Optimization Starter Code**\n\n```python\nimport threading\nimport time\nimport random\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass\nfrom core.handlers import BaseHandler\nfrom core.records import LogRecord\n\n@dataclass\nclass SamplingConfig:\n    \"\"\"Configuration for adaptive sampling behavior.\"\"\"\n    base_sample_rate: float = 1.0\n    max_sample_rate: float = 1.0\n    min_sample_rate: float = 0.01\n    adaptation_window: int = 60  # seconds\n    importance_boost: Dict[str, float] = None\n    \n    def __post_init__(self):\n        if self.importance_boost is None:\n            self.importance_boost = {\n                'ERROR': 10.0,\n                'FATAL': 100.0,\n                'WARN': 2.0\n            }\n\nclass TokenBucketRateLimiter:\n    \"\"\"Thread-safe token bucket rate limiter for smooth rate limiting.\"\"\"\n    \n    def __init__(self, tokens_per_second: float, burst_capacity: int):\n        self.tokens_per_second = tokens_per_second\n        self.burst_capacity = burst_capacity\n        self._tokens = float(burst_capacity)\n        self._last_update = time.time()\n        self._lock = threading.Lock()\n    \n    def acquire(self, tokens: int = 1) -> bool:\n        \"\"\"\n        Attempt to acquire the specified number of tokens.\n        Returns True if tokens were acquired, False if rate limited.\n        \"\"\"\n        with self._lock:\n            now = time.time()\n            # TODO 1: Calculate tokens to add based on time elapsed\n            # TODO 2: Add tokens to bucket without exceeding burst capacity\n            # TODO 3: Check if enough tokens available for request\n            # TODO 4: Deduct tokens if available and return success\n            # TODO 5: Return False if insufficient tokens (rate limited)\n            pass\n\nclass AdaptiveSampler:\n    \"\"\"Intelligent sampling that adapts to load and preserves important events.\"\"\"\n    \n    def __init__(self, config: SamplingConfig):\n        self.config = config\n        self._current_rate = config.base_sample_rate\n        self._decision_cache: Dict[str, bool] = {}\n        self._load_monitor = LoadMonitor()\n        self._lock = threading.RLock()\n        \n    def should_sample(self, record: LogRecord) -> bool:\n        \"\"\"\n        Determine if this log record should be sampled (kept).\n        Uses correlation ID for consistent sampling decisions.\n        \"\"\"\n        # TODO 1: Check if correlation ID already has cached decision\n        # TODO 2: Calculate importance multiplier based on log level\n        # TODO 3: Get current system load from load monitor\n        # TODO 4: Adjust sampling rate based on load and importance\n        # TODO 5: Make deterministic decision based on correlation ID hash\n        # TODO 6: Cache decision for correlation ID consistency\n        # TODO 7: Return sampling decision\n        pass\n    \n    def _calculate_adaptive_rate(self, base_importance: float, system_load: float) -> float:\n        \"\"\"Calculate sampling rate based on importance and system load.\"\"\"\n        # TODO: Implement adaptive rate calculation\n        # Hint: Higher load should reduce sampling rate, higher importance should increase it\n        pass\n\nclass LoadMonitor:\n    \"\"\"Monitor system load to inform sampling decisions.\"\"\"\n    \n    def __init__(self, measurement_window: int = 30):\n        self.measurement_window = measurement_window\n        self._cpu_samples = []\n        self._memory_samples = []\n        self._lock = threading.Lock()\n        self._monitoring = False\n        \n    def get_current_load(self) -> Dict[str, float]:\n        \"\"\"Get current system load metrics.\"\"\"\n        # TODO 1: Collect current CPU usage\n        # TODO 2: Collect current memory usage  \n        # TODO 3: Calculate average over measurement window\n        # TODO 4: Return normalized load values (0.0 to 1.0)\n        pass\n```\n\n**Elasticsearch Handler Infrastructure**\n\n```python\nimport json\nimport threading\nimport time\nfrom datetime import datetime, timezone\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom core.handlers import BaseHandler\nfrom core.records import LogRecord\n\n@dataclass\nclass ElasticsearchConfig:\n    \"\"\"Configuration for Elasticsearch integration.\"\"\"\n    hosts: List[str]\n    index_prefix: str = \"logs\"\n    batch_size: int = 100\n    flush_interval: float = 5.0\n    max_retries: int = 3\n    timeout: float = 30.0\n    \nclass BulkProcessor:\n    \"\"\"Efficient bulk processing for Elasticsearch indexing.\"\"\"\n    \n    def __init__(self, config: ElasticsearchConfig, client):\n        self.config = config\n        self.client = client\n        self._batch_buffer: List[Dict[str, Any]] = []\n        self._batch_lock = threading.Lock()\n        self._last_flush = time.time()\n        \n    def add_document(self, record: LogRecord) -> None:\n        \"\"\"Add log record to batch buffer for bulk indexing.\"\"\"\n        document = {\n            '_index': self._generate_index_name(record),\n            '_source': record.to_dict()\n        }\n        \n        with self._batch_lock:\n            # TODO 1: Add document to batch buffer\n            # TODO 2: Check if batch is full or flush interval exceeded\n            # TODO 3: Trigger flush if either condition met\n            # TODO 4: Handle buffer overflow protection\n            pass\n    \n    def _generate_index_name(self, record: LogRecord) -> str:\n        \"\"\"Generate time-based index name for log record.\"\"\"\n        # TODO: Create index name like \"logs-app-2023-12-01\"\n        # Hint: Use record timestamp and config.index_prefix\n        pass\n    \n    def flush_batch(self) -> bool:\n        \"\"\"Flush current batch to Elasticsearch.\"\"\"\n        with self._batch_lock:\n            if not self._batch_buffer:\n                return True\n                \n            # TODO 1: Copy current batch and clear buffer\n            # TODO 2: Execute bulk index operation\n            # TODO 3: Handle partial failures and retries\n            # TODO 4: Update last flush timestamp\n            # TODO 5: Return success status\n            pass\n\nclass ElasticsearchHandler(BaseHandler):\n    \"\"\"Handler that indexes log records to Elasticsearch for search and analytics.\"\"\"\n    \n    def __init__(self, config: ElasticsearchConfig):\n        super().__init__(name=\"elasticsearch\")\n        self.config = config\n        self._client = None  # TODO: Initialize Elasticsearch client\n        self._bulk_processor = BulkProcessor(config, self._client)\n        \n    def _write_record(self, record: LogRecord) -> None:\n        \"\"\"Write log record to Elasticsearch via bulk processor.\"\"\"\n        # TODO 1: Validate Elasticsearch client connection\n        # TODO 2: Add record to bulk processor\n        # TODO 3: Handle connection errors gracefully\n        # TODO 4: Implement circuit breaker logic for outages\n        pass\n```\n\n**Configuration Management Core**\n\n```python\nimport threading\nimport json\nimport yaml\nfrom typing import Dict, Any, Optional, Callable\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom core.logger import LoggerRegistry\n\n@dataclass\nclass ConfigurationChange:\n    \"\"\"Represents a configuration change with validation and rollback info.\"\"\"\n    change_id: str\n    timestamp: float\n    changes: Dict[str, Any]\n    previous_values: Dict[str, Any]\n    source: str  # \"file\", \"api\", \"environment\"\n    \nclass ConfigurationValidator:\n    \"\"\"Validates configuration changes before applying them.\"\"\"\n    \n    def __init__(self):\n        self._validation_rules: List[Callable[[Dict[str, Any]], List[str]]] = []\n        self._register_default_rules()\n    \n    def validate_configuration(self, config: Dict[str, Any]) -> List[str]:\n        \"\"\"\n        Validate configuration and return list of errors.\n        Empty list means configuration is valid.\n        \"\"\"\n        errors = []\n        # TODO 1: Run all validation rules against configuration\n        # TODO 2: Collect all validation errors from rules\n        # TODO 3: Check for configuration consistency\n        # TODO 4: Validate resource limits and constraints\n        # TODO 5: Return comprehensive error list\n        return errors\n    \n    def _register_default_rules(self):\n        \"\"\"Register built-in validation rules.\"\"\"\n        # TODO: Add validation rules for log levels, handler configs, etc.\n        pass\n\nclass ConfigurationManager:\n    \"\"\"Manages dynamic configuration updates with validation and rollback.\"\"\"\n    \n    def __init__(self, logger_registry: LoggerRegistry):\n        self.logger_registry = logger_registry\n        self._current_config: Dict[str, Any] = {}\n        self._config_history: List[ConfigurationChange] = []\n        self._validator = ConfigurationValidator()\n        self._lock = threading.RLock()\n        \n    def apply_configuration(self, new_config: Dict[str, Any], source: str = \"api\") -> bool:\n        \"\"\"\n        Apply new configuration with validation and rollback support.\n        Returns True if configuration was applied successfully.\n        \"\"\"\n        with self._lock:\n            # TODO 1: Validate new configuration\n            # TODO 2: Create configuration change record\n            # TODO 3: Apply changes atomically\n            # TODO 4: Update logger registry\n            # TODO 5: Handle rollback on failure\n            # TODO 6: Update configuration history\n            pass\n    \n    def rollback_to_previous(self) -> bool:\n        \"\"\"Rollback to the previous configuration.\"\"\"\n        # TODO 1: Find most recent configuration change\n        # TODO 2: Apply previous values\n        # TODO 3: Validate rollback configuration\n        # TODO 4: Update logger registry\n        # TODO 5: Record rollback in history\n        pass\n```\n\n**Milestone Checkpoints**\n\nAfter implementing performance optimizations:\n- Run `python -m performance.load_test` to generate high log volume\n- Verify that sampling reduces output volume proportionally\n- Check that rate limiting prevents resource exhaustion\n- Confirm async dispatch doesn't block application threads\n\nAfter implementing Elasticsearch integration:\n- Start local Elasticsearch instance\n- Send log entries through `ElasticsearchHandler`\n- Query Elasticsearch to verify proper indexing and field mapping\n- Test index rotation and retention policies\n\nAfter implementing configuration management:\n- Modify configuration files and verify hot reload\n- Use API to change log levels without restart\n- Test configuration validation with invalid settings\n- Verify rollback functionality restores previous behavior\n\n**Common Extension Pitfalls**\n\n⚠️ **Pitfall: Elasticsearch Connection Pooling**\nElasticsearch handlers can exhaust connection pools under high load. Implement proper connection pooling with limits and timeouts. Use circuit breakers to prevent cascade failures when Elasticsearch is unavailable.\n\n⚠️ **Pitfall: Configuration Race Conditions**\nConcurrent configuration updates can create inconsistent states. Use proper locking and atomic updates. Validate that configuration changes don't conflict with ongoing operations.\n\n⚠️ **Pitfall: Async Queue Memory Leaks**\nUnbounded async queues consume memory indefinitely under sustained load. Implement queue size limits, overflow handling, and backpressure mechanisms. Monitor queue depths and implement alerting.\n\n⚠️ **Pitfall: Sampling Bias**\nPoor sampling strategies can lose critical debugging information. Ensure error logs are never sampled, maintain complete traces for sampled requests, and implement importance-based sampling that preserves context around failures.\n\n\n## Glossary\n\n> **Milestone(s):** This section provides essential terminology definitions that support all three milestones, with foundational terms like structured logging and log levels supporting Milestone 1 (Logger Core), JSON formatting and serialization terms supporting Milestone 2 (Structured Output), and correlation ID and context propagation terms supporting Milestone 3 (Context & Correlation).\n\nThis glossary provides precise definitions of all key terms used throughout the structured logging system design. Think of this glossary as the shared vocabulary that enables clear communication between team members - just as air traffic controllers use standardized terminology to prevent miscommunication during critical operations, we need consistent definitions to avoid ambiguity when discussing logging system components and behaviors.\n\nEach term is defined with its specific meaning within the context of this logging system, including how it relates to other components and what behaviors it encompasses. The definitions progress from foundational concepts to more specialized terminology, building a comprehensive understanding of the system's vocabulary.\n\n### Core Logging Concepts\n\n**Structured Logging**: A logging approach that produces machine-readable output with consistent, queryable field structure rather than free-form text messages. Unlike traditional string-based logging where information is embedded in unstructured text, structured logging separates message content from contextual metadata, enabling automated log analysis, filtering, and correlation. Each log record contains well-defined fields such as timestamp, level, message, and arbitrary context data serialized in a standardized format like JSON.\n\n**Log Level**: A numeric severity indicator that determines the importance and urgency of a log message. The system uses five standard levels with specific numeric values: `DEBUG` (10) for detailed diagnostic information useful during development, `INFO` (20) for general informational messages about normal system operation, `WARN` (30) for potentially problematic situations that don't prevent continued operation, `ERROR` (40) for error conditions that affect specific operations but don't halt the entire system, and `FATAL` (50) for critical errors that may cause system shutdown. Log levels enable filtering where messages below a configured threshold are suppressed to reduce noise.\n\n**Log Level Filtering**: The mechanism for suppressing log messages below a configured severity threshold to control output volume and focus on relevant information. When a logger's minimum level is set to `WARN`, for example, only messages at `WARN`, `ERROR`, and `FATAL` levels are processed, while `DEBUG` and `INFO` messages are discarded before any formatting or output processing occurs. This filtering happens early in the logging pipeline to minimize performance impact from unwanted messages.\n\n**Logger**: The primary interface through which application code generates log messages, maintaining configuration such as name, minimum level, output handlers, and contextual information. Loggers are organized in a hierarchical tree structure where child loggers inherit configuration from their parents unless explicitly overridden. Each logger processes incoming messages by checking level thresholds, enriching records with context, applying formatting, and dispatching to configured output destinations.\n\n**Logger Hierarchy**: A tree structure of parent-child logger relationships that enables organized configuration management and context inheritance. Loggers are typically named using dot-separated paths like `com.example.service.database` where each segment represents a level in the hierarchy. Child loggers automatically inherit configuration settings like minimum level and output handlers from their parents, but can override these settings locally. This hierarchy prevents configuration duplication and provides logical organization matching application structure.\n\n### Data Structures and Records\n\n**LogRecord**: The fundamental data structure representing a single log event, containing all information needed to format and output the message. A LogRecord includes the timestamp when the event occurred, the numeric log level, the primary message text, the name of the originating logger, and a dictionary of contextual key-value pairs. LogRecords are immutable once created to ensure consistency across multiple output handlers and prevent accidental modification during processing.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `timestamp` | str | ISO 8601 formatted UTC timestamp when the log event occurred |\n| `level` | int | Numeric log level indicating message severity (10-50 range) |\n| `message` | str | Primary descriptive text explaining what happened |\n| `logger_name` | str | Hierarchical name of the logger that created this record |\n| `context` | Dict[str, Any] | Additional key-value pairs providing contextual information |\n\n**Context**: A dictionary of key-value pairs that provides additional contextual information about the environment, request, or operation when a log event occurs. Context data automatically propagates through nested function calls and is inherited by child loggers, eliminating the need to manually pass contextual information through method parameters. Context fields commonly include correlation IDs, user identifiers, request URLs, database connection details, and business-specific metadata that aids in log analysis and debugging.\n\n**Correlation ID**: A unique identifier that links related log entries across service boundaries, function calls, and asynchronous operations within the same logical request or transaction. Correlation IDs are typically generated at request entry points and automatically injected into every log record within that request scope. This enables distributed tracing where logs from multiple services, components, or threads can be correlated to understand the complete flow of a user request through the system.\n\n### Output and Formatting\n\n**Handler**: An abstract component responsible for delivering formatted log records to a specific output destination such as standard output, files, remote logging services, or databases. Each handler operates independently with its own error recovery, buffering, and retry logic to ensure that failures in one output destination don't affect others. Handlers can filter records based on level or content, apply destination-specific formatting, and implement circuit breaker patterns to handle temporary outages gracefully.\n\n**Handler Dispatch**: The routing mechanism that delivers log records to one or more configured output handlers, ensuring that each handler receives a copy of the record for independent processing. The dispatch system handles concurrent access safely, manages handler failures through circuit breakers, and maintains buffer queues for temporary storage when handlers are unavailable. Failed handlers are automatically retried with exponential backoff while continuing to serve working destinations.\n\n**Formatter**: A component that converts LogRecord objects into formatted strings suitable for output to specific destinations. Formatters implement different output styles such as single-line JSON for machine processing, colored console output for human readability during development, or custom formats required by specific log aggregation systems. The formatter system supports pluggable architecture where custom formatters can be registered and selected by name.\n\n**JSON Formatter**: A concrete formatter implementation that serializes LogRecord objects as single-line JSON strings with consistent field ordering and proper handling of complex data types. The JSON formatter includes circular reference protection to prevent infinite loops when serializing objects that reference themselves, automatic timestamp formatting, and configurable field inclusion/exclusion. Output is optimized for log aggregation systems that expect one JSON object per line.\n\n**Pretty Formatter**: A human-readable formatter designed for development and debugging that produces colored, indented output optimized for console viewing. Pretty formatters automatically detect terminal color capabilities, apply syntax highlighting to different log levels, format timestamps in human-friendly formats, and optionally pretty-print JSON context data with indentation. This formatter prioritizes readability over machine processing efficiency.\n\n### Context Management and Propagation\n\n**Context Propagation**: The mechanism for automatically carrying contextual information through nested function calls, asynchronous operations, and service boundaries without requiring explicit parameter passing. Context propagation uses thread-local storage for synchronous code and async-local storage for asynchronous operations, ensuring that context fields set at request entry points are available throughout the entire request processing pipeline.\n\n**Ambient Context**: Contextual information that is automatically available anywhere within the current execution scope without being explicitly passed through method parameters. Ambient context includes correlation IDs, user session data, request metadata, and business context that was established earlier in the call chain. This pattern eliminates the need to modify function signatures throughout the codebase when adding new contextual information.\n\n**Context Inheritance**: The behavior where child contexts automatically inherit all key-value pairs from their parent contexts and can add additional fields without affecting the parent. When a function creates a nested logging context, it receives all fields from the current context plus any new fields it adds locally. Changes made in child contexts are isolated and don't propagate back to parent contexts, ensuring proper scoping and preventing side effects.\n\n**Async Context Bridge**: Infrastructure that preserves logging context when crossing asynchronous operation boundaries such as task creation, coroutine execution, and callback invocation. The bridge automatically captures the current context when async operations are initiated and restores that context when the async code executes, ensuring that correlation IDs and contextual information remain available throughout the entire request processing flow regardless of thread switches or event loop scheduling.\n\n### Thread Safety and Concurrency\n\n**Thread Safety**: The property that logging operations produce correct results when called concurrently from multiple threads without external synchronization. Thread-safe logging ensures that log records are not corrupted, context information is not mixed between threads, and internal data structures remain consistent under concurrent access. This is achieved through careful locking, immutable data structures, and atomic operations on shared state.\n\n**Race Condition**: A concurrency bug where the correctness of logging operations depends on the relative timing of thread execution, potentially leading to corrupted output, mixed log records, or inconsistent context information. Common race conditions in logging systems include context corruption when multiple threads modify shared context simultaneously, interleaved output when multiple threads write to the same destination, and inconsistent state when logger configuration changes occur concurrently with logging operations.\n\n**Immutability**: The design principle where LogRecord objects and context dictionaries cannot be modified after creation, preventing accidental changes that could corrupt logs or create race conditions. Immutable objects can be safely shared between multiple handlers and threads without synchronization overhead. When context changes are needed, new immutable objects are created rather than modifying existing ones.\n\n### Error Handling and Recovery\n\n**Circuit Breaker Pattern**: An error handling mechanism that prevents cascade failures by automatically disabling failed handlers and periodically attempting recovery. When a handler experiences consecutive failures exceeding a configured threshold, the circuit breaker opens and stops sending records to that handler while allowing other handlers to continue operating normally. The circuit breaker periodically attempts to close by testing the failed handler, automatically resuming normal operation when the handler recovers.\n\n**Graceful Degradation**: The system's ability to maintain partial functionality when individual components fail, ensuring that logging continues to work even when some output destinations are unavailable. Failed file handlers fall back to console output, failed network handlers buffer records locally for later retry, and serialization failures are logged with simplified fallback representations rather than crashing the application.\n\n**Handler Isolation**: The design principle that failures in one output handler do not affect the operation of other handlers or the logging system as a whole. Each handler maintains independent error state, recovery logic, and buffer management. When one handler fails, other handlers continue processing records normally, and the failed handler can recover independently without affecting system-wide logging operation.\n\n**Safe Serialization**: JSON encoding with protection against edge cases that could cause failures or infinite loops, including circular references, non-serializable objects, and excessively large data structures. Safe serialization detects circular references and replaces them with reference markers, converts non-serializable objects to string representations, and truncates large objects to prevent memory exhaustion while preserving essential information.\n\n### Performance and Optimization\n\n**Buffer Management**: Intelligent queuing of log records when output handlers are temporarily unavailable, with configurable size limits and memory usage controls to prevent unbounded growth. Buffered records are automatically delivered when handlers recover, with oldest records discarded if buffer limits are exceeded. Buffer management includes both in-memory queues for short-term outages and persistent storage for longer-term handler failures.\n\n**Level Filtering Optimization**: Early rejection of log messages below the configured threshold before expensive operations like context enrichment, formatting, or serialization occur. Level filtering uses numeric comparison for efficiency and caches effective levels after walking the logger hierarchy to avoid repeated parent traversal. This optimization ensures that disabled log levels have minimal performance impact.\n\n**Lazy Evaluation**: Deferring expensive operations like complex context serialization, timestamp formatting, or message string formatting until they are actually needed by an active handler. If no handlers are configured or all handlers reject a message due to level filtering, expensive formatting operations are skipped entirely, improving performance for disabled log levels.\n\n### Testing and Debugging\n\n**Milestone Checkpoints**: Concrete verification criteria that validate correct implementation after completing each development stage. Checkpoints specify expected behavior, output formats, performance characteristics, and error handling that should be observed when testing the implemented functionality. Each checkpoint includes specific test commands, expected results, and troubleshooting guidance for common implementation issues.\n\n**Integration Testing**: Comprehensive testing that verifies correct interaction between logging system components under realistic production conditions, including concurrent access, handler failures, context propagation across async boundaries, and end-to-end request tracing. Integration tests simulate real-world scenarios like network outages, disk full conditions, and high-concurrency load to ensure robust system behavior.\n\n**Trace Logging**: An internal debugging system that records the behavior of the logging infrastructure itself, providing visibility into handler dispatch, context propagation, error recovery, and performance characteristics. Trace logging helps diagnose issues like why certain log messages are not appearing, how context flows through the system, and where performance bottlenecks occur during high-volume logging.\n\n### Advanced Features\n\n**Adaptive Sampling**: Intelligent sampling that automatically adjusts log retention rates based on system load, message importance, and available resources to maintain performance while preserving critical information. Adaptive sampling uses algorithms that increase sampling rates for error conditions and correlation contexts while reducing rates for routine operational messages during high-load periods.\n\n**Rate Limiting**: Controlling logging throughput to prevent system overload during high-volume scenarios, using algorithms like token bucket rate limiting that allow burst capacity while maintaining sustainable average rates. Rate limiting can be applied per logger, per level, or per context to prevent specific components from overwhelming the logging system.\n\n**Dynamic Reconfiguration**: The ability to change logging behavior at runtime without restarting the application, including adjusting log levels, adding or removing handlers, modifying formatter settings, and updating context propagation rules. Dynamic reconfiguration enables responsive troubleshooting and performance tuning in production environments without service interruption.\n\n**Bulk Indexing**: Batching multiple log records into single operations for efficient delivery to external systems like Elasticsearch or database storage, reducing network overhead and improving throughput for high-volume logging scenarios. Bulk indexing includes automatic flushing based on time intervals or batch sizes, with retry logic for partial failures.\n\n### Implementation Guidance\n\nThe terminology defined above forms the foundation for implementing a production-grade structured logging system. Understanding these concepts and their relationships is essential for making correct design decisions and avoiding common implementation pitfalls.\n\n**Key Term Relationships:**\n\n| Primary Term | Related Terms | Relationship Description |\n|--------------|---------------|-------------------------|\n| `LogRecord` | `Context`, `LogLevel`, `Formatter` | LogRecord contains Context data, has a LogLevel, processed by Formatters |\n| `Logger` | `Logger Hierarchy`, `Handler Dispatch`, `Level Filtering` | Logger participates in hierarchy, dispatches to handlers, filters by level |\n| `Context` | `Context Propagation`, `Correlation ID`, `Context Inheritance` | Context propagates through calls, contains correlation ID, supports inheritance |\n| `Handler` | `Circuit Breaker`, `Buffer Management`, `Safe Serialization` | Handler uses circuit breaker, manages buffers, performs safe serialization |\n| `Formatter` | `JSON Formatter`, `Pretty Formatter`, `Safe Serialization` | Formatters are concrete implementations using safe serialization techniques |\n\n**Common Terminology Mistakes:**\n\n⚠️ **Pitfall: Confusing \"Context\" with \"Configuration\"**\nContext refers to runtime key-value data that describes the current execution environment (correlation IDs, user session, request metadata), while configuration refers to static settings that control logging behavior (minimum levels, handler settings, formatter choices). Context flows through application execution and changes frequently, while configuration is typically set at startup and changes infrequently.\n\n⚠️ **Pitfall: Misunderstanding \"Thread Safety\" vs \"Concurrent Performance\"**\nThread safety means operations produce correct results under concurrent access, which is a correctness requirement. Concurrent performance refers to how well the system scales under concurrent load, which is an efficiency consideration. A system can be thread-safe but perform poorly under concurrency due to excessive locking, or can have good concurrent performance but be thread-unsafe due to race conditions.\n\n⚠️ **Pitfall: Conflating \"Structured Logging\" with \"JSON Format\"**\nStructured logging is the architectural approach of separating message content from contextual metadata in consistent, queryable field structure. JSON is one possible serialization format for structured logs, but structured logging can also use formats like XML, Protocol Buffers, or custom binary formats. The key is consistent field structure, not the specific serialization mechanism.\n\nThis glossary provides the vocabulary foundation needed to understand, implement, and maintain the structured logging system. Refer back to these definitions when encountering unfamiliar terms in other sections of the design document.\n"}