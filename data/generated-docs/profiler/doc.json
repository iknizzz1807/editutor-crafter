{"html":"<h1 id=\"cpumemory-profiler-design-document\">CPU/Memory Profiler: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>This system builds a sampling profiler that captures call stacks at regular intervals and tracks memory allocations to help developers identify performance bottlenecks. The key architectural challenge is efficiently collecting profiling data with minimal overhead while providing rich visualization through flame graphs and allocation tracking.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones (1-4) — understanding why profiling is challenging and how existing solutions work</p>\n</blockquote>\n<p>Performance profiling represents one of the most challenging aspects of software engineering diagnostics. When applications run slowly, consume excessive memory, or exhibit unpredictable behavior, developers need tools to peer inside the running process and understand what is actually happening. However, this investigation process is fraught with complexity because the very act of observation can change the behavior being observed, similar to the observer effect in quantum physics. The profiler must gather detailed information about program execution while introducing minimal overhead, resolve cryptic memory addresses into meaningful function names, and present vast amounts of timing data in an intuitive visual format that reveals performance bottlenecks.</p>\n<p>The fundamental challenge lies in the <strong>observer paradox</strong>: profiling tools must be invasive enough to capture meaningful data but non-invasive enough to avoid distorting the very performance characteristics they seek to measure. A profiler that adds 50% overhead to the target application will hide the real performance problems behind its own instrumentation costs. Additionally, modern applications execute millions of function calls per second across multiple threads, dynamically load shared libraries, and allocate memory in complex patterns that span the entire program lifecycle. Capturing, processing, and interpreting this torrent of execution data requires sophisticated sampling strategies, efficient data structures, and clever visualization techniques.</p>\n<h3 id=\"mental-model-the-detective-analogy\">Mental Model: The Detective Analogy</h3>\n<p>Think of performance profiling as <strong>detective work investigating performance crimes</strong>. Just as a detective investigating a complex case must gather evidence without contaminating the crime scene, a profiler must collect execution evidence without significantly altering the program&#39;s behavior. The detective analogy illuminates several key aspects of profiling challenges:</p>\n<p><strong>Crime Scene Preservation</strong>: A detective cannot change the scene while investigating it, or they risk destroying crucial evidence. Similarly, a profiler cannot significantly slow down the target application or change its memory allocation patterns, as this would mask the original performance problems. The profiler must be a silent observer that captures authentic program behavior.</p>\n<p><strong>Evidence Collection Strategy</strong>: Detectives cannot be everywhere at once, so they must strategically choose when and where to look for clues. Profilers face the same constraint — they cannot capture every single function call and memory allocation without overwhelming overhead. Instead, they use <strong>sampling techniques</strong> to periodically &quot;photograph&quot; the program&#39;s state, much like a detective taking periodic surveillance photos to understand a suspect&#39;s routine.</p>\n<p><strong>Witness Testimony vs. Physical Evidence</strong>: In detective work, witness accounts can be unreliable, but physical evidence provides objective truth. Similarly, developers&#39; intuitions about where their programs spend time are often wrong (the equivalent of unreliable witness testimony), but stack sampling provides objective evidence of actual execution patterns. The profiler serves as an impartial witness that records what really happened.</p>\n<p><strong>Pattern Recognition</strong>: Detectives solve cases by identifying patterns across multiple pieces of evidence — the same person appearing at different crime scenes, similar methods used across incidents. Profilers reveal performance problems by identifying patterns across thousands of samples — the same function appearing frequently in stack traces indicates a performance hotspot, similar to how the same suspect appearing in multiple witness statements indicates involvement.</p>\n<p><strong>Timeline Reconstruction</strong>: Detectives often need to reconstruct the sequence of events leading to a crime. Memory profilers perform similar timeline reconstruction, tracking when memory was allocated and whether it was ever freed, to identify the sequence of events leading to memory leaks.</p>\n<p><strong>Multiple Investigation Techniques</strong>: Different crimes require different investigation approaches — financial crimes need accounting expertise, while violent crimes need forensic analysis. Similarly, different performance problems require different profiling approaches: CPU-bound issues need call stack sampling to find hot functions, while memory problems need allocation tracking to find leaks and excessive usage.</p>\n<p>This detective metaphor helps explain why profiling tools are complex: they must employ sophisticated evidence-gathering techniques, maintain objectivity under challenging conditions, and synthesize vast amounts of data into actionable insights about what really happened during program execution.</p>\n<h3 id=\"existing-profiling-solutions\">Existing Profiling Solutions</h3>\n<p>The profiling ecosystem offers numerous tools, each making different trade-offs between overhead, accuracy, ease of use, and the types of performance problems they can detect. Understanding these existing solutions helps clarify the design space and reveals why building a custom profiler requires careful architectural decisions.</p>\n<table>\n<thead>\n<tr>\n<th>Tool</th>\n<th>Profiling Method</th>\n<th>Overhead</th>\n<th>Target Problems</th>\n<th>Advantages</th>\n<th>Disadvantages</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Linux perf</strong></td>\n<td>Statistical sampling via hardware performance counters</td>\n<td>Very Low (1-5%)</td>\n<td>CPU hotspots, cache misses, branch predictions</td>\n<td>Hardware-assisted sampling, extremely low overhead, kernel integration</td>\n<td>Complex command-line interface, requires root privileges, difficult symbol resolution</td>\n</tr>\n<tr>\n<td><strong>gprof</strong></td>\n<td>Function entry/exit instrumentation</td>\n<td>High (10-40%)</td>\n<td>Function-level call counts and timing</td>\n<td>Built into GCC, detailed call graph analysis, deterministic profiling</td>\n<td>Requires recompilation, significant overhead, misses short-lived functions</td>\n</tr>\n<tr>\n<td><strong>Valgrind (Callgrind)</strong></td>\n<td>Dynamic binary instrumentation</td>\n<td>Very High (50-100x slowdown)</td>\n<td>Detailed instruction-level analysis, cache simulation</td>\n<td>Extremely detailed analysis, no recompilation needed, instruction-accurate</td>\n<td>Prohibitive overhead for production use, slow for large applications</td>\n</tr>\n<tr>\n<td><strong>Intel VTune</strong></td>\n<td>Hardware performance monitoring + sampling</td>\n<td>Low (5-15%)</td>\n<td>CPU optimization, threading issues, memory bottlenecks</td>\n<td>Professional-grade analysis, hardware vendor support, GUI interface</td>\n<td>Proprietary, Intel-specific features, expensive licensing</td>\n</tr>\n<tr>\n<td><strong>Python cProfile</strong></td>\n<td>Function call tracing via interpreter hooks</td>\n<td>Medium (20-50%)</td>\n<td>Python-specific hotspot identification</td>\n<td>Language-integrated, deterministic profiling, built-in standard library</td>\n<td>Python-only, cannot profile native extensions, interpreter overhead</td>\n</tr>\n<tr>\n<td><strong>Go pprof</strong></td>\n<td>Statistical sampling + runtime integration</td>\n<td>Low (1-5%)</td>\n<td>Go-specific CPU and memory profiling</td>\n<td>Language-integrated, production-safe, excellent tooling</td>\n<td>Go-specific, limited cross-language support, requires runtime cooperation</td>\n</tr>\n<tr>\n<td><strong>AddressSanitizer</strong></td>\n<td>Memory allocation tracking via compiler instrumentation</td>\n<td>High (50-100%)</td>\n<td>Memory safety bugs, buffer overflows, use-after-free</td>\n<td>Comprehensive memory error detection, precise error reporting</td>\n<td>Requires recompilation, significant memory overhead, not for production</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Key Insight</strong>: No single profiling tool excels at everything. Each tool represents a different point in the trade-off space between overhead and detail. Statistical samplers like <code>perf</code> provide low overhead but miss short-duration events, while instrumentation-based tools like <code>gprof</code> capture every event but introduce significant performance penalties.</p>\n</blockquote>\n<p><strong>Statistical Sampling Tools</strong> (<code>perf</code>, <code>pprof</code>) work by periodically interrupting the program and examining its current state. They achieve low overhead because they only &quot;look&quot; at the program occasionally, like taking random snapshots of a busy intersection to understand traffic patterns. However, they can miss events that happen between samples, and their accuracy depends on the sampling frequency — higher frequency means better accuracy but more overhead.</p>\n<p><strong>Instrumentation-Based Tools</strong> (<code>gprof</code>, <code>cProfile</code>) modify the program to record every function entry and exit, like installing security cameras at every doorway in a building. This provides complete coverage but requires either recompilation or runtime code modification, both of which add significant overhead. The trade-off is completeness versus performance impact.</p>\n<p><strong>Dynamic Analysis Tools</strong> (<code>Valgrind</code>) execute the program in a controlled virtual environment that can observe every instruction, like having a dedicated investigator watch every action a suspect takes. This provides the most detailed analysis possible but at the cost of extreme slowdown, making these tools unsuitable for production environments but invaluable for development-time debugging.</p>\n<p><strong>Hardware-Assisted Tools</strong> (<code>perf</code>, <code>VTune</code>) leverage specialized CPU features like performance monitoring units (PMUs) that can count events like cache misses, branch mispredictions, and instruction cycles with minimal software overhead. These tools represent the closest thing to &quot;free&quot; profiling, but they require hardware support and often need elevated privileges to access the performance counters.</p>\n<blockquote>\n<p><strong>Decision: Why Build a Custom Profiler?</strong></p>\n<ul>\n<li><strong>Context</strong>: Existing tools each excel in specific scenarios but lack comprehensive coverage across CPU profiling, memory tracking, and visualization in a single system</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Use existing tools like perf + Valgrind + custom scripts</li>\n<li>Extend an existing open-source profiler</li>\n<li>Build a new profiler from scratch</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Build a new profiler that combines statistical sampling for CPU profiling with allocation tracking for memory analysis</li>\n<li><strong>Rationale</strong>: This allows us to optimize the entire pipeline from data collection to visualization, implement consistent data formats across CPU and memory profiling, and provide a unified interface for both types of analysis. Educational value also comes from understanding the complete profiling pipeline.</li>\n<li><strong>Consequences</strong>: Higher implementation effort but better integration between components, customizable overhead/accuracy trade-offs, and deeper understanding of profiling fundamentals.</li>\n</ul>\n</blockquote>\n<p>The comparison reveals several gaps in existing solutions that motivate building a custom profiler:</p>\n<p><strong>Integration Challenges</strong>: Using multiple tools (e.g., <code>perf</code> for CPU profiling + <code>Valgrind</code> for memory analysis) requires correlating data from different sources with different sampling methodologies and output formats. Each tool has its own symbol resolution logic, data aggregation approach, and visualization format, making it difficult to get a unified view of application performance.</p>\n<p><strong>Overhead Customization</strong>: Most existing tools provide limited control over the overhead/accuracy trade-off. They either sample at fixed rates or require recompilation for instrumentation. A custom profiler can implement adaptive sampling rates, configurable overhead budgets, and hybrid approaches that combine sampling with targeted instrumentation.</p>\n<p><strong>Educational Value</strong>: Building a profiler from scratch reveals the fundamental challenges and design patterns that underlie all performance analysis tools. Understanding how to capture stack traces in signal handlers, resolve symbols from ELF binaries, and aggregate timing data into flame graphs provides deep insight into system programming and performance analysis techniques.</p>\n<p><strong>Specialized Use Cases</strong>: Custom profilers can be optimized for specific environments, programming languages, or performance problems that general-purpose tools handle poorly. For example, a profiler designed for web services might include HTTP request correlation, while a profiler for embedded systems might minimize memory usage for metadata storage.</p>\n<p>This analysis of existing solutions establishes the design requirements for our custom profiler: it must achieve low overhead through statistical sampling (like <code>perf</code>), provide comprehensive memory tracking (like <code>Valgrind</code>), generate intuitive visualizations (like flame graphs), and integrate all these capabilities in a single coherent system that developers can easily deploy and interpret.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section establishes the foundational understanding and technology choices that will guide the implementation of all subsequent components. The goal is to make informed decisions about the profiling approach and understand how it fits into the broader ecosystem of performance analysis tools.</p>\n<h4 id=\"technology-recommendations-table\">Technology Recommendations Table</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>CPU Profiling</strong></td>\n<td><code>signal</code>-based SIGPROF with fixed intervals</td>\n<td>Hardware performance counters via <code>/proc/</code> interfaces</td>\n</tr>\n<tr>\n<td><strong>Symbol Resolution</strong></td>\n<td>Basic ELF parsing with <code>objdump</code> fallback</td>\n<td>Full DWARF parser with line number support</td>\n</tr>\n<tr>\n<td><strong>Memory Tracking</strong></td>\n<td><code>LD_PRELOAD</code> malloc interception</td>\n<td><code>ptrace</code>-based system call interception</td>\n</tr>\n<tr>\n<td><strong>Data Storage</strong></td>\n<td>JSON files for samples and symbols</td>\n<td>SQLite database with indexed queries</td>\n</tr>\n<tr>\n<td><strong>Visualization</strong></td>\n<td>Static SVG generation with embedded JavaScript</td>\n<td>Interactive web application with real-time updates</td>\n</tr>\n<tr>\n<td><strong>Target Language</strong></td>\n<td>Python scripts and C programs</td>\n<td>Multi-language support (Python, C++, Go, Rust)</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-project-structure\">Recommended Project Structure</h4>\n<p>The profiler implementation should be organized to separate concerns clearly and allow independent development and testing of each component:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>cpu-memory-profiler/\n├── src/\n│   ├── sampler/              # Stack sampling implementation (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── signal_sampler.py    # SIGPROF-based sampling\n│   │   ├── stack_unwinder.py    # Frame pointer walking\n│   │   └── sample_storage.py    # Sample data structures\n│   ├── symbolizer/           # Symbol resolution (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── elf_parser.py        # ELF binary and symbol table parsing\n│   │   ├── dwarf_reader.py      # DWARF debug information\n│   │   └── symbol_cache.py      # Address-to-symbol mapping cache\n│   ├── visualizer/           # Flame graph generation (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── stack_aggregator.py  # Stack folding and counting\n│   │   ├── flamegraph.py        # SVG flame graph generation\n│   │   └── interactive.py       # Zoom/search functionality\n│   ├── memory/               # Memory profiling (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── malloc_hooks.py      # Allocation interception\n│   │   ├── leak_detector.py     # Memory leak analysis\n│   │   └── allocation_tracker.py # Allocation metadata storage\n│   └── common/               # Shared utilities\n│       ├── __init__.py\n│       ├── data_structures.py   # Core data types\n│       ├── config.py            # Configuration management\n│       └── utils.py             # Helper functions\n├── tests/                    # Test suite organized by component\n│   ├── test_sampler/\n│   ├── test_symbolizer/\n│   ├── test_visualizer/\n│   ├── test_memory/\n│   └── integration/\n├── tools/                    # Command-line interfaces\n│   ├── profile_cpu.py           # CPU profiling entry point\n│   ├── profile_memory.py        # Memory profiling entry point\n│   └── generate_flamegraph.py   # Visualization tool\n├── examples/                 # Sample programs to profile\n│   ├── cpu_bound.py\n│   ├── memory_leaker.c\n│   └── recursive_fibonacci.py\n├── docs/                     # Documentation\n└── requirements.txt          # Python dependencies</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Configuration Management</strong> (Complete implementation ready to use):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/common/config.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SamplingConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for stack sampling behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    frequency_hz: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#6A737D\">          # Samples per second</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_stack_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 64</span><span style=\"color:#6A737D\">        # Maximum frames to capture</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    include_kernel: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">     # Include kernel stack frames</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_overhead_percent: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span><span style=\"color:#6A737D\">  # Target overhead as % of runtime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for symbol resolution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_dwarf: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">        # Parse DWARF debug info</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_symbols: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">       # Cache symbol lookups</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    demangle_cpp: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">        # Demangle C++ symbols</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_search_paths: </span><span style=\"color:#79B8FF\">list</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\"> # Additional symbol search directories</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.symbol_search_paths </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.symbol_search_paths </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'/usr/lib/debug'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'/usr/local/lib/debug'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VisualizationConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for flame graph generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    color_scheme: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'hot'</span><span style=\"color:#6A737D\">        # Color scheme: hot, cold, mem, io</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_width_pixels: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">        # Minimum flame width to display</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'CPU Profile'</span><span style=\"color:#6A737D\">       # Graph title</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_search: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">       # Include search functionality</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_zoom: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">         # Include zoom functionality</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Main profiler configuration combining all components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sampling: SamplingConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbols: SymbolConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    visualization: VisualizationConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    output_directory: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> './profile_output'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_json</span><span style=\"color:#E1E4E8\">(cls, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'ProfilerConfig'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load configuration from JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(config_path, </span><span style=\"color:#9ECBFF\">'r'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> json.load(f)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            sampling</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SamplingConfig(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'sampling'</span><span style=\"color:#E1E4E8\">, {})),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SymbolConfig(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'symbols'</span><span style=\"color:#E1E4E8\">, {})),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            visualization</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">VisualizationConfig(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'visualization'</span><span style=\"color:#E1E4E8\">, {})),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            output_directory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'output_directory'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'./profile_output'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_json</span><span style=\"color:#E1E4E8\">(self, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Save configuration to JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'sampling'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.sampling.</span><span style=\"color:#79B8FF\">__dict__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'symbols'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.symbols.</span><span style=\"color:#79B8FF\">__dict__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'visualization'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.visualization.</span><span style=\"color:#79B8FF\">__dict__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'output_directory'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.output_directory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(config_path, </span><span style=\"color:#9ECBFF\">'w'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            json.dump(data, f, </span><span style=\"color:#FFAB70\">indent</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Logging Infrastructure</strong> (Complete implementation ready to use):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/common/utils.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Generator</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> setup_logging</span><span style=\"color:#E1E4E8\">(level: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'INFO'</span><span style=\"color:#E1E4E8\">, log_file: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configure logging for the profiler system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    numeric_level </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> getattr</span><span style=\"color:#E1E4E8\">(logging, level.upper(), logging.</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    formatter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.Formatter(</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        '</span><span style=\"color:#79B8FF\">%(asctime)s</span><span style=\"color:#9ECBFF\"> [</span><span style=\"color:#79B8FF\">%(levelname)s</span><span style=\"color:#9ECBFF\">] </span><span style=\"color:#79B8FF\">%(name)s</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%(message)s</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        datefmt</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'%Y-%m-</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> %H:%M:%S'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    handlers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [logging.StreamHandler(sys.stdout)]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> log_file:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handlers.append(logging.FileHandler(log_file))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logging.basicConfig(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        level</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">numeric_level,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        handlers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">handlers,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        format</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">%(asctime)s</span><span style=\"color:#9ECBFF\"> [</span><span style=\"color:#79B8FF\">%(levelname)s</span><span style=\"color:#9ECBFF\">] </span><span style=\"color:#79B8FF\">%(name)s</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%(message)s</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> timer_context</span><span style=\"color:#E1E4E8\">(operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Generator[</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for timing operations with automatic logging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.debug(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Starting </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Completed </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">elapsed</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_bytes</span><span style=\"color:#E1E4E8\">(size_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format byte count as human-readable string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> unit </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'KB'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'MB'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GB'</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> size_bytes </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">size_bytes</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}{</span><span style=\"color:#E1E4E8\">unit</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size_bytes </span><span style=\"color:#F97583\">/=</span><span style=\"color:#79B8FF\"> 1024</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">size_bytes</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">TB\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_percentage</span><span style=\"color:#E1E4E8\">(value: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, total: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format value as percentage of total with appropriate precision.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> total </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"0.0%\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    percentage </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (value </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">percentage</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">%\"</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton\">Core Logic Skeleton</h4>\n<p><strong>Main Profiler Controller</strong> (Skeleton for learners to implement):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/profiler.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.common.config </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ProfilerConfig</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.common.data_structures </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Profile, Sample</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Profiler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Main profiler coordinator that orchestrates sampling, symbolization, and visualization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: ProfilerConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize component instances (sampler, symbolizer, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> profile_process</span><span style=\"color:#E1E4E8\">(self, pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, duration_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Profile a running process for the specified duration.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            pid: Process ID to profile</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            duration_seconds: How long to collect samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Profile object containing all collected data</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that target process exists and is accessible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Configure and start the stack sampler with specified frequency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Set up signal handler for graceful shutdown on Ctrl+C</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Start sample collection timer for specified duration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Periodically check sampling overhead and adjust frequency if needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Stop sampling after duration expires</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Collect all samples from sampler's storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return Profile object with raw samples (symbolization happens later)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> symbolize_profile</span><span style=\"color:#E1E4E8\">(self, profile: Profile) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resolve raw addresses to function names and source locations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            profile: Profile with raw address samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Profile with symbolized stack frames</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract unique addresses from all stack frames in samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load symbol tables for target executable and shared libraries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Build address-to-symbol mapping for all unique addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Replace raw addresses in stack frames with symbol information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add source file and line number info if DWARF data available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Cache symbol resolution results for performance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return updated profile with symbolic information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_flame_graph</span><span style=\"color:#E1E4E8\">(self, profile: Profile, output_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate interactive SVG flame graph from profiling data.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            profile: Symbolized profile data</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            output_path: Where to write the SVG file</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Aggregate samples by unique stack signature (stack folding)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Build hierarchical call tree from folded stacks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate width percentages based on sample counts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate SVG coordinates for each flame graph rectangle</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Apply color coding based on function categories (user/kernel/lib)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Add interactive JavaScript for zoom and search features</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Write complete SVG file with embedded styling and scripts</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-implementation-hints\">Language-Specific Implementation Hints</h4>\n<p><strong>Python-Specific Considerations</strong>:</p>\n<ul>\n<li>Use <code>signal.signal(signal.SIGPROF, handler)</code> for timer-based sampling interrupts</li>\n<li>Use <code>traceback.extract_tb()</code> and <code>inspect.currentframe()</code> for stack frame walking</li>\n<li>Use <code>struct.unpack()</code> for parsing binary ELF headers and DWARF sections</li>\n<li>Use <code>ctypes</code> for interacting with malloc/free hooks if implementing memory tracking</li>\n<li>Use <code>os.kill(pid, 0)</code> to check if target process exists before profiling</li>\n<li>Consider <code>multiprocessing.Process</code> for running profiler in separate process to minimize target interference</li>\n</ul>\n<p><strong>Platform Compatibility Notes</strong>:</p>\n<ul>\n<li>Linux: Full support for <code>/proc/</code> filesystem, ELF binaries, DWARF debug info</li>\n<li>macOS: Use Mach-O binary format instead of ELF, different debug symbol handling</li>\n<li>Windows: Use PE/COFF binary format, PDB debug symbols, different sampling mechanisms</li>\n</ul>\n<p><strong>Performance Optimization Hints</strong>:</p>\n<ul>\n<li>Use <code>collections.defaultdict</code> for efficient sample aggregation during stack folding</li>\n<li>Use <code>lru_cache</code> decorator for symbol resolution results to avoid repeated ELF parsing</li>\n<li>Use <code>mmap</code> for reading large binary files (executables, core dumps) efficiently</li>\n<li>Pre-compile regular expressions used for C++ symbol demangling</li>\n<li>Use <code>bisect</code> module for efficient address range lookups in symbol tables</li>\n</ul>\n<h4 id=\"milestone-verification-checkpoints\">Milestone Verification Checkpoints</h4>\n<p>After implementing the foundational components, verify the setup with these checkpoints:</p>\n<p><strong>Configuration System Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.common.config import ProfilerConfig</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">config = ProfilerConfig.from_json('examples/basic_config.json')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Sampling frequency: {config.sampling.frequency_hz}Hz')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Output directory: {config.output_directory}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n<p>Expected output: Configuration values loaded from JSON without errors.</p>\n<p><strong>Logging System Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.common.utils import setup_logging, timer_context</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">setup_logging('DEBUG')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">with timer_context('test operation'):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    import time; time.sleep(0.1)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n<p>Expected output: Debug log showing operation start and completion with timing.</p>\n<p><strong>Project Structure Checkpoint</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">find</span><span style=\"color:#9ECBFF\"> src/</span><span style=\"color:#79B8FF\"> -name</span><span style=\"color:#9ECBFF\"> \"*.py\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> head</span><span style=\"color:#79B8FF\"> -10</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python3</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"import src.common.config; print('Import successful')\"</span></span></code></pre></div>\n<p>Expected output: Python files found in expected locations, no import errors.</p>\n<h4 id=\"common-setup-pitfalls\">Common Setup Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Mixing Development and Production Configurations</strong></p>\n<ul>\n<li><strong>Problem</strong>: Using high-frequency sampling (1000Hz) during development and forgetting to reduce it for production profiling</li>\n<li><strong>Why it&#39;s wrong</strong>: High sampling frequencies can add 20%+ overhead to the target application</li>\n<li><strong>Fix</strong>: Always start with low frequencies (10-100Hz) and increase only if needed for accuracy</li>\n</ul>\n<p>⚠️ <strong>Pitfall: Insufficient Permissions for System Profiling</strong></p>\n<ul>\n<li><strong>Problem</strong>: Profiler fails silently when trying to profile other users&#39; processes or access performance counters</li>\n<li><strong>Why it&#39;s wrong</strong>: Many profiling operations require root privileges or specific capabilities</li>\n<li><strong>Fix</strong>: Document required permissions clearly and provide helpful error messages when permissions are missing</li>\n</ul>\n<p>⚠️ <strong>Pitfall: Hardcoded File Paths in Configuration</strong></p>\n<ul>\n<li><strong>Problem</strong>: Configuration files contain absolute paths that break when moved between systems</li>\n<li><strong>Why it&#39;s wrong</strong>: Makes the profiler non-portable and fragile across development/production environments</li>\n<li><strong>Fix</strong>: Use relative paths and environment variable substitution in configuration files</li>\n</ul>\n<p>⚠️ <strong>Pitfall: No Graceful Degradation for Missing Debug Symbols</strong></p>\n<ul>\n<li><strong>Problem</strong>: Profiler crashes or produces empty output when debug symbols are missing</li>\n<li><strong>Why it&#39;s wrong</strong>: Most production binaries are stripped of debug information</li>\n<li><strong>Fix</strong>: Implement fallback symbol resolution using symbol tables even when DWARF debug info is unavailable</li>\n</ul>\n<p>This foundational understanding and infrastructure setup prepares for the detailed implementation of each profiling component, ensuring consistent approaches to configuration, logging, error handling, and data management across all milestones.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones (1-4) — establishing clear scope boundaries and success criteria for the profiler implementation</p>\n</blockquote>\n<h3 id=\"mental-model-the-telescope-analogy\">Mental Model: The Telescope Analogy</h3>\n<p>Think of building a profiler like constructing a telescope for astronomical observation. A telescope has a specific purpose — to observe distant objects — and requires careful design trade-offs between magnification power, field of view, light gathering ability, and portability. Similarly, our profiler has a focused mission: to observe program behavior with minimal disturbance while providing actionable insights.</p>\n<p>Just as astronomers must decide whether they&#39;re building a wide-field survey telescope or a high-resolution planetary observer, we must define what our profiler will and won&#39;t do. A telescope that tries to excel at everything ends up being mediocre at everything. Our profiler needs clear goals that drive every architectural decision, from sampling frequency to memory overhead to visualization features.</p>\n<p>The <strong>observer paradox</strong> applies to both telescopes and profilers: the act of observation can change what you&#39;re observing. Telescopes block starlight with their secondary mirrors, and profilers consume CPU cycles and memory. The key is minimizing this interference while maximizing the quality of observation data.</p>\n<h3 id=\"functional-goals\">Functional Goals</h3>\n<p>Our profiler&#39;s functional goals define the core capabilities that users will directly interact with. These goals directly map to the four milestone deliverables and establish what &quot;done&quot; looks like for each component.</p>\n<h4 id=\"statistical-sampling-profiling\">Statistical Sampling Profiling</h4>\n<p>The profiler must implement <strong>statistical sampling</strong> to capture representative snapshots of program execution without requiring code modification. This non-intrusive approach allows profiling production applications while maintaining their original behavior.</p>\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Requirement</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Stack Sampling</td>\n<td>Capture complete call stacks at regular intervals</td>\n<td>Sample 100% of timer interrupts with &lt;1% sample loss</td>\n</tr>\n<tr>\n<td>Sampling Frequency Control</td>\n<td>Support rates from 10Hz to 10KHz</td>\n<td>Configurable via <code>SamplingConfig.frequency_hz</code> with validation</td>\n</tr>\n<tr>\n<td>Thread Targeting</td>\n<td>Profile specific processes or individual threads</td>\n<td>Accept PID or TID parameters with proper permission checking</td>\n</tr>\n<tr>\n<td>Kernel Stack Capture</td>\n<td>Include kernel-mode execution when permissions allow</td>\n<td>Optional via <code>SamplingConfig.include_kernel</code> flag</td>\n</tr>\n<tr>\n<td>Stack Depth Control</td>\n<td>Limit capture depth for performance</td>\n<td>Configurable <code>max_stack_depth</code> with 64-frame maximum</td>\n</tr>\n</tbody></table>\n<p>The sampling mechanism must handle edge cases gracefully. When a process is blocked in a system call, we should either capture the kernel stack (if possible) or record the blocking state. Signal delivery failures should be detected and reported without crashing the profiler.</p>\n<h4 id=\"symbol-resolution-and-debug-information\">Symbol Resolution and Debug Information</h4>\n<p>Raw memory addresses provide no insight to developers. The profiler must convert instruction pointers into human-readable function names, source file locations, and line numbers through comprehensive symbol resolution.</p>\n<table>\n<thead>\n<tr>\n<th>Symbol Type</th>\n<th>Source</th>\n<th>Resolution Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Function Names</td>\n<td>ELF Symbol Tables</td>\n<td>Parse <code>.symtab</code> and <code>.dynsym</code> sections</td>\n</tr>\n<tr>\n<td>Source Files</td>\n<td>DWARF Debug Info</td>\n<td>Extract from <code>.debug_info</code> and <code>.debug_line</code></td>\n</tr>\n<tr>\n<td>Line Numbers</td>\n<td>DWARF Line Tables</td>\n<td>Map addresses to source locations</td>\n</tr>\n<tr>\n<td>C++ Symbols</td>\n<td>Mangled Names</td>\n<td>Demangle using <code>SymbolConfig.demangle_cpp</code></td>\n</tr>\n<tr>\n<td>Shared Libraries</td>\n<td>Dynamic Loading</td>\n<td>Track <code>dlopen()</code> events and resolve symbols</td>\n</tr>\n<tr>\n<td>JIT Code</td>\n<td>Runtime Mapping</td>\n<td>Support language-specific symbol APIs when available</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight</strong>: Symbol resolution is often the performance bottleneck in profilers. We prioritize caching and lazy loading over comprehensive symbol information. A function name with approximate source location provides 80% of the value with 20% of the computational cost.</p>\n</blockquote>\n<p>The symbol resolver must handle <strong>Address Space Layout Randomization (ASLR)</strong> correctly by calculating base addresses for each loaded module. It should gracefully degrade when debug information is missing, providing at least binary+offset information (e.g., <code>libc.so.6+0x12345</code>) rather than failing completely.</p>\n<h4 id=\"interactive-flame-graph-visualization\">Interactive Flame Graph Visualization</h4>\n<p>Flame graphs transform thousands of stack samples into an intuitive hierarchical visualization that reveals performance hotspots and call patterns. Our implementation must generate publication-quality visualizations with interactive features for deep analysis.</p>\n<table>\n<thead>\n<tr>\n<th>Visualization Feature</th>\n<th>Implementation</th>\n<th>Interactive Capability</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hierarchical Layout</td>\n<td>SVG coordinate system with proportional widths</td>\n<td>Pan and zoom to explore call trees</td>\n</tr>\n<tr>\n<td>Color Coding</td>\n<td>Function categories (user/library/kernel)</td>\n<td>Hover tooltips with detailed metrics</td>\n</tr>\n<tr>\n<td>Search Integration</td>\n<td>Text matching within function names</td>\n<td>Highlight matching functions across graph</td>\n</tr>\n<tr>\n<td>Differential Views</td>\n<td>Side-by-side profile comparison</td>\n<td>Toggle between absolute and relative differences</td>\n</tr>\n<tr>\n<td>Inverted Graphs</td>\n<td>Bottom-up caller analysis</td>\n<td>Switch between caller and callee perspectives</td>\n</tr>\n<tr>\n<td>Export Formats</td>\n<td>SVG, PNG, and folded stack text</td>\n<td>Share visualizations and integrate with tools</td>\n</tr>\n</tbody></table>\n<p>The flame graph generator must handle large datasets efficiently. A profile with 100,000 samples might contain 10,000 unique stack traces after folding. The visualization should render smoothly in web browsers and provide responsive interaction even with complex call graphs.</p>\n<h4 id=\"memory-allocation-tracking-and-leak-detection\">Memory Allocation Tracking and Leak Detection</h4>\n<p>Beyond CPU profiling, the system must track heap allocations to identify memory-intensive code paths and detect potential leaks. This requires intercepting allocation functions and maintaining allocation metadata throughout program execution.</p>\n<table>\n<thead>\n<tr>\n<th>Memory Feature</th>\n<th>Tracking Method</th>\n<th>Detection Capability</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Allocation Sites</td>\n<td>Stack trace capture at malloc()</td>\n<td>Identify top allocation sources by bytes</td>\n</tr>\n<tr>\n<td>Allocation Sizes</td>\n<td>Record requested and actual sizes</td>\n<td>Track memory usage patterns over time</td>\n</tr>\n<tr>\n<td>Leak Detection</td>\n<td>Match allocations with free() calls</td>\n<td>Report unfreed allocations at program exit</td>\n</tr>\n<tr>\n<td>Allocation Timeline</td>\n<td>Timestamp each allocation/deallocation</td>\n<td>Generate memory usage graphs over time</td>\n</tr>\n<tr>\n<td>Call Stack Attribution</td>\n<td>Full backtrace per allocation</td>\n<td>Create allocation flame graphs</td>\n</tr>\n<tr>\n<td>Memory Categories</td>\n<td>Classify by allocation size/lifetime</td>\n<td>Distinguish leaks from long-lived data</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Critical Design Choice</strong>: We use function interposition via <code>LD_PRELOAD</code> rather than compiler instrumentation. This allows profiling existing binaries without recompilation, but requires careful handling of recursive malloc calls and thread safety.</p>\n</blockquote>\n<h3 id=\"non-functional-goals\">Non-Functional Goals</h3>\n<p>Non-functional goals establish the quality attributes and constraints that govern how the profiler operates in real-world environments. These goals often drive architectural decisions more strongly than functional requirements.</p>\n<h4 id=\"performance-and-overhead-constraints\">Performance and Overhead Constraints</h4>\n<p>The profiler&#39;s primary non-functional requirement is minimizing performance impact on target applications. Violating this constraint makes the tool unusable for production profiling.</p>\n<table>\n<thead>\n<tr>\n<th>Performance Metric</th>\n<th>Target</th>\n<th>Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CPU Overhead</td>\n<td>&lt;2% for 100Hz sampling</td>\n<td>Compare execution time with/without profiling</td>\n</tr>\n<tr>\n<td>Memory Overhead</td>\n<td>&lt;10MB baseline + 1KB per stack</td>\n<td>Monitor profiler memory usage during capture</td>\n</tr>\n<tr>\n<td>Sample Processing</td>\n<td>&lt;100μs per sample</td>\n<td>Time from signal handler to storage completion</td>\n</tr>\n<tr>\n<td>Symbol Resolution</td>\n<td>&lt;1ms per unique address</td>\n<td>Cache hit rate &gt;95% after warmup period</td>\n</tr>\n<tr>\n<td>Flame Graph Generation</td>\n<td>&lt;5 seconds for 100K samples</td>\n<td>End-to-end processing time measurement</td>\n</tr>\n<tr>\n<td>Storage Efficiency</td>\n<td>&lt;50 bytes per sample average</td>\n<td>Compressed stack representation</td>\n</tr>\n</tbody></table>\n<p>These targets reflect real-world production constraints. A 2% CPU overhead allows profiling in production during normal operations. Higher overhead limits profiling to development environments, reducing the tool&#39;s value for diagnosing production performance issues.</p>\n<h4 id=\"reliability-and-error-handling\">Reliability and Error Handling</h4>\n<p>The profiler must operate reliably even when targeting unstable or crashing applications. Profiler bugs should never crash or corrupt the target process.</p>\n<table>\n<thead>\n<tr>\n<th>Reliability Aspect</th>\n<th>Requirement</th>\n<th>Implementation Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signal Safety</td>\n<td>No unsafe operations in signal handlers</td>\n<td>Pre-allocate buffers, avoid malloc/printf</td>\n</tr>\n<tr>\n<td>Target Process Isolation</td>\n<td>Profiler crashes don&#39;t affect target</td>\n<td>Run as separate process with ptrace/proc access</td>\n</tr>\n<tr>\n<td>Graceful Degradation</td>\n<td>Partial results when components fail</td>\n<td>Continue sampling even if symbol resolution fails</td>\n</tr>\n<tr>\n<td>Data Integrity</td>\n<td>Detect and handle corrupted samples</td>\n<td>Checksums and validation for critical data structures</td>\n</tr>\n<tr>\n<td>Resource Cleanup</td>\n<td>Release resources on early termination</td>\n<td>Signal handlers for cleanup on SIGINT/SIGTERM</td>\n</tr>\n<tr>\n<td>Permission Handling</td>\n<td>Graceful failure when lacking privileges</td>\n<td>Detect capabilities and disable unavailable features</td>\n</tr>\n</tbody></table>\n<p>The profiler should provide meaningful error messages when it cannot operate. &quot;Permission denied&quot; is less helpful than &quot;Cannot attach to process 1234: profiler must run as root to profile processes owned by other users.&quot;</p>\n<h4 id=\"usability-and-developer-experience\">Usability and Developer Experience</h4>\n<p>The profiler targets developers who need quick insights into performance problems. Complex configuration or interpretation should not impede rapid diagnosis.</p>\n<table>\n<thead>\n<tr>\n<th>Usability Feature</th>\n<th>Design Goal</th>\n<th>Implementation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Zero-Configuration Defaults</td>\n<td>Work out-of-box for common cases</td>\n<td>Sensible values in <code>DEFAULT_FREQUENCY_HZ</code> constants</td>\n</tr>\n<tr>\n<td>Configuration Management</td>\n<td>JSON-based configuration with validation</td>\n<td><code>ProfilerConfig.from_json()</code> with schema validation</td>\n</tr>\n<tr>\n<td>Progress Indication</td>\n<td>Show profiling status during capture</td>\n<td>Progress bars and ETA for long-running operations</td>\n</tr>\n<tr>\n<td>Output Organization</td>\n<td>Structured output with clear naming</td>\n<td>Timestamp-based directories with descriptive filenames</td>\n</tr>\n<tr>\n<td>Error Diagnostics</td>\n<td>Actionable error messages with fixes</td>\n<td>Suggest solutions for common permission/setup issues</td>\n</tr>\n<tr>\n<td>Documentation Integration</td>\n<td>Self-documenting configuration and outputs</td>\n<td>JSON schema docs and embedded help text</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Philosophy</strong>: Optimize for the 80% use case where developers want to quickly profile a process and see a flame graph. Advanced features should be discoverable but not impose complexity on basic workflows.</p>\n</blockquote>\n<h3 id=\"explicit-non-goals\">Explicit Non-Goals</h3>\n<p>Clearly defining what the profiler will NOT do prevents scope creep and helps maintain focus on core functionality. These explicit exclusions guide architectural decisions and help users set appropriate expectations.</p>\n<h4 id=\"advanced-profiling-modalities\">Advanced Profiling Modalities</h4>\n<p>While comprehensive profiling tools support multiple measurement approaches, our profiler deliberately focuses on statistical sampling and basic memory tracking.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Alternative Solutions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Instrumentation-Based Profiling</td>\n<td>Requires code modification or compiler integration</td>\n<td>Use compiler-based tools like gprof or PGO</td>\n</tr>\n<tr>\n<td>Hardware Performance Counters</td>\n<td>Platform-specific and requires kernel support</td>\n<td>Use perf or Intel VTune for detailed metrics</td>\n</tr>\n<tr>\n<td>Real-Time Profiling</td>\n<td>Complex streaming infrastructure required</td>\n<td>Use dedicated APM tools like New Relic or DataDog</td>\n</tr>\n<tr>\n<td>Network/IO Profiling</td>\n<td>Different expertise domain from CPU/memory</td>\n<td>Use tools like tcpdump, iotop, or strace</td>\n</tr>\n<tr>\n<td>GPU Profiling</td>\n<td>Specialized hardware knowledge required</td>\n<td>Use NVIDIA Nsight or AMD profiling tools</td>\n</tr>\n<tr>\n<td>Multi-Language Runtime Integration</td>\n<td>Each runtime needs custom integration</td>\n<td>Use language-specific profilers (py-spy, async-profiler)</td>\n</tr>\n</tbody></table>\n<h4 id=\"production-deployment-features\">Production Deployment Features</h4>\n<p>Our profiler targets development and debugging workflows rather than production monitoring infrastructure.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Alternative Solutions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distributed Profiling</td>\n<td>Complex coordination and data aggregation</td>\n<td>Use APM platforms with distributed tracing</td>\n</tr>\n<tr>\n<td>Real-Time Dashboards</td>\n<td>Requires web framework and database storage</td>\n<td>Export data to existing monitoring systems</td>\n</tr>\n<tr>\n<td>Alerting and Notifications</td>\n<td>Not a monitoring system</td>\n<td>Integrate with existing alerting infrastructure</td>\n</tr>\n<tr>\n<td>User Authentication/Authorization</td>\n<td>Security adds significant complexity</td>\n<td>Use filesystem permissions and sudo access</td>\n</tr>\n<tr>\n<td>Multi-Tenant Profiling</td>\n<td>Isolation and resource management complexity</td>\n<td>Deploy separate profiler instances per tenant</td>\n</tr>\n<tr>\n<td>Continuous Background Profiling</td>\n<td>Persistent daemon and storage management</td>\n<td>Use always-on profiling services</td>\n</tr>\n</tbody></table>\n<h4 id=\"advanced-memory-analysis\">Advanced Memory Analysis</h4>\n<p>While we track basic allocation patterns, comprehensive memory analysis requires specialized tools and techniques beyond our scope.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Alternative Solutions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache Miss Analysis</td>\n<td>Requires hardware performance counters</td>\n<td>Use perf with cache event sampling</td>\n</tr>\n<tr>\n<td>Memory Layout Optimization</td>\n<td>Complex static analysis problem</td>\n<td>Use memory sanitizers and specialized profilers</td>\n</tr>\n<tr>\n<td>NUMA Topology Analysis</td>\n<td>Platform-specific and complex</td>\n<td>Use numactl and NUMA-aware profilers</td>\n</tr>\n<tr>\n<td>Virtual Memory Analysis</td>\n<td>Kernel-level data access required</td>\n<td>Use vmstat, /proc analysis, and kernel profilers</td>\n</tr>\n<tr>\n<td>Garbage Collection Analysis</td>\n<td>Language runtime integration required</td>\n<td>Use runtime-specific GC profilers</td>\n</tr>\n<tr>\n<td>Memory Fragmentation Analysis</td>\n<td>Requires heap internals knowledge</td>\n<td>Use jemalloc/tcmalloc analysis tools</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Architecture Decision Record: Focus on Statistical Sampling</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple profiling approaches exist (sampling, instrumentation, hardware counters), each with different trade-offs in accuracy, overhead, and implementation complexity.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Pure statistical sampling with signal-based interrupts</li>\n<li>Hybrid approach combining sampling with selective instrumentation</li>\n<li>Hardware counter-based profiling with fallback to sampling</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement pure statistical sampling as the primary profiling method</li>\n<li><strong>Rationale</strong>: Statistical sampling provides good accuracy for most performance issues while maintaining low overhead and broad compatibility. It works without code modification and doesn&#39;t require special hardware or kernel features. The 95% accuracy rate is sufficient for identifying performance hotspots in real applications.</li>\n<li><strong>Consequences</strong>: We accept some inaccuracy in precise timing measurements but gain simplicity and broad applicability. This approach works equally well for optimized production binaries and development builds with debug symbols.</li>\n</ul>\n</blockquote>\n<h4 id=\"integration-and-ecosystem-features\">Integration and Ecosystem Features</h4>\n<p>Our profiler will produce standard output formats but won&#39;t deeply integrate with external tools and platforms.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale</th>\n<th>Alternative Solutions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>IDE Integration</td>\n<td>Each IDE has different plugin architectures</td>\n<td>Use command-line workflow and import results</td>\n</tr>\n<tr>\n<td>CI/CD Pipeline Integration</td>\n<td>Complex automation and threshold management</td>\n<td>Use performance regression testing frameworks</td>\n</tr>\n<tr>\n<td>Custom Visualization Frameworks</td>\n<td>Significant UI/UX development effort</td>\n<td>Export data to existing visualization platforms</td>\n</tr>\n<tr>\n<td>Database Storage Backend</td>\n<td>Adds operational complexity</td>\n<td>Use filesystem storage with external indexing</td>\n</tr>\n<tr>\n<td>Custom Query Languages</td>\n<td>Complex parser and execution engine</td>\n<td>Use standard text processing tools (grep, jq)</td>\n</tr>\n<tr>\n<td>Cloud Service Integration</td>\n<td>Platform-specific APIs and authentication</td>\n<td>Use cloud CLI tools and standard data formats</td>\n</tr>\n</tbody></table>\n<h3 id=\"success-metrics-and-validation-criteria\">Success Metrics and Validation Criteria</h3>\n<p>To validate that our goals are met, we define measurable success criteria for each functional and non-functional goal.</p>\n<h4 id=\"functional-success-metrics\">Functional Success Metrics</h4>\n<table>\n<thead>\n<tr>\n<th>Goal Area</th>\n<th>Success Metric</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Stack Sampling</td>\n<td>99%+ sample capture rate at 100Hz</td>\n<td>Compare timer interrupts sent vs samples collected</td>\n</tr>\n<tr>\n<td>Symbol Resolution</td>\n<td>95%+ symbol resolution rate for debug builds</td>\n<td>Count resolved vs unresolved addresses in test binaries</td>\n</tr>\n<tr>\n<td>Flame Graph Quality</td>\n<td>Generate readable graphs for 100K+ samples</td>\n<td>Performance test with large profiles</td>\n</tr>\n<tr>\n<td>Memory Tracking</td>\n<td>Detect 100% of obvious leaks in test programs</td>\n<td>Run against known-leaky programs with validation</td>\n</tr>\n<tr>\n<td>Cross-Platform Support</td>\n<td>Work on Linux distributions with kernel 4.0+</td>\n<td>Test on Ubuntu, CentOS, Alpine with various kernels</td>\n</tr>\n</tbody></table>\n<h4 id=\"non-functional-success-metrics\">Non-Functional Success Metrics</h4>\n<table>\n<thead>\n<tr>\n<th>Goal Area</th>\n<th>Success Metric</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Performance Overhead</td>\n<td>&lt;2% CPU overhead for typical workloads</td>\n<td>Benchmark CPU-intensive programs with/without profiling</td>\n</tr>\n<tr>\n<td>Memory Efficiency</td>\n<td>&lt;10MB baseline memory usage</td>\n<td>Monitor profiler RSS during execution</td>\n</tr>\n<tr>\n<td>Reliability</td>\n<td>Zero target process crashes in 1000+ profiling runs</td>\n<td>Stress test with various application types</td>\n</tr>\n<tr>\n<td>Usability</td>\n<td>New users can generate flame graph in &lt;5 minutes</td>\n<td>User testing with developers unfamiliar with profiling</td>\n</tr>\n<tr>\n<td>Error Handling</td>\n<td>Graceful failure for 95%+ error conditions</td>\n<td>Fault injection testing with simulated failures</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<p>Our technology choices balance simplicity for learning with real-world applicability. Python provides excellent readability for understanding profiling concepts while still supporting the low-level operations required for stack sampling.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Core Implementation</td>\n<td>Python 3.8+ with ctypes for system calls</td>\n<td>Python C extensions for performance-critical paths</td>\n</tr>\n<tr>\n<td>Signal Handling</td>\n<td>Standard library signal module</td>\n<td>Custom signal handling with real-time signals</td>\n</tr>\n<tr>\n<td>Symbol Resolution</td>\n<td>pyelftools for ELF parsing</td>\n<td>DWARF debugging with libdwarf bindings</td>\n</tr>\n<tr>\n<td>Process Control</td>\n<td>psutil for process management</td>\n<td>Direct ptrace system calls for advanced features</td>\n</tr>\n<tr>\n<td>Visualization</td>\n<td>matplotlib for basic graphs</td>\n<td>Custom SVG generation for interactive flame graphs</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>JSON with built-in json module</td>\n<td>YAML with PyYAML for complex configurations</td>\n</tr>\n<tr>\n<td>Testing Framework</td>\n<td>unittest for component testing</td>\n<td>pytest with fixtures for integration testing</td>\n</tr>\n<tr>\n<td>Documentation</td>\n<td>Markdown with examples</td>\n<td>Sphinx for API documentation generation</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-project-structure\">Recommended Project Structure</h4>\n<p>Organize the codebase to reflect the major components and support incremental development through the milestones.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>cpu-memory-profiler/\n├── README.md                          # Quick start and overview\n├── requirements.txt                   # Python dependencies\n├── setup.py                          # Installation configuration\n├── config/\n│   ├── default_config.json          # Default profiler configuration\n│   └── example_configs/              # Example configurations for different scenarios\n├── src/profiler/\n│   ├── __init__.py                   # Package initialization and version\n│   ├── config.py                     # ProfilerConfig and related classes\n│   ├── main.py                       # Command-line interface and main entry point\n│   ├── sampler/                      # Stack Sampling Component (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── stack_sampler.py          # Core sampling logic with signal handlers\n│   │   ├── sample_storage.py         # Sample and stack frame data structures\n│   │   └── platform_utils.py         # Platform-specific system call wrappers\n│   ├── symbols/                      # Symbol Resolution Component (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── symbol_resolver.py        # Main symbol resolution logic\n│   │   ├── elf_parser.py            # ELF binary and symbol table parsing\n│   │   ├── dwarf_reader.py          # DWARF debug information processing\n│   │   └── symbol_cache.py          # Symbol lookup caching and optimization\n│   ├── visualization/                # Flame Graph Generation (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── flame_graph.py           # SVG flame graph generation\n│   │   ├── stack_aggregator.py      # Stack folding and aggregation algorithms\n│   │   └── svg_renderer.py          # Low-level SVG coordinate and rendering\n│   ├── memory/                       # Memory Profiling Component (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── allocation_tracker.py    # malloc/free interposition\n│   │   ├── leak_detector.py         # Memory leak analysis\n│   │   └── memory_visualizer.py     # Memory allocation flame graphs\n│   └── utils/                        # Shared utilities and helpers\n│       ├── __init__.py\n│       ├── logging_config.py         # Logging setup and configuration\n│       ├── time_utils.py            # Timing and performance measurement\n│       └── format_helpers.py        # Data formatting and display utilities\n├── tests/                            # Comprehensive test suite\n│   ├── unit/                        # Component unit tests\n│   ├── integration/                 # End-to-end integration tests\n│   ├── fixtures/                    # Test programs and sample data\n│   └── benchmarks/                  # Performance regression tests\n├── examples/                         # Example programs and usage scenarios\n│   ├── cpu_intensive.py             # CPU-bound test program\n│   ├── memory_leaky.py              # Memory allocation test program\n│   └── mixed_workload.py            # Combined CPU/memory test program\n├── docs/                            # Documentation and guides\n│   ├── design_document.md           # This design document\n│   ├── user_guide.md               # End-user documentation\n│   └── developer_guide.md          # Development and contribution guide\n└── diagrams/                        # Architecture diagrams\n    ├── system-components.svg        # High-level component architecture\n    ├── sampling-sequence.svg        # Stack sampling sequence diagram\n    └── symbol-resolution-flow.svg   # Symbol resolution process flow</code></pre></div>\n\n<h4 id=\"configuration-management-infrastructure\">Configuration Management Infrastructure</h4>\n<p>Provide complete configuration management that supports the goals while remaining simple for basic use cases.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Configuration management for the CPU/Memory Profiler.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Handles loading, validation, and default values for all profiler settings.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, asdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Default configuration constants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEFAULT_FREQUENCY_HZ</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">MAX_STACK_DEPTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 64</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TARGET_OVERHEAD_PERCENT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SamplingConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for stack sampling behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    frequency_hz: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> DEFAULT_FREQUENCY_HZ</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_stack_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> MAX_STACK_DEPTH</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    include_kernel: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_overhead_percent: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> TARGET_OVERHEAD_PERCENT</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate sampling configuration parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement validation for frequency range (10Hz - 10KHz)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate max_stack_depth is positive and reasonable (&#x3C;= 256)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check target_overhead_percent is between 0.1 and 20.0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Raise ValueError with descriptive messages for invalid values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for symbol resolution and debug information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_dwarf: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_symbols: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    demangle_cpp: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_search_paths: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize default symbol search paths if not provided.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.symbol_search_paths </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up default search paths for common locations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Include /usr/lib/debug, /usr/local/lib, current directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add environment variable expansion (e.g., $HOME/.local/lib)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.symbol_search_paths </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VisualizationConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for flame graph generation and display.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    color_scheme: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"hot\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_width_pixels: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"CPU Profile Flame Graph\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_search: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_zoom: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate visualization configuration parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check color_scheme is in allowed values (hot, cold, aqua, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate min_width_pixels is positive</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Ensure title is reasonable length (&#x3C;100 chars)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Top-level profiler configuration containing all component settings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sampling: SamplingConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbols: SymbolConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    visualization: VisualizationConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    output_directory: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"./profiler_output\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize default configurations for unspecified components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.sampling </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.sampling </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SamplingConfig()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.symbols </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.symbols </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SymbolConfig()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.visualization </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.visualization </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> VisualizationConfig()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_json</span><span style=\"color:#E1E4E8\">(cls, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'ProfilerConfig'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load configuration from JSON file with validation and defaults.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Read JSON file and handle file not found errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse JSON with error handling for malformed files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create config objects from dictionary data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Run validation on all configuration sections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return populated ProfilerConfig instance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use **dict unpacking to create dataclass instances from JSON</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> NotImplementedError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Implement JSON configuration loading\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_json</span><span style=\"color:#E1E4E8\">(self, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Save configuration to JSON file with pretty formatting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert config to dictionary using asdict()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Write JSON with proper indentation for readability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle file write errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create parent directories if they don't exist</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate entire configuration and all components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call validate() on each component configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check output_directory is writable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify configuration consistency across components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_default_config</span><span style=\"color:#E1E4E8\">() -> ProfilerConfig:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load default configuration, falling back to built-in defaults.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Try loading from ~/.profiler/config.json first</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Fall back to /etc/profiler/config.json for system defaults</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: If no config files exist, return ProfilerConfig() with defaults</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log which configuration source was used</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> ProfilerConfig()</span></span></code></pre></div>\n\n<h4 id=\"utility-infrastructure\">Utility Infrastructure</h4>\n<p>Provide common utilities that support the non-functional goals around logging, performance measurement, and error handling.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/usr/bin/env python3</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Utility functions supporting profiler operations and non-functional requirements.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Handles logging, timing, formatting, and common operations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Generator, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> setup_logging</span><span style=\"color:#E1E4E8\">(level: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"INFO\"</span><span style=\"color:#E1E4E8\">, log_file: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configure logging system for profiler operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert level string to logging constant (DEBUG, INFO, WARNING, ERROR)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create formatter with timestamp, level, and message</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add console handler for interactive usage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add file handler if log_file is specified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up logger hierarchy for different components (sampler, symbols, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> timer_context</span><span style=\"color:#E1E4E8\">(operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Generator[</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for timing operations and logging performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Record start time using time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log operation start at DEBUG level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Yield control to wrapped operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate elapsed time and log at INFO level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle exceptions and log timing even if operation fails</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: This supports the &#x3C;2% overhead goal by measuring profiler impact</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logging.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> completed in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">elapsed</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_bytes</span><span style=\"color:#E1E4E8\">(size_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format byte count as human-readable string (KB, MB, GB).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle negative sizes gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use 1024-based units (KiB, MiB, GiB) for accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Choose appropriate precision (0 decimals for bytes, 1-2 for larger units)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return string like \"1.5 MiB\" or \"42 bytes\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # This supports memory profiling goal of tracking allocation sizes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> size_bytes </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">size_bytes</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> bytes\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement remaining unit conversions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">size_bytes</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> bytes\"</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_percentage</span><span style=\"color:#E1E4E8\">(value: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, total: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format value as percentage of total with appropriate precision.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle division by zero gracefully (return \"0.0%\")</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate percentage with floating point precision</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Choose precision based on magnitude (0.01% vs 15.2% vs 99%)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return formatted string like \"15.2%\" or \"&#x3C;0.01%\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> total </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"0.0%\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    percentage </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (value </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">percentage</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">%\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> ensure_output_directory</span><span style=\"color:#E1E4E8\">(output_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Path:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create output directory and return Path object, handling errors gracefully.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert string to Path object for robust path handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create directory and any necessary parent directories</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle permission errors with helpful error messages</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if path exists but is not a directory (error case)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return Path object for use by calling code</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path(output_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    path.mkdir(</span><span style=\"color:#FFAB70\">parents</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> check_process_permissions</span><span style=\"color:#E1E4E8\">(pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Check if profiler has sufficient permissions to attach to process.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if target process exists using /proc/{pid}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify read permissions on /proc/{pid}/maps and /proc/{pid}/mem</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For other users' processes, verify profiler is running as root</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return True if profiling should succeed, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # This supports the reliability goal of graceful permission handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">  # Placeholder - implement permission checking</span></span></code></pre></div>\n\n<h4 id=\"milestone-verification-checkpoints\">Milestone Verification Checkpoints</h4>\n<p>Each milestone should have clear verification criteria that confirm the implementation meets our functional goals.</p>\n<p><strong>Milestone 1 Checkpoint (Stack Sampling):</strong></p>\n<ul>\n<li>Run <code>python -m profiler.sampler --test-mode --frequency 100 --duration 5</code> against a CPU-intensive test program</li>\n<li>Expected: Capture ~500 samples (5 seconds × 100Hz) with &lt;1% loss rate</li>\n<li>Verify: Each sample contains valid stack frames with instruction pointers</li>\n<li>Test signal safety: Run against multi-threaded programs without crashes</li>\n<li>Performance: Verify &lt;2% overhead on CPU-intensive workloads</li>\n</ul>\n<p><strong>Milestone 2 Checkpoint (Symbol Resolution):</strong></p>\n<ul>\n<li>Process samples from Milestone 1 through symbol resolver</li>\n<li>Expected: &gt;95% symbol resolution rate for debug-enabled binaries</li>\n<li>Verify: Function names are human-readable, not raw addresses</li>\n<li>Test: Include C++ programs to verify name demangling works</li>\n<li>Performance: Symbol resolution completes in &lt;1 second for 1000 samples</li>\n</ul>\n<p><strong>Milestone 3 Checkpoint (Flame Graphs):</strong></p>\n<ul>\n<li>Generate flame graph from processed samples</li>\n<li>Expected: Interactive SVG file loads in web browser</li>\n<li>Verify: Zoom and search functionality works correctly</li>\n<li>Test: Function widths represent relative execution time accurately</li>\n<li>Visual: Color coding distinguishes user code from library functions</li>\n</ul>\n<p><strong>Milestone 4 Checkpoint (Memory Profiling):</strong></p>\n<ul>\n<li>Profile a program with known memory leaks</li>\n<li>Expected: Detect all obvious leaks with allocation call stacks</li>\n<li>Verify: Track allocation sizes accurately throughout execution</li>\n<li>Test: Generate memory allocation flame graph showing hot allocation sites</li>\n<li>Performance: &lt;10MB overhead for tracking 10,000 allocations</li>\n</ul>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones (1-4) — establishes the core architectural components and their relationships that enable stack sampling, symbol resolution, flame graph generation, and memory profiling</p>\n</blockquote>\n<h3 id=\"mental-model-the-observatory-network\">Mental Model: The Observatory Network</h3>\n<p>Think of this profiler system as a <strong>distributed observatory network</strong> studying a distant star system (your running program). Just as astronomers use multiple specialized instruments working in concert—telescopes for imaging, spectrometers for composition analysis, photometers for brightness measurement—our profiler employs four specialized components that collaborate to create a complete picture of program performance.</p>\n<p>The <strong>Sampler</strong> acts like the main telescope, periodically capturing snapshots of the program&#39;s execution state at precise intervals. The <strong>Symbolizer</strong> functions as the spectrometer, analyzing the raw data to identify what each captured element actually represents in human-readable terms. The <strong>Aggregator</strong> serves as the data processing center, combining thousands of individual observations into meaningful patterns and statistics. Finally, the <strong>Visualizer</strong> works like the publication department, transforming complex datasets into intuitive visual representations that reveal insights at a glance.</p>\n<p>This observatory metaphor captures a crucial architectural principle: <strong>separation of concerns through specialized components</strong>. Each component excels at one specific aspect of the profiling process, and their interfaces are designed for clean data handoffs. This modular design allows us to optimize each component independently, swap implementations as needed, and reason about the system&#39;s behavior at different scales.</p>\n<p>The architecture also embodies the <strong>observer paradox</strong> principle from physics—the act of observation inevitably affects the system being observed. Our design minimizes this effect by keeping the observation components (Sampler) as lightweight as possible while pushing the heavy computational work (symbol resolution, aggregation, visualization) to offline processing phases that don&#39;t impact the target program&#39;s performance.</p>\n<h3 id=\"component-overview\">Component Overview</h3>\n<p>The profiler system consists of four primary components that form a <strong>data processing pipeline</strong> from raw execution samples to rich visualizations. Each component has distinct responsibilities, well-defined interfaces, and specific performance characteristics that collectively enable comprehensive performance analysis with minimal overhead.</p>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<h4 id=\"core-component-responsibilities\">Core Component Responsibilities</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Primary Responsibility</th>\n<th>Input Data</th>\n<th>Output Data</th>\n<th>Performance Characteristic</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Sampler</strong></td>\n<td>Capture execution state snapshots</td>\n<td>Running process PID, sampling config</td>\n<td>Raw stack samples with timestamps</td>\n<td>Ultra-low latency (&lt; 10μs per sample)</td>\n</tr>\n<tr>\n<td><strong>Symbolizer</strong></td>\n<td>Resolve addresses to human-readable names</td>\n<td>Raw samples + debug information</td>\n<td>Symbolized samples with function names</td>\n<td>I/O intensive (symbol table parsing)</td>\n</tr>\n<tr>\n<td><strong>Aggregator</strong></td>\n<td>Combine samples into statistical summaries</td>\n<td>Symbolized samples</td>\n<td>Aggregated call trees and statistics</td>\n<td>Memory intensive (tree construction)</td>\n</tr>\n<tr>\n<td><strong>Visualizer</strong></td>\n<td>Generate interactive visual representations</td>\n<td>Aggregated data</td>\n<td>SVG flame graphs and reports</td>\n<td>CPU intensive (coordinate calculations)</td>\n</tr>\n</tbody></table>\n<p>Each component is designed as a <strong>pure transformation function</strong> at its core—taking well-defined input data structures and producing well-defined output structures. This functional approach enables easy testing, parallel processing, and composition of different profiling workflows.</p>\n<h4 id=\"component-interaction-patterns\">Component Interaction Patterns</h4>\n<p>The components interact through three primary patterns that balance performance, flexibility, and maintainability:</p>\n<p><strong>Sequential Pipeline Processing</strong> represents the most common workflow where each component processes the complete output of the previous stage. This pattern optimizes for simplicity and enables comprehensive post-processing analysis. For example, after sampling completes, the entire sample set undergoes symbol resolution, then aggregation, then visualization in sequence.</p>\n<p><strong>Streaming Pipeline Processing</strong> handles large datasets that don&#39;t fit in memory by processing data in chunks. The Sampler produces batches of samples that flow through each subsequent component in overlapping time windows. This pattern is essential for long-running profiles or high-frequency sampling scenarios.</p>\n<p><strong>Caching and Incremental Processing</strong> optimizes repeated operations by maintaining persistent state between profiling sessions. The Symbolizer caches resolved symbols across runs, while the Aggregator can incrementally update flame graphs as new samples arrive. This pattern significantly improves performance for interactive profiling workflows.</p>\n<blockquote>\n<p><strong>Key Architectural Insight</strong>: The pipeline design allows each component to be independently optimized for its specific computational characteristics—the Sampler for minimal latency, the Symbolizer for I/O throughput, the Aggregator for memory efficiency, and the Visualizer for rendering quality.</p>\n</blockquote>\n<h4 id=\"cross-cutting-concerns\">Cross-Cutting Concerns</h4>\n<p>Several concerns span multiple components and require coordinated design decisions:</p>\n<p><strong>Configuration Management</strong> flows through all components via the <code>ProfilerConfig</code> hierarchy. Each component receives its specific configuration subset but can access global settings like output directories and logging levels. This approach balances component independence with system-wide consistency.</p>\n<p><strong>Error Handling and Resilience</strong> follows a <strong>graceful degradation</strong> principle where component failures don&#39;t cascade to abort the entire profiling session. For instance, if symbol resolution fails for some addresses, those samples appear with raw addresses rather than causing profile generation to fail entirely.</p>\n<p><strong>Resource Management</strong> coordinates memory usage across components to stay within system limits. The Sampler uses fixed-size circular buffers, the Symbolizer implements bounded caches, and the Aggregator can switch to disk-based storage for large datasets.</p>\n<p><strong>Observability and Debugging</strong> provides instrumentation points in each component for diagnosing profiler behavior itself. This includes timing measurements, sample counts, cache hit rates, and error frequencies that help identify bottlenecks in the profiling pipeline.</p>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<blockquote>\n<p><strong>Decision: Separate Components vs. Monolithic Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Profiling involves distinct computational phases with different performance characteristics and failure modes</li>\n<li><strong>Options Considered</strong>: Single integrated binary, separate components with IPC, modular library with pluggable interfaces</li>\n<li><strong>Decision</strong>: Modular library architecture with separate classes/modules for each component</li>\n<li><strong>Rationale</strong>: Enables independent optimization of each phase, simplifies testing through mocking interfaces, allows for future distributed processing, and provides clear separation of concerns for maintainability</li>\n<li><strong>Consequences</strong>: Slightly more complex data marshaling between components, but gains significant flexibility for testing, optimization, and feature development</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Monolithic Binary</td>\n<td>Simple deployment, no IPC overhead</td>\n<td>Difficult to test individual phases, limited optimization opportunities</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Separate Processes</td>\n<td>True isolation, can distribute across machines</td>\n<td>IPC complexity, serialization overhead, deployment complexity</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Modular Library</td>\n<td>Clean interfaces, easy testing, single deployment</td>\n<td>Shared address space, need careful resource management</td>\n<td><strong>Yes</strong></td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Push vs. Pull Data Flow</strong></p>\n<ul>\n<li><strong>Context</strong>: Components need to coordinate data transfer while maintaining loose coupling</li>\n<li><strong>Options Considered</strong>: Push-based callbacks, pull-based iterators, hybrid message queues</li>\n<li><strong>Decision</strong>: Push-based interfaces with pull-based internal implementation</li>\n<li><strong>Rationale</strong>: Push interfaces provide simple function call semantics for the common case while internal pull mechanisms enable streaming and memory management for large datasets</li>\n<li><strong>Consequences</strong>: Slightly more complex interface design but enables both simple batch processing and efficient streaming workflows</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Synchronous vs. Asynchronous Processing</strong></p>\n<ul>\n<li><strong>Context</strong>: Profiling can generate large amounts of data that may not fit in memory</li>\n<li><strong>Options Considered</strong>: Fully synchronous pipeline, fully asynchronous with callbacks, hybrid approach</li>\n<li><strong>Decision</strong>: Synchronous interfaces with asynchronous internal implementation where needed</li>\n<li><strong>Rationale</strong>: Synchronous interfaces are easier to understand and debug, while internal async processing can be added transparently for performance-critical sections like I/O</li>\n<li><strong>Consequences</strong>: Simpler API surface but requires careful design to avoid blocking operations in performance-critical paths</li>\n</ul>\n</blockquote>\n<h4 id=\"component-interface-design-principles\">Component Interface Design Principles</h4>\n<p>The interfaces between components follow several key design principles that emerged from analyzing profiler performance bottlenecks and failure modes:</p>\n<p><strong>Type Safety Over Performance</strong> means all inter-component data transfer uses strongly-typed structures rather than raw bytes or generic containers. While this adds some serialization overhead, it eliminates entire classes of bugs related to data format mismatches and makes the system much easier to debug.</p>\n<p><strong>Immutable Data Structures</strong> ensure that once a component produces output, it cannot be accidentally modified by downstream components. This enables safe parallel processing and eliminates race conditions, though it requires careful memory management to avoid excessive copying.</p>\n<p><strong>Error Context Preservation</strong> requires that each component augment errors with its own context rather than just propagating generic failures. This creates rich error messages that help users understand exactly where profiling failed and why.</p>\n<p><strong>Resource Lifecycle Management</strong> makes each component responsible for cleaning up its own resources, with clear ownership transfer semantics at component boundaries. This prevents resource leaks even when profiling encounters errors or is interrupted.</p>\n<h3 id=\"recommended-file-structure\">Recommended File Structure</h3>\n<p>The codebase organization reflects the component architecture while providing clear separation between core profiling logic, infrastructure concerns, and user-facing interfaces. This structure supports both development workflow efficiency and long-term maintainability as the profiler grows in complexity.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n├── README.md                           # Project overview and quick start\n├── requirements.txt                    # Python dependencies\n├── setup.py                           # Installation configuration\n├── pyproject.toml                     # Modern Python project metadata\n├── \n├── profiler/                          # Main package\n│   ├── __init__.py                    # Package exports and version\n│   ├── config/                        # Configuration management\n│   │   ├── __init__.py\n│   │   ├── models.py                  # ProfilerConfig, SamplingConfig, etc.\n│   │   ├── loader.py                  # from_json, to_json functions\n│   │   └── defaults.py                # Default configuration values\n│   │\n│   ├── sampling/                      # Stack Sampling Component (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── sampler.py                 # Main Sampler class\n│   │   ├── stack_unwinder.py          # Stack frame walking logic\n│   │   ├── signal_handler.py          # SIGPROF signal handling\n│   │   └── sample_storage.py          # Sample collection and buffering\n│   │\n│   ├── symbols/                       # Symbol Resolution Component (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── symbolizer.py              # Main Symbolizer class\n│   │   ├── elf_parser.py              # ELF binary and symbol table parsing\n│   │   ├── dwarf_reader.py            # DWARF debug information processing\n│   │   ├── symbol_cache.py            # Address-to-symbol caching\n│   │   └── cpp_demangler.py           # C++ name demangling\n│   │\n│   ├── aggregation/                   # Data Aggregation Component (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── aggregator.py              # Main Aggregator class\n│   │   ├── stack_folder.py            # Stack folding and merging logic\n│   │   ├── call_tree.py               # Hierarchical call tree construction\n│   │   └── statistics.py             # Sample counting and percentage calculations\n│   │\n│   ├── visualization/                 # Flame Graph Generation Component (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── visualizer.py              # Main Visualizer class\n│   │   ├── flame_graph.py             # SVG flame graph generation\n│   │   ├── svg_builder.py             # SVG DOM construction utilities\n│   │   ├── color_schemes.py           # Color coding for different function types\n│   │   └── interactive.py             # JavaScript for zoom/search functionality\n│   │\n│   ├── memory/                        # Memory Profiling Component (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── memory_profiler.py         # Main memory tracking class\n│   │   ├── allocation_tracker.py      # Malloc/free interception\n│   │   ├── leak_detector.py           # Memory leak identification\n│   │   └── allocation_flame_graph.py  # Memory-specific visualizations\n│   │\n│   ├── core/                          # Shared infrastructure\n│   │   ├── __init__.py\n│   │   ├── data_models.py             # Sample, StackFrame, Symbol, Profile classes\n│   │   ├── utils.py                   # format_bytes, format_percentage, timer_context\n│   │   ├── logging.py                 # setup_logging and profiler-specific loggers\n│   │   └── exceptions.py              # Custom exception classes\n│   │\n│   └── cli/                           # Command-line interface\n│       ├── __init__.py\n│       ├── main.py                    # Main CLI entry point\n│       ├── commands/                  # Subcommand implementations\n│       │   ├── __init__.py\n│       │   ├── profile.py             # profile_process command\n│       │   ├── symbolize.py           # symbolize_profile command\n│       │   └── visualize.py           # generate_flame_graph command\n│       └── output.py                  # Output formatting utilities\n│\n├── tests/                             # Test suite\n│   ├── __init__.py\n│   ├── conftest.py                    # Pytest configuration and fixtures\n│   ├── unit/                          # Unit tests for individual components\n│   │   ├── test_sampler.py\n│   │   ├── test_symbolizer.py\n│   │   ├── test_aggregator.py\n│   │   ├── test_visualizer.py\n│   │   └── test_memory_profiler.py\n│   ├── integration/                   # Integration tests across components\n│   │   ├── test_full_pipeline.py\n│   │   └── test_memory_tracking.py\n│   └── fixtures/                      # Test data and sample programs\n│       ├── sample_programs/           # Test programs to profile\n│       ├── expected_outputs/          # Reference flame graphs and reports\n│       └── debug_symbols/             # Test binaries with debug info\n│\n├── examples/                          # Usage examples and tutorials\n│   ├── basic_profiling.py             # Simple profiling example\n│   ├── memory_leak_detection.py       # Memory profiling example\n│   ├── custom_visualization.py        # Advanced flame graph customization\n│   └── config_examples/               # Sample configuration files\n│       ├── high_frequency.json        # High-frequency sampling config\n│       ├── memory_focused.json        # Memory-heavy profiling config\n│       └── production.json            # Low-overhead production config\n│\n├── docs/                              # Documentation\n│   ├── architecture.md               # This design document\n│   ├── api_reference.md              # API documentation\n│   ├── troubleshooting.md            # Common issues and solutions\n│   └── performance_tuning.md         # Profiler optimization guide\n│\n└── scripts/                          # Development and deployment scripts\n    ├── install_deps.sh               # Dependency installation\n    ├── run_tests.sh                  # Test suite runner\n    ├── benchmark_profiler.sh         # Performance benchmarking\n    └── generate_docs.sh              # Documentation generation</code></pre></div>\n\n<h4 id=\"file-organization-rationale\">File Organization Rationale</h4>\n<p>This structure reflects several key organizational principles that support both development efficiency and long-term maintainability:</p>\n<p><strong>Component-Based Directory Structure</strong> mirrors the architectural components directly, making it easy for developers to locate functionality and understand system boundaries. Each major component gets its own top-level directory under the main package, with clear ownership of related functionality.</p>\n<p><strong>Separation of Core Logic and Infrastructure</strong> distinguishes between domain-specific profiling logic (sampling, symbols, etc.) and cross-cutting infrastructure concerns (configuration, logging, utilities). This separation enables easier testing and reuse of infrastructure components.</p>\n<p><strong>Clear Public API Surface</strong> through the <code>__init__.py</code> files that explicitly define what each module exports. This prevents accidental coupling to internal implementation details and makes it easier to refactor code within modules without breaking external users.</p>\n<p><strong>Test Organization Matching Source Structure</strong> with unit tests organized by component and integration tests covering cross-component workflows. This makes it easy to run focused test suites during development and ensures comprehensive coverage.</p>\n<p><strong>Example-Driven Documentation</strong> through the examples directory that shows realistic usage patterns rather than just API reference material. These examples serve as both documentation and integration tests for common workflows.</p>\n<h4 id=\"module-dependency-guidelines\">Module Dependency Guidelines</h4>\n<p>The file structure enforces several dependency rules that maintain architectural integrity:</p>\n<p><strong>Core Module Independence</strong> ensures that the <code>core/</code> directory contains only foundational types and utilities with no dependencies on specific profiling components. This enables safe importing of data models and utilities from any component.</p>\n<p><strong>Component Isolation</strong> means components should primarily depend on the core module and external libraries, not directly on each other. Cross-component communication happens through well-defined data types in the core module.</p>\n<p><strong>CLI as Thin Orchestration Layer</strong> keeps command-line interface code focused on argument parsing and component orchestration rather than embedding business logic. This enables easy creation of alternative interfaces (web UI, programmatic API) without duplicating functionality.</p>\n<p><strong>Test Dependency Direction</strong> allows tests to depend on any source module but prevents source modules from depending on test utilities. This keeps the production code clean while enabling comprehensive testing infrastructure.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The implementation of this architecture requires careful attention to both the component interfaces and the infrastructure that supports them. The following guidance provides concrete starting points and patterns that support the architectural principles while avoiding common pitfalls.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Recommended for Learning</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Configuration</strong></td>\n<td>JSON files + Python dict</td>\n<td>YAML with schema validation (Pydantic)</td>\n<td>JSON + dict (simple parsing)</td>\n</tr>\n<tr>\n<td><strong>Signal Handling</strong></td>\n<td>Python signal module</td>\n<td>Custom C extension with signal masks</td>\n<td>Python signal module</td>\n</tr>\n<tr>\n<td><strong>Stack Unwinding</strong></td>\n<td>Python traceback module</td>\n<td>libunwind or custom frame walking</td>\n<td>Python traceback (limited depth)</td>\n</tr>\n<tr>\n<td><strong>ELF Parsing</strong></td>\n<td>pyelftools library</td>\n<td>Custom binary parser</td>\n<td>pyelftools (handles complexity)</td>\n</tr>\n<tr>\n<td><strong>SVG Generation</strong></td>\n<td>String templates + formatting</td>\n<td>XML DOM library (lxml)</td>\n<td>String templates (direct control)</td>\n</tr>\n<tr>\n<td><strong>Memory Interception</strong></td>\n<td>LD_PRELOAD wrapper script</td>\n<td>Python ctypes hooks</td>\n<td>LD_PRELOAD (easier debugging)</td>\n</tr>\n</tbody></table>\n<h4 id=\"configuration-infrastructure-starter-code\">Configuration Infrastructure Starter Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># profiler/config/models.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SamplingConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for statistical sampling behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    frequency_hz: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_stack_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 64</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    include_kernel: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_overhead_percent: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate configuration values and raise ValueError for invalid settings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.frequency_hz </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"frequency_hz must be 1-10000, got </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.frequency_hz</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_stack_depth </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 256</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"max_stack_depth must be 1-256, got </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.max_stack_depth</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.target_overhead_percent </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 50.0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"target_overhead_percent must be 0.1-50.0, got </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.target_overhead_percent</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for address-to-symbol resolution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_dwarf: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_symbols: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    demangle_cpp: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_search_paths: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.symbol_search_paths </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.symbol_search_paths </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">\"/usr/lib/debug\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"/usr/local/lib/debug\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VisualizationConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for flame graph generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    color_scheme: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"hot\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_width_pixels: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"CPU Profile\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_search: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_zoom: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Top-level profiler configuration combining all component settings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sampling: SamplingConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbols: SymbolConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    visualization: VisualizationConfig</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    output_directory: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"./profiler_output\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_json</span><span style=\"color:#E1E4E8\">(cls, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'ProfilerConfig'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load configuration from JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(config_path, </span><span style=\"color:#9ECBFF\">'r'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> json.load(f)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            sampling</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SamplingConfig(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'sampling'</span><span style=\"color:#E1E4E8\">, {})),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SymbolConfig(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'symbols'</span><span style=\"color:#E1E4E8\">, {})),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            visualization</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">VisualizationConfig(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'visualization'</span><span style=\"color:#E1E4E8\">, {})),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            output_directory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">data.get(</span><span style=\"color:#9ECBFF\">'output_directory'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'./profiler_output'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_json</span><span style=\"color:#E1E4E8\">(self, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Save configuration to JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'sampling'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.sampling.</span><span style=\"color:#79B8FF\">__dict__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'symbols'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.symbols.</span><span style=\"color:#79B8FF\">__dict__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'visualization'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.visualization.</span><span style=\"color:#79B8FF\">__dict__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'output_directory'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.output_directory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(config_path, </span><span style=\"color:#9ECBFF\">'w'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            json.dump(data, f, </span><span style=\"color:#FFAB70\">indent</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"core-data-model-infrastructure\">Core Data Model Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># profiler/core/data_models.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackFrame</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Single frame in a call stack.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filename: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_number: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_name: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_resolved</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if this frame has been symbolized.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.function_name </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Sample</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Single stack trace capture with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: datetime</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pid: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tid: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stack_frames: List[StackFrame]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.sample_id:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.sample_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(uuid.uuid4())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Profile</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete profiling session results.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time: datetime</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_time: Optional[datetime]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_pid: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    samples: List[Sample]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> duration_seconds</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate profile duration in seconds.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.end_time </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.end_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.start_time).total_seconds()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> sample_count</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get total number of samples collected.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.samples)</span></span></code></pre></div>\n\n<h4 id=\"utility-infrastructure\">Utility Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># profiler/core/utils.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Generator</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_bytes</span><span style=\"color:#E1E4E8\">(size_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format byte count as human readable string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> size_bytes </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"0 B\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    units </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'B'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'KB'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'MB'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GB'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'TB'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(size_bytes)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    unit_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> size </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 1024.0</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> unit_index </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(units) </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        size </span><span style=\"color:#F97583\">/=</span><span style=\"color:#79B8FF\"> 1024.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        unit_index </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">size</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {</span><span style=\"color:#E1E4E8\">units[unit_index]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> format_percentage</span><span style=\"color:#E1E4E8\">(value: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, total: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Format value as percentage with appropriate precision.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> total </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"0.00%\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    percentage </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (value </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> percentage </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 10.0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">percentage</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">%\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    elif</span><span style=\"color:#E1E4E8\"> percentage </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">percentage</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">%\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">percentage</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">%\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> timer_context</span><span style=\"color:#E1E4E8\">(operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Generator[</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for timing operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#9ECBFF\">'profiler.timing'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.debug(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Starting </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        duration </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Completed </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">duration</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># profiler/core/logging.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> setup_logging</span><span style=\"color:#E1E4E8\">(level: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"INFO\"</span><span style=\"color:#E1E4E8\">, log_file: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configure logging system for profiler components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Create formatter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    formatter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.Formatter(</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        '</span><span style=\"color:#79B8FF\">%(asctime)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(name)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(levelname)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(message)s</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Configure root logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    root_logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#9ECBFF\">'profiler'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    root_logger.setLevel(</span><span style=\"color:#79B8FF\">getattr</span><span style=\"color:#E1E4E8\">(logging, level.upper()))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Console handler</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    console_handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.StreamHandler(sys.stderr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    console_handler.setFormatter(formatter)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    root_logger.addHandler(console_handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # File handler if specified</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> log_file:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        file_handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.FileHandler(log_file)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        file_handler.setFormatter(formatter)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        root_logger.addHandler(file_handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Component-specific loggers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> component </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'sampling'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'symbols'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'aggregation'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'visualization'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'memory'</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'profiler.</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">component</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.setLevel(</span><span style=\"color:#79B8FF\">getattr</span><span style=\"color:#E1E4E8\">(logging, level.upper()))</span></span></code></pre></div>\n\n<h4 id=\"core-component-interface-skeletons\">Core Component Interface Skeletons</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># profiler/sampling/sampler.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.core.data_models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Profile, Sample</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.config.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SamplingConfig</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Sampler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Statistical sampling component for capturing call stacks.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: SamplingConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize signal handler setup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize sample storage buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up timer for sampling frequency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> profile_process</span><span style=\"color:#E1E4E8\">(self, pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, duration_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Collect profiling samples from target process.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            pid: Process ID to profile</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            duration_seconds: How long to collect samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Profile containing all collected samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that target process exists and is accessible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Install SIGPROF signal handler in target process</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Configure timer to fire at configured frequency_hz</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Start timer and begin sample collection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Sleep for duration_seconds while samples accumulate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Stop timer and disable signal handler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Collect all buffered samples and return Profile</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use signal.alarm() for timer setup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Signal handler must be async-signal-safe (no malloc)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># profiler/symbols/symbolizer.py  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.core.data_models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Profile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.config.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SymbolConfig</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Symbolizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Address-to-symbol resolution component.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: SymbolConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize symbol cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up ELF parser</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Configure DWARF reader if enabled</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> symbolize_profile</span><span style=\"color:#E1E4E8\">(self, profile: Profile) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resolve addresses to function names for all samples.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            profile: Profile with raw address samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Profile with resolved function names and source locations</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load symbol tables for target process binary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load symbol tables for all shared libraries  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each sample in profile.samples:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4:   For each stack frame in sample.stack_frames:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5:     Look up address in symbol cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6:     If not cached, resolve via ELF + DWARF</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7:     Update frame with function_name, filename, line_number</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8:     Store result in symbol cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Return profile with all frames symbolized</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use pyelftools for ELF parsing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Cache negative lookups to avoid repeated failed resolutions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-implementation-notes\">Language-Specific Implementation Notes</h4>\n<p><strong>Signal Handling in Python</strong>: Use the <code>signal</code> module for SIGPROF installation, but be aware that Python&#39;s signal handling has limitations. The signal handler must be extremely lightweight and avoid calling most Python functions that might trigger garbage collection or memory allocation.</p>\n<p><strong>Stack Unwinding Options</strong>: Python&#39;s built-in <code>traceback</code> module works well for Python code but cannot capture native C extensions or kernel frames. For more complete stack traces, consider using the <code>py-spy</code> approach of reading <code>/proc/PID/maps</code> and walking frame pointers manually.</p>\n<p><strong>ELF Parsing Tools</strong>: The <code>pyelftools</code> library handles most ELF parsing complexity and DWARF debug information reading. Install with <code>pip install pyelftools</code>. For performance-critical applications, consider caching parsed symbols to disk.</p>\n<p><strong>Memory Interception</strong>: Python&#39;s <code>ctypes</code> library can intercept malloc/free calls, but LD_PRELOAD with a simple C wrapper is often more reliable for comprehensive allocation tracking.</p>\n<h4 id=\"common-pitfalls-and-solutions\">Common Pitfalls and Solutions</h4>\n<p>⚠️ <strong>Pitfall: Circular Import Dependencies Between Components</strong>\nComponent modules that import each other create circular dependencies that prevent Python from loading the modules. This typically happens when components need to call each other&#39;s methods directly.\n<strong>Solution</strong>: Use dependency injection through constructor parameters or rely on the core data models for communication. Components should only import from <code>core/</code> and external libraries, not from sibling components.</p>\n<p>⚠️ <strong>Pitfall: Configuration Object Mutation</strong>\nIf components modify their configuration objects during runtime, it becomes impossible to reproduce profiling results or understand what settings were actually used.\n<strong>Solution</strong>: Make configuration objects immutable after creation (use <code>frozen=True</code> in dataclasses) and create new configuration instances for any modifications rather than mutating existing ones.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Error Handling Across Components</strong>\nWhen each component handles errors differently, it becomes difficult for users to understand what went wrong and how to fix it. Some components might fail silently while others crash loudly.\n<strong>Solution</strong>: Define a common exception hierarchy in <code>core/exceptions.py</code> and establish consistent error handling patterns. Each component should catch its specific errors and re-raise them as profiler-specific exceptions with added context.</p>\n<p>⚠️ <strong>Pitfall: Resource Leaks in Component Cleanup</strong>\nComponents that open files, create threads, or allocate memory but don&#39;t clean up properly can cause resource leaks that accumulate over multiple profiling sessions.\n<strong>Solution</strong>: Use Python context managers (<code>with</code> statements) for all resource management and implement <code>__enter__</code> and <code>__exit__</code> methods on component classes to ensure proper cleanup even when exceptions occur.</p>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) — these data structures underpin stack sampling, symbol resolution, flame graph generation, and memory profiling</p>\n</blockquote>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fdata-model-relationships.svg\" alt=\"Data Model Relationships\"></p>\n<h3 id=\"mental-model-the-evidence-collection-system\">Mental Model: The Evidence Collection System</h3>\n<p>Think of the profiler&#39;s data model as a comprehensive evidence collection system for a performance investigation. Just as a detective gathers different types of evidence (photographs, witness statements, forensic reports, timelines), our profiler collects different types of performance data that all interconnect to tell the complete story.</p>\n<p>The <strong>raw samples</strong> are like crime scene photographs — they capture exactly what was happening at a specific moment in time, preserving the call stack &quot;scene&quot; with all its details. The <strong>symbol information</strong> acts like a witness database — it helps us identify who the &quot;suspects&quot; (functions) are by translating anonymous addresses into recognizable names and locations. The <strong>memory allocation records</strong> are like financial transaction logs — they track every resource exchange (malloc/free) with timestamps and amounts. Finally, the <strong>aggregated flame graph data</strong> resembles the detective&#39;s final case file — all the evidence organized and cross-referenced to reveal patterns and highlight the most significant findings.</p>\n<p>This mental model helps explain why our data structures are designed with specific relationships: just as evidence must maintain chain of custody and cross-reference properly, our profiling data must preserve the connections between samples, symbols, and allocations while enabling efficient aggregation and analysis.</p>\n<h3 id=\"sample-and-stack-structures\">Sample and Stack Structures</h3>\n<p>The foundation of our profiler lies in accurately representing captured call stacks and their associated metadata. These data structures must balance completeness with efficiency, since we&#39;ll be creating thousands of samples per second during active profiling.</p>\n<h4 id=\"core-sample-representation\">Core Sample Representation</h4>\n<p>The <code>Sample</code> structure captures a single point-in-time snapshot of a thread&#39;s execution state. Each sample represents one &quot;photograph&quot; of the call stack taken during statistical sampling.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>timestamp</td>\n<td>float</td>\n<td>Unix timestamp with microsecond precision when sample was captured</td>\n</tr>\n<tr>\n<td>thread_id</td>\n<td>int</td>\n<td>Thread identifier that was sampled (OS thread ID)</td>\n</tr>\n<tr>\n<td>process_id</td>\n<td>int</td>\n<td>Process identifier containing the sampled thread</td>\n</tr>\n<tr>\n<td>stack_frames</td>\n<td>list[StackFrame]</td>\n<td>Ordered list of stack frames from innermost (leaf) to outermost (root)</td>\n</tr>\n<tr>\n<td>cpu_id</td>\n<td>int</td>\n<td>CPU core number where the sample was captured (-1 if unknown)</td>\n</tr>\n<tr>\n<td>sample_weight</td>\n<td>int</td>\n<td>Number of profiling events this sample represents (usually 1 for statistical sampling)</td>\n</tr>\n<tr>\n<td>context_switches</td>\n<td>int</td>\n<td>Number of context switches since last sample (if available)</td>\n</tr>\n<tr>\n<td>sample_type</td>\n<td>str</td>\n<td>Type of sample: &quot;cpu&quot;, &quot;wall&quot;, &quot;memory&quot;, or &quot;custom&quot;</td>\n</tr>\n</tbody></table>\n<p>The <code>timestamp</code> field uses floating-point Unix time to provide microsecond precision, which is essential for correlating samples with external events and understanding temporal patterns. The <code>thread_id</code> and <code>process_id</code> fields enable multi-process and multi-threaded profiling scenarios, allowing us to separate and aggregate samples by execution context.</p>\n<p>The <code>stack_frames</code> list maintains strict ordering from leaf to root, meaning <code>stack_frames[0]</code> contains the function that was actively executing when the sample was captured, and <code>stack_frames[-1]</code> contains the program&#39;s entry point (typically <code>main</code>). This ordering convention simplifies flame graph generation and stack folding algorithms.</p>\n<h4 id=\"stack-frame-representation\">Stack Frame Representation</h4>\n<p>Each <code>StackFrame</code> represents one level of the call stack, containing both raw address information and resolved symbolic data.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>address</td>\n<td>int</td>\n<td>Raw instruction pointer address where execution was sampled</td>\n</tr>\n<tr>\n<td>function_name</td>\n<td>str</td>\n<td>Resolved function name, or hex address string if resolution failed</td>\n</tr>\n<tr>\n<td>filename</td>\n<td>str</td>\n<td>Source code filename containing this function (empty string if unavailable)</td>\n</tr>\n<tr>\n<td>line_number</td>\n<td>int</td>\n<td>Source code line number within the file (0 if unavailable)</td>\n</tr>\n<tr>\n<td>module_name</td>\n<td>str</td>\n<td>Name of executable or shared library containing this address</td>\n</tr>\n<tr>\n<td>module_offset</td>\n<td>int</td>\n<td>Offset within the module where this address is located</td>\n</tr>\n<tr>\n<td>inlined_frames</td>\n<td>list[InlinedFrame]</td>\n<td>List of inlined function calls at this address (from DWARF info)</td>\n</tr>\n<tr>\n<td>is_kernel</td>\n<td>bool</td>\n<td>True if this frame represents kernel code execution</td>\n</tr>\n</tbody></table>\n<p>The <code>address</code> field preserves the raw instruction pointer value, which serves as the primary key for symbol resolution and enables address-based aggregation. Even after symbol resolution completes, we retain the original address for debugging and advanced analysis.</p>\n<p>The symbol resolution fields (<code>function_name</code>, <code>filename</code>, <code>line_number</code>) may be populated asynchronously after initial sample capture. This design allows the sampling component to operate at maximum speed without blocking on symbol lookups, which can be expensive I/O operations.</p>\n<p>The <code>module_name</code> and <code>module_offset</code> fields support debugging scenarios where multiple versions of the same library are loaded, or when analyzing core dumps where absolute addresses are meaningless but module-relative offsets remain valid.</p>\n<h4 id=\"inlined-function-handling\">Inlined Function Handling</h4>\n<p>Modern compilers aggressively inline functions for performance, but this creates challenges for profiling since multiple logical functions may be executing at a single instruction address. The <code>InlinedFrame</code> structure captures this information when available from DWARF debug data.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>function_name</td>\n<td>str</td>\n<td>Name of the inlined function</td>\n</tr>\n<tr>\n<td>filename</td>\n<td>str</td>\n<td>Source file containing the inlined function definition</td>\n</tr>\n<tr>\n<td>line_number</td>\n<td>int</td>\n<td>Line number where the inlined function is defined</td>\n</tr>\n<tr>\n<td>call_filename</td>\n<td>str</td>\n<td>Source file containing the call site that was inlined</td>\n</tr>\n<tr>\n<td>call_line_number</td>\n<td>int</td>\n<td>Line number of the call site that was inlined</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Architecture Decision: Separate Inlined Frame Storage</strong></p>\n<ul>\n<li><strong>Context</strong>: Compiler inlining means multiple logical function calls can exist at one instruction address</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Flatten inlined functions into separate StackFrame entries</li>\n<li>Store inlined functions as nested data within StackFrame</li>\n<li>Ignore inlined function information entirely</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Store as nested <code>inlined_frames</code> list within StackFrame</li>\n<li><strong>Rationale</strong>: Preserves the actual runtime call stack structure while maintaining inlined function visibility. Flattening would create &quot;fake&quot; addresses that don&#39;t exist at runtime, while ignoring inlined functions loses valuable debugging information for heavily optimized code.</li>\n<li><strong>Consequences</strong>: Flame graph generation must handle the nested structure, but we get accurate attribution of time to inlined functions without distorting the actual runtime stack.</li>\n</ul>\n</blockquote>\n<h4 id=\"sample-collection-and-batching\">Sample Collection and Batching</h4>\n<p>During high-frequency sampling, creating individual <code>Sample</code> objects for every captured stack would generate excessive memory allocation overhead. Our design uses a batching strategy to amortize this cost.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>samples</td>\n<td>list[Sample]</td>\n<td>Collected samples in chronological order</td>\n</tr>\n<tr>\n<td>start_time</td>\n<td>float</td>\n<td>Timestamp of first sample in this batch</td>\n</tr>\n<tr>\n<td>end_time</td>\n<td>float</td>\n<td>Timestamp of last sample in this batch</td>\n</tr>\n<tr>\n<td>dropped_samples</td>\n<td>int</td>\n<td>Number of samples lost due to signal handler overrun</td>\n</tr>\n<tr>\n<td>target_process</td>\n<td>str</td>\n<td>Command line or executable name of profiled process</td>\n</tr>\n<tr>\n<td>sampling_frequency</td>\n<td>int</td>\n<td>Configured sampling rate in Hz for this batch</td>\n</tr>\n<tr>\n<td>total_sample_time</td>\n<td>float</td>\n<td>Cumulative time spent in sampling signal handler</td>\n</tr>\n</tbody></table>\n<p>The <code>SampleBatch</code> structure groups samples collected during a time window, typically 1-10 seconds depending on sampling frequency and memory constraints. This batching enables efficient disk I/O when persisting samples and provides natural boundaries for streaming analysis.</p>\n<p>The <code>dropped_samples</code> field tracks sampling overhead and signal handler performance. When the signal handler takes too long to complete stack unwinding, the kernel may deliver the next SIGPROF before the previous handler finishes, causing sample loss. This metric helps detect when sampling frequency exceeds system capabilities.</p>\n<h3 id=\"symbol-and-debug-information\">Symbol and Debug Information</h3>\n<p>Symbol resolution transforms raw instruction pointer addresses into human-readable function names, source locations, and debugging metadata. Our symbol data structures optimize for both lookup performance and memory efficiency, since a typical profiling session may resolve millions of unique addresses.</p>\n<h4 id=\"symbol-table-representation\">Symbol Table Representation</h4>\n<p>The <code>Symbol</code> structure represents one resolved function symbol, containing all available debugging information for a specific address or address range.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>start_address</td>\n<td>int</td>\n<td>Starting address of this symbol&#39;s code range</td>\n</tr>\n<tr>\n<td>end_address</td>\n<td>int</td>\n<td>Ending address of this symbol&#39;s code range (exclusive)</td>\n</tr>\n<tr>\n<td>function_name</td>\n<td>str</td>\n<td>Demangled function name (original mangled name in raw_name)</td>\n</tr>\n<tr>\n<td>raw_name</td>\n<td>str</td>\n<td>Original symbol name from ELF symbol table (before C++ demangling)</td>\n</tr>\n<tr>\n<td>source_file</td>\n<td>str</td>\n<td>Primary source file containing this function definition</td>\n</tr>\n<tr>\n<td>line_ranges</td>\n<td>list[LineRange]</td>\n<td>Mapping from address ranges to source line numbers</td>\n</tr>\n<tr>\n<td>parameter_types</td>\n<td>list[str]</td>\n<td>Function parameter type names (from DWARF if available)</td>\n</tr>\n<tr>\n<td>return_type</td>\n<td>str</td>\n<td>Function return type name (from DWARF if available)</td>\n</tr>\n<tr>\n<td>is_inlined</td>\n<td>bool</td>\n<td>True if this function is only available as inlined instances</td>\n</tr>\n<tr>\n<td>compilation_unit</td>\n<td>str</td>\n<td>Source file that was compiled to produce this symbol</td>\n</tr>\n</tbody></table>\n<p>The address range design (<code>start_address</code>, <code>end_address</code>) enables efficient range-based lookups using binary search or interval trees. Most profiling queries ask &quot;what function contains address X?&quot; rather than &quot;what is the exact symbol at address X?&quot;, so range-based storage matches the access pattern.</p>\n<p>Function signature information (<code>parameter_types</code>, <code>return_type</code>) comes from DWARF debugging data when available, enabling rich IDE-like experiences in profiler UIs. This information helps distinguish between overloaded functions and provides context for performance analysis.</p>\n<h4 id=\"line-number-information\">Line Number Information</h4>\n<p>Source line attribution requires mapping instruction addresses to specific lines within source files. The <code>LineRange</code> structure captures this mapping efficiently.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>start_address</td>\n<td>int</td>\n<td>First instruction address mapped to this source line</td>\n</tr>\n<tr>\n<td>end_address</td>\n<td>int</td>\n<td>Last instruction address mapped to this source line (exclusive)</td>\n</tr>\n<tr>\n<td>line_number</td>\n<td>int</td>\n<td>Source line number within the file</td>\n</tr>\n<tr>\n<td>column_number</td>\n<td>int</td>\n<td>Column number within the source line (0 if unavailable)</td>\n</tr>\n<tr>\n<td>is_statement</td>\n<td>bool</td>\n<td>True if this address corresponds to a source statement boundary</td>\n</tr>\n<tr>\n<td>is_prologue_end</td>\n<td>bool</td>\n<td>True if this address marks the end of function prologue</td>\n</tr>\n<tr>\n<td>is_epilogue_begin</td>\n<td>bool</td>\n<td>True if this address marks the beginning of function epilogue</td>\n</tr>\n</tbody></table>\n<p>The <code>is_statement</code> flag helps distinguish between compiler-generated instructions and actual source code statements. When users set breakpoints or analyze performance at the source level, they typically care about statement boundaries rather than individual assembly instructions.</p>\n<p>Prologue and epilogue markers enable more accurate profiling attribution. Time spent in function prologues (setting up stack frames) and epilogues (cleanup) represents function call overhead rather than the function&#39;s core logic, so advanced analysis can separate these costs.</p>\n<h4 id=\"module-and-binary-information\">Module and Binary Information</h4>\n<p>The <code>Module</code> structure represents one executable file or shared library, containing metadata necessary for symbol resolution and address translation.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>name</td>\n<td>str</td>\n<td>Module name (basename of file, e.g., &quot;libc.so.6&quot;)</td>\n</tr>\n<tr>\n<td>path</td>\n<td>str</td>\n<td>Full filesystem path to the module file</td>\n</tr>\n<tr>\n<td>base_address</td>\n<td>int</td>\n<td>Virtual memory address where this module is loaded</td>\n</tr>\n<tr>\n<td>size</td>\n<td>int</td>\n<td>Size of the module&#39;s memory mapping in bytes</td>\n</tr>\n<tr>\n<td>build_id</td>\n<td>str</td>\n<td>Unique identifier for this specific build (from ELF build-id)</td>\n</tr>\n<tr>\n<td>symbols</td>\n<td>dict[int, Symbol]</td>\n<td>Symbol table mapping start addresses to Symbol objects</td>\n</tr>\n<tr>\n<td>has_debug_info</td>\n<td>bool</td>\n<td>True if DWARF debug information is available</td>\n</tr>\n<tr>\n<td>architecture</td>\n<td>str</td>\n<td>Target architecture (e.g., &quot;x86_64&quot;, &quot;aarch64&quot;)</td>\n</tr>\n<tr>\n<td>load_time</td>\n<td>float</td>\n<td>Timestamp when this module was loaded (for dynamic libraries)</td>\n</tr>\n</tbody></table>\n<p>The <code>build_id</code> field provides definitive version identification, which is crucial when profiling systems with multiple versions of the same library or when analyzing offline profile data. Build IDs prevent symbol resolution errors caused by version mismatches between the profiled binary and the debugging session.</p>\n<p>The <code>base_address</code> enables translation between file offsets (used in symbol tables) and runtime virtual addresses (captured in samples). Address Space Layout Randomization (ASLR) means the same executable will load at different base addresses on each run, so this translation is essential for symbol resolution.</p>\n<blockquote>\n<p><strong>Architecture Decision: Lazy Symbol Loading Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Large applications may contain millions of symbols, but profiling typically only encounters a small subset</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Load all symbols from all modules at profiler startup</li>\n<li>Load symbols on-demand as addresses are encountered during resolution</li>\n<li>Pre-load symbols only for the main executable, lazy-load for libraries</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Hybrid approach — pre-load main executable symbols, lazy-load library symbols on first access</li>\n<li><strong>Rationale</strong>: Main executable symbols are frequently accessed and relatively small. Library symbols are numerous but sparsely accessed, so lazy loading reduces memory usage and startup time. Full eager loading would consume excessive memory and slow profiler startup.</li>\n<li><strong>Consequences</strong>: Symbol resolution has variable latency (first access to a library is slower), but overall memory usage scales with actual profiling patterns rather than total available symbols.</li>\n</ul>\n</blockquote>\n<h4 id=\"symbol-cache-and-performance\">Symbol Cache and Performance</h4>\n<p>Symbol resolution involves expensive operations like ELF file parsing, DWARF processing, and string demangling. The <code>SymbolCache</code> structure optimizes repeated lookups and manages memory usage.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>address_to_symbol</td>\n<td>dict[int, Symbol]</td>\n<td>Direct mapping from instruction addresses to resolved symbols</td>\n</tr>\n<tr>\n<td>module_cache</td>\n<td>dict[str, Module]</td>\n<td>Cache of loaded module information by build ID</td>\n</tr>\n<tr>\n<td>demangled_names</td>\n<td>dict[str, str]</td>\n<td>Cache of demangled C++ function names</td>\n</tr>\n<tr>\n<td>miss_cache</td>\n<td>set[int]</td>\n<td>Set of addresses known to have no symbol information</td>\n</tr>\n<tr>\n<td>cache_size_bytes</td>\n<td>int</td>\n<td>Current memory usage of all cached data</td>\n</tr>\n<tr>\n<td>max_cache_size</td>\n<td>int</td>\n<td>Maximum allowed cache size before eviction begins</td>\n</tr>\n<tr>\n<td>hit_count</td>\n<td>int</td>\n<td>Number of successful cache lookups (for performance metrics)</td>\n</tr>\n<tr>\n<td>miss_count</td>\n<td>int</td>\n<td>Number of cache misses requiring expensive resolution</td>\n</tr>\n</tbody></table>\n<p>The <code>miss_cache</code> prevents repeated expensive lookups for addresses that have no symbol information (common in JIT-compiled code, dynamically generated code, or stripped binaries). Recording negative results eliminates redundant file I/O and parsing attempts.</p>\n<p>Cache eviction uses a hybrid strategy: least-recently-used (LRU) for individual symbols, but never evicts entire modules unless memory pressure is severe. This design reflects the access pattern where recently seen addresses are likely to be seen again (temporal locality), but module metadata has high setup cost and should be preserved.</p>\n<h3 id=\"memory-allocation-structures\">Memory Allocation Structures</h3>\n<p>Memory profiling tracks heap allocations throughout program execution, recording allocation sites, sizes, and lifetimes to identify memory leaks and usage patterns. These data structures must handle millions of allocation events with minimal overhead to avoid skewing the program&#39;s memory behavior.</p>\n<h4 id=\"allocation-event-tracking\">Allocation Event Tracking</h4>\n<p>The <code>Allocation</code> structure represents one heap allocation event, capturing the allocation context and metadata necessary for leak detection and usage analysis.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>allocation_id</td>\n<td>int</td>\n<td>Unique identifier for this allocation (typically the returned pointer value)</td>\n</tr>\n<tr>\n<td>size</td>\n<td>int</td>\n<td>Number of bytes requested in the allocation call</td>\n</tr>\n<tr>\n<td>actual_size</td>\n<td>int</td>\n<td>Actual bytes allocated by the heap (may be larger due to alignment/bookkeeping)</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>float</td>\n<td>Unix timestamp when allocation occurred</td>\n</tr>\n<tr>\n<td>thread_id</td>\n<td>int</td>\n<td>Thread ID that performed the allocation</td>\n</tr>\n<tr>\n<td>allocation_stack</td>\n<td>list[StackFrame]</td>\n<td>Call stack leading to malloc/new/etc.</td>\n</tr>\n<tr>\n<td>is_freed</td>\n<td>bool</td>\n<td>True if this allocation has been freed</td>\n</tr>\n<tr>\n<td>free_timestamp</td>\n<td>float</td>\n<td>Unix timestamp when deallocation occurred (0.0 if not freed)</td>\n</tr>\n<tr>\n<td>free_thread_id</td>\n<td>int</td>\n<td>Thread ID that performed the deallocation (-1 if not freed)</td>\n</tr>\n<tr>\n<td>allocation_type</td>\n<td>str</td>\n<td>Type of allocation: &quot;malloc&quot;, &quot;calloc&quot;, &quot;realloc&quot;, &quot;new&quot;, &quot;new[]&quot;</td>\n</tr>\n</tbody></table>\n<p>The dual size tracking (<code>size</code> vs <code>actual_size</code>) helps identify heap fragmentation and memory manager overhead. Many allocators round up requests to alignment boundaries or add metadata headers, so the actual memory consumption may significantly exceed requested amounts.</p>\n<p>The <code>allocation_id</code> typically uses the returned pointer value as a unique identifier, which simplifies tracking through the malloc/free lifecycle. However, pointer reuse (where a freed address is returned by a subsequent malloc) requires careful handling to avoid incorrectly matching allocations with frees from previous allocations.</p>\n<p>Stack trace capture at allocation sites enables powerful analysis of memory usage patterns. Unlike CPU profiling, where we sample periodically, memory profiling captures a stack trace for every allocation, providing complete call path information for every byte allocated.</p>\n<h4 id=\"memory-usage-timeline\">Memory Usage Timeline</h4>\n<p>The <code>MemorySnapshot</code> structure captures heap state at regular intervals, enabling visualization of memory usage over time and identification of memory growth trends.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>timestamp</td>\n<td>float</td>\n<td>Unix timestamp when this snapshot was captured</td>\n</tr>\n<tr>\n<td>total_allocated</td>\n<td>int</td>\n<td>Cumulative bytes allocated since profiling began</td>\n</tr>\n<tr>\n<td>total_freed</td>\n<td>int</td>\n<td>Cumulative bytes freed since profiling began</td>\n</tr>\n<tr>\n<td>live_bytes</td>\n<td>int</td>\n<td>Current bytes allocated but not yet freed</td>\n</tr>\n<tr>\n<td>live_allocations</td>\n<td>int</td>\n<td>Current number of allocations not yet freed</td>\n</tr>\n<tr>\n<td>heap_size</td>\n<td>int</td>\n<td>Total heap size from system (if available)</td>\n</tr>\n<tr>\n<td>fragmentation_bytes</td>\n<td>int</td>\n<td>Bytes lost to heap fragmentation (heap_size - live_bytes)</td>\n</tr>\n<tr>\n<td>allocation_rate</td>\n<td>float</td>\n<td>Recent allocation rate in bytes per second</td>\n</tr>\n<tr>\n<td>free_rate</td>\n<td>float</td>\n<td>Recent deallocation rate in bytes per second</td>\n</tr>\n</tbody></table>\n<p>Timeline snapshots enable detection of memory leaks (continuously increasing <code>live_bytes</code>), allocation bursts (spikes in <code>allocation_rate</code>), and fragmentation issues (growing gap between <code>heap_size</code> and <code>live_bytes</code>). This temporal view complements the detailed per-allocation data.</p>\n<p>The rate calculations (<code>allocation_rate</code>, <code>free_rate</code>) use exponential smoothing over recent samples to provide stable measurements despite the bursty nature of memory allocations. Raw rates would fluctuate wildly, making trend detection difficult.</p>\n<h4 id=\"leak-detection-and-classification\">Leak Detection and Classification</h4>\n<p>The <code>MemoryLeak</code> structure represents a detected memory leak, combining allocation information with analysis of why the allocation is considered leaked.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>allocation</td>\n<td>Allocation</td>\n<td>The leaked allocation record</td>\n</tr>\n<tr>\n<td>leak_confidence</td>\n<td>float</td>\n<td>Confidence score (0.0-1.0) that this is actually a leak</td>\n</tr>\n<tr>\n<td>leak_category</td>\n<td>str</td>\n<td>Classification: &quot;definite&quot;, &quot;probable&quot;, &quot;possible&quot;, &quot;reachable&quot;</td>\n</tr>\n<tr>\n<td>allocation_age</td>\n<td>float</td>\n<td>Time in seconds since allocation occurred</td>\n</tr>\n<tr>\n<td>similar_leaks</td>\n<td>int</td>\n<td>Number of other leaks with identical call stack</td>\n</tr>\n<tr>\n<td>total_leaked_bytes</td>\n<td>int</td>\n<td>Total bytes leaked by this call stack pattern</td>\n</tr>\n<tr>\n<td>detection_method</td>\n<td>str</td>\n<td>How this leak was identified: &quot;unreachable&quot;, &quot;exit_scan&quot;, &quot;periodic_scan&quot;</td>\n</tr>\n<tr>\n<td>suppression_matched</td>\n<td>str</td>\n<td>Name of suppression rule that matches this leak (empty if not suppressed)</td>\n</tr>\n</tbody></table>\n<p>Leak classification reflects different levels of certainty about whether an allocation represents a true bug. &quot;Definite&quot; leaks are allocations with no remaining pointers anywhere in the program&#39;s memory. &quot;Probable&quot; leaks have pointers that exist but appear to be in freed memory or other unlikely locations. &quot;Possible&quot; leaks have pointers but in locations that suggest they may be false positives (like uninitialized memory that happens to contain the right bit pattern).</p>\n<p>The <code>similar_leaks</code> and <code>total_leaked_bytes</code> fields enable aggregation of leak reports. Instead of reporting 10,000 individual leaked strings, we can report &quot;10,000 leaks totaling 500KB from <code>parse_config()</code> at line 42&quot;, which provides more actionable information.</p>\n<blockquote>\n<p><strong>Architecture Decision: Allocation Tracking Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Memory profiling must intercept every malloc/free call without significantly impacting performance or memory usage</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>LD_PRELOAD wrapper that replaces malloc/free with instrumented versions</li>\n<li>Compiler instrumentation that adds tracking code at every allocation site</li>\n<li>Dynamic binary instrumentation using tools like Intel Pin</li>\n<li>Operating system-level tracking using kernel tracing facilities</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: LD_PRELOAD approach with efficient data structures and batched reporting</li>\n<li><strong>Rationale</strong>: LD_PRELOAD works with existing binaries without recompilation, has predictable overhead, and provides complete allocation coverage. Compiler instrumentation requires source code access and recompilation. Dynamic instrumentation has higher overhead. OS-level tracking lacks call stack information.</li>\n<li><strong>Consequences</strong>: Easy integration with existing applications, but limited to dynamically linked binaries. Static binaries and programs that use custom allocators require different approaches.</li>\n</ul>\n</blockquote>\n<h4 id=\"allocation-site-analysis\">Allocation Site Analysis</h4>\n<p>The <code>AllocationSite</code> structure aggregates multiple allocations that originate from the same code location, enabling identification of the highest-impact allocation sources.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>call_stack_hash</td>\n<td>int</td>\n<td>Hash of the allocation call stack for grouping</td>\n</tr>\n<tr>\n<td>representative_stack</td>\n<td>list[StackFrame]</td>\n<td>Full call stack for one allocation from this site</td>\n</tr>\n<tr>\n<td>total_allocations</td>\n<td>int</td>\n<td>Number of allocations performed from this call stack</td>\n</tr>\n<tr>\n<td>total_bytes</td>\n<td>int</td>\n<td>Cumulative bytes allocated from this call stack</td>\n</tr>\n<tr>\n<td>peak_live_bytes</td>\n<td>int</td>\n<td>Maximum bytes simultaneously live from this call stack</td>\n</tr>\n<tr>\n<td>peak_live_count</td>\n<td>int</td>\n<td>Maximum simultaneous live allocations from this call stack</td>\n</tr>\n<tr>\n<td>average_size</td>\n<td>float</td>\n<td>Average allocation size from this call stack</td>\n</tr>\n<tr>\n<td>lifetime_distribution</td>\n<td>list[int]</td>\n<td>Histogram of allocation lifetimes in time buckets</td>\n</tr>\n<tr>\n<td>first_seen</td>\n<td>float</td>\n<td>Timestamp of first allocation from this call stack</td>\n</tr>\n<tr>\n<td>last_seen</td>\n<td>float</td>\n<td>Timestamp of most recent allocation from this call stack</td>\n</tr>\n</tbody></table>\n<p>Call stack hashing (<code>call_stack_hash</code>) enables efficient grouping of allocations with identical origins. The hash typically includes function names and line numbers from the top N frames of the call stack, balancing between specificity and grouping effectiveness.</p>\n<p>Lifetime distribution analysis reveals allocation patterns that inform optimization strategies. Short-lived allocations might benefit from stack allocation or object pooling, while long-lived allocations might indicate opportunities for lazy initialization or more efficient data structures.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Excessive Memory Overhead from Metadata</strong>\nMany implementations store too much metadata per sample or allocation, causing the profiler to consume more memory than the program being profiled. Calculate the expected memory usage: at 1000Hz sampling with 10-frame stacks, you&#39;ll generate 36MB of sample data per hour (assuming 1KB per sample). Design your data structures to minimize per-sample overhead and implement batching or streaming to disk.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Address Space Layout Randomization (ASLR) Handling</strong>\nStoring absolute addresses without accounting for ASLR breaks symbol resolution when analyzing profile data on a different system or after a program restart. Always store module-relative offsets alongside absolute addresses, and include module base addresses and build IDs in your data model. This enables symbol resolution even when the binary loads at a different address.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Memory Allocation Tracking</strong>\nUsing the returned pointer address directly as an allocation ID creates race conditions when addresses are reused. A common bug is matching a free() call to the wrong allocation because the same address was returned by a previous malloc/free cycle. Include allocation sequence numbers or timestamps in your allocation IDs to distinguish between different uses of the same address.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Compiler Optimizations in Stack Traces</strong>\nModern compilers perform aggressive optimizations like inlining, tail call optimization, and frame pointer omission that distort call stacks. Your data model must handle missing frame pointers (use DWARF CFI for unwinding), inlined functions (store nested inline information), and optimized-away frames (mark synthetic frames). Without this, flame graphs will show incorrect call relationships and missing functions.</p>\n<p>⚠️ <strong>Pitfall: Inefficient Symbol Resolution Caching</strong>\nSymbol resolution is expensive, but naive caching strategies can consume excessive memory. A common mistake is caching every resolved address individually instead of caching at the module level. Cache symbol tables per-module and use range-based lookups instead of per-address entries. Also implement cache eviction policies, or long-running profiling sessions will exhaust system memory.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation patterns and starter code for the data model components, focusing on Python as the primary language while highlighting key design decisions that apply to all languages.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Data Serialization</td>\n<td>JSON with Python <code>json</code> module</td>\n<td>Protocol Buffers with <code>protobuf</code> library</td>\n</tr>\n<tr>\n<td>Symbol Parsing</td>\n<td><code>pyelftools</code> library for ELF/DWARF</td>\n<td>Custom C extension with <code>libelf</code> and <code>libdw</code></td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>Python lists and dicts with periodic cleanup</td>\n<td><code>numpy</code> arrays for sample data, <code>sqlite3</code> for large datasets</td>\n</tr>\n<tr>\n<td>Caching Strategy</td>\n<td>Simple <code>dict</code> with size limits</td>\n<td><code>functools.lru_cache</code> or Redis for persistent caching</td>\n</tr>\n<tr>\n<td>Performance Monitoring</td>\n<td>Basic timing with <code>time.time()</code></td>\n<td><code>cProfile</code> integration with custom metrics</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n├── data_model/\n│   ├── __init__.py              ← Export main types\n│   ├── sample.py                ← Sample and StackFrame classes\n│   ├── symbol.py                ← Symbol resolution data structures\n│   ├── memory.py                ← Memory allocation tracking structures\n│   ├── cache.py                 ← Symbol and data caching implementations\n│   └── serialization.py        ← Save/load profile data to disk\n├── collectors/\n│   ├── stack_sampler.py         ← Stack sampling implementation\n│   ├── symbol_resolver.py       ← Symbol resolution implementation\n│   └── memory_tracker.py       ← Memory allocation tracking\n├── analysis/\n│   ├── flame_graph.py           ← Flame graph generation\n│   └── leak_detector.py        ← Memory leak analysis\n└── utils/\n    ├── elf_parser.py            ← ELF file parsing utilities\n    └── dwarf_reader.py          ← DWARF debug info reader</code></pre></div>\n\n<h4 id=\"core-data-structure-implementation\">Core Data Structure Implementation</h4>\n<p><strong>Complete Sample Data Structures (sample.py):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core data structures for representing profiling samples and call stacks.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides efficient storage and manipulation of captured execution state.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SampleType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Types of profiling samples that can be captured.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CPU</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cpu\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WALL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"wall\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MEMORY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"memory\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CUSTOM</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"custom\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackFrame</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents one frame in a call stack with symbol information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                           # Raw instruction pointer address</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">               # Resolved function name (empty if unresolved)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filename: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">                    # Source file containing this function</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                  # Source line number (0 if unknown)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">                 # Executable/library containing this address</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_offset: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                # Offset within the module</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    inlined_frames: List[</span><span style=\"color:#9ECBFF\">'InlinedFrame'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_kernel: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">               # True for kernel code execution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate frame data and set defaults.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.address </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Invalid negative address: </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.address</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.function_name </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.address </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.function_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"0x</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.address</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#6A737D\">  # Fallback to hex address</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> InlinedFrame</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents an inlined function call within a stack frame.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                    # Name of inlined function</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filename: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                         # Source file of inlined function</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                      # Line number of inlined function definition</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    call_filename: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">               # Source file containing the call site</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    call_line_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">             # Line number of inlined call site</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Sample</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Individual stack trace capture with timing and context metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                      # Unix timestamp with microsecond precision</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                        # OS thread identifier</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    process_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                       # OS process identifier  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stack_frames: List[StackFrame]        </span><span style=\"color:#6A737D\"># Stack trace from leaf to root</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cpu_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#6A737D\">                      # CPU core number (-1 if unknown)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_weight: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">                # Number of events this sample represents</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context_switches: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">             # Context switches since last sample</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_type: SampleType </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SampleType.</span><span style=\"color:#79B8FF\">CPU</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate sample data and normalize timestamps.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.stack_frames:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Sample must contain at least one stack frame\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.sample_weight </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sample weight must be positive: </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.sample_weight</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SampleBatch</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Collection of samples with metadata for batch processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    samples: List[Sample]                 </span><span style=\"color:#6A737D\"># Samples in chronological order</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                     # Timestamp of first sample</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                       # Timestamp of last sample</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dropped_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">              # Samples lost due to overrun</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_process: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">              # Command line of profiled process</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sampling_frequency: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> DEFAULT_FREQUENCY_HZ</span><span style=\"color:#6A737D\">  # Configured sample rate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_sample_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">        # Time spent in sampling overhead</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_sample</span><span style=\"color:#E1E4E8\">(self, sample: Sample) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add a sample to this batch, updating timestamps.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate sample timestamp is reasonable (not far in past/future)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Update start_time if this is the first sample or earlier than current start</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update end_time if this sample is later than current end</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Append sample to samples list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Keep samples sorted by timestamp for efficient processing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_duration</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return the time span covered by samples in this batch.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return end_time - start_time, handling empty batch case</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_sample_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate actual sampling rate achieved by this batch.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return len(samples) / get_duration(), handling division by zero</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Symbol Resolution Data Structures (symbol.py):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Data structures for symbol resolution and debug information management.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Handles mapping from addresses to function names and source locations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LineRange</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Maps address range to source code line information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                    # First instruction mapped to this line</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                      # Last instruction mapped to this line (exclusive)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                      # Source line number</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    column_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                # Column within line (0 if unavailable)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_statement: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">             # True if address corresponds to statement boundary</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_prologue_end: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">         # True if address marks end of function prologue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_epilogue_begin: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">       # True if address marks start of function epilogue</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Symbol</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete symbol information for a function or code range.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                    # Starting address of symbol's code</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                      # Ending address (exclusive)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                    # Demangled function name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    raw_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                         # Original mangled name from symbol table</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    source_file: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">                 # Primary source file for this function</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_ranges: List[LineRange] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    parameter_types: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># From DWARF</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    return_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">                 # From DWARF</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_inlined: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">              # True if function exists only inlined</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    compilation_unit: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">            # Source file that was compiled</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> contains_address</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if address falls within this symbol's range.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return True if start_address &#x3C;= address &#x3C; end_address</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_line_number</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find source line number for specific address within symbol.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Search line_ranges for range containing address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return line_number from matching LineRange</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return 0 if no line mapping found</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Module</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents one executable or shared library with symbol information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                             # Module basename (e.g., \"libc.so.6\")</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                             # Full filesystem path</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    base_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                     # Virtual memory load address</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                             # Size of module mapping in bytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    build_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                         # Unique build identifier</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbols: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Symbol] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># start_address -> Symbol</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    has_debug_info: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">          # True if DWARF debug info available</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    architecture: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"x86_64\"</span><span style=\"color:#6A737D\">         # Target architecture</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    load_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">                # When module was loaded</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> find_symbol</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Symbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find symbol containing the given address.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate module-relative address: address - base_address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Binary search symbols dict for symbol containing relative address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return matching Symbol or None if not found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use bisect module for efficient range searches</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_symbol</span><span style=\"color:#E1E4E8\">(self, symbol: Symbol) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add symbol to this module's symbol table.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate symbol addresses are within module range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check for overlapping symbols and warn/resolve conflicts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add to symbols dict using start_address as key</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolCache</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Cache for resolved symbols with memory management and performance tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address_to_symbol: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Symbol] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_cache: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Module] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># build_id -> Module</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    demangled_names: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># raw -> demangled</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    miss_cache: Set[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">set</span><span style=\"color:#E1E4E8\">)              </span><span style=\"color:#6A737D\"># Known missing addresses</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_size_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">             # Current memory usage estimate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_cache_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#6A737D\">  # 100MB default limit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hit_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                    # Successful lookups</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    miss_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                   # Failed lookups requiring resolution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> lookup_symbol</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Symbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Look up symbol for address, returning cached result if available.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check address_to_symbol cache for direct hit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If hit, increment hit_count and return symbol</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check miss_cache to avoid expensive re-lookup of known misses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If miss, increment miss_count and return None</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Consider LRU eviction if cache is approaching size limit</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cache_symbol</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, symbol: Optional[Symbol]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Cache resolved symbol result (or miss) for future lookups.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: If symbol is None, add address to miss_cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If symbol exists, add to address_to_symbol cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update cache_size_bytes estimate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Trigger eviction if cache exceeds max_cache_size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_hit_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate cache hit rate for performance monitoring.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return hit_count / (hit_count + miss_count), handle division by zero</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"memory-allocation-tracking-implementation\">Memory Allocation Tracking Implementation</h4>\n<p><strong>Memory Profiling Data Structures (memory.py):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Data structures for tracking memory allocations and detecting leaks.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides comprehensive allocation lifecycle management and analysis.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Set, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Types of heap allocation calls.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MALLOC</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"malloc\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CALLOC</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"calloc\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    REALLOC</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"realloc\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    NEW</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"new\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    NEW_ARRAY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"new[]\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LeakCategory</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Classification levels for detected memory leaks.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEFINITE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"definite\"</span><span style=\"color:#6A737D\">     # No remaining pointers to allocation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PROBABLE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"probable\"</span><span style=\"color:#6A737D\">     # Pointers exist but in suspicious locations</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    POSSIBLE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"possible\"</span><span style=\"color:#6A737D\">     # Pointers exist but may be false positives</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    REACHABLE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"reachable\"</span><span style=\"color:#6A737D\">   # Still reachable but not freed at exit</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Allocation</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Record of a single heap allocation with lifecycle tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                    # Unique ID (typically pointer address)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                             # Requested allocation size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    actual_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                      # Actual bytes allocated by heap</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                      # When allocation occurred</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                        # Thread that performed allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_stack: List[StackFrame]    </span><span style=\"color:#6A737D\"># Call stack at allocation site</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_type: AllocationType </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AllocationType.</span><span style=\"color:#79B8FF\">MALLOC</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Deallocation tracking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_freed: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">                # True after free() called</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">           # When deallocation occurred</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#6A737D\">              # Thread that performed free</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_lifetime</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate allocation lifetime in seconds.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: If not freed, return current time - timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If freed, return free_timestamp - timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle edge case where free_timestamp is invalid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_long_lived</span><span style=\"color:#E1E4E8\">(self, threshold_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10.0</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if allocation has lived longer than threshold.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compare get_lifetime() with threshold_seconds</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MemorySnapshot</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Point-in-time view of heap memory usage and statistics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                      # When snapshot was captured</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_allocated: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                  # Cumulative bytes allocated</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_freed: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                      # Cumulative bytes freed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    live_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                       # Currently allocated bytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    live_allocations: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                 # Currently allocated objects</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    heap_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                    # Total heap size from system</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_rate: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">          # Recent allocation rate (bytes/sec)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_rate: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">                # Recent free rate (bytes/sec)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_fragmentation_bytes</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate estimated heap fragmentation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return heap_size - live_bytes (if heap_size available)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_fragmentation_ratio</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate fragmentation as percentage of heap size.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return get_fragmentation_bytes() / heap_size (handle division by zero)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MemoryLeak</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Detected memory leak with classification and analysis.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation: Allocation                </span><span style=\"color:#6A737D\"># The leaked allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    leak_confidence: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                # Confidence score 0.0-1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    leak_category: LeakCategory           </span><span style=\"color:#6A737D\"># Classification of leak type</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_age: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">                 # Seconds since allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    similar_leaks: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                # Other leaks with same call stack</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_leaked_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">           # Total bytes from this call pattern</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    detection_method: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"unreachable\"</span><span style=\"color:#6A737D\"> # How leak was identified</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    suppression_matched: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">         # Suppression rule name if applicable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_stack_signature</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate unique signature for this leak's call stack.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract function names from allocation.allocation_stack</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create hash from top N frames (typically 8-10)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return hex string of hash for grouping similar leaks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationSite</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Aggregated statistics for allocations from same call stack.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    call_stack_hash: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#6A737D\">                  # Hash of allocation call stack</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    representative_stack: List[StackFrame] </span><span style=\"color:#6A737D\"># Example stack from this site</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_allocations: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">            # Number of allocations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">                  # Cumulative bytes allocated</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    peak_live_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">              # Maximum simultaneous live bytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    peak_live_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">              # Maximum simultaneous live allocations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lifetime_distribution: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Histogram buckets</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    first_seen: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">               # Timestamp of first allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_seen: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">                # Timestamp of most recent allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_allocation</span><span style=\"color:#E1E4E8\">(self, allocation: Allocation) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update statistics with new allocation from this site.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Increment total_allocations counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add allocation.size to total_bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update first_seen if this is earlier (or first allocation)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update last_seen with allocation.timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update lifetime_distribution when allocation is freed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_average_size</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate average allocation size from this site.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return total_bytes / total_allocations (handle division by zero)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_active</span><span style=\"color:#E1E4E8\">(self, current_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, inactive_threshold: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60.0</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if this allocation site has been used recently.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return True if (current_time - last_seen) &#x3C; inactive_threshold</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Verification (Stack Sampling Data Model):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic sample creation and validation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_sample.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_sample_creation - PASS (validates Sample constructor)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_stack_frame_validation - PASS (validates StackFrame address handling)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_sample_batch_operations - PASS (validates SampleBatch add/sort operations)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from data_model.sample import Sample, StackFrame</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Create test sample with realistic stack</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">frames = [</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    StackFrame(0x401234, 'inner_function', 'main.c', 45),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    StackFrame(0x401190, 'outer_function', 'main.c', 23),  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    StackFrame(0x401000, 'main', 'main.c', 10)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">sample = Sample(time.time(), 12345, 678, frames)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Sample captured at {sample.timestamp} with {len(sample.stack_frames)} frames')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Verification (Symbol Resolution Data Model):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test symbol resolution data structures</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_symbol.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_symbol_address_ranges - PASS (validates Symbol.contains_address())</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_module_symbol_lookup - PASS (validates Module.find_symbol()) </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_symbol_cache_hit_rate - PASS (validates SymbolCache performance tracking)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from data_model.symbol import Symbol, Module</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Create test module with symbol</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">module = Module('test.exe', '/tmp/test', 0x400000, 4096, 'build123')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">symbol = Symbol(0x401000, 0x401100, 'test_function', 'test_function')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">module.add_symbol(symbol)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">found = module.find_symbol(0x401050)  # Address within symbol range</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Found symbol: {found.function_name if found else None}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Milestone 4 Verification (Memory Allocation Data Model):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test memory tracking data structures</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_memory.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_allocation_lifecycle - PASS (validates Allocation lifetime tracking)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_memory_snapshot_calculations - PASS (validates MemorySnapshot fragmentation)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># test_allocation_site_aggregation - PASS (validates AllocationSite statistics)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from data_model.memory import Allocation, MemorySnapshot, AllocationType</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Create test allocation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">alloc = Allocation(0x7f8b4c001000, 1024, 1024, time.time(), 12345, [])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">snapshot = MemorySnapshot(time.time(), 1024, 0, 1024, 1, 2048)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Allocation lifetime: {alloc.get_lifetime():.3f}s')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Heap fragmentation: {snapshot.get_fragmentation_ratio():.1%}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips-for-data-model-issues\">Debugging Tips for Data Model Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Memory usage grows without bound</td>\n<td>Missing cache eviction in SymbolCache</td>\n<td>Check cache_size_bytes and hit/miss ratios</td>\n<td>Implement LRU eviction when max_cache_size exceeded</td>\n</tr>\n<tr>\n<td>Symbol resolution returns wrong function names</td>\n<td>ASLR not handled correctly</td>\n<td>Compare module base_address with actual load address from /proc/pid/maps</td>\n<td>Store and use module-relative addresses for symbol lookup</td>\n</tr>\n<tr>\n<td>Stack frames missing or truncated</td>\n<td>Frame pointer omission or corruption</td>\n<td>Check if binary compiled with -fomit-frame-pointer, inspect assembly</td>\n<td>Use DWARF unwinding instead of frame pointer walking</td>\n</tr>\n<tr>\n<td>Allocation/free mismatches in leak detection</td>\n<td>Pointer reuse causing ID collisions</td>\n<td>Check if allocation_id values repeat after free</td>\n<td>Include allocation sequence number in ID generation</td>\n</tr>\n<tr>\n<td>Sample timestamps inconsistent</td>\n<td>Clock source changes or NTP adjustments</td>\n<td>Compare sample timestamps with system clock, check for jumps</td>\n<td>Use monotonic clock source (time.monotonic) instead of wall clock</td>\n</tr>\n<tr>\n<td>Inlined function information missing</td>\n<td>DWARF debug info not available or not parsed</td>\n<td>Check has_debug_info flag, verify debug symbols installed</td>\n<td>Install debug packages or compile with -g flag</td>\n</tr>\n</tbody></table>\n<h2 id=\"stack-sampling-component\">Stack Sampling Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1 — Stack Sampling: Periodically sample call stacks using signal-based interruption to capture program execution state with configurable frequency and minimal overhead</p>\n</blockquote>\n<h3 id=\"mental-model-photography-metaphor\">Mental Model: Photography Metaphor</h3>\n<p>Think of stack sampling as taking photographs of a moving process. Just as a photographer captures snapshots of a running race to understand the motion and positions of runners, a profiler captures snapshots of a program&#39;s call stack to understand its execution behavior. Each photograph (sample) shows where the runners (threads) are at that exact moment in time. By taking many photographs at regular intervals, we can reconstruct the overall pattern of the race (program execution) and identify where runners spend most of their time (performance hotspots).</p>\n<p>The photographer must balance several factors: taking photos too frequently might slow down the race (overhead), while taking them too infrequently might miss important moments (undersampling). The camera&#39;s shutter speed (signal handler execution time) must be fast enough not to interfere with the race itself. Sometimes the photographer might miss a shot due to technical issues (dropped samples), and occasionally the lighting conditions make it hard to identify specific runners (symbol resolution challenges).</p>\n<p>This analogy helps us understand the core challenges of statistical sampling: we&#39;re observing a dynamic system without significantly altering its behavior, and we must infer overall patterns from discrete observations. The <strong>observer paradox</strong> applies here — the act of measurement can change what we&#39;re measuring, so minimizing overhead is crucial for accurate profiling.</p>\n<h3 id=\"signal-based-sampling\">Signal-Based Sampling</h3>\n<p>Stack sampling relies on <strong>statistical sampling</strong> through periodic interruption of the target process using timer signals. The most common approach uses <code>SIGPROF</code>, a signal specifically designed for profiling that delivers at regular intervals based on process CPU time consumption, not wall-clock time. This ensures that profiling samples correlate with actual CPU usage rather than idle time.</p>\n<p>The sampling mechanism operates through several coordinated components. First, we configure an interval timer using <code>setitimer()</code> with <code>ITIMER_PROF</code> to deliver <code>SIGPROF</code> signals at our desired <strong>sampling frequency</strong>. When the signal arrives, the kernel interrupts the target process and invokes our signal handler, which captures a snapshot of the current call stack. The signal handler must execute quickly and safely, storing the captured stack frames for later processing.</p>\n<p><strong>Signal Handler Safety and Async-Safe Operations</strong></p>\n<p>Signal handlers operate in a severely restricted execution environment. They can only call <strong>async-signal-safe</strong> functions, which excludes most standard library functions including <code>malloc()</code>, <code>printf()</code>, and most system calls. This restriction exists because the signal can arrive at any point during program execution, potentially interrupting non-reentrant functions and causing deadlocks or corruption.</p>\n<p>Our signal handler must use only async-safe operations like <code>write()</code> for logging and pre-allocated data structures for storing samples. We cannot dynamically allocate memory during signal handling, so we must pre-allocate a circular buffer for samples and use atomic operations to manage the buffer indices safely across multiple threads.</p>\n<blockquote>\n<p><strong>Architecture Decision Record: Signal vs Threading Approach</strong></p>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Signal-Based Sampling with SIGPROF</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to periodically interrupt target process to capture call stacks with minimal overhead and accurate timing</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Signal-based sampling with <code>SIGPROF</code> and <code>setitimer()</code></li>\n<li>Separate profiler thread with periodic sleep and <code>ptrace()</code> attachment</li>\n<li>Instrumentation-based sampling with compiler-inserted hooks</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Signal-based sampling with <code>SIGPROF</code></li>\n<li><strong>Rationale</strong>: Signal approach provides deterministic timing based on CPU consumption rather than wall-clock time, automatically handles multi-threaded programs by interrupting whichever thread is running, and avoids the complexity of external process attachment. Timer signals are designed specifically for this use case.</li>\n<li><strong>Consequences</strong>: Enables accurate CPU-time-based profiling but restricts signal handler to async-safe operations only. Requires careful buffer management and atomic operations for thread safety.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Sampling Approach</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SIGPROF signals</td>\n<td>CPU-time based, automatic thread handling, kernel support</td>\n<td>Limited to async-safe operations, signal delivery overhead</td>\n</tr>\n<tr>\n<td>ptrace() attachment</td>\n<td>Full debugging capabilities, external process control</td>\n<td>High overhead, requires separate process, complex setup</td>\n</tr>\n<tr>\n<td>Compiler instrumentation</td>\n<td>Rich metadata access, precise control points</td>\n<td>Requires recompilation, significant overhead, code bloat</td>\n</tr>\n</tbody></table>\n<p><strong>Timer Configuration and Frequency Management</strong></p>\n<p>The sampling frequency directly impacts the trade-off between profiling accuracy and overhead. Higher frequencies provide more detailed profiles but consume more CPU cycles and may perturb the target program&#39;s behavior. The <code>SamplingConfig</code> structure captures these parameters:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>frequency_hz</code></td>\n<td>int</td>\n<td>Samples per second, typically 10Hz to 10KHz range</td>\n</tr>\n<tr>\n<td><code>max_stack_depth</code></td>\n<td>int</td>\n<td>Maximum call stack frames to capture per sample</td>\n</tr>\n<tr>\n<td><code>include_kernel</code></td>\n<td>bool</td>\n<td>Whether to capture kernel space stack frames</td>\n</tr>\n<tr>\n<td><code>target_overhead_percent</code></td>\n<td>float</td>\n<td>Desired profiling overhead as percentage of CPU time</td>\n</tr>\n</tbody></table>\n<p>The timer setup process involves several steps. First, we install a signal handler for <code>SIGPROF</code> using <code>sigaction()</code> with appropriate flags to ensure reliable signal delivery. Next, we configure the interval timer using <code>setitimer(ITIMER_PROF, &amp;timer_spec, NULL)</code> where <code>timer_spec</code> specifies both the initial delay and recurring interval. The timer automatically accounts for CPU time consumption, pausing during I/O waits and resuming when the process consumes CPU cycles.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: <code>ITIMER_PROF</code> measures CPU time, not wall-clock time. A process sleeping in <code>read()</code> won&#39;t receive signals, but a process spinning in a tight loop will receive them at the configured rate. This behavior is exactly what we want for CPU profiling.</p>\n</blockquote>\n<p><strong>Multi-Threading Considerations</strong></p>\n<p>Signal-based sampling in multi-threaded programs requires careful consideration of signal delivery semantics. In modern POSIX systems, signals are delivered to the entire process, and the kernel selects one thread to handle each signal delivery. This means <code>SIGPROF</code> will interrupt whichever thread is currently running, providing automatic load balancing across threads without explicit thread tracking.</p>\n<p>However, this creates challenges for sample storage. Multiple threads might simultaneously execute the signal handler if multiple cores are involved, requiring thread-safe data structures for the sample buffer. We use a lock-free circular buffer with atomic compare-and-swap operations to manage buffer indices, avoiding mutex operations that are not async-safe.</p>\n<p>The sample capture process must also record which thread was interrupted. We obtain the thread ID using <code>pthread_self()</code> within the signal handler and store it in the <code>Sample</code> structure. This enables per-thread analysis and helps identify thread-specific performance bottlenecks.</p>\n<h3 id=\"stack-frame-unwinding\">Stack Frame Unwinding</h3>\n<p>Once a signal interrupts execution, we must quickly traverse the call stack to capture the sequence of function calls that led to the current execution point. <strong>Stack unwinding</strong> reconstructs this call chain by following frame pointers or using debug information to navigate from the current stack frame back through each calling function.</p>\n<p><strong>Frame Pointer-Based Unwinding</strong></p>\n<p>The most common unwinding approach relies on frame pointers, which are register values that point to stack frames for each function call. In x86-64 architecture, the frame pointer is stored in the <code>%rbp</code> register, and each stack frame contains a pointer to the previous frame, creating a linked list structure through the stack.</p>\n<p>The unwinding algorithm follows these steps:</p>\n<ol>\n<li>Obtain the current frame pointer from the interrupted execution context provided by the signal handler</li>\n<li>Read the return address from the current stack frame to identify the calling function</li>\n<li>Follow the frame pointer chain to the previous stack frame</li>\n<li>Repeat until reaching the stack bottom or maximum depth limit</li>\n<li>Store each discovered instruction pointer in a <code>StackFrame</code> structure</li>\n</ol>\n<p>However, frame pointer unwinding has significant limitations. Modern compilers often omit frame pointers as an optimization, using the saved space for additional register variables. This optimization, enabled by <code>-fomit-frame-pointer</code> in GCC, breaks the frame pointer chain and makes traditional unwinding impossible.</p>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Missing Frame Pointers</strong>\nMany production binaries are compiled with frame pointer omission for performance. This breaks simple stack unwinding and results in truncated profiles showing only the interrupted function. Always compile profiling targets with <code>-fno-omit-frame-pointer</code> or use DWARF-based unwinding for accurate results.</p>\n</blockquote>\n<p><strong>DWARF-Based Unwinding for Optimized Code</strong></p>\n<p>When frame pointers are unavailable, we must use <strong>debug symbols</strong> and DWARF (Debug With Arbitrary Record Format) information to reconstruct the call stack. DWARF provides detailed unwinding instructions that describe how to locate the previous frame&#39;s registers and return address for each function, even in heavily optimized code.</p>\n<p>DWARF unwinding is significantly more complex than frame pointer traversal:</p>\n<ol>\n<li>Parse the <code>.eh_frame</code> or <code>.debug_frame</code> sections from the executable and shared libraries</li>\n<li>Build a table of unwinding rules indexed by instruction pointer ranges</li>\n<li>For each frame, look up the appropriate unwinding rules based on the current instruction pointer</li>\n<li>Execute the DWARF virtual machine instructions to compute the previous frame&#39;s registers</li>\n<li>Use the computed return address to continue unwinding</li>\n</ol>\n<p>This approach works with optimized code but requires substantial implementation effort and has higher runtime overhead. Many production profilers use libraries like <code>libunwind</code> or <code>libdwarf</code> to handle the complexity of DWARF unwinding.</p>\n<blockquote>\n<p><strong>Architecture Decision Record: Unwinding Strategy</strong></p>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Hybrid Unwinding with Frame Pointer Fallback</strong></p>\n<ul>\n<li><strong>Context</strong>: Need reliable stack unwinding for both optimized and debug builds with minimal signal handler overhead</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Frame pointer only (simple but unreliable with optimized code)</li>\n<li>DWARF-only unwinding (reliable but complex and slow)</li>\n<li>Hybrid approach with frame pointer primary, DWARF fallback</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Hybrid approach starting with frame pointer unwinding, falling back to DWARF when chains break</li>\n<li><strong>Rationale</strong>: Frame pointer unwinding is fast and sufficient for debug builds and unoptimized code. DWARF fallback handles optimized production binaries. Hybrid approach balances simplicity and reliability.</li>\n<li><strong>Consequences</strong>: Requires implementing both unwinding methods but provides best performance for common cases while maintaining accuracy for production deployments.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Unwinding Method</th>\n<th>Speed</th>\n<th>Reliability</th>\n<th>Implementation Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Frame pointers</td>\n<td>Fast</td>\n<td>Poor with optimizations</td>\n<td>Low</td>\n</tr>\n<tr>\n<td>DWARF CFI</td>\n<td>Slow</td>\n<td>High</td>\n<td>High</td>\n</tr>\n<tr>\n<td>Hybrid approach</td>\n<td>Medium</td>\n<td>High</td>\n<td>Medium</td>\n</tr>\n</tbody></table>\n<p><strong>Signal Context and Register Access</strong></p>\n<p>The signal handler receives execution context through a <code>ucontext_t</code> structure that contains the interrupted program&#39;s register state. This context provides the starting point for stack unwinding by giving us access to the stack pointer (<code>%rsp</code>), frame pointer (<code>%rbp</code>), and instruction pointer (<code>%rip</code>) at the moment of interruption.</p>\n<p>Accessing these registers requires platform-specific code, as register layout differs between architectures. On x86-64 Linux, we extract registers from <code>uctx-&gt;uc_mcontext.gregs[]</code> array using architecture-specific indices. The instruction pointer gives us the current execution location, while the stack and frame pointers provide starting points for unwinding.</p>\n<p><strong>Sample Storage During Signal Handling</strong></p>\n<p>Since signal handlers cannot use dynamic memory allocation, we must pre-allocate storage for captured samples. The profiler maintains a circular buffer of <code>Sample</code> structures, using atomic operations to manage producer and consumer indices safely across multiple threads.</p>\n<p>The <code>Sample</code> structure captures all information needed for later analysis:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>timestamp</code></td>\n<td>float</td>\n<td>Time when sample was captured (seconds since epoch)</td>\n</tr>\n<tr>\n<td><code>thread_id</code></td>\n<td>int</td>\n<td>Thread ID of interrupted execution</td>\n</tr>\n<tr>\n<td><code>process_id</code></td>\n<td>int</td>\n<td>Process ID of target program</td>\n</tr>\n<tr>\n<td><code>stack_frames</code></td>\n<td>List[StackFrame]</td>\n<td>Captured call stack frames</td>\n</tr>\n<tr>\n<td><code>cpu_id</code></td>\n<td>int</td>\n<td>CPU core where sample was taken</td>\n</tr>\n<tr>\n<td><code>sample_weight</code></td>\n<td>int</td>\n<td>Weight for weighted sampling (usually 1)</td>\n</tr>\n<tr>\n<td><code>context_switches</code></td>\n<td>int</td>\n<td>Number of context switches since last sample</td>\n</tr>\n<tr>\n<td><code>sample_type</code></td>\n<td>SampleType</td>\n<td>Type of sampling event (CPU, timer, etc.)</td>\n</tr>\n</tbody></table>\n<p>Each <code>StackFrame</code> within the sample contains:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>address</code></td>\n<td>int</td>\n<td>Raw instruction pointer address</td>\n</tr>\n<tr>\n<td><code>function_name</code></td>\n<td>str</td>\n<td>Resolved function name (empty during capture)</td>\n</tr>\n<tr>\n<td><code>filename</code></td>\n<td>str</td>\n<td>Source file name (resolved later)</td>\n</tr>\n<tr>\n<td><code>line_number</code></td>\n<td>int</td>\n<td>Source line number (resolved later)</td>\n</tr>\n<tr>\n<td><code>module_name</code></td>\n<td>str</td>\n<td>Executable or shared library name</td>\n</tr>\n<tr>\n<td><code>module_offset</code></td>\n<td>int</td>\n<td>Offset within the module</td>\n</tr>\n<tr>\n<td><code>inlined_frames</code></td>\n<td>List[InlinedFrame]</td>\n<td>Inlined function information</td>\n</tr>\n<tr>\n<td><code>is_kernel</code></td>\n<td>bool</td>\n<td>Whether this frame is in kernel space</td>\n</tr>\n</tbody></table>\n<p>The signal handler populates only the <code>address</code>, <code>module_name</code>, <code>module_offset</code>, and <code>is_kernel</code> fields. Symbol resolution happens later in a separate thread to avoid async-unsafe operations during signal handling.</p>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<blockquote>\n<p><strong>Architecture Decision Record: Sample Buffer Management</strong></p>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Lock-Free Circular Buffer with Atomic Operations</strong></p>\n<ul>\n<li><strong>Context</strong>: Signal handlers need thread-safe storage for captured samples but cannot use mutexes or other blocking synchronization primitives</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Pre-allocated arrays with per-thread separation</li>\n<li>Lock-free circular buffer with atomic indices</li>\n<li>Signal masking with single-threaded sample storage</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Lock-free circular buffer using atomic compare-and-swap for index management</li>\n<li><strong>Rationale</strong>: Provides thread safety without blocking operations, automatically balances load across threads, and handles overflow gracefully by overwriting oldest samples. Atomic operations are async-safe and have minimal overhead.</li>\n<li><strong>Consequences</strong>: Enables high-frequency sampling without signal handler blocking, but requires careful memory ordering and may lose samples under extreme load. Buffer size must be tuned to prevent overflow during processing delays.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Architecture Decision Record: Kernel Stack Sampling</strong></p>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Optional Kernel Stack Capture via /proc Interface</strong></p>\n<ul>\n<li><strong>Context</strong>: CPU hotspots may exist in kernel code during system calls, but capturing kernel stacks requires additional privileges and mechanism</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>User-space only sampling (simple but incomplete view)</li>\n<li>Kernel stack via /proc/PID/stack reading during signal handler</li>\n<li>eBPF-based kernel stack capture (requires modern kernel)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Optional kernel stack capture by reading /proc/PID/stack when include_kernel is enabled</li>\n<li><strong>Rationale</strong>: Provides kernel visibility without requiring eBPF support, can be enabled/disabled based on analysis needs, and works on older kernels. Reading /proc is async-safe and relatively fast.</li>\n<li><strong>Consequences</strong>: Requires additional file I/O during signal handling but provides complete execution visibility. May require elevated privileges for some kernel stack access.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Architecture Decision Record: Thread-Specific vs Process-Wide Sampling</strong></p>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Process-Wide Sampling with Thread ID Recording</strong></p>\n<ul>\n<li><strong>Context</strong>: Multi-threaded programs need profiling that can identify per-thread hotspots while maintaining implementation simplicity</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Separate timer per thread with thread-specific handlers</li>\n<li>Process-wide timer with automatic thread selection</li>\n<li>Manual thread iteration with ptrace attachment</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Single process-wide ITIMER_PROF timer with thread ID recording in each sample</li>\n<li><strong>Rationale</strong>: Kernel automatically delivers signals to whichever thread is consuming CPU time, providing natural load balancing. Thread ID in each sample enables per-thread analysis during post-processing. Avoids complex thread management and multiple timer coordination.</li>\n<li><strong>Consequences</strong>: Simplifies implementation and automatically focuses on active threads, but may undersample threads with infrequent CPU usage. Thread creation/destruction during profiling is handled transparently.</li>\n</ul>\n</blockquote>\n<p><strong>Sampling Frequency and Overhead Trade-offs</strong></p>\n<p>The choice of sampling frequency represents the fundamental trade-off in statistical profiling: accuracy versus overhead. Higher frequencies provide more detailed profiles with better statistical significance, but increase the CPU time consumed by signal handling and stack unwinding.</p>\n<table>\n<thead>\n<tr>\n<th>Frequency Range</th>\n<th>Use Case</th>\n<th>Typical Overhead</th>\n<th>Statistical Accuracy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>10-50 Hz</td>\n<td>Production profiling</td>\n<td>&lt;0.5%</td>\n<td>Good for major hotspots</td>\n</tr>\n<tr>\n<td>100-500 Hz</td>\n<td>Development profiling</td>\n<td>1-3%</td>\n<td>Detailed function analysis</td>\n</tr>\n<tr>\n<td>1-10 KHz</td>\n<td>Micro-benchmarking</td>\n<td>5-15%</td>\n<td>High-resolution profiling</td>\n</tr>\n</tbody></table>\n<p>The <code>TARGET_OVERHEAD_PERCENT</code> constant guides automatic frequency selection when overhead limits are more important than absolute frequency. The profiler can dynamically adjust frequency based on observed signal handler execution time, increasing frequency when handlers complete quickly and reducing it when overhead exceeds targets.</p>\n<p><strong>Signal Delivery Reliability and Dropped Samples</strong></p>\n<p>Signal delivery is not guaranteed, and samples may be dropped under several conditions. High system load can delay signal delivery beyond the timer interval, causing missed samples. Signal handlers that execute too slowly may still be running when the next signal arrives, leading to signal coalescing where multiple timer events result in only one signal delivery.</p>\n<p>The profiler tracks dropped samples by comparing the expected sample count (based on elapsed time and configured frequency) with the actual samples collected. The <code>SampleBatch</code> structure records this information:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>samples</code></td>\n<td>List[Sample]</td>\n<td>Successfully captured samples</td>\n</tr>\n<tr>\n<td><code>start_time</code></td>\n<td>float</td>\n<td>Profiling session start timestamp</td>\n</tr>\n<tr>\n<td><code>end_time</code></td>\n<td>float</td>\n<td>Profiling session end timestamp</td>\n</tr>\n<tr>\n<td><code>dropped_samples</code></td>\n<td>int</td>\n<td>Estimated number of missed samples</td>\n</tr>\n<tr>\n<td><code>target_process</code></td>\n<td>str</td>\n<td>Process name or PID being profiled</td>\n</tr>\n<tr>\n<td><code>sampling_frequency</code></td>\n<td>int</td>\n<td>Configured sampling rate in Hz</td>\n</tr>\n<tr>\n<td><code>total_sample_time</code></td>\n<td>float</td>\n<td>Cumulative time spent in signal handlers</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Async-Unsafe Operations in Signal Handler</strong></p>\n<p>The most dangerous mistake is calling non-async-safe functions within the signal handler. Functions like <code>malloc()</code>, <code>free()</code>, <code>printf()</code>, and most standard library calls can cause deadlocks if the signal interrupts the same function being called from the main program thread.</p>\n<p><strong>Why it&#39;s wrong</strong>: If the signal handler calls <code>malloc()</code> while the main thread is already inside <code>malloc()</code>, both will attempt to acquire the same internal mutex, causing an unrecoverable deadlock.</p>\n<p><strong>How to fix</strong>: Use only async-safe functions listed in <code>signal-safety(7)</code>. Pre-allocate all data structures, use atomic operations for synchronization, and defer complex processing to a separate thread outside the signal handler.</p>\n<p>⚠️ <strong>Pitfall: Sampling Bias in Tight Loops</strong></p>\n<p>Statistical sampling can miss or underrepresent very short functions that execute quickly relative to the sampling period. Conversely, functions that block on I/O may be overrepresented if using wall-clock-based timers instead of CPU-time-based timers.</p>\n<p><strong>Why it&#39;s wrong</strong>: A function that executes for 0.1ms but runs 1000 times per second consumes 10% of CPU time but might never be sampled if the sampling frequency is too low. This leads to incomplete profiles that miss actual hotspots.</p>\n<p><strong>How to fix</strong>: Use <code>ITIMER_PROF</code> for CPU-time-based sampling rather than <code>ITIMER_REAL</code>. Choose sampling frequencies high enough to capture short functions multiple times. Consider weighted sampling where sample counts are adjusted based on elapsed time between samples.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Stack Unwinding Failures</strong></p>\n<p>Stack unwinding can fail due to corrupted frame pointers, missing debug information, or execution in signal handlers or dynamically generated code. Silently ignoring these failures results in truncated profiles that underrepresent complex call chains.</p>\n<p><strong>Why it&#39;s wrong</strong>: If unwinding consistently fails after the first few frames, the profile will show most time spent in leaf functions rather than revealing the calling context that led to those functions. This makes it impossible to identify the high-level code paths responsible for performance issues.</p>\n<p><strong>How to fix</strong>: Implement robust error detection during unwinding, track unwinding failure rates, and provide fallback strategies. Log unwinding failures for analysis, and consider hybrid approaches that combine multiple unwinding methods for better reliability.</p>\n<p>⚠️ <strong>Pitfall: Excessive Signal Handler Overhead</strong></p>\n<p>Performing too much work in the signal handler itself can create a feedback loop where profiling overhead becomes the dominant CPU consumer, distorting the profile results.</p>\n<p><strong>Why it&#39;s wrong</strong>: If the signal handler takes 1ms to execute and runs at 1KHz frequency, it consumes 100% CPU time, making meaningful profiling impossible. The overhead becomes self-amplifying as more signal handling creates more apparent hotspots in signal handling code.</p>\n<p><strong>How to fix</strong>: Minimize signal handler work to address capture and storage only. Move symbol resolution, stack analysis, and complex processing to separate threads. Monitor signal handler execution time and automatically reduce sampling frequency if overhead exceeds targets. Use efficient data structures and avoid memory allocations during signal handling.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Buffer Sizing for High-Frequency Sampling</strong></p>\n<p>The circular buffer for storing samples must be sized appropriately for the sampling frequency and processing speed. Undersized buffers cause sample loss, while oversized buffers consume excessive memory.</p>\n<p><strong>Why it&#39;s wrong</strong>: A 10KHz sampling rate generates 10,000 samples per second. If each sample contains 20 stack frames, that&#39;s 200,000 addresses per second. A buffer holding only 1,000 samples will overflow in 0.1 seconds, losing most profiling data.</p>\n<p><strong>How to fix</strong>: Size buffers based on maximum expected sampling rate multiplied by processing delay. Implement watermark monitoring that warns when buffer usage exceeds safe thresholds. Consider multiple buffers with background processing to maintain continuous sampling during analysis phases.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signal Handling</td>\n<td>Python <code>signal</code> module with ctypes for stack walking</td>\n<td>C extension module with libunwind integration</td>\n</tr>\n<tr>\n<td>Stack Unwinding</td>\n<td>Frame pointer walking with ctypes memory access</td>\n<td>DWARF-based unwinding with pyelftools and libunwind</td>\n</tr>\n<tr>\n<td>Sample Storage</td>\n<td>Collections.deque with threading.Lock</td>\n<td>Lock-free circular buffer using multiprocessing.Array</td>\n</tr>\n<tr>\n<td>Timer Management</td>\n<td>signal.setitimer() with ITIMER_PROF</td>\n<td>Custom timer thread with more precise control</td>\n</tr>\n<tr>\n<td>Cross-Platform</td>\n<td>Linux-specific implementation using /proc</td>\n<td>Abstract platform layer supporting Linux, macOS, Windows</td>\n</tr>\n</tbody></table>\n<p>For learning purposes, start with the simple options using Python&#39;s built-in capabilities, then enhance with advanced techniques as needed for production use.</p>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n├── sampling/\n│   ├── __init__.py\n│   ├── sampler.py              ← Main sampling logic and configuration\n│   ├── signal_handler.py       ← Signal handler implementation\n│   ├── stack_unwinder.py       ← Stack frame unwinding logic\n│   ├── sample_buffer.py        ← Thread-safe sample storage\n│   └── platform/\n│       ├── __init__.py\n│       ├── linux.py            ← Linux-specific signal and stack handling\n│       └── common.py           ← Platform-independent utilities\n├── data_model/\n│   ├── __init__.py\n│   ├── sample.py               ← Sample and StackFrame data structures\n│   └── config.py               ← SamplingConfig and ProfilerConfig\n└── utils/\n    ├── __init__.py\n    ├── timing.py               ← Timer utilities and overhead measurement\n    └── logging.py              ← Async-safe logging for signal handlers</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Platform Detection and Signal Utilities</strong> (<code>profiler/sampling/platform/linux.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> signal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ctypes </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> c_void_p, c_int, c_ulong</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, List</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Linux-specific constants</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">ITIMER_PROF</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SIGPROF</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 27</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RegisterContext</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents CPU register state at signal delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, rip: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, rsp: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, rbp: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.instruction_pointer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rip</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stack_pointer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rsp</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.frame_pointer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rbp</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> extract_signal_context</span><span style=\"color:#E1E4E8\">(signum: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, frame) -> RegisterContext:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Extract register context from Python signal frame.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Note: Python's signal frame is limited compared to full ucontext_t.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    For production use, consider a C extension for complete register access.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Python frame gives us limited context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> frame </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"No frame context available\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Extract what we can from Python frame object</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    code_obj </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> frame.f_code</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    instruction_pointer </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> id</span><span style=\"color:#E1E4E8\">(code_obj)  </span><span style=\"color:#6A737D\"># Approximation for demo</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # In real implementation, use ctypes to access ucontext_t</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # This is a simplified version for educational purposes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> RegisterContext(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        rip</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">instruction_pointer,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        rsp</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Would extract from ucontext_t in production</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        rbp</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#6A737D\">   # Would extract from ucontext_t in production</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> setup_profiling_signal</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configure signal handling for profiling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Ensure signal handler runs with minimal restrictions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signal.siginterrupt(signal.</span><span style=\"color:#79B8FF\">SIGPROF</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> read_proc_stack</span><span style=\"color:#E1E4E8\">(pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Read kernel stack from /proc/PID/stack if available.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'/proc/</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">pid</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">/stack'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'r'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> [line.strip() </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> line </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> f </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> line.strip()]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">OSError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">IOError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> []  </span><span style=\"color:#6A737D\"># Kernel stack not available</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TimerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"ITIMER configuration for profiling signals.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, frequency_hz: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.interval_sec </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#F97583\"> /</span><span style=\"color:#E1E4E8\"> frequency_hz</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.initial_sec </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.interval_sec</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> set_profiling_timer</span><span style=\"color:#E1E4E8\">(config: TimerConfig) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Start ITIMER_PROF timer for regular SIGPROF delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signal.setitimer(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signal.</span><span style=\"color:#79B8FF\">ITIMER_PROF</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config.initial_sec,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config.interval_sec</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> clear_profiling_timer</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Stop profiling timer.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signal.setitimer(signal.</span><span style=\"color:#79B8FF\">ITIMER_PROF</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Thread-Safe Sample Buffer</strong> (<code>profiler/sampling/sample_buffer.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.data_model.sample </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Sample</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> BufferStats</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Statistics about sample buffer usage and performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dropped_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_buffer_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    current_buffer_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_drop_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate percentage of dropped samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_samples </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.dropped_samples </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_samples) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SampleBuffer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe circular buffer for storing captured samples.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Uses deque with maxlen for automatic overflow handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Thread safety provided by explicit locking since signal handlers</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    cannot use lock-free algorithms safely in Python.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_size)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> BufferStats()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._max_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_sample</span><span style=\"color:#E1E4E8\">(self, sample: Sample) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add sample to buffer.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if sample was stored, False if buffer full and sample dropped.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer) </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._max_size:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">._stats.dropped_samples </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._buffer.append(sample)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._stats.total_samples </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._stats.current_buffer_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._stats.current_buffer_size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._stats.max_buffer_size:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">._stats.max_buffer_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._stats.current_buffer_size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_samples</span><span style=\"color:#E1E4E8\">(self, max_count: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> List[Sample]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract samples from buffer for processing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            max_count: Maximum samples to extract (None for all).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of samples in FIFO order.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> max_count </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">._buffer.clear()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                samples </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">min</span><span style=\"color:#E1E4E8\">(max_count, </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer))):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._buffer:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        samples.append(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer.popleft())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._stats.current_buffer_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> samples</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_stats</span><span style=\"color:#E1E4E8\">(self) -> BufferStats:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current buffer statistics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> BufferStats(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                total_samples</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._stats.total_samples,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                dropped_samples</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._stats.dropped_samples,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                max_buffer_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._stats.max_buffer_size,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                current_buffer_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._buffer)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Main Sampler Implementation</strong> (<code>profiler/sampling/sampler.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> signal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Callable</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.data_model.config </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SamplingConfig</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.data_model.sample </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Sample, SampleBatch</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.signal_handler </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ProfilerSignalHandler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.sample_buffer </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SampleBuffer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.platform.linux </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> set_profiling_timer, clear_profiling_timer, TimerConfig</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackSampler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Captures call stacks at regular intervals using signal-based interruption.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: SamplingConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SampleBuffer(</span><span style=\"color:#FFAB70\">max_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">config.frequency_hz </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># 1 minute buffer</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.signal_handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ProfilerSignalHandler(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.buffer, config)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_sampling </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.start_time: Optional[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> start_sampling</span><span style=\"color:#E1E4E8\">(self, target_pid: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Begin stack sampling of target process.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            target_pid: Process ID to profile (None for current process).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_sampling:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Sampling already active\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate sampling configuration parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check frequency_hz is within reasonable range (1-10000)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Verify max_stack_depth is positive and &#x3C; 1000</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Ensure target process exists if pid specified</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Install signal handler for SIGPROF</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Use signal.signal(signal.SIGPROF, self.signal_handler.handle_signal)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Store previous handler for restoration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Configure and start profiling timer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Create TimerConfig with desired frequency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call set_profiling_timer() to begin signal delivery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Record sampling session metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Set self.start_time = time.time()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Mark self.is_sampling = True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Log sampling start with configuration details</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> stop_sampling</span><span style=\"color:#E1E4E8\">(self) -> SampleBatch:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Stop sampling and return collected samples.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            SampleBatch containing all captured samples and metadata.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_sampling:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"No active sampling session\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Stop timer signal delivery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call clear_profiling_timer() to stop SIGPROF signals</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Restore previous signal handler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Restore signal.SIGPROF to previous handler</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Collect all buffered samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call self.buffer.get_samples() to extract samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Get buffer statistics for dropped sample count</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate session statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Compute actual sampling duration = time.time() - self.start_time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Calculate achieved sample rate = len(samples) / duration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Estimate dropped samples from timer frequency vs actual samples</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create and return SampleBatch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Populate all metadata fields from session</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Include buffer statistics and timing information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Mark self.is_sampling = False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_current_stats</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current sampling statistics without stopping.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if sampling is active</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Get buffer statistics from self.buffer.get_stats()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate elapsed time and current sample rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return dictionary with current metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span></code></pre></div>\n\n<p><strong>Signal Handler Implementation</strong> (<code>profiler/sampling/signal_handler.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> signal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.data_model.sample </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Sample, StackFrame, SampleType</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.data_model.config </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SamplingConfig</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.stack_unwinder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StackUnwinder</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.sample_buffer </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SampleBuffer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.platform.linux </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> extract_signal_context, read_proc_stack</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerSignalHandler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Signal handler for capturing stack samples during SIGPROF delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, sample_buffer: SampleBuffer, config: SamplingConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sample_buffer</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.unwinder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackUnwinder(config.max_stack_depth)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sample_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_signal</span><span style=\"color:#E1E4E8\">(self, signum: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, frame) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Signal handler called on SIGPROF delivery.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        CRITICAL: This function runs in signal context and can only use</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        async-safe operations. No malloc, no locks, minimal processing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate signal number and frame context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check signum == signal.SIGPROF</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Ensure frame is not None</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Return early if invalid (avoid exceptions in signal handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Capture basic sample metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Get current timestamp using time.time() (async-safe)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Get thread ID using threading.get_ident()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Get process ID using os.getpid()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Increment self.sample_count atomically</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Extract execution context from signal frame</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call extract_signal_context(signum, frame)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Handle any exceptions silently (return early)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Unwind call stack from current context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call self.unwinder.unwind_stack(context)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Limit unwinding time to avoid signal handler delays</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Set timeout based on target overhead percentage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Capture kernel stack if enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check self.config.include_kernel</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call read_proc_stack(os.getpid()) if enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Append kernel frames to stack_frames list</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create sample object and store in buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Create Sample with all captured information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call self.buffer.add_sample(sample)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Handle buffer full condition silently (don't raise exceptions)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Handle any errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Catch all exceptions and return silently</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Never call malloc, printf, or other unsafe functions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Log errors to pre-allocated error counter only</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span></code></pre></div>\n\n<p><strong>Stack Unwinding Implementation</strong> (<code>profiler/sampling/stack_unwinder.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.data_model.sample </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StackFrame</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling.platform.linux </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> RegisterContext</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackUnwinder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Unwinds call stacks using frame pointer traversal.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 64</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_depth </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_depth</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> unwind_stack</span><span style=\"color:#E1E4E8\">(self, context: RegisterContext) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Unwind call stack from given execution context.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            context: CPU register state from signal delivery.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of stack frames from current function back to main().</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize unwinding from current context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Start with instruction_pointer from context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Set current_frame_ptr = context.frame_pointer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Create empty frames list for results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Follow frame pointer chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Loop while current_frame_ptr is valid and depth &#x3C; max_depth</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Read return address from frame_ptr + sizeof(void*)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Read next frame pointer from frame_ptr + 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Use ctypes to safely access memory addresses</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create StackFrame for each discovered frame</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Set address to instruction pointer value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Determine module_name from address range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Calculate module_offset = address - module_base</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Mark is_kernel based on address range</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle frame pointer validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check frame pointers are aligned (typically 8-byte alignment)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Verify frame pointers increase monotonically (stack grows down)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Stop unwinding if frame pointer seems corrupted</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Detect unwinding completion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Stop when frame pointer becomes NULL or invalid</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Stop when return address is NULL (reached bottom)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Stop when maximum depth reached</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle memory access errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Catch segmentation faults from invalid memory access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Return partial stack if unwinding fails partway</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Never raise exceptions (called from signal handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _read_memory_safe</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Safely read memory from target process.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            address: Memory address to read from.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            size: Number of bytes to read.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Memory contents or None if read fails.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement safe memory reading using ctypes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Use ctypes.c_void_p to access raw memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Handle access violations gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Return None for any read failures</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _is_valid_frame_pointer</span><span style=\"color:#E1E4E8\">(self, ptr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if frame pointer looks valid.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            ptr: Frame pointer value to validate.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if pointer seems valid for unwinding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement frame pointer validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check alignment (usually 8-byte aligned on x86-64)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Verify address is in reasonable stack range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Ensure pointer is not NULL</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Student implements</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the stack sampling component, verify correct operation with these tests:</p>\n<p><strong>Basic Functionality Test</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from profiler.sampling.sampler import StackSampler</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from profiler.data_model.config import SamplingConfig</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">config = SamplingConfig(frequency_hz=100, max_stack_depth=20, include_kernel=False, target_overhead_percent=2.0)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">sampler = StackSampler(config)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">sampler.start_sampling()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">time.sleep(5)  # Let it sample for 5 seconds</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">batch = sampler.stop_sampling()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Captured {len(batch.samples)} samples')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Drop rate: {batch.dropped_samples}/{batch.dropped_samples + len(batch.samples)}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Sample rate: {len(batch.samples) / (batch.end_time - batch.start_time):.1f} Hz')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Expected Output</strong>:</p>\n<ul>\n<li>Should capture approximately 500 samples (100 Hz × 5 seconds)</li>\n<li>Drop rate should be 0% for this light test</li>\n<li>Sample rate should be close to configured 100 Hz</li>\n<li>Each sample should have 3-10 stack frames (depending on call depth)</li>\n</ul>\n<p><strong>Manual Verification</strong>:</p>\n<ol>\n<li>Run a CPU-intensive Python program in background</li>\n<li>Profile it for 10 seconds at 1000 Hz</li>\n<li>Verify samples contain diverse instruction addresses</li>\n<li>Check that sampling stops cleanly without hanging</li>\n</ol>\n<p><strong>Signs of Problems</strong>:</p>\n<ul>\n<li><strong>Zero samples captured</strong>: Signal handler not installing correctly or timer not firing</li>\n<li><strong>All samples have 1 frame</strong>: Stack unwinding failing, probably due to frame pointer issues</li>\n<li><strong>High drop rate (&gt;5%)</strong>: Buffer too small or signal handler taking too long</li>\n<li><strong>Segmentation faults</strong>: Memory access errors in stack unwinding, need better validation</li>\n<li><strong>Program hangs</strong>: Signal handler deadlock, probably calling non-async-safe functions</li>\n</ul>\n<h2 id=\"symbol-resolution-component\">Symbol Resolution Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2 — Symbol Resolution: Convert raw addresses to human-readable function names and source locations by parsing ELF binaries, loading symbol tables, and processing DWARF debug information</p>\n</blockquote>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fsymbol-resolution-flow.svg\" alt=\"Symbol Resolution Process\"></p>\n<h3 id=\"mental-model-address-book-lookup\">Mental Model: Address Book Lookup</h3>\n<p>Think of symbol resolution like looking up addresses in a comprehensive phone book system. When you have a raw memory address from a stack sample, it&#39;s like having a street address but no idea what business or person lives there. The symbol resolution process is like having multiple phone books (ELF symbol tables, DWARF debug information, shared library maps) that help you translate that cryptic address into meaningful information: &quot;Oh, this address corresponds to the <code>calculate_tax</code> function in <code>tax_processor.cpp</code> at line 142.&quot;</p>\n<p>Just as a phone book lookup might involve checking the main directory first, then consulting specialized business directories, and finally looking up detailed contact information, symbol resolution follows a hierarchical lookup process. First, we determine which binary or shared library contains the address (like finding the right phone book). Then we search the symbol table to find the function name (like finding the business name). Finally, we consult DWARF debug information to get precise source file and line number details (like getting the exact office suite number).</p>\n<p>The challenge is that this &quot;phone book&quot; system must be extremely fast because we&#39;re doing thousands of lookups per second during profiling. Modern programs load dozens of shared libraries, each with thousands of symbols, creating a massive address space that changes as libraries are loaded and unloaded. We need intelligent caching and efficient data structures to make these lookups fast enough that symbol resolution doesn&#39;t become a bottleneck in our profiling pipeline.</p>\n<p>Additionally, just as some buildings might not be listed in phone books (unlisted numbers or new constructions), some code addresses might not have symbols available. This happens with stripped binaries, optimized code, or dynamically generated code. Our symbol resolution system must gracefully handle these cases and provide useful fallback information.</p>\n<h3 id=\"elf-binary-and-symbol-table-parsing\">ELF Binary and Symbol Table Parsing</h3>\n<p>The foundation of symbol resolution lies in understanding the <strong>Executable and Linkable Format (ELF)</strong>, which is the standard binary format for executables and shared libraries on Linux systems. Every compiled program contains structured metadata that maps memory addresses to function names, and our profiler must parse this information efficiently.</p>\n<p><strong>ELF Structure and Symbol Tables</strong></p>\n<p>An ELF binary contains multiple sections, but for symbol resolution we primarily care about the <code>.symtab</code> (symbol table), <code>.dynsym</code> (dynamic symbol table), and <code>.strtab</code> (string table) sections. The symbol table contains entries that map address ranges to symbol names, while the string table holds the actual function name strings to save space through deduplication.</p>\n<p>Each symbol table entry contains crucial information for address resolution:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>st_name</td>\n<td>uint32</td>\n<td>Offset into string table for symbol name</td>\n</tr>\n<tr>\n<td>st_value</td>\n<td>uint64</td>\n<td>Symbol address (or offset within section)</td>\n</tr>\n<tr>\n<td>st_size</td>\n<td>uint64</td>\n<td>Size of symbol in bytes</td>\n</tr>\n<tr>\n<td>st_info</td>\n<td>uint8</td>\n<td>Symbol type and binding information</td>\n</tr>\n<tr>\n<td>st_other</td>\n<td>uint8</td>\n<td>Symbol visibility</td>\n</tr>\n<tr>\n<td>st_shndx</td>\n<td>uint16</td>\n<td>Section index this symbol belongs to</td>\n</tr>\n</tbody></table>\n<p>The symbol resolution process begins by loading these tables into memory and building efficient lookup structures. We cannot simply iterate through symbols for each address lookup because that would be too slow for production profiling.</p>\n<p><strong>Address Space Layout Randomization (ASLR) Handling</strong></p>\n<p>Modern Linux systems use ASLR to randomize the base addresses where executables and shared libraries are loaded. This security feature means that the addresses in our stack samples are <strong>runtime addresses</strong>, while the addresses in ELF symbol tables are <strong>file offsets</strong> or <strong>virtual addresses</strong> from the original linking process.</p>\n<p>To resolve this discrepancy, we must determine the <strong>base address</strong> where each binary or shared library was actually loaded at runtime. This information is available through the <code>/proc/[pid]/maps</code> file, which shows the memory mappings for a running process:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>7f8b4c000000-7f8b4c021000 r-xp 00000000 08:01 1234567 /lib/x86_64-linux-gnu/ld-2.31.so\n7f8b4c021000-7f8b4c022000 r--p 00021000 08:01 1234567 /lib/x86_64-linux-gnu/ld-2.31.so</code></pre></div>\n\n<p>Each line provides the runtime address range, permissions, file offset, device, inode, and file path. By parsing this information, we can calculate the <strong>load bias</strong> (difference between runtime base address and ELF virtual address) for each module.</p>\n<p><strong>Symbol Lookup Algorithm</strong></p>\n<p>The core symbol lookup algorithm operates through the following steps:</p>\n<ol>\n<li><p><strong>Module Identification</strong>: Given a runtime address, search through loaded modules to find which binary or shared library contains this address by checking if the address falls within any module&#39;s memory range.</p>\n</li>\n<li><p><strong>Address Translation</strong>: Convert the runtime address to a file-relative address by subtracting the module&#39;s base address and accounting for any load bias.</p>\n</li>\n<li><p><strong>Symbol Table Search</strong>: Use binary search on the sorted symbol table to find the symbol whose address range contains our target address. Symbols are sorted by start address to enable efficient searching.</p>\n</li>\n<li><p><strong>Symbol Validation</strong>: Verify that the address falls within the symbol&#39;s size range (<code>st_value &lt;= address &lt; st_value + st_size</code>). Some symbols may have zero size, requiring special handling.</p>\n</li>\n<li><p><strong>Name Resolution</strong>: Use the string table offset (<code>st_name</code>) to retrieve the actual function name string.</p>\n</li>\n</ol>\n<p><strong>Module Loading and Caching</strong></p>\n<p>Our <code>Module</code> data structure represents a single binary or shared library:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>name</td>\n<td>str</td>\n<td>Module name (filename without path)</td>\n</tr>\n<tr>\n<td>path</td>\n<td>str</td>\n<td>Full filesystem path to binary</td>\n</tr>\n<tr>\n<td>base_address</td>\n<td>int</td>\n<td>Runtime base address where module is loaded</td>\n</tr>\n<tr>\n<td>size</td>\n<td>int</td>\n<td>Total size of module in memory</td>\n</tr>\n<tr>\n<td>build_id</td>\n<td>str</td>\n<td>Unique identifier for this binary version</td>\n</tr>\n<tr>\n<td>symbols</td>\n<td>Dict[int, Symbol]</td>\n<td>Map from start address to symbol information</td>\n</tr>\n<tr>\n<td>has_debug_info</td>\n<td>bool</td>\n<td>Whether DWARF debug information is available</td>\n</tr>\n<tr>\n<td>architecture</td>\n<td>str</td>\n<td>Target architecture (x86_64, aarch64, etc.)</td>\n</tr>\n<tr>\n<td>load_time</td>\n<td>float</td>\n<td>Timestamp when module was first loaded</td>\n</tr>\n</tbody></table>\n<p>The module loading process involves several stages. First, we parse the ELF header to validate the file format and extract basic information like architecture and entry point. Next, we iterate through the section headers to locate symbol table sections. For each symbol table, we read all symbol entries and build our internal symbol map, sorting by address for efficient lookup.</p>\n<p><strong>C++ Symbol Demangling</strong></p>\n<p>Compiled C++ code uses <strong>name mangling</strong> to encode function signatures, namespaces, and template instantiations into unique symbol names. A simple C++ function like <code>MyClass::calculate(int, double)</code> might appear in the symbol table as <code>_ZN7MyClass9calculateEid</code>. For human-readable profiling output, we must <strong>demangle</strong> these names back to their original form.</p>\n<p>The demangling process uses the platform&#39;s demangling library (typically <code>libc++abi</code> or <code>libstdc++</code>) to convert mangled names. Since demangling can be expensive, we cache the results in our <code>SymbolCache</code>:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>demangled_names</td>\n<td>Dict[str, str]</td>\n<td>Cache mapping mangled names to demangled versions</td>\n</tr>\n<tr>\n<td>hit_count</td>\n<td>int</td>\n<td>Number of successful cache lookups</td>\n</tr>\n<tr>\n<td>miss_count</td>\n<td>int</td>\n<td>Number of cache misses requiring computation</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight</strong>: Symbol demangling can consume significant CPU time during symbol resolution, especially for heavily templated C++ code. Aggressive caching of demangled names is essential for maintaining profiling performance. We also provide configuration options to disable demangling entirely for performance-critical scenarios where raw mangled names are acceptable.</p>\n</blockquote>\n<h3 id=\"dwarf-debug-information\">DWARF Debug Information</h3>\n<p>While ELF symbol tables provide function names and address ranges, <strong>DWARF debug information</strong> contains much richer metadata about the source code structure. DWARF enables us to map instruction addresses not just to function names, but to specific source file names, line numbers, and even column positions. This information transforms raw addresses into actionable debugging data.</p>\n<p><strong>DWARF Structure and Compilation Units</strong></p>\n<p>DWARF debug information is organized into <strong>compilation units</strong>, each representing a single source file that was compiled. Within each compilation unit, we find <strong>Debug Information Entries (DIEs)</strong> that describe functions, variables, types, and source line mappings.</p>\n<p>The most critical DWARF sections for symbol resolution are:</p>\n<table>\n<thead>\n<tr>\n<th>Section</th>\n<th>Purpose</th>\n<th>Content</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>.debug_info</td>\n<td>Core debug data</td>\n<td>Function definitions, variable types, compilation units</td>\n</tr>\n<tr>\n<td>.debug_line</td>\n<td>Line number mapping</td>\n<td>Maps instruction addresses to source file:line:column</td>\n</tr>\n<tr>\n<td>.debug_abbrev</td>\n<td>Abbreviation table</td>\n<td>Compression scheme for debug_info section</td>\n</tr>\n<tr>\n<td>.debug_str</td>\n<td>String table</td>\n<td>Shared string storage for debug information</td>\n</tr>\n<tr>\n<td>.debug_ranges</td>\n<td>Address ranges</td>\n<td>Non-contiguous address ranges for optimized code</td>\n</tr>\n</tbody></table>\n<p><strong>Line Number Program Execution</strong></p>\n<p>The <code>.debug_line</code> section contains a state machine program that generates the complete mapping from instruction addresses to source locations. This compact encoding allows the compiler to efficiently represent line number information even for heavily optimized code where instructions from different source lines might be interleaved.</p>\n<p>The line number state machine maintains several registers:</p>\n<table>\n<thead>\n<tr>\n<th>Register</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>address</td>\n<td>uint64</td>\n<td>Current instruction address</td>\n</tr>\n<tr>\n<td>file</td>\n<td>uint32</td>\n<td>Index into file name table</td>\n</tr>\n<tr>\n<td>line</td>\n<td>uint32</td>\n<td>Current source line number</td>\n</tr>\n<tr>\n<td>column</td>\n<td>uint32</td>\n<td>Current column number within line</td>\n</tr>\n<tr>\n<td>is_stmt</td>\n<td>bool</td>\n<td>Whether this address corresponds to a statement boundary</td>\n</tr>\n<tr>\n<td>basic_block</td>\n<td>bool</td>\n<td>Whether this address starts a basic block</td>\n</tr>\n<tr>\n<td>end_sequence</td>\n<td>bool</td>\n<td>Whether this ends a sequence of instructions</td>\n</tr>\n</tbody></table>\n<p>Our DWARF parser executes this state machine program and builds a sorted table of line number entries. Each entry in our <code>LineRange</code> structure captures the relationship between code addresses and source locations:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>start_address</td>\n<td>int</td>\n<td>Beginning of address range for this source line</td>\n</tr>\n<tr>\n<td>end_address</td>\n<td>int</td>\n<td>End of address range (exclusive)</td>\n</tr>\n<tr>\n<td>line_number</td>\n<td>int</td>\n<td>Source file line number</td>\n</tr>\n<tr>\n<td>column_number</td>\n<td>int</td>\n<td>Column within the source line</td>\n</tr>\n<tr>\n<td>is_statement</td>\n<td>bool</td>\n<td>True if address represents a source statement boundary</td>\n</tr>\n<tr>\n<td>is_prologue_end</td>\n<td>bool</td>\n<td>True if function prologue ends at this address</td>\n</tr>\n<tr>\n<td>is_epilogue_begin</td>\n<td>bool</td>\n<td>True if function epilogue begins at this address</td>\n</tr>\n</tbody></table>\n<p><strong>Handling Optimized and Inlined Code</strong></p>\n<p>Modern compiler optimizations significantly complicate symbol resolution. <strong>Function inlining</strong> means that code from one function appears directly within another function&#39;s instruction stream. <strong>Dead code elimination</strong> removes unreachable code, creating gaps in the address space. <strong>Instruction reordering</strong> can cause instructions from different source lines to be interleaved.</p>\n<p>DWARF handles inlined functions through special DIE entries that describe the inlining relationship. Our <code>InlinedFrame</code> structure captures this information:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>function_name</td>\n<td>str</td>\n<td>Name of the inlined function</td>\n</tr>\n<tr>\n<td>filename</td>\n<td>str</td>\n<td>Source file containing the inlined function</td>\n</tr>\n<tr>\n<td>line_number</td>\n<td>int</td>\n<td>Line number where function is defined</td>\n</tr>\n<tr>\n<td>call_filename</td>\n<td>str</td>\n<td>Source file containing the call site</td>\n</tr>\n<tr>\n<td>call_line_number</td>\n<td>int</td>\n<td>Line number of the inlining call site</td>\n</tr>\n</tbody></table>\n<p>When resolving an address that falls within inlined code, we must construct a chain of <code>InlinedFrame</code> entries representing the complete inlining stack. This allows flame graphs to accurately represent the logical call structure even when physical function calls have been optimized away.</p>\n<p><strong>DWARF Parsing Performance Optimizations</strong></p>\n<p>Parsing complete DWARF information for large binaries can be extremely slow, potentially taking several seconds for large C++ applications. Since profiling must have low latency, we implement several optimization strategies:</p>\n<p><strong>Lazy Loading</strong>: We parse only the compilation unit headers initially, deferring detailed parsing until we actually need symbol information for addresses within that unit. This reduces startup time when profiling applications that only execute code from a small subset of the binary.</p>\n<p><strong>Address Range Indexing</strong>: We build an index mapping address ranges to compilation units, allowing us to quickly determine which unit contains a given address without scanning through all units linearly.</p>\n<p><strong>Line Number Caching</strong>: Since line number programs can be expensive to execute repeatedly, we cache the complete line number table for compilation units that we&#39;ve already processed.</p>\n<p><strong>Incremental Parsing</strong>: For applications that load shared libraries dynamically, we parse DWARF information incrementally as new libraries are loaded rather than attempting to parse everything upfront.</p>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<blockquote>\n<p><strong>Decision: Symbol Lookup Data Structure</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to efficiently resolve thousands of addresses per second during profiling. Linear search through symbol tables would be too slow for production use.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Linear search through unsorted symbol list</li>\n<li>Hash table mapping addresses to symbols</li>\n<li>Sorted symbol array with binary search</li>\n<li>Interval tree for overlapping address ranges</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Sorted symbol array with binary search</li>\n<li><strong>Rationale</strong>: Provides O(log n) lookup performance with minimal memory overhead. Hash tables would require exact address matches, but we need range queries. Interval trees add complexity without significant performance benefits for typical symbol table sizes.</li>\n<li><strong>Consequences</strong>: Enables fast symbol resolution with predictable performance characteristics. Requires sorting symbols during module loading, adding slight initialization cost.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Linear search</td>\n<td>Simple implementation, no preprocessing</td>\n<td>O(n) lookup time, unusable for large binaries</td>\n</tr>\n<tr>\n<td>Hash table</td>\n<td>O(1) average lookup time</td>\n<td>Requires exact address matches, no range queries</td>\n</tr>\n<tr>\n<td>Binary search</td>\n<td>O(log n) lookup, low memory overhead</td>\n<td>Requires sorted array, O(n log n) preprocessing</td>\n</tr>\n<tr>\n<td>Interval tree</td>\n<td>Handles overlapping ranges efficiently</td>\n<td>Complex implementation, higher memory usage</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Symbol Cache Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Symbol resolution involves expensive operations like ELF parsing, DWARF processing, and string demangling. Without caching, repeated lookups become a performance bottleneck.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>No caching - resolve every address freshly</li>\n<li>Simple LRU cache with fixed size</li>\n<li>Multi-level cache with different policies for hits vs misses</li>\n<li>Persistent symbol cache across profiling sessions</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Multi-level cache with LRU for symbols and separate miss cache</li>\n<li><strong>Rationale</strong>: Hot addresses in typical programs follow power law distribution - small number of addresses account for majority of samples. Miss cache prevents repeated expensive lookups for addresses with no symbols (common in optimized binaries).</li>\n<li><strong>Consequences</strong>: Dramatically improves symbol resolution performance after warmup period. Adds memory overhead and cache management complexity.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No caching</td>\n<td>Simple, no memory overhead</td>\n<td>Extremely poor performance, repeated expensive work</td>\n</tr>\n<tr>\n<td>LRU cache</td>\n<td>Good hit rates for hot addresses</td>\n<td>Still slow for repeated misses</td>\n</tr>\n<tr>\n<td>Multi-level cache</td>\n<td>Optimizes both hits and misses</td>\n<td>More complex implementation</td>\n</tr>\n<tr>\n<td>Persistent cache</td>\n<td>Fast across sessions</td>\n<td>Cache invalidation complexity, disk storage</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: ASLR and Load Bias Handling</strong></p>\n<ul>\n<li><strong>Context</strong>: Modern systems randomize load addresses for security. Raw addresses from stack samples don&#39;t match addresses in ELF symbol tables.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Parse /proc/[pid]/maps at startup and assume static layout</li>\n<li>Re-read /proc/[pid]/maps periodically to detect changes</li>\n<li>Hook into dynamic linker notifications</li>\n<li>Use ptrace to monitor memory mapping changes</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Parse /proc/[pid]/maps at startup with periodic refresh</li>\n<li><strong>Rationale</strong>: Most profiling sessions target processes with stable memory layouts after initialization. Periodic refresh catches dynamic library loading without excessive overhead. Hooking into linker adds complexity and ptrace requires elevated privileges.</li>\n<li><strong>Consequences</strong>: Works well for typical profiling scenarios. May miss short-lived dynamic libraries loaded between refresh intervals.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Static startup parsing</td>\n<td>Simple, low overhead</td>\n<td>Misses dynamic library loading</td>\n</tr>\n<tr>\n<td>Periodic refresh</td>\n<td>Catches most library changes</td>\n<td>Slight performance overhead</td>\n</tr>\n<tr>\n<td>Linker hooking</td>\n<td>Real-time updates</td>\n<td>Complex implementation, fragile</td>\n</tr>\n<tr>\n<td>ptrace monitoring</td>\n<td>Complete accuracy</td>\n<td>Requires root privileges, high overhead</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: DWARF Processing Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: DWARF debug information can be massive (gigabytes for large C++ applications). Full parsing is too slow for interactive profiling.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Parse all DWARF information at startup</li>\n<li>Lazy parsing - only process DWARF for addresses we actually encounter</li>\n<li>Background thread pre-parsing popular compilation units</li>\n<li>External symbol server with pre-processed DWARF data</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Lazy parsing with background thread optimization</li>\n<li><strong>Rationale</strong>: Most profiling sessions only exercise small fraction of total code. Lazy parsing provides good performance for typical use cases. Background thread can speculatively parse compilation units for hot addresses.</li>\n<li><strong>Consequences</strong>: First lookup for an address may be slower due to DWARF parsing overhead. Memory usage scales with actual profiling coverage rather than total binary size.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Full startup parsing</td>\n<td>Consistent lookup performance</td>\n<td>Extremely slow startup, high memory usage</td>\n</tr>\n<tr>\n<td>Lazy parsing</td>\n<td>Fast startup, memory efficient</td>\n<td>Variable lookup latency</td>\n</tr>\n<tr>\n<td>Background pre-parsing</td>\n<td>Good compromise on latency</td>\n<td>Complex thread coordination</td>\n</tr>\n<tr>\n<td>External symbol server</td>\n<td>Very fast, shared across teams</td>\n<td>Infrastructure complexity, network dependency</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Ignoring ASLR When Resolving Addresses</strong></p>\n<p>Many developers assume that addresses from stack samples can be directly compared with addresses from ELF symbol tables. This works on older systems or when ASLR is disabled, but fails on modern Linux distributions where ASLR is enabled by default.</p>\n<p><strong>Why it&#39;s wrong</strong>: ASLR randomizes the base addresses where executables and shared libraries are loaded. The virtual addresses in ELF files represent the original link-time layout, while runtime addresses include a random offset. Directly comparing these addresses will result in no symbol matches.</p>\n<p><strong>How to fix</strong>: Always parse <code>/proc/[pid]/maps</code> to determine the actual load addresses of modules. Calculate the load bias by subtracting the ELF virtual address from the runtime base address. Apply this bias when translating sample addresses for symbol lookup.</p>\n<p><strong>Example symptom</strong>: Symbol resolution returns no results despite having proper debug symbols, or returns symbols from completely wrong functions.</p>\n<p>⚠️ <strong>Pitfall: Linear Search Through Large Symbol Tables</strong></p>\n<p>Developers often implement symbol resolution by iterating through all symbols in a module until finding one that contains the target address. This appears to work during initial testing with small programs but becomes prohibitively slow with real applications.</p>\n<p><strong>Why it&#39;s wrong</strong>: Large C++ applications can have hundreds of thousands of symbols. Linear search creates O(n) lookup time, making symbol resolution the bottleneck in profiling performance. When profiling at 1000 Hz, even 1ms per symbol lookup is too slow.</p>\n<p><strong>How to fix</strong>: Sort symbols by start address during module loading. Use binary search to find the containing symbol in O(log n) time. Consider building additional indexes for very large symbol tables.</p>\n<p><strong>Example symptom</strong>: Profiler becomes unusably slow when targeting large applications, or symbol resolution takes longer than the actual profiling.</p>\n<p>⚠️ <strong>Pitfall: Not Handling Stripped Binaries Gracefully</strong></p>\n<p>Production binaries are often stripped of symbol tables to reduce size and prevent reverse engineering. Developers sometimes assume symbol tables will always be available and crash or return confusing errors when encountering stripped binaries.</p>\n<p><strong>Why it&#39;s wrong</strong>: Stripped binaries have no <code>.symtab</code> section or have empty symbol tables. Code that assumes symbol availability will fail or return incorrect results. This makes the profiler unusable for many production environments.</p>\n<p><strong>How to fix</strong>: Always check whether symbol sections exist before attempting to parse them. Provide fallback behavior for stripped binaries, such as showing module name and offset instead of function name. Consider supporting external debug symbol files.</p>\n<p><strong>Example symptom</strong>: Profiler crashes with &quot;section not found&quot; errors, or shows no function names for any addresses in the target application.</p>\n<p>⚠️ <strong>Pitfall: Inefficient String Handling in Symbol Names</strong></p>\n<p>Symbol names, especially mangled C++ names, can be quite long. Developers sometimes copy these strings repeatedly during symbol resolution, creating memory allocation pressure and garbage collection overhead in managed languages.</p>\n<p><strong>Why it&#39;s wrong</strong>: String copying during hot path operations can become a significant performance bottleneck. Memory allocations in the symbol resolution path can trigger garbage collection at unpredictable times, causing profiling hiccups.</p>\n<p><strong>How to fix</strong>: Use string interning or reference-based approaches to avoid copying symbol names. Cache demangled names to avoid repeated demangling operations. Consider using string views or slices that reference the original string table data.</p>\n<p><strong>Example symptom</strong>: High memory allocation rates during profiling, garbage collection pauses in managed language implementations, or unexpectedly slow symbol resolution.</p>\n<p>⚠️ <strong>Pitfall: Not Caching DWARF Parsing Results</strong></p>\n<p>DWARF debug information parsing is computationally expensive, involving state machine execution and complex data structure traversal. Developers sometimes parse DWARF information fresh for every address lookup, causing severe performance problems.</p>\n<p><strong>Why it&#39;s wrong</strong>: DWARF parsing can take milliseconds per compilation unit. If the profiler repeatedly looks up addresses from the same compilation unit (which is common due to locality), this creates excessive CPU overhead.</p>\n<p><strong>How to fix</strong>: Cache parsed line number tables and compilation unit information. Build indexes mapping address ranges to compilation units to avoid scanning through all units. Use lazy parsing to defer DWARF processing until actually needed.</p>\n<p><strong>Example symptom</strong>: Profiler uses excessive CPU time for symbol resolution, profiling overhead becomes unacceptably high, or symbol resolution latency varies dramatically between addresses.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Multi-Threaded Symbol Resolution</strong></p>\n<p>When profiling multi-threaded applications, symbol resolution might be called concurrently from multiple threads. Developers sometimes share symbol caches and data structures without proper synchronization, leading to crashes or corrupted data.</p>\n<p><strong>Why it&#39;s wrong</strong>: Symbol cache updates, module loading, and DWARF parsing involve complex data structure modifications that are not atomic. Concurrent access can lead to inconsistent state, use-after-free errors, or corrupt cache entries.</p>\n<p><strong>How to fix</strong>: Use appropriate synchronization primitives (mutexes, read-write locks) to protect shared symbol resolution state. Consider using lock-free data structures for high-performance scenarios. Design the API to minimize contention between threads.</p>\n<p><strong>Example symptom</strong>: Intermittent crashes during symbol resolution, corrupted function names in output, or deadlocks when multiple threads perform symbol lookups simultaneously.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ELF Parsing</td>\n<td>pyelftools library (pure Python)</td>\n<td>Custom parser with mmap for performance</td>\n</tr>\n<tr>\n<td>DWARF Processing</td>\n<td>pyelftools DWARF reader</td>\n<td>libdwarf bindings or custom parser</td>\n</tr>\n<tr>\n<td>Symbol Caching</td>\n<td>Python dict with manual LRU</td>\n<td>Redis or memcached for distributed caching</td>\n</tr>\n<tr>\n<td>Address Translation</td>\n<td>Simple arithmetic with /proc/maps</td>\n<td>libunwind for robust stack unwinding</td>\n</tr>\n<tr>\n<td>String Demangling</td>\n<td>subprocess calls to c++filt</td>\n<td>Direct bindings to libiberty or libc++abi</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n  symbolizer/\n    __init__.py                 ← Public API exports\n    symbolizer.py              ← Main Symbolizer class and high-level API\n    elf_parser.py              ← ELF binary parsing and symbol extraction\n    dwarf_parser.py            ← DWARF debug information processing\n    symbol_cache.py            ← Symbol caching and performance optimization\n    module_loader.py           ← Module loading and ASLR handling\n    address_resolver.py        ← Core address-to-symbol resolution logic\n    demangler.py              ← C++ symbol demangling utilities\n    tests/\n      test_symbolizer.py       ← Integration tests for full symbolization\n      test_elf_parser.py       ← Unit tests for ELF parsing\n      test_dwarf_parser.py     ← Unit tests for DWARF processing\n      test_symbol_cache.py     ← Unit tests for caching behavior\n      fixtures/                ← Test binaries with known symbols\n        simple_cpp_program     ← Basic C++ program with debug info\n        stripped_binary        ← Production binary without symbols\n        inlined_functions      ← Binary with aggressive inlining</code></pre></div>\n\n<p><strong>Infrastructure Starter Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># symbolizer/elf_parser.py - Complete ELF parsing implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> mmap</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, NamedTuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ELFSymbol</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">NamedTuple</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a single symbol from ELF symbol table.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_address: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_type: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    binding: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ELFParser</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Parses ELF binaries to extract symbol information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, binary_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.binary_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path(binary_path)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbols: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, ELFSymbol] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '&#x3C;'</span><span style=\"color:#6A737D\">  # Little endian</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> parse_symbols</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, ELFSymbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse all symbols from the ELF binary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.binary_path, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                with</span><span style=\"color:#E1E4E8\"> mmap.mmap(f.fileno(), </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">access</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">mmap.</span><span style=\"color:#79B8FF\">ACCESS_READ</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> mm:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Parse ELF header to determine format</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._validate_elf_header(mm):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        return</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Extract section headers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    sections </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._parse_section_headers(mm)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Find symbol table sections</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    symtab </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sections.get(</span><span style=\"color:#9ECBFF\">'.symtab'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    strtab </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sections.get(</span><span style=\"color:#9ECBFF\">'.strtab'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> symtab </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> strtab:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._parse_symbol_table(mm, symtab, strtab)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">IOError</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">OSError</span><span style=\"color:#E1E4E8\">, struct.error):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _validate_elf_header</span><span style=\"color:#E1E4E8\">(self, mm: mmap.mmap) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate ELF magic and extract basic format info.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(mm) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 64</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> mm[:</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#F97583\"> b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\x7f</span><span style=\"color:#9ECBFF\">ELF'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Determine 32-bit vs 64-bit and endianness</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mm[</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '&#x3C;'</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> mm[</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> else</span><span style=\"color:#9ECBFF\"> '>'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _parse_section_headers</span><span style=\"color:#E1E4E8\">(self, mm: mmap.mmap) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse section headers and return mapping of names to info.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Implementation details for parsing ELF section headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Returns dict mapping section names to (offset, size, type) tuples</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sections </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Parse ELF header to get section header table location</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        header_fmt </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#9ECBFF\">'Q'</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> 'L'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shoff_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 40</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 32</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shentsize_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 58</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 46</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shnum_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 48</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shstrndx_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 62</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 50</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shoff </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(header_fmt, mm[e_shoff_offset:e_shoff_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shentsize </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'H'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   mm[e_shentsize_offset:e_shentsize_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shnum </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'H'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               mm[e_shnum_offset:e_shnum_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        e_shstrndx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'H'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  mm[e_shstrndx_offset:e_shstrndx_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Parse section headers and build name mapping</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(e_shnum):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            header_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> e_shoff </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> e_shentsize</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> header_offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> e_shentsize </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(mm):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Parse section header fields we care about</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sh_name_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'L'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                         mm[header_offset:header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sh_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'L'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   mm[header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">:header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                sh_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'Q'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                        mm[header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">24</span><span style=\"color:#E1E4E8\">:header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                sh_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'Q'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                       mm[header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">:header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">40</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                sh_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'L'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                        mm[header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">:header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                sh_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'L'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                       mm[header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">:header_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">24</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Get section name from string table</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> e_shstrndx:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span><span style=\"color:#6A737D\">  # Skip string table header itself</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # We'll implement section name lookup in a full implementation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # For now, recognize sections by type</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> sh_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># SHT_SYMTAB</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                sections[</span><span style=\"color:#9ECBFF\">'.symtab'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (sh_offset, sh_size, sh_type)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> sh_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># SHT_STRTAB</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                sections[</span><span style=\"color:#9ECBFF\">'.strtab'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (sh_offset, sh_size, sh_type)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> sections</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _parse_symbol_table</span><span style=\"color:#E1E4E8\">(self, mm: mmap.mmap, symtab_info: </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           strtab_info: </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, ELFSymbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse symbol table entries and resolve names.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        symbols </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        symtab_offset, symtab_size, _ </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symtab_info</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        strtab_offset, strtab_size, _ </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> strtab_info</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Symbol table entry size depends on architecture</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sym_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 24</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 16</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        num_symbols </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symtab_size </span><span style=\"color:#F97583\">//</span><span style=\"color:#E1E4E8\"> sym_size</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(num_symbols):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sym_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symtab_offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sym_size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> sym_offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> sym_size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(mm):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Parse symbol entry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_64bit:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                st_name, st_info, st_other, st_shndx, st_value, st_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'LBBHQQ'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 mm[sym_offset:sym_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">24</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                st_name, st_value, st_size, st_info, st_other, st_shndx </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    struct.unpack(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.byte_order </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> 'LLLBBH'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 mm[sym_offset:sym_offset</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Skip symbols with no size or invalid addresses</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> st_size </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> st_value </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Extract symbol name from string table</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> st_name </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> strtab_size:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                name_start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> strtab_offset </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> st_name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                name_end </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mm.find(</span><span style=\"color:#F97583\">b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\x00</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, name_start)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> name_end </span><span style=\"color:#F97583\">!=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    symbol_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mm[name_start:name_end].decode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                                                               errors</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'replace'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    symbol </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ELFSymbol(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        name</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">symbol_name,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        start_address</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">st_value,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        size</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">st_size,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        symbol_type</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">st_info </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#F97583\"> 0x</span><span style=\"color:#79B8FF\">f</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        binding</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">st_info </span><span style=\"color:#F97583\">>></span><span style=\"color:#79B8FF\"> 4</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    symbols[st_value] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symbol</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> symbols</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># symbolizer/symbol_cache.py - Complete caching implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Optional, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> OrderedDict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolCache</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"High-performance cache for symbol resolution results.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_cache_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">):  </span><span style=\"color:#6A737D\"># 1MB default</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.address_to_symbol: OrderedDict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Optional[Symbol]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> OrderedDict()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.module_cache: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Module] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.demangled_names: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.miss_cache: Set[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_cache_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_cache_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.hit_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.miss_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.last_cleanup </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> lookup_symbol</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Symbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Look up cached symbol or return None for miss.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check miss cache first (faster than symbol lookup)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> address </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.miss_cache:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.miss_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check symbol cache</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> address </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.address_to_symbol:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.hit_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Move to end for LRU</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            symbol </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.address_to_symbol.pop(address)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.address_to_symbol[address] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symbol</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> symbol</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.miss_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cache_symbol</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, symbol: Optional[Symbol]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Cache symbol result or miss for future lookups.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> symbol </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.miss_cache.add(address)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Limit miss cache size to prevent memory bloat</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.miss_cache) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.miss_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.miss_cache)[</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">5000</span><span style=\"color:#E1E4E8\">:])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.address_to_symbol[address] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symbol</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._cleanup_if_needed()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_hit_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate symbol cache hit rate percentage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total_requests </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.hit_count </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.miss_count</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.hit_count </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_requests </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> total_requests </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _cleanup_if_needed</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Remove old entries if cache is too large.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.address_to_symbol) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 64</span><span style=\"color:#6A737D\">  # Rough size estimate</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> current_size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_cache_size:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Remove oldest 25% of entries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            remove_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.address_to_symbol) </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 4</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(remove_count):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.address_to_symbol.popitem(</span><span style=\"color:#FFAB70\">last</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># symbolizer/symbolizer.py - Main symbolization logic to implement</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Symbolizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Main symbol resolution engine for profiler.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: SymbolConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbol_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SymbolCache()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.modules: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Module] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.process_maps: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> symbolize_profile</span><span style=\"color:#E1E4E8\">(self, profile: Profile) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resolve addresses to function names for all samples in profile.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract target process ID from profile metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load process memory maps using _load_process_maps()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each sample in profile.sample_batch.samples:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Call symbolize_stack_frames() on sample.stack_frames</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Update sample with resolved symbol information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return profile with populated function names and source info</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Process all samples to batch module loading efficiently</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> symbolize_stack_frames</span><span style=\"color:#E1E4E8\">(self, stack_frames: List[StackFrame]) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resolve symbol information for a list of stack frames.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: For each frame in stack_frames:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Check symbol_cache.lookup_symbol() first for performance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - If cache miss, call _resolve_address() to find symbol</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Update frame with function_name, filename, line_number</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Cache result using symbol_cache.cache_symbol()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle special cases like kernel frames (is_kernel=True)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Process inlined functions if DWARF info available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return updated stack_frames with symbol information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Batch process frames from same module for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _resolve_address</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, process_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Symbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Core address resolution logic - find symbol for given address.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find which module contains this address using _find_module()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If no module found, return None (cache as miss)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate file-relative address by subtracting module base</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Search module symbols using binary search on sorted addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: If symbol found, enhance with DWARF info if available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Apply C++ demangling if enabled in config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use Module.find_symbol() method for efficient lookup</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _load_process_maps</span><span style=\"color:#E1E4E8\">(self, process_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse /proc/[pid]/maps to get module load addresses.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Read /proc/{process_id}/maps file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Parse each line to extract: start_addr, end_addr, perms, path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Filter for executable regions (perms contains 'x')</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For each executable mapping:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Create Module object if not already loaded</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Parse ELF symbols using ELFParser if first time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Calculate load bias (runtime_addr - elf_virtual_addr)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         - Store in self.modules and self.process_maps</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle shared libraries and ASLR properly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Cache parsed modules across different processes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _find_module</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, process_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Module]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find which module contains the given runtime address.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get process memory maps for process_id</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Binary search through sorted address ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if address falls within any module's range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return Module object or None if not found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Consider caching recent lookups for hot addresses</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _enhance_with_dwarf</span><span style=\"color:#E1E4E8\">(self, symbol: Symbol, module: Module) -> Symbol:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add source file and line number info using DWARF debug data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if module.has_debug_info is True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load DWARF parser for this module (lazy loading)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Execute line number program to get address->line mapping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Find line number entry containing symbol address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update symbol with source_file and line_ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle inlined functions and create InlinedFrame entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Cache parsed line number tables for performance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing symbol resolution, verify correct behavior:</p>\n<p><strong>Expected Command</strong>: <code>python -m profiler.symbolizer.tests.test_symbolizer</code></p>\n<p><strong>Expected Output</strong>:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Symbol Resolution Tests\n✓ ELF parsing extracts correct symbol count\n✓ Address resolution maps to correct function names  \n✓ DWARF processing provides source line numbers\n✓ Symbol caching improves lookup performance\n✓ C++ demangling produces readable names\n✓ ASLR handling works with randomized addresses\nCache hit rate: 85.2% (target: &gt;80%)</code></pre></div>\n\n<p><strong>Manual Verification Steps</strong>:</p>\n<ol>\n<li>Create a simple C++ program with debug info: <code>g++ -g -o test_program test.cpp</code></li>\n<li>Run symbolizer on known addresses: <code>addr2line -e test_program &lt;address&gt;</code> </li>\n<li>Compare symbolizer output with addr2line results</li>\n<li>Verify that stripped binaries fail gracefully without crashes</li>\n</ol>\n<p><strong>Signs of Problems</strong>:</p>\n<ul>\n<li>Function names are all &quot;unknown&quot; or missing despite having symbols</li>\n<li>Source line numbers are incorrect or missing  </li>\n<li>Performance is slower than 1000 lookups per second</li>\n<li>Cache hit rate is below 70% after warmup period</li>\n<li>Crashes when processing stripped binaries or invalid addresses</li>\n</ul>\n<h2 id=\"flame-graph-generation-component\">Flame Graph Generation Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 3 — Flame Graph Generation: Aggregate captured stack samples and create interactive SVG flame graph visualizations that enable developers to understand program hotspots and call relationships through hierarchical visualization</p>\n</blockquote>\n<h3 id=\"mental-model-family-tree-visualization\">Mental Model: Family Tree Visualization</h3>\n<p>Think of flame graph generation like creating a family tree from scattered birth certificates. You have thousands of individual samples, each representing a captured call stack at a specific moment in time. Each sample is like a birth certificate that says &quot;function A called function B called function C.&quot; Your job is to gather all these individual records and build a comprehensive family tree that shows which functions are related to each other and how frequently those relationships occur.</p>\n<p>Just as a family tree shows ancestral relationships with the oldest generation at the bottom and newer generations stacked above, a flame graph displays call relationships with the program entry point at the bottom and deeper function calls stacked vertically. The width of each &quot;family branch&quot; represents how many descendants (samples) belong to that lineage, making it immediately obvious which code paths are most heavily trafficked.</p>\n<p>The key insight is that flame graphs transform temporal data (samples collected over time) into spatial data (visual hierarchies). Instead of reading through thousands of individual stack traces, developers can see the &quot;big picture&quot; of their program&#39;s execution patterns at a glance. Hot code paths appear as wide horizontal bands, while infrequently called functions appear as thin slivers or disappear entirely if they fall below the visualization threshold.</p>\n<h3 id=\"stack-folding-and-aggregation\">Stack Folding and Aggregation</h3>\n<p>Stack folding represents the core algorithmic challenge of flame graph generation: converting thousands or millions of individual stack samples into a hierarchical tree structure that accurately represents call frequencies and relationships. This process involves three fundamental operations: stack signature generation, hierarchical aggregation, and weight calculation.</p>\n<p><strong>Stack signature generation</strong> creates unique identifiers for each distinct call stack pattern. The aggregator processes each <code>Sample</code> by concatenating the <code>function_name</code> fields from its <code>stack_frames</code> list, creating a stack signature string. For example, a stack containing frames [&quot;main&quot;, &quot;process_request&quot;, &quot;parse_json&quot;, &quot;malloc&quot;] becomes the signature &quot;main;process_request;parse_json;malloc&quot;. This semicolon-delimited format, known as folded stack format, enables efficient grouping of identical call patterns.</p>\n<p>The signature generation algorithm handles several critical edge cases. Inlined functions from <code>InlinedFrame</code> structures must be properly expanded into the signature to maintain call hierarchy accuracy. Kernel frames marked with <code>is_kernel=True</code> receive special prefixes to distinguish them from user-space functions. Address-only frames that failed symbol resolution get represented as hex addresses to prevent information loss.</p>\n<p><strong>Hierarchical aggregation</strong> builds the flame graph tree structure by processing stack signatures in a specific order. The aggregator maintains a tree where each node represents a unique function call context. Unlike traditional call trees that group by function name alone, flame graph nodes represent the full calling context — the same function called from different code paths becomes separate nodes in the tree.</p>\n<p>The aggregation algorithm processes each stack signature from bottom to top, creating or updating tree nodes along the path. For the signature &quot;main;process_request;parse_json;malloc&quot;, the algorithm first finds or creates a root node for &quot;main&quot;, then finds or creates a child node &quot;process_request&quot; under &quot;main&quot;, and so forth. Each node maintains a sample count that gets incremented when matching signatures are encountered.</p>\n<blockquote>\n<p><strong>Critical Design Insight:</strong> The stack folding algorithm must preserve calling context, not just function identity. A function called from two different code paths must appear as separate nodes in the flame graph tree to accurately represent the program&#39;s execution patterns.</p>\n</blockquote>\n<p><strong>Weight calculation</strong> determines the visual width of each flame graph rectangle based on the aggregated sample counts. The algorithm calculates weights recursively, where each node&#39;s weight equals the sum of its direct sample count plus the weights of all its children. This ensures that parent nodes accurately represent the cumulative time spent in their entire call subtree.</p>\n<p>The weight calculation must handle sample weights correctly when individual samples have different durations or importance. The <code>sample_weight</code> field in each <code>Sample</code> allows for weighted aggregation where some samples count more heavily than others. This becomes crucial when dealing with adaptive sampling rates or when merging profiles with different sampling frequencies.</p>\n<table>\n<thead>\n<tr>\n<th>Aggregation Operation</th>\n<th>Input</th>\n<th>Output</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signature Generation</td>\n<td>List[StackFrame]</td>\n<td>str</td>\n<td>Create unique identifier for call stack pattern</td>\n</tr>\n<tr>\n<td>Tree Building</td>\n<td>List[str]</td>\n<td>FlameNode</td>\n<td>Build hierarchical tree from folded signatures</td>\n</tr>\n<tr>\n<td>Weight Calculation</td>\n<td>FlameNode</td>\n<td>int</td>\n<td>Calculate cumulative sample counts for visualization</td>\n</tr>\n<tr>\n<td>Width Normalization</td>\n<td>FlameNode, total_samples</td>\n<td>float</td>\n<td>Convert sample counts to pixel widths</td>\n</tr>\n<tr>\n<td>Color Assignment</td>\n<td>FlameNode</td>\n<td>str</td>\n<td>Assign colors based on function category or module</td>\n</tr>\n</tbody></table>\n<p>The folded stack format output becomes a critical interface point for the flame graph generation system. This format, popularized by Brendan Gregg&#39;s flame graph tools, enables interoperability with existing visualization tools and provides a human-readable intermediate representation for debugging aggregation logic.</p>\n<blockquote>\n<p><strong>Decision: Folded Stack Format</strong></p>\n<ul>\n<li><strong>Context</strong>: Need standardized intermediate format between aggregation and visualization</li>\n<li><strong>Options Considered</strong>: Custom binary format, JSON tree structure, folded stack text format</li>\n<li><strong>Decision</strong>: Adopt folded stack text format with sample counts</li>\n<li><strong>Rationale</strong>: Industry standard format enables tool interoperability, human-readable for debugging, compact representation, widely supported by existing flame graph tools</li>\n<li><strong>Consequences</strong>: Enables integration with external tools but requires parsing step for custom visualizations</li>\n</ul>\n</blockquote>\n<h3 id=\"interactive-svg-generation\">Interactive SVG Generation</h3>\n<p>Interactive SVG generation transforms the aggregated flame graph tree into a scalable vector graphics document that supports user interaction through embedded JavaScript. This process involves coordinate calculation, SVG element generation, and interactive feature implementation.</p>\n<p><strong>Coordinate calculation</strong> maps the logical flame graph tree structure onto a two-dimensional pixel coordinate system. The algorithm performs a recursive tree traversal, calculating the x-coordinate and width for each node based on its cumulative sample weight, and the y-coordinate based on its depth in the call hierarchy.</p>\n<p>The coordinate system uses a bottom-up layout where the root node (typically main) appears at the bottom of the visualization and deeper call stack levels appear higher on the y-axis. Each stack level has a fixed height defined by <code>min_width_pixels</code> in the <code>VisualizationConfig</code>, typically 16-20 pixels to accommodate readable function names.</p>\n<p>Width calculation requires careful normalization to ensure the entire flame graph fits within the target SVG viewport. The algorithm calculates each node&#39;s width as: <code>node_width = (node_weight / total_samples) * viewport_width</code>. Nodes with widths below <code>min_width_pixels</code> get filtered out to prevent visual clutter and improve rendering performance.</p>\n<table>\n<thead>\n<tr>\n<th>Coordinate Calculation</th>\n<th>Formula</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Node Width</td>\n<td>(node_weight / total_samples) * viewport_width</td>\n<td>Proportional width based on sample frequency</td>\n</tr>\n<tr>\n<td>Node X Position</td>\n<td>parent_x + cumulative_child_widths</td>\n<td>Horizontal positioning within parent</td>\n</tr>\n<tr>\n<td>Node Y Position</td>\n<td>stack_depth * rectangle_height</td>\n<td>Vertical positioning by call depth</td>\n</tr>\n<tr>\n<td>Text X Position</td>\n<td>node_x + (node_width / 2)</td>\n<td>Center text within rectangle</td>\n</tr>\n<tr>\n<td>Text Y Position</td>\n<td>node_y + (rectangle_height / 2) + (font_size / 3)</td>\n<td>Vertically center text with baseline adjustment</td>\n</tr>\n</tbody></table>\n<p><strong>SVG element generation</strong> creates the actual XML structure for the flame graph visualization. Each flame graph node becomes an SVG <code>&lt;rect&gt;</code> element with calculated coordinates and a <code>&lt;text&gt;</code> element for the function name. The generator groups related elements using <code>&lt;g&gt;</code> tags to enable hierarchical styling and interaction handling.</p>\n<p>The SVG generation algorithm implements several optimization techniques to manage large flame graphs with thousands of nodes. Text elements include <code>textLength</code> attributes to prevent overflow beyond rectangle boundaries. Long function names get truncated with ellipsis indicators while preserving tooltips that show full names. Rectangle elements receive data attributes containing metadata like sample counts and percentages for interactive features.</p>\n<p>Color assignment uses configurable schemes defined in <code>VisualizationConfig.color_scheme</code> to distinguish different categories of code. Common schemes include module-based coloring (different colors for user code, system libraries, kernel functions) and hash-based coloring (consistent colors for the same function across different contexts).</p>\n<p><strong>Interactive feature implementation</strong> embeds JavaScript directly into the SVG document to enable zoom, search, and tooltip functionality without requiring external dependencies. The interaction system responds to mouse events on flame graph rectangles and provides several user interface capabilities.</p>\n<p>Zoom functionality allows users to focus on specific portions of large flame graphs by clicking on any rectangle to make it the new root of the visualization. The zoom implementation recalculates coordinates and scales all elements to fit the viewport, effectively creating a &quot;drill-down&quot; interaction that helps users explore deep call stacks.</p>\n<p>Search functionality highlights all rectangles containing user-specified function names or patterns. The search implementation uses JavaScript regular expressions to match against the text content of each flame graph node, applying highlighting styles to matching elements and providing navigation between search results.</p>\n<table>\n<thead>\n<tr>\n<th>Interactive Feature</th>\n<th>Trigger</th>\n<th>Behavior</th>\n<th>Implementation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Rectangle Hover</td>\n<td>Mouse enter/leave</td>\n<td>Show tooltip with function details</td>\n<td>JavaScript event listeners + CSS transitions</td>\n</tr>\n<tr>\n<td>Rectangle Click</td>\n<td>Mouse click</td>\n<td>Zoom to clicked function as new root</td>\n<td>Coordinate recalculation + SVG transformation</td>\n</tr>\n<tr>\n<td>Search Box</td>\n<td>Text input</td>\n<td>Highlight matching function names</td>\n<td>RegExp matching + CSS class application</td>\n</tr>\n<tr>\n<td>Reset Zoom</td>\n<td>Button click</td>\n<td>Return to full flame graph view</td>\n<td>Restore original coordinate system</td>\n</tr>\n<tr>\n<td>Export Data</td>\n<td>Button click</td>\n<td>Download folded stack format</td>\n<td>Generate text file from current view</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Embedded JavaScript vs External Framework</strong></p>\n<ul>\n<li><strong>Context</strong>: Need interactive features in flame graph visualization</li>\n<li><strong>Options Considered</strong>: React/Vue.js web application, D3.js visualization framework, embedded SVG JavaScript</li>\n<li><strong>Decision</strong>: Embed JavaScript directly in SVG documents</li>\n<li><strong>Rationale</strong>: Self-contained files require no external dependencies, faster loading for large graphs, simpler deployment and sharing, reduced complexity for basic interactions</li>\n<li><strong>Consequences</strong>: Limited to basic interactions but enables standalone flame graph files that work anywhere</li>\n</ul>\n</blockquote>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<p>The flame graph generation component involves several critical architectural decisions that significantly impact performance, usability, and maintainability. These decisions establish the foundation for how aggregated stack data transforms into interactive visualizations.</p>\n<blockquote>\n<p><strong>Decision: SVG vs Canvas vs HTML for Visualization</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to render potentially thousands of rectangles with text labels in web browsers efficiently</li>\n<li><strong>Options Considered</strong>: SVG with embedded interactivity, HTML5 Canvas with JavaScript, HTML div elements with CSS positioning</li>\n<li><strong>Decision</strong>: SVG with embedded JavaScript for interactivity</li>\n<li><strong>Rationale</strong>: SVG provides vector scaling without pixelation, built-in text rendering with proper font metrics, CSS styling capabilities, accessibility features for screen readers, and ability to embed JavaScript for interactions while remaining printable</li>\n<li><strong>Consequences</strong>: Better print quality and accessibility than Canvas, simpler than HTML positioning, but potentially slower rendering for extremely large graphs (&gt;10k rectangles)</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Visualization Technology</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SVG + JavaScript</td>\n<td>Vector scaling, accessibility, printable, embedded interactivity</td>\n<td>Memory usage for large graphs, complex coordinate calculations</td>\n<td>✅ Yes</td>\n</tr>\n<tr>\n<td>HTML5 Canvas</td>\n<td>High performance rendering, pixel-perfect control</td>\n<td>Poor text rendering, no accessibility, requires complex hit detection</td>\n<td>❌ No</td>\n</tr>\n<tr>\n<td>HTML + CSS</td>\n<td>Simple layout, good performance</td>\n<td>Poor print quality, complex positioning math, limited text overflow handling</td>\n<td>❌ No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Bottom-Up vs Top-Down Flame Graph Orientation</strong></p>\n<ul>\n<li><strong>Context</strong>: Stack samples represent call chains from program entry point to deepest function call</li>\n<li><strong>Options Considered</strong>: Bottom-up layout (main at bottom), top-down layout (main at top), sidewise layout (main at left)</li>\n<li><strong>Decision</strong>: Bottom-up layout with main function at bottom of visualization</li>\n<li><strong>Rationale</strong>: Matches traditional flame graph conventions established by Brendan Gregg, intuitive &quot;flames rise upward&quot; mental model, consistent with stack unwinding direction, enables easy visual identification of leaf functions</li>\n<li><strong>Consequences</strong>: Follows industry standards enabling tool compatibility but may feel inverted to developers used to call tree visualizations</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Fixed vs Dynamic Rectangle Heights</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance readability with information density in flame graph visualization</li>\n<li><strong>Options Considered</strong>: Fixed height for all rectangles, dynamic height based on sample count, adaptive height based on function name length</li>\n<li><strong>Decision</strong>: Fixed rectangle height with configurable pixel size</li>\n<li><strong>Rationale</strong>: Consistent visual rhythm makes patterns easier to identify, simplifies coordinate calculations, ensures text readability at all zoom levels, prevents visual bias toward high-sample functions</li>\n<li><strong>Consequences</strong>: Efficient rendering and clear readability but some visual information loss compared to area-proportional representations</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Rectangle Sizing Approach</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Fixed Height</td>\n<td>Consistent visual rhythm, simple math, good text readability</td>\n<td>Less information density than proportional sizing</td>\n<td>✅ Yes</td>\n</tr>\n<tr>\n<td>Dynamic Height</td>\n<td>More information in same space, visually emphasizes hot functions</td>\n<td>Complex calculations, text sizing issues, visual bias</td>\n<td>❌ No</td>\n</tr>\n<tr>\n<td>Adaptive Height</td>\n<td>Optimizes for text content, handles long names better</td>\n<td>Inconsistent appearance, complex layout algorithm</td>\n<td>❌ No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Client-Side vs Server-Side Interactivity</strong></p>\n<ul>\n<li><strong>Context</strong>: Users need zoom, search, and tooltip functionality in flame graphs</li>\n<li><strong>Options Considered</strong>: Server-side rendering with form submissions, client-side JavaScript with DOM manipulation, hybrid approach with progressive enhancement</li>\n<li><strong>Decision</strong>: Pure client-side JavaScript embedded in SVG documents</li>\n<li><strong>Rationale</strong>: Eliminates server round-trips for interactions, enables offline usage of saved flame graphs, reduces server load, provides instant responsiveness for zoom and search operations</li>\n<li><strong>Consequences</strong>: Self-contained flame graph files but requires JavaScript-enabled browsers and increases initial file size</li>\n</ul>\n</blockquote>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>Flame graph generation involves several algorithmic and implementation challenges that commonly trip up developers building profiler visualizations. Understanding these pitfalls helps avoid subtle bugs that can produce misleading or incorrect flame graphs.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Width Calculations Leading to Visual Gaps</strong></p>\n<p>Developers frequently make floating-point precision errors when calculating rectangle widths, leading to visual gaps or overlaps in the flame graph. This occurs when the sum of child node widths doesn&#39;t exactly equal the parent node width due to rounding errors in the width calculation formula.</p>\n<p>The problem manifests when converting from sample counts (integers) to pixel coordinates (floats). A parent node with 1000 samples and three children with 333, 333, and 334 samples respectively may have child widths that don&#39;t sum to exactly the parent width after pixel conversion. This creates visible gaps that users interpret as missing data or profiler bugs.</p>\n<p><strong>Fix:</strong> Implement width correction algorithms that distribute rounding errors across child nodes. Calculate all child widths first, then adjust the rightmost child&#39;s width to ensure the sum exactly matches the parent width: <code>children[-1].width += parent.width - sum(child.width for child in children)</code>.</p>\n<p>⚠️ <strong>Pitfall: Stack Signature Hash Collisions Corrupting Aggregation</strong></p>\n<p>When using hash-based aggregation for performance optimization, developers sometimes use weak hash functions that produce collisions for different call stacks. This causes the aggregator to merge samples from completely different code paths, creating flame graphs that show incorrect call relationships.</p>\n<p>Hash collisions typically occur when using simple string hash functions on folded stack signatures, especially for programs with many similar function names or deep call stacks. The collision rate increases dramatically with large sample counts, leading to subtle aggregation errors that are difficult to detect through casual inspection.</p>\n<p><strong>Fix:</strong> Use cryptographic hash functions like SHA-256 for stack signature generation, or avoid hashing entirely by using the full folded stack string as the aggregation key. For performance-critical applications, implement collision detection by storing both the hash and the original stack signature, falling back to string comparison when hash collisions occur.</p>\n<p>⚠️ <strong>Pitfall: Memory Explosion from Inefficient Tree Storage</strong></p>\n<p>Naive tree implementations can consume excessive memory when storing large numbers of flame graph nodes, especially for programs with deep call stacks or many distinct code paths. This occurs when each tree node stores redundant information or uses inefficient pointer structures.</p>\n<p>The problem becomes severe with large-scale profiling where millions of samples create hundreds of thousands of distinct flame graph nodes. Storing full function names, file paths, and metadata in every node can consume gigabytes of memory and cause profiler crashes or system resource exhaustion.</p>\n<p><strong>Fix:</strong> Implement string interning for function names and file paths to eliminate duplicate storage. Use compact node representations with integer IDs referencing shared string tables. Consider tree compression techniques that merge nodes with single children to reduce depth and memory usage.</p>\n<p>⚠️ <strong>Pitfall: Text Rendering Performance Degradation with Large Graphs</strong></p>\n<p>SVG text rendering becomes a significant performance bottleneck when flame graphs contain thousands of text elements, leading to slow browser rendering and poor user interaction responsiveness. This problem compounds when using complex fonts or when the browser must calculate text metrics for layout.</p>\n<p>The performance issue becomes noticeable with flame graphs containing more than 5,000-10,000 visible rectangles. Browsers struggle to render all the text elements smoothly, causing laggy zoom operations and poor scrolling performance that makes the flame graph difficult to use.</p>\n<p><strong>Fix:</strong> Implement level-of-detail rendering that only shows text for rectangles above a minimum width threshold. Use <code>visibility: hidden</code> for text in small rectangles rather than removing elements entirely. Consider lazy text rendering that only creates text elements for currently visible portions of large flame graphs.</p>\n<p>⚠️ <strong>Pitfall: Color Scheme Accessibility Issues</strong></p>\n<p>Developers often choose color schemes that look appealing on their development monitors but create accessibility problems for users with color vision deficiencies or different display settings. Red-green color schemes are particularly problematic, as they become indistinguishable for users with deuteranopia or protanopia.</p>\n<p>The accessibility issue extends beyond color blindness to include low-contrast combinations that become unreadable on different monitors or in bright lighting conditions. Poor color choices can make flame graphs effectively unusable for significant portions of the user base.</p>\n<p><strong>Fix:</strong> Use colorbrewer-style palettes designed for accessibility and data visualization. Implement multiple color scheme options including high-contrast modes. Provide alternative visual encoding through patterns or textures in addition to color. Test color schemes with accessibility simulation tools and actual users with color vision deficiencies.</p>\n<table>\n<thead>\n<tr>\n<th>Common Color Scheme Issues</th>\n<th>Problem</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Red-Green Combinations</td>\n<td>Invisible to ~8% of male users</td>\n<td>Use blue-orange or purple-green alternatives</td>\n</tr>\n<tr>\n<td>Low Contrast</td>\n<td>Unreadable in bright lighting</td>\n<td>Ensure 3:1 minimum contrast ratio</td>\n</tr>\n<tr>\n<td>Too Many Colors</td>\n<td>Cognitive overload, no meaning</td>\n<td>Limit to 8-12 distinct colors with clear categories</td>\n</tr>\n<tr>\n<td>Inconsistent Mapping</td>\n<td>Same function different colors</td>\n<td>Use deterministic color assignment algorithm</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Interactive Feature State Corruption</strong></p>\n<p>JavaScript state management in interactive flame graphs can become corrupted when users perform rapid interactions like multiple zoom operations or overlapping search queries. This leads to flame graphs stuck in incorrect zoom states or search highlights that don&#39;t clear properly.</p>\n<p>State corruption typically occurs when asynchronous operations overlap or when event handlers don&#39;t properly clean up previous state before applying new changes. Users may find themselves unable to reset the flame graph to its original state or encountering JavaScript errors that break interactivity.</p>\n<p><strong>Fix:</strong> Implement proper state management with explicit state transitions and cleanup procedures. Use debouncing for rapid user interactions. Provide explicit reset functionality that restores the flame graph to a known good state. Add error boundaries that gracefully handle JavaScript exceptions without breaking the entire visualization.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The flame graph generation component bridges the gap between aggregated profiling data and interactive visualizations that developers can use to understand program behavior. This section provides concrete implementation strategies and starter code for building robust flame graph generation.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SVG Generation</td>\n<td>String concatenation with templates</td>\n<td>XML library with proper escaping (xml.etree.ElementTree)</td>\n</tr>\n<tr>\n<td>Tree Aggregation</td>\n<td>Dictionary-based grouping</td>\n<td>Trie data structure with path compression</td>\n</tr>\n<tr>\n<td>Coordinate Math</td>\n<td>Direct calculation with floating point</td>\n<td>Fixed-point arithmetic for precision</td>\n</tr>\n<tr>\n<td>Color Schemes</td>\n<td>Hardcoded RGB values</td>\n<td>Colorbrewer palettes with accessibility support</td>\n</tr>\n<tr>\n<td>JavaScript Embedding</td>\n<td>Template strings with substitution</td>\n<td>Separate .js files with build-time inlining</td>\n</tr>\n<tr>\n<td>Output Format</td>\n<td>Single SVG file</td>\n<td>Multi-file bundle with CSS and JS separation</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>The flame graph generation component should be organized to separate aggregation logic, coordinate calculation, SVG generation, and interactive features:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n  flame_graph/\n    __init__.py                 ← public API exports\n    aggregator.py               ← stack folding and tree building logic\n    coordinates.py              ← pixel coordinate calculation\n    svg_generator.py            ← SVG element creation and formatting\n    interactive.py              ← JavaScript code for zoom/search features\n    color_schemes.py            ← predefined color palettes and assignment\n    templates/                  ← SVG and JavaScript template files\n      flame_graph_template.svg\n      interactive_features.js\n      default_styles.css\n    test/\n      test_aggregation.py       ← unit tests for tree building\n      test_coordinates.py       ← coordinate calculation tests\n      test_svg_generation.py    ← SVG output validation\n      sample_profiles.py        ← test data for integration tests</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Stack Aggregation Foundation</strong> (<code>aggregator.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FlameNode</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a single node in the flame graph tree.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    self_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    children: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'FlameNode'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    parent: Optional[</span><span style=\"color:#9ECBFF\">'FlameNode'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    depth: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.children </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.children </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_child</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, module: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'FlameNode'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add or get child node with given function name.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> name </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.children:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.children[name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FlameNode(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                function_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">name,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                sample_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                self_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                total_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                children</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                parent</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.depth </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                module_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">module</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.children[name]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_totals</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Recursively calculate total sample counts including children.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.total_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.self_count</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> child </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.children.values():</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.total_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> child.calculate_totals()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_count</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackAggregator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Converts individual stack samples into aggregated flame graph tree.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.root </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FlameNode(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            function_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"&#x3C;root>\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            sample_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            self_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            total_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            children</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            parent</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            module_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.folded_stacks: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_sample</span><span style=\"color:#E1E4E8\">(self, sample: </span><span style=\"color:#9ECBFF\">'Sample'</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process a single sample and add it to the aggregated tree.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Convert stack frames to folded stack signature</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signature </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._create_stack_signature(sample.stack_frames)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.folded_stacks[signature] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> sample.sample_weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Build tree path for this stack</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_node </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.root</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> frame </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> reversed</span><span style=\"color:#E1E4E8\">(sample.stack_frames):  </span><span style=\"color:#6A737D\"># Bottom-up traversal</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            child_node </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_node.add_child(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                frame.function_name, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                frame.module_name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            child_node.sample_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> sample.sample_weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_node </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> child_node</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Increment self count for leaf node</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_node.self_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> sample.sample_weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _create_stack_signature</span><span style=\"color:#E1E4E8\">(self, frames: List[</span><span style=\"color:#9ECBFF\">'StackFrame'</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create folded stack signature from stack frames.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle inlined frames by expanding them into signature</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add special prefixes for kernel frames</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use hex addresses for unresolved symbols</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_folded_output</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Export aggregated data in folded stack format.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lines </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> signature, count </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.folded_stacks.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lines.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">signature</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#79B8FF\"> {</span><span style=\"color:#E1E4E8\">count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">.join(lines)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> finalize</span><span style=\"color:#E1E4E8\">(self) -> FlameNode:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Complete aggregation and return root node with calculated totals.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.root.calculate_totals()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.root</span></span></code></pre></div>\n\n<p><strong>Color Scheme Management</strong> (<code>color_schemes.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ColorScheme</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Available color schemes for flame graph visualization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CATEGORY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"category\"</span><span style=\"color:#6A737D\">      # Color by function category (user/system/kernel)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MODULE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"module\"</span><span style=\"color:#6A737D\">          # Color by module/library</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HASH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"hash\"</span><span style=\"color:#6A737D\">             # Deterministic hash-based coloring</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HEAT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"heat\"</span><span style=\"color:#6A737D\">             # Hot/cold based on sample frequency</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ColorAssigner</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Assigns colors to flame graph nodes based on configured scheme.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Colorbrewer-inspired palettes optimized for accessibility</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CATEGORY_COLORS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"user\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"#1f77b4\"</span><span style=\"color:#E1E4E8\">,      </span><span style=\"color:#6A737D\"># Blue for user code</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"system\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"#ff7f0e\"</span><span style=\"color:#E1E4E8\">,    </span><span style=\"color:#6A737D\"># Orange for system libraries  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"kernel\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"#2ca02c\"</span><span style=\"color:#E1E4E8\">,    </span><span style=\"color:#6A737D\"># Green for kernel functions</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"jit\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"#d62728\"</span><span style=\"color:#E1E4E8\">,       </span><span style=\"color:#6A737D\"># Red for JIT compiled code</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"unknown\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"#9467bd\"</span><span style=\"color:#6A737D\">    # Purple for unresolved symbols</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MODULE_PALETTE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"#1f77b4\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#ff7f0e\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#2ca02c\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#d62728\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#9467bd\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"#8c564b\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#e377c2\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#7f7f7f\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#bcbd22\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"#17becf\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, scheme: ColorScheme </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ColorScheme.</span><span style=\"color:#79B8FF\">CATEGORY</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.scheme </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> scheme</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.module_colors: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.color_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_color</span><span style=\"color:#E1E4E8\">(self, node: FlameNode) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get color for flame graph node based on current scheme.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.scheme </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ColorScheme.</span><span style=\"color:#79B8FF\">CATEGORY</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_category_color(node)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.scheme </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ColorScheme.</span><span style=\"color:#79B8FF\">MODULE</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_module_color(node.module_name)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.scheme </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ColorScheme.</span><span style=\"color:#79B8FF\">HASH</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._get_hash_color(node.function_name)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> \"#1f77b4\"</span><span style=\"color:#6A737D\">  # Default blue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_category_color</span><span style=\"color:#E1E4E8\">(self, node: FlameNode) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Determine color based on function category.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement category detection logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for kernel function patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify system library vs user code</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_module_color</span><span style=\"color:#E1E4E8\">(self, module_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Assign consistent color per module.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> module_name </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.module_colors:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            color </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">MODULE_PALETTE</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.color_index </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">MODULE_PALETTE</span><span style=\"color:#E1E4E8\">)]</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.module_colors[module_name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> color</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.color_index </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.module_colors[module_name]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _get_hash_color</span><span style=\"color:#E1E4E8\">(self, function_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate deterministic color from function name hash.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        hash_value </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(hashlib.md5(function_name.encode()).hexdigest()[:</span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        hue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> hash_value </span><span style=\"color:#F97583\">%</span><span style=\"color:#79B8FF\"> 360</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._hsl_to_hex(hue, </span><span style=\"color:#79B8FF\">70</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Fixed saturation and lightness</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _hsl_to_hex</span><span style=\"color:#E1E4E8\">(self, h: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, s: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, l: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert HSL color values to hex string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement HSL to RGB conversion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Format as hex color string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Coordinate Calculation Engine</strong> (<code>coordinates.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Rectangle</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a flame graph rectangle with pixel coordinates.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    x: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    y: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    width: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    height: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    node: FlameNode</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    color: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    text_x: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    text_y: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CoordinateCalculator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Calculates pixel coordinates for flame graph rectangles.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, viewport_width: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, viewport_height: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 rectangle_height: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 18</span><span style=\"color:#E1E4E8\">, min_width: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.5</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.viewport_width </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> viewport_width</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.viewport_height </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> viewport_height</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rectangle_height </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rectangle_height</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.min_width </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> min_width</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_coordinates</span><span style=\"color:#E1E4E8\">(self, root: FlameNode) -> List[Rectangle]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate pixel coordinates for all flame graph rectangles.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        rectangles </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate root node has calculated totals</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate scaling factor from samples to pixels</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Perform recursive traversal starting from root</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For each node, calculate x position within parent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate width based on sample proportion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Skip nodes below minimum width threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Calculate text positioning within rectangle</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Add rectangle to output list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use depth-first traversal to maintain proper ordering</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> rectangles</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _calculate_node_coordinates</span><span style=\"color:#E1E4E8\">(self, node: FlameNode, parent_x: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  parent_width: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  total_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Rectangle:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate coordinates for a single node.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate proportional width based on sample count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Determine x position within parent bounds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate y position from depth and rectangle height</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle text positioning and truncation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return Rectangle with calculated coordinates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _calculate_children_layout</span><span style=\"color:#E1E4E8\">(self, node: FlameNode, node_x: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 node_width: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, total_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Tuple[FlameNode, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate layout positions for all children of a node.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Sort children by sample count (largest first)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate cumulative x positions for children</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Distribute any rounding error to rightmost child</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return list of (child_node, x_position, width) tuples</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>SVG Generation Framework</strong> (<code>svg_generator.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, TextIO</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> xml.etree.ElementTree </span><span style=\"color:#F97583\">as</span><span style=\"color:#79B8FF\"> ET</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SVGFlameGraphGenerator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generates interactive SVG flame graph from rectangle coordinates.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: VisualizationConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.svg_width </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1200</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.svg_height </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 800</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_svg</span><span style=\"color:#E1E4E8\">(self, rectangles: List[Rectangle], output_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate complete SVG flame graph file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create root SVG element with viewBox and dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add CSS styles for rectangles, text, and interactions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate rectangle and text elements for each flame node</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Embed JavaScript code for zoom and search functionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add search UI elements (search box, reset button)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Write complete SVG document to file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use xml.etree.ElementTree for proper XML generation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _create_rectangle_group</span><span style=\"color:#E1E4E8\">(self, rect: Rectangle) -> </span><span style=\"color:#79B8FF\">ET</span><span style=\"color:#E1E4E8\">.Element:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create SVG group containing rectangle and text elements.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create &#x3C;g> group element with data attributes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add &#x3C;rect> element with coordinates and styling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add &#x3C;text> element with function name and positioning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Include tooltip title element for hover information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return completed group element</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _embed_interactive_features</span><span style=\"color:#E1E4E8\">(self, root_svg: </span><span style=\"color:#79B8FF\">ET</span><span style=\"color:#E1E4E8\">.Element) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add JavaScript code for zoom, search, and tooltip functionality.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create &#x3C;script> element with JavaScript code</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add event listeners for rectangle clicks (zoom)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Implement search highlighting functionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add tooltip positioning and content logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Include reset zoom functionality</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_css_styles</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate CSS styles for flame graph elements.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        &#x3C;style></span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        .flame-rect {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            stroke: #000;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            stroke-width: 0.5px;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            cursor: pointer;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        }</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        .flame-text {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            font-family: Verdana, sans-serif;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            font-size: 12px;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            text-anchor: middle;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            dominant-baseline: central;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            pointer-events: none;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        }</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        .flame-rect:hover {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            stroke: #00f;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            stroke-width: 1px;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        }</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        .search-highlight {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            stroke: #ff0;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            stroke-width: 2px;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        }</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        &#x3C;/style></span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the flame graph generation component, verify correct functionality with these checkpoints:</p>\n<p><strong>Aggregation Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> profiler/flame_graph/test/test_aggregation.py</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected behavior: All aggregation tests pass, including edge cases like empty stacks, single-frame stacks, and deeply nested call chains. The folded stack output should match expected format with correct sample counts.</p>\n<p><strong>Coordinate Calculation Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from profiler.flame_graph.coordinates import CoordinateCalculator</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from profiler.flame_graph.aggregator import FlameNode</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Create simple test tree and verify coordinate calculation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">calc = CoordinateCalculator(1000, 600)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Should produce rectangles with correct proportional widths</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>SVG Generation Validation:</strong></p>\n<ol>\n<li>Generate a flame graph from sample profile data</li>\n<li>Open the resulting SVG file in a web browser</li>\n<li>Verify rectangles display correctly with proportional widths</li>\n<li>Test zoom functionality by clicking on rectangles</li>\n<li>Test search functionality with known function names</li>\n<li>Verify tooltip information appears on hover</li>\n</ol>\n<p><strong>Manual Integration Test:</strong>\nCreate a simple test program with known call patterns, profile it with your stack sampler, and generate a flame graph. The resulting visualization should clearly show the expected call relationships and sample distributions.</p>\n<p>Signs of correct implementation:</p>\n<ul>\n<li>Rectangle widths accurately represent sample proportions</li>\n<li>Function names appear centered and readable</li>\n<li>Zoom operations correctly recalculate coordinates</li>\n<li>Search highlighting works for partial name matches</li>\n<li>Color scheme appropriately distinguishes function categories</li>\n</ul>\n<p>Common signs of problems:</p>\n<ul>\n<li>Visual gaps between rectangles (width calculation errors)</li>\n<li>Overlapping rectangles (coordinate calculation bugs)</li>\n<li>Missing or garbled text (SVG text positioning issues)</li>\n<li>Broken interactivity (JavaScript errors in console)</li>\n<li>Inconsistent colors for same functions (color assignment problems)</li>\n</ul>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fflame-graph-generation.svg\" alt=\"Flame Graph Generation Pipeline\"></p>\n<h2 id=\"memory-profiling-component\">Memory Profiling Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 4 — Memory Profiling: Track heap allocations and detect memory leaks using function interposition to identify allocation patterns, heavy allocation sites, and leaked memory</p>\n</blockquote>\n<h3 id=\"mental-model-library-book-checkout\">Mental Model: Library Book Checkout</h3>\n<p>Think of memory allocation tracking like a library&#39;s book checkout system. When patrons (code) want to borrow books (memory), they must register with the librarian (allocation interceptor) who records their name (call stack), the book title (allocation size), and checkout time (timestamp). The librarian maintains a detailed ledger (allocation metadata) of who has what books and when they took them.</p>\n<p>Just as a library can identify overdue books by comparing checkout records against returns, memory leak detection works by tracking allocations without corresponding free operations. The library knows books are missing when they don&#39;t appear in returned stacks after a reasonable time. Similarly, the profiler identifies memory leaks by finding allocations that persist throughout program execution without being freed.</p>\n<p>The librarian also notices patterns: certain patrons (functions) consistently check out many books (heavy allocators), some subjects are more popular (allocation hot spots), and some books never get returned (definite leaks). This systematic tracking transforms chaotic borrowing activity into actionable insights about library usage, just as allocation tracking reveals memory usage patterns in running programs.</p>\n<p>Memory profiling faces the unique challenge of intercepting every allocation and deallocation in a running program while maintaining comprehensive metadata about each operation. Unlike stack sampling which observes execution state periodically, allocation tracking must capture every memory operation to provide complete coverage for leak detection and allocation analysis.</p>\n<h3 id=\"allocation-function-interposition\">Allocation Function Interposition</h3>\n<p><strong>Function interposition</strong> provides the mechanism to intercept calls to memory allocation functions like <code>malloc</code>, <code>calloc</code>, <code>realloc</code>, and <code>free</code>. The profiler inserts itself between application code and the standard library&#39;s memory management functions, creating an opportunity to record allocation metadata before delegating to the real allocation functions.</p>\n<p>The interposition layer acts as a transparent proxy that preserves the exact semantics of the original allocation functions while adding profiling instrumentation. When application code calls <code>malloc(1024)</code>, the interposed version captures the call stack, records allocation metadata, calls the real <code>malloc</code>, stores tracking information keyed by the returned pointer, and returns the allocated address to the application.</p>\n<p><strong>Allocation tracking metadata</strong> requires careful design to balance completeness against overhead. Each <code>Allocation</code> record contains essential information for leak detection and performance analysis:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>allocation_id</td>\n<td>int</td>\n<td>Unique identifier for this allocation</td>\n</tr>\n<tr>\n<td>size</td>\n<td>int</td>\n<td>Requested allocation size in bytes</td>\n</tr>\n<tr>\n<td>actual_size</td>\n<td>int</td>\n<td>Actual allocated size (may include alignment padding)</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>float</td>\n<td>Time when allocation occurred</td>\n</tr>\n<tr>\n<td>thread_id</td>\n<td>int</td>\n<td>Thread that performed the allocation</td>\n</tr>\n<tr>\n<td>allocation_stack</td>\n<td>List[StackFrame]</td>\n<td>Call stack at allocation site</td>\n</tr>\n<tr>\n<td>allocation_type</td>\n<td>AllocationType</td>\n<td>malloc, calloc, realloc, new, etc.</td>\n</tr>\n<tr>\n<td>is_freed</td>\n<td>bool</td>\n<td>Whether this allocation has been freed</td>\n</tr>\n<tr>\n<td>free_timestamp</td>\n<td>float</td>\n<td>Time when allocation was freed (if applicable)</td>\n</tr>\n<tr>\n<td>free_thread_id</td>\n<td>int</td>\n<td>Thread that performed the free (if applicable)</td>\n</tr>\n</tbody></table>\n<p><strong>Stack trace capture at allocation sites</strong> provides the crucial context needed to identify where memory is being allocated in the source code. Unlike stack sampling which captures arbitrary execution points, allocation stack traces always represent meaningful code locations where memory allocation decisions occurred. The profiler must unwind the call stack synchronously during each allocation call, capturing the complete calling context from the allocation site back to the program entry point.</p>\n<p>The allocation stack trace serves multiple analysis purposes: identifying allocation hot spots (functions that allocate large amounts of memory), understanding allocation call patterns (which high-level operations trigger many allocations), and providing debugging context for memory leaks (the exact code path that allocated leaked memory).</p>\n<p><strong>Allocation site aggregation</strong> groups individual allocations by their call stack signature to identify patterns in memory usage. An <code>AllocationSite</code> represents all allocations that occurred from the same calling context:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>call_stack_hash</td>\n<td>int</td>\n<td>Hash of the call stack for grouping</td>\n</tr>\n<tr>\n<td>representative_stack</td>\n<td>List[StackFrame]</td>\n<td>Example call stack for this site</td>\n</tr>\n<tr>\n<td>total_allocations</td>\n<td>int</td>\n<td>Number of allocations from this site</td>\n</tr>\n<tr>\n<td>total_bytes</td>\n<td>int</td>\n<td>Total bytes allocated from this site</td>\n</tr>\n<tr>\n<td>peak_live_bytes</td>\n<td>int</td>\n<td>Maximum bytes live simultaneously</td>\n</tr>\n<tr>\n<td>peak_live_count</td>\n<td>int</td>\n<td>Maximum allocations live simultaneously</td>\n</tr>\n<tr>\n<td>lifetime_distribution</td>\n<td>List[int]</td>\n<td>Histogram of allocation lifetimes</td>\n</tr>\n<tr>\n<td>first_seen</td>\n<td>float</td>\n<td>Time of first allocation from this site</td>\n</tr>\n<tr>\n<td>last_seen</td>\n<td>float</td>\n<td>Time of most recent allocation from this site</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: LD_PRELOAD vs Link-Time Interposition</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple mechanisms exist for intercepting allocation functions, each with different implementation complexity and runtime characteristics</li>\n<li><strong>Options Considered</strong>: LD_PRELOAD dynamic interposition, link-time symbol interposition, binary rewriting, compile-time instrumentation</li>\n<li><strong>Decision</strong>: Use LD_PRELOAD for primary interposition with fallback detection for static linking</li>\n<li><strong>Rationale</strong>: LD_PRELOAD provides transparent interposition without requiring recompilation, works with existing binaries, and allows profiling arbitrary processes. Link-time approaches require build system integration and source access.</li>\n<li><strong>Consequences</strong>: Some allocations in static constructors or early initialization may be missed, requires shared library implementation, limited effectiveness with statically linked binaries</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Interposition Method</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>LD_PRELOAD</td>\n<td>Works with existing binaries, no recompilation</td>\n<td>Misses static constructors, library loading order issues</td>\n<td>General purpose profiling</td>\n</tr>\n<tr>\n<td>Link-time symbols</td>\n<td>Catches all allocations, reliable ordering</td>\n<td>Requires build integration, source access needed</td>\n<td>Development-time profiling</td>\n</tr>\n<tr>\n<td>Binary rewriting</td>\n<td>Complete coverage, works post-build</td>\n<td>Complex implementation, architecture specific</td>\n<td>Specialized analysis tools</td>\n</tr>\n</tbody></table>\n<p><strong>Memory allocation flame graphs</strong> extend the flame graph visualization concept to show memory allocation patterns rather than CPU sampling. Instead of displaying which functions consume CPU time most frequently, allocation flame graphs show which call paths allocate the most memory. The width of each flame graph segment represents the total bytes allocated from that calling context, enabling developers to quickly identify memory-intensive code paths.</p>\n<p>The allocation flame graph aggregates <code>AllocationSite</code> data using the same hierarchical folding algorithm as CPU flame graphs, but weights each call stack by <code>total_bytes</code> rather than sample count. This visualization reveals allocation patterns that complement CPU profiling: functions may allocate substantial memory without consuming significant CPU time, or brief CPU spikes may trigger large allocation bursts.</p>\n<h3 id=\"memory-leak-detection\">Memory Leak Detection</h3>\n<p><strong>Memory leak identification</strong> requires distinguishing between legitimate long-lived allocations and genuine leaks where memory is allocated but never freed. The profiler maintains a live allocation set containing all allocations that have not yet been freed, tracking their age and allocation context to classify potential leaks.</p>\n<p>Leak detection operates on several principles: allocations that persist for extended periods without being freed may indicate leaks, allocations from the same call site that accumulate without corresponding frees suggest systematic leaks, and allocations that grow without bound over time indicate unbounded memory growth patterns.</p>\n<p><strong>Leak confidence scoring</strong> addresses the fundamental challenge that not all long-lived allocations represent bugs. Global data structures, caches, and configuration objects may legitimately persist throughout program execution. The <code>MemoryLeak</code> structure includes confidence scoring to help developers prioritize investigation:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>allocation</td>\n<td>Allocation</td>\n<td>The potentially leaked allocation</td>\n</tr>\n<tr>\n<td>leak_confidence</td>\n<td>float</td>\n<td>Confidence score from 0.0 to 1.0</td>\n</tr>\n<tr>\n<td>leak_category</td>\n<td>LeakCategory</td>\n<td>Classification of leak type</td>\n</tr>\n<tr>\n<td>allocation_age</td>\n<td>float</td>\n<td>How long allocation has been live</td>\n</tr>\n<tr>\n<td>similar_leaks</td>\n<td>int</td>\n<td>Count of similar allocations from same site</td>\n</tr>\n<tr>\n<td>total_leaked_bytes</td>\n<td>int</td>\n<td>Total bytes from this leak site</td>\n</tr>\n<tr>\n<td>detection_method</td>\n<td>str</td>\n<td>Which heuristic identified this leak</td>\n</tr>\n<tr>\n<td>suppression_matched</td>\n<td>str</td>\n<td>Suppression rule that matched (if any)</td>\n</tr>\n</tbody></table>\n<p><strong>Leak categorization</strong> helps developers understand different types of memory problems. <code>LeakCategory</code> distinguishes between definite leaks (allocations with no remaining references), possible leaks (allocations with questionable reference patterns), reachable leaks (allocations still referenced but logically leaked), and growth patterns (accumulating allocations suggesting unbounded growth).</p>\n<blockquote>\n<p><strong>Decision: Leak Detection Heuristics vs Reference Tracking</strong></p>\n<ul>\n<li><strong>Context</strong>: Different approaches exist for identifying memory leaks, ranging from simple time-based heuristics to comprehensive reference graph analysis</li>\n<li><strong>Options Considered</strong>: Age-based heuristics, reference counting, mark-and-sweep analysis, static analysis integration</li>\n<li><strong>Decision</strong>: Implement age-based and growth-pattern heuristics with optional reference tracking</li>\n<li><strong>Rationale</strong>: Heuristics provide good coverage with minimal overhead, while full reference tracking requires significant complexity and memory overhead. Many real leaks exhibit clear temporal patterns.</li>\n<li><strong>Consequences</strong>: Some false positives from long-lived legitimate allocations, requires manual tuning of age thresholds, may miss complex reference cycle leaks</li>\n</ul>\n</blockquote>\n<p><strong>Memory usage timeline tracking</strong> captures heap behavior over time through periodic <code>MemorySnapshot</code> recordings. These snapshots provide insight into allocation patterns, memory growth trends, and correlation between program phases and memory usage:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>timestamp</td>\n<td>float</td>\n<td>When this snapshot was captured</td>\n</tr>\n<tr>\n<td>total_allocated</td>\n<td>int</td>\n<td>Cumulative bytes allocated since start</td>\n</tr>\n<tr>\n<td>total_freed</td>\n<td>int</td>\n<td>Cumulative bytes freed since start</td>\n</tr>\n<tr>\n<td>live_bytes</td>\n<td>int</td>\n<td>Currently allocated bytes (total - freed)</td>\n</tr>\n<tr>\n<td>live_allocations</td>\n<td>int</td>\n<td>Number of allocations currently active</td>\n</tr>\n<tr>\n<td>heap_size</td>\n<td>int</td>\n<td>Total heap size from OS perspective</td>\n</tr>\n<tr>\n<td>allocation_rate</td>\n<td>float</td>\n<td>Recent allocation rate in bytes per second</td>\n</tr>\n<tr>\n<td>free_rate</td>\n<td>float</td>\n<td>Recent deallocation rate in bytes per second</td>\n</tr>\n</tbody></table>\n<p>Timeline analysis reveals memory usage patterns that single-point measurements cannot capture: steady memory growth indicating leaks, periodic allocation spikes corresponding to specific operations, memory fragmentation through heap size versus live bytes comparison, and allocation rate imbalances where allocation consistently exceeds deallocation.</p>\n<p><strong>Suppression and filtering</strong> mechanisms help focus leak detection on actionable issues by filtering out known false positives and expected long-lived allocations. Suppression rules match allocation call stacks against patterns, allowing developers to mark specific allocation sites as expected long-lived allocations.</p>\n<p>Suppression configuration supports call stack pattern matching, allocation size thresholds, and lifetime exemptions. For example, a suppression rule might ignore allocations from <code>initialize_global_config()</code> that exceed 24 hours in lifetime, or filter out allocations smaller than 64 bytes that persist longer than program startup phase.</p>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<blockquote>\n<p><strong>Decision: Allocation Metadata Storage Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Profiler must maintain metadata for every live allocation, potentially millions of records, requiring efficient storage and lookup</li>\n<li><strong>Options Considered</strong>: Hash table with pointer keys, red-black tree sorted by address, separate metadata heap, embedded metadata in allocation headers</li>\n<li><strong>Decision</strong>: Hash table with allocation pointer as key, separate metadata heap for allocation records</li>\n<li><strong>Rationale</strong>: Hash table provides O(1) lookup performance for malloc/free operations, separate heap prevents metadata corruption from application bugs, pointer keys enable direct lookup without address translation</li>\n<li><strong>Consequences</strong>: Additional memory overhead for hash table and metadata heap, potential hash collisions requiring collision handling, metadata heap fragmentation over time</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Storage Strategy</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Memory Overhead</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash table</td>\n<td>O(1) lookup, simple implementation</td>\n<td>Hash collisions, memory overhead</td>\n<td>~200% for metadata</td>\n</tr>\n<tr>\n<td>Red-black tree</td>\n<td>Sorted iteration, predictable performance</td>\n<td>O(log n) lookup, complex balancing</td>\n<td>~150% for metadata</td>\n</tr>\n<tr>\n<td>Embedded headers</td>\n<td>Low overhead, cache locality</td>\n<td>Corrupted by application bugs</td>\n<td>~10% for headers</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Thread Safety in Allocation Tracking</strong></p>\n<ul>\n<li><strong>Context</strong>: Multi-threaded programs allocate memory concurrently, requiring thread-safe metadata management without introducing contention or deadlocks</li>\n<li><strong>Options Considered</strong>: Global mutex for all operations, per-thread allocation tables, lock-free hash table, thread-local buffering with periodic merging</li>\n<li><strong>Decision</strong>: Thread-local allocation tables with global merger thread for aggregation</li>\n<li><strong>Rationale</strong>: Thread-local tables eliminate contention during allocation/free operations while preserving global view through periodic merging. Avoids deadlocks in signal handlers and recursive allocation scenarios.</li>\n<li><strong>Consequences</strong>: Delayed visibility of allocations across threads, memory overhead for per-thread tables, complexity in merger thread synchronization</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Handling Recursive Allocation Calls</strong></p>\n<ul>\n<li><strong>Context</strong>: Allocation tracking code itself may trigger memory allocations (stack unwinding, metadata storage), creating infinite recursion if not handled carefully</li>\n<li><strong>Options Considered</strong>: Thread-local recursion flag, pre-allocated metadata buffers, async-safe allocation tracking, allocation call filtering</li>\n<li><strong>Decision</strong>: Thread-local recursion detection with pre-allocated emergency buffers</li>\n<li><strong>Rationale</strong>: Recursion flag prevents infinite loops, emergency buffers ensure tracking continues even when normal allocation fails, maintains complete allocation coverage</li>\n<li><strong>Consequences</strong>: Small overhead for recursion checking on every allocation, limited capacity in emergency scenarios, potential metadata loss under extreme memory pressure</li>\n</ul>\n</blockquote>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Recursive malloc calls during stack unwinding</strong></p>\n<p>The most dangerous pitfall in allocation interception occurs when the stack unwinding code itself triggers memory allocations, creating infinite recursion. This happens because stack unwinding may need to allocate memory for symbol resolution, debug information parsing, or internal data structures, which triggers the interposed malloc, which attempts stack unwinding, creating a cycle.</p>\n<p>The problem manifests as stack overflow crashes or hanging programs when profiling begins. Developers often miss this because the recursion only occurs during profiling, not during normal program execution. The issue is particularly subtle because it may only happen for specific allocation sites or under certain conditions.</p>\n<p><strong>Solution</strong>: Implement thread-local recursion detection using a simple boolean flag. When entering the allocation interceptor, check if the current thread is already processing an allocation. If so, delegate directly to the real malloc without any tracking. Use pre-allocated buffers for essential stack unwinding operations to avoid allocation dependencies.</p>\n<p>⚠️ <strong>Pitfall: Thread safety violations in metadata management</strong></p>\n<p>Multi-threaded programs create complex synchronization challenges for allocation tracking. The common mistake is using inadequate synchronization (like simple mutexes) which leads to deadlocks when malloc is called from signal handlers, during library loading, or from within other locked code sections. Global mutex protection can also create severe contention bottlenecks.</p>\n<p>Symptoms include programs hanging during initialization, deadlocks under memory pressure, or metadata corruption in multi-threaded scenarios. These issues are particularly hard to debug because they may only occur under specific timing conditions or high thread contention.</p>\n<p><strong>Solution</strong>: Use thread-local allocation tracking tables that require no synchronization during allocation/free operations. Implement a separate merger thread that periodically collects and aggregates data from all thread-local tables using lock-free or carefully ordered synchronization. Ensure all metadata operations are async-safe for signal handler compatibility.</p>\n<p>⚠️ <strong>Pitfall: Excessive memory overhead from tracking metadata</strong></p>\n<p>Allocation tracking can consume substantial memory overhead, sometimes exceeding the memory usage of the application being profiled. This occurs when the tracking metadata (call stacks, timestamps, allocation records) requires more space than the tracked allocations themselves, especially for programs with many small allocations.</p>\n<p>The problem is particularly severe for applications that make millions of small allocations, where each 16-byte allocation might require 200+ bytes of tracking metadata. This can lead to out-of-memory conditions or severely degraded performance due to increased memory pressure.</p>\n<p><strong>Solution</strong>: Implement sampling for small allocations (track every Nth allocation under certain size thresholds), use memory-efficient data structures for metadata storage, and provide configurable limits on metadata memory usage. Consider aggregating very small allocations by call site rather than tracking individually.</p>\n<p>⚠️ <strong>Pitfall: Missing allocations from static constructors and early initialization</strong></p>\n<p>LD_PRELOAD interposition misses allocations that occur during static constructor execution or early program initialization, before the preloaded library is fully initialized. This happens because static constructors run before main() and potentially before the profiler can set up its interception hooks.</p>\n<p>The result is incomplete allocation tracking that misses some allocations but sees their corresponding free operations, leading to negative allocation counts or false leak reports. This is particularly problematic for C++ programs with extensive static initialization.</p>\n<p><strong>Solution</strong>: Implement early initialization detection and delayed tracking startup. Use library constructor attributes to initialize profiling as early as possible. Consider alternative interposition methods (like link-time interposition) for comprehensive coverage when needed.</p>\n<p>⚠️ <strong>Pitfall: Incorrect leak classification of legitimate long-lived allocations</strong></p>\n<p>Memory leak detection often generates false positives by flagging legitimate long-lived allocations as potential leaks. Global configuration objects, cached data, and persistent data structures are not leaks even if they persist throughout program execution. Poor leak classification creates noise that obscures real memory problems.</p>\n<p>This manifests as leak reports for allocations that are intentionally never freed, such as program configuration, static lookup tables, or singleton objects. Developers waste time investigating these false positives instead of focusing on genuine memory leaks.</p>\n<p><strong>Solution</strong>: Implement sophisticated leak classification using allocation patterns, call stack analysis, and configurable suppression rules. Allow developers to mark specific allocation sites or call stack patterns as expected long-lived allocations. Use growth-based detection rather than purely time-based heuristics.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Function Interposition</td>\n<td>LD_PRELOAD with dlsym symbol resolution</td>\n<td>Binary rewriting with Intel Pin or DynamoRIO</td>\n</tr>\n<tr>\n<td>Metadata Storage</td>\n<td>Python dictionary with allocation pointer keys</td>\n<td>Custom hash table with memory pool allocation</td>\n</tr>\n<tr>\n<td>Stack Unwinding</td>\n<td>Python traceback module (limited accuracy)</td>\n<td>libunwind for precise native stack traces</td>\n</tr>\n<tr>\n<td>Memory Tracking</td>\n<td>Simple allocation/free counter</td>\n<td>Full allocation site analysis with lifetime histograms</td>\n</tr>\n<tr>\n<td>Leak Detection</td>\n<td>Age-based heuristics with configurable thresholds</td>\n<td>Reference graph analysis with mark-and-sweep</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n  memory/\n    __init__.py                    ← main memory profiler interface\n    interceptor.py                 ← allocation function interposition\n    tracker.py                     ← allocation metadata management\n    leak_detector.py               ← memory leak identification\n    allocation_sites.py            ← allocation site aggregation\n    memory_flame.py                ← memory allocation flame graphs\n    native_interceptor.c           ← C extension for LD_PRELOAD\n    malloc_intercept.so            ← compiled interposition library\n  tests/\n    test_memory_profiling.py       ← memory profiler test suite\n    test_programs/\n      leaky_program.c              ← test program with intentional leaks\n      allocation_heavy.py          ← Python program with allocation patterns</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete LD_PRELOAD allocation interceptor</strong> (native_interceptor.c):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> _GNU_SOURCE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;dlfcn.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/types.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;pthread.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;execinfo.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Function pointers to real allocation functions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">real_malloc)(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">real_free)(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">real_realloc)(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">real_calloc)(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Thread-local recursion detection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#E1E4E8\"> __thread </span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> in_malloc_hook </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize real function pointers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> init_hooks</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (real_malloc) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    real_malloc </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> dlsym</span><span style=\"color:#E1E4E8\">(RTLD_NEXT, </span><span style=\"color:#9ECBFF\">\"malloc\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    real_free </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> dlsym</span><span style=\"color:#E1E4E8\">(RTLD_NEXT, </span><span style=\"color:#9ECBFF\">\"free\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    real_realloc </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> dlsym</span><span style=\"color:#E1E4E8\">(RTLD_NEXT, </span><span style=\"color:#9ECBFF\">\"realloc\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    real_calloc </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> dlsym</span><span style=\"color:#E1E4E8\">(RTLD_NEXT, </span><span style=\"color:#9ECBFF\">\"calloc\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">real_malloc </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">real_free </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">real_realloc </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">real_calloc) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        fprintf</span><span style=\"color:#E1E4E8\">(stderr, </span><span style=\"color:#9ECBFF\">\"Error: failed to load real allocation functions</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        exit</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Capture call stack (simplified version)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#B392F0\"> capture_backtrace</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void**</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> max_frames</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> backtrace</span><span style=\"color:#E1E4E8\">(buffer, max_frames);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Send allocation info to Python profiler via named pipe or shared memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> record_allocation</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> ptr</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void**</span><span style=\"color:#FFAB70\"> backtrace</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> frame_count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement communication with Python profiler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Could use named pipe, shared memory, or direct Python C API calls</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> record_deallocation</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> ptr</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Implement deallocation recording</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Malloc interceptor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    init_hooks</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Prevent recursion during stack capture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (in_malloc_hook) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#B392F0\"> real_malloc</span><span style=\"color:#E1E4E8\">(size);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Call real malloc first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void*</span><span style=\"color:#E1E4E8\"> result </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> real_malloc</span><span style=\"color:#E1E4E8\">(size);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Record allocation with stack trace</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (result) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        in_malloc_hook </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        void*</span><span style=\"color:#FFAB70\"> backtrace_buffer</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> frame_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> capture_backtrace</span><span style=\"color:#E1E4E8\">(backtrace_buffer, </span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        record_allocation</span><span style=\"color:#E1E4E8\">(result, size, backtrace_buffer, frame_count);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        in_malloc_hook </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> result;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free interceptor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> free</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> ptr</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    init_hooks</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (ptr </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">in_malloc_hook) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        in_malloc_hook </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        record_deallocation</span><span style=\"color:#E1E4E8\">(ptr);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        in_malloc_hook </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    real_free</span><span style=\"color:#E1E4E8\">(ptr);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Similar interceptors for realloc and calloc...</span></span></code></pre></div>\n\n<p><strong>Complete Python metadata tracker</strong> (tracker.py):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> weakref</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Allocation</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    actual_size: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_stack: List[</span><span style=\"color:#9ECBFF\">'StackFrame'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_type: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_freed: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_lifetime</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate allocation lifetime in seconds\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_freed:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.free_timestamp </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_long_lived</span><span style=\"color:#E1E4E8\">(self, threshold_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if allocation exceeds lifetime threshold\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.get_lifetime() </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> threshold_seconds</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationSite</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    call_stack_hash: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    representative_stack: List[</span><span style=\"color:#9ECBFF\">'StackFrame'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_allocations: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    peak_live_bytes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    peak_live_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lifetime_distribution: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    first_seen: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_seen: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_allocation</span><span style=\"color:#E1E4E8\">(self, allocation: Allocation) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update allocation site statistics with new allocation\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.total_allocations </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.total_bytes </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> allocation.size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.last_seen </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> allocation.timestamp</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.first_seen </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.first_seen </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> allocation.timestamp</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_average_size</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate average allocation size from site\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_allocations </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_bytes </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.total_allocations</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationTracker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._live_allocations: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Allocation] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}  </span><span style=\"color:#6A737D\"># ptr -> Allocation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._allocation_sites: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, AllocationSite] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}  </span><span style=\"color:#6A737D\"># hash -> site</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._allocation_counter </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._thread_local </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.local()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_allocation</span><span style=\"color:#E1E4E8\">(self, ptr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, stack_frames: List[</span><span style=\"color:#9ECBFF\">'StackFrame'</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record a new allocation\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate unique allocation ID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create Allocation object with current timestamp and thread ID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate stack hash for allocation site grouping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update or create AllocationSite for this stack</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Store allocation in live allocations dict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update allocation site statistics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_deallocation</span><span style=\"color:#E1E4E8\">(self, ptr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record a deallocation\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Look up allocation by pointer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Mark allocation as freed with timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update allocation site statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Remove from live allocations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_live_allocations</span><span style=\"color:#E1E4E8\">(self) -> List[Allocation]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get all currently live allocations\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._live_allocations.values())</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_allocation_sites</span><span style=\"color:#E1E4E8\">(self) -> List[AllocationSite]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get all allocation sites sorted by total bytes\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sites </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._allocation_sites.values())</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(sites, </span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\"> s: s.total_bytes, </span><span style=\"color:#FFAB70\">reverse</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Memory leak detector</strong> (leak_detector.py):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LeakCategory</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEFINITE_LEAK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"definite\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    POSSIBLE_LEAK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"possible\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    REACHABLE_LEAK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"reachable\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    GROWTH_PATTERN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"growth\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MemoryLeak</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation: Allocation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    leak_confidence: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    leak_category: LeakCategory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_age: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    similar_leaks: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_leaked_bytes: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    detection_method: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    suppression_matched: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LeakDetector</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, age_threshold: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 300.0</span><span style=\"color:#E1E4E8\">, growth_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.age_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> age_threshold</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.growth_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> growth_threshold</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.suppression_rules: List[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_leaks</span><span style=\"color:#E1E4E8\">(self, live_allocations: List[Allocation], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     allocation_sites: List[AllocationSite]) -> List[MemoryLeak]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect memory leaks from live allocations and sites\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Identify age-based potential leaks (allocations older than threshold)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Group similar leaks by call stack hash  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate confidence scores based on allocation patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Identify growth patterns from allocation sites</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Apply suppression rules to filter false positives</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Classify leaks by category (definite, possible, reachable)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Sort leaks by confidence and total leaked bytes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> analyze_growth_patterns</span><span style=\"color:#E1E4E8\">(self, sites: List[AllocationSite]) -> List[MemoryLeak]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Identify allocation sites showing unbounded growth\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Find sites with high allocation rate and low free rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate growth velocity over time windows</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify sites exceeding growth thresholds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create MemoryLeak entries for growth patterns</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_leak_confidence</span><span style=\"color:#E1E4E8\">(self, allocation: Allocation, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  similar_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate confidence score for potential leak\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Factor in allocation age (older = higher confidence)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Consider number of similar unfree'd allocations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Analyze allocation call stack for leak-prone patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Account for allocation size (larger = higher impact)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return confidence score between 0.0 and 1.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing allocation interception and basic tracking:</p>\n<ol>\n<li><p><strong>Compile the LD_PRELOAD library</strong>: <code>gcc -shared -fPIC native_interceptor.c -o malloc_intercept.so -ldl</code></p>\n</li>\n<li><p><strong>Test with a simple program</strong>:</p>\n</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">   LD_PRELOAD</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">./malloc_intercept.so</span><span style=\"color:#B392F0\"> ./test_program</span></span></code></pre></div>\n\n<ol start=\"3\">\n<li><p><strong>Expected behavior</strong>: The program should run normally but with allocation/deallocation events being recorded. You should see allocation tracking output or be able to query live allocations.</p>\n</li>\n<li><p><strong>Verification steps</strong>:</p>\n<ul>\n<li>Confirm no crashes or hangs during program execution</li>\n<li>Verify allocation and deallocation events are captured</li>\n<li>Check that call stacks are properly recorded</li>\n<li>Test with multi-threaded programs to verify thread safety</li>\n</ul>\n</li>\n<li><p><strong>Common issues</strong>:</p>\n<ul>\n<li><strong>Infinite recursion</strong>: Program hangs or crashes immediately → Check recursion detection</li>\n<li><strong>Missing symbols</strong>: &quot;symbol not found&quot; errors → Verify dlsym calls and linking</li>\n<li><strong>Metadata corruption</strong>: Inconsistent allocation counts → Review thread synchronization</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<ul>\n<li><strong>Use <code>ctypes</code> or <code>cffi</code></strong> to interface between Python profiler and C interception library</li>\n<li><strong>Shared memory or named pipes</strong> provide efficient communication channel for allocation events</li>\n<li><strong>Memory mapping with <code>mmap</code></strong> enables low-overhead metadata storage</li>\n<li><strong>Threading.local()</strong> provides thread-safe storage for per-thread allocation data</li>\n<li><strong>Weak references</strong> help avoid reference cycles in allocation tracking metadata</li>\n<li><strong>Signal handling</strong> requires async-safe code in allocation interceptors</li>\n<li><strong>Process forking</strong> requires careful cleanup and re-initialization of tracking state</li>\n</ul>\n<h2 id=\"interactions-and-data-flow\">Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) — orchestrates the complete data pipeline from stack sampling through symbol resolution to flame graph generation and memory leak detection</p>\n</blockquote>\n<h3 id=\"mental-model-the-assembly-line\">Mental Model: The Assembly Line</h3>\n<p>Think of the profiler as a sophisticated manufacturing assembly line where raw materials (memory addresses and timing data) flow through specialized stations that progressively refine and transform them into finished products (flame graphs and memory reports). Just as an automotive assembly line has welding stations, paint booths, and quality control checkpoints, our profiler has sampling stations, symbolization workbenches, and aggregation facilities. Each station has a specific job, operates at its own pace, and hands off partially completed work to the next station. The key insight is that data flows in one primary direction, but stations can operate concurrently and maintain their own buffers to handle varying processing speeds.</p>\n<p>The assembly line metaphor helps us understand three critical aspects of profiler data flow: <strong>buffering</strong> (stations need input queues to handle bursty work), <strong>backpressure</strong> (when downstream stations get overwhelmed, upstream stations must slow down or drop work), and <strong>quality control</strong> (each station validates its inputs and outputs to prevent defective data from corrupting the final product).</p>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<h3 id=\"profiling-data-pipeline\">Profiling Data Pipeline</h3>\n<p>The profiling data pipeline represents the core data transformation sequence that converts raw execution observations into actionable performance insights. This pipeline operates as a series of connected stages, each with specific responsibilities, performance characteristics, and failure modes.</p>\n<h4 id=\"primary-pipeline-stages\">Primary Pipeline Stages</h4>\n<p>The main profiling pipeline consists of four sequential stages that process data in distinct phases:</p>\n<table>\n<thead>\n<tr>\n<th>Stage</th>\n<th>Input</th>\n<th>Output</th>\n<th>Processing Time</th>\n<th>Buffer Capacity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Stack Sampling</strong></td>\n<td>Signal interrupts</td>\n<td>Raw <code>Sample</code> objects</td>\n<td>1-10 microseconds</td>\n<td>10,000 samples</td>\n</tr>\n<tr>\n<td><strong>Symbol Resolution</strong></td>\n<td><code>Sample</code> with addresses</td>\n<td><code>Sample</code> with function names</td>\n<td>100-1000 microseconds</td>\n<td>1,000 samples</td>\n</tr>\n<tr>\n<td><strong>Stack Aggregation</strong></td>\n<td>Individual samples</td>\n<td><code>FlameNode</code> tree</td>\n<td>10-100 microseconds</td>\n<td>Unlimited (streaming)</td>\n</tr>\n<tr>\n<td><strong>Visualization</strong></td>\n<td>Aggregated tree</td>\n<td>SVG flame graph</td>\n<td>1-10 milliseconds</td>\n<td>N/A (file output)</td>\n</tr>\n</tbody></table>\n<p><strong>Stage 1: Stack Sampling Collection</strong></p>\n<p>The sampling stage operates as a high-frequency data collector that captures execution snapshots at regular intervals. When a <code>SIGPROF</code> timer signal arrives, the signal handler executes in an async-safe context and must complete its work within microseconds to avoid distorting the target program&#39;s behavior.</p>\n<p>The sampling process follows this sequence:</p>\n<ol>\n<li><strong>Signal Delivery</strong>: The kernel delivers <code>SIGPROF</code> to the target process based on the configured <code>TimerConfig</code> interval</li>\n<li><strong>Context Capture</strong>: The signal handler extracts the <code>RegisterContext</code> from the interrupted execution state</li>\n<li><strong>Stack Unwinding</strong>: Frame pointer traversal builds a <code>List[StackFrame]</code> representing the current call chain</li>\n<li><strong>Sample Creation</strong>: A complete <code>Sample</code> object is constructed with timestamp, thread ID, and captured stack frames</li>\n<li><strong>Buffer Storage</strong>: The sample is added to a thread-safe ring buffer using atomic operations</li>\n<li><strong>Overflow Handling</strong>: If the buffer is full, either the oldest sample is evicted or the new sample is dropped based on configured policy</li>\n</ol>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: The sampling stage operates under severe constraints because it runs in signal handler context. It cannot perform any operations that might block, allocate memory, or acquire locks. This forces us to pre-allocate all data structures and use only async-safe functions.</p>\n</blockquote>\n<p><strong>Stage 2: Symbol Resolution Processing</strong></p>\n<p>Symbol resolution transforms raw memory addresses into human-readable function names and source locations. This stage operates asynchronously from sampling and can afford higher latency because it doesn&#39;t run in signal handler context.</p>\n<p>The symbol resolution pipeline processes samples in batches:</p>\n<ol>\n<li><strong>Batch Extraction</strong>: Pull a batch of raw samples from the sampling buffer (typically 100-1000 samples)</li>\n<li><strong>Address Collection</strong>: Extract unique addresses from all <code>StackFrame</code> objects in the batch to minimize duplicate symbol lookups</li>\n<li><strong>Cache Lookup</strong>: Query the <code>SymbolCache</code> for each address to avoid expensive ELF parsing for previously resolved symbols</li>\n<li><strong>ELF Resolution</strong>: For cache misses, parse the appropriate <code>Module</code> to find the containing <code>Symbol</code></li>\n<li><strong>DWARF Processing</strong>: If debug information is available, extract source file names and line numbers from <code>LineRange</code> data</li>\n<li><strong>Frame Enrichment</strong>: Update each <code>StackFrame</code> with resolved <code>function_name</code>, <code>filename</code>, and <code>line_number</code></li>\n<li><strong>Cache Population</strong>: Store newly resolved symbols in the cache for future lookups</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Batch Processing Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Individual sample processing has high per-sample overhead due to symbol table parsing</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Process samples individually as they arrive</li>\n<li>Batch samples for bulk processing</li>\n<li>Stream processing with mini-batches</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Use batch processing with configurable batch sizes (default 500 samples)</li>\n<li><strong>Rationale</strong>: Batching amortizes symbol table parsing cost across multiple samples and enables address deduplication</li>\n<li><strong>Consequences</strong>: Introduces processing latency but reduces CPU overhead by 10-50x for symbol-heavy workloads</li>\n</ul>\n</blockquote>\n<p><strong>Stage 3: Stack Aggregation and Folding</strong></p>\n<p>The aggregation stage transforms individual stack samples into hierarchical call trees suitable for flame graph visualization. This process must preserve calling context while merging identical call paths to show frequency patterns.</p>\n<p>The aggregation algorithm operates as a streaming tree builder:</p>\n<ol>\n<li><strong>Root Initialization</strong>: Create a root <code>FlameNode</code> representing the entire profiling session</li>\n<li><strong>Sample Processing</strong>: For each symbolized <code>Sample</code>, traverse its <code>stack_frames</code> from bottom (main) to top (leaf function)</li>\n<li><strong>Path Traversal</strong>: Starting from the root node, follow or create child nodes for each frame in the call stack</li>\n<li><strong>Weight Accumulation</strong>: Increment <code>sample_count</code> for each node along the traversed path</li>\n<li><strong>Self-Time Tracking</strong>: Update <code>self_count</code> only for the leaf node representing the actual interrupted function</li>\n<li><strong>Metadata Preservation</strong>: Attach module names and other attributes to nodes for visualization coloring</li>\n</ol>\n<p>The folded stack format provides an intermediate representation that captures the essential aggregation information:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>main;parse_config;load_json;malloc 145\nmain;parse_config;validate_schema;check_required 89\nmain;process_data;compute_hash;sha256_update 234</code></pre></div>\n\n<p>Each line represents a unique call path with its accumulated sample count, enabling downstream tools to reconstruct the calling hierarchy.</p>\n<p><strong>Stage 4: Visualization Generation</strong></p>\n<p>The final stage converts the aggregated flame tree into an interactive SVG visualization. This stage performs coordinate calculations, color assignment, and interactive feature embedding.</p>\n<p>The visualization pipeline executes these steps:</p>\n<ol>\n<li><strong>Tree Traversal</strong>: Perform depth-first traversal of the <code>FlameNode</code> tree to calculate cumulative widths</li>\n<li><strong>Coordinate Mapping</strong>: Convert logical sample counts to pixel coordinates using the configured flame graph dimensions</li>\n<li><strong>Rectangle Generation</strong>: Create <code>Rectangle</code> objects for each visible node (filtering out rectangles below <code>MIN_WIDTH_THRESHOLD</code>)</li>\n<li><strong>Color Assignment</strong>: Apply the selected <code>ColorScheme</code> to distinguish different modules, function types, or call frequencies</li>\n<li><strong>SVG Construction</strong>: Generate SVG elements with embedded JavaScript for zoom and search functionality</li>\n<li><strong>Interactive Features</strong>: Add event handlers for mouse hover tooltips, click zoom, and text search highlighting</li>\n</ol>\n<h4 id=\"pipeline-performance-characteristics\">Pipeline Performance Characteristics</h4>\n<p>The profiling pipeline exhibits different performance characteristics at each stage that affect overall system behavior:</p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Sampling</th>\n<th>Symbolization</th>\n<th>Aggregation</th>\n<th>Visualization</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Throughput</strong></td>\n<td>10K samples/sec</td>\n<td>1K samples/sec</td>\n<td>50K samples/sec</td>\n<td>10 graphs/sec</td>\n</tr>\n<tr>\n<td><strong>Latency</strong></td>\n<td>10 microseconds</td>\n<td>1 millisecond</td>\n<td>100 microseconds</td>\n<td>100 milliseconds</td>\n</tr>\n<tr>\n<td><strong>Memory Usage</strong></td>\n<td>1KB per sample</td>\n<td>10MB symbol cache</td>\n<td>100KB tree</td>\n<td>50KB SVG</td>\n</tr>\n<tr>\n<td><strong>CPU Overhead</strong></td>\n<td>0.1% per 100Hz</td>\n<td>5-20% during resolution</td>\n<td>1-2% during aggregation</td>\n<td>Negligible</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Bottleneck Analysis</strong>: Symbol resolution typically becomes the pipeline bottleneck due to ELF parsing overhead. The system uses adaptive batching and aggressive caching to mitigate this limitation.</p>\n</blockquote>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fprofiler-state-machine.svg\" alt=\"Profiler State Machine\"></p>\n<h4 id=\"error-propagation-and-recovery\">Error Propagation and Recovery</h4>\n<p>The pipeline implements a comprehensive error handling strategy that prevents failures in one stage from corrupting downstream processing:</p>\n<table>\n<thead>\n<tr>\n<th>Error Type</th>\n<th>Detection Point</th>\n<th>Recovery Strategy</th>\n<th>Data Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Signal Handler Crash</strong></td>\n<td>Sampling stage</td>\n<td>Restart sampling with reduced frequency</td>\n<td>Lost samples during restart</td>\n</tr>\n<tr>\n<td><strong>Symbol Parse Failure</strong></td>\n<td>Symbolization stage</td>\n<td>Mark frames as unresolved, continue processing</td>\n<td>Missing function names, addresses shown</td>\n</tr>\n<tr>\n<td><strong>Memory Exhaustion</strong></td>\n<td>Any stage</td>\n<td>Drop oldest data, trigger garbage collection</td>\n<td>Reduced profiling window</td>\n</tr>\n<tr>\n<td><strong>File System Errors</strong></td>\n<td>Visualization stage</td>\n<td>Retry with temporary directory</td>\n<td>Delayed output generation</td>\n</tr>\n</tbody></table>\n<h3 id=\"memory-tracking-data-flow\">Memory Tracking Data Flow</h3>\n<p>The memory profiling data flow operates in parallel with stack sampling but follows a different architectural pattern based on <strong>event-driven interception</strong> rather than periodic sampling. This approach captures every allocation and deallocation event, providing complete memory usage visibility at the cost of higher runtime overhead.</p>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fmemory-tracking-sequence.svg\" alt=\"Memory Allocation Tracking\"></p>\n<h4 id=\"memory-tracking-architecture\">Memory Tracking Architecture</h4>\n<p>Memory profiling operates through function interposition, where the profiler intercepts calls to allocation functions like <code>malloc</code>, <code>calloc</code>, <code>realloc</code>, and <code>free</code>. This interception happens at the dynamic linking level using <code>LD_PRELOAD</code> to substitute profiler versions of these functions.</p>\n<p><strong>Interposition Mechanism</strong></p>\n<p>The memory tracking system implements a transparent proxy layer that wraps standard allocation functions:</p>\n<ol>\n<li><strong>Dynamic Loading</strong>: At process startup, <code>LD_PRELOAD</code> causes the dynamic linker to load profiler allocation functions before the standard library versions</li>\n<li><strong>Function Forwarding</strong>: Profiler functions perform tracking operations then forward to the real allocation functions using <code>dlsym(RTLD_NEXT, &quot;malloc&quot;)</code></li>\n<li><strong>Metadata Association</strong>: Each allocation gets associated with tracking metadata without modifying the returned pointer</li>\n<li><strong>Thread Safety</strong>: All tracking operations use thread-local storage and atomic operations to handle concurrent allocations</li>\n</ol>\n<p><strong>Allocation Event Processing</strong></p>\n<p>When an allocation function is called, the memory tracker follows this processing sequence:</p>\n<ol>\n<li><strong>Stack Capture</strong>: Immediately capture the current call stack to identify the allocation site</li>\n<li><strong>Allocation Forwarding</strong>: Call the real allocation function to obtain memory and actual size</li>\n<li><strong>Metadata Creation</strong>: Create an <code>Allocation</code> object with size, timestamp, thread ID, and captured stack</li>\n<li><strong>Hash Table Storage</strong>: Store allocation metadata in a thread-safe hash table keyed by returned pointer</li>\n<li><strong>Site Aggregation</strong>: Update the corresponding <code>AllocationSite</code> statistics for this call stack signature</li>\n<li><strong>Memory Accounting</strong>: Update global memory counters and per-thread allocation rates</li>\n</ol>\n<p><strong>Deallocation Event Processing</strong></p>\n<p>Free operations trigger a parallel deallocation tracking sequence:</p>\n<ol>\n<li><strong>Metadata Lookup</strong>: Find the <code>Allocation</code> object associated with the freed pointer</li>\n<li><strong>Lifetime Calculation</strong>: Compute allocation lifetime and update lifetime distribution statistics</li>\n<li><strong>Site Updates</strong>: Decrement live allocation counts for the corresponding <code>AllocationSite</code></li>\n<li><strong>Metadata Cleanup</strong>: Remove allocation metadata and mark as freed to detect double-free errors</li>\n<li><strong>Leak Prevention</strong>: Update leak detection heuristics based on allocation age and frequency patterns</li>\n</ol>\n<h4 id=\"memory-data-structures-and-flow\">Memory Data Structures and Flow</h4>\n<p>The memory tracking system maintains several interconnected data structures that provide different analytical perspectives:</p>\n<table>\n<thead>\n<tr>\n<th>Data Structure</th>\n<th>Purpose</th>\n<th>Update Frequency</th>\n<th>Memory Overhead</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Active Allocations Map</strong></td>\n<td>Track live allocations</td>\n<td>Every malloc/free</td>\n<td>64 bytes per allocation</td>\n</tr>\n<tr>\n<td><strong>Allocation Sites Index</strong></td>\n<td>Aggregate by call stack</td>\n<td>Every malloc</td>\n<td>256 bytes per unique site</td>\n</tr>\n<tr>\n<td><strong>Memory Timeline</strong></td>\n<td>Historical usage patterns</td>\n<td>Every 100ms</td>\n<td>32 bytes per snapshot</td>\n</tr>\n<tr>\n<td><strong>Leak Candidates List</strong></td>\n<td>Potential memory leaks</td>\n<td>Every leak scan</td>\n<td>128 bytes per suspected leak</td>\n</tr>\n</tbody></table>\n<p><strong>Allocation Site Aggregation</strong></p>\n<p>The memory profiler groups allocations by their call stack signatures to identify allocation hotspots and patterns. This aggregation process enables developers to find the source code locations responsible for the most memory usage.</p>\n<p>The site aggregation algorithm:</p>\n<ol>\n<li><strong>Stack Signature</strong>: Generate a hash of the complete call stack using function addresses or resolved names</li>\n<li><strong>Site Lookup</strong>: Find or create an <code>AllocationSite</code> entry for this signature</li>\n<li><strong>Statistics Update</strong>: Increment counters for total allocations, bytes allocated, and peak usage</li>\n<li><strong>Lifetime Tracking</strong>: Update the lifetime distribution histogram for allocations from this site</li>\n<li><strong>Growth Detection</strong>: Compare current allocation rate to historical averages to detect growth patterns</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Call Stack Hashing Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to efficiently group allocations by identical call stacks without storing full stack copies</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Hash raw addresses (fast but breaks with ASLR)</li>\n<li>Hash resolved function names (slower but stable)</li>\n<li>Hybrid approach with address-based fast path and name-based fallback</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Use hybrid hashing with resolved names as canonical signature</li>\n<li><strong>Rationale</strong>: Provides stable grouping across program runs while maintaining performance for hot allocation sites</li>\n<li><strong>Consequences</strong>: Requires symbol resolution during allocation tracking, adding 10-50μs overhead per unique site</li>\n</ul>\n</blockquote>\n<h4 id=\"leak-detection-algorithm\">Leak Detection Algorithm</h4>\n<p>Memory leak detection operates as a background analysis process that examines allocation patterns to identify problematic memory usage. The leak detector runs periodically (every 10-60 seconds) and applies multiple heuristics to classify allocations.</p>\n<p><strong>Leak Classification Heuristics</strong></p>\n<p>The leak detection system applies several analytical techniques:</p>\n<table>\n<thead>\n<tr>\n<th>Heuristic</th>\n<th>Description</th>\n<th>Confidence Weight</th>\n<th>False Positive Rate</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Age-Based</strong></td>\n<td>Allocations older than threshold without free</td>\n<td>0.3</td>\n<td>High (long-lived data structures)</td>\n</tr>\n<tr>\n<td><strong>Growth Pattern</strong></td>\n<td>Allocation sites with unbounded growth rates</td>\n<td>0.5</td>\n<td>Medium (caches and buffers)</td>\n</tr>\n<tr>\n<td><strong>Reference Analysis</strong></td>\n<td>Allocations with no discoverable references</td>\n<td>0.8</td>\n<td>Low (requires heap scanning)</td>\n</tr>\n<tr>\n<td><strong>Frequency Anomaly</strong></td>\n<td>Sites with sudden allocation rate increases</td>\n<td>0.4</td>\n<td>Medium (legitimate growth spurts)</td>\n</tr>\n</tbody></table>\n<p><strong>Leak Confidence Scoring</strong></p>\n<p>Each potential leak receives a confidence score between 0.0 and 1.0 based on multiple factors:</p>\n<ol>\n<li><strong>Allocation Age</strong>: Longer-lived allocations receive higher leak scores, but with diminishing returns after 1 hour</li>\n<li><strong>Site Growth Rate</strong>: Allocation sites showing exponential or linear growth patterns get elevated scores</li>\n<li><strong>Reachability</strong>: Allocations not reachable from stack or global variables receive maximum scores</li>\n<li><strong>Similar Patterns</strong>: Multiple allocations from the same site with identical behavior increase collective confidence</li>\n<li><strong>Suppression Rules</strong>: User-defined patterns can reduce scores for known false positives</li>\n</ol>\n<p><strong>Memory Usage Timeline</strong></p>\n<p>The memory profiler maintains a timeline of memory usage that enables trend analysis and growth pattern detection:</p>\n<ol>\n<li><strong>Snapshot Collection</strong>: Every 100ms, capture current memory usage statistics including heap size, allocation rate, and fragmentation</li>\n<li><strong>Trend Analysis</strong>: Apply sliding window analysis to detect growth trends, allocation spikes, and usage plateaus</li>\n<li><strong>Anomaly Detection</strong>: Flag unusual patterns like sudden memory spikes or allocation rate changes</li>\n<li><strong>Correlation Analysis</strong>: Associate memory usage changes with specific allocation sites and code paths</li>\n</ol>\n<h3 id=\"output-formats-and-apis\">Output Formats and APIs</h3>\n<p>The profiler system supports multiple output formats and integration APIs to accommodate different analysis workflows and external tooling. The output system operates as the final stage of both profiling pipelines and must handle format conversion, data serialization, and external tool compatibility.</p>\n<h4 id=\"primary-output-formats\">Primary Output Formats</h4>\n<p>The profiler generates several output formats optimized for different use cases:</p>\n<table>\n<thead>\n<tr>\n<th>Format</th>\n<th>Primary Use Case</th>\n<th>File Extension</th>\n<th>Size (typical)</th>\n<th>Generation Time</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Interactive SVG</strong></td>\n<td>Developer analysis</td>\n<td><code>.svg</code></td>\n<td>500KB - 5MB</td>\n<td>100-500ms</td>\n</tr>\n<tr>\n<td><strong>Folded Stack Format</strong></td>\n<td>Tool interoperability</td>\n<td><code>.folded</code></td>\n<td>100KB - 1MB</td>\n<td>10-50ms</td>\n</tr>\n<tr>\n<td><strong>JSON Profile Data</strong></td>\n<td>Programmatic analysis</td>\n<td><code>.json</code></td>\n<td>1MB - 10MB</td>\n<td>50-200ms</td>\n</tr>\n<tr>\n<td><strong>Memory Report HTML</strong></td>\n<td>Leak analysis</td>\n<td><code>.html</code></td>\n<td>200KB - 2MB</td>\n<td>200-800ms</td>\n</tr>\n<tr>\n<td><strong>Raw Sample Data</strong></td>\n<td>Custom processing</td>\n<td><code>.samples</code></td>\n<td>10MB - 100MB</td>\n<td>20-100ms</td>\n</tr>\n</tbody></table>\n<p><strong>Interactive SVG Flame Graphs</strong></p>\n<p>The SVG flame graph format serves as the primary visualization output for performance analysis. These files embed interactive JavaScript that enables zoom, search, and tooltip functionality without requiring external dependencies.</p>\n<p>SVG flame graph structure:</p>\n<ol>\n<li><strong>Document Header</strong>: SVG dimensions, viewport settings, and embedded CSS styles for consistent appearance</li>\n<li><strong>Rectangle Elements</strong>: Each <code>&lt;rect&gt;</code> element represents a function call with position, size, and color encoding</li>\n<li><strong>Text Labels</strong>: Function names positioned within rectangles, with truncation handling for narrow functions</li>\n<li><strong>Interactive Script</strong>: Embedded JavaScript handling mouse events, zoom operations, and search highlighting</li>\n<li><strong>Metadata Comments</strong>: Profiling session information, sample counts, and generation parameters embedded as XML comments</li>\n</ol>\n<p>The interactive features include:</p>\n<ul>\n<li><strong>Click Zoom</strong>: Clicking any rectangle zooms to show that function as the root with proportional child scaling</li>\n<li><strong>Reset View</strong>: Double-click background to return to full flame graph view</li>\n<li><strong>Text Search</strong>: Search box highlights matching function names with yellow background</li>\n<li><strong>Hover Tooltips</strong>: Display full function name, sample count, and percentage for truncated labels</li>\n<li><strong>Permalink Generation</strong>: URL fragments preserve zoom state for sharing specific flame graph views</li>\n</ul>\n<p><strong>Folded Stack Format</strong></p>\n<p>The folded stack format provides a compact text representation that&#39;s compatible with external flame graph tools and enables custom analysis scripting:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>main;parse_config;json_parse;malloc 423\nmain;parse_config;json_parse;strdup 156  \nmain;process_data;hash_compute;sha256_init 234\nmain;process_data;hash_compute;sha256_update 1847\nmain;process_data;hash_compute;sha256_final 089</code></pre></div>\n\n<p>Each line contains:</p>\n<ul>\n<li><strong>Call Stack Path</strong>: Semicolon-separated function names from root to leaf</li>\n<li><strong>Sample Count</strong>: Number of times this exact call path was observed during profiling</li>\n<li><strong>Optional Metadata</strong>: Additional fields like module names or source locations can be appended</li>\n</ul>\n<p><strong>JSON Profile Data</strong></p>\n<p>The JSON format provides complete profiling data in a structured format suitable for programmatic analysis and integration with performance monitoring systems:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">json</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"profiling_session\"</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"start_time\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">1672531200.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"duration_seconds\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">30.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"target_process\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"my_application\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"sampling_frequency\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"total_samples\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">3000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  },</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"flame_tree\"</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"function_name\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"main\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"sample_count\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">3000</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"self_count\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">45</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    \"children\"</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#FDAEB7;font-style:italic\">...</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  },</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"hot_functions\"</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#FDAEB7;font-style:italic\">...</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"memory_profile\"</span><span style=\"color:#E1E4E8\">: {</span><span style=\"color:#FDAEB7;font-style:italic\">...</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Memory Report HTML</strong></p>\n<p>Memory profiling generates comprehensive HTML reports that combine allocation analysis, leak detection, and usage trends in a single document:</p>\n<ol>\n<li><strong>Executive Summary</strong>: Top allocation sites, total memory usage, and leak count overview</li>\n<li><strong>Allocation Hotspots</strong>: Table of functions allocating the most memory with stack traces</li>\n<li><strong>Memory Leaks</strong>: Detailed leak reports with confidence scores and recommended fixes</li>\n<li><strong>Usage Timeline</strong>: Interactive charts showing memory usage over time</li>\n<li><strong>Allocation Patterns</strong>: Analysis of allocation size distributions and lifetime patterns</li>\n</ol>\n<h4 id=\"api-integration-points\">API Integration Points</h4>\n<p>The profiler provides several API integration mechanisms for embedding profiling capabilities in larger systems:</p>\n<p><strong>Python API Interface</strong></p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>profile_process()</code></td>\n<td><code>pid: int, duration: float</code></td>\n<td><code>Profile</code></td>\n<td>Collect samples from running process</td>\n</tr>\n<tr>\n<td><code>profile_function()</code></td>\n<td><code>func: callable, *args</code></td>\n<td><code>Profile</code></td>\n<td>Profile single function execution</td>\n</tr>\n<tr>\n<td><code>load_profile()</code></td>\n<td><code>filename: str</code></td>\n<td><code>Profile</code></td>\n<td>Load previously saved profile data</td>\n</tr>\n<tr>\n<td><code>generate_flame_graph()</code></td>\n<td><code>profile: Profile, output: str</code></td>\n<td><code>None</code></td>\n<td>Generate SVG flame graph file</td>\n</tr>\n<tr>\n<td><code>detect_memory_leaks()</code></td>\n<td><code>profile: Profile</code></td>\n<td><code>List[MemoryLeak]</code></td>\n<td>Run leak detection analysis</td>\n</tr>\n<tr>\n<td><code>export_folded_stacks()</code></td>\n<td><code>profile: Profile</code></td>\n<td><code>str</code></td>\n<td>Convert to folded stack format</td>\n</tr>\n</tbody></table>\n<p><strong>Configuration API</strong></p>\n<p>The profiler accepts configuration through multiple channels:</p>\n<table>\n<thead>\n<tr>\n<th>Configuration Source</th>\n<th>Priority</th>\n<th>Format</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Command Line Arguments</strong></td>\n<td>Highest</td>\n<td><code>--sampling-freq=100</code></td>\n<td>Interactive profiling sessions</td>\n</tr>\n<tr>\n<td><strong>Configuration File</strong></td>\n<td>Medium</td>\n<td>JSON/YAML</td>\n<td>Reproducible profiling setups</td>\n</tr>\n<tr>\n<td><strong>Environment Variables</strong></td>\n<td>Low</td>\n<td><code>PROFILER_FREQ=100</code></td>\n<td>Container and CI environments</td>\n</tr>\n<tr>\n<td><strong>Programmatic API</strong></td>\n<td>Highest</td>\n<td><code>ProfilerConfig</code> object</td>\n<td>Embedded profiling</td>\n</tr>\n</tbody></table>\n<p><strong>External Tool Integration</strong></p>\n<p>The profiler supports integration with external performance analysis tools through standard interfaces:</p>\n<table>\n<thead>\n<tr>\n<th>Integration</th>\n<th>Interface</th>\n<th>Data Flow</th>\n<th>Benefits</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>perf Integration</strong></td>\n<td>Import perf.data files</td>\n<td>External → Profiler</td>\n<td>Leverage hardware counters</td>\n</tr>\n<tr>\n<td><strong>Grafana Dashboard</strong></td>\n<td>Prometheus metrics export</td>\n<td>Profiler → External</td>\n<td>Real-time monitoring</td>\n</tr>\n<tr>\n<td><strong>FlameGraph Scripts</strong></td>\n<td>Folded stack format</td>\n<td>Profiler → External</td>\n<td>Brendan Gregg&#39;s toolchain</td>\n</tr>\n<tr>\n<td><strong>IDE Plugins</strong></td>\n<td>JSON API over HTTP</td>\n<td>Bidirectional</td>\n<td>In-editor performance analysis</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Philosophy</strong>: The output system emphasizes <strong>format interoperability</strong> over proprietary formats. This decision enables integration with existing performance toolchains while providing native visualizations for immediate analysis.</p>\n</blockquote>\n<h4 id=\"data-export-pipeline\">Data Export Pipeline</h4>\n<p>The output generation pipeline operates as a final transformation stage that converts internal profiler data structures into external formats:</p>\n<ol>\n<li><strong>Data Validation</strong>: Verify profile completeness and consistency before export</li>\n<li><strong>Format Selection</strong>: Choose appropriate output format based on user requirements and data characteristics</li>\n<li><strong>Template Processing</strong>: Apply formatting templates and styling for human-readable outputs</li>\n<li><strong>Optimization</strong>: Compress data, remove redundant information, and optimize for target file size</li>\n<li><strong>Metadata Injection</strong>: Add profiling session information, generation timestamps, and tool versions</li>\n<li><strong>File Generation</strong>: Write formatted output to specified destination with atomic operations</li>\n</ol>\n<p><strong>Performance Considerations</strong></p>\n<p>Output generation performance varies significantly by format:</p>\n<ul>\n<li><strong>SVG Generation</strong>: Dominated by coordinate calculations and JavaScript embedding (100-500ms for 10K samples)</li>\n<li><strong>JSON Export</strong>: Limited by serialization overhead and pretty-printing (50-200ms for 10K samples)</li>\n<li><strong>Folded Format</strong>: Fastest export due to simple text generation (10-50ms for 10K samples)</li>\n<li><strong>HTML Reports</strong>: Slowest due to template processing and embedded charts (200-800ms for complex reports)</li>\n</ul>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Fsampling-sequence.svg\" alt=\"Sampling Sequence\"></p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance provides concrete code structures and technology recommendations for building the profiler data pipeline and output systems.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Pipeline Orchestration</strong></td>\n<td>Python threading with Queue</td>\n<td>AsyncIO with aiofiles</td>\n</tr>\n<tr>\n<td><strong>Data Serialization</strong></td>\n<td>JSON with built-in library</td>\n<td>MessagePack or Protocol Buffers</td>\n</tr>\n<tr>\n<td><strong>SVG Generation</strong></td>\n<td>String templating</td>\n<td>XML library with DOM manipulation</td>\n</tr>\n<tr>\n<td><strong>Memory Interposition</strong></td>\n<td>ctypes with LD_PRELOAD</td>\n<td>Custom C extension module</td>\n</tr>\n<tr>\n<td><strong>Symbol Resolution</strong></td>\n<td>pyelftools library</td>\n<td>Custom ELF parser with mmap</td>\n</tr>\n<tr>\n<td><strong>Interactive Features</strong></td>\n<td>Embedded JavaScript</td>\n<td>WebAssembly for complex operations</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n  src/\n    profiler/\n      pipeline/\n        __init__.py\n        sampler.py           ← Signal-based stack sampling\n        symbolizer.py        ← Address to symbol resolution  \n        aggregator.py        ← Stack folding and tree building\n        visualizer.py        ← SVG flame graph generation\n        memory_tracker.py    ← Allocation interception\n      data/\n        __init__.py\n        structures.py        ← Core data classes (Sample, StackFrame, etc.)\n        buffers.py          ← Thread-safe ring buffers\n        cache.py            ← Symbol and metadata caching\n      output/\n        __init__.py\n        formats.py          ← Export format implementations\n        svg_generator.py    ← Interactive SVG creation\n        report_generator.py ← HTML memory reports\n      utils/\n        __init__.py\n        elf_parser.py       ← Symbol table parsing utilities\n        signal_handling.py  ← Async-safe signal operations\n  tests/\n    test_pipeline.py\n    test_memory_tracking.py\n    test_output_formats.py\n  examples/\n    basic_profiling.py\n    memory_leak_demo.py</code></pre></div>\n\n<h4 id=\"core-pipeline-infrastructure\">Core Pipeline Infrastructure</h4>\n<p><strong>Complete Pipeline Coordinator</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> queue</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, List, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> concurrent.futures </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ThreadPoolExecutor</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PipelineStats</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Statistics for monitoring pipeline performance and health.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    samples_collected: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    samples_symbolized: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    samples_aggregated: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dropped_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_cache_hits: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_cache_misses: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_errors: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_error: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pipeline_start_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_processing_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate samples processed per second since pipeline start.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.pipeline_start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.samples_collected </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> elapsed </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> elapsed </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_error_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate error rate as percentage of total samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.samples_collected </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.processing_errors</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.processing_errors </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100.0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> total </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerPipeline</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Coordinates the complete profiling pipeline from sampling to output generation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Manages concurrent processing stages with proper error handling and backpressure.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: ProfilerConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PipelineStats()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Inter-stage communication queues with bounded capacity</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sample_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue.Queue(</span><span style=\"color:#FFAB70\">maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbolized_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue.Queue(</span><span style=\"color:#FFAB70\">maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.aggregated_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue.Queue(</span><span style=\"color:#FFAB70\">maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Pipeline components (imported from respective modules)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sampler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackSampler(config.sampling)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbolizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AddressSymbolizer(config.symbols)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.aggregator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackAggregator()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.visualizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FlameGraphGenerator(config.visualization)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Control flags and synchronization</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.shutdown_event </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Event()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stage_threads: List[threading.Thread] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> start_profiling</span><span style=\"color:#E1E4E8\">(self, target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, duration_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Start the complete profiling pipeline for specified target and duration.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            target_pid: Process ID to profile</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            duration_seconds: How long to collect samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate target process exists and is accessible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Start sampling thread with configured frequency and target PID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Start symbolization worker thread pool (2-4 threads)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Start aggregation thread for real-time stack folding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Set up shutdown timer for specified duration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Initialize all pipeline queues and reset statistics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> stop_profiling</span><span style=\"color:#E1E4E8\">(self) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Stop profiling pipeline and return collected profile data.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Complete Profile object with all processed samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Signal all stages to stop processing new data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Wait for queues to drain with reasonable timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Join all worker threads to ensure clean shutdown</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Collect final statistics and validate data consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Build and return complete Profile object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use shutdown_event and queue.join() for graceful shutdown</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _sampling_stage</span><span style=\"color:#E1E4E8\">(self, target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Sampling stage worker that collects raw stack samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Set up signal handler for SIGPROF using signal.signal()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Configure interval timer with configured frequency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Enter sampling loop until shutdown_event is set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle sampling errors gracefully and update statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Place samples in sample_queue with timeout handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _symbolization_stage</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Symbolization stage worker that resolves addresses to function names.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Pull batches of samples from sample_queue </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract unique addresses to minimize symbol lookup overhead</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Resolve addresses using symbolizer with caching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update samples with resolved function names and line numbers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Place symbolized samples in symbolized_queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle symbol resolution errors by marking frames as unresolved</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _aggregation_stage</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Aggregation stage worker that builds flame graph tree structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Pull symbolized samples from symbolized_queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Process each sample through stack aggregation algorithm</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update flame tree nodes with sample counts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle memory pressure by periodically compacting tree</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Place intermediate results in aggregated_queue for visualization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Thread-Safe Sample Buffer</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RingBuffer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Thread-safe ring buffer optimized for high-frequency sample collection.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Implements lock-free operations where possible for minimal overhead.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, capacity: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> capacity</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">capacity)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()  </span><span style=\"color:#6A737D\"># Allow recursive locking</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.dropped_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.total_added </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_sample</span><span style=\"color:#E1E4E8\">(self, sample: Sample) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Add sample to buffer, dropping oldest if at capacity.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            True if sample was added, False if dropped due to errors</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate sample has required fields (timestamp, stack_frames)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Acquire buffer lock with timeout to prevent blocking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add sample to deque (automatically evicts oldest if full)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update statistics counters atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return success status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use with self.lock: for automatic lock management</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_samples</span><span style=\"color:#E1E4E8\">(self, max_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Sample]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Extract up to max_count samples from buffer for processing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            max_count: Maximum number of samples to extract</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of samples removed from buffer (may be fewer than max_count)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Acquire buffer lock </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate actual extraction count (min of max_count and buffer size)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Extract samples from left side of deque (oldest first)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return extracted samples as list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use popleft() in loop or convert to list and clear portion</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_stats</span><span style=\"color:#E1E4E8\">(self) -> BufferStats:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current buffer statistics for monitoring.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create BufferStats object with current metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Include total_added, dropped_count, current size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate buffer utilization percentage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return statistics object</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"memory-tracking-infrastructure\">Memory Tracking Infrastructure</h4>\n<p><strong>Complete Allocation Tracker with Interposition</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes.util</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Optional, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> traceback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> atexit</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationTracker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Memory allocation tracker using function interposition to monitor heap usage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Intercepts malloc, free, realloc calls and maintains allocation metadata.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Load libc and get original allocation functions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        libc_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ctypes.util.find_library(</span><span style=\"color:#9ECBFF\">\"c\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.libc </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ctypes.CDLL(libc_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Function prototypes for original allocation functions  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_malloc </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.libc.malloc</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_free </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.libc.free</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_realloc </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.libc.realloc</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Allocation tracking data structures</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.active_allocations: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Allocation] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.allocation_sites: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, AllocationSite] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.memory_timeline: List[MemorySnapshot] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Thread safety and recursion prevention</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.tracker_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.in_tracker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.local()  </span><span style=\"color:#6A737D\"># Prevent recursion</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Register cleanup handler</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        atexit.register(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._generate_final_report)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> intercept_malloc</span><span style=\"color:#E1E4E8\">(self, size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Intercept malloc calls to track allocations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            size: Requested allocation size in bytes</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Pointer to allocated memory (as integer address)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for recursion using threading.local to prevent infinite loops</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Call original malloc to get actual memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Capture current call stack using traceback or inspect</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate stack signature for allocation site tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create Allocation object with metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Store allocation in active_allocations dict</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Update allocation site statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return original pointer unchanged</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use getattr(self.in_tracker, 'active', False) to check recursion</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> intercept_free</span><span style=\"color:#E1E4E8\">(self, ptr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Intercept free calls to track deallocations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            ptr: Pointer being freed (as integer address)  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Call original free first to avoid use-after-free</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Look up allocation metadata in active_allocations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If found, calculate allocation lifetime</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update allocation site lifetime statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Remove allocation from active_allocations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Mark allocation as freed with timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Handle case where ptr is not found (double free or untracked allocation)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_leaks</span><span style=\"color:#E1E4E8\">(self) -> List[MemoryLeak]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Analyze active allocations to detect potential memory leaks.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of MemoryLeak objects with confidence scores</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Iterate through all active allocations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate allocation age and check against thresholds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Group allocations by allocation site for pattern analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply leak detection heuristics (age, growth, reachability)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate confidence scores for each suspected leak</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create MemoryLeak objects with detailed information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Sort leaks by confidence score and return high-confidence leaks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _calculate_stack_signature</span><span style=\"color:#E1E4E8\">(self, stack_frames: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate unique signature for call stack to identify allocation sites.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Join stack frame strings with separator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate MD5 or SHA256 hash of joined string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return hash as hexadecimal string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use hashlib.md5(stack_string.encode()).hexdigest()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _capture_call_stack</span><span style=\"color:#E1E4E8\">(self) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Capture current call stack for allocation site identification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use traceback.extract_stack() to get current call stack</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Filter out tracker internal functions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Convert traceback frames to StackFrame objects</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Resolve function names and file locations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return list of StackFrame objects</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"output-format-generation\">Output Format Generation</h4>\n<p><strong>SVG Flame Graph Generator</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> xml.etree.ElementTree </span><span style=\"color:#F97583\">as</span><span style=\"color:#79B8FF\"> ET</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> InteractiveSVGGenerator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Generates interactive SVG flame graphs with embedded JavaScript for zoom and search.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Optimizes for file size and rendering performance.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: VisualizationConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.width </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1200</span><span style=\"color:#6A737D\">  # Default canvas width</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.height </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 600</span><span style=\"color:#6A737D\">  # Default canvas height</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.colors </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._load_color_scheme(config.color_scheme)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_svg</span><span style=\"color:#E1E4E8\">(self, flame_tree: FlameNode, output_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Generate complete interactive SVG flame graph file.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            flame_tree: Root node of aggregated call tree</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            output_path: File path for generated SVG</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate coordinates for all visible rectangles</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create SVG root element with viewbox and dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add CSS styles for consistent appearance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate rectangle elements with colors and positions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add text labels with truncation for narrow rectangles</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Embed interactive JavaScript for zoom and search</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Add metadata comments with profiling session info</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Write complete SVG to output file with pretty formatting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_coordinates</span><span style=\"color:#E1E4E8\">(self, root: FlameNode) -> List[Rectangle]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate pixel coordinates for all flame graph rectangles.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            root: Root flame graph node</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of Rectangle objects with calculated positions and sizes</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Traverse flame tree depth-first to calculate total widths</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate width scale factor (pixels per sample)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Assign x-coordinates based on cumulative child widths</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Assign y-coordinates based on tree depth</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Filter out rectangles below minimum width threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create Rectangle objects with final pixel coordinates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Assign colors based on configured color scheme</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use recursive traversal to maintain parent-child positioning</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _embed_javascript</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate JavaScript code for interactive features.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create zoom functionality for click-to-zoom behavior</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Implement search highlighting with text matching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add tooltip display for hover events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Include reset view functionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add keyboard shortcuts for common operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return complete JavaScript as string for embedding</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After implementing the basic pipeline (Milestones 1-2):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> profiler.examples.basic_profiling</span><span style=\"color:#79B8FF\"> --pid</span><span style=\"color:#79B8FF\"> 1234</span><span style=\"color:#79B8FF\"> --duration</span><span style=\"color:#79B8FF\"> 10</span></span></code></pre></div>\n<p>Expected output:</p>\n<ul>\n<li>Console shows sampling rate and symbol resolution progress</li>\n<li>Generates <code>profile_1234.svg</code> with basic flame graph</li>\n<li>Symbol cache hit rate should exceed 80% for typical programs</li>\n</ul>\n<p><strong>After implementing memory tracking (Milestone 4):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">LD_PRELOAD</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">./profiler/memory_tracker.so</span><span style=\"color:#B392F0\"> python</span><span style=\"color:#9ECBFF\"> memory_hungry_app.py</span></span></code></pre></div>\n<p>Expected behavior:</p>\n<ul>\n<li>Memory report generated showing top allocation sites</li>\n<li>Leak detection identifies allocations without matching frees</li>\n<li>Timeline shows memory usage growth patterns</li>\n</ul>\n<p><strong>Integration testing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_pipeline.py</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected test results:</p>\n<ul>\n<li>All pipeline stages process samples without data loss</li>\n<li>Error handling gracefully manages symbol resolution failures</li>\n<li>Memory tracking correctly associates allocations with call sites</li>\n</ul>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) — robust error handling underpins reliable stack sampling, symbol resolution, flame graph generation, and memory profiling across all failure scenarios</p>\n</blockquote>\n<h3 id=\"mental-model-the-safety-net-system\">Mental Model: The Safety Net System</h3>\n<p>Think of error handling in a profiler like a comprehensive safety net system for a trapeze performance. Just as trapeze artists have multiple safety nets at different levels, primary nets to catch most falls, and emergency protocols when nets fail, our profiler must have layered error detection and recovery mechanisms. The primary safety nets catch common issues like missing symbols or failed signal delivery. Secondary nets handle more serious problems like corrupted debug information or allocation tracking failures. Emergency protocols ensure graceful degradation when multiple systems fail simultaneously, always prioritizing the stability of the target process being profiled.</p>\n<p>The key insight is that profiler errors must never compromise the target application — we are observers, not participants, and our failures should be invisible to the observed system. This constraint shapes every aspect of our error handling strategy.</p>\n<h3 id=\"sampling-error-scenarios\">Sampling Error Scenarios</h3>\n<p><strong>Stack sampling operates in a fundamentally hostile environment</strong> — signal handlers with severe restrictions, racing against target process execution, and working with potentially corrupted or incomplete stack data. The <strong>signal-based interruption</strong> mechanism creates numerous failure modes that require sophisticated detection and recovery strategies.</p>\n<h4 id=\"signal-delivery-failures\">Signal Delivery Failures</h4>\n<p>Signal delivery represents the most fundamental failure point in statistical sampling. When the kernel cannot deliver <code>SIGPROF</code> signals reliably, our sampling becomes incomplete or biased, leading to inaccurate profile results.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Detection Strategy</th>\n<th>Recovery Action</th>\n<th>Impact on Profile Quality</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signal blocked by target</td>\n<td>Monitor signal queue depth, detect missed intervals</td>\n<td>Switch to alternative sampling method, warn user</td>\n<td>High - creates blind spots in profile</td>\n</tr>\n<tr>\n<td>Signal handler crashed</td>\n<td>Segmentation fault or illegal instruction in handler</td>\n<td>Disable sampling, save partial results</td>\n<td>Critical - profiling stops completely</td>\n</tr>\n<tr>\n<td>Signal delivery delayed</td>\n<td>Compare expected vs actual sample timestamps</td>\n<td>Adjust frequency estimation, flag timing issues</td>\n<td>Medium - affects accuracy of timing data</td>\n</tr>\n<tr>\n<td>Target process in syscall</td>\n<td>Detect kernel stack samples without user frames</td>\n<td>Continue sampling, increase syscall visibility</td>\n<td>Low - kernel time still captured</td>\n</tr>\n<tr>\n<td>Signal interrupted by another signal</td>\n<td>Detect nested signal handler execution</td>\n<td>Use signal masking, defer processing</td>\n<td>Medium - may lose individual samples</td>\n</tr>\n</tbody></table>\n<p>The most insidious failure mode occurs when signals are consistently delayed or dropped during specific execution patterns. For example, tight computational loops with disabled interrupts can create <strong>sampling bias</strong> where expensive code paths appear underrepresented in the profile results.</p>\n<p><strong>Signal Handler Safety Violations</strong></p>\n<p>Signal handlers operate under severe restrictions — they can only safely call <strong>async-safe</strong> functions. Violations of these restrictions cause unpredictable crashes or data corruption in the target process.</p>\n<table>\n<thead>\n<tr>\n<th>Unsafe Operation</th>\n<th>Why It&#39;s Dangerous</th>\n<th>Safe Alternative</th>\n<th>Detection Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>malloc/free calls</td>\n<td>Non-reentrant, can deadlock on heap locks</td>\n<td>Pre-allocated fixed-size buffers</td>\n<td>Static analysis of handler code</td>\n</tr>\n<tr>\n<td>File I/O operations</td>\n<td>May block or corrupt file descriptors</td>\n<td>Lock-free ring buffer to separate thread</td>\n<td>Monitor handler execution time</td>\n</tr>\n<tr>\n<td>Complex library calls</td>\n<td>Unknown reentrancy, may call unsafe functions</td>\n<td>Minimal processing, defer complex work</td>\n<td>Code review and testing</td>\n</tr>\n<tr>\n<td>Floating point operations</td>\n<td>May corrupt FPU state</td>\n<td>Avoid FP math in signal context</td>\n<td>Compiler warnings and analysis</td>\n</tr>\n<tr>\n<td>Dynamic memory allocation</td>\n<td>Heap corruption in multi-threaded scenarios</td>\n<td>Stack allocation or pre-allocated pools</td>\n<td>Runtime detection of malloc calls</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Critical Design Principle</strong>: Signal handlers should do the absolute minimum work required to capture the stack state, then delegate all complex processing to a separate thread operating in normal execution context.</p>\n</blockquote>\n<h4 id=\"stack-unwinding-errors\">Stack Unwinding Errors</h4>\n<p><strong>Stack unwinding</strong> reconstructs the call chain by following frame pointers or interpreting DWARF unwind information. Multiple failure modes can produce incomplete or incorrect call stacks.</p>\n<p><strong>Frame Pointer Chain Corruption</strong></p>\n<p>Frame pointer corruption creates the most common stack unwinding failures. The chain of frame pointers can be broken by compiler optimizations, corrupted memory, or non-standard calling conventions.</p>\n<table>\n<thead>\n<tr>\n<th>Corruption Type</th>\n<th>Symptoms</th>\n<th>Detection Logic</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>NULL frame pointer</td>\n<td>Stack trace truncated prematurely</td>\n<td>Check for NULL before dereferencing</td>\n<td>Accept truncated stack, flag as incomplete</td>\n</tr>\n<tr>\n<td>Circular frame pointer</td>\n<td>Infinite loop in unwinding</td>\n<td>Track visited addresses, detect cycles</td>\n<td>Break cycle, report partial stack</td>\n</tr>\n<tr>\n<td>Invalid memory address</td>\n<td>Segmentation fault during unwinding</td>\n<td>Validate address ranges before access</td>\n<td>Stop unwinding, use partial stack</td>\n</tr>\n<tr>\n<td>Optimized away frame pointer</td>\n<td>Missing intermediate functions</td>\n<td>Compare with DWARF info if available</td>\n<td>Use DWARF unwinding as fallback</td>\n</tr>\n<tr>\n<td>Stack buffer overflow</td>\n<td>Frame pointers point to corrupted data</td>\n<td>Sanity check frame pointer values</td>\n<td>Abort unwinding, flag security issue</td>\n</tr>\n</tbody></table>\n<p>The unwinding algorithm must validate each frame pointer before dereferencing to prevent crashes in the signal handler:</p>\n<ol>\n<li>Check that the frame pointer falls within valid stack memory ranges for the thread</li>\n<li>Verify that the return address extracted from the frame appears in executable memory</li>\n<li>Ensure forward progress — each frame pointer must be greater than the previous</li>\n<li>Limit maximum stack depth to prevent infinite loops or excessive processing time</li>\n<li>Stop unwinding if any validation fails, preserving the partial stack captured so far</li>\n</ol>\n<p><strong>DWARF Unwinding Failures</strong></p>\n<p>DWARF-based unwinding provides more robust stack reconstruction but introduces additional failure modes related to debug information parsing and interpretation.</p>\n<table>\n<thead>\n<tr>\n<th>DWARF Issue</th>\n<th>Error Symptoms</th>\n<th>Detection Method</th>\n<th>Fallback Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Missing .debug_frame section</td>\n<td>No unwind info available</td>\n<td>Check ELF section headers</td>\n<td>Fall back to frame pointer unwinding</td>\n</tr>\n<tr>\n<td>Corrupted DWARF data</td>\n<td>Parse errors or invalid opcodes</td>\n<td>Validate DWARF structure during parsing</td>\n<td>Skip to next frame or abort unwinding</td>\n</tr>\n<tr>\n<td>Unsupported DWARF version</td>\n<td>Parser cannot interpret format</td>\n<td>Check version field in section header</td>\n<td>Use older parser version or skip</td>\n</tr>\n<tr>\n<td>Complex unwind expressions</td>\n<td>Cannot evaluate CFA expressions</td>\n<td>Monitor expression evaluation depth</td>\n<td>Simplify expression or use approximation</td>\n</tr>\n<tr>\n<td>Inconsistent debug info</td>\n<td>DWARF contradicts actual stack layout</td>\n<td>Cross-validate with frame pointer data</td>\n<td>Trust runtime data over debug info</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Hybrid Unwinding Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Both frame pointer and DWARF unwinding have distinct failure modes and complementary strengths</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Frame pointer only (simple, fast, but unreliable with optimized code)</li>\n<li>DWARF only (complete, but complex and can fail with corrupted debug info)</li>\n<li>Hybrid approach using both methods with cross-validation</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement hybrid unwinding with frame pointer as primary method and DWARF as validation/fallback</li>\n<li><strong>Rationale</strong>: Frame pointers provide fast, reliable unwinding for most cases, while DWARF catches optimized code and provides validation. Cross-validation detects corruption early.</li>\n<li><strong>Consequences</strong>: Increased complexity but much higher reliability across different compilation scenarios</li>\n</ul>\n</blockquote>\n<h4 id=\"buffer-overflow-and-sample-loss\">Buffer Overflow and Sample Loss</h4>\n<p>High-frequency sampling can overwhelm the sample collection buffers, leading to dropped samples and distorted profile results. The <code>RingBuffer</code> component handles overflow gracefully but requires monitoring to detect when sample loss becomes significant.</p>\n<table>\n<thead>\n<tr>\n<th>Overflow Scenario</th>\n<th>Detection Metrics</th>\n<th>Mitigation Strategy</th>\n<th>Quality Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Burst sampling</td>\n<td><code>dropped_count</code> increases rapidly</td>\n<td>Increase buffer size, reduce frequency</td>\n<td>Medium - may miss burst patterns</td>\n</tr>\n<tr>\n<td>Sustained overload</td>\n<td><code>total_added</code> &gt;&gt; samples processed</td>\n<td>Add backpressure to sampling loop</td>\n<td>High - systematic bias in results</td>\n</tr>\n<tr>\n<td>Memory pressure</td>\n<td>Buffer allocation fails</td>\n<td>Use fixed pre-allocated buffers</td>\n<td>Low - graceful capacity limitation</td>\n</tr>\n<tr>\n<td>Processing lag</td>\n<td>Symbolization cannot keep up</td>\n<td>Separate processing into pipeline stages</td>\n<td>Medium - increased latency</td>\n</tr>\n</tbody></table>\n<p>The <code>BufferStats</code> structure tracks buffer health and enables adaptive frequency adjustment:</p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Calculation</th>\n<th>Warning Threshold</th>\n<th>Action Required</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Drop Rate</td>\n<td><code>dropped_count / total_added</code></td>\n<td>&gt; 5%</td>\n<td>Reduce sampling frequency or increase buffer size</td>\n</tr>\n<tr>\n<td>Fill Ratio</td>\n<td><code>current_buffer_size / max_buffer_size</code></td>\n<td>&gt; 80%</td>\n<td>Increase processing rate or buffer capacity</td>\n</tr>\n<tr>\n<td>Processing Lag</td>\n<td>Time between sample capture and processing</td>\n<td>&gt; 100ms</td>\n<td>Optimize symbol resolution or add parallelism</td>\n</tr>\n<tr>\n<td>Memory Usage</td>\n<td>Total bytes in all buffers</td>\n<td>&gt; 100MB</td>\n<td>Implement sample compression or streaming</td>\n</tr>\n</tbody></table>\n<h3 id=\"symbol-resolution-failures\">Symbol Resolution Failures</h3>\n<p><strong>Symbol resolution</strong> transforms raw instruction pointer addresses into meaningful function names and source locations. This process depends on external debug information and binary metadata, creating numerous failure modes that require graceful degradation strategies.</p>\n<h4 id=\"missing-debug-symbols\">Missing Debug Symbols</h4>\n<p>The most common symbol resolution failure occurs when debug symbols are stripped from binaries or unavailable in standard search paths. Applications deployed in production environments typically strip debug information to reduce binary size, making detailed profiling challenging.</p>\n<table>\n<thead>\n<tr>\n<th>Missing Symbol Type</th>\n<th>Impact on Profiling</th>\n<th>Detection Method</th>\n<th>Graceful Degradation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Function names</td>\n<td>Raw addresses only</td>\n<td>Symbol table parsing fails</td>\n<td>Display addresses with module+offset</td>\n</tr>\n<tr>\n<td>Source file names</td>\n<td>No file context</td>\n<td>DWARF parsing returns empty</td>\n<td>Show function name without file info</td>\n</tr>\n<tr>\n<td>Line numbers</td>\n<td>No precise location</td>\n<td>Line number table missing</td>\n<td>Show function name and file only</td>\n</tr>\n<tr>\n<td>Inline function info</td>\n<td>Inlining hidden</td>\n<td>DWARF inline info absent</td>\n<td>Report outermost function only</td>\n</tr>\n<tr>\n<td>Template specializations</td>\n<td>Generic names</td>\n<td>C++ demangling incomplete</td>\n<td>Show mangled name with partial demangling</td>\n</tr>\n</tbody></table>\n<p>The <code>SymbolCache</code> must handle symbol lookup failures elegantly while providing useful fallback information:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Case</th>\n<th>Cache Behavior</th>\n<th>Fallback Display Format</th>\n<th>User Experience</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No symbol found</td>\n<td>Cache miss result to avoid repeated lookups</td>\n<td><code>&lt;unknown&gt;+0x1234 [libfoo.so]</code></td>\n<td>Clear indication of missing symbol</td>\n</tr>\n<tr>\n<td>Partial symbol info</td>\n<td>Cache available fields, mark incomplete</td>\n<td><code>malloc (libc.so.6)</code></td>\n<td>Useful but incomplete information</td>\n</tr>\n<tr>\n<td>Corrupted symbol data</td>\n<td>Mark symbol as invalid, skip caching</td>\n<td><code>&lt;corrupted&gt;+0x5678 [binary]</code></td>\n<td>Safe fallback without crashes</td>\n</tr>\n<tr>\n<td>Address outside module</td>\n<td>Detect invalid address range</td>\n<td><code>&lt;invalid address 0x7fff1234&gt;</code></td>\n<td>Clear error indication</td>\n</tr>\n</tbody></table>\n<p><strong>Address Space Layout Randomization (ASLR) Complications</strong></p>\n<p>ASLR randomizes the load addresses of shared libraries and executables, requiring <strong>load bias</strong> calculation to map runtime addresses back to symbol table addresses. Incorrect bias calculations produce symbol lookup failures or incorrect symbol attribution.</p>\n<table>\n<thead>\n<tr>\n<th>ASLR Issue</th>\n<th>Symptoms</th>\n<th>Detection Logic</th>\n<th>Correction Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Incorrect load bias</td>\n<td>Symbols offset by constant amount</td>\n<td>Compare expected vs actual symbol addresses</td>\n<td>Recalculate bias from runtime library mapping</td>\n</tr>\n<tr>\n<td>PIE binary handling</td>\n<td>Main executable symbols not found</td>\n<td>Main program addresses don&#39;t resolve</td>\n<td>Parse /proc/pid/maps for executable base address</td>\n</tr>\n<tr>\n<td>Dynamic library reloading</td>\n<td>Previously resolved symbols become invalid</td>\n<td>Symbol addresses change between samples</td>\n<td>Invalidate cache, reload symbol tables</td>\n</tr>\n<tr>\n<td>Nested address spaces</td>\n<td>Container or VM address translation</td>\n<td>Symbols resolve to wrong functions</td>\n<td>Detect virtualization, adjust address mapping</td>\n</tr>\n</tbody></table>\n<p>The <code>Module</code> structure tracks load-time information to handle ASLR correctly:</p>\n<table>\n<thead>\n<tr>\n<th>Module Field</th>\n<th>Purpose</th>\n<th>Update Trigger</th>\n<th>Validation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>base_address</code></td>\n<td>Runtime load address of module</td>\n<td>Library load/unload events</td>\n<td>Cross-check with /proc/pid/maps</td>\n</tr>\n<tr>\n<td><code>load_time</code></td>\n<td>When module was loaded</td>\n<td>dlopen() interception</td>\n<td>Compare with sample timestamps</td>\n</tr>\n<tr>\n<td><code>build_id</code></td>\n<td>Unique identifier for binary version</td>\n<td>Module registration</td>\n<td>Match against symbol file build ID</td>\n</tr>\n<tr>\n<td><code>architecture</code></td>\n<td>Target CPU architecture</td>\n<td>Binary header parsing</td>\n<td>Validate against current process architecture</td>\n</tr>\n</tbody></table>\n<h4 id=\"corrupted-debug-information\">Corrupted Debug Information</h4>\n<p>Debug information can become corrupted due to build system errors, file system corruption, or incompatible debugging formats. Corrupted DWARF data causes parsing failures that must be detected and handled without crashing the profiler.</p>\n<p><strong>DWARF Parsing Errors</strong></p>\n<p>DWARF debug information uses a complex hierarchical format that can become corrupted in subtle ways. Robust parsing requires validation at multiple levels and graceful error recovery.</p>\n<table>\n<thead>\n<tr>\n<th>Corruption Type</th>\n<th>Parse Error</th>\n<th>Validation Check</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid section headers</td>\n<td>Cannot locate debug sections</td>\n<td>Verify ELF section table integrity</td>\n<td>Skip DWARF, use symbol table only</td>\n</tr>\n<tr>\n<td>Truncated debug data</td>\n<td>Premature end of data</td>\n<td>Check section size vs data consumed</td>\n<td>Use partial data, mark as incomplete</td>\n</tr>\n<tr>\n<td>Invalid DWARF opcodes</td>\n<td>Unknown instruction in unwind info</td>\n<td>Validate opcode against DWARF standard</td>\n<td>Skip invalid instruction, continue parsing</td>\n</tr>\n<tr>\n<td>Circular references</td>\n<td>DIE references create loops</td>\n<td>Track visited DIEs during traversal</td>\n<td>Break cycle, mark incomplete</td>\n</tr>\n<tr>\n<td>Version mismatch</td>\n<td>Unsupported DWARF version</td>\n<td>Check version field in section header</td>\n<td>Use compatible parser subset</td>\n</tr>\n</tbody></table>\n<p>The symbol resolution pipeline implements defensive parsing with multiple validation layers:</p>\n<ol>\n<li><strong>ELF Structure Validation</strong>: Verify section headers, string tables, and symbol table format before parsing</li>\n<li><strong>DWARF Header Validation</strong>: Check compilation unit headers, version compatibility, and section boundaries  </li>\n<li><strong>Parse Tree Validation</strong>: Detect circular references, invalid offsets, and malformed DIE hierarchies</li>\n<li><strong>Cross-Reference Validation</strong>: Verify that address ranges and line number tables are consistent</li>\n<li><strong>Runtime Validation</strong>: Confirm that resolved symbols produce reasonable results during profiling</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Defensive Parsing with Graceful Degradation</strong></p>\n<ul>\n<li><strong>Context</strong>: Corrupted debug information can crash the profiler or produce misleading results, but partial information is often still valuable</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Strict parsing that fails fast on any corruption (reliable but loses all data)</li>\n<li>Permissive parsing that attempts to work around corruption (risky but preserves more data)</li>\n<li>Layered validation with graceful degradation (balanced approach)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement layered validation that preserves partial information while marking quality levels</li>\n<li><strong>Rationale</strong>: Partial profiling information is usually better than no information, but users need to understand data quality limitations</li>\n<li><strong>Consequences</strong>: More complex parsing logic but higher reliability and better user experience under adverse conditions</li>\n</ul>\n</blockquote>\n<h4 id=\"symbol-cache-corruption\">Symbol Cache Corruption</h4>\n<p>The <code>SymbolCache</code> maintains large amounts of metadata that can become corrupted due to memory errors, race conditions, or logic bugs. Cache corruption manifests as incorrect symbol resolution, crashes during lookup, or memory leaks.</p>\n<table>\n<thead>\n<tr>\n<th>Corruption Scenario</th>\n<th>Symptoms</th>\n<th>Detection Method</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash table corruption</td>\n<td>Lookups return wrong symbols</td>\n<td>Cross-validate results with fresh lookups</td>\n<td>Rebuild cache from scratch</td>\n</tr>\n<tr>\n<td>Memory overrun</td>\n<td>Cache grows unboundedly</td>\n<td>Monitor <code>cache_size_bytes</code> vs <code>max_cache_size</code></td>\n<td>Implement LRU eviction, cap growth</td>\n</tr>\n<tr>\n<td>Race condition</td>\n<td>Inconsistent cache state</td>\n<td>Detect concurrent modification patterns</td>\n<td>Add fine-grained locking or lock-free structures</td>\n</tr>\n<tr>\n<td>Reference counting errors</td>\n<td>Use-after-free or memory leaks</td>\n<td>Track object lifecycle with debugging builds</td>\n<td>Implement reference counting discipline</td>\n</tr>\n<tr>\n<td>Address mapping errors</td>\n<td>Symbols resolve to wrong addresses</td>\n<td>Validate resolved addresses against known good data</td>\n<td>Flush cache, reload symbol tables</td>\n</tr>\n</tbody></table>\n<p><strong>Cache Health Monitoring</strong></p>\n<p>The symbol cache includes comprehensive health monitoring to detect corruption early and trigger recovery actions before user-visible failures occur.</p>\n<table>\n<thead>\n<tr>\n<th>Health Metric</th>\n<th>Calculation</th>\n<th>Warning Threshold</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hit Rate Degradation</td>\n<td><code>hit_count / (hit_count + miss_count)</code></td>\n<td>&lt; 80% (normally 95%+)</td>\n<td>Clear cache, warm with common symbols</td>\n</tr>\n<tr>\n<td>Cache Size Growth</td>\n<td><code>cache_size_bytes</code> growth rate</td>\n<td>&gt; 10MB/minute</td>\n<td>Enable aggressive eviction</td>\n</tr>\n<tr>\n<td>Lookup Time Increase</td>\n<td>Average time per <code>lookup_symbol()</code> call</td>\n<td>&gt; 100μs (normally &lt; 10μs)</td>\n<td>Rebuild cache with optimized structure</td>\n</tr>\n<tr>\n<td>Corruption Detection</td>\n<td>Checksum validation of critical structures</td>\n<td>Any checksum mismatch</td>\n<td>Flush corrupted cache segment</td>\n</tr>\n</tbody></table>\n<h3 id=\"memory-tracking-edge-cases\">Memory Tracking Edge Cases</h3>\n<p><strong>Memory profiling</strong> operates through <strong>function interposition</strong>, intercepting allocation and deallocation calls to track heap usage patterns. This approach creates complex interactions with the target application&#39;s memory management, threading model, and error handling that require sophisticated edge case handling.</p>\n<h4 id=\"allocation-function-interposition-failures\">Allocation Function Interposition Failures</h4>\n<p>Function interposition using <code>LD_PRELOAD</code> can fail in numerous ways that lead to incomplete or incorrect memory tracking. These failures often manifest as missing allocations, double-free detection errors, or crashes in the allocation tracking logic.</p>\n<p><strong>Interception Bypass Scenarios</strong></p>\n<p>Applications can bypass malloc interception through static linking, direct system calls, or alternative memory allocation mechanisms that don&#39;t go through the standard library functions.</p>\n<table>\n<thead>\n<tr>\n<th>Bypass Method</th>\n<th>Detection Strategy</th>\n<th>Tracking Workaround</th>\n<th>Impact Assessment</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Static linking</td>\n<td>Monitor for untracked allocations via heap growth</td>\n<td>Hook mmap/brk syscalls directly</td>\n<td>Medium - misses malloc details but tracks total heap</td>\n</tr>\n<tr>\n<td>Alternative allocators</td>\n<td>Detect usage of tcmalloc, jemalloc, etc.</td>\n<td>Hook alternative allocator APIs</td>\n<td>High - completely missing allocation data</td>\n</tr>\n<tr>\n<td>Direct syscall usage</td>\n<td>Monitor mmap/munmap system calls</td>\n<td>Use ptrace or eBPF for syscall interception</td>\n<td>Low - unusual in normal applications</td>\n</tr>\n<tr>\n<td>Stack allocations</td>\n<td>Large stack usage without heap allocations</td>\n<td>Monitor stack growth via /proc/pid/stat</td>\n<td>Low - stack usage typically bounded</td>\n</tr>\n<tr>\n<td>Memory mapped files</td>\n<td>mmap usage that bypasses malloc</td>\n<td>Hook mmap family of functions</td>\n<td>Medium - can represent significant memory usage</td>\n</tr>\n</tbody></table>\n<p><strong>Recursive Allocation Detection</strong></p>\n<p>The allocation tracker itself needs memory for metadata storage, creating the risk of recursive malloc calls that can deadlock or cause infinite recursion. This represents one of the most dangerous failure modes in memory profiling.</p>\n<table>\n<thead>\n<tr>\n<th>Recursion Source</th>\n<th>Risk Level</th>\n<th>Prevention Method</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Metadata allocation</td>\n<td>High - immediate deadlock</td>\n<td>Use thread-local state to detect recursion</td>\n<td>Disable tracking for recursive calls</td>\n</tr>\n<tr>\n<td>Stack trace capture</td>\n<td>Medium - can trigger symbol resolution</td>\n<td>Pre-allocate stack trace buffers</td>\n<td>Limit stack trace depth</td>\n</tr>\n<tr>\n<td>Hash table operations</td>\n<td>High - dynamic resize triggers malloc</td>\n<td>Use fixed-size hash tables or custom allocators</td>\n<td>Fall back to simplified tracking</td>\n</tr>\n<tr>\n<td>Logging operations</td>\n<td>Low - typically uses stack allocation</td>\n<td>Avoid dynamic allocation in log paths</td>\n<td>Disable logging during tracking</td>\n</tr>\n<tr>\n<td>Signal handler malloc</td>\n<td>Critical - undefined behavior</td>\n<td>Never allocate memory in signal handlers</td>\n<td>Use lock-free data structures</td>\n</tr>\n</tbody></table>\n<p>The <code>AllocationTracker</code> uses thread-local storage to prevent recursive tracking:</p>\n<table>\n<thead>\n<tr>\n<th>Thread-Local Field</th>\n<th>Purpose</th>\n<th>Critical Section</th>\n<th>Recovery Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>in_tracker</code></td>\n<td>Recursion detection flag</td>\n<td>Set during malloc interception</td>\n<td>Skip tracking, allow original malloc</td>\n</tr>\n<tr>\n<td><code>recursion_depth</code></td>\n<td>Track nested calls</td>\n<td>Increment on entry, decrement on exit</td>\n<td>Abort tracking if depth &gt; 3</td>\n</tr>\n<tr>\n<td><code>buffer_offset</code></td>\n<td>Current position in pre-allocated buffer</td>\n<td>Updated during metadata writes</td>\n<td>Reset on buffer overflow</td>\n</tr>\n<tr>\n<td><code>error_count</code></td>\n<td>Track allocation tracking failures</td>\n<td>Increment on any error</td>\n<td>Disable tracking if errors &gt; 100</td>\n</tr>\n</tbody></table>\n<h4 id=\"memory-leak-detection-false-positives\">Memory Leak Detection False Positives</h4>\n<p>Leak detection algorithms must distinguish between genuine memory leaks and legitimate long-lived allocations. False positives create noise that obscures real issues, while false negatives allow actual leaks to go undetected.</p>\n<p><strong>Long-Lived vs Leaked Allocations</strong></p>\n<p>Many applications legitimately allocate memory that persists for the entire program lifetime. The leak detector must avoid flagging these allocations as leaks while still catching genuine problems.</p>\n<table>\n<thead>\n<tr>\n<th>Allocation Pattern</th>\n<th>Leak Likelihood</th>\n<th>Classification Logic</th>\n<th>User Guidance</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Initialization phase allocations</td>\n<td>Low - likely legitimate</td>\n<td>Age &gt; program_lifetime * 0.8 → not leak</td>\n<td>Flag as &quot;program lifetime allocation&quot;</td>\n</tr>\n<tr>\n<td>Growing allocation sites</td>\n<td>High - potential leak</td>\n<td><code>total_bytes</code> increasing over time → likely leak</td>\n<td>Report growth rate and call stack</td>\n</tr>\n<tr>\n<td>Cache-like patterns</td>\n<td>Medium - depends on bounds</td>\n<td>Check if growth plateaus → cache, continues → leak</td>\n<td>Monitor allocation rate over time</td>\n</tr>\n<tr>\n<td>Error handling allocations</td>\n<td>Low - typically cleaned up</td>\n<td>Correlate with error events → legitimate</td>\n<td>Cross-check with exception handling</td>\n</tr>\n<tr>\n<td>Thread-local allocations</td>\n<td>Medium - may persist per thread</td>\n<td>Check thread lifetime vs allocation lifetime</td>\n<td>Report per-thread statistics</td>\n</tr>\n</tbody></table>\n<p><strong>Suppression Rules and False Positive Management</strong></p>\n<p>Production applications often have known allocations that appear as leaks but are intentional or unavoidable. A suppression system allows users to filter these known issues while preserving detection of new problems.</p>\n<table>\n<thead>\n<tr>\n<th>Suppression Type</th>\n<th>Matching Logic</th>\n<th>Configuration Format</th>\n<th>Maintenance Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Call stack pattern</td>\n<td>Match function names in allocation stack</td>\n<td>Regex pattern against folded stack</td>\n<td>Version control suppression files</td>\n</tr>\n<tr>\n<td>Allocation size</td>\n<td>Filter allocations of specific sizes</td>\n<td>Size range or exact byte count</td>\n<td>Regular review to prevent over-suppression</td>\n</tr>\n<tr>\n<td>Source location</td>\n<td>Suppress leaks from specific code locations</td>\n<td>File path and line number ranges</td>\n<td>Update suppressions with code changes</td>\n</tr>\n<tr>\n<td>Time-based</td>\n<td>Ignore leaks detected during startup/shutdown</td>\n<td>Time window relative to program lifecycle</td>\n<td>Adjust windows based on application behavior</td>\n</tr>\n<tr>\n<td>Thread-based</td>\n<td>Suppress leaks from specific thread types</td>\n<td>Thread name or creation stack pattern</td>\n<td>Monitor for new thread types</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Confidence-Based Leak Classification</strong></p>\n<ul>\n<li><strong>Context</strong>: Binary leak/not-leak classification produces too many false positives and negatives for practical use</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Binary classification (definite leak or not leak)</li>\n<li>Three-tier system (definite, possible, unlikely)</li>\n<li>Continuous confidence score with user-configurable thresholds</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement confidence scoring with multiple evidence sources</li>\n<li><strong>Rationale</strong>: Allows users to adjust sensitivity based on their tolerance for false positives vs false negatives</li>\n<li><strong>Consequences</strong>: More complex implementation but much more practical for real-world usage</li>\n</ul>\n</blockquote>\n<h4 id=\"allocation-metadata-corruption\">Allocation Metadata Corruption</h4>\n<p>The allocation tracking system maintains metadata for every active allocation, creating a large amount of state that can become corrupted. Metadata corruption leads to incorrect leak detection, crashes during deallocation, or memory usage miscalculations.</p>\n<p><strong>Metadata Integrity Validation</strong></p>\n<p>Each allocation record includes validation information to detect corruption early and prevent cascading failures.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Check</th>\n<th>Implementation</th>\n<th>Trigger Frequency</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Magic number validation</td>\n<td>Store known pattern at beginning of metadata</td>\n<td>Every metadata access</td>\n<td>Mark allocation as corrupted, skip processing</td>\n</tr>\n<tr>\n<td>Checksum verification</td>\n<td>CRC32 of allocation record fields</td>\n<td>Periodic validation pass</td>\n<td>Rebuild metadata from partial information</td>\n</tr>\n<tr>\n<td>Cross-reference validation</td>\n<td>Verify allocation_id matches hash table key</td>\n<td>During lookup operations</td>\n<td>Remove inconsistent entries</td>\n</tr>\n<tr>\n<td>Range validation</td>\n<td>Check that allocation addresses fall within heap</td>\n<td>Before deallocation processing</td>\n<td>Flag as potential corruption</td>\n</tr>\n<tr>\n<td>Thread ID validation</td>\n<td>Verify thread_id corresponds to known thread</td>\n<td>During thread-local operations</td>\n<td>Update with current thread or mark invalid</td>\n</tr>\n</tbody></table>\n<p><strong>Metadata Storage Corruption Recovery</strong></p>\n<p>When metadata storage becomes corrupted, the tracker must continue operating while minimizing data loss and preventing crashes.</p>\n<table>\n<thead>\n<tr>\n<th>Corruption Scenario</th>\n<th>Detection Method</th>\n<th>Immediate Response</th>\n<th>Long-term Recovery</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash table corruption</td>\n<td>Lookup operations return invalid data</td>\n<td>Switch to linear search through backup storage</td>\n<td>Rebuild hash table from valid entries</td>\n</tr>\n<tr>\n<td>Memory pool corruption</td>\n<td>Allocation of new metadata fails</td>\n<td>Use emergency allocation pool</td>\n<td>Compact and defragment memory pool</td>\n</tr>\n<tr>\n<td>Index corruption</td>\n<td>Cannot locate allocation records</td>\n<td>Scan all allocation entries sequentially</td>\n<td>Rebuild index from allocation metadata</td>\n</tr>\n<tr>\n<td>Thread synchronization corruption</td>\n<td>Lock operations fail or deadlock</td>\n<td>Use lock-free fallback operations</td>\n<td>Reset synchronization primitives</td>\n</tr>\n</tbody></table>\n<p><img src=\"/api/project/profiler/architecture-doc/asset?path=diagrams%2Ferror-handling-flow.svg\" alt=\"Error Detection and Recovery\"></p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Ignoring Signal Handler Safety</strong>\nSignal handlers have severe restrictions on what functions they can safely call. Calling malloc, printf, or any non-async-safe function from a signal handler can cause deadlocks or crashes in the target process. The solution is to do minimal work in the signal handler — just capture the stack state and defer all complex processing to a separate thread.</p>\n<p>⚠️ <strong>Pitfall: Not Handling Stripped Binaries</strong>\nProduction binaries often have debug symbols stripped to reduce size. Attempting to parse DWARF information from stripped binaries will fail. Always check for the presence of debug sections before attempting to parse them, and provide graceful fallback to symbol table information or address+offset display.</p>\n<p>⚠️ <strong>Pitfall: Recursive Malloc in Allocation Tracking</strong>\nThe allocation tracker needs memory to store metadata about allocations, but calling malloc from the malloc hook creates infinite recursion. Use thread-local flags to detect recursion and either use pre-allocated buffers or temporarily disable tracking for the tracker&#39;s own allocations.</p>\n<p>⚠️ <strong>Pitfall: Assuming Symbol Lookup Always Succeeds</strong>\nSymbol resolution can fail for many reasons — missing debug info, ASLR complications, corrupted data. Always have fallback display formats that show addresses and module information even when symbol names cannot be resolved. Users need to see something meaningful rather than blank entries or crashes.</p>\n<p>⚠️ <strong>Pitfall: Not Validating Address Ranges During Stack Unwinding</strong>\nStack unwinding can encounter corrupted frame pointers that point to invalid memory addresses. Dereferencing invalid pointers in a signal handler will crash the target process. Always validate that frame pointers fall within legitimate stack ranges before dereferencing them.</p>\n<p>⚠️ <strong>Pitfall: Treating All Allocations as Potential Leaks</strong>\nMany applications legitimately allocate memory that lives for the entire program duration. Flagging all long-lived allocations as leaks creates too much noise. Implement confidence scoring that considers allocation patterns, timing, and growth characteristics to distinguish likely leaks from legitimate long-lived allocations.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Error Detection</td>\n<td>Basic exception handling with try/catch blocks</td>\n<td>Comprehensive error codes with structured logging</td>\n</tr>\n<tr>\n<td>Signal Safety</td>\n<td>Manual async-safe function checking</td>\n<td>Static analysis tools for signal handler validation</td>\n</tr>\n<tr>\n<td>Corruption Detection</td>\n<td>Simple checksums (CRC32)</td>\n<td>ECC memory protection or hardware watchpoints</td>\n</tr>\n<tr>\n<td>Cache Validation</td>\n<td>Periodic full cache rebuilds</td>\n<td>Incremental validation with self-healing data structures</td>\n</tr>\n<tr>\n<td>Leak Detection</td>\n<td>Simple reference counting</td>\n<td>Machine learning classification with confidence scoring</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">profiler</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── error_handling</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py                    ← Error handling module exports</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── sampling_errors.py             ← Stack sampling error recovery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── symbol_errors.py               ← Symbol resolution error handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── memory_errors.py               ← Memory tracking error management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── error_reporter.py              ← Centralized error reporting </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── recovery_strategies.py         ← Automated recovery implementations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── validation</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── </span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">.py                    ← Validation utilities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── stack_validator.py             ← Stack unwinding validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── symbol_validator.py            ← Symbol resolution validation  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── cache_validator.py             ← Cache integrity checking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── metadata_validator.py          ← Allocation metadata validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">└── tests</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ├── test_error_scenarios.py        ← Error injection </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> recovery testing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ├── test_corruption_detection.py   ← Data corruption simulation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    └── test_graceful_degradation.py   ← Degradation behavior verification</span></span></code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete Error Reporting System</strong> (<code>error_reporter.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, List, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict, deque</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ErrorSeverity</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Error severity levels for prioritization and handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INFO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"info\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARNING</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"warning\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"error\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CRITICAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"critical\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ErrorCategory</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Categories of profiler errors for classification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    SAMPLING</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"sampling\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    SYMBOL_RESOLUTION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"symbol_resolution\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MEMORY_TRACKING</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"memory_tracking\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CACHE_CORRUPTION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cache_corruption\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    BUFFER_OVERFLOW</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"buffer_overflow\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ErrorReport</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete error report with context and recovery information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    category: ErrorCategory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    severity: ErrorSeverity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">any</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stack_trace: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recovery_action: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    similar_error_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ErrorReporter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Centralized error reporting and recovery coordination.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_error_history: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_error_history </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_error_history</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.error_history: deque </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_error_history)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.error_counts: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.recovery_handlers: Dict[ErrorCategory, List[Callable]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.suppression_rules: List[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Setup logging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logging.basicConfig(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            level</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">logging.</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            format</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">%(asctime)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(name)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(levelname)s</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">%(message)s</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#9ECBFF\">'profiler.errors'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> report_error</span><span style=\"color:#E1E4E8\">(self, category: ErrorCategory, severity: ErrorSeverity, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    stack_trace: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ErrorReport:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Report an error and trigger appropriate recovery actions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Generate unique error ID based on category and message</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            error_signature </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">category.value</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">{hash</span><span style=\"color:#E1E4E8\">(message)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.error_counts[error_signature] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Create error report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            error_report </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ErrorReport(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">error_signature,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                category</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">category,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                severity</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">severity,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                message</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">message,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                timestamp</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time(),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">context </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> {},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                stack_trace</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">stack_trace,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                recovery_action</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                similar_error_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.error_counts[error_signature]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Check suppression rules</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._is_suppressed(error_report):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> error_report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Add to history</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.error_history.append(error_report)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Log error</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._log_error(error_report)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Trigger recovery if available</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            recovery_action </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._trigger_recovery(error_report)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            error_report.recovery_action </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> recovery_action</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> error_report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_recovery_handler</span><span style=\"color:#E1E4E8\">(self, category: ErrorCategory, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                handler: Callable[[ErrorReport], </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register a recovery handler for specific error categories.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.recovery_handlers[category].append(handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_suppression_rule</span><span style=\"color:#E1E4E8\">(self, rule: Dict):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add rule to suppress specific error patterns.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.suppression_rules.append(rule)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_error_statistics</span><span style=\"color:#E1E4E8\">(self) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get comprehensive error statistics for monitoring.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            total_errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.error_history)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> total_errors </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"total_errors\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            recent_errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [e </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> e </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.error_history </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                           if</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> e.timestamp </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 300</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Last 5 minutes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"total_errors\"</span><span style=\"color:#E1E4E8\">: total_errors,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"recent_errors\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(recent_errors),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"error_rate\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(recent_errors) </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 300.0</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Errors per second</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"categories\"</span><span style=\"color:#E1E4E8\">: defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"severities\"</span><span style=\"color:#E1E4E8\">: defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"top_errors\"</span><span style=\"color:#E1E4E8\">: []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Count by category and severity</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> error </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.error_history:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                stats[</span><span style=\"color:#9ECBFF\">\"categories\"</span><span style=\"color:#E1E4E8\">][error.category.value] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                stats[</span><span style=\"color:#9ECBFF\">\"severities\"</span><span style=\"color:#E1E4E8\">][error.severity.value] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Top error types by frequency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            top_errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.error_counts.items(), </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                              key</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\"> x: x[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], </span><span style=\"color:#FFAB70\">reverse</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)[:</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            stats[</span><span style=\"color:#9ECBFF\">\"top_errors\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> top_errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> dict</span><span style=\"color:#E1E4E8\">(stats)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _is_suppressed</span><span style=\"color:#E1E4E8\">(self, error_report: ErrorReport) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if error matches any suppression rules.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> rule </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.suppression_rules:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._matches_rule(error_report, rule):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _matches_rule</span><span style=\"color:#E1E4E8\">(self, error_report: ErrorReport, rule: Dict) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if error matches a specific suppression rule.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Simple pattern matching - can be extended</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> \"category\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> rule </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> error_report.category.value </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> rule[</span><span style=\"color:#9ECBFF\">\"category\"</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> \"message_pattern\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> rule </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> rule[</span><span style=\"color:#9ECBFF\">\"message_pattern\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> error_report.message:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> \"max_count\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> rule </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> error_report.similar_error_count </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> rule[</span><span style=\"color:#9ECBFF\">\"max_count\"</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _log_error</span><span style=\"color:#E1E4E8\">(self, error_report: ErrorReport):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log error with appropriate level and formatting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        log_message </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"[</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">error_report.category.value</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">] </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">error_report.message</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> error_report.context:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            log_message </span><span style=\"color:#F97583\">+=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\" Context: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">error_report.context</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> error_report.severity </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ErrorSeverity.</span><span style=\"color:#79B8FF\">CRITICAL</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.logger.critical(log_message)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> error_report.severity </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ErrorSeverity.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.logger.error(log_message)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> error_report.severity </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> ErrorSeverity.</span><span style=\"color:#79B8FF\">WARNING</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.logger.warning(log_message)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.logger.info(log_message)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _trigger_recovery</span><span style=\"color:#E1E4E8\">(self, error_report: ErrorReport) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Trigger registered recovery handlers for the error category.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handlers </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.recovery_handlers.get(error_report.category, [])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> handlers:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> handler </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> handlers:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                recovery_description </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> handler(error_report)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> recovery_description:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Recovery action taken: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">recovery_description</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> recovery_description</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Recovery handler failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global error reporter instance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">error_reporter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ErrorReporter()</span></span></code></pre></div>\n\n<p><strong>Complete Validation Framework</strong> (<code>validation/__init__.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Any, List, Optional, Dict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationResult</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validation results with increasing severity.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    VALID</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"valid\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARNING</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"warning\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"error\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CORRUPTED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"corrupted\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationIssue</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Description of a validation problem found.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    result: ValidationResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fix_suggestion: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Validator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for all data validation implementations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self, data: Any) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate data and return list of issues found.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> is_valid</span><span style=\"color:#E1E4E8\">(self, data: Any) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Quick check if data passes validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate(data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> all</span><span style=\"color:#E1E4E8\">(issue.result </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [ValidationResult.</span><span style=\"color:#79B8FF\">VALID</span><span style=\"color:#E1E4E8\">, ValidationResult.</span><span style=\"color:#79B8FF\">WARNING</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                  for</span><span style=\"color:#E1E4E8\"> issue </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> issues)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_worst_result</span><span style=\"color:#E1E4E8\">(self, data: Any) -> ValidationResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get the most severe validation result.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate(data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> issues:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ValidationResult.</span><span style=\"color:#79B8FF\">VALID</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return worst result found</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        severities </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [ValidationResult.</span><span style=\"color:#79B8FF\">VALID</span><span style=\"color:#E1E4E8\">, ValidationResult.</span><span style=\"color:#79B8FF\">WARNING</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     ValidationResult.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">, ValidationResult.</span><span style=\"color:#79B8FF\">CORRUPTED</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        worst </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ValidationResult.</span><span style=\"color:#79B8FF\">VALID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> issue </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> issues:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> severities.index(issue.result) </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> severities.index(worst):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                worst </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> issue.result</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> worst</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_address_range</span><span style=\"color:#E1E4E8\">(address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, min_addr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, max_addr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"address\"</span><span style=\"color:#E1E4E8\">) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate that an address falls within expected range.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> address </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> min_addr </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> address </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> max_addr:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues.append(ValidationIssue(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ValidationResult.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> 0x</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">address</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> outside valid range [0x</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">min_addr</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, 0x</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">max_addr</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">]\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"address\"</span><span style=\"color:#E1E4E8\">: address, </span><span style=\"color:#9ECBFF\">\"min_addr\"</span><span style=\"color:#E1E4E8\">: min_addr, </span><span style=\"color:#9ECBFF\">\"max_addr\"</span><span style=\"color:#E1E4E8\">: max_addr},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            fix_suggestion</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Check address calculation or memory mapping\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_not_null</span><span style=\"color:#E1E4E8\">(value: Any, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"value\"</span><span style=\"color:#E1E4E8\">) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate that a value is not None or NULL.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> value </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">isinstance</span><span style=\"color:#E1E4E8\">(value, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> value </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues.append(ValidationIssue(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ValidationResult.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> is null or zero\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"value\"</span><span style=\"color:#E1E4E8\">: value},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            fix_suggestion</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Initialize value before use\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_buffer_bounds</span><span style=\"color:#E1E4E8\">(buffer_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          current_usage: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate buffer size and usage are within bounds.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> buffer_size </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> max_size:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues.append(ValidationIssue(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ValidationResult.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Buffer size </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">buffer_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> exceeds maximum </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">max_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"buffer_size\"</span><span style=\"color:#E1E4E8\">: buffer_size, </span><span style=\"color:#9ECBFF\">\"max_size\"</span><span style=\"color:#E1E4E8\">: max_size},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            fix_suggestion</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Increase max_size or reduce buffer requirements\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> current_usage </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> buffer_size:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues.append(ValidationIssue(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ValidationResult.</span><span style=\"color:#79B8FF\">CORRUPTED</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Buffer usage </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">current_usage</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> exceeds size </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">buffer_size</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"usage\"</span><span style=\"color:#E1E4E8\">: current_usage, </span><span style=\"color:#9ECBFF\">\"size\"</span><span style=\"color:#E1E4E8\">: buffer_size},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            fix_suggestion</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Buffer overflow detected - check bounds checking\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    usage_ratio </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_usage </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> buffer_size </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> buffer_size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> usage_ratio </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.9</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues.append(ValidationIssue(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            result</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ValidationResult.</span><span style=\"color:#79B8FF\">WARNING</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Buffer </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">usage_ratio</span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">% full, approaching capacity\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"usage_ratio\"</span><span style=\"color:#E1E4E8\">: usage_ratio},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            fix_suggestion</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Consider increasing buffer size or improving processing rate\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> issues</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Sampling Error Recovery</strong> (<code>sampling_errors.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> signal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data_model </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Sample, StackFrame, RegisterContext, BufferStats</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Validator, ValidationIssue, ValidationResult</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..error_handling </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> error_reporter, ErrorCategory, ErrorSeverity</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackValidator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Validator</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validates stack frames and call chains for corruption.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, min_stack_addr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, max_stack_addr: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.min_stack_addr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> min_stack_addr</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_stack_addr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_stack_addr</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self, stack_frames: List[StackFrame]) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate entire call stack for consistency and corruption.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check that stack is not empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate each frame address is within stack bounds  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check for circular references in frame pointer chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify forward progress (each frame deeper in stack)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate instruction pointers are in executable memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Check for suspiciously long call chains (> MAX_STACK_DEPTH)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Detect frame pointer corruption patterns</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SamplingErrorRecovery</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles errors and recovery during stack sampling operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: </span><span style=\"color:#9ECBFF\">'SamplingConfig'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.consecutive_failures </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.last_successful_sample </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.signal_delivery_failures </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stack_validator </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # Initialize with actual stack bounds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_signal_delivery_failure</span><span style=\"color:#E1E4E8\">(self, target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                     expected_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                     actual_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle failed or delayed signal delivery to target process.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate signal delivery success rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if failure rate exceeds threshold (> 10%)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Determine likely cause (blocked signals, process state, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Report error with appropriate severity level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Decide whether to continue sampling or abort</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Implement adaptive frequency reduction if needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return True if recovery successful, False if should abort</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> recover_from_stack_corruption</span><span style=\"color:#E1E4E8\">(self, context: RegisterContext, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                    partial_stack: List[StackFrame]) -> Optional[List[StackFrame]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Attempt to recover usable stack information from corrupted unwind.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate existing frames in partial stack</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt alternative unwinding method (DWARF vs frame pointer)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check if instruction pointer is in known good location</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Truncate stack at first sign of corruption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add synthetic frame for current function if possible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Mark recovered stack with quality indicator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return best possible stack or None if completely unusable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_buffer_overflow</span><span style=\"color:#E1E4E8\">(self, buffer_stats: BufferStats) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle sample buffer overflow with appropriate recovery strategy.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate current buffer utilization and drop rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Determine if overflow is transient burst or sustained overload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Implement emergency sample dropping with priority preservation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Reduce sampling frequency if sustained overload detected</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Report buffer health statistics to user</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return description of recovery action taken</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"recovery_action_description\"</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_sample_integrity</span><span style=\"color:#E1E4E8\">(self, sample: Sample) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate that a captured sample contains reasonable data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check sample timestamp is reasonable (not in future, not too old)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate thread_id and process_id are positive integers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Ensure stack_frames list is not empty and not too long</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate each stack frame using StackValidator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check sample_weight is positive</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return True only if sample passes all validation checks</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">  # Placeholder</span></span></code></pre></div>\n\n<p><strong>Symbol Resolution Error Handling</strong> (<code>symbol_errors.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data_model </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Symbol, Module, SymbolCache, ELFSymbol</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..validation </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Validator, ValidationIssue, ValidationResult</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..error_handling </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> error_reporter, ErrorCategory, ErrorSeverity</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolErrorRecovery</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles symbol resolution failures and cache corruption recovery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, symbol_cache: SymbolCache):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbol_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> symbol_cache</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.fallback_display_formats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"no_symbol\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"&#x3C;unknown>+0x</span><span style=\"color:#79B8FF\">{offset</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> [</span><span style=\"color:#79B8FF\">{module}</span><span style=\"color:#9ECBFF\">]\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"partial_symbol\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{function}</span><span style=\"color:#9ECBFF\"> (</span><span style=\"color:#79B8FF\">{module}</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"corrupted\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"&#x3C;corrupted>+0x</span><span style=\"color:#79B8FF\">{offset</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> [</span><span style=\"color:#79B8FF\">{module}</span><span style=\"color:#9ECBFF\">]\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"invalid_address\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"&#x3C;invalid address 0x</span><span style=\"color:#79B8FF\">{address</span><span style=\"color:#F97583\">:x</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_missing_debug_symbols</span><span style=\"color:#E1E4E8\">(self, module_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate fallback display when debug symbols are unavailable.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if module has any symbol table information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate offset within module for address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Look for nearest symbol before address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Format fallback string with available information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return formatted string or None if address is invalid</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_aslr_bias_error</span><span style=\"color:#E1E4E8\">(self, module: Module, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             test_addresses: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect incorrect ASLR bias calculation and compute correct bias.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Try resolving test addresses with current bias</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If resolution fails, scan /proc/pid/maps for actual load address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate correct bias from runtime vs link-time addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate new bias resolves test addresses correctly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return correct bias or None if unable to determine</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> recover_from_cache_corruption</span><span style=\"color:#E1E4E8\">(self, corruption_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Recover symbol cache from detected corruption.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Determine extent of corruption (partial vs complete)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Save any validated cache entries to backup storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Clear corrupted cache segments</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Reload symbol tables from original binary files</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Rebuild cache with saved entries and fresh data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Validate rebuilt cache passes integrity checks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return True if recovery successful</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_dwarf_parsing</span><span style=\"color:#E1E4E8\">(self, dwarf_data: </span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             expected_checksum: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ValidationResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate DWARF debug information before parsing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check DWARF section headers for correct magic numbers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate version number is supported</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify section sizes match header declarations  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for truncated data or premature EOF</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate optional checksum if provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return validation result with severity level</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> ValidationResult.</span><span style=\"color:#79B8FF\">VALID</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_symbol_quality_report</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">any</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate comprehensive report on symbol resolution quality.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate symbol cache hit/miss rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Count symbols by resolution quality (complete, partial, missing)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Identify modules with poor symbol coverage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Report DWARF parsing success/failure rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: List top addresses that failed resolution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return structured report dictionary</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {}  </span><span style=\"color:#6A737D\"># Placeholder</span></span></code></pre></div>\n\n<p><strong>Memory Tracking Error Management</strong> (<code>memory_errors.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, List, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ctypes </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> CDLL</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..data_model </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Allocation, AllocationSite, MemoryLeak, LeakCategory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..error_handling </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> error_reporter, ErrorCategory, ErrorSeverity</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationTracker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Tracks memory allocations with comprehensive error handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.active_allocations: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Allocation] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.allocation_sites: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, AllocationSite] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.tracker_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.in_tracker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.local()  </span><span style=\"color:#6A737D\"># Recursion detection</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.error_counts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"recursion\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"corruption\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"overflow\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Initialize recursion detection</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.in_tracker.active </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_recursive_malloc</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect if we're already inside allocation tracking to prevent recursion.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check thread-local recursion flag</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return True if recursion detected</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Increment error counter for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_allocation_metadata</span><span style=\"color:#E1E4E8\">(self, allocation: Allocation) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate allocation metadata for corruption or inconsistency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check allocation_id is positive and unique</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate size and actual_size are reasonable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check timestamp is not in future</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate thread_id exists and is positive  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check stack frames are properly formatted</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return list of validation error messages</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> []  </span><span style=\"color:#6A737D\"># Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> recover_from_metadata_corruption</span><span style=\"color:#E1E4E8\">(self, corrupted_allocations: Set[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Recover from corrupted allocation metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Remove clearly corrupted allocation records</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt to reconstruct metadata from partial information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Scan heap for allocations missing from tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update allocation site statistics after cleanup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Reset corruption detection mechanisms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return number of allocations successfully recovered</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> classify_leak_confidence</span><span style=\"color:#E1E4E8\">(self, allocation: Allocation, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                similar_leaks: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate confidence score for potential memory leak.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Consider allocation age relative to program lifetime</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if allocation site shows growth pattern</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Look for similar allocations that were never freed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Consider allocation size and frequency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check if allocation occurred during error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return confidence score between 0.0 and 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">  # Placeholder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_allocation_failure</span><span style=\"color:#E1E4E8\">(self, size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, stack_frames: List[StackFrame]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle case where malloc succeeds but tracking allocation fails.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Log allocation failure with context information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt to allocate tracking metadata with backup method</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If backup fails, increment unknown allocation counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Consider disabling tracking if failure rate too high</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Report failure through error reporting system</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Placeholder</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Error Handling Validation Checkpoints:</strong></p>\n<p>After implementing error handling for each milestone:</p>\n<p><strong>Milestone 1 - Stack Sampling Error Handling:</strong></p>\n<ul>\n<li><strong>Test Command</strong>: <code>python -m pytest tests/test_sampling_errors.py -v</code></li>\n<li><strong>Expected Behavior</strong>: <ul>\n<li>Signal delivery failures detected and reported</li>\n<li>Stack corruption handled without crashing target process</li>\n<li>Buffer overflow triggers frequency reduction</li>\n<li>Sample validation rejects clearly corrupted data</li>\n</ul>\n</li>\n<li><strong>Manual Verification</strong>:<ul>\n<li>Run profiler on process with blocked signals → should report delivery failures</li>\n<li>Profile optimized binary with missing frame pointers → should gracefully degrade</li>\n<li>Set very high sampling frequency → should detect buffer overflow and adapt</li>\n</ul>\n</li>\n</ul>\n<p><strong>Milestone 2 - Symbol Resolution Error Handling:</strong></p>\n<ul>\n<li><strong>Test Command</strong>: <code>python -m pytest tests/test_symbol_errors.py -v</code></li>\n<li><strong>Expected Behavior</strong>:<ul>\n<li>Missing debug symbols produce fallback display formats</li>\n<li>ASLR bias errors detected and corrected automatically  </li>\n<li>Cache corruption triggers rebuild without data loss</li>\n<li>DWARF parsing failures handled gracefully</li>\n</ul>\n</li>\n<li><strong>Manual Verification</strong>:<ul>\n<li>Profile stripped binary → should show <code>&lt;unknown&gt;+offset</code> format</li>\n<li>Profile with corrupted cache → should detect and recover</li>\n<li>Run with invalid symbol search paths → should report missing symbols</li>\n</ul>\n</li>\n</ul>\n<p><strong>Milestone 3 - Flame Graph Error Handling:</strong></p>\n<ul>\n<li><strong>Test Command</strong>: <code>python -m pytest tests/test_flame_graph_errors.py -v</code></li>\n<li><strong>Expected Behavior</strong>:<ul>\n<li>Incomplete symbol resolution produces partial but usable flame graphs</li>\n<li>Coordinate calculation handles edge cases without crashes</li>\n<li>SVG generation continues with missing or corrupted data</li>\n</ul>\n</li>\n<li><strong>Manual Verification</strong>:<ul>\n<li>Generate flame graph with mostly missing symbols → should complete with fallback names</li>\n<li>Create flame graph with extremely deep call stacks → should handle without overflow</li>\n</ul>\n</li>\n</ul>\n<p><strong>Milestone 4 - Memory Tracking Error Handling:</strong></p>\n<ul>\n<li><strong>Test Command</strong>: <code>python -m pytest tests/test_memory_errors.py -v</code></li>\n<li><strong>Expected Behavior</strong>:<ul>\n<li>Recursive malloc calls detected and handled safely</li>\n<li>Metadata corruption detected and recovered from</li>\n<li>Leak classification handles false positives appropriately</li>\n</ul>\n</li>\n<li><strong>Manual Verification</strong>:<ul>\n<li>Profile application with complex allocation patterns → should avoid recursion</li>\n<li>Inject metadata corruption → should detect and recover</li>\n<li>Run on application with legitimate long-lived allocations → should not flag as leaks</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis Method</th>\n<th>Fix Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Profiler crashes target process</td>\n<td>Unsafe signal handler operations</td>\n<td>Check signal handler for non-async-safe calls</td>\n<td>Use only async-safe functions, defer complex work</td>\n</tr>\n<tr>\n<td>Missing samples during CPU-intensive periods</td>\n<td>Signal delivery blocked or delayed</td>\n<td>Monitor signal delivery success rates</td>\n<td>Increase signal priority, check target process state</td>\n</tr>\n<tr>\n<td>Symbol resolution returns wrong functions</td>\n<td>Incorrect ASLR bias calculation</td>\n<td>Cross-validate addresses with /proc/pid/maps</td>\n<td>Recalculate load bias, update module base addresses</td>\n</tr>\n<tr>\n<td>Cache hit rate suddenly drops</td>\n<td>Cache corruption or invalidation</td>\n<td>Check cache integrity, validate stored symbols</td>\n<td>Clear cache, rebuild from symbol tables</td>\n</tr>\n<tr>\n<td>Memory tracker causes infinite recursion</td>\n<td>Malloc called from within malloc hook</td>\n<td>Enable recursion detection logging</td>\n<td>Use thread-local flags, pre-allocate metadata buffers</td>\n</tr>\n<tr>\n<td>Leak detection reports false positives</td>\n<td>Legitimate long-lived allocations flagged</td>\n<td>Analyze allocation patterns and lifetimes</td>\n<td>Implement confidence scoring, add suppression rules</td>\n</tr>\n<tr>\n<td>Stack unwinding produces truncated stacks</td>\n<td>Frame pointer corruption or missing info</td>\n<td>Validate frame pointers before dereferencing</td>\n<td>Add bounds checking, implement DWARF fallback</td>\n</tr>\n<tr>\n<td>Buffer overflow causes sample loss</td>\n<td>Processing cannot keep up with sampling</td>\n<td>Monitor buffer utilization and processing rates</td>\n<td>Reduce sampling frequency, add processing parallelism</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) — comprehensive testing strategy ensures reliable stack sampling, accurate symbol resolution, correct flame graph generation, and robust memory profiling across diverse runtime conditions</p>\n</blockquote>\n<h3 id=\"mental-model-the-quality-assurance-laboratory\">Mental Model: The Quality Assurance Laboratory</h3>\n<p>Think of testing a profiler like running a medical laboratory that analyzes blood samples. Just as a lab needs multiple types of tests — unit tests for individual reagents, integration tests for complete diagnostic workflows, and validation tests against known medical conditions — our profiler testing strategy operates at multiple levels. Unit tests verify individual components work in isolation (like testing if a single reagent changes color correctly), integration tests ensure the complete profiling pipeline produces accurate results (like running a full blood panel), and milestone verification confirms each development stage delivers expected capabilities (like validating diagnostic accuracy against known patient conditions). The challenge is that unlike static blood samples, our profiler must accurately measure living, dynamic programs while introducing minimal measurement disturbance.</p>\n<p>The testing strategy must address the <strong>observer paradox</strong> inherent in profiling tools: the act of measurement potentially changes the behavior being measured. This requires carefully designed test scenarios that validate profiler accuracy without introducing measurement artifacts that could mask real bugs or create false failures.</p>\n<h3 id=\"unit-testing-approach\">Unit Testing Approach</h3>\n<p>Unit testing focuses on validating individual profiler components in isolation using controlled, deterministic test inputs. This approach eliminates external dependencies like signal delivery timing, symbol file availability, or target process behavior that could introduce non-deterministic test failures.</p>\n<h4 id=\"stack-sampling-component-testing\">Stack Sampling Component Testing</h4>\n<p>The <code>StackSampler</code> component requires careful unit testing because it operates through signal delivery and stack unwinding — inherently system-dependent operations. The testing strategy isolates core logic from system interactions by providing mock contexts and controlled stack configurations.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Mock Component</th>\n<th>Test Focus</th>\n<th>Example Scenarios</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signal Context Extraction</td>\n<td>Python signal frame</td>\n<td>Register extraction accuracy</td>\n<td>Valid frame pointer, null stack pointer, corrupted context</td>\n</tr>\n<tr>\n<td>Stack Frame Unwinding</td>\n<td>Memory layout simulation</td>\n<td>Frame pointer traversal</td>\n<td>Deep recursion, leaf functions, corrupted frame chains</td>\n</tr>\n<tr>\n<td>Sample Buffer Management</td>\n<td>Controlled sample injection</td>\n<td>Buffer overflow handling</td>\n<td>Capacity limits, concurrent access, sample ordering</td>\n</tr>\n<tr>\n<td>Timer Configuration</td>\n<td>Mock timer interface</td>\n<td>Frequency validation</td>\n<td>Valid ranges, boundary conditions, frequency conversion</td>\n</tr>\n<tr>\n<td>Thread Safety</td>\n<td>Concurrent test harness</td>\n<td>Signal handler safety</td>\n<td>Multiple threads sampling, signal delivery races</td>\n</tr>\n</tbody></table>\n<p>The unit tests create synthetic stack configurations that represent common execution patterns: recursive function calls, deeply nested library calls, mixed user/kernel stacks, and edge cases like empty stacks or single-frame stacks. These controlled scenarios enable deterministic validation of stack unwinding logic without depending on actual program execution.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Example test data structure for controlled stack scenarios</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SYNTHETIC_STACKS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    'simple_recursion'</span><span style=\"color:#E1E4E8\">: [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff1000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'expected_function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff0f80</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'expected_function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'recursive_func'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400120</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff0f00</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'expected_function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'recursive_func'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    'library_calls'</span><span style=\"color:#E1E4E8\">: [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff1000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'expected_function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7f8000000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff0f80</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'expected_function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'libc_function'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7f8000100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff0f00</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'expected_function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'kernel_syscall'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"symbol-resolution-component-testing\">Symbol Resolution Component Testing</h4>\n<p>The <code>Symbolizer</code> component testing focuses on address-to-symbol mapping accuracy across different binary formats and debug information scenarios. Unit tests use crafted ELF files and symbol tables to validate parsing logic without depending on system-installed binaries.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Mock Input</th>\n<th>Validation Focus</th>\n<th>Edge Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ELF Parsing</td>\n<td>Minimal ELF binaries</td>\n<td>Section header parsing</td>\n<td>Corrupted headers, missing sections, malformed entries</td>\n</tr>\n<tr>\n<td>Symbol Table Loading</td>\n<td>Crafted symbol tables</td>\n<td>Address range calculation</td>\n<td>Overlapping symbols, zero-size symbols, duplicate names</td>\n</tr>\n<tr>\n<td>DWARF Processing</td>\n<td>Synthetic debug info</td>\n<td>Line number mapping</td>\n<td>Inlined functions, optimized code, missing line info</td>\n</tr>\n<tr>\n<td>Address Resolution</td>\n<td>Known address sets</td>\n<td>Lookup accuracy</td>\n<td>Boundary addresses, unmapped regions, ASLR offsets</td>\n</tr>\n<tr>\n<td>Cache Management</td>\n<td>Controlled lookup patterns</td>\n<td>Hit/miss ratios</td>\n<td>Cache eviction, concurrent access, memory pressure</td>\n</tr>\n</tbody></table>\n<p>The unit testing approach generates minimal ELF files containing only essential sections needed for symbol resolution testing. This eliminates dependencies on specific system libraries while enabling comprehensive validation of parsing logic.</p>\n<blockquote>\n<p><strong>Key Testing Insight</strong>: Symbol resolution unit tests must validate both successful resolution paths and graceful failure handling. A robust profiler continues operating when encountering stripped binaries, corrupted debug information, or missing symbol files — common conditions in production environments.</p>\n</blockquote>\n<h4 id=\"flame-graph-generation-component-testing\">Flame Graph Generation Component Testing</h4>\n<p>The <code>FlameGraphGenerator</code> component testing validates stack aggregation algorithms and SVG coordinate calculation logic using deterministic sample sets. Unit tests focus on mathematical correctness of aggregation and layout algorithms rather than visual appearance.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Input Data</th>\n<th>Algorithm Validation</th>\n<th>Expected Output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Stack Aggregation</td>\n<td>Synthetic sample sets</td>\n<td>Tree construction accuracy</td>\n<td>Correct node hierarchy, accurate sample counts</td>\n</tr>\n<tr>\n<td>Folded Stack Generation</td>\n<td>Known call patterns</td>\n<td>Text format compliance</td>\n<td>Standard folded format, proper escaping, count accuracy</td>\n</tr>\n<tr>\n<td>Coordinate Calculation</td>\n<td>Mock flame trees</td>\n<td>Rectangle positioning</td>\n<td>Non-overlapping rectangles, proportional widths, proper nesting</td>\n</tr>\n<tr>\n<td>Color Assignment</td>\n<td>Various node types</td>\n<td>Color scheme consistency</td>\n<td>Deterministic colors, category mapping, contrast validation</td>\n</tr>\n<tr>\n<td>SVG Generation</td>\n<td>Simple flame trees</td>\n<td>XML structure validation</td>\n<td>Valid SVG syntax, proper scaling, embedded JavaScript</td>\n</tr>\n</tbody></table>\n<p>The unit testing strategy creates controlled sample distributions that exercise aggregation edge cases: single-sample stacks, identical call patterns with different frequencies, deeply nested call chains, and wide call trees with many siblings at each level.</p>\n<h4 id=\"memory-profiling-component-testing\">Memory Profiling Component Testing</h4>\n<p>The <code>AllocationTracker</code> component testing requires careful simulation of malloc/free patterns without actual memory allocation. Unit tests use mock allocation interfaces and controlled allocation sequences to validate tracking logic.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Mock Interface</th>\n<th>Tracking Validation</th>\n<th>Leak Detection</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Allocation Recording</td>\n<td>Fake malloc implementation</td>\n<td>Metadata accuracy</td>\n<td>Size tracking, stack capture, timestamp recording</td>\n</tr>\n<tr>\n<td>Deallocation Matching</td>\n<td>Controlled free patterns</td>\n<td>Allocation pairing</td>\n<td>Matching allocation/deallocation pairs, orphaned frees</td>\n</tr>\n<tr>\n<td>Leak Classification</td>\n<td>Synthetic allocation trees</td>\n<td>Confidence scoring</td>\n<td>Definite leaks, possible leaks, reachable allocations</td>\n</tr>\n<tr>\n<td>Growth Pattern Detection</td>\n<td>Time-series allocation data</td>\n<td>Trend analysis</td>\n<td>Linear growth, exponential growth, periodic patterns</td>\n</tr>\n<tr>\n<td>Thread Safety</td>\n<td>Concurrent allocation simulation</td>\n<td>Race condition detection</td>\n<td>Metadata corruption, double-free detection</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Mock-Based Allocation Testing</strong></p>\n<ul>\n<li><strong>Context</strong>: Memory profiling tests need to validate allocation tracking without actual heap operations that could interfere with test process memory management</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Mock malloc/free with fake pointer arithmetic</li>\n<li>Custom memory pool with real allocation tracking</li>\n<li>Process isolation with real malloc interception</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Mock malloc/free with controlled pointer generation</li>\n<li><strong>Rationale</strong>: Enables deterministic test scenarios, eliminates memory management complications in test process, allows exhaustive edge case testing without heap fragmentation concerns</li>\n<li><strong>Consequences</strong>: Tests validate tracking logic accuracy but require separate integration testing for real malloc interception behavior</li>\n</ul>\n</blockquote>\n<h3 id=\"integration-testing\">Integration Testing</h3>\n<p>Integration testing validates the complete profiler pipeline using real target processes and actual system interactions. This testing layer ensures components work correctly together and handle realistic execution environments with proper signal delivery, symbol file parsing, and memory allocation patterns.</p>\n<h4 id=\"end-to-end-profiling-pipeline-testing\">End-to-End Profiling Pipeline Testing</h4>\n<p>The integration testing approach uses purpose-built test programs that exhibit known execution patterns, enabling validation of complete profiling accuracy from sample collection through flame graph generation.</p>\n<p><strong>Test Program Categories:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Program Type</th>\n<th>Execution Pattern</th>\n<th>Expected Profile Characteristics</th>\n<th>Validation Points</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CPU Intensive</td>\n<td>Tight computation loops</td>\n<td>High sample concentration in compute functions</td>\n<td>Sample distribution accuracy, stack depth consistency</td>\n</tr>\n<tr>\n<td>I/O Heavy</td>\n<td>File/network operations</td>\n<td>Samples distributed across I/O and kernel functions</td>\n<td>Kernel stack capture, blocking operation handling</td>\n</tr>\n<tr>\n<td>Memory Allocator</td>\n<td>Intensive malloc/free patterns</td>\n<td>Clear allocation hotspots, leak detection</td>\n<td>Allocation site identification, leak classification accuracy</td>\n</tr>\n<tr>\n<td>Multi-threaded</td>\n<td>Concurrent execution</td>\n<td>Per-thread sample separation, shared code identification</td>\n<td>Thread attribution, sampling fairness</td>\n</tr>\n<tr>\n<td>Dynamic Loading</td>\n<td>Runtime library loading</td>\n<td>Symbol resolution for loaded libraries</td>\n<td>Dynamic symbol updates, ASLR handling</td>\n</tr>\n</tbody></table>\n<p>The integration test harness executes these test programs under profiler control while monitoring both profiler behavior and test program execution characteristics. This dual monitoring approach detects measurement artifacts introduced by profiling overhead.</p>\n<p><strong>Sample Program: CPU Intensive Fibonacci Calculator</strong></p>\n<p>This test program implements recursive Fibonacci calculation with known execution characteristics that enable validation of stack sampling accuracy and symbol resolution correctness.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test program execution pattern</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> fibonacci_test</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test program with predictable call stack patterns\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Expected profile: 80% time in recursive_fibonacci</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Expected stack depth: 20-30 frames for fib(25)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Expected call tree: main -> fibonacci_test -> recursive_fibonacci</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> recursive_fibonacci(</span><span style=\"color:#79B8FF\">25</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>The integration test validates that profiler output matches expected execution characteristics: recursive_fibonacci should consume approximately 80% of samples, maximum stack depth should reach 25-30 frames, and the call tree hierarchy should reflect the recursive calling pattern.</p>\n<h4 id=\"real-world-program-profiling\">Real-World Program Profiling</h4>\n<p>Integration testing includes profiling actual applications with known performance characteristics to validate profiler accuracy in realistic scenarios. These tests use applications where performance bottlenecks are well-understood, enabling verification of profiler analysis correctness.</p>\n<table>\n<thead>\n<tr>\n<th>Application Type</th>\n<th>Known Bottlenecks</th>\n<th>Profiler Validation</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Web Server</td>\n<td>Request parsing, database queries</td>\n<td>Hotspot identification accuracy</td>\n<td>Top functions match known bottlenecks</td>\n</tr>\n<tr>\n<td>Image Processor</td>\n<td>Pixel manipulation loops, memory allocation</td>\n<td>CPU and memory profile correlation</td>\n<td>High allocation sites align with processing functions</td>\n</tr>\n<tr>\n<td>Database Engine</td>\n<td>Index operations, buffer management</td>\n<td>Mixed CPU/memory profiling</td>\n<td>Lock contention and allocation patterns visible</td>\n</tr>\n<tr>\n<td>Scientific Computing</td>\n<td>Mathematical libraries, vectorized operations</td>\n<td>Deep call stacks, optimized code</td>\n<td>SIMD functions identified, proper attribution</td>\n</tr>\n</tbody></table>\n<p>The integration testing framework automatically profiles these applications under controlled workloads and compares profiler output against expected performance patterns. Automated validation checks verify that known performance bottlenecks appear prominently in flame graphs and allocation tracking identifies expected memory-intensive code paths.</p>\n<h4 id=\"cross-platform-validation\">Cross-Platform Validation</h4>\n<p>The integration test suite validates profiler behavior across different operating system configurations, compiler toolchains, and runtime environments to ensure broad compatibility.</p>\n<p><strong>Platform Test Matrix:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Platform</th>\n<th>Compiler</th>\n<th>Debug Info</th>\n<th>Signal Support</th>\n<th>Validation Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Linux x86_64</td>\n<td>GCC</td>\n<td>DWARF 4</td>\n<td>SIGPROF</td>\n<td>Baseline functionality</td>\n</tr>\n<tr>\n<td>Linux ARM64</td>\n<td>GCC</td>\n<td>DWARF 5</td>\n<td>SIGPROF</td>\n<td>Architecture differences</td>\n</tr>\n<tr>\n<td>Linux x86_64</td>\n<td>Clang</td>\n<td>DWARF 4</td>\n<td>SIGPROF</td>\n<td>Compiler variations</td>\n</tr>\n<tr>\n<td>macOS x86_64</td>\n<td>Clang</td>\n<td>DWARF 4</td>\n<td>SIGPROF</td>\n<td>Darwin signal handling</td>\n</tr>\n<tr>\n<td>Linux (stripped)</td>\n<td>GCC</td>\n<td>None</td>\n<td>SIGPROF</td>\n<td>Graceful degradation</td>\n</tr>\n</tbody></table>\n<p>Each platform configuration runs the complete integration test suite to validate consistent profiler behavior across environments. Platform-specific tests verify proper handling of architectural differences like calling conventions, signal delivery mechanisms, and debug information formats.</p>\n<h4 id=\"performance-impact-measurement\">Performance Impact Measurement</h4>\n<p>Integration testing includes overhead measurement to ensure profiler operation remains within acceptable performance impact boundaries defined in project goals. The testing framework measures both profiler resource consumption and target application performance degradation.</p>\n<p><strong>Overhead Measurement Framework:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Measurement Method</th>\n<th>Acceptable Threshold</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CPU Overhead</td>\n<td>Target process CPU time comparison</td>\n<td>&lt; 2% increase</td>\n<td>Reduce sampling frequency</td>\n</tr>\n<tr>\n<td>Memory Overhead</td>\n<td>Profiler process RSS measurement</td>\n<td>&lt; 50MB for typical workloads</td>\n<td>Implement sample streaming</td>\n</tr>\n<tr>\n<td>Sample Loss Rate</td>\n<td>Dropped samples vs. expected samples</td>\n<td>&lt; 1% under normal load</td>\n<td>Increase buffer capacity</td>\n</tr>\n<tr>\n<td>Latency Impact</td>\n<td>Request processing time measurement</td>\n<td>&lt; 5% increase for web workloads</td>\n<td>Optimize signal handler</td>\n</tr>\n<tr>\n<td>Startup Overhead</td>\n<td>Process initialization time</td>\n<td>&lt; 100ms additional startup time</td>\n<td>Lazy symbol loading</td>\n</tr>\n</tbody></table>\n<p>The integration test framework automatically measures these overhead metrics during profiling sessions and validates that measurements remain within acceptable bounds. Tests that exceed overhead thresholds trigger automated analysis to identify performance regression sources.</p>\n<blockquote>\n<p><strong>Critical Integration Testing Principle</strong>: Integration tests must validate profiler accuracy while simultaneously monitoring profiler impact on target processes. A profiler that produces accurate results but significantly alters program behavior fails to meet real-world usability requirements.</p>\n</blockquote>\n<h3 id=\"milestone-verification-checkpoints\">Milestone Verification Checkpoints</h3>\n<p>Milestone verification provides structured validation points that confirm each development stage delivers expected functionality before proceeding to subsequent milestones. Each checkpoint includes automated testing, manual verification steps, and expected output validation.</p>\n<h4 id=\"milestone-1-stack-sampling-verification\">Milestone 1: Stack Sampling Verification</h4>\n<p>The first milestone checkpoint validates that stack sampling infrastructure correctly captures call stacks at configurable frequencies with minimal overhead and proper signal handling.</p>\n<p><strong>Automated Verification Tests:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Name</th>\n<th>Validation Focus</th>\n<th>Success Criteria</th>\n<th>Failure Diagnosis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>test_sampling_frequency</code></td>\n<td>Timer accuracy</td>\n<td>Measured frequency within 5% of configured</td>\n<td>Check timer configuration, signal delivery</td>\n</tr>\n<tr>\n<td><code>test_stack_depth_limits</code></td>\n<td>Stack unwinding bounds</td>\n<td>Respects max_stack_depth configuration</td>\n<td>Verify frame pointer traversal logic</td>\n</tr>\n<tr>\n<td><code>test_signal_handler_safety</code></td>\n<td>Async-safe operations</td>\n<td>No crashes during intensive sampling</td>\n<td>Review signal handler implementation</td>\n</tr>\n<tr>\n<td><code>test_thread_targeting</code></td>\n<td>Thread-specific sampling</td>\n<td>Samples only from target thread</td>\n<td>Check signal delivery targeting</td>\n</tr>\n<tr>\n<td><code>test_kernel_stack_capture</code></td>\n<td>Kernel frame inclusion</td>\n<td>Captures kernel frames when available</td>\n<td>Verify kernel stack access permissions</td>\n</tr>\n</tbody></table>\n<p><strong>Manual Verification Procedure:</strong></p>\n<ol>\n<li><strong>Start Simple Target Process</strong>: Launch a test program with known execution pattern (recursive function calls)</li>\n<li><strong>Configure Profiler</strong>: Set sampling frequency to 100Hz with maximum stack depth of 50 frames</li>\n<li><strong>Collect Samples</strong>: Profile target process for 10 seconds to gather approximately 1000 samples</li>\n<li><strong>Validate Sample Distribution</strong>: Verify samples show expected function frequency distribution</li>\n<li><strong>Check Overhead Impact</strong>: Confirm target process performance degradation remains under 2%</li>\n</ol>\n<p><strong>Expected Output Characteristics:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Sampling Statistics:\n- Target Process: fibonacci_recursive (PID 12345)\n- Configured Frequency: 100Hz\n- Actual Sample Rate: 98.7Hz (within tolerance)\n- Total Samples Collected: 987\n- Average Stack Depth: 23.4 frames\n- Kernel Frames Captured: 156 (15.8%)\n- Signal Delivery Failures: 2 (0.2%)\n- Overhead Estimate: 1.3%</code></pre></div>\n\n<p><strong>Milestone 1 Success Criteria:</strong></p>\n<ul>\n<li>Sample collection rate within 5% of configured frequency</li>\n<li>No signal handler crashes during extended sampling periods</li>\n<li>Stack depth distribution matches target program characteristics</li>\n<li>Overhead measurements below 2% CPU impact</li>\n<li>Thread-specific sampling correctly isolates target thread activity</li>\n</ul>\n<h4 id=\"milestone-2-symbol-resolution-verification\">Milestone 2: Symbol Resolution Verification</h4>\n<p>The second milestone checkpoint validates that symbol resolution correctly converts raw addresses to function names and source locations across different binary formats and debug information scenarios.</p>\n<p><strong>Automated Verification Tests:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Name</th>\n<th>Validation Focus</th>\n<th>Success Criteria</th>\n<th>Failure Diagnosis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>test_elf_symbol_loading</code></td>\n<td>Binary parsing accuracy</td>\n<td>All expected symbols loaded from test binary</td>\n<td>Check ELF parsing logic, symbol table access</td>\n</tr>\n<tr>\n<td><code>test_address_resolution</code></td>\n<td>Address-to-symbol mapping</td>\n<td>Known addresses resolve to expected function names</td>\n<td>Verify symbol lookup algorithm, address ranges</td>\n</tr>\n<tr>\n<td><code>test_dwarf_line_numbers</code></td>\n<td>Source location accuracy</td>\n<td>Addresses map to correct source files and line numbers</td>\n<td>Check DWARF parsing, line number tables</td>\n</tr>\n<tr>\n<td><code>test_shared_library_symbols</code></td>\n<td>Dynamic library support</td>\n<td>Resolves symbols from loaded shared libraries</td>\n<td>Verify library enumeration, ASLR handling</td>\n</tr>\n<tr>\n<td><code>test_symbol_cache_performance</code></td>\n<td>Cache hit rates</td>\n<td>Cache hit rate above 80% for repeated lookups</td>\n<td>Tune cache size, eviction policy</td>\n</tr>\n</tbody></table>\n<p><strong>Manual Verification Procedure:</strong></p>\n<ol>\n<li><strong>Prepare Test Binary</strong>: Compile test program with debug information using <code>-g</code> flag</li>\n<li><strong>Load Symbol Information</strong>: Initialize symbolizer with test binary and verify symbol count</li>\n<li><strong>Resolve Known Addresses</strong>: Test address resolution for main function, library calls, and edge cases</li>\n<li><strong>Validate Source Mapping</strong>: Confirm DWARF line number mapping for several known code locations</li>\n<li><strong>Test Graceful Degradation</strong>: Verify behavior with stripped binaries and missing debug information</li>\n</ol>\n<p><strong>Expected Output Characteristics:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Symbol Resolution Statistics:\n- Binary: /tmp/test_program (ELF 64-bit)\n- Symbols Loaded: 1,247 functions\n- Debug Information: DWARF 4 (available)\n- Address Resolution Success Rate: 94.2%\n- Cache Hit Rate: 87.3%\n- Average Lookup Time: 0.12ms\n- Missing Symbols: 73 (stripped library functions)\n- Source File Coverage: 89.6% of samples</code></pre></div>\n\n<p><strong>Milestone 2 Success Criteria:</strong></p>\n<ul>\n<li>Successfully loads symbols from ELF binaries with standard toolchains</li>\n<li>Resolves over 90% of addresses from debug-enabled binaries</li>\n<li>Provides graceful fallback for addresses without available symbols</li>\n<li>Symbol cache achieves hit rates above 80% during typical profiling</li>\n<li>DWARF parsing correctly maps addresses to source files and line numbers</li>\n</ul>\n<h4 id=\"milestone-3-flame-graph-generation-verification\">Milestone 3: Flame Graph Generation Verification</h4>\n<p>The third milestone checkpoint validates that flame graph generation correctly aggregates stack samples and produces interactive visualizations that accurately represent program execution patterns.</p>\n<p><strong>Automated Verification Tests:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Name</th>\n<th>Validation Focus</th>\n<th>Success Criteria</th>\n<th>Failure Diagnosis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>test_stack_aggregation</code></td>\n<td>Sample folding accuracy</td>\n<td>Identical stacks properly merged with correct counts</td>\n<td>Check aggregation algorithm, stack comparison logic</td>\n</tr>\n<tr>\n<td><code>test_flame_tree_construction</code></td>\n<td>Hierarchical structure</td>\n<td>Tree reflects calling relationships accurately</td>\n<td>Verify parent-child relationships, node creation</td>\n</tr>\n<tr>\n<td><code>test_svg_coordinate_calculation</code></td>\n<td>Layout mathematics</td>\n<td>Rectangle positions and widths match sample proportions</td>\n<td>Check coordinate calculation, scaling logic</td>\n</tr>\n<tr>\n<td><code>test_interactive_features</code></td>\n<td>SVG functionality</td>\n<td>Zoom and search features work correctly</td>\n<td>Test JavaScript embedding, event handling</td>\n</tr>\n<tr>\n<td><code>test_color_scheme_consistency</code></td>\n<td>Visual coherence</td>\n<td>Colors consistently represent function categories</td>\n<td>Verify color assignment algorithm</td>\n</tr>\n</tbody></table>\n<p><strong>Manual Verification Procedure:</strong></p>\n<ol>\n<li><strong>Generate Test Profile</strong>: Create profile data with known stack patterns and sample distributions</li>\n<li><strong>Build Flame Graph</strong>: Generate SVG flame graph and verify visual structure matches expectations</li>\n<li><strong>Validate Proportions</strong>: Confirm rectangle widths accurately represent relative sample counts</li>\n<li><strong>Test Interactivity</strong>: Verify zoom functionality and search features work in web browser</li>\n<li><strong>Check Color Coding</strong>: Ensure consistent color assignment for function categories</li>\n</ol>\n<p><strong>Expected Output Characteristics:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Flame Graph Generation Statistics:\n- Input Samples: 10,000 stack traces\n- Unique Call Stacks: 1,247 distinct patterns\n- Aggregated Nodes: 3,891 flame graph nodes\n- Maximum Stack Depth: 42 frames\n- SVG File Size: 2.3MB\n- Rectangle Count: 3,891 drawable elements\n- Color Categories: User (45%), Libraries (38%), Kernel (17%)\n- Generation Time: 0.8 seconds</code></pre></div>\n\n<p><strong>Milestone 3 Success Criteria:</strong></p>\n<ul>\n<li>Stack aggregation correctly merges identical call patterns</li>\n<li>Flame graph proportions accurately reflect sample distribution</li>\n<li>Interactive features (zoom, search) function correctly in standard browsers</li>\n<li>Color coding consistently distinguishes function categories</li>\n<li>Generated SVG files load and render properly across different viewing environments</li>\n</ul>\n<h4 id=\"milestone-4-memory-profiling-verification\">Milestone 4: Memory Profiling Verification</h4>\n<p>The fourth milestone checkpoint validates that memory profiling correctly tracks allocations, detects leaks, and identifies allocation hotspots with acceptable overhead for allocation-intensive programs.</p>\n<p><strong>Automated Verification Tests:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Name</th>\n<th>Validation Focus</th>\n<th>Success Criteria</th>\n<th>Failure Diagnosis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>test_allocation_interception</code></td>\n<td>Function hooking</td>\n<td>All malloc/free calls captured correctly</td>\n<td>Check LD_PRELOAD setup, hook installation</td>\n</tr>\n<tr>\n<td><code>test_allocation_tracking</code></td>\n<td>Metadata accuracy</td>\n<td>Allocation size and stack traces recorded properly</td>\n<td>Verify tracking data structures, thread safety</td>\n</tr>\n<tr>\n<td><code>test_leak_detection_accuracy</code></td>\n<td>Leak classification</td>\n<td>Correctly identifies definite vs. possible leaks</td>\n<td>Check leak detection algorithm, reachability analysis</td>\n</tr>\n<tr>\n<td><code>test_allocation_site_analysis</code></td>\n<td>Hotspot identification</td>\n<td>Top allocation sites ranked by total bytes correctly</td>\n<td>Verify aggregation logic, call stack hashing</td>\n</tr>\n<tr>\n<td><code>test_memory_overhead</code></td>\n<td>Tracking impact</td>\n<td>Metadata overhead remains below 10% of tracked allocations</td>\n<td>Optimize tracking structures, measure overhead</td>\n</tr>\n</tbody></table>\n<p><strong>Manual Verification Procedure:</strong></p>\n<ol>\n<li><strong>Prepare Allocation Test Program</strong>: Create program with known allocation patterns and intentional leaks</li>\n<li><strong>Enable Memory Tracking</strong>: Launch program with allocation interception enabled</li>\n<li><strong>Execute Allocation Workload</strong>: Run program through allocation-intensive operations</li>\n<li><strong>Analyze Allocation Report</strong>: Verify hotspot identification and leak detection accuracy</li>\n<li><strong>Validate Overhead Impact</strong>: Confirm memory tracking overhead remains acceptable</li>\n</ol>\n<p><strong>Expected Output Characteristics:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Memory Profiling Statistics:\n- Tracked Allocations: 45,672 malloc calls\n- Peak Live Allocations: 12,389 active allocations\n- Total Bytes Allocated: 247.8 MB\n- Detected Leaks: 23 definite, 7 possible\n- Top Allocation Site: image_processing.c:142 (45.2 MB total)\n- Average Allocation Size: 5,428 bytes\n- Allocation Tracking Overhead: 7.3% memory increase\n- Processing Time: 2.1 seconds analysis</code></pre></div>\n\n<p><strong>Milestone 4 Success Criteria:</strong></p>\n<ul>\n<li>Allocation interception captures all heap operations without missed calls</li>\n<li>Leak detection accurately identifies intentional leaks in test programs</li>\n<li>Allocation site analysis correctly ranks hotspots by memory consumption</li>\n<li>Memory tracking overhead remains below 10% for typical allocation patterns</li>\n<li>Memory profiling integrates with existing flame graph generation for combined analysis</li>\n</ul>\n<blockquote>\n<p><strong>Comprehensive Milestone Validation</strong>: Each milestone builds upon previous achievements, requiring regression testing to ensure new functionality doesn&#39;t break existing capabilities. The final validation confirms all four milestones work together as an integrated profiling system.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The testing infrastructure requires careful setup to handle the unique challenges of testing a profiling tool. The implementation provides both automated test frameworks and manual verification procedures that developers can use to validate their profiler implementation at each development stage.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Test Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unit Testing Framework</td>\n<td><code>pytest</code> with basic assertions</td>\n<td><code>pytest</code> with <code>pytest-mock</code> and <code>hypothesis</code> property testing</td>\n</tr>\n<tr>\n<td>Process Management</td>\n<td><code>subprocess</code> module for test program control</td>\n<td><code>psutil</code> for detailed process monitoring and resource tracking</td>\n</tr>\n<tr>\n<td>Binary Generation</td>\n<td>Hand-crafted minimal ELF files</td>\n<td><code>pyelftools</code> for programmatic ELF construction</td>\n</tr>\n<tr>\n<td>SVG Validation</td>\n<td>String parsing and basic XML checks</td>\n<td><code>lxml</code> with XSD schema validation for proper SVG structure</td>\n</tr>\n<tr>\n<td>Performance Measurement</td>\n<td>Simple time/memory comparisons</td>\n<td><code>py-spy</code> or similar for independent profiler validation</td>\n</tr>\n<tr>\n<td>Mock Data Generation</td>\n<td>Static test data files</td>\n<td><code>factory_boy</code> for dynamic test data generation</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<p>The testing infrastructure should be organized to support both component isolation and integration testing workflows:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler-project/\n├── src/\n│   ├── profiler/\n│   │   ├── sampling.py          # Stack sampling implementation\n│   │   ├── symbols.py           # Symbol resolution implementation\n│   │   ├── flamegraph.py        # Flame graph generation\n│   │   └── memory.py            # Memory profiling implementation\n│   └── common/\n│       ├── data_structures.py   # Core data types\n│       └── config.py            # Configuration management\n├── tests/\n│   ├── unit/\n│   │   ├── test_sampling.py     # Stack sampling unit tests\n│   │   ├── test_symbols.py      # Symbol resolution unit tests\n│   │   ├── test_flamegraph.py   # Flame graph unit tests\n│   │   └── test_memory.py       # Memory profiling unit tests\n│   ├── integration/\n│   │   ├── test_end_to_end.py   # Complete profiling pipeline tests\n│   │   ├── test_real_programs.py # Real application profiling tests\n│   │   └── test_performance.py  # Overhead measurement tests\n│   ├── fixtures/\n│   │   ├── test_programs/       # Purpose-built test applications\n│   │   ├── sample_binaries/     # Test ELF files with known symbols\n│   │   └── expected_outputs/    # Reference flame graphs and reports\n│   └── conftest.py              # Pytest configuration and shared fixtures\n├── tools/\n│   ├── test_program_builder.py  # Generates test programs with known patterns\n│   ├── overhead_monitor.py      # Measures profiler performance impact\n│   └── milestone_validator.py   # Automated milestone checkpoint verification\n└── docs/\n    └── testing_guide.md         # Manual testing procedures and troubleshooting</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Complete Test Program Generator</strong> (handles the complexity of creating programs with predictable execution patterns):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tools/test_program_builder.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Generates test programs with known execution characteristics for profiler validation.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestProgramSpec</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Specification for generating a test program with predictable behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    execution_pattern: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">  # 'cpu_intensive', 'io_heavy', 'memory_allocator', 'recursive'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    runtime_seconds: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expected_hotspots: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Function names that should appear prominently in profile</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_pattern: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]  </span><span style=\"color:#6A737D\"># Memory allocation characteristics</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestProgramBuilder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Builds test programs with known execution patterns for profiler validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, output_dir: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"/tmp/profiler_test_programs\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.output_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output_dir</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        os.makedirs(output_dir, </span><span style=\"color:#FFAB70\">exist_ok</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> build_cpu_intensive_program</span><span style=\"color:#E1E4E8\">(self, spec: TestProgramSpec) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate CPU-intensive test program with predictable hotspots.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        program_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'''</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">#include &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">#include &#x3C;time.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">// Expected hotspot: recursive_fibonacci should consume ~80% of samples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">long recursive_fibonacci(int n) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    if (n &#x3C;= 1) return n;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return recursive_fibonacci(n-1) + recursive_fibonacci(n-2);</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">}}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">// Expected hotspot: busy_computation should consume ~15% of samples  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">void busy_computation(int iterations) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    volatile long sum = 0;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    for (int i = 0; i &#x3C; iterations; i++) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        sum += i * i;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    }}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">}}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">int main() </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    clock_t start = clock();</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    while ((double)(clock() - start) / CLOCKS_PER_SEC &#x3C; </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">spec.runtime_seconds</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        // This creates predictable call stack pattern for validation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        recursive_fibonacci(20);  // Creates deep recursive stacks</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        busy_computation(1000);   // Creates flat computation profile</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    }}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return 0;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">}}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">'''</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._compile_program(spec.name, program_code)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> build_memory_allocator_program</span><span style=\"color:#E1E4E8\">(self, spec: TestProgramSpec) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate memory-intensive test program with known allocation patterns.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        program_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">'''</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">#include &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">#include &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">#include &#x3C;time.h></span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">#include &#x3C;string.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">// Expected allocation hotspot: large_allocations</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">void* large_allocations(size_t count, size_t size) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    void** ptrs = malloc(count * sizeof(void*));</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    for (size_t i = 0; i &#x3C; count; i++) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        ptrs[i] = malloc(size);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        memset(ptrs[i], 0, size);  // Touch allocated memory</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    }}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return ptrs;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">}}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">// Expected leak: intentional_leak never frees allocated memory</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">void intentional_leak(size_t size) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    void* ptr = malloc(size);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    memset(ptr, 0xAB, size);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    // Intentionally not freed - should appear in leak report</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">}}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">int main() </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    clock_t start = clock();</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    void* large_ptr = NULL;</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    while ((double)(clock() - start) / CLOCKS_PER_SEC &#x3C; </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">spec.runtime_seconds</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">) </span><span style=\"color:#79B8FF\">{{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        // Pattern: large allocations that get freed</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        large_ptr = large_allocations(100, 1024);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        free(large_ptr);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        // Pattern: small leaks that accumulate  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        intentional_leak(64);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        // Pattern: temporary allocations with short lifetime</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        void* temp = malloc(256);</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        free(temp);</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    }}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    return 0;</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">}}</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">'''</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._compile_program(spec.name, program_code, </span><span style=\"color:#FFAB70\">debug_symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _compile_program</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, source_code: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, debug_symbols: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compile test program and return path to executable.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        source_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> os.path.join(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.output_dir, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">.c\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        binary_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> os.path.join(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.output_dir, name)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(source_path, </span><span style=\"color:#9ECBFF\">'w'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            f.write(source_code)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        compile_cmd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">'gcc'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-o'</span><span style=\"color:#E1E4E8\">, binary_path, source_path]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> debug_symbols:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            compile_cmd.extend([</span><span style=\"color:#9ECBFF\">'-g'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'-O1'</span><span style=\"color:#E1E4E8\">])  </span><span style=\"color:#6A737D\"># Light optimization to keep realistic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> subprocess.run(compile_cmd, </span><span style=\"color:#FFAB70\">capture_output</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">text</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> result.returncode </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> RuntimeError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Compilation failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result.stderr</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> binary_path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_standard_test_suite</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create complete set of standard test programs.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        test_specs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            TestProgramSpec(</span><span style=\"color:#9ECBFF\">\"cpu_intensive\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"recursive\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5.0</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          [</span><span style=\"color:#9ECBFF\">\"recursive_fibonacci\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"busy_computation\"</span><span style=\"color:#E1E4E8\">], {}),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            TestProgramSpec(</span><span style=\"color:#9ECBFF\">\"memory_allocator\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"allocation\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          [</span><span style=\"color:#9ECBFF\">\"large_allocations\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"intentional_leak\"</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          {</span><span style=\"color:#9ECBFF\">\"leak_size\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"large_alloc_size\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        programs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> spec </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> test_specs:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> spec.execution_pattern </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"recursive\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                programs[spec.name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.build_cpu_intensive_program(spec)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> spec.execution_pattern </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> \"allocation\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                programs[spec.name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.build_memory_allocator_program(spec)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> programs</span></span></code></pre></div>\n\n<p><strong>Complete Overhead Measurement Framework</strong> (measures profiler impact on target processes):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tools/overhead_monitor.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Measures profiler overhead and validates performance impact stays within bounds.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> psutil</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceMetrics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Performance measurements for overhead analysis.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cpu_time_seconds: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    memory_rss_bytes: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wall_clock_seconds: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context_switches: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    page_faults: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> OverheadReport</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comparison of performance with and without profiling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    baseline_metrics: PerformanceMetrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    profiled_metrics: PerformanceMetrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cpu_overhead_percent: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    memory_overhead_bytes: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    acceptable_overhead: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> OverheadMonitor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Measures and validates profiler performance overhead.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_cpu_overhead: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span><span style=\"color:#E1E4E8\">, max_memory_mb: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 50.0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_cpu_overhead </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_cpu_overhead</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_memory_mb </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_memory_mb</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> measure_baseline_performance</span><span style=\"color:#E1E4E8\">(self, test_program_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   runtime_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> PerformanceMetrics:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run test program without profiling to establish baseline performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._run_and_measure(test_program_path, runtime_seconds)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> measure_profiled_performance</span><span style=\"color:#E1E4E8\">(self, test_program_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   runtime_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   profiler_config: Dict) -> PerformanceMetrics:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run test program under profiler and measure performance impact.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Launch profiler with specified configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Start target program as child process  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Monitor both profiler and target process metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Stop profiling after runtime_seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return combined performance metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use psutil to monitor both processes simultaneously</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _run_and_measure</span><span style=\"color:#E1E4E8\">(self, program_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, runtime_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> PerformanceMetrics:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute program and collect detailed performance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Start process and get initial measurements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        process </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> subprocess.Popen([program_path])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        psutil_process </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil.Process(process.pid)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        initial_cpu_times </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil_process.cpu_times()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        initial_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil_process.memory_info()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        initial_ctx_switches </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil_process.num_ctx_switches()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Wait for completion</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        process.wait()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Get final measurements</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        final_cpu_times </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil_process.cpu_times()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        final_memory </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil_process.memory_info()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        final_ctx_switches </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil_process.num_ctx_switches()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wall_clock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> PerformanceMetrics(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            cpu_time_seconds</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">final_cpu_times.user </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> initial_cpu_times.user,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            memory_rss_bytes</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">max</span><span style=\"color:#E1E4E8\">(final_memory.rss, initial_memory.rss),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            wall_clock_seconds</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">wall_clock,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context_switches</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">final_ctx_switches.voluntary </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> initial_ctx_switches.voluntary,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            page_faults</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">final_memory.rss </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 4096</span><span style=\"color:#6A737D\">  # Rough estimate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_overhead_report</span><span style=\"color:#E1E4E8\">(self, baseline: PerformanceMetrics, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               profiled: PerformanceMetrics) -> OverheadReport:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compare baseline vs profiled performance and validate overhead bounds.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cpu_overhead </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ((profiled.cpu_time_seconds </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> baseline.cpu_time_seconds) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                       /</span><span style=\"color:#E1E4E8\"> baseline.cpu_time_seconds </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        memory_overhead </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> profiled.memory_rss_bytes </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> baseline.memory_rss_bytes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        acceptable </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (cpu_overhead </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_cpu_overhead </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     memory_overhead </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_memory_mb </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> OverheadReport(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            baseline_metrics</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">baseline,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            profiled_metrics</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">profiled,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            cpu_overhead_percent</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">cpu_overhead,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            memory_overhead_bytes</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">memory_overhead,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            acceptable_overhead</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">acceptable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span></code></pre></div>\n\n<h4 id=\"core-logic-testing-skeletons\">Core Logic Testing Skeletons</h4>\n<p><strong>Stack Sampling Test Framework</strong> (validates sampling accuracy and signal handling):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/unit/test_sampling.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Unit tests for stack sampling component with mock signal handling.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> unittest.mock </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Mock, patch, MagicMock</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.sampling </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StackSampler, SamplingConfig, Sample, StackFrame</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestStackSampler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test stack sampling with controlled signal scenarios.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_sampling_frequency_accuracy</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate timer configuration produces expected sampling rate.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SamplingConfig(</span><span style=\"color:#FFAB70\">frequency_hz</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">max_stack_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sampler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackSampler(config)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Mock timer interface to control signal delivery timing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Start sampling for known duration (e.g., 1 second)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Count delivered signals and calculate actual frequency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Assert actual frequency within 5% of configured frequency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify timer cleanup on sampling stop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use unittest.mock.patch to mock signal.alarm and signal.signal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_stack_unwinding_accuracy</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate stack frame traversal with synthetic call stacks.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sampler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackSampler(SamplingConfig(</span><span style=\"color:#FFAB70\">frequency_hz</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">max_stack_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Mock execution context representing recursive function calls</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        mock_frames </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff1000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff0f80</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'recursive_func'</span><span style=\"color:#E1E4E8\">},  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400120</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'frame_pointer'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">7fff0f00</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'function'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'recursive_func'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create mock register context from synthetic frame data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Call stack unwinding logic with mock context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify returned stack frames match expected sequence</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Assert frame pointer traversal follows correct chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate stack depth limit enforcement</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Mock the signal frame parameter passed to signal handler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @patch</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">'profiler.sampling.signal'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_signal_handler_safety</span><span style=\"color:#E1E4E8\">(self, mock_signal):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify signal handler only uses async-safe operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sampler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackSampler(SamplingConfig(</span><span style=\"color:#FFAB70\">frequency_hz</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">max_stack_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Install signal handler and verify registration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Simulate rapid signal delivery to test concurrency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify no malloc/free calls in signal handler path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check that sample buffer operations are atomic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate proper signal mask handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Monitor syscalls used during signal handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_sample_buffer_overflow_handling</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate graceful behavior when sample buffer reaches capacity.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SamplingConfig(</span><span style=\"color:#FFAB70\">frequency_hz</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">max_stack_depth</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># High frequency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sampler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> StackSampler(config)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Configure small buffer size to force overflow</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate more samples than buffer capacity  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify oldest samples discarded when buffer full</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check that overflow counter increments correctly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Ensure no memory corruption during overflow</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use mock samples to control buffer filling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Symbol Resolution Test Framework</strong> (validates address-to-symbol mapping):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/unit/test_symbols.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Unit tests for symbol resolution with synthetic ELF data.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> unittest.mock </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Mock, patch</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> profiler.symbols </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Symbolizer, SymbolConfig, Symbol, Module</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestSymbolizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test symbol resolution with controlled binary data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_elf_symbol_table_parsing</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate ELF symbol table parsing with synthetic binary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SymbolConfig(</span><span style=\"color:#FFAB70\">enable_dwarf</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">cache_symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        symbolizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Symbolizer(config)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create synthetic ELF data with known symbol layout</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        synthetic_symbols </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'size'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'FUNC'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'helper_func'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'size'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">50</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'FUNC'</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'global_var'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">600000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'size'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'OBJECT'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Mock ELF file reading to return synthetic symbol data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load symbols from mock binary file  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify all expected symbols loaded with correct addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test symbol lookup for addresses within symbol ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate handling of symbols with zero size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use pyelftools structure mocking for ELF parsing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_address_resolution_with_aslr</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate symbol lookup handles ASLR address offsets correctly.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        symbolizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Symbolizer(SymbolConfig(</span><span style=\"color:#FFAB70\">cache_symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Mock module loaded with ASLR offset</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        base_symbols </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'func1'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'link_address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'size'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'name'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'func2'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'link_address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">1100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'size'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">80</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        aslr_offset </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> 0x</span><span style=\"color:#79B8FF\">7f0000000000</span><span style=\"color:#6A737D\">  # Typical ASLR base</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create module with ASLR-adjusted symbol addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Test address lookup with runtime addresses (link + offset)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify correct symbol returned for offset addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test address ranges at symbol boundaries  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate cache consistency with ASLR adjustments</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Mock /proc/pid/maps parsing for runtime address discovery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_dwarf_line_number_mapping</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate DWARF debug information parsing for source locations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SymbolConfig(</span><span style=\"color:#FFAB70\">enable_dwarf</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">cache_symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        symbolizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Symbolizer(config)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Synthetic DWARF line number table</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        line_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400000</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'file'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main.c'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'line'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'column'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400010</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'file'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'main.c'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'line'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">11</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'column'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">},</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">'address'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">0x</span><span style=\"color:#79B8FF\">400020</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'file'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'helper.c'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'line'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">25</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'column'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Mock DWARF parsing to return synthetic line information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Test address-to-source mapping for known addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify file name and line number accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test handling of addresses between line number entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate graceful handling of missing line information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Mock dwarf.DWARFInfo parsing methods</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_symbol_cache_performance</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate symbol cache hit rates and eviction behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SymbolConfig(</span><span style=\"color:#FFAB70\">cache_symbols</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">symbol_search_paths</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"/tmp\"</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        symbolizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Symbolizer(config)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Populate cache with known symbol set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Perform repeated lookups and measure hit rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test cache eviction under memory pressure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify cache consistency after evictions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Measure lookup performance improvement from caching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Control cache size to force eviction scenarios</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-implementation\">Milestone Checkpoint Implementation</h4>\n<p><strong>Automated Milestone Validation</strong> (verifies each development stage):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tools/milestone_validator.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"Automated validation for profiler implementation milestones.\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MilestoneResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Results from milestone validation check.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    milestone_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    passed: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    test_results: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    performance_metrics: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_messages: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recommendations: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MilestoneValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validates profiler implementation against milestone requirements.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, test_program_dir: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"/tmp/profiler_test_programs\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_program_dir </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> test_program_dir</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.validation_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_1_stack_sampling</span><span style=\"color:#E1E4E8\">(self) -> MilestoneResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 1: Stack sampling implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        test_results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        performance_metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        error_messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test sampling frequency accuracy (within 5% of target)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate stack depth limits enforcement  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check signal handler safety (no crashes under load)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Measure sampling overhead (should be &#x3C; 2%)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Test thread-specific targeting capability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use test programs from TestProgramBuilder</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Example validation structure:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Run cpu_intensive test program under profiler</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            test_program </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> os.path.join(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.test_program_dir, </span><span style=\"color:#9ECBFF\">\"cpu_intensive\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> os.path.exists(test_program):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                error_messages.append(</span><span style=\"color:#9ECBFF\">\"Test program not found - run TestProgramBuilder first\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> MilestoneResult(</span><span style=\"color:#9ECBFF\">\"Milestone 1\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, {}, {}, error_messages, [])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Validate sampling works</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sampling_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._test_basic_sampling(test_program)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            test_results[</span><span style=\"color:#9ECBFF\">\"basic_sampling\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sampling_result.success</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            performance_metrics[</span><span style=\"color:#9ECBFF\">\"sampling_frequency\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sampling_result.measured_frequency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            error_messages.append(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Sampling validation failed: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        passed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> all</span><span style=\"color:#E1E4E8\">(test_results.values()) </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(error_messages) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        recommendations </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._generate_milestone_1_recommendations(test_results, performance_metrics)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> MilestoneResult(</span><span style=\"color:#9ECBFF\">\"Milestone 1\"</span><span style=\"color:#E1E4E8\">, passed, test_results, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             performance_metrics, error_messages, recommendations)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_2_symbol_resolution</span><span style=\"color:#E1E4E8\">(self) -> MilestoneResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 2: Symbol resolution implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test ELF symbol loading from test binaries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate address-to-function name resolution accuracy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check DWARF line number mapping functionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test shared library symbol resolution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Measure symbol cache performance metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_3_flame_graphs</span><span style=\"color:#E1E4E8\">(self) -> MilestoneResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 3: Flame graph generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test stack aggregation produces correct sample counts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate flame graph tree structure reflects call hierarchy  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check SVG generation creates valid XML structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test interactive features (zoom, search) work in browsers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify color coding consistency across different profiles</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_4_memory_profiling</span><span style=\"color:#E1E4E8\">(self) -> MilestoneResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 4: Memory profiling implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test allocation interception captures all malloc/free calls</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate leak detection finds intentional leaks in test programs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check allocation site ranking by memory consumption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Measure memory tracking overhead (should be &#x3C; 10%)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Test integration with flame graph generation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _test_basic_sampling</span><span style=\"color:#E1E4E8\">(self, test_program_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test basic sampling functionality with controlled program.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This would implement actual sampling test logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Returns object with success flag and measured metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_milestone_1_recommendations</span><span style=\"color:#E1E4E8\">(self, test_results: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                            metrics: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate specific recommendations for improving Milestone 1 implementation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        recommendations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> test_results.get(</span><span style=\"color:#9ECBFF\">\"basic_sampling\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            recommendations.append(</span><span style=\"color:#9ECBFF\">\"Check signal handler installation - use signal.signal(signal.SIGPROF, handler)\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> metrics.get(</span><span style=\"color:#9ECBFF\">\"sampling_frequency\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 95</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Less than 95% of target frequency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            recommendations.append(</span><span style=\"color:#9ECBFF\">\"Sampling frequency too low - check timer configuration and signal delivery\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> metrics.get(</span><span style=\"color:#9ECBFF\">\"overhead_percent\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            recommendations.append(</span><span style=\"color:#9ECBFF\">\"Overhead too high - optimize signal handler, reduce stack unwinding work\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> recommendations</span></span></code></pre></div>\n\n<p>This comprehensive testing strategy ensures profiler reliability across all development stages while providing clear validation criteria and debugging guidance for each milestone. The combination of automated testing, manual verification, and structured checkpoints enables systematic profiler development with confidence in correctness and performance characteristics.</p>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) — debugging techniques and common issue resolution for stack sampling, symbol resolution, flame graph generation, and memory profiling implementation</p>\n</blockquote>\n<h3 id=\"mental-model-the-medical-diagnosis-approach\">Mental Model: The Medical Diagnosis Approach</h3>\n<p>Think of debugging a profiler like being a doctor diagnosing a complex patient. The profiler has multiple interconnected systems (sampling, symbols, visualization, memory tracking) that can fail independently or cascade into system-wide problems. Like a doctor, you need systematic diagnostic techniques: observing symptoms, running targeted tests, understanding how systems interact, and applying targeted treatments while monitoring for side effects.</p>\n<p>Just as a doctor doesn&#39;t randomly prescribe medicine but follows a diagnostic process—gathering symptoms, forming hypotheses, running tests, narrowing possibilities—debugging a profiler requires methodical investigation. Some symptoms are obvious (crashes, missing data), while others are subtle (slight sampling bias, memory leaks in the profiler itself). The key is building diagnostic intuition about which symptoms point to which underlying causes.</p>\n<p>The profiler&#39;s complexity comes from its dual nature: it must be transparent to the target program (observer paradox) while capturing detailed execution information under tight performance constraints. This creates debugging challenges unique to systems programming—race conditions in signal handlers, symbol resolution that depends on external debug information, and visualization bugs that only appear with specific call patterns.</p>\n<h3 id=\"stack-sampling-issues\">Stack Sampling Issues</h3>\n<p>Stack sampling represents the most critical and error-prone component because it operates under severe constraints: signal handlers must be async-safe, stack unwinding must handle corrupted or incomplete stack frames, and sampling must maintain precise timing while avoiding observer paradox effects. Understanding these failure modes and their diagnostic signatures enables rapid problem resolution.</p>\n<h4 id=\"signal-handler-problems\">Signal Handler Problems</h4>\n<p>Signal delivery failures manifest in multiple ways that require different diagnostic approaches. The most common pattern is <strong>missing samples</strong> where the profiler receives fewer samples than expected based on the configured sampling frequency. This typically indicates that signals are being dropped, blocked, or handled incorrectly.</p>\n<p><strong>Signal delivery verification</strong> starts with comparing expected vs. actual sample counts. If you configure 100Hz sampling for 10 seconds, you should receive approximately 1000 samples, allowing for some variance due to system scheduling. Significant deviations (less than 90% of expected samples) indicate signal delivery problems.</p>\n<p>The target process might be blocking <code>SIGPROF</code> signals, either intentionally through signal masking or accidentally through long-running system calls. Processes that spend significant time in uninterruptible system calls (like disk I/O) won&#39;t receive timer signals during those periods. You can detect this by monitoring the process&#39;s state in <code>/proc/[pid]/stat</code> and looking for extended periods in &quot;D&quot; (uninterruptible sleep) state.</p>\n<p><strong>Signal handler safety violations</strong> cause the most dangerous and hard-to-reproduce bugs. Signal handlers operate in a restricted environment where only async-safe functions are permitted. Calling non-async-safe functions like <code>malloc</code>, <code>printf</code>, or complex library functions can cause deadlocks, memory corruption, or crashes that appear randomly and are difficult to debug.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Signal handler bugs often manifest as intermittent hangs or crashes that seem unrelated to profiling. The target program might hang during a <code>malloc</code> call because the signal handler interrupted another <code>malloc</code> and then called a non-async-safe function that tries to acquire the same malloc lock.</p>\n</blockquote>\n<p>Common async-safety violations include:</p>\n<table>\n<thead>\n<tr>\n<th>Violation</th>\n<th>Symptom</th>\n<th>Detection Method</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dynamic memory allocation</td>\n<td>Random hangs in malloc/free</td>\n<td>Check signal handler for malloc calls</td>\n<td>Pre-allocate buffers, use async-safe alternatives</td>\n</tr>\n<tr>\n<td>Printf/logging calls</td>\n<td>Deadlocks in output functions</td>\n<td>Look for stdio calls in handler</td>\n<td>Use write() system call or defer logging</td>\n</tr>\n<tr>\n<td>Complex library calls</td>\n<td>Crashes in unexpected locations</td>\n<td>Review handler for non-async-safe functions</td>\n<td>Minimize handler work, defer to main thread</td>\n</tr>\n<tr>\n<td>Mutex operations</td>\n<td>Deadlocks on shared resources</td>\n<td>Check for lock acquisition in handler</td>\n<td>Use atomic operations or lock-free data structures</td>\n</tr>\n</tbody></table>\n<p><strong>Timer configuration errors</strong> appear when the profiler cannot establish the requested sampling frequency. This happens when the requested frequency exceeds system capabilities (attempting 10KHz on a system that can only deliver 1KHz), when multiple profilers compete for timer resources, or when the process lacks sufficient privileges for high-frequency profiling.</p>\n<h4 id=\"stack-unwinding-failures\">Stack Unwinding Failures</h4>\n<p>Stack unwinding transforms the current execution context into a meaningful call chain, but this process can fail in numerous ways that require careful diagnosis. <strong>Frame pointer corruption</strong> represents the most common unwinding failure, where the linked list of stack frames contains invalid pointers that cause segmentation faults or infinite loops during unwinding.</p>\n<p>Modern compilers often optimize away frame pointers for performance, making traditional frame pointer walking impossible. When frame pointers are missing, the unwinder must fall back to DWARF debug information or heuristic-based unwinding, both of which have higher failure rates and performance costs.</p>\n<p><strong>Stripped binary handling</strong> creates scenarios where no symbol information exists for critical parts of the call stack. Stripped binaries contain no symbol table or debug information, so addresses can only be attributed to anonymous memory regions. The profiler must gracefully handle these scenarios by displaying addresses in hex format while continuing to unwind the stack above and below the stripped regions.</p>\n<p><strong>Inlined function handling</strong> complicates unwinding because a single instruction pointer might correspond to multiple logical function calls. The compiler inlines small functions directly into their callers, eliminating the actual function call. DWARF debug information contains inline records that map instruction addresses to multiple function entries, but parsing this information correctly requires sophisticated logic.</p>\n<p>Stack unwinding performance directly affects profiler overhead and accuracy. <strong>Slow unwinding</strong> can cause the profiler to miss subsequent timer signals, creating sampling bias toward functions that are expensive to unwind. Fast leaf functions might be underrepresented if their stacks unwind quickly, while functions with deep or complex call chains might appear overrepresented due to unwinding latency.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The goal isn&#39;t perfect stack traces but statistically representative sampling. It&#39;s better to capture 95% of samples with 90% accuracy than to capture 50% of samples with 100% accuracy, because sampling bias from missed samples creates more analysis errors than minor unwinding inaccuracies.</p>\n</blockquote>\n<p>Common unwinding failures and their diagnostic signatures:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Segfault during unwind</td>\n<td>Profiler crashes with SIGSEGV</td>\n<td>Corrupted frame pointers</td>\n<td>Check frame pointer chain validity before dereferencing</td>\n</tr>\n<tr>\n<td>Infinite unwind loops</td>\n<td>Profiler hangs, stack traces grow without bound</td>\n<td>Circular frame pointer references</td>\n<td>Implement cycle detection and maximum depth limits</td>\n</tr>\n<tr>\n<td>Missing symbols in traces</td>\n<td>Hex addresses instead of function names</td>\n<td>Stripped binaries or missing debug info</td>\n<td>Verify symbol availability and implement fallback display</td>\n</tr>\n<tr>\n<td>Truncated stack traces</td>\n<td>Incomplete call chains</td>\n<td>Unwinding stopped at invalid frame</td>\n<td>Check unwinding termination conditions and error handling</td>\n</tr>\n<tr>\n<td>Biased sampling patterns</td>\n<td>Some functions never appear despite being active</td>\n<td>Unwinding failures causing sample drops</td>\n<td>Monitor unwinding success/failure rates per module</td>\n</tr>\n</tbody></table>\n<h4 id=\"buffer-management-and-data-integrity\">Buffer Management and Data Integrity</h4>\n<p>Sample collection operates under strict performance constraints that make buffer management critical. <strong>Buffer overflow</strong> occurs when the profiler generates samples faster than they can be processed by downstream components. This creates backpressure that must be handled through intelligent dropping policies rather than simply blocking sample collection.</p>\n<p>The sample buffer acts as a decoupling mechanism between the high-frequency sampling process and the lower-frequency symbol resolution and aggregation processes. Buffer sizing requires balancing memory usage against the ability to handle processing bursts without dropping samples.</p>\n<p><strong>Sample corruption</strong> can occur during buffer operations, especially in multi-threaded environments where producer and consumer threads access the buffer concurrently. Corruption manifests as invalid addresses in stack frames, nonsensical timestamps, or impossible thread/process IDs that cause downstream processing failures.</p>\n<p>Lock-free buffer implementations avoid blocking in signal handlers but introduce subtle correctness issues around memory ordering and ABA problems. Traditional locked implementations risk deadlock if a signal arrives while the main thread holds the buffer lock.</p>\n<h3 id=\"symbol-resolution-issues\">Symbol Resolution Issues</h3>\n<p>Symbol resolution transforms raw instruction addresses into human-readable function names and source locations, but this process depends on external debug information that may be missing, corrupted, or incorrectly formatted. Understanding symbol resolution failure modes enables both robust error handling and accurate diagnosis of profiling anomalies.</p>\n<h4 id=\"missing-debug-symbols\">Missing Debug Symbols</h4>\n<p>The most common symbol resolution problem is <strong>missing debug information</strong>, which manifests as hex addresses instead of function names in flame graphs. This occurs when binaries are stripped of symbol tables, when debug packages aren&#39;t installed, or when dynamic libraries are loaded from non-standard locations without corresponding debug information.</p>\n<p>Debug information distribution varies significantly across operating systems and deployment environments. Development systems typically have debug symbols available, while production systems often strip symbols to reduce binary size and deployment complexity. This creates a debugging paradox where performance problems are most critical in production environments that have the least debugging information.</p>\n<p><strong>Symbol package management</strong> becomes critical for effective profiling workflows. Most Linux distributions separate debug symbols into optional packages (like <code>-dbg</code> or <code>-debuginfo</code> packages) that must be explicitly installed. Missing debug packages for system libraries like libc create large gaps in profiling data where critical functions appear as anonymous address ranges.</p>\n<p>Dynamic library symbol resolution requires understanding the runtime linking process. Libraries loaded via <code>dlopen()</code> might not have their symbols immediately available, especially if they&#39;re loaded from non-standard paths or with <code>RTLD_LOCAL</code> visibility. The profiler must track library load events and refresh its symbol tables dynamically.</p>\n<p><strong>JIT-compiled code</strong> presents special challenges because traditional debug information doesn&#39;t exist at compile time. Language runtimes like Python, Java, and JavaScript generate machine code at runtime, but this code exists only in memory without corresponding debug files. Advanced profilers can integrate with runtime symbol APIs, but this requires language-specific knowledge and cooperation from the target process.</p>\n<p>Common missing symbol scenarios:</p>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Manifestation</th>\n<th>Underlying Cause</th>\n<th>Resolution Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Stripped production binaries</td>\n<td>Hex addresses for main application functions</td>\n<td>Symbols removed during build/deploy</td>\n<td>Install debug packages or rebuild with symbols</td>\n</tr>\n<tr>\n<td>Missing system library symbols</td>\n<td>Core library functions show as addresses</td>\n<td>Debug packages not installed</td>\n<td>Install distribution debug packages</td>\n</tr>\n<tr>\n<td>Dynamic library symbols unavailable</td>\n<td>Shared library calls appear anonymous</td>\n<td>Library loaded from non-standard path</td>\n<td>Configure symbol search paths or use LD_DEBUG</td>\n</tr>\n<tr>\n<td>JIT code without symbols</td>\n<td>Runtime-generated code shows as raw addresses</td>\n<td>No debug info for generated code</td>\n<td>Integrate with language-specific symbol APIs</td>\n</tr>\n<tr>\n<td>Kernel symbols missing</td>\n<td>System call and kernel functions anonymous</td>\n<td>Kernel debug info not available</td>\n<td>Install kernel debug packages or enable kallsyms</td>\n</tr>\n</tbody></table>\n<h4 id=\"address-resolution-problems\">Address Resolution Problems</h4>\n<p><strong>Address Space Layout Randomization (ASLR)</strong> complicates symbol resolution by randomizing the base addresses where executables and libraries are loaded. The profiler captures instruction pointers from the live process, but symbol tables contain link-time addresses that don&#39;t account for ASLR offsets. Resolving symbols requires calculating the correct offset between runtime and link-time addresses.</p>\n<p>ASLR bias calculation failures create systematic symbol resolution errors where all addresses in a module are offset by a constant amount. This typically manifests as symbols being attributed to the wrong functions, often offset by exactly the ASLR randomization amount. Detecting this requires comparing resolved addresses against expected function boundaries and validating that instruction addresses fall within reasonable symbol ranges.</p>\n<p><strong>Shared library base address tracking</strong> becomes complex when libraries are mapped multiple times at different addresses, or when address spaces contain multiple versions of the same library. Each mapping requires its own ASLR bias calculation, and the profiler must determine which mapping corresponds to each captured instruction pointer.</p>\n<p>Position-Independent Executable (PIE) binaries randomize even the main executable&#39;s base address, extending ASLR complications beyond shared libraries. Older profiling tools that assumed fixed executable base addresses fail completely with PIE binaries, producing entirely incorrect symbol attribution.</p>\n<p><strong>Memory mapping changes</strong> during profiling can invalidate cached symbol resolution information. When the target process loads or unloads shared libraries, previous address-to-symbol mappings become invalid. The profiler must detect these changes and refresh its symbol tables, but detecting mapping changes requires either polling <code>/proc/[pid]/maps</code> or integrating with dynamic linker notifications.</p>\n<h4 id=\"symbol-cache-performance\">Symbol Cache Performance</h4>\n<p>Symbol resolution represents a significant computational cost that must be amortized through intelligent caching strategies. <strong>Cache miss cascades</strong> occur when similar addresses repeatedly miss the cache, causing expensive symbol lookups for every sample. This typically happens when the cache size is too small for the working set of addresses, or when the cache replacement policy doesn&#39;t account for profiling access patterns.</p>\n<p>Profiling access patterns differ significantly from typical program locality patterns. Instead of temporal locality (recently accessed addresses being accessed again), profiling exhibits <strong>hot spot locality</strong> where certain functions generate many samples but new addresses are constantly introduced as program execution progresses.</p>\n<p><strong>Cache coherency</strong> becomes critical when the target process loads or unloads libraries during profiling. Cached symbol information can become stale, causing incorrect symbol attribution. The profiler must either invalidate relevant cache entries when mapping changes are detected, or implement cache entries with validity periods that account for potential mapping changes.</p>\n<p>Symbol lookup performance varies dramatically based on the search strategy and data structures used. Linear searches through symbol tables create O(n) lookup costs that become prohibitive for large binaries. Binary search reduces this to O(log n), but requires maintaining sorted symbol tables and handling overlapping symbol ranges correctly.</p>\n<p><strong>Debug information parsing overhead</strong> can dominate symbol resolution performance, especially for DWARF debug information which can be significantly larger than the actual executable code. Lazy parsing strategies load debug information on-demand, but create unpredictable latency spikes. Eager parsing provides consistent performance but requires substantial memory overhead and startup time.</p>\n<h3 id=\"memory-tracking-issues\">Memory Tracking Issues</h3>\n<p>Memory profiling operates by intercepting allocation functions and tracking metadata for each allocation, but this instrumentation introduces complex failure modes related to recursion, thread safety, and metadata management. Understanding these failure modes is critical for building robust memory profilers and accurately interpreting memory profiling results.</p>\n<h4 id=\"allocation-interception-problems\">Allocation Interception Problems</h4>\n<p><strong>Recursive allocation calls</strong> represent the most dangerous memory tracking failure mode. When the memory tracker intercepts <code>malloc()</code> and then calls <code>malloc()</code> internally to allocate tracking metadata, it creates infinite recursion that typically manifests as stack overflow crashes. This recursion can be subtle—calling any function that internally allocates memory (like <code>printf()</code> for logging) can trigger recursive allocation.</p>\n<p>Preventing recursion requires careful design of the interception mechanism. Thread-local storage can track whether the current thread is already inside the memory tracker, allowing recursive calls to bypass tracking. However, this approach risks missing allocations that occur during tracking operations, creating gaps in allocation coverage.</p>\n<p><strong>Function interposition mechanisms</strong> each have distinct failure modes and compatibility issues. <code>LD_PRELOAD</code> interposition works by replacing dynamic library symbols, but fails for statically linked binaries or programs that use alternative allocation mechanisms. Binary patching approaches can handle static linking but require architecture-specific knowledge and may conflict with security mechanisms like code signing.</p>\n<p>Dynamic symbol interposition using <code>dlsym(RTLD_NEXT, &quot;malloc&quot;)</code> provides more robust interception but introduces startup ordering dependencies. The memory tracker must obtain function pointers to the original allocation functions before any allocation occurs, creating bootstrap challenges during program initialization.</p>\n<p><strong>Multiple allocator support</strong> complicates interception because modern programs often use multiple allocation mechanisms simultaneously. Standard <code>malloc/free</code>, C++ <code>new/delete</code>, custom memory pools, and garbage-collected languages all manage memory differently. The profiler must intercept all relevant allocation points to provide complete allocation tracking.</p>\n<p>Common interception failure modes:</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Prevention Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Infinite recursion</td>\n<td>Stack overflow in malloc</td>\n<td>Tracker allocates during interception</td>\n<td>Use pre-allocated buffers or thread-local recursion detection</td>\n</tr>\n<tr>\n<td>Missing static allocations</td>\n<td>Some allocations not tracked</td>\n<td>LD_PRELOAD doesn&#39;t affect static linking</td>\n<td>Combine multiple interposition techniques</td>\n</tr>\n<tr>\n<td>Bootstrap ordering issues</td>\n<td>Crashes during program startup</td>\n<td>Tracker not ready when first allocation occurs</td>\n<td>Initialize tracker before main() execution</td>\n</tr>\n<tr>\n<td>Custom allocator bypass</td>\n<td>Large allocations missing from tracking</td>\n<td>Program uses non-standard allocators</td>\n<td>Instrument additional allocation functions</td>\n</tr>\n<tr>\n<td>Thread creation race</td>\n<td>Missing allocations in new threads</td>\n<td>Interception not ready when thread starts</td>\n<td>Ensure thread-safe tracker initialization</td>\n</tr>\n</tbody></table>\n<h4 id=\"memory-leak-detection-challenges\">Memory Leak Detection Challenges</h4>\n<p><strong>False positive leaks</strong> occur when the leak detection algorithm incorrectly identifies legitimate long-lived allocations as memory leaks. This happens most commonly with allocations that are freed during program shutdown, after leak detection has run. Global data structures, caches, and singleton objects typically exhibit this pattern, creating noise in leak reports that obscures real leaks.</p>\n<p>Distinguishing true leaks from false positives requires understanding allocation lifetime patterns and program structure. <strong>Reachable allocations</strong> are those that could theoretically be freed because the program still holds pointers to them, while <strong>definitely lost</strong> allocations have no remaining pointers. However, determining reachability requires sophisticated analysis that may not be practical in a performance-oriented profiler.</p>\n<p><strong>Growth pattern detection</strong> attempts to identify memory leaks by looking for allocation sites with continuously increasing memory usage over time. This approach avoids the complexities of reachability analysis but can misidentify legitimate growth patterns (like caches that grow to a steady state) as memory leaks.</p>\n<p>Leak detection timing affects both accuracy and performance overhead. <strong>Continuous leak detection</strong> provides real-time feedback but requires maintaining extensive metadata for all active allocations. <strong>Snapshot-based detection</strong> reduces overhead by analyzing allocation patterns at discrete intervals, but may miss short-lived leaks that occur between snapshots.</p>\n<p><strong>Suppression rules</strong> help filter known false positives from leak reports, but maintaining suppression databases requires ongoing effort and can mask real leaks if rules are too broad. Effective suppression rules balance specificity (avoiding false positives) with maintainability (avoiding overly complex rule sets).</p>\n<h4 id=\"metadata-management-and-corruption\">Metadata Management and Corruption</h4>\n<p>Memory tracking requires storing metadata for each allocation, but this metadata storage can become corrupted through various mechanisms, creating incorrect leak reports and profiler crashes. <strong>Metadata corruption</strong> typically manifests as impossible allocation sizes, invalid stack traces, or crashes when accessing allocation tracking data structures.</p>\n<p>Concurrent access to allocation metadata from multiple threads creates race conditions that can corrupt tracking data structures. <strong>Thread safety</strong> in memory tracking requires careful synchronization that doesn&#39;t introduce deadlock risks with the allocation functions being intercepted. Fine-grained locking reduces contention but increases complexity and the potential for lock ordering issues.</p>\n<p><strong>Memory overhead</strong> from tracking metadata can become significant for programs with many small allocations. Each tracked allocation requires storing at least the allocation size, timestamp, and call stack information. For programs that make millions of small allocations, metadata overhead can exceed the overhead of the original allocations.</p>\n<p>Metadata storage strategies involve trade-offs between accuracy, performance, and memory usage:</p>\n<table>\n<thead>\n<tr>\n<th>Strategy</th>\n<th>Memory Overhead</th>\n<th>Performance Impact</th>\n<th>Accuracy</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Full stack traces</td>\n<td>High (100+ bytes per allocation)</td>\n<td>Moderate (backtrace capture cost)</td>\n<td>Excellent</td>\n<td>Development debugging</td>\n</tr>\n<tr>\n<td>Compressed stack signatures</td>\n<td>Medium (20-50 bytes per allocation)</td>\n<td>Low (hash calculation cost)</td>\n<td>Good</td>\n<td>Production profiling</td>\n</tr>\n<tr>\n<td>Sampling-based tracking</td>\n<td>Low (only track subset of allocations)</td>\n<td>Very low</td>\n<td>Fair</td>\n<td>High-throughput applications</td>\n</tr>\n<tr>\n<td>Statistical estimation</td>\n<td>Very low (aggregate statistics only)</td>\n<td>Minimal</td>\n<td>Limited</td>\n<td>Real-time monitoring</td>\n</tr>\n</tbody></table>\n<p><strong>Heap fragmentation tracking</strong> requires monitoring not just allocation patterns but also the layout of the heap memory space. This involves understanding how the underlying allocator (malloc implementation) manages memory regions and detecting when allocator behavior contributes to fragmentation issues.</p>\n<h3 id=\"debugging-tools-and-techniques\">Debugging Tools and Techniques</h3>\n<p>Effective profiler debugging requires specialized tools and techniques that account for the unique challenges of debugging a debugging tool. The profiler operates under strict performance constraints while interacting with low-level system interfaces, creating debugging scenarios that don&#39;t occur in typical application development.</p>\n<h4 id=\"logging-and-observability\">Logging and Observability</h4>\n<p><strong>Structured logging</strong> for profiler components must balance diagnostic value against performance overhead. Traditional logging approaches that write to files or stdout can introduce significant latency that affects profiling accuracy. Profiler logging typically requires asynchronous, lock-free logging mechanisms that defer formatting and I/O operations to background threads.</p>\n<p>Log level management becomes critical because profiler debugging often requires detailed trace-level information, but enabling verbose logging in production environments can overwhelm log storage and processing systems. Dynamic log level adjustment allows enabling detailed logging for specific components or time periods without restarting the profiler.</p>\n<p><strong>Metrics collection</strong> provides observability into profiler behavior and performance characteristics. Key metrics include sampling rates achieved vs. configured, symbol resolution cache hit rates, buffer utilization levels, and processing latency distributions. These metrics help identify performance bottlenecks and configuration issues before they affect profiling accuracy.</p>\n<p>Profiler metrics should be exported in formats compatible with standard monitoring systems (Prometheus, StatsD, etc.) to enable integration with existing observability infrastructure. This allows correlating profiler performance with overall system metrics and detecting environmental factors that affect profiling.</p>\n<p>Essential profiler metrics to track:</p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Specific Metrics</th>\n<th>Purpose</th>\n<th>Alert Thresholds</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sampling Performance</td>\n<td>Achieved vs configured frequency, signal delivery success rate</td>\n<td>Detect sampling issues</td>\n<td>&lt;90% of configured rate</td>\n</tr>\n<tr>\n<td>Symbol Resolution</td>\n<td>Cache hit rate, lookup latency distribution, missing symbol rate</td>\n<td>Monitor resolution performance</td>\n<td>&lt;80% cache hit rate</td>\n</tr>\n<tr>\n<td>Buffer Management</td>\n<td>Buffer utilization, overflow events, processing latency</td>\n<td>Prevent data loss</td>\n<td>&gt;90% buffer utilization</td>\n</tr>\n<tr>\n<td>Memory Tracking</td>\n<td>Metadata overhead, allocation tracking coverage, leak detection runtime</td>\n<td>Monitor tracking efficiency</td>\n<td>&gt;10% metadata overhead</td>\n</tr>\n<tr>\n<td>Overall Health</td>\n<td>Error rates, crash frequency, profiler memory usage growth</td>\n<td>System stability</td>\n<td>Any crash events</td>\n</tr>\n</tbody></table>\n<h4 id=\"diagnostic-test-programs\">Diagnostic Test Programs</h4>\n<p><strong>Synthetic test programs</strong> enable controlled testing of profiler components under known conditions. These programs generate predictable execution patterns, allocation behaviors, and call stack structures that allow validating profiler accuracy and identifying performance issues.</p>\n<p>CPU-intensive test programs should generate recognizable hot spots that appear prominently in flame graphs. Simple programs with tight loops, recursive functions, and known call patterns allow verifying that sampling captures expected execution patterns. Mathematical computations (prime number generation, matrix operations) provide sustained CPU usage with predictable profiling signatures.</p>\n<p><strong>Memory allocation test programs</strong> create controlled allocation patterns that exercise leak detection and allocation tracking capabilities. These programs should include definite memory leaks, false positive scenarios (allocations freed at shutdown), and various allocation sizes and patterns. Memory stress tests with many small allocations help validate metadata management under load.</p>\n<p>Multi-threaded test programs verify that profiler components handle concurrency correctly. Thread synchronization patterns, shared data structures, and inter-thread communication create complex execution patterns that can expose race conditions and signal handling issues in the profiler itself.</p>\n<p><strong>Regression test suites</strong> capture known profiler behaviors and detect when changes break existing functionality. These tests should include both positive cases (verifying correct behavior) and negative cases (ensuring graceful handling of error conditions). Automated regression testing prevents introducing bugs when adding features or optimizing performance.</p>\n<h4 id=\"interactive-debugging-techniques\">Interactive Debugging Techniques</h4>\n<p><strong>Live profiler inspection</strong> allows examining profiler state while it&#39;s actively collecting data. This might involve attaching debuggers to the profiler process itself, though this creates observer paradox issues where debugging the profiler affects its behavior. Non-intrusive inspection through shared memory regions or Unix domain sockets provides visibility without affecting sampling accuracy.</p>\n<p><strong>Flame graph analysis techniques</strong> help identify profiling anomalies and validate profiler accuracy. Unexpected flame graph patterns (missing expected functions, impossible call relationships, skewed sample distributions) often indicate profiler bugs rather than target program behavior. Comparing flame graphs from the same program using different profilers can identify systematic biases or errors.</p>\n<p><strong>Symbol resolution validation</strong> involves comparing resolved symbols against known ground truth. Running profilers on programs with known function names and call patterns allows detecting symbol resolution errors. Debugging information validators can check that resolved symbols are consistent with available debug data.</p>\n<p><strong>Memory tracking validation</strong> requires comparing allocation tracking results against known allocation patterns. Programs with controlled allocation behaviors allow verifying that all allocations are captured and that leak detection identifies only actual leaks. Allocation tracking can be validated by instrumenting test programs with manual allocation counting.</p>\n<p>Debugging workflow recommendations:</p>\n<table>\n<thead>\n<tr>\n<th>Issue Category</th>\n<th>Initial Diagnosis</th>\n<th>Deep Investigation</th>\n<th>Validation Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Missing samples</td>\n<td>Check signal delivery and handler installation</td>\n<td>Trace signal handling with strace/ltrace</td>\n<td>Compare with external profiler results</td>\n</tr>\n<tr>\n<td>Symbol resolution failures</td>\n<td>Verify debug package installation and paths</td>\n<td>Examine ELF headers and DWARF data with objdump</td>\n<td>Test with simple programs with known symbols</td>\n</tr>\n<tr>\n<td>Memory tracking gaps</td>\n<td>Check function interposition and threading</td>\n<td>Analyze allocation patterns with allocator debugging</td>\n<td>Compare with valgrind or AddressSanitizer</td>\n</tr>\n<tr>\n<td>Performance overhead</td>\n<td>Measure overhead with controlled workloads</td>\n<td>Profile the profiler itself</td>\n<td>Validate against overhead budgets</td>\n</tr>\n<tr>\n<td>Flame graph anomalies</td>\n<td>Review aggregation logic and sample processing</td>\n<td>Trace data flow through processing pipeline</td>\n<td>Generate flame graphs for known call patterns</td>\n</tr>\n</tbody></table>\n<h4 id=\"recovery-and-graceful-degradation\">Recovery and Graceful Degradation</h4>\n<p><strong>Error recovery strategies</strong> must maintain profiling functionality even when individual components fail. Component isolation ensures that symbol resolution failures don&#39;t prevent sample collection, and that visualization errors don&#39;t corrupt collected profiling data. Each component should have fallback behaviors that provide reduced functionality rather than complete failure.</p>\n<p><strong>Graceful degradation</strong> involves detecting when profiling overhead exceeds acceptable limits and automatically reducing profiling intensity. This might involve decreasing sampling frequency, disabling expensive symbol resolution, or switching to statistical sampling modes that maintain basic functionality with lower overhead.</p>\n<p><strong>State recovery</strong> after profiler crashes or restarts requires persisting critical profiling state to stable storage. Sample buffers, symbol caches, and allocation tracking metadata should be recoverable to avoid losing profiling data during profiler restarts. However, recovery mechanisms must not introduce additional overhead during normal operation.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Building robust debugging capabilities into a profiler requires implementing systematic error detection, logging, and recovery mechanisms that provide visibility into profiler behavior without compromising performance or accuracy.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logging Framework</td>\n<td>Python logging module with async handlers</td>\n<td>Structured logging with JSON output to centralized systems</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Simple counters with periodic output</td>\n<td>Prometheus client library with custom metrics</td>\n</tr>\n<tr>\n<td>Error Tracking</td>\n<td>Exception logging with stack traces</td>\n<td>Error aggregation with Sentry or similar service</td>\n</tr>\n<tr>\n<td>Diagnostic Tools</td>\n<td>Basic print debugging and manual testing</td>\n<td>Automated test harnesses with known-good baselines</td>\n</tr>\n<tr>\n<td>State Inspection</td>\n<td>JSON dumps of internal state</td>\n<td>Live debugging APIs with minimal overhead</td>\n</tr>\n<tr>\n<td>Performance Monitoring</td>\n<td>Basic timing measurements</td>\n<td>Detailed performance profiling of the profiler itself</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">profiler</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  debugging</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    __init__</span><span style=\"color:#E1E4E8\">.py                    ← debugging utilities exports</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logger.py                      ← structured logging setup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics.py                     ← profiler metrics collection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validators.py                  ← data validation utilities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    test_programs</span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\">                 ← synthetic test programs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      cpu_intensive.py             ← </span><span style=\"color:#79B8FF\">CPU</span><span style=\"color:#E1E4E8\"> profiling test cases</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      memory_patterns.py           ← memory allocation test patterns</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      threading_stress.py          ← multi</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">threaded test scenarios</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    diagnostics</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      signal_debugging.py          ← signal handler diagnostics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      symbol_validation.py         ← symbol resolution testing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      memory_validation.py         ← allocation tracking validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recovery</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      error_handlers.py            ← error recovery mechanisms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      state_persistence.py         ← profiler state backup</span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\">restore</span></span></code></pre></div>\n\n<h4 id=\"core-infrastructure-code\">Core Infrastructure Code</h4>\n<p>Complete logging infrastructure that handles the unique requirements of profiler debugging:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, asdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict, deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LogLevel</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEBUG</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"debug\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    INFO</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"info\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARNING</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"warning\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    ERROR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"error\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CRITICAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"critical\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerLogEvent</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    level: LogLevel</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    component: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stack_trace: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AsyncProfilerLogger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"High-performance async logger designed for profiler debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_buffer_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_buffer_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_buffer_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log_buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_buffer_size)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.buffer_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.dropped_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.background_task </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.shutdown_event </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Event()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> start_background_logging</span><span style=\"color:#E1E4E8\">(self, output_file: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start background thread for async log processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.output_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output_file</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.background_task </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Thread(</span><span style=\"color:#FFAB70\">target</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._background_worker, </span><span style=\"color:#FFAB70\">daemon</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.background_task.start()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _background_worker</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Background thread that processes log events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.output_file, </span><span style=\"color:#9ECBFF\">'w'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            while</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.shutdown_event.is_set():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                events_to_write </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.buffer_lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    while</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.log_buffer </span><span style=\"color:#F97583\">and</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(events_to_write) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        events_to_write.append(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.log_buffer.popleft())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> event </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> events_to_write:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    json.dump(asdict(event), f)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    f.write(</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    f.flush()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> events_to_write:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    time.sleep(</span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Small delay when no events</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log_event</span><span style=\"color:#E1E4E8\">(self, level: LogLevel, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                  context: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log event with minimal latency impact.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        event </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ProfilerLogEvent(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            timestamp</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time(),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            level</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">level,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            component</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">component,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            message</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">message,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">context </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> {},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            thread_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">threading.get_ident()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.buffer_lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.log_buffer) </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_buffer_size:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.dropped_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.log_buffer.append(event)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerMetrics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Lightweight metrics collection for profiler components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.counters </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.histograms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.gauges </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> increment_counter</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, labels: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Thread-safe counter increment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        key </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._make_key(name, labels)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.counters[key] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_histogram</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, labels: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record histogram value with automatic trimming.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        key </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._make_key(name, labels)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.histograms[key].append(value)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Keep only recent values to prevent unbounded growth</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.histograms[key]) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.histograms[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.histograms[key][</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> set_gauge</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, labels: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Set gauge value.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        key </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._make_key(name, labels)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.gauges[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _make_key</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, labels: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create metric key from name and labels.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> labels:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        label_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> ','</span><span style=\"color:#E1E4E8\">.join(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">k</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">v</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(labels.items()))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">name</span><span style=\"color:#79B8FF\">}{{{</span><span style=\"color:#E1E4E8\">label_str</span><span style=\"color:#79B8FF\">}}}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> export_metrics</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Export all metrics for external consumption.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'counters'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.counters),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'gauges'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.gauges),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'histograms'</span><span style=\"color:#E1E4E8\">: {k: {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'count'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(v),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'min'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">min</span><span style=\"color:#E1E4E8\">(v) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> v </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'max'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">max</span><span style=\"color:#E1E4E8\">(v) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> v </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'avg'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">sum</span><span style=\"color:#E1E4E8\">(v) </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(v) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> v </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                } </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> k, v </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.histograms.items()},</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'uptime_seconds'</span><span style=\"color:#E1E4E8\">: time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global instances for profiler-wide use</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">profiler_logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AsyncProfilerLogger()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">profiler_metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ProfilerMetrics()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> setup_profiler_debugging</span><span style=\"color:#E1E4E8\">(log_file: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, metrics_export_interval: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Initialize profiler debugging infrastructure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    profiler_logger.start_background_logging(log_file)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Start metrics export timer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> export_metrics</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            time.sleep(metrics_export_interval)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> profiler_metrics.export_metrics()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            profiler_logger.log_event(LogLevel.</span><span style=\"color:#79B8FF\">INFO</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"metrics\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"periodic_export\"</span><span style=\"color:#E1E4E8\">, metrics)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics_thread </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Thread(</span><span style=\"color:#FFAB70\">target</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">export_metrics, </span><span style=\"color:#FFAB70\">daemon</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics_thread.start()</span></span></code></pre></div>\n\n<p>Complete validation framework for profiler data integrity:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationResult</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PASS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"pass\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WARN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"warning\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    FAIL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"failure\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ValidationIssue</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    result: ValidationResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    fix_suggestion: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerDataValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive validation for profiler data structures.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_sample_batch</span><span style=\"color:#E1E4E8\">(self, batch: </span><span style=\"color:#9ECBFF\">'SampleBatch'</span><span style=\"color:#E1E4E8\">) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate sample batch for common issues.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check timestamp ordering within batch</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate all samples have reasonable thread/process IDs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check for duplicate samples (same timestamp + thread)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate stack frame addresses are in reasonable ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check sampling frequency matches expected rate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_symbol_resolution</span><span style=\"color:#E1E4E8\">(self, symbols: List[</span><span style=\"color:#9ECBFF\">'Symbol'</span><span style=\"color:#E1E4E8\">]) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate symbol resolution results.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for overlapping symbol address ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate symbol names are not empty or malformed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check that file paths exist and are readable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate line numbers are within file bounds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check for reasonable symbol sizes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_memory_allocations</span><span style=\"color:#E1E4E8\">(self, allocations: List[</span><span style=\"color:#9ECBFF\">'Allocation'</span><span style=\"color:#E1E4E8\">]) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate memory allocation tracking data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check allocation IDs are unique and sequential</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate allocation sizes are positive and reasonable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check timestamps are monotonically increasing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate thread IDs exist in process</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check stack traces are complete and valid</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_flame_graph_data</span><span style=\"color:#E1E4E8\">(self, root: </span><span style=\"color:#9ECBFF\">'FlameNode'</span><span style=\"color:#E1E4E8\">) -> List[ValidationIssue]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate flame graph tree structure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check tree structure is acyclic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate sample counts sum correctly at each level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check all nodes have valid function names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate parent-child relationships are consistent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check depth limits are respected</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> issues</span></span></code></pre></div>\n\n<h4 id=\"core-debugging-utilities\">Core Debugging Utilities</h4>\n<p>Essential debugging utilities that profiler components can use:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DebugContext</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for debugging profiler operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.operation_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> operation_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> component</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __enter__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        profiler_logger.log_event(LogLevel.</span><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.component, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                f</span><span style=\"color:#9ECBFF\">\"Starting </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.context_data)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __exit__</span><span style=\"color:#E1E4E8\">(self, exc_type, exc_val, exc_tb):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        duration </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.start_time</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context_data[</span><span style=\"color:#9ECBFF\">'duration_seconds'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> exc_type:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            profiler_logger.log_event(LogLevel.</span><span style=\"color:#79B8FF\">ERROR</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.component,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                    f</span><span style=\"color:#9ECBFF\">\"Failed </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">exc_val</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.context_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            profiler_metrics.increment_counter(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.component</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_errors\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            profiler_logger.log_event(LogLevel.</span><span style=\"color:#79B8FF\">DEBUG</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.component,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                    f</span><span style=\"color:#9ECBFF\">\"Completed </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.context_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        profiler_metrics.record_histogram(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.component</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_operation_duration\"</span><span style=\"color:#E1E4E8\">, duration)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_context</span><span style=\"color:#E1E4E8\">(self, key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, value: Any):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add context information for debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context_data[key] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> value</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> handle_signal_delivery_failure</span><span style=\"color:#E1E4E8\">(target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, expected_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, actual_samples: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handle failed signal delivery and determine recovery strategy.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate sample delivery success rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if target process is in uninterruptible sleep</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify signal mask configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Adjust sampling frequency if delivery rate too low</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return True if recovery possible, False if should abort</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> recover_from_stack_corruption</span><span style=\"color:#E1E4E8\">(context: </span><span style=\"color:#9ECBFF\">'RegisterContext'</span><span style=\"color:#E1E4E8\">, partial_stack: List[</span><span style=\"color:#9ECBFF\">'StackFrame'</span><span style=\"color:#E1E4E8\">]) -> Optional[List[</span><span style=\"color:#9ECBFF\">'StackFrame'</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Attempt to recover usable stack from corrupted unwind.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate existing stack frames for reasonableness</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt alternative unwinding methods (DWARF vs frame pointer)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use heuristics to repair corrupted frame pointer chains</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Fill gaps with anonymous frames if necessary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return repaired stack or None if unrecoverable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> detect_recursive_malloc</span><span style=\"color:#E1E4E8\">() -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Detect recursion in allocation tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check thread-local recursion flag</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Examine call stack for malloc/free functions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return True if recursion detected</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-validation-checkpoints\">Milestone Validation Checkpoints</h4>\n<p>After implementing each milestone, use these validation procedures:</p>\n<p><strong>Milestone 1 - Stack Sampling Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic sampling functionality</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> profiler.debugging.validators</span><span style=\"color:#9ECBFF\"> validate_milestone_1_stack_sampling</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Sampling rate within 10% of configured rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Stack traces contain reasonable function addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - No signal delivery failures or handler crashes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Buffer utilization stays below 90%</span></span></code></pre></div>\n\n<p><strong>Milestone 2 - Symbol Resolution Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test symbol resolution with known binaries  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> profiler.debugging.validators</span><span style=\"color:#9ECBFF\"> validate_milestone_2_symbol_resolution</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - >95% of addresses resolve to function names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Symbol cache hit rate >80% after warmup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - No symbol overlaps or invalid address ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - DWARF parsing completes without errors</span></span></code></pre></div>\n\n<p><strong>Milestone 3 - Flame Graph Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test flame graph generation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> profiler.debugging.validators</span><span style=\"color:#9ECBFF\"> validate_milestone_3_flame_graphs</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - SVG file generates without errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Sample counts sum correctly at each level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Interactive features (zoom, search) work</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Color schemes render distinctly</span></span></code></pre></div>\n\n<p><strong>Milestone 4 - Memory Profiling Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test memory tracking</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> profiler.debugging.validators</span><span style=\"color:#9ECBFF\"> validate_milestone_4_memory_profiling</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - All allocations captured without recursion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Leak detection identifies only actual leaks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Memory overhead &#x3C;10% of tracked allocations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - No metadata corruption detected</span></span></code></pre></div>\n\n\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Future directions building on all milestones (1-4) — extending the profiler with advanced profiling features and scalability enhancements beyond the core stack sampling, symbol resolution, flame graph generation, and memory profiling capabilities</p>\n</blockquote>\n<h3 id=\"mental-model-the-observatory-expansion\">Mental Model: The Observatory Expansion</h3>\n<p>Think of the current profiler as a personal telescope in your backyard — it can observe nearby stars (local processes) with good detail using basic optical instruments (stack sampling and memory tracking). Future extensions transform this into a full observatory complex: adding specialized instruments like radio telescopes (hardware performance counters) to detect different phenomena, building an array of synchronized telescopes (distributed profiling) to observe larger cosmic events (distributed systems), and installing real-time streaming equipment (live analysis) to broadcast discoveries as they happen. Each extension leverages the solid foundation of the original telescope while expanding its reach and capabilities.</p>\n<p>The architectural foundation we&#39;ve built provides natural extension points for these enhancements. The modular component design with clear data flow pipelines allows new data sources to integrate seamlessly, while the symbol resolution and visualization infrastructure can adapt to display new types of profiling information without fundamental redesign.</p>\n<h3 id=\"advanced-profiling-features\">Advanced Profiling Features</h3>\n<p>Advanced profiling features extend the core capabilities by adding new data sources and analysis techniques that provide deeper insights into program behavior. These extensions leverage the existing sampling, symbolization, and visualization infrastructure while introducing specialized collection mechanisms and enhanced analysis algorithms.</p>\n<h4 id=\"hardware-performance-counters-integration\">Hardware Performance Counters Integration</h4>\n<p>Hardware performance counters represent specialized CPU registers that track low-level execution events like cache misses, branch mispredictions, memory stall cycles, and instruction throughput. Modern processors expose hundreds of these counters through performance monitoring units, providing visibility into microarchitectural behavior that software-based sampling cannot observe.</p>\n<blockquote>\n<p><strong>Decision: Event-Based Sampling with Hardware Counters</strong></p>\n<ul>\n<li><strong>Context</strong>: Software timer sampling provides call stack visibility but misses microarchitectural bottlenecks like cache behavior, branch prediction efficiency, and memory bandwidth utilization that significantly impact performance</li>\n<li><strong>Options Considered</strong>: <ul>\n<li>Separate hardware counter tool requiring manual correlation</li>\n<li>Integrated counter sampling synchronized with stack sampling  </li>\n<li>Pure hardware event sampling without stack context</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Integrate hardware counter sampling with existing stack sampling using Linux perf_event_open system calls</li>\n<li><strong>Rationale</strong>: Synchronizing hardware events with call stack context enables attributing microarchitectural costs to specific functions, providing actionable optimization guidance that neither approach delivers alone</li>\n<li><strong>Consequences</strong>: Requires elevated privileges for counter access, adds complexity to sample correlation, but enables root cause analysis of performance bottlenecks invisible to software sampling</li>\n</ul>\n</blockquote>\n<p>The integration extends the existing <code>Sample</code> data structure to include hardware event counts collected alongside each stack trace. The sampler component configures performance monitoring counters using the perf_event_open system call, enabling overflow sampling where hardware events trigger sample collection rather than timer signals. This approach captures both the call stack context and the associated hardware costs in a single sample.</p>\n<table>\n<thead>\n<tr>\n<th>Hardware Counter Type</th>\n<th>Event Examples</th>\n<th>Performance Insight</th>\n<th>Integration Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache Performance</td>\n<td>L1/L2/L3 cache misses, cache references</td>\n<td>Memory access efficiency, data locality issues</td>\n<td>Counter overflow triggers stack sample</td>\n</tr>\n<tr>\n<td>Branch Prediction</td>\n<td>Branch instructions, branch misses</td>\n<td>Control flow predictability, loop efficiency</td>\n<td>Sample includes branch statistics</td>\n</tr>\n<tr>\n<td>Memory Subsystem</td>\n<td>Memory loads, stores, bandwidth utilization</td>\n<td>Memory bottleneck identification</td>\n<td>Memory event sampling with stack context</td>\n</tr>\n<tr>\n<td>Instruction Pipeline</td>\n<td>Instructions retired, stall cycles</td>\n<td>CPU utilization efficiency, pipeline bubbles</td>\n<td>Instruction-based sampling frequency</td>\n</tr>\n<tr>\n<td>Power and Thermal</td>\n<td>CPU energy consumption, thermal throttling</td>\n<td>Power efficiency analysis, thermal constraints</td>\n<td>Energy-aware profiling periods</td>\n</tr>\n</tbody></table>\n<p>The flame graph visualization adapts to display hardware event data through enhanced color coding and tooltip information. Instead of showing only sample counts, flame graph nodes can represent cache miss rates, instructions per cycle, or energy consumption per function. The interactive SVG generation includes additional overlays that switch between different hardware event views, enabling developers to correlate software structure with microarchitectural behavior.</p>\n<h4 id=\"custom-event-sampling\">Custom Event Sampling</h4>\n<p>Custom event sampling enables profiling application-specific events and user-defined performance metrics beyond standard CPU and memory behavior. This extension allows developers to instrument critical application logic with custom sampling points that integrate seamlessly with existing profiling infrastructure.</p>\n<p>The implementation introduces a custom event registration API that applications can use to define domain-specific sampling events. These events integrate with the existing sampling infrastructure by extending the <code>SampleType</code> enumeration to include user-defined event categories. Custom events can trigger additional stack capture or annotate existing samples with application context.</p>\n<table>\n<thead>\n<tr>\n<th>Custom Event Category</th>\n<th>Example Events</th>\n<th>Use Case</th>\n<th>Integration Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Application Logic</td>\n<td>Database query completion, cache operations</td>\n<td>Business logic profiling</td>\n<td>Event-driven stack sampling</td>\n</tr>\n<tr>\n<td>Resource Usage</td>\n<td>File I/O operations, network requests</td>\n<td>I/O bottleneck analysis</td>\n<td>Asynchronous event correlation</td>\n</tr>\n<tr>\n<td>User Interactions</td>\n<td>UI event processing, request handling</td>\n<td>User experience optimization</td>\n<td>Event timestamp correlation</td>\n</tr>\n<tr>\n<td>System Integration</td>\n<td>External service calls, message processing</td>\n<td>Distributed system analysis</td>\n<td>Cross-process event tracking</td>\n</tr>\n<tr>\n<td>Performance Metrics</td>\n<td>Custom latency measurements, throughput counters</td>\n<td>Domain-specific optimization</td>\n<td>Metric annotation of samples</td>\n</tr>\n</tbody></table>\n<p>The symbol resolution component extends to handle custom event symbols by maintaining an application-provided symbol registry. This registry maps custom event identifiers to human-readable names and metadata, enabling flame graph visualization of application-specific profiling data with the same symbolic richness as system-level profiling.</p>\n<h4 id=\"multi-language-support\">Multi-Language Support</h4>\n<p>Multi-language support enables profiling polyglot applications that combine multiple programming languages within a single process or across cooperating processes. Modern applications frequently integrate Python, Go, Rust, C++, JavaScript, and other languages, requiring profiler extensions that understand each language&#39;s runtime characteristics and calling conventions.</p>\n<p>The symbol resolution component extends to handle language-specific symbol formats and runtime environments. Each language runtime provides different mechanisms for stack unwinding and symbol lookup, requiring specialized unwinding strategies that integrate with the core profiler infrastructure.</p>\n<table>\n<thead>\n<tr>\n<th>Language Runtime</th>\n<th>Stack Unwinding Method</th>\n<th>Symbol Resolution</th>\n<th>Integration Challenges</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Python</td>\n<td>Python C API frame walking</td>\n<td>Python bytecode to source mapping</td>\n<td>GIL interaction, bytecode interpretation</td>\n</tr>\n<tr>\n<td>Go</td>\n<td>Runtime stack scanner</td>\n<td>Go symbol table format</td>\n<td>Goroutine multiplexing, runtime symbols</td>\n</tr>\n<tr>\n<td>Rust</td>\n<td>DWARF unwinding</td>\n<td>Cargo symbol resolution</td>\n<td>Name mangling, trait object symbols</td>\n</tr>\n<tr>\n<td>JavaScript (V8)</td>\n<td>V8 profiler API</td>\n<td>JIT code mapping</td>\n<td>Dynamic compilation, optimized code</td>\n</tr>\n<tr>\n<td>Java (JVM)</td>\n<td>JVMTI interface</td>\n<td>Class file symbol mapping</td>\n<td>JIT compilation, class loading</td>\n</tr>\n</tbody></table>\n<p>The implementation maintains language-specific unwinding modules that register with the core sampling infrastructure. When unwinding encounters a frame from a specific language runtime, it delegates to the appropriate language-specific unwinder that understands the runtime&#39;s frame layout and symbol conventions. The unified flame graph visualization displays mixed-language call stacks with color coding to distinguish language boundaries.</p>\n<p>The aggregation component handles language interoperability by normalizing symbol names and call conventions across language boundaries. This normalization enables accurate aggregation of call stacks that cross language boundaries while preserving the ability to drill down into language-specific implementation details.</p>\n<h4 id=\"advanced-memory-analysis\">Advanced Memory Analysis</h4>\n<p>Advanced memory analysis extends basic allocation tracking with sophisticated analysis techniques that provide deeper insights into memory usage patterns and performance characteristics. These extensions analyze temporal allocation patterns, memory access behaviors, and heap fragmentation to identify optimization opportunities beyond simple leak detection.</p>\n<p>The memory profiling component enhances allocation tracking with temporal analysis that identifies memory usage trends and allocation lifecycle patterns. This analysis correlates allocation timing with application behavior to identify memory hotspots and allocation inefficiencies.</p>\n<table>\n<thead>\n<tr>\n<th>Analysis Technique</th>\n<th>Memory Insight</th>\n<th>Implementation Approach</th>\n<th>Visualization Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Allocation Lifetime Analysis</td>\n<td>Memory holding time distributions</td>\n<td>Timestamp-based tracking</td>\n<td>Allocation duration histograms</td>\n</tr>\n<tr>\n<td>Spatial Locality Analysis</td>\n<td>Memory access pattern efficiency</td>\n<td>Address-based clustering</td>\n<td>Memory layout visualization</td>\n</tr>\n<tr>\n<td>Temporal Allocation Patterns</td>\n<td>Memory usage trends over time</td>\n<td>Time-series allocation tracking</td>\n<td>Memory usage timeline graphs</td>\n</tr>\n<tr>\n<td>Heap Fragmentation Analysis</td>\n<td>Memory layout efficiency</td>\n<td>Free space tracking</td>\n<td>Fragmentation heatmaps</td>\n</tr>\n<tr>\n<td>Memory Access Profiling</td>\n<td>Cache-friendly allocation patterns</td>\n<td>Hardware counter correlation</td>\n<td>Access pattern flame graphs</td>\n</tr>\n</tbody></table>\n<p>The enhanced memory tracking correlates allocation patterns with performance counters to identify memory access inefficiencies. By combining allocation site information with cache miss counters, the profiler can identify data structures that cause cache thrashing or memory bandwidth bottlenecks, providing optimization guidance that basic allocation tracking cannot deliver.</p>\n<h3 id=\"scalability-and-performance\">Scalability and Performance</h3>\n<p>Scalability and performance extensions address the fundamental limitations of single-process profiling by enabling large-scale profiling deployments and real-time analysis capabilities. These extensions transform the profiler from a development tool into a production monitoring system capable of continuous performance analysis across distributed systems.</p>\n<h4 id=\"distributed-profiling\">Distributed Profiling</h4>\n<p>Distributed profiling enables coordinated profiling across multiple processes, machines, and services in a distributed system. This extension provides visibility into system-wide performance characteristics and cross-service interaction patterns that single-process profiling cannot capture.</p>\n<blockquote>\n<p><strong>Decision: Federated Profiling Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Modern applications consist of hundreds of microservices across dozens of machines, making single-process profiling inadequate for understanding system-wide performance bottlenecks and service interaction costs</li>\n<li><strong>Options Considered</strong>:<ul>\n<li>Centralized profiling server collecting all samples</li>\n<li>Federated profiling with hierarchical aggregation</li>\n<li>Independent profilers with offline correlation</li>\n</ul>\n</li>\n<li><strong>Decision</strong>: Implement federated profiling with local aggregation and hierarchical sample merging</li>\n<li><strong>Rationale</strong>: Centralized collection creates network bottlenecks and single points of failure, while offline correlation loses temporal relationships; federated architecture scales horizontally while preserving cross-service correlation</li>\n<li><strong>Consequences</strong>: Requires distributed coordination protocols and consistent timestamp synchronization, but enables scalable system-wide profiling with preserved causal relationships</li>\n</ul>\n</blockquote>\n<p>The distributed profiling implementation extends the existing profiler with cluster coordination capabilities that enable synchronized profiling across multiple processes and machines. Each node runs a local profiler instance that coordinates with a cluster controller to synchronize profiling periods and aggregate results hierarchically.</p>\n<table>\n<thead>\n<tr>\n<th>Distribution Component</th>\n<th>Responsibility</th>\n<th>Implementation</th>\n<th>Coordination Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cluster Controller</td>\n<td>Profiling coordination, result aggregation</td>\n<td>Central coordinator service</td>\n<td>HTTP API with profiler agents</td>\n</tr>\n<tr>\n<td>Profiler Agent</td>\n<td>Local profiling, sample preprocessing</td>\n<td>Extended core profiler</td>\n<td>gRPC communication with controller</td>\n</tr>\n<tr>\n<td>Sample Aggregator</td>\n<td>Cross-node sample merging</td>\n<td>Distributed aggregation service</td>\n<td>Consistent hashing for data sharding</td>\n</tr>\n<tr>\n<td>Distributed Storage</td>\n<td>Profile data persistence</td>\n<td>Distributed file system</td>\n<td>Object storage with metadata indexing</td>\n</tr>\n<tr>\n<td>Timeline Synchronizer</td>\n<td>Cross-node timestamp correlation</td>\n<td>NTP-based time synchronization</td>\n<td>Timestamp adjustment protocols</td>\n</tr>\n</tbody></table>\n<p>The distributed flame graph visualization combines samples from multiple services into unified visualizations that show cross-service call relationships. The flame graph generation component extends to handle distributed call stacks where individual stack frames may originate from different processes or machines, requiring correlation based on distributed tracing identifiers.</p>\n<h4 id=\"streaming-data-processing\">Streaming Data Processing</h4>\n<p>Streaming data processing enables real-time profiling analysis with continuous sample processing and live visualization updates. This extension transforms the profiler from a batch analysis tool into a real-time monitoring system that provides immediate feedback on performance changes and anomalies.</p>\n<p>The streaming implementation replaces the batch processing pipeline with a continuous stream processing architecture that analyzes samples as they arrive. This architecture enables real-time anomaly detection, live flame graph updates, and immediate alerting on performance degradations.</p>\n<table>\n<thead>\n<tr>\n<th>Streaming Component</th>\n<th>Processing Function</th>\n<th>Implementation Technology</th>\n<th>Performance Characteristic</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sample Stream Processor</td>\n<td>Real-time sample analysis</td>\n<td>Event stream processing framework</td>\n<td>Sub-second processing latency</td>\n</tr>\n<tr>\n<td>Live Aggregation Engine</td>\n<td>Continuous flame graph updates</td>\n<td>Sliding window aggregation</td>\n<td>Configurable window sizes</td>\n</tr>\n<tr>\n<td>Anomaly Detection</td>\n<td>Performance regression identification</td>\n<td>Statistical change detection</td>\n<td>Real-time alert generation</td>\n</tr>\n<tr>\n<td>Live Visualization</td>\n<td>Dynamic flame graph updates</td>\n<td>WebSocket-based updates</td>\n<td>Interactive real-time displays</td>\n</tr>\n<tr>\n<td>Stream Storage</td>\n<td>Continuous profile archiving</td>\n<td>Time-series database</td>\n<td>Compressed sample storage</td>\n</tr>\n</tbody></table>\n<p>The streaming aggregation maintains sliding window aggregates that enable real-time flame graph generation without requiring complete sample collection cycles. The aggregation windows adapt automatically based on sampling rate and available system resources, balancing analysis latency with resource consumption.</p>\n<h4 id=\"real-time-analysis\">Real-Time Analysis</h4>\n<p>Real-time analysis extends streaming processing with advanced analytics that detect performance anomalies, identify regression patterns, and provide automated optimization recommendations. This extension enables proactive performance management with immediate feedback on code changes and deployment impacts.</p>\n<p>The real-time analysis engine implements statistical models that establish performance baselines and detect significant deviations from expected behavior. These models adapt continuously to evolving application behavior while maintaining sensitivity to genuine performance regressions.</p>\n<table>\n<thead>\n<tr>\n<th>Analysis Capability</th>\n<th>Detection Method</th>\n<th>Response Action</th>\n<th>Implementation Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Performance Regression</td>\n<td>Statistical change detection</td>\n<td>Automated alerting</td>\n<td>Baseline comparison algorithms</td>\n</tr>\n<tr>\n<td>Hotspot Evolution</td>\n<td>Call stack pattern analysis</td>\n<td>Optimization recommendations</td>\n<td>Machine learning classification</td>\n</tr>\n<tr>\n<td>Memory Leak Prediction</td>\n<td>Allocation trend extrapolation</td>\n<td>Preventive warnings</td>\n<td>Time-series forecasting</td>\n</tr>\n<tr>\n<td>Capacity Planning</td>\n<td>Resource usage projection</td>\n<td>Scaling recommendations</td>\n<td>Predictive modeling</td>\n</tr>\n<tr>\n<td>Root Cause Analysis</td>\n<td>Anomaly correlation</td>\n<td>Automated diagnosis</td>\n<td>Causal inference algorithms</td>\n</tr>\n</tbody></table>\n<p>The real-time visualization adapts to display analysis results with live annotations and recommendations overlaid on flame graphs. The interactive SVG generation includes real-time highlighting of performance anomalies and optimization opportunities, enabling immediate identification of performance issues without manual analysis.</p>\n<h3 id=\"extension-architecture-integration\">Extension Architecture Integration</h3>\n<p>The extension architecture leverages the modular design established in the core profiler to enable seamless integration of advanced features without disrupting existing functionality. Each extension integrates through well-defined plugin interfaces that maintain backward compatibility while enabling progressive feature adoption.</p>\n<p>The plugin architecture extends the core <code>ProfilerConfig</code> structure with extension-specific configuration sections that enable selective feature activation. Extensions register with the main profiler through standardized interfaces that define data flow integration points and configuration requirements.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Point</th>\n<th>Extension Interface</th>\n<th>Data Flow Impact</th>\n<th>Configuration Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sample Collection</td>\n<td>Custom samplers</td>\n<td>Additional sample sources</td>\n<td>Sampler plugin registration</td>\n</tr>\n<tr>\n<td>Symbol Resolution</td>\n<td>Language-specific resolvers</td>\n<td>Extended symbol lookup</td>\n<td>Resolver plugin configuration</td>\n</tr>\n<tr>\n<td>Data Aggregation</td>\n<td>Custom aggregators</td>\n<td>Enhanced data processing</td>\n<td>Aggregation pipeline extension</td>\n</tr>\n<tr>\n<td>Visualization</td>\n<td>Advanced renderers</td>\n<td>Extended output formats</td>\n<td>Visualization plugin selection</td>\n</tr>\n<tr>\n<td>Analysis Engine</td>\n<td>Custom analyzers</td>\n<td>Real-time processing</td>\n<td>Analysis pipeline registration</td>\n</tr>\n</tbody></table>\n<p>The backward compatibility strategy ensures that existing profiler deployments continue functioning unchanged when extensions are available but not activated. The extension loading mechanism validates compatibility and gracefully degrades functionality when required dependencies are unavailable.</p>\n<blockquote>\n<p>The fundamental insight enabling these extensions is that profiling is fundamentally a data pipeline problem — samples flow from collection through processing to visualization. By designing clean interfaces between pipeline stages, we enable arbitrary extensions at each stage without disrupting the overall architecture. This modularity transforms the profiler from a fixed-function tool into an extensible platform for performance analysis.</p>\n</blockquote>\n<h3 id=\"common-extension-pitfalls\">Common Extension Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Extension Compatibility Breaking</strong>\nAdding extensions that modify core data structures without maintaining backward compatibility breaks existing tooling and configurations. This happens when extensions directly modify <code>Sample</code> or <code>StackFrame</code> structures instead of extending them through composition. The fix involves designing extension data as separate structures that attach to core types without modifying their existing fields, using composition patterns that preserve API stability.</p>\n<p>⚠️ <strong>Pitfall: Performance Regression from Extensions</strong>\nHeavy-weight extensions can introduce significant overhead that defeats the profiler&#39;s low-impact design goals. This occurs when extensions perform expensive operations in sampling hot paths or maintain large in-memory state. The solution requires careful performance budget allocation for each extension and lazy loading strategies that defer expensive operations outside critical sampling paths.</p>\n<p>⚠️ <strong>Pitfall: Extension Configuration Complexity</strong>\nMultiple extensions with independent configuration systems create an overwhelming configuration burden that makes the profiler difficult to deploy and maintain. This happens when each extension introduces its own configuration format and validation logic. The fix involves designing unified configuration schemas that provide sensible defaults and configuration validation that helps users understand extension interactions and conflicts.</p>\n<p>⚠️ <strong>Pitfall: Distributed Profiling Clock Synchronization</strong>\nDistributed profiling without proper clock synchronization produces meaningless cross-service correlation and timeline analysis. This occurs when different machines have significant clock skew that corrupts temporal relationships between samples. The solution requires implementing clock synchronization protocols and timestamp adjustment algorithms that account for network latency and clock drift across distributed profiling nodes.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The extension implementation builds upon the existing profiler infrastructure while adding new capabilities through plugin interfaces and enhanced data processing pipelines. The following guidance provides concrete implementation strategies for the major extension categories.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Extension Category</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hardware Counters</td>\n<td>Linux perf_event_open syscalls</td>\n<td>Intel PCM library integration</td>\n</tr>\n<tr>\n<td>Custom Events</td>\n<td>Function pointer registration</td>\n<td>Dynamic instrumentation (eBPF)</td>\n</tr>\n<tr>\n<td>Multi-Language</td>\n<td>Language-specific APIs</td>\n<td>Universal unwinding libraries</td>\n</tr>\n<tr>\n<td>Distributed Profiling</td>\n<td>HTTP REST coordination</td>\n<td>gRPC streaming coordination</td>\n</tr>\n<tr>\n<td>Streaming Processing</td>\n<td>In-process queues</td>\n<td>Apache Kafka integration</td>\n</tr>\n<tr>\n<td>Real-Time Analysis</td>\n<td>Statistical algorithms</td>\n<td>Machine learning frameworks</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>profiler/\n  cmd/\n    profiler/main.py           ← main profiler entry point\n    cluster-controller/main.py  ← distributed profiling coordinator\n  core/\n    sampling/sampler.py        ← core sampling infrastructure\n    symbols/resolver.py        ← core symbol resolution\n    visualization/flame_graph.py ← core flame graph generation\n  extensions/\n    hardware/\n      perf_counters.py         ← hardware counter integration\n      counter_sampler.py       ← hardware event sampling\n    languages/\n      python_unwinder.py       ← Python-specific stack unwinding\n      go_unwinder.py           ← Go runtime integration\n      language_registry.py     ← multi-language coordination\n    distributed/\n      cluster_coordinator.py   ← distributed profiling coordination\n      agent_client.py          ← profiler agent communication\n      sample_aggregator.py     ← cross-node sample merging\n    streaming/\n      stream_processor.py      ← real-time sample processing\n      live_aggregator.py       ← streaming aggregation engine\n      anomaly_detector.py      ← performance anomaly detection\n    analysis/\n      regression_detector.py   ← performance regression analysis\n      optimizer.py             ← automated optimization recommendations\n  plugins/\n    __init__.py                ← plugin discovery and loading\n    interfaces.py              ← plugin interface definitions\n    registry.py                ← extension registration system</code></pre></div>\n\n<h4 id=\"hardware-counter-integration-infrastructure\">Hardware Counter Integration Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Hardware performance counter integration using Linux perf_event_open.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides complete infrastructure for hardware event sampling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.sampling.sampler </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BaseSampler, Sample, StackFrame</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Hardware counter event definitions from linux/perf_event.h</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">PERF_COUNT_HW_CPU_CYCLES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">PERF_COUNT_HW_INSTRUCTIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">PERF_COUNT_HW_CACHE_REFERENCES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">PERF_COUNT_HW_CACHE_MISSES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">PERF_COUNT_HW_BRANCH_INSTRUCTIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 4</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">PERF_COUNT_HW_BRANCH_MISSES</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HardwareEvent</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_type: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_period: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HardwareCounters</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cycles: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    instructions: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_references: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_misses: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    branch_instructions: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    branch_misses: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_ipc</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Instructions per cycle calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.instructions </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.cycles </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.cycles </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_cache_miss_rate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Cache miss rate percentage.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.cache_misses </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.cache_references </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 100.0</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.cache_references </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HardwareCounterSampler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">BaseSampler</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Hardware counter sampling using perf_event_open.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, events: List[HardwareEvent]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(target_pid)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> events</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.event_fds: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.counter_values </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HardwareCounters()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> start_sampling</span><span style=\"color:#E1E4E8\">(self, target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start hardware counter sampling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Open perf_event_open file descriptors for each hardware event</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Configure event sampling periods and overflow notifications  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up signal handler for counter overflow events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Enable counter collection and start monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use ctypes to call perf_event_open syscall directly</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_counter_overflow</span><span style=\"color:#E1E4E8\">(self, signum: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, frame) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle hardware counter overflow signal.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Read current counter values from perf event file descriptors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Capture current call stack using existing stack unwinding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create Sample with both stack frames and hardware counter data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Store sample in collection buffer for later processing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> read_counter_values</span><span style=\"color:#E1E4E8\">(self) -> HardwareCounters:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Read current hardware counter values.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Read counter values from each perf event file descriptor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse counter data from kernel perf event format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update HardwareCounters structure with current values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return complete counter snapshot</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> stop_sampling</span><span style=\"color:#E1E4E8\">(self) -> List[Sample]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Stop hardware counter sampling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Disable hardware counter collection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Close perf event file descriptors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return collected samples with hardware counter data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"custom-event-sampling-framework\">Custom Event Sampling Framework</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Custom event sampling framework for application-specific profiling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Enables user-defined events to trigger stack sampling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Callable, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.sampling.sampler </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Sample, StackFrame</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CustomEvent</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">threading.get_ident)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CustomEventRegistry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Registry for custom profiling events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.event_handlers: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Callable] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.event_samples: List[Sample] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sampling_enabled </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_event</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, handler: Callable[[CustomEvent], </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register custom event handler.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate event_id is unique and handler is callable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Store event handler in registry with event_id as key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up event triggering mechanism for registered events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> trigger_event</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Optional[Sample]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Trigger custom event and optionally capture stack.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create CustomEvent instance with provided metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Capture current call stack if sampling is enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Call registered event handler with event data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return Sample with custom event context if stack captured</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> enable_sampling</span><span style=\"color:#E1E4E8\">(self, capture_stacks: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Enable stack capture for custom events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Enable sampling flag to capture stacks on event triggers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Configure stack capture depth and filtering options</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Usage example for application integration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> setup_custom_events</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Example setup for application-specific custom events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CustomEventRegistry()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Database query profiling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> db_query_handler</span><span style=\"color:#E1E4E8\">(event: CustomEvent):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> event.metadata.get(</span><span style=\"color:#9ECBFF\">'duration_ms'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> query_time </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Log slow queries</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Slow query detected: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">query_time</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    registry.register_event(</span><span style=\"color:#9ECBFF\">'db_query'</span><span style=\"color:#E1E4E8\">, db_query_handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Cache operation profiling  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> cache_handler</span><span style=\"color:#E1E4E8\">(event: CustomEvent):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        hit_rate </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> event.metadata.get(</span><span style=\"color:#9ECBFF\">'hit_rate'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> hit_rate </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0.8</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Alert on low hit rates</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Low cache hit rate: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">hit_rate</span><span style=\"color:#F97583\">:.2%</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    registry.register_event(</span><span style=\"color:#9ECBFF\">'cache_operation'</span><span style=\"color:#E1E4E8\">, cache_handler)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> registry</span></span></code></pre></div>\n\n<h4 id=\"multi-language-stack-unwinding\">Multi-Language Stack Unwinding</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Multi-language stack unwinding supporting Python, Go, Rust, and C/C++.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Coordinates language-specific unwinding strategies.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.symbols.resolver </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StackFrame</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LanguageUnwinder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for language-specific stack unwinding.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> can_unwind_frame</span><span style=\"color:#E1E4E8\">(self, frame_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if this unwinder can handle the given frame.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> unwind_stack</span><span style=\"color:#E1E4E8\">(self, context: Any) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Unwind stack using language-specific method.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_language_name</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return language name for this unwinder.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PythonUnwinder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">LanguageUnwinder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Python-specific stack unwinding using interpreter frames.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> can_unwind_frame</span><span style=\"color:#E1E4E8\">(self, frame_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if frame_address points to Python interpreter code</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate frame address against Python runtime memory ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return True if this appears to be a Python frame</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> unwind_stack</span><span style=\"color:#E1E4E8\">(self, context: Any) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Access Python interpreter frame chain using C API</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract Python function names and source file information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert Python bytecode locations to source line numbers  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Build StackFrame list with Python-specific symbol information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_language_name</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"Python\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GoUnwinder</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">LanguageUnwinder</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Go-specific stack unwinding using runtime stack scanner.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> can_unwind_frame</span><span style=\"color:#E1E4E8\">(self, frame_address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if frame_address is within Go executable memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Look for Go runtime stack management symbols</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate against known Go calling conventions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> unwind_stack</span><span style=\"color:#E1E4E8\">(self, context: Any) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use Go runtime stack scanning to find frame boundaries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse Go symbol table format for function names</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle Go goroutine stack switching and runtime calls</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Build StackFrame list with Go-specific naming conventions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_language_name</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#9ECBFF\"> \"Go\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MultiLanguageUnwinder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Coordinates unwinding across multiple language runtimes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.unwinders: List[LanguageUnwinder] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.language_cache: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, LanguageUnwinder] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_unwinder</span><span style=\"color:#E1E4E8\">(self, unwinder: LanguageUnwinder):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register language-specific unwinder.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add unwinder to registry with priority ordering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate unwinder implements required interface methods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Clear language cache when new unwinders are added</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> unwind_mixed_stack</span><span style=\"color:#E1E4E8\">(self, context: Any) -> List[StackFrame]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Unwind stack handling multiple language transitions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start with native unwinding to get initial frame addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: For each frame, find appropriate language-specific unwinder</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Use cached unwinder for previously seen frame addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Merge language-specific frames into unified stack trace</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle transitions between different language runtimes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"distributed-profiling-coordination\">Distributed Profiling Coordination</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Distributed profiling coordination using hierarchical sample aggregation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides cluster-wide profiling with local preprocessing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, asdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> aiohttp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.sampling.sampler </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Profile, Sample</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerNode</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    node_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    port: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    capabilities: Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_heartbeat: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilingSession</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    session_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_processes: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># node_id -> pid</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    duration_seconds: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sampling_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ClusterController</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Coordinates distributed profiling across multiple nodes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, listen_port: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 8080</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.listen_port </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> listen_port</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.active_nodes: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, ProfilerNode] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.profiling_sessions: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, ProfilingSession] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session_results: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[Profile]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> start_distributed_session</span><span style=\"color:#E1E4E8\">(self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                       session_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start coordinated profiling across cluster.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate unique session ID and validate configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Select appropriate nodes based on target processes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Send synchronized start commands to selected nodes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Configure consistent sampling parameters across nodes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return session ID for tracking profiling progress</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> collect_session_results</span><span style=\"color:#E1E4E8\">(self, session_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Collect and merge profiling results from all nodes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Wait for completion signals from all participating nodes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Retrieve Profile data from each node via HTTP API</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Merge sample data while preserving temporal relationships</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Aggregate symbol information across nodes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate unified Profile with cross-service call stacks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> handle_node_heartbeat</span><span style=\"color:#E1E4E8\">(self, node_data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process heartbeat from profiler agent node.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update node status and capabilities in active_nodes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for session assignments that need node participation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Send pending profiling commands to newly available nodes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerAgent</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Local profiler agent that coordinates with cluster controller.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, node_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, controller_address: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.node_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> node_id</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.controller_address </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> controller_address</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.local_profiler </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.active_sessions: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Profile] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> start_agent</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start profiler agent and register with controller.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize local profiler with agent configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Register with cluster controller and report capabilities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start heartbeat loop to maintain controller connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Listen for profiling session commands from controller</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> execute_profiling_session</span><span style=\"color:#E1E4E8\">(self, session_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> Profile:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute local profiling session as part of distributed session.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Configure local profiler using session parameters  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start profiling target process specified in session config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Run profiling for configured duration with synchronized timing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Collect and preprocess samples before sending to controller</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return Profile data for aggregation with other nodes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"streaming-analysis-pipeline\">Streaming Analysis Pipeline</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Streaming analysis pipeline for real-time profiling data processing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides continuous sample analysis with live anomaly detection.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> queue</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> AsyncGenerator, Dict, List, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> statistics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque, defaultdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> core.sampling.sampler </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Sample, Profile</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceBaseline</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    average_samples: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    std_deviation: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence_interval: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    observation_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceAnomaly</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    current_samples: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expected_samples: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    deviation_magnitude: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    anomaly_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">  # 'spike', 'drop', 'trend'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StreamProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Processes profiling samples in real-time streaming fashion.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, window_size_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.window_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> window_size_seconds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sample_windows: deque </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Last 100 windows</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.function_baselines: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, PerformanceBaseline] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.anomaly_callbacks: List[Callable[[PerformanceAnomaly], </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> process_sample_stream</span><span style=\"color:#E1E4E8\">(self, sample_stream: AsyncGenerator[Sample, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process continuous stream of profiling samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Group incoming samples into time-based windows</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Aggregate samples within each window for analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update performance baselines with new sample data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Detect anomalies by comparing current vs baseline patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Trigger registered callbacks when anomalies are detected</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> update_baselines</span><span style=\"color:#E1E4E8\">(self, window_samples: List[Sample]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Update performance baselines with new sample window.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Count samples per function in current window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update running statistics for each function's baseline</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate confidence intervals using statistical methods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Adjust baseline sensitivity based on sample variance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_anomalies</span><span style=\"color:#E1E4E8\">(self, current_samples: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> List[PerformanceAnomaly]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect performance anomalies against established baselines.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compare current sample counts vs baseline expectations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate statistical significance of deviations  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Classify anomaly types (spike, drop, trend change)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate PerformanceAnomaly objects with confidence scores</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Filter anomalies below configured confidence thresholds</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LiveFlameGraphGenerator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generates live flame graphs from streaming sample data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, update_interval_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.update_interval </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> update_interval_seconds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.live_aggregator </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.websocket_clients: Set[WebSocket] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> start_live_updates</span><span style=\"color:#E1E4E8\">(self, sample_stream: AsyncGenerator[Sample, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start live flame graph updates from sample stream.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize live aggregation with sliding window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Process samples continuously and update aggregation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate flame graph updates at configured intervals</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Broadcast flame graph updates to connected WebSocket clients</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle client connections and disconnections gracefully</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_incremental_update</span><span style=\"color:#E1E4E8\">(self, new_samples: List[Sample]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate incremental flame graph update from new samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update live aggregation tree with new sample data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate changes in sample counts since last update</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate delta update containing only changed nodes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Format update for efficient WebSocket transmission</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Include performance anomaly annotations in updates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-extension-validation\">Milestone Checkpoint: Extension Validation</h4>\n<p>After implementing extensions, validate functionality with these checkpoints:</p>\n<p><strong>Hardware Counter Extension:</strong></p>\n<ul>\n<li>Run: <code>python -m profiler.extensions.hardware --target-pid &lt;PID&gt; --duration 30 --counters cycles,instructions,cache-misses</code></li>\n<li>Expected: Flame graph with hardware counter annotations showing IPC and cache miss rates</li>\n<li>Verify: Counter values correlate with CPU-intensive vs memory-intensive functions</li>\n</ul>\n<p><strong>Distributed Profiling Extension:</strong></p>\n<ul>\n<li>Run cluster controller: <code>python -m profiler.extensions.distributed.controller --port 8080</code></li>\n<li>Run agents on multiple machines: <code>python -m profiler.extensions.distributed.agent --controller http://controller:8080</code></li>\n<li>Start distributed session: <code>curl -X POST http://controller:8080/sessions -d &#39;{&quot;targets&quot;: {...}}&#39;</code></li>\n<li>Expected: Unified flame graph combining samples from all participating nodes</li>\n<li>Verify: Cross-service call relationships appear correctly in merged visualization</li>\n</ul>\n<p><strong>Streaming Analysis Extension:</strong></p>\n<ul>\n<li>Run: <code>python -m profiler.extensions.streaming --live-updates --anomaly-detection</code></li>\n<li>Expected: Live flame graph updates in web browser with real-time anomaly highlighting</li>\n<li>Verify: Performance spikes and drops trigger immediate visual annotations</li>\n</ul>\n<p>Each extension should integrate seamlessly with existing profiler functionality while providing enhanced capabilities that justify the additional complexity.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The extension implementation leverages the existing profiler&#39;s plugin architecture to add advanced capabilities without disrupting core functionality. Extensions integrate through well-defined interfaces that maintain backward compatibility while enabling progressive feature adoption.</p>\n<h4 id=\"debugging-extension-integration\">Debugging Extension Integration</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Extension fails to load</td>\n<td>Missing dependencies or interface mismatch</td>\n<td>Check extension registration logs and interface compatibility</td>\n<td>Install missing dependencies and verify interface implementation</td>\n</tr>\n<tr>\n<td>Hardware counters show zero values</td>\n<td>Insufficient permissions or unsupported hardware</td>\n<td>Test perf_event_open with elevated privileges</td>\n<td>Run with CAP_SYS_ADMIN or configure /proc/sys/kernel/perf_event_paranoid</td>\n</tr>\n<tr>\n<td>Distributed profiling loses samples</td>\n<td>Network issues or clock synchronization</td>\n<td>Check network connectivity and NTP synchronization</td>\n<td>Configure reliable network and NTP time synchronization</td>\n</tr>\n<tr>\n<td>Streaming updates lag significantly</td>\n<td>Processing pipeline bottleneck</td>\n<td>Monitor queue sizes and processing rates</td>\n<td>Increase processing parallelism or reduce sample rate</td>\n</tr>\n<tr>\n<td>Multi-language unwinding crashes</td>\n<td>Stack corruption or unsupported runtime</td>\n<td>Enable debug logging for language unwinders</td>\n<td>Add runtime version checks and graceful fallback handling</td>\n</tr>\n</tbody></table>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) — comprehensive terminology and definitions supporting stack sampling, symbol resolution, flame graph generation, and memory profiling implementation</p>\n</blockquote>\n<h3 id=\"mental-model-the-technical-dictionary\">Mental Model: The Technical Dictionary</h3>\n<p>Think of this glossary as a technical dictionary for a specialized domain. Just as a medical dictionary defines terms like &quot;myocardial infarction&quot; with precise clinical meaning, this glossary provides exact definitions for profiling terminology. Each term has specific meaning within the context of performance profiling that differs from general computing usage. For example, &quot;sampling&quot; in profiling specifically means &quot;statistical sampling of execution state&quot; rather than general data sampling.</p>\n<h3 id=\"core-profiling-concepts\">Core Profiling Concepts</h3>\n<p>The fundamental concepts that underpin all profiling activities form the foundation for understanding how performance measurement systems operate.</p>\n<p><strong>Statistical sampling</strong> refers to the periodic observation of program execution state at regular intervals to build a representative picture of program behavior. Unlike exhaustive instrumentation that records every event, statistical sampling captures snapshots at predetermined frequencies, trading completeness for minimal overhead. The key insight is that sufficiently frequent sampling provides statistically valid approximations of actual program behavior while maintaining acceptable performance impact.</p>\n<p><strong>Instrumentation</strong> involves modifying code or runtime behavior to record execution events as they occur. This can take the form of compiler-inserted probes, runtime library interposition, or dynamic binary modification. Instrumentation provides complete event coverage but introduces observer paradox effects where the measurement overhead changes the behavior being measured.</p>\n<p><strong>Observer paradox</strong> describes the fundamental challenge where measurement overhead alters the behavior being profiled. Heavy instrumentation can change timing relationships, memory allocation patterns, and cache behavior, making the profiled execution unrepresentative of normal operation. Effective profilers minimize this paradox through low-overhead collection techniques.</p>\n<p><strong>Overhead</strong> quantifies the performance cost imposed by profiling measurement collection, typically expressed as percentage CPU time increase or memory consumption. Target overhead levels for production profiling usually stay below 2-5% to maintain system responsiveness while gathering useful performance data.</p>\n<h3 id=\"stack-sampling-terminology\">Stack Sampling Terminology</h3>\n<p>Stack sampling involves capturing execution context at regular intervals using timer-based interruption mechanisms.</p>\n<p><strong>Stack sampling</strong> means capturing the complete call stack at regular intervals using timer signals to interrupt program execution. Each sample provides a snapshot of the current function call hierarchy, from the innermost executing function up through all calling functions to the program entry point. Accumulated samples reveal which code paths consume the most execution time.</p>\n<p><strong>Sampling frequency</strong> specifies the rate of stack captures per second measured in Hz. Common frequencies range from 10Hz for low-overhead collection to 10KHz for detailed analysis. Higher frequencies provide better time resolution but increase measurement overhead and data volume. The choice involves balancing precision against performance impact.</p>\n<p><strong>Signal-based interruption</strong> uses operating system timer signals like <code>SIGPROF</code> to periodically interrupt program execution for stack capture. The timer mechanism ensures deterministic sampling intervals independent of program control flow, preventing sampling bias toward particular code patterns or execution paths.</p>\n<p><strong>Stack unwinding</strong> describes the process of walking frame pointers or debug information to reconstruct the complete call chain from the current execution point. This involves traversing linked stack frames backward from the interrupted function through all calling functions to build the complete call hierarchy.</p>\n<p><strong>Frame pointer</strong> refers to the processor register pointing to the current function&#39;s stack frame structure. Frame pointers enable reliable stack traversal by providing a linked list of activation records. However, compiler optimizations may eliminate frame pointers, requiring alternative unwinding mechanisms like DWARF debug information.</p>\n<p><strong>Async-safe</strong> describes functions safe to call from signal handlers without causing deadlocks or corruption. Signal handlers execute in an unpredictable context and must avoid non-reentrant functions like <code>malloc</code>, <code>printf</code>, or mutex operations. Stack sampling signal handlers must use only async-safe operations for reliable data collection.</p>\n<h3 id=\"symbol-resolution-terminology\">Symbol Resolution Terminology</h3>\n<p>Symbol resolution converts raw memory addresses into human-readable function names and source code locations.</p>\n<p><strong>Symbol resolution</strong> involves converting raw memory addresses captured during sampling into human-readable function names and source code locations. This process requires parsing debug information, symbol tables, and handling address space layout randomization to provide meaningful profiling output.</p>\n<p><strong>Debug symbols</strong> contain metadata mapping memory addresses to source code locations and function information. This includes function names, parameter types, source file names, line numbers, and variable locations. Debug symbols enable rich profiling output but significantly increase binary size.</p>\n<p><strong>ASLR (Address Space Layout Randomization)</strong> randomizes the memory layout of program components for security purposes. This means the same function loads at different virtual addresses between program runs. Symbol resolution must account for ASLR by calculating load bias between link-time and runtime addresses.</p>\n<p><strong>DWARF (Debug Information Format)</strong> provides a standardized format for encoding source-level debugging information in object files. DWARF includes line number tables mapping addresses to source locations, call frame information for stack unwinding, and variable location descriptions. Modern symbol resolution relies heavily on DWARF data.</p>\n<p><strong>ELF (Executable and Linkable Format)</strong> defines the binary format for executables and shared libraries on Unix-like systems. ELF files contain symbol tables, debug sections, and program headers needed for symbol resolution. Profilers must parse ELF structure to extract symbol information.</p>\n<p><strong>Demangling</strong> converts mangled C++ symbol names back to readable form. C++ compilers encode function overloading, namespaces, and template parameters into symbol names using complex name mangling schemes. Demangling reverses this process to display human-readable function names in profiling output.</p>\n<p><strong>Load bias</strong> represents the offset between link-time virtual addresses and actual runtime load addresses. ASLR and dynamic linking cause programs to load at different addresses than specified during linking. Symbol resolution must calculate and apply load bias to correctly map runtime addresses to symbols.</p>\n<h3 id=\"flame-graph-terminology\">Flame Graph Terminology</h3>\n<p>Flame graphs provide hierarchical visualization of profiling data showing call stack relationships and frequency.</p>\n<p><strong>Flame graph</strong> displays a hierarchical visualization showing call stack frequency and relationships. Functions appear as horizontal rectangles where width represents time spent (sample count) and vertical position shows call depth. This creates a flame-like appearance with the main function at the bottom and leaf functions at the top.</p>\n<p><strong>Stack folding</strong> converts individual stack traces into aggregated signature counts by creating unique identifiers for each call stack sequence. Multiple samples with identical call stacks get merged into a single entry with accumulated sample counts, reducing data volume while preserving call context.</p>\n<p><strong>Folded stack format</strong> uses semicolon-delimited text to represent call stacks with sample counts. Each line contains a complete call stack from bottom to top with function names separated by semicolons, followed by a space and sample count. This format enables efficient aggregation and flame graph generation.</p>\n<p><strong>Coordinate calculation</strong> maps logical tree structures to pixel positions for visualization. This involves calculating rectangle coordinates based on sample counts, determining appropriate scaling factors, and handling text layout within flame graph rectangles. Proper coordinate calculation ensures accurate visual representation of profiling data.</p>\n<p><strong>Interactive SVG</strong> provides scalable vector graphics with embedded JavaScript for user interactions. Interactive flame graphs support zooming into specific subtrees, searching for function names, and displaying detailed information on hover. SVG format ensures crisp rendering at any zoom level.</p>\n<p><strong>Color scheme</strong> defines systematic color assignment strategies for visual distinction between different categories of functions. Common schemes include category-based coloring (user code vs. libraries vs. kernel), module-based coloring, or hash-based coloring for consistent function identification across different flame graphs.</p>\n<p><strong>Stack signature</strong> creates unique identifier strings from call stack sequences for aggregation purposes. Signatures typically concatenate function names in call order to create hash keys for grouping identical stacks. Proper signature generation enables efficient stack folding and flame graph construction.</p>\n<p><strong>Hierarchical aggregation</strong> builds tree structures that preserve calling context while accumulating sample counts. Each tree node represents a function at a specific call depth, with children representing functions called from that context. Sample counts propagate upward to show inclusive time spent in each subtree.</p>\n<p><strong>Weight calculation</strong> determines visual width based on cumulative sample counts to accurately represent time proportions. Rectangle width in flame graphs must accurately reflect the percentage of total time spent in each function relative to siblings at the same call depth.</p>\n<p><strong>Bottom-up layout</strong> orientates flame graphs with the main function at the bottom and leaf functions at the top. This layout matches the natural stack growth direction and provides intuitive visualization where deeper call stacks appear higher in the graph.</p>\n<h3 id=\"memory-profiling-terminology\">Memory Profiling Terminology</h3>\n<p>Memory profiling involves tracking allocation patterns and detecting memory leaks through runtime interposition.</p>\n<p><strong>Function interposition</strong> intercepts calls to library functions like <code>malloc</code> and <code>free</code> to track memory operations. This can be implemented through <code>LD_PRELOAD</code> library replacement, dynamic symbol interposition, or compile-time instrumentation. Interposition enables comprehensive allocation tracking without source code modification.</p>\n<p><strong>Allocation metadata</strong> contains tracking information for each memory allocation including size, timestamp, thread ID, and call stack context. This metadata enables leak detection, allocation site analysis, and memory usage pattern identification. Metadata overhead must be minimized to avoid significant memory consumption.</p>\n<p><strong>Leak detection</strong> identifies allocations without corresponding free operations by analyzing allocation metadata at program termination or specific checkpoints. True leaks require distinguishing between definitely lost memory and memory that remains reachable but was never explicitly freed.</p>\n<p><strong>Allocation site</strong> refers to the unique call stack location where memory allocation occurs. Grouping allocations by site enables identification of problematic allocation patterns, excessive allocation frequency, or growing memory usage trends. Allocation site analysis helps prioritize memory optimization efforts.</p>\n<p><strong>Recursion detection</strong> prevents infinite loops in allocation tracking when the tracking system itself triggers additional allocations. Memory profilers must use thread-local storage or other mechanisms to detect when they are executing within their own allocation tracking code to avoid recursive instrumentation.</p>\n<p><strong>Thread-local storage</strong> provides per-thread data storage for tracking allocation context without requiring locks or atomic operations. This enables efficient allocation metadata management in multi-threaded programs while avoiding synchronization overhead that could affect program timing.</p>\n<p><strong>Suppression rules</strong> define patterns to filter false positive leaks from analysis results. These rules identify allocation sites known to produce intentional long-lived allocations that appear as leaks but represent normal program behavior. Suppressions improve signal-to-noise ratio in leak reports.</p>\n<p><strong>Growth patterns</strong> identify allocation sites with unbounded memory growth that may indicate resource leaks even if individual allocations are properly freed. These patterns detect scenarios where allocation rate exceeds free rate, leading to gradual memory consumption increases over time.</p>\n<h3 id=\"error-handling-and-recovery-terminology\">Error Handling and Recovery Terminology</h3>\n<p>Robust profiling systems require comprehensive error handling and graceful degradation strategies.</p>\n<p><strong>Graceful degradation</strong> maintains core functionality despite errors or missing data by falling back to simplified behavior when full functionality is unavailable. For example, symbol resolution might display raw addresses when debug symbols are missing, or flame graphs might use simplified color schemes when detailed categorization fails.</p>\n<p><strong>Backpressure</strong> occurs when downstream processing stages become overwhelmed and upstream stages must slow down or drop work to prevent memory exhaustion. Profiling pipelines implement backpressure handling through bounded queues, sample dropping policies, and flow control mechanisms.</p>\n<h3 id=\"performance-analysis-terminology\">Performance Analysis Terminology</h3>\n<p>Advanced profiling involves hardware performance monitoring and anomaly detection capabilities.</p>\n<p><strong>Hardware performance counters</strong> are specialized CPU registers that track execution events like instruction counts, cache misses, branch predictions, and memory access patterns. These counters provide detailed microarchitectural insights beyond basic timing information available through software sampling.</p>\n<p><strong>Event-based sampling</strong> triggers sample collection based on hardware events rather than fixed time intervals. For example, sampling every 10,000 cache misses provides insight into cache-sensitive code patterns regardless of execution time. Event-based sampling reveals performance characteristics invisible to time-based sampling.</p>\n<p><strong>Custom event sampling</strong> enables application-specific profiling events for domain-specific performance analysis. Applications can register custom events and trigger sample collection at semantically meaningful points like transaction boundaries, request completion, or algorithm phases.</p>\n<p><strong>Multi-language profiling</strong> involves profiling polyglot applications that execute across multiple runtime environments like native code, JVM, Python interpreter, and JavaScript engines. This requires coordinating profiling data collection across different execution environments and unifying results for coherent analysis.</p>\n<p><strong>Performance baseline</strong> establishes normal performance characteristics for comparison against current measurements. Baselines enable detection of performance regressions, identification of unusual behavior patterns, and validation that optimizations produce expected improvements.</p>\n<p><strong>Anomaly detection</strong> identifies significant deviations from established performance baselines using statistical analysis. This enables automated identification of performance issues, unusual execution patterns, or potential optimization opportunities without manual analysis of profiling data.</p>\n<h3 id=\"distributed-profiling-terminology\">Distributed Profiling Terminology</h3>\n<p>Large-scale profiling systems require coordination across multiple processes and machines.</p>\n<p><strong>Distributed profiling</strong> coordinates profiling data collection across multiple processes or machines to provide system-wide performance visibility. This involves timestamp synchronization, distributed sample aggregation, and unified visualization of multi-node profiling results.</p>\n<p><strong>Streaming data processing</strong> enables real-time continuous analysis of profiling samples as they are collected rather than batch processing after collection completion. Streaming processing supports live profiling dashboards, real-time anomaly detection, and immediate feedback on performance changes.</p>\n<p><strong>Federated profiling</strong> implements hierarchical distributed profiling architectures where local profiling agents aggregate data before forwarding to central collection systems. This approach scales profiling data collection across large systems while managing network bandwidth and central processing requirements.</p>\n<p><strong>Clock synchronization</strong> maintains consistent timestamps across distributed profiling nodes to enable accurate temporal correlation of events. Without proper clock synchronization, distributed profiling data cannot be meaningfully aggregated or analyzed for causality relationships.</p>\n<h3 id=\"data-structure-and-algorithm-terminology\">Data Structure and Algorithm Terminology</h3>\n<p>Implementation requires understanding of core data structures and algorithms used throughout profiling systems.</p>\n<p>The following table defines key data structure concepts used throughout the profiler implementation:</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Usage Context</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Ring buffer</td>\n<td>Fixed-size circular buffer for sample storage with overflow handling</td>\n<td>Sample collection buffering</td>\n</tr>\n<tr>\n<td>Hash table</td>\n<td>Key-value mapping for fast symbol and allocation lookups</td>\n<td>Symbol caches, allocation tracking</td>\n</tr>\n<tr>\n<td>Binary search tree</td>\n<td>Ordered tree structure for efficient address range queries</td>\n<td>Symbol table organization</td>\n</tr>\n<tr>\n<td>Trie structure</td>\n<td>Prefix tree for efficient string matching and completion</td>\n<td>Function name search indexing</td>\n</tr>\n<tr>\n<td>Priority queue</td>\n<td>Ordered queue for processing items by importance or timestamp</td>\n<td>Sample processing prioritization</td>\n</tr>\n<tr>\n<td>Bloom filter</td>\n<td>Probabilistic data structure for fast membership testing</td>\n<td>Symbol cache miss optimization</td>\n</tr>\n<tr>\n<td>LRU cache</td>\n<td>Least-recently-used cache eviction policy for bounded memory usage</td>\n<td>Symbol cache management</td>\n</tr>\n<tr>\n<td>Copy-on-write</td>\n<td>Memory optimization technique sharing data until modification</td>\n<td>Sample batch optimization</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-constants-and-defaults\">Implementation Constants and Defaults</h3>\n<p>The following table defines standard constants and default values used throughout the profiler implementation:</p>\n<table>\n<thead>\n<tr>\n<th>Constant</th>\n<th>Value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>DEFAULT_FREQUENCY_HZ</code></td>\n<td>100</td>\n<td>Default sampling frequency in samples per second</td>\n</tr>\n<tr>\n<td><code>MAX_STACK_DEPTH</code></td>\n<td>128</td>\n<td>Maximum call stack frames to capture per sample</td>\n</tr>\n<tr>\n<td><code>TARGET_OVERHEAD_PERCENT</code></td>\n<td>2.0</td>\n<td>Target profiling overhead as percentage of CPU time</td>\n</tr>\n<tr>\n<td><code>DEFAULT_RECTANGLE_HEIGHT</code></td>\n<td>18</td>\n<td>Default flame graph rectangle height in pixels</td>\n</tr>\n<tr>\n<td><code>MIN_WIDTH_THRESHOLD</code></td>\n<td>0.5</td>\n<td>Minimum rectangle width in pixels for flame graph display</td>\n</tr>\n<tr>\n<td><code>DEFAULT_WINDOW_SIZE</code></td>\n<td>60</td>\n<td>Default time window in seconds for analysis</td>\n</tr>\n<tr>\n<td><code>ANOMALY_CONFIDENCE_THRESHOLD</code></td>\n<td>0.95</td>\n<td>Confidence threshold for performance anomaly detection</td>\n</tr>\n<tr>\n<td><code>PERF_COUNT_HW_CPU_CYCLES</code></td>\n<td>0</td>\n<td>Hardware performance counter for CPU cycles</td>\n</tr>\n<tr>\n<td><code>PERF_COUNT_HW_INSTRUCTIONS</code></td>\n<td>1</td>\n<td>Hardware performance counter for instructions executed</td>\n</tr>\n<tr>\n<td><code>PERF_COUNT_HW_CACHE_REFERENCES</code></td>\n<td>2</td>\n<td>Hardware performance counter for cache references</td>\n</tr>\n<tr>\n<td><code>PERF_COUNT_HW_CACHE_MISSES</code></td>\n<td>3</td>\n<td>Hardware performance counter for cache misses</td>\n</tr>\n</tbody></table>\n<h3 id=\"system-integration-terminology\">System Integration Terminology</h3>\n<p>Profilers must integrate with operating system facilities and development toolchains.</p>\n<p><strong>Signal delivery</strong> describes the mechanism by which the operating system delivers timer signals to target processes for stack sampling. Understanding signal delivery behavior is crucial for reliable sampling, especially in multi-threaded programs where signals may be delivered to arbitrary threads.</p>\n<p><strong>Dynamic linking</strong> enables runtime loading and symbol resolution of shared libraries. Profilers must track dynamically loaded libraries and update symbol tables when libraries are loaded or unloaded during program execution.</p>\n<p><strong>Process attachment</strong> allows profilers to connect to already-running processes rather than requiring restart under profiler control. This capability enables profiling of long-running services, debugging production issues, and ad-hoc performance analysis.</p>\n<p><strong>Container profiling</strong> involves profiling applications running within containerized environments where traditional profiling techniques may be limited by container security policies, namespace isolation, or resource constraints.</p>\n<h3 id=\"visualization-and-user-interface-terminology\">Visualization and User Interface Terminology</h3>\n<p>Effective profiling requires intuitive visualization and interaction mechanisms.</p>\n<p><strong>Zooming</strong> enables users to focus on specific portions of flame graphs by expanding selected regions to fill the display area. Proper zooming maintains visual context while providing detailed examination of performance hotspots.</p>\n<p><strong>Search functionality</strong> allows users to quickly locate specific functions within large flame graphs through text matching and highlighting. Search typically supports substring matching, regular expressions, and navigation between multiple matches.</p>\n<p><strong>Tooltip display</strong> provides detailed information when users hover over flame graph elements, including exact sample counts, percentages, source file locations, and function signatures. Tooltips enhance usability without cluttering the visual display.</p>\n<p><strong>Color coding</strong> systematically assigns colors to distinguish different categories of functions, modules, or performance characteristics. Effective color coding enables quick visual identification of patterns and reduces cognitive load during analysis.</p>\n<h3 id=\"quality-assurance-terminology\">Quality Assurance Terminology</h3>\n<p>Profiler development requires comprehensive testing and validation strategies.</p>\n<p><strong>Regression testing</strong> validates that profiler functionality continues working correctly as implementation evolves. This includes testing against known workloads with expected results, performance overhead validation, and compatibility testing across different environments.</p>\n<p><strong>Stress testing</strong> validates profiler behavior under extreme conditions like very high sampling frequencies, large call stacks, rapid allocation patterns, or resource-constrained environments. Stress testing reveals breaking points and failure modes.</p>\n<p><strong>Accuracy validation</strong> compares profiler results against known ground truth or reference implementations to ensure measurement correctness. This involves synthetic workloads with predictable behavior and cross-validation with established profiling tools.</p>\n<p><strong>Overhead measurement</strong> quantifies the performance impact of profiling on target applications through controlled before-and-after comparisons. Overhead measurements must account for different workload characteristics and system configurations.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-stack-selection\">Technology Stack Selection</h4>\n<p>The following table provides technology recommendations for implementing different aspects of the profiler:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signal handling</td>\n<td>Python signal module</td>\n<td>Custom C extension for signal handlers</td>\n</tr>\n<tr>\n<td>Binary parsing</td>\n<td>pyelftools library</td>\n<td>Custom ELF parser with mmap</td>\n</tr>\n<tr>\n<td>Symbol management</td>\n<td>dictionaries with linear search</td>\n<td>B-tree or radix tree implementation</td>\n</tr>\n<tr>\n<td>SVG generation</td>\n<td>string formatting with templates</td>\n<td>XML library with DOM manipulation</td>\n</tr>\n<tr>\n<td>Memory tracking</td>\n<td>ctypes with LD_PRELOAD</td>\n<td>Custom malloc implementation</td>\n</tr>\n<tr>\n<td>Threading</td>\n<td>threading module with locks</td>\n<td>multiprocessing for isolation</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>JSON files with dict parsing</td>\n<td>YAML with schema validation</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Python logging module</td>\n<td>Structured logging with correlation IDs</td>\n</tr>\n</tbody></table>\n<h4 id=\"project-file-organization\">Project File Organization</h4>\n<p>Organize the profiler implementation following this recommended directory structure:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>cpu_memory_profiler/\n  __init__.py                     ← package initialization\n  cli/\n    main.py                       ← command line interface\n    config.py                     ← configuration management\n  core/\n    sampler.py                    ← stack sampling implementation\n    symbolizer.py                 ← symbol resolution implementation  \n    aggregator.py                 ← flame graph aggregation\n    memory_tracker.py             ← memory profiling implementation\n  data/\n    models.py                     ← data structure definitions\n    serialization.py              ← data format handling\n  visualization/\n    flame_graph.py                ← SVG generation\n    color_schemes.py              ← color mapping logic\n  utils/\n    elf_parser.py                 ← ELF binary parsing utilities\n    signal_utils.py               ← signal handling utilities\n    time_utils.py                 ← timestamp and timing utilities\n  tests/\n    test_sampler.py               ← sampling component tests\n    test_symbolizer.py            ← symbol resolution tests\n    test_memory.py                ← memory profiling tests\n    test_integration.py           ← end-to-end integration tests\n    fixtures/                     ← test data and programs\n  examples/\n    basic_profiling.py            ← simple usage examples\n    advanced_config.py            ← complex configuration examples</code></pre></div>\n\n<h4 id=\"core-data-structures-implementation\">Core Data Structures Implementation</h4>\n<p>Complete implementation of essential profiler data structures:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Optional, Any, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StackFrame</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a single frame in a call stack.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filename: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    module_offset: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    inlined_frames: List[</span><span style=\"color:#9ECBFF\">'InlinedFrame'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_kernel: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> InlinedFrame</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents an inlined function within a stack frame.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    function_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filename: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    line_number: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    call_filename: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    call_line_number: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SampleType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Types of profiling samples.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CPU_TIME</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"cpu_time\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WALL_TIME</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"wall_time\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MEMORY_ALLOCATION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"memory_allocation\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CUSTOM_EVENT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"custom_event\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Sample</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"A single profiling sample with complete context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    process_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stack_frames: List[StackFrame]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cpu_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_weight: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context_switches: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sample_type: SampleType </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SampleType.</span><span style=\"color:#79B8FF\">CPU_TIME</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AllocationType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Types of memory allocations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MALLOC</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"malloc\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CALLOC</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"calloc\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    REALLOC</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"realloc\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    NEW</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"new\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    NEW_ARRAY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"new[]\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LeakCategory</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Categories of memory leaks.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DEFINITE_LEAK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"definite_leak\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    POSSIBLE_LEAK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"possible_leak\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    REACHABLE_LEAK</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"reachable_leak\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    GROWTH_PATTERN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"growth_pattern\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Allocation</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Tracks a single memory allocation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    size: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    actual_size: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    thread_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_stack: List[StackFrame]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    allocation_type: AllocationType</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_freed: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_timestamp: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    free_thread_id: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_lifetime</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate allocation lifetime in seconds.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_freed:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.free_timestamp </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp</span></span></code></pre></div>\n\n<h4 id=\"configuration-management\">Configuration Management</h4>\n<p>Complete configuration system with validation and defaults:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SamplingConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for stack sampling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    frequency_hz: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_stack_depth: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 128</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    include_kernel: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_overhead_percent: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate configuration values.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        issues </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.frequency_hz </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            issues.append(</span><span style=\"color:#9ECBFF\">\"frequency_hz must be between 1 and 10000\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_stack_depth </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 512</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            issues.append(</span><span style=\"color:#9ECBFF\">\"max_stack_depth must be between 1 and 512\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> 0.1</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.target_overhead_percent </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 50.0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            issues.append(</span><span style=\"color:#9ECBFF\">\"target_overhead_percent must be between 0.1 and 50.0\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> issues</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for symbol resolution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_dwarf: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_symbols: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    demangle_cpp: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbol_search_paths: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">\"/usr/lib/debug\"</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VisualizationConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for flame graph generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    color_scheme: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"category\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_width_pixels: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"CPU Profile\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_search: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    enable_zoom: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete profiler configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sampling: SamplingConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SamplingConfig)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    symbols: SymbolConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">SymbolConfig)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    visualization: VisualizationConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">VisualizationConfig)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    output_directory: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"./profiler_output\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_json</span><span style=\"color:#E1E4E8\">(cls, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'ProfilerConfig'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load configuration from JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement JSON loading with error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate all configuration sections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Apply defaults for missing values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return populated ProfilerConfig instance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_json</span><span style=\"color:#E1E4E8\">(self, config_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Save configuration to JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert dataclass to dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Write JSON file with proper formatting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle file system errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"essential-profiling-pipeline-skeleton\">Essential Profiling Pipeline Skeleton</h4>\n<p>Core profiling coordination with detailed implementation guidance:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> signal</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ctypes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> queue </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Queue, Empty</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> threading </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Thread, Event</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque, defaultdict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProfilerPipeline</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Coordinates the complete profiling pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: ProfilerConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PipelineStats()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sample_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Queue(</span><span style=\"color:#FFAB70\">maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbolized_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Queue(</span><span style=\"color:#FFAB70\">maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">5000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.aggregated_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Queue(</span><span style=\"color:#FFAB70\">maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._stop_event </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Event()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> start_profiling</span><span style=\"color:#E1E4E8\">(self, target_pid: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, duration_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Start the complete profiling pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate target process exists and is accessible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start sampling thread with signal-based interruption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start symbol resolution thread processing sample queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start aggregation thread building flame graph data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up timer for duration-based stopping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize pipeline statistics tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> stop_profiling</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#9ECBFF\">'Profile'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Stop profiling pipeline and return collected data.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Signal all threads to stop processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Drain remaining samples from all queues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Finalize symbol resolution for remaining samples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Complete aggregation and generate final flame graph</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Collect and return comprehensive Profile object</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RingBuffer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Lock-free ring buffer for high-frequency sample collection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, capacity: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> capacity</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.buffer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">capacity)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.dropped_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.total_added </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_sample</span><span style=\"color:#E1E4E8\">(self, sample: Sample) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add sample to buffer, returning False if dropped.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Acquire lock for thread-safe access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if buffer is at capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Drop oldest sample if necessary and increment dropped_count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add new sample to buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update total_added counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return success/failure status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"symbol-resolution-utilities\">Symbol Resolution Utilities</h4>\n<p>Complete ELF parsing and symbol management implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> mmap</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> BinaryIO</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> struct</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ELFParser</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Parses ELF binaries for symbol information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, binary_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.binary_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> binary_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.symbols </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.load_bias </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> parse_symbol_table</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Symbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse ELF symbol table and return symbol mappings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Open binary file with mmap for efficient access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse ELF header to locate symbol table sections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Iterate through symbol table entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract symbol name, address, size, and type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Build Symbol objects with complete metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return dictionary mapping addresses to symbols</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> parse_dwarf_debug_info</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, LineRange]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Parse DWARF debug information for line number mappings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Locate .debug_line section in ELF file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse DWARF line number program header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Execute line number program to build address-to-line mappings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create LineRange objects with source file information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return mapping from addresses to source locations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SymbolCache</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"LRU cache for resolved symbols with miss tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.address_to_symbol </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.module_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.demangled_names </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.miss_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> set</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_cache_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.hit_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.miss_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> lookup_symbol</span><span style=\"color:#E1E4E8\">(self, address: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Optional[Symbol]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Look up cached symbol or return None for cache miss.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if address is in miss cache (known failures)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Look up symbol in address_to_symbol cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Update hit/miss statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement LRU eviction if cache exceeds max_size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return cached symbol or None</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-validation-checkpoints\">Milestone Validation Checkpoints</h4>\n<p>After implementing each milestone, validate functionality using these specific tests:</p>\n<p><strong>Milestone 1 Validation - Stack Sampling:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Expected: Successful sample collection with configurable frequency</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> cpu_memory_profiler.tests.test_sampler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should output: \"Collected X samples at Y Hz frequency\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Profile a simple CPU-bound loop for 5 seconds</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/basic_profiling.py</span><span style=\"color:#79B8FF\"> --target-pid</span><span style=\"color:#79B8FF\"> 1234</span><span style=\"color:#79B8FF\"> --duration</span><span style=\"color:#79B8FF\"> 5</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Validation - Symbol Resolution:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Expected: Raw addresses converted to function names</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> cpu_memory_profiler.tests.test_symbolizer</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should output: Function names instead of hex addresses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Symbols should include main(), library functions</span></span></code></pre></div>\n\n<p><strong>Milestone 3 Validation - Flame Graph Generation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Expected: Interactive SVG flame graph file generated</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> examples/generate_flame_graph.py</span><span style=\"color:#79B8FF\"> --input</span><span style=\"color:#9ECBFF\"> profile.data</span><span style=\"color:#79B8FF\"> --output</span><span style=\"color:#9ECBFF\"> flame.svg</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should output: flame.svg file viewable in web browser with zoom/search</span></span></code></pre></div>\n\n<p><strong>Milestone 4 Validation - Memory Profiling:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Expected: Memory allocations tracked with leak detection</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> cpu_memory_profiler.tests.test_memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should output: Allocation sites and detected leaks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification: Profile program with known memory leaks</span></span></code></pre></div>\n\n<h4 id=\"common-implementation-pitfalls\">Common Implementation Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Signal Handler Safety Violations</strong></p>\n<p>Many developers incorrectly call non-async-safe functions from signal handlers, causing deadlocks or corruption. Signal handlers can only safely call a limited set of functions listed in signal-safety(7).</p>\n<p><strong>Wrong approach:</strong> Calling <code>malloc()</code>, <code>printf()</code>, or acquiring locks in signal handlers.</p>\n<p><strong>Correct approach:</strong> Use only async-safe functions and pre-allocated buffers. Copy minimal data in the signal handler and defer complex processing to safe contexts.</p>\n<p>⚠️ <strong>Pitfall: Ignoring ASLR in Symbol Resolution</strong></p>\n<p>Forgetting to calculate load bias causes symbol resolution to fail because runtime addresses don&#39;t match symbol table addresses.</p>\n<p><strong>Wrong approach:</strong> Directly using symbol table addresses for runtime address lookup.</p>\n<p><strong>Correct approach:</strong> Calculate load bias by comparing actual module load address with symbol table base address, then apply bias to all symbol lookups.</p>\n<p>⚠️ <strong>Pitfall: Recursive Allocation Tracking</strong></p>\n<p>Memory profilers that use <code>malloc()</code> internally for tracking data structures trigger recursive allocation calls, leading to stack overflow or infinite loops.</p>\n<p><strong>Wrong approach:</strong> Using standard allocation functions in tracking code.</p>\n<p><strong>Correct approach:</strong> Use thread-local flags to detect recursion and pre-allocated buffers or alternative allocation strategies for tracking metadata.</p>\n","toc":[{"level":1,"text":"CPU/Memory Profiler: Design Document","id":"cpumemory-profiler-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"Mental Model: The Detective Analogy","id":"mental-model-the-detective-analogy"},{"level":3,"text":"Existing Profiling Solutions","id":"existing-profiling-solutions"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations Table","id":"technology-recommendations-table"},{"level":4,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton","id":"core-logic-skeleton"},{"level":4,"text":"Language-Specific Implementation Hints","id":"language-specific-implementation-hints"},{"level":4,"text":"Milestone Verification Checkpoints","id":"milestone-verification-checkpoints"},{"level":4,"text":"Common Setup Pitfalls","id":"common-setup-pitfalls"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Mental Model: The Telescope Analogy","id":"mental-model-the-telescope-analogy"},{"level":3,"text":"Functional Goals","id":"functional-goals"},{"level":4,"text":"Statistical Sampling Profiling","id":"statistical-sampling-profiling"},{"level":4,"text":"Symbol Resolution and Debug Information","id":"symbol-resolution-and-debug-information"},{"level":4,"text":"Interactive Flame Graph Visualization","id":"interactive-flame-graph-visualization"},{"level":4,"text":"Memory Allocation Tracking and Leak Detection","id":"memory-allocation-tracking-and-leak-detection"},{"level":3,"text":"Non-Functional Goals","id":"non-functional-goals"},{"level":4,"text":"Performance and Overhead Constraints","id":"performance-and-overhead-constraints"},{"level":4,"text":"Reliability and Error Handling","id":"reliability-and-error-handling"},{"level":4,"text":"Usability and Developer Experience","id":"usability-and-developer-experience"},{"level":3,"text":"Explicit Non-Goals","id":"explicit-non-goals"},{"level":4,"text":"Advanced Profiling Modalities","id":"advanced-profiling-modalities"},{"level":4,"text":"Production Deployment Features","id":"production-deployment-features"},{"level":4,"text":"Advanced Memory Analysis","id":"advanced-memory-analysis"},{"level":4,"text":"Integration and Ecosystem Features","id":"integration-and-ecosystem-features"},{"level":3,"text":"Success Metrics and Validation Criteria","id":"success-metrics-and-validation-criteria"},{"level":4,"text":"Functional Success Metrics","id":"functional-success-metrics"},{"level":4,"text":"Non-Functional Success Metrics","id":"non-functional-success-metrics"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":4,"text":"Configuration Management Infrastructure","id":"configuration-management-infrastructure"},{"level":4,"text":"Utility Infrastructure","id":"utility-infrastructure"},{"level":4,"text":"Milestone Verification Checkpoints","id":"milestone-verification-checkpoints"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Mental Model: The Observatory Network","id":"mental-model-the-observatory-network"},{"level":3,"text":"Component Overview","id":"component-overview"},{"level":4,"text":"Core Component Responsibilities","id":"core-component-responsibilities"},{"level":4,"text":"Component Interaction Patterns","id":"component-interaction-patterns"},{"level":4,"text":"Cross-Cutting Concerns","id":"cross-cutting-concerns"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":4,"text":"Component Interface Design Principles","id":"component-interface-design-principles"},{"level":3,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"File Organization Rationale","id":"file-organization-rationale"},{"level":4,"text":"Module Dependency Guidelines","id":"module-dependency-guidelines"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Configuration Infrastructure Starter Code","id":"configuration-infrastructure-starter-code"},{"level":4,"text":"Core Data Model Infrastructure","id":"core-data-model-infrastructure"},{"level":4,"text":"Utility Infrastructure","id":"utility-infrastructure"},{"level":4,"text":"Core Component Interface Skeletons","id":"core-component-interface-skeletons"},{"level":4,"text":"Language-Specific Implementation Notes","id":"language-specific-implementation-notes"},{"level":4,"text":"Common Pitfalls and Solutions","id":"common-pitfalls-and-solutions"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Mental Model: The Evidence Collection System","id":"mental-model-the-evidence-collection-system"},{"level":3,"text":"Sample and Stack Structures","id":"sample-and-stack-structures"},{"level":4,"text":"Core Sample Representation","id":"core-sample-representation"},{"level":4,"text":"Stack Frame Representation","id":"stack-frame-representation"},{"level":4,"text":"Inlined Function Handling","id":"inlined-function-handling"},{"level":4,"text":"Sample Collection and Batching","id":"sample-collection-and-batching"},{"level":3,"text":"Symbol and Debug Information","id":"symbol-and-debug-information"},{"level":4,"text":"Symbol Table Representation","id":"symbol-table-representation"},{"level":4,"text":"Line Number Information","id":"line-number-information"},{"level":4,"text":"Module and Binary Information","id":"module-and-binary-information"},{"level":4,"text":"Symbol Cache and Performance","id":"symbol-cache-and-performance"},{"level":3,"text":"Memory Allocation Structures","id":"memory-allocation-structures"},{"level":4,"text":"Allocation Event Tracking","id":"allocation-event-tracking"},{"level":4,"text":"Memory Usage Timeline","id":"memory-usage-timeline"},{"level":4,"text":"Leak Detection and Classification","id":"leak-detection-and-classification"},{"level":4,"text":"Allocation Site Analysis","id":"allocation-site-analysis"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Data Structure Implementation","id":"core-data-structure-implementation"},{"level":4,"text":"Memory Allocation Tracking Implementation","id":"memory-allocation-tracking-implementation"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips for Data Model Issues","id":"debugging-tips-for-data-model-issues"},{"level":2,"text":"Stack Sampling Component","id":"stack-sampling-component"},{"level":3,"text":"Mental Model: Photography Metaphor","id":"mental-model-photography-metaphor"},{"level":3,"text":"Signal-Based Sampling","id":"signal-based-sampling"},{"level":3,"text":"Stack Frame Unwinding","id":"stack-frame-unwinding"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Symbol Resolution Component","id":"symbol-resolution-component"},{"level":3,"text":"Mental Model: Address Book Lookup","id":"mental-model-address-book-lookup"},{"level":3,"text":"ELF Binary and Symbol Table Parsing","id":"elf-binary-and-symbol-table-parsing"},{"level":3,"text":"DWARF Debug Information","id":"dwarf-debug-information"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Flame Graph Generation Component","id":"flame-graph-generation-component"},{"level":3,"text":"Mental Model: Family Tree Visualization","id":"mental-model-family-tree-visualization"},{"level":3,"text":"Stack Folding and Aggregation","id":"stack-folding-and-aggregation"},{"level":3,"text":"Interactive SVG Generation","id":"interactive-svg-generation"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Memory Profiling Component","id":"memory-profiling-component"},{"level":3,"text":"Mental Model: Library Book Checkout","id":"mental-model-library-book-checkout"},{"level":3,"text":"Allocation Function Interposition","id":"allocation-function-interposition"},{"level":3,"text":"Memory Leak Detection","id":"memory-leak-detection"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":2,"text":"Interactions and Data Flow","id":"interactions-and-data-flow"},{"level":3,"text":"Mental Model: The Assembly Line","id":"mental-model-the-assembly-line"},{"level":3,"text":"Profiling Data Pipeline","id":"profiling-data-pipeline"},{"level":4,"text":"Primary Pipeline Stages","id":"primary-pipeline-stages"},{"level":4,"text":"Pipeline Performance Characteristics","id":"pipeline-performance-characteristics"},{"level":4,"text":"Error Propagation and Recovery","id":"error-propagation-and-recovery"},{"level":3,"text":"Memory Tracking Data Flow","id":"memory-tracking-data-flow"},{"level":4,"text":"Memory Tracking Architecture","id":"memory-tracking-architecture"},{"level":4,"text":"Memory Data Structures and Flow","id":"memory-data-structures-and-flow"},{"level":4,"text":"Leak Detection Algorithm","id":"leak-detection-algorithm"},{"level":3,"text":"Output Formats and APIs","id":"output-formats-and-apis"},{"level":4,"text":"Primary Output Formats","id":"primary-output-formats"},{"level":4,"text":"API Integration Points","id":"api-integration-points"},{"level":4,"text":"Data Export Pipeline","id":"data-export-pipeline"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Pipeline Infrastructure","id":"core-pipeline-infrastructure"},{"level":4,"text":"Memory Tracking Infrastructure","id":"memory-tracking-infrastructure"},{"level":4,"text":"Output Format Generation","id":"output-format-generation"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Mental Model: The Safety Net System","id":"mental-model-the-safety-net-system"},{"level":3,"text":"Sampling Error Scenarios","id":"sampling-error-scenarios"},{"level":4,"text":"Signal Delivery Failures","id":"signal-delivery-failures"},{"level":4,"text":"Stack Unwinding Errors","id":"stack-unwinding-errors"},{"level":4,"text":"Buffer Overflow and Sample Loss","id":"buffer-overflow-and-sample-loss"},{"level":3,"text":"Symbol Resolution Failures","id":"symbol-resolution-failures"},{"level":4,"text":"Missing Debug Symbols","id":"missing-debug-symbols"},{"level":4,"text":"Corrupted Debug Information","id":"corrupted-debug-information"},{"level":4,"text":"Symbol Cache Corruption","id":"symbol-cache-corruption"},{"level":3,"text":"Memory Tracking Edge Cases","id":"memory-tracking-edge-cases"},{"level":4,"text":"Allocation Function Interposition Failures","id":"allocation-function-interposition-failures"},{"level":4,"text":"Memory Leak Detection False Positives","id":"memory-leak-detection-false-positives"},{"level":4,"text":"Allocation Metadata Corruption","id":"allocation-metadata-corruption"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Mental Model: The Quality Assurance Laboratory","id":"mental-model-the-quality-assurance-laboratory"},{"level":3,"text":"Unit Testing Approach","id":"unit-testing-approach"},{"level":4,"text":"Stack Sampling Component Testing","id":"stack-sampling-component-testing"},{"level":4,"text":"Symbol Resolution Component Testing","id":"symbol-resolution-component-testing"},{"level":4,"text":"Flame Graph Generation Component Testing","id":"flame-graph-generation-component-testing"},{"level":4,"text":"Memory Profiling Component Testing","id":"memory-profiling-component-testing"},{"level":3,"text":"Integration Testing","id":"integration-testing"},{"level":4,"text":"End-to-End Profiling Pipeline Testing","id":"end-to-end-profiling-pipeline-testing"},{"level":4,"text":"Real-World Program Profiling","id":"real-world-program-profiling"},{"level":4,"text":"Cross-Platform Validation","id":"cross-platform-validation"},{"level":4,"text":"Performance Impact Measurement","id":"performance-impact-measurement"},{"level":3,"text":"Milestone Verification Checkpoints","id":"milestone-verification-checkpoints"},{"level":4,"text":"Milestone 1: Stack Sampling Verification","id":"milestone-1-stack-sampling-verification"},{"level":4,"text":"Milestone 2: Symbol Resolution Verification","id":"milestone-2-symbol-resolution-verification"},{"level":4,"text":"Milestone 3: Flame Graph Generation Verification","id":"milestone-3-flame-graph-generation-verification"},{"level":4,"text":"Milestone 4: Memory Profiling Verification","id":"milestone-4-memory-profiling-verification"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Testing Skeletons","id":"core-logic-testing-skeletons"},{"level":4,"text":"Milestone Checkpoint Implementation","id":"milestone-checkpoint-implementation"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Mental Model: The Medical Diagnosis Approach","id":"mental-model-the-medical-diagnosis-approach"},{"level":3,"text":"Stack Sampling Issues","id":"stack-sampling-issues"},{"level":4,"text":"Signal Handler Problems","id":"signal-handler-problems"},{"level":4,"text":"Stack Unwinding Failures","id":"stack-unwinding-failures"},{"level":4,"text":"Buffer Management and Data Integrity","id":"buffer-management-and-data-integrity"},{"level":3,"text":"Symbol Resolution Issues","id":"symbol-resolution-issues"},{"level":4,"text":"Missing Debug Symbols","id":"missing-debug-symbols"},{"level":4,"text":"Address Resolution Problems","id":"address-resolution-problems"},{"level":4,"text":"Symbol Cache Performance","id":"symbol-cache-performance"},{"level":3,"text":"Memory Tracking Issues","id":"memory-tracking-issues"},{"level":4,"text":"Allocation Interception Problems","id":"allocation-interception-problems"},{"level":4,"text":"Memory Leak Detection Challenges","id":"memory-leak-detection-challenges"},{"level":4,"text":"Metadata Management and Corruption","id":"metadata-management-and-corruption"},{"level":3,"text":"Debugging Tools and Techniques","id":"debugging-tools-and-techniques"},{"level":4,"text":"Logging and Observability","id":"logging-and-observability"},{"level":4,"text":"Diagnostic Test Programs","id":"diagnostic-test-programs"},{"level":4,"text":"Interactive Debugging Techniques","id":"interactive-debugging-techniques"},{"level":4,"text":"Recovery and Graceful Degradation","id":"recovery-and-graceful-degradation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Infrastructure Code","id":"core-infrastructure-code"},{"level":4,"text":"Core Debugging Utilities","id":"core-debugging-utilities"},{"level":4,"text":"Milestone Validation Checkpoints","id":"milestone-validation-checkpoints"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Mental Model: The Observatory Expansion","id":"mental-model-the-observatory-expansion"},{"level":3,"text":"Advanced Profiling Features","id":"advanced-profiling-features"},{"level":4,"text":"Hardware Performance Counters Integration","id":"hardware-performance-counters-integration"},{"level":4,"text":"Custom Event Sampling","id":"custom-event-sampling"},{"level":4,"text":"Multi-Language Support","id":"multi-language-support"},{"level":4,"text":"Advanced Memory Analysis","id":"advanced-memory-analysis"},{"level":3,"text":"Scalability and Performance","id":"scalability-and-performance"},{"level":4,"text":"Distributed Profiling","id":"distributed-profiling"},{"level":4,"text":"Streaming Data Processing","id":"streaming-data-processing"},{"level":4,"text":"Real-Time Analysis","id":"real-time-analysis"},{"level":3,"text":"Extension Architecture Integration","id":"extension-architecture-integration"},{"level":3,"text":"Common Extension Pitfalls","id":"common-extension-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Hardware Counter Integration Infrastructure","id":"hardware-counter-integration-infrastructure"},{"level":4,"text":"Custom Event Sampling Framework","id":"custom-event-sampling-framework"},{"level":4,"text":"Multi-Language Stack Unwinding","id":"multi-language-stack-unwinding"},{"level":4,"text":"Distributed Profiling Coordination","id":"distributed-profiling-coordination"},{"level":4,"text":"Streaming Analysis Pipeline","id":"streaming-analysis-pipeline"},{"level":4,"text":"Milestone Checkpoint: Extension Validation","id":"milestone-checkpoint-extension-validation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Debugging Extension Integration","id":"debugging-extension-integration"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Mental Model: The Technical Dictionary","id":"mental-model-the-technical-dictionary"},{"level":3,"text":"Core Profiling Concepts","id":"core-profiling-concepts"},{"level":3,"text":"Stack Sampling Terminology","id":"stack-sampling-terminology"},{"level":3,"text":"Symbol Resolution Terminology","id":"symbol-resolution-terminology"},{"level":3,"text":"Flame Graph Terminology","id":"flame-graph-terminology"},{"level":3,"text":"Memory Profiling Terminology","id":"memory-profiling-terminology"},{"level":3,"text":"Error Handling and Recovery Terminology","id":"error-handling-and-recovery-terminology"},{"level":3,"text":"Performance Analysis Terminology","id":"performance-analysis-terminology"},{"level":3,"text":"Distributed Profiling Terminology","id":"distributed-profiling-terminology"},{"level":3,"text":"Data Structure and Algorithm Terminology","id":"data-structure-and-algorithm-terminology"},{"level":3,"text":"Implementation Constants and Defaults","id":"implementation-constants-and-defaults"},{"level":3,"text":"System Integration Terminology","id":"system-integration-terminology"},{"level":3,"text":"Visualization and User Interface Terminology","id":"visualization-and-user-interface-terminology"},{"level":3,"text":"Quality Assurance Terminology","id":"quality-assurance-terminology"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Stack Selection","id":"technology-stack-selection"},{"level":4,"text":"Project File Organization","id":"project-file-organization"},{"level":4,"text":"Core Data Structures Implementation","id":"core-data-structures-implementation"},{"level":4,"text":"Configuration Management","id":"configuration-management"},{"level":4,"text":"Essential Profiling Pipeline Skeleton","id":"essential-profiling-pipeline-skeleton"},{"level":4,"text":"Symbol Resolution Utilities","id":"symbol-resolution-utilities"},{"level":4,"text":"Milestone Validation Checkpoints","id":"milestone-validation-checkpoints"},{"level":4,"text":"Common Implementation Pitfalls","id":"common-implementation-pitfalls"}],"title":"CPU/Memory Profiler: Design Document","markdown":"# CPU/Memory Profiler: Design Document\n\n\n## Overview\n\nThis system builds a sampling profiler that captures call stacks at regular intervals and tracks memory allocations to help developers identify performance bottlenecks. The key architectural challenge is efficiently collecting profiling data with minimal overhead while providing rich visualization through flame graphs and allocation tracking.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** Foundation for all milestones (1-4) — understanding why profiling is challenging and how existing solutions work\n\nPerformance profiling represents one of the most challenging aspects of software engineering diagnostics. When applications run slowly, consume excessive memory, or exhibit unpredictable behavior, developers need tools to peer inside the running process and understand what is actually happening. However, this investigation process is fraught with complexity because the very act of observation can change the behavior being observed, similar to the observer effect in quantum physics. The profiler must gather detailed information about program execution while introducing minimal overhead, resolve cryptic memory addresses into meaningful function names, and present vast amounts of timing data in an intuitive visual format that reveals performance bottlenecks.\n\nThe fundamental challenge lies in the **observer paradox**: profiling tools must be invasive enough to capture meaningful data but non-invasive enough to avoid distorting the very performance characteristics they seek to measure. A profiler that adds 50% overhead to the target application will hide the real performance problems behind its own instrumentation costs. Additionally, modern applications execute millions of function calls per second across multiple threads, dynamically load shared libraries, and allocate memory in complex patterns that span the entire program lifecycle. Capturing, processing, and interpreting this torrent of execution data requires sophisticated sampling strategies, efficient data structures, and clever visualization techniques.\n\n### Mental Model: The Detective Analogy\n\nThink of performance profiling as **detective work investigating performance crimes**. Just as a detective investigating a complex case must gather evidence without contaminating the crime scene, a profiler must collect execution evidence without significantly altering the program's behavior. The detective analogy illuminates several key aspects of profiling challenges:\n\n**Crime Scene Preservation**: A detective cannot change the scene while investigating it, or they risk destroying crucial evidence. Similarly, a profiler cannot significantly slow down the target application or change its memory allocation patterns, as this would mask the original performance problems. The profiler must be a silent observer that captures authentic program behavior.\n\n**Evidence Collection Strategy**: Detectives cannot be everywhere at once, so they must strategically choose when and where to look for clues. Profilers face the same constraint — they cannot capture every single function call and memory allocation without overwhelming overhead. Instead, they use **sampling techniques** to periodically \"photograph\" the program's state, much like a detective taking periodic surveillance photos to understand a suspect's routine.\n\n**Witness Testimony vs. Physical Evidence**: In detective work, witness accounts can be unreliable, but physical evidence provides objective truth. Similarly, developers' intuitions about where their programs spend time are often wrong (the equivalent of unreliable witness testimony), but stack sampling provides objective evidence of actual execution patterns. The profiler serves as an impartial witness that records what really happened.\n\n**Pattern Recognition**: Detectives solve cases by identifying patterns across multiple pieces of evidence — the same person appearing at different crime scenes, similar methods used across incidents. Profilers reveal performance problems by identifying patterns across thousands of samples — the same function appearing frequently in stack traces indicates a performance hotspot, similar to how the same suspect appearing in multiple witness statements indicates involvement.\n\n**Timeline Reconstruction**: Detectives often need to reconstruct the sequence of events leading to a crime. Memory profilers perform similar timeline reconstruction, tracking when memory was allocated and whether it was ever freed, to identify the sequence of events leading to memory leaks.\n\n**Multiple Investigation Techniques**: Different crimes require different investigation approaches — financial crimes need accounting expertise, while violent crimes need forensic analysis. Similarly, different performance problems require different profiling approaches: CPU-bound issues need call stack sampling to find hot functions, while memory problems need allocation tracking to find leaks and excessive usage.\n\nThis detective metaphor helps explain why profiling tools are complex: they must employ sophisticated evidence-gathering techniques, maintain objectivity under challenging conditions, and synthesize vast amounts of data into actionable insights about what really happened during program execution.\n\n### Existing Profiling Solutions\n\nThe profiling ecosystem offers numerous tools, each making different trade-offs between overhead, accuracy, ease of use, and the types of performance problems they can detect. Understanding these existing solutions helps clarify the design space and reveals why building a custom profiler requires careful architectural decisions.\n\n| Tool | Profiling Method | Overhead | Target Problems | Advantages | Disadvantages |\n|------|-----------------|----------|----------------|------------|--------------|\n| **Linux perf** | Statistical sampling via hardware performance counters | Very Low (1-5%) | CPU hotspots, cache misses, branch predictions | Hardware-assisted sampling, extremely low overhead, kernel integration | Complex command-line interface, requires root privileges, difficult symbol resolution |\n| **gprof** | Function entry/exit instrumentation | High (10-40%) | Function-level call counts and timing | Built into GCC, detailed call graph analysis, deterministic profiling | Requires recompilation, significant overhead, misses short-lived functions |\n| **Valgrind (Callgrind)** | Dynamic binary instrumentation | Very High (50-100x slowdown) | Detailed instruction-level analysis, cache simulation | Extremely detailed analysis, no recompilation needed, instruction-accurate | Prohibitive overhead for production use, slow for large applications |\n| **Intel VTune** | Hardware performance monitoring + sampling | Low (5-15%) | CPU optimization, threading issues, memory bottlenecks | Professional-grade analysis, hardware vendor support, GUI interface | Proprietary, Intel-specific features, expensive licensing |\n| **Python cProfile** | Function call tracing via interpreter hooks | Medium (20-50%) | Python-specific hotspot identification | Language-integrated, deterministic profiling, built-in standard library | Python-only, cannot profile native extensions, interpreter overhead |\n| **Go pprof** | Statistical sampling + runtime integration | Low (1-5%) | Go-specific CPU and memory profiling | Language-integrated, production-safe, excellent tooling | Go-specific, limited cross-language support, requires runtime cooperation |\n| **AddressSanitizer** | Memory allocation tracking via compiler instrumentation | High (50-100%) | Memory safety bugs, buffer overflows, use-after-free | Comprehensive memory error detection, precise error reporting | Requires recompilation, significant memory overhead, not for production |\n\n> **Key Insight**: No single profiling tool excels at everything. Each tool represents a different point in the trade-off space between overhead and detail. Statistical samplers like `perf` provide low overhead but miss short-duration events, while instrumentation-based tools like `gprof` capture every event but introduce significant performance penalties.\n\n**Statistical Sampling Tools** (`perf`, `pprof`) work by periodically interrupting the program and examining its current state. They achieve low overhead because they only \"look\" at the program occasionally, like taking random snapshots of a busy intersection to understand traffic patterns. However, they can miss events that happen between samples, and their accuracy depends on the sampling frequency — higher frequency means better accuracy but more overhead.\n\n**Instrumentation-Based Tools** (`gprof`, `cProfile`) modify the program to record every function entry and exit, like installing security cameras at every doorway in a building. This provides complete coverage but requires either recompilation or runtime code modification, both of which add significant overhead. The trade-off is completeness versus performance impact.\n\n**Dynamic Analysis Tools** (`Valgrind`) execute the program in a controlled virtual environment that can observe every instruction, like having a dedicated investigator watch every action a suspect takes. This provides the most detailed analysis possible but at the cost of extreme slowdown, making these tools unsuitable for production environments but invaluable for development-time debugging.\n\n**Hardware-Assisted Tools** (`perf`, `VTune`) leverage specialized CPU features like performance monitoring units (PMUs) that can count events like cache misses, branch mispredictions, and instruction cycles with minimal software overhead. These tools represent the closest thing to \"free\" profiling, but they require hardware support and often need elevated privileges to access the performance counters.\n\n> **Decision: Why Build a Custom Profiler?**\n> - **Context**: Existing tools each excel in specific scenarios but lack comprehensive coverage across CPU profiling, memory tracking, and visualization in a single system\n> - **Options Considered**: \n>   1. Use existing tools like perf + Valgrind + custom scripts\n>   2. Extend an existing open-source profiler\n>   3. Build a new profiler from scratch\n> - **Decision**: Build a new profiler that combines statistical sampling for CPU profiling with allocation tracking for memory analysis\n> - **Rationale**: This allows us to optimize the entire pipeline from data collection to visualization, implement consistent data formats across CPU and memory profiling, and provide a unified interface for both types of analysis. Educational value also comes from understanding the complete profiling pipeline.\n> - **Consequences**: Higher implementation effort but better integration between components, customizable overhead/accuracy trade-offs, and deeper understanding of profiling fundamentals.\n\nThe comparison reveals several gaps in existing solutions that motivate building a custom profiler:\n\n**Integration Challenges**: Using multiple tools (e.g., `perf` for CPU profiling + `Valgrind` for memory analysis) requires correlating data from different sources with different sampling methodologies and output formats. Each tool has its own symbol resolution logic, data aggregation approach, and visualization format, making it difficult to get a unified view of application performance.\n\n**Overhead Customization**: Most existing tools provide limited control over the overhead/accuracy trade-off. They either sample at fixed rates or require recompilation for instrumentation. A custom profiler can implement adaptive sampling rates, configurable overhead budgets, and hybrid approaches that combine sampling with targeted instrumentation.\n\n**Educational Value**: Building a profiler from scratch reveals the fundamental challenges and design patterns that underlie all performance analysis tools. Understanding how to capture stack traces in signal handlers, resolve symbols from ELF binaries, and aggregate timing data into flame graphs provides deep insight into system programming and performance analysis techniques.\n\n**Specialized Use Cases**: Custom profilers can be optimized for specific environments, programming languages, or performance problems that general-purpose tools handle poorly. For example, a profiler designed for web services might include HTTP request correlation, while a profiler for embedded systems might minimize memory usage for metadata storage.\n\nThis analysis of existing solutions establishes the design requirements for our custom profiler: it must achieve low overhead through statistical sampling (like `perf`), provide comprehensive memory tracking (like `Valgrind`), generate intuitive visualizations (like flame graphs), and integrate all these capabilities in a single coherent system that developers can easily deploy and interpret.\n\n### Implementation Guidance\n\nThis section establishes the foundational understanding and technology choices that will guide the implementation of all subsequent components. The goal is to make informed decisions about the profiling approach and understand how it fits into the broader ecosystem of performance analysis tools.\n\n#### Technology Recommendations Table\n\n| Component | Simple Option | Advanced Option |\n|-----------|--------------|----------------|\n| **CPU Profiling** | `signal`-based SIGPROF with fixed intervals | Hardware performance counters via `/proc/` interfaces |\n| **Symbol Resolution** | Basic ELF parsing with `objdump` fallback | Full DWARF parser with line number support |\n| **Memory Tracking** | `LD_PRELOAD` malloc interception | `ptrace`-based system call interception |\n| **Data Storage** | JSON files for samples and symbols | SQLite database with indexed queries |\n| **Visualization** | Static SVG generation with embedded JavaScript | Interactive web application with real-time updates |\n| **Target Language** | Python scripts and C programs | Multi-language support (Python, C++, Go, Rust) |\n\n#### Recommended Project Structure\n\nThe profiler implementation should be organized to separate concerns clearly and allow independent development and testing of each component:\n\n```\ncpu-memory-profiler/\n├── src/\n│   ├── sampler/              # Stack sampling implementation (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── signal_sampler.py    # SIGPROF-based sampling\n│   │   ├── stack_unwinder.py    # Frame pointer walking\n│   │   └── sample_storage.py    # Sample data structures\n│   ├── symbolizer/           # Symbol resolution (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── elf_parser.py        # ELF binary and symbol table parsing\n│   │   ├── dwarf_reader.py      # DWARF debug information\n│   │   └── symbol_cache.py      # Address-to-symbol mapping cache\n│   ├── visualizer/           # Flame graph generation (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── stack_aggregator.py  # Stack folding and counting\n│   │   ├── flamegraph.py        # SVG flame graph generation\n│   │   └── interactive.py       # Zoom/search functionality\n│   ├── memory/               # Memory profiling (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── malloc_hooks.py      # Allocation interception\n│   │   ├── leak_detector.py     # Memory leak analysis\n│   │   └── allocation_tracker.py # Allocation metadata storage\n│   └── common/               # Shared utilities\n│       ├── __init__.py\n│       ├── data_structures.py   # Core data types\n│       ├── config.py            # Configuration management\n│       └── utils.py             # Helper functions\n├── tests/                    # Test suite organized by component\n│   ├── test_sampler/\n│   ├── test_symbolizer/\n│   ├── test_visualizer/\n│   ├── test_memory/\n│   └── integration/\n├── tools/                    # Command-line interfaces\n│   ├── profile_cpu.py           # CPU profiling entry point\n│   ├── profile_memory.py        # Memory profiling entry point\n│   └── generate_flamegraph.py   # Visualization tool\n├── examples/                 # Sample programs to profile\n│   ├── cpu_bound.py\n│   ├── memory_leaker.c\n│   └── recursive_fibonacci.py\n├── docs/                     # Documentation\n└── requirements.txt          # Python dependencies\n```\n\n#### Infrastructure Starter Code\n\n**Configuration Management** (Complete implementation ready to use):\n\n```python\n# src/common/config.py\nimport json\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass SamplingConfig:\n    \"\"\"Configuration for stack sampling behavior.\"\"\"\n    frequency_hz: int = 100          # Samples per second\n    max_stack_depth: int = 64        # Maximum frames to capture\n    include_kernel: bool = False     # Include kernel stack frames\n    target_overhead_percent: float = 2.0  # Target overhead as % of runtime\n\n@dataclass\nclass SymbolConfig:\n    \"\"\"Configuration for symbol resolution.\"\"\"\n    enable_dwarf: bool = True        # Parse DWARF debug info\n    cache_symbols: bool = True       # Cache symbol lookups\n    demangle_cpp: bool = True        # Demangle C++ symbols\n    symbol_search_paths: list = None # Additional symbol search directories\n    \n    def __post_init__(self):\n        if self.symbol_search_paths is None:\n            self.symbol_search_paths = ['/usr/lib/debug', '/usr/local/lib/debug']\n\n@dataclass\nclass VisualizationConfig:\n    \"\"\"Configuration for flame graph generation.\"\"\"\n    color_scheme: str = 'hot'        # Color scheme: hot, cold, mem, io\n    min_width_pixels: int = 1        # Minimum flame width to display\n    title: str = 'CPU Profile'       # Graph title\n    enable_search: bool = True       # Include search functionality\n    enable_zoom: bool = True         # Include zoom functionality\n\n@dataclass\nclass ProfilerConfig:\n    \"\"\"Main profiler configuration combining all components.\"\"\"\n    sampling: SamplingConfig\n    symbols: SymbolConfig\n    visualization: VisualizationConfig\n    output_directory: str = './profile_output'\n    \n    @classmethod\n    def from_json(cls, config_path: str) -> 'ProfilerConfig':\n        \"\"\"Load configuration from JSON file.\"\"\"\n        with open(config_path, 'r') as f:\n            data = json.load(f)\n        \n        return cls(\n            sampling=SamplingConfig(**data.get('sampling', {})),\n            symbols=SymbolConfig(**data.get('symbols', {})),\n            visualization=VisualizationConfig(**data.get('visualization', {})),\n            output_directory=data.get('output_directory', './profile_output')\n        )\n    \n    def to_json(self, config_path: str) -> None:\n        \"\"\"Save configuration to JSON file.\"\"\"\n        data = {\n            'sampling': self.sampling.__dict__,\n            'symbols': self.symbols.__dict__,\n            'visualization': self.visualization.__dict__,\n            'output_directory': self.output_directory\n        }\n        with open(config_path, 'w') as f:\n            json.dump(data, f, indent=2)\n```\n\n**Logging Infrastructure** (Complete implementation ready to use):\n\n```python\n# src/common/utils.py\nimport logging\nimport sys\nimport time\nfrom contextlib import contextmanager\nfrom typing import Generator\n\ndef setup_logging(level: str = 'INFO', log_file: Optional[str] = None) -> None:\n    \"\"\"Configure logging for the profiler system.\"\"\"\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\n    \n    formatter = logging.Formatter(\n        '%(asctime)s [%(levelname)s] %(name)s: %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S'\n    )\n    \n    handlers = [logging.StreamHandler(sys.stdout)]\n    if log_file:\n        handlers.append(logging.FileHandler(log_file))\n    \n    logging.basicConfig(\n        level=numeric_level,\n        handlers=handlers,\n        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'\n    )\n\n@contextmanager\ndef timer_context(operation_name: str) -> Generator[None, None, None]:\n    \"\"\"Context manager for timing operations with automatic logging.\"\"\"\n    logger = logging.getLogger(__name__)\n    start_time = time.perf_counter()\n    logger.debug(f\"Starting {operation_name}\")\n    try:\n        yield\n    finally:\n        elapsed = time.perf_counter() - start_time\n        logger.info(f\"Completed {operation_name} in {elapsed:.3f}s\")\n\ndef format_bytes(size_bytes: int) -> str:\n    \"\"\"Format byte count as human-readable string.\"\"\"\n    for unit in ['B', 'KB', 'MB', 'GB']:\n        if size_bytes < 1024:\n            return f\"{size_bytes:.1f}{unit}\"\n        size_bytes /= 1024\n    return f\"{size_bytes:.1f}TB\"\n\ndef format_percentage(value: float, total: float) -> str:\n    \"\"\"Format value as percentage of total with appropriate precision.\"\"\"\n    if total == 0:\n        return \"0.0%\"\n    percentage = (value / total) * 100\n    return f\"{percentage:.1f}%\"\n```\n\n#### Core Logic Skeleton\n\n**Main Profiler Controller** (Skeleton for learners to implement):\n\n```python\n# src/profiler.py\nfrom typing import Dict, List, Optional\nfrom src.common.config import ProfilerConfig\nfrom src.common.data_structures import Profile, Sample\nimport logging\n\nclass Profiler:\n    \"\"\"Main profiler coordinator that orchestrates sampling, symbolization, and visualization.\"\"\"\n    \n    def __init__(self, config: ProfilerConfig):\n        self.config = config\n        self.logger = logging.getLogger(__name__)\n        # TODO: Initialize component instances (sampler, symbolizer, etc.)\n        \n    def profile_process(self, pid: int, duration_seconds: float) -> Profile:\n        \"\"\"Profile a running process for the specified duration.\n        \n        Args:\n            pid: Process ID to profile\n            duration_seconds: How long to collect samples\n            \n        Returns:\n            Profile object containing all collected data\n        \"\"\"\n        # TODO 1: Validate that target process exists and is accessible\n        # TODO 2: Configure and start the stack sampler with specified frequency\n        # TODO 3: Set up signal handler for graceful shutdown on Ctrl+C\n        # TODO 4: Start sample collection timer for specified duration\n        # TODO 5: Periodically check sampling overhead and adjust frequency if needed\n        # TODO 6: Stop sampling after duration expires\n        # TODO 7: Collect all samples from sampler's storage\n        # TODO 8: Return Profile object with raw samples (symbolization happens later)\n        pass\n    \n    def symbolize_profile(self, profile: Profile) -> Profile:\n        \"\"\"Resolve raw addresses to function names and source locations.\n        \n        Args:\n            profile: Profile with raw address samples\n            \n        Returns:\n            Profile with symbolized stack frames\n        \"\"\"\n        # TODO 1: Extract unique addresses from all stack frames in samples\n        # TODO 2: Load symbol tables for target executable and shared libraries\n        # TODO 3: Build address-to-symbol mapping for all unique addresses\n        # TODO 4: Replace raw addresses in stack frames with symbol information\n        # TODO 5: Add source file and line number info if DWARF data available\n        # TODO 6: Cache symbol resolution results for performance\n        # TODO 7: Return updated profile with symbolic information\n        pass\n    \n    def generate_flame_graph(self, profile: Profile, output_path: str) -> None:\n        \"\"\"Generate interactive SVG flame graph from profiling data.\n        \n        Args:\n            profile: Symbolized profile data\n            output_path: Where to write the SVG file\n        \"\"\"\n        # TODO 1: Aggregate samples by unique stack signature (stack folding)\n        # TODO 2: Build hierarchical call tree from folded stacks\n        # TODO 3: Calculate width percentages based on sample counts\n        # TODO 4: Generate SVG coordinates for each flame graph rectangle\n        # TODO 5: Apply color coding based on function categories (user/kernel/lib)\n        # TODO 6: Add interactive JavaScript for zoom and search features\n        # TODO 7: Write complete SVG file with embedded styling and scripts\n        pass\n```\n\n#### Language-Specific Implementation Hints\n\n**Python-Specific Considerations**:\n- Use `signal.signal(signal.SIGPROF, handler)` for timer-based sampling interrupts\n- Use `traceback.extract_tb()` and `inspect.currentframe()` for stack frame walking\n- Use `struct.unpack()` for parsing binary ELF headers and DWARF sections\n- Use `ctypes` for interacting with malloc/free hooks if implementing memory tracking\n- Use `os.kill(pid, 0)` to check if target process exists before profiling\n- Consider `multiprocessing.Process` for running profiler in separate process to minimize target interference\n\n**Platform Compatibility Notes**:\n- Linux: Full support for `/proc/` filesystem, ELF binaries, DWARF debug info\n- macOS: Use Mach-O binary format instead of ELF, different debug symbol handling\n- Windows: Use PE/COFF binary format, PDB debug symbols, different sampling mechanisms\n\n**Performance Optimization Hints**:\n- Use `collections.defaultdict` for efficient sample aggregation during stack folding\n- Use `lru_cache` decorator for symbol resolution results to avoid repeated ELF parsing\n- Use `mmap` for reading large binary files (executables, core dumps) efficiently\n- Pre-compile regular expressions used for C++ symbol demangling\n- Use `bisect` module for efficient address range lookups in symbol tables\n\n#### Milestone Verification Checkpoints\n\nAfter implementing the foundational components, verify the setup with these checkpoints:\n\n**Configuration System Checkpoint**:\n```bash\npython3 -c \"\nfrom src.common.config import ProfilerConfig\nconfig = ProfilerConfig.from_json('examples/basic_config.json')\nprint(f'Sampling frequency: {config.sampling.frequency_hz}Hz')\nprint(f'Output directory: {config.output_directory}')\n\"\n```\nExpected output: Configuration values loaded from JSON without errors.\n\n**Logging System Checkpoint**:\n```bash\npython3 -c \"\nfrom src.common.utils import setup_logging, timer_context\nsetup_logging('DEBUG')\nwith timer_context('test operation'):\n    import time; time.sleep(0.1)\n\"\n```\nExpected output: Debug log showing operation start and completion with timing.\n\n**Project Structure Checkpoint**:\n```bash\nfind src/ -name \"*.py\" | head -10\npython3 -c \"import src.common.config; print('Import successful')\"\n```\nExpected output: Python files found in expected locations, no import errors.\n\n#### Common Setup Pitfalls\n\n⚠️ **Pitfall: Mixing Development and Production Configurations**\n- **Problem**: Using high-frequency sampling (1000Hz) during development and forgetting to reduce it for production profiling\n- **Why it's wrong**: High sampling frequencies can add 20%+ overhead to the target application\n- **Fix**: Always start with low frequencies (10-100Hz) and increase only if needed for accuracy\n\n⚠️ **Pitfall: Insufficient Permissions for System Profiling**\n- **Problem**: Profiler fails silently when trying to profile other users' processes or access performance counters\n- **Why it's wrong**: Many profiling operations require root privileges or specific capabilities\n- **Fix**: Document required permissions clearly and provide helpful error messages when permissions are missing\n\n⚠️ **Pitfall: Hardcoded File Paths in Configuration**\n- **Problem**: Configuration files contain absolute paths that break when moved between systems\n- **Why it's wrong**: Makes the profiler non-portable and fragile across development/production environments\n- **Fix**: Use relative paths and environment variable substitution in configuration files\n\n⚠️ **Pitfall: No Graceful Degradation for Missing Debug Symbols**\n- **Problem**: Profiler crashes or produces empty output when debug symbols are missing\n- **Why it's wrong**: Most production binaries are stripped of debug information\n- **Fix**: Implement fallback symbol resolution using symbol tables even when DWARF debug info is unavailable\n\nThis foundational understanding and infrastructure setup prepares for the detailed implementation of each profiling component, ensuring consistent approaches to configuration, logging, error handling, and data management across all milestones.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** Foundation for all milestones (1-4) — establishing clear scope boundaries and success criteria for the profiler implementation\n\n### Mental Model: The Telescope Analogy\n\nThink of building a profiler like constructing a telescope for astronomical observation. A telescope has a specific purpose — to observe distant objects — and requires careful design trade-offs between magnification power, field of view, light gathering ability, and portability. Similarly, our profiler has a focused mission: to observe program behavior with minimal disturbance while providing actionable insights.\n\nJust as astronomers must decide whether they're building a wide-field survey telescope or a high-resolution planetary observer, we must define what our profiler will and won't do. A telescope that tries to excel at everything ends up being mediocre at everything. Our profiler needs clear goals that drive every architectural decision, from sampling frequency to memory overhead to visualization features.\n\nThe **observer paradox** applies to both telescopes and profilers: the act of observation can change what you're observing. Telescopes block starlight with their secondary mirrors, and profilers consume CPU cycles and memory. The key is minimizing this interference while maximizing the quality of observation data.\n\n### Functional Goals\n\nOur profiler's functional goals define the core capabilities that users will directly interact with. These goals directly map to the four milestone deliverables and establish what \"done\" looks like for each component.\n\n#### Statistical Sampling Profiling\n\nThe profiler must implement **statistical sampling** to capture representative snapshots of program execution without requiring code modification. This non-intrusive approach allows profiling production applications while maintaining their original behavior.\n\n| Feature | Requirement | Success Criteria |\n|---------|-------------|------------------|\n| Stack Sampling | Capture complete call stacks at regular intervals | Sample 100% of timer interrupts with <1% sample loss |\n| Sampling Frequency Control | Support rates from 10Hz to 10KHz | Configurable via `SamplingConfig.frequency_hz` with validation |\n| Thread Targeting | Profile specific processes or individual threads | Accept PID or TID parameters with proper permission checking |\n| Kernel Stack Capture | Include kernel-mode execution when permissions allow | Optional via `SamplingConfig.include_kernel` flag |\n| Stack Depth Control | Limit capture depth for performance | Configurable `max_stack_depth` with 64-frame maximum |\n\nThe sampling mechanism must handle edge cases gracefully. When a process is blocked in a system call, we should either capture the kernel stack (if possible) or record the blocking state. Signal delivery failures should be detected and reported without crashing the profiler.\n\n#### Symbol Resolution and Debug Information\n\nRaw memory addresses provide no insight to developers. The profiler must convert instruction pointers into human-readable function names, source file locations, and line numbers through comprehensive symbol resolution.\n\n| Symbol Type | Source | Resolution Method |\n|-------------|---------|------------------|\n| Function Names | ELF Symbol Tables | Parse `.symtab` and `.dynsym` sections |\n| Source Files | DWARF Debug Info | Extract from `.debug_info` and `.debug_line` |\n| Line Numbers | DWARF Line Tables | Map addresses to source locations |\n| C++ Symbols | Mangled Names | Demangle using `SymbolConfig.demangle_cpp` |\n| Shared Libraries | Dynamic Loading | Track `dlopen()` events and resolve symbols |\n| JIT Code | Runtime Mapping | Support language-specific symbol APIs when available |\n\n> **Design Insight**: Symbol resolution is often the performance bottleneck in profilers. We prioritize caching and lazy loading over comprehensive symbol information. A function name with approximate source location provides 80% of the value with 20% of the computational cost.\n\nThe symbol resolver must handle **Address Space Layout Randomization (ASLR)** correctly by calculating base addresses for each loaded module. It should gracefully degrade when debug information is missing, providing at least binary+offset information (e.g., `libc.so.6+0x12345`) rather than failing completely.\n\n#### Interactive Flame Graph Visualization\n\nFlame graphs transform thousands of stack samples into an intuitive hierarchical visualization that reveals performance hotspots and call patterns. Our implementation must generate publication-quality visualizations with interactive features for deep analysis.\n\n| Visualization Feature | Implementation | Interactive Capability |\n|----------------------|----------------|------------------------|\n| Hierarchical Layout | SVG coordinate system with proportional widths | Pan and zoom to explore call trees |\n| Color Coding | Function categories (user/library/kernel) | Hover tooltips with detailed metrics |\n| Search Integration | Text matching within function names | Highlight matching functions across graph |\n| Differential Views | Side-by-side profile comparison | Toggle between absolute and relative differences |\n| Inverted Graphs | Bottom-up caller analysis | Switch between caller and callee perspectives |\n| Export Formats | SVG, PNG, and folded stack text | Share visualizations and integrate with tools |\n\nThe flame graph generator must handle large datasets efficiently. A profile with 100,000 samples might contain 10,000 unique stack traces after folding. The visualization should render smoothly in web browsers and provide responsive interaction even with complex call graphs.\n\n#### Memory Allocation Tracking and Leak Detection\n\nBeyond CPU profiling, the system must track heap allocations to identify memory-intensive code paths and detect potential leaks. This requires intercepting allocation functions and maintaining allocation metadata throughout program execution.\n\n| Memory Feature | Tracking Method | Detection Capability |\n|----------------|-----------------|---------------------|\n| Allocation Sites | Stack trace capture at malloc() | Identify top allocation sources by bytes |\n| Allocation Sizes | Record requested and actual sizes | Track memory usage patterns over time |\n| Leak Detection | Match allocations with free() calls | Report unfreed allocations at program exit |\n| Allocation Timeline | Timestamp each allocation/deallocation | Generate memory usage graphs over time |\n| Call Stack Attribution | Full backtrace per allocation | Create allocation flame graphs |\n| Memory Categories | Classify by allocation size/lifetime | Distinguish leaks from long-lived data |\n\n> **Critical Design Choice**: We use function interposition via `LD_PRELOAD` rather than compiler instrumentation. This allows profiling existing binaries without recompilation, but requires careful handling of recursive malloc calls and thread safety.\n\n### Non-Functional Goals\n\nNon-functional goals establish the quality attributes and constraints that govern how the profiler operates in real-world environments. These goals often drive architectural decisions more strongly than functional requirements.\n\n#### Performance and Overhead Constraints\n\nThe profiler's primary non-functional requirement is minimizing performance impact on target applications. Violating this constraint makes the tool unusable for production profiling.\n\n| Performance Metric | Target | Measurement Method |\n|-------------------|--------|-------------------|\n| CPU Overhead | <2% for 100Hz sampling | Compare execution time with/without profiling |\n| Memory Overhead | <10MB baseline + 1KB per stack | Monitor profiler memory usage during capture |\n| Sample Processing | <100μs per sample | Time from signal handler to storage completion |\n| Symbol Resolution | <1ms per unique address | Cache hit rate >95% after warmup period |\n| Flame Graph Generation | <5 seconds for 100K samples | End-to-end processing time measurement |\n| Storage Efficiency | <50 bytes per sample average | Compressed stack representation |\n\nThese targets reflect real-world production constraints. A 2% CPU overhead allows profiling in production during normal operations. Higher overhead limits profiling to development environments, reducing the tool's value for diagnosing production performance issues.\n\n#### Reliability and Error Handling\n\nThe profiler must operate reliably even when targeting unstable or crashing applications. Profiler bugs should never crash or corrupt the target process.\n\n| Reliability Aspect | Requirement | Implementation Strategy |\n|-------------------|-------------|------------------------|\n| Signal Safety | No unsafe operations in signal handlers | Pre-allocate buffers, avoid malloc/printf |\n| Target Process Isolation | Profiler crashes don't affect target | Run as separate process with ptrace/proc access |\n| Graceful Degradation | Partial results when components fail | Continue sampling even if symbol resolution fails |\n| Data Integrity | Detect and handle corrupted samples | Checksums and validation for critical data structures |\n| Resource Cleanup | Release resources on early termination | Signal handlers for cleanup on SIGINT/SIGTERM |\n| Permission Handling | Graceful failure when lacking privileges | Detect capabilities and disable unavailable features |\n\nThe profiler should provide meaningful error messages when it cannot operate. \"Permission denied\" is less helpful than \"Cannot attach to process 1234: profiler must run as root to profile processes owned by other users.\"\n\n#### Usability and Developer Experience\n\nThe profiler targets developers who need quick insights into performance problems. Complex configuration or interpretation should not impede rapid diagnosis.\n\n| Usability Feature | Design Goal | Implementation |\n|------------------|-------------|----------------|\n| Zero-Configuration Defaults | Work out-of-box for common cases | Sensible values in `DEFAULT_FREQUENCY_HZ` constants |\n| Configuration Management | JSON-based configuration with validation | `ProfilerConfig.from_json()` with schema validation |\n| Progress Indication | Show profiling status during capture | Progress bars and ETA for long-running operations |\n| Output Organization | Structured output with clear naming | Timestamp-based directories with descriptive filenames |\n| Error Diagnostics | Actionable error messages with fixes | Suggest solutions for common permission/setup issues |\n| Documentation Integration | Self-documenting configuration and outputs | JSON schema docs and embedded help text |\n\n> **Design Philosophy**: Optimize for the 80% use case where developers want to quickly profile a process and see a flame graph. Advanced features should be discoverable but not impose complexity on basic workflows.\n\n### Explicit Non-Goals\n\nClearly defining what the profiler will NOT do prevents scope creep and helps maintain focus on core functionality. These explicit exclusions guide architectural decisions and help users set appropriate expectations.\n\n#### Advanced Profiling Modalities\n\nWhile comprehensive profiling tools support multiple measurement approaches, our profiler deliberately focuses on statistical sampling and basic memory tracking.\n\n| Excluded Feature | Rationale | Alternative Solutions |\n|-----------------|-----------|----------------------|\n| Instrumentation-Based Profiling | Requires code modification or compiler integration | Use compiler-based tools like gprof or PGO |\n| Hardware Performance Counters | Platform-specific and requires kernel support | Use perf or Intel VTune for detailed metrics |\n| Real-Time Profiling | Complex streaming infrastructure required | Use dedicated APM tools like New Relic or DataDog |\n| Network/IO Profiling | Different expertise domain from CPU/memory | Use tools like tcpdump, iotop, or strace |\n| GPU Profiling | Specialized hardware knowledge required | Use NVIDIA Nsight or AMD profiling tools |\n| Multi-Language Runtime Integration | Each runtime needs custom integration | Use language-specific profilers (py-spy, async-profiler) |\n\n#### Production Deployment Features\n\nOur profiler targets development and debugging workflows rather than production monitoring infrastructure.\n\n| Excluded Feature | Rationale | Alternative Solutions |\n|-----------------|-----------|----------------------|\n| Distributed Profiling | Complex coordination and data aggregation | Use APM platforms with distributed tracing |\n| Real-Time Dashboards | Requires web framework and database storage | Export data to existing monitoring systems |\n| Alerting and Notifications | Not a monitoring system | Integrate with existing alerting infrastructure |\n| User Authentication/Authorization | Security adds significant complexity | Use filesystem permissions and sudo access |\n| Multi-Tenant Profiling | Isolation and resource management complexity | Deploy separate profiler instances per tenant |\n| Continuous Background Profiling | Persistent daemon and storage management | Use always-on profiling services |\n\n#### Advanced Memory Analysis\n\nWhile we track basic allocation patterns, comprehensive memory analysis requires specialized tools and techniques beyond our scope.\n\n| Excluded Feature | Rationale | Alternative Solutions |\n|-----------------|-----------|----------------------|\n| Cache Miss Analysis | Requires hardware performance counters | Use perf with cache event sampling |\n| Memory Layout Optimization | Complex static analysis problem | Use memory sanitizers and specialized profilers |\n| NUMA Topology Analysis | Platform-specific and complex | Use numactl and NUMA-aware profilers |\n| Virtual Memory Analysis | Kernel-level data access required | Use vmstat, /proc analysis, and kernel profilers |\n| Garbage Collection Analysis | Language runtime integration required | Use runtime-specific GC profilers |\n| Memory Fragmentation Analysis | Requires heap internals knowledge | Use jemalloc/tcmalloc analysis tools |\n\n> **Architecture Decision Record: Focus on Statistical Sampling**\n> - **Context**: Multiple profiling approaches exist (sampling, instrumentation, hardware counters), each with different trade-offs in accuracy, overhead, and implementation complexity.\n> - **Options Considered**: \n>   1. Pure statistical sampling with signal-based interrupts\n>   2. Hybrid approach combining sampling with selective instrumentation\n>   3. Hardware counter-based profiling with fallback to sampling\n> - **Decision**: Implement pure statistical sampling as the primary profiling method\n> - **Rationale**: Statistical sampling provides good accuracy for most performance issues while maintaining low overhead and broad compatibility. It works without code modification and doesn't require special hardware or kernel features. The 95% accuracy rate is sufficient for identifying performance hotspots in real applications.\n> - **Consequences**: We accept some inaccuracy in precise timing measurements but gain simplicity and broad applicability. This approach works equally well for optimized production binaries and development builds with debug symbols.\n\n#### Integration and Ecosystem Features\n\nOur profiler will produce standard output formats but won't deeply integrate with external tools and platforms.\n\n| Excluded Feature | Rationale | Alternative Solutions |\n|-----------------|-----------|----------------------|\n| IDE Integration | Each IDE has different plugin architectures | Use command-line workflow and import results |\n| CI/CD Pipeline Integration | Complex automation and threshold management | Use performance regression testing frameworks |\n| Custom Visualization Frameworks | Significant UI/UX development effort | Export data to existing visualization platforms |\n| Database Storage Backend | Adds operational complexity | Use filesystem storage with external indexing |\n| Custom Query Languages | Complex parser and execution engine | Use standard text processing tools (grep, jq) |\n| Cloud Service Integration | Platform-specific APIs and authentication | Use cloud CLI tools and standard data formats |\n\n### Success Metrics and Validation Criteria\n\nTo validate that our goals are met, we define measurable success criteria for each functional and non-functional goal.\n\n#### Functional Success Metrics\n\n| Goal Area | Success Metric | Validation Method |\n|-----------|----------------|------------------|\n| Stack Sampling | 99%+ sample capture rate at 100Hz | Compare timer interrupts sent vs samples collected |\n| Symbol Resolution | 95%+ symbol resolution rate for debug builds | Count resolved vs unresolved addresses in test binaries |\n| Flame Graph Quality | Generate readable graphs for 100K+ samples | Performance test with large profiles |\n| Memory Tracking | Detect 100% of obvious leaks in test programs | Run against known-leaky programs with validation |\n| Cross-Platform Support | Work on Linux distributions with kernel 4.0+ | Test on Ubuntu, CentOS, Alpine with various kernels |\n\n#### Non-Functional Success Metrics\n\n| Goal Area | Success Metric | Validation Method |\n|-----------|----------------|------------------|\n| Performance Overhead | <2% CPU overhead for typical workloads | Benchmark CPU-intensive programs with/without profiling |\n| Memory Efficiency | <10MB baseline memory usage | Monitor profiler RSS during execution |\n| Reliability | Zero target process crashes in 1000+ profiling runs | Stress test with various application types |\n| Usability | New users can generate flame graph in <5 minutes | User testing with developers unfamiliar with profiling |\n| Error Handling | Graceful failure for 95%+ error conditions | Fault injection testing with simulated failures |\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\nOur technology choices balance simplicity for learning with real-world applicability. Python provides excellent readability for understanding profiling concepts while still supporting the low-level operations required for stack sampling.\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|------------------|\n| Core Implementation | Python 3.8+ with ctypes for system calls | Python C extensions for performance-critical paths |\n| Signal Handling | Standard library signal module | Custom signal handling with real-time signals |\n| Symbol Resolution | pyelftools for ELF parsing | DWARF debugging with libdwarf bindings |\n| Process Control | psutil for process management | Direct ptrace system calls for advanced features |\n| Visualization | matplotlib for basic graphs | Custom SVG generation for interactive flame graphs |\n| Configuration | JSON with built-in json module | YAML with PyYAML for complex configurations |\n| Testing Framework | unittest for component testing | pytest with fixtures for integration testing |\n| Documentation | Markdown with examples | Sphinx for API documentation generation |\n\n#### Recommended Project Structure\n\nOrganize the codebase to reflect the major components and support incremental development through the milestones.\n\n```\ncpu-memory-profiler/\n├── README.md                          # Quick start and overview\n├── requirements.txt                   # Python dependencies\n├── setup.py                          # Installation configuration\n├── config/\n│   ├── default_config.json          # Default profiler configuration\n│   └── example_configs/              # Example configurations for different scenarios\n├── src/profiler/\n│   ├── __init__.py                   # Package initialization and version\n│   ├── config.py                     # ProfilerConfig and related classes\n│   ├── main.py                       # Command-line interface and main entry point\n│   ├── sampler/                      # Stack Sampling Component (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── stack_sampler.py          # Core sampling logic with signal handlers\n│   │   ├── sample_storage.py         # Sample and stack frame data structures\n│   │   └── platform_utils.py         # Platform-specific system call wrappers\n│   ├── symbols/                      # Symbol Resolution Component (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── symbol_resolver.py        # Main symbol resolution logic\n│   │   ├── elf_parser.py            # ELF binary and symbol table parsing\n│   │   ├── dwarf_reader.py          # DWARF debug information processing\n│   │   └── symbol_cache.py          # Symbol lookup caching and optimization\n│   ├── visualization/                # Flame Graph Generation (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── flame_graph.py           # SVG flame graph generation\n│   │   ├── stack_aggregator.py      # Stack folding and aggregation algorithms\n│   │   └── svg_renderer.py          # Low-level SVG coordinate and rendering\n│   ├── memory/                       # Memory Profiling Component (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── allocation_tracker.py    # malloc/free interposition\n│   │   ├── leak_detector.py         # Memory leak analysis\n│   │   └── memory_visualizer.py     # Memory allocation flame graphs\n│   └── utils/                        # Shared utilities and helpers\n│       ├── __init__.py\n│       ├── logging_config.py         # Logging setup and configuration\n│       ├── time_utils.py            # Timing and performance measurement\n│       └── format_helpers.py        # Data formatting and display utilities\n├── tests/                            # Comprehensive test suite\n│   ├── unit/                        # Component unit tests\n│   ├── integration/                 # End-to-end integration tests\n│   ├── fixtures/                    # Test programs and sample data\n│   └── benchmarks/                  # Performance regression tests\n├── examples/                         # Example programs and usage scenarios\n│   ├── cpu_intensive.py             # CPU-bound test program\n│   ├── memory_leaky.py              # Memory allocation test program\n│   └── mixed_workload.py            # Combined CPU/memory test program\n├── docs/                            # Documentation and guides\n│   ├── design_document.md           # This design document\n│   ├── user_guide.md               # End-user documentation\n│   └── developer_guide.md          # Development and contribution guide\n└── diagrams/                        # Architecture diagrams\n    ├── system-components.svg        # High-level component architecture\n    ├── sampling-sequence.svg        # Stack sampling sequence diagram\n    └── symbol-resolution-flow.svg   # Symbol resolution process flow\n```\n\n#### Configuration Management Infrastructure\n\nProvide complete configuration management that supports the goals while remaining simple for basic use cases.\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nConfiguration management for the CPU/Memory Profiler.\nHandles loading, validation, and default values for all profiler settings.\n\"\"\"\n\nimport json\nimport os\nfrom dataclasses import dataclass, asdict\nfrom typing import List, Optional\nfrom pathlib import Path\n\n# Default configuration constants\nDEFAULT_FREQUENCY_HZ = 100\nMAX_STACK_DEPTH = 64\nTARGET_OVERHEAD_PERCENT = 2.0\n\n@dataclass\nclass SamplingConfig:\n    \"\"\"Configuration for stack sampling behavior.\"\"\"\n    frequency_hz: int = DEFAULT_FREQUENCY_HZ\n    max_stack_depth: int = MAX_STACK_DEPTH\n    include_kernel: bool = False\n    target_overhead_percent: float = TARGET_OVERHEAD_PERCENT\n    \n    def validate(self) -> None:\n        \"\"\"Validate sampling configuration parameters.\"\"\"\n        # TODO: Implement validation for frequency range (10Hz - 10KHz)\n        # TODO: Validate max_stack_depth is positive and reasonable (<= 256)\n        # TODO: Check target_overhead_percent is between 0.1 and 20.0\n        # TODO: Raise ValueError with descriptive messages for invalid values\n        pass\n\n@dataclass\nclass SymbolConfig:\n    \"\"\"Configuration for symbol resolution and debug information.\"\"\"\n    enable_dwarf: bool = True\n    cache_symbols: bool = True\n    demangle_cpp: bool = True\n    symbol_search_paths: List[str] = None\n    \n    def __post_init__(self):\n        \"\"\"Initialize default symbol search paths if not provided.\"\"\"\n        if self.symbol_search_paths is None:\n            # TODO: Set up default search paths for common locations\n            # TODO: Include /usr/lib/debug, /usr/local/lib, current directory\n            # TODO: Add environment variable expansion (e.g., $HOME/.local/lib)\n            self.symbol_search_paths = []\n\n@dataclass\nclass VisualizationConfig:\n    \"\"\"Configuration for flame graph generation and display.\"\"\"\n    color_scheme: str = \"hot\"\n    min_width_pixels: int = 1\n    title: str = \"CPU Profile Flame Graph\"\n    enable_search: bool = True\n    enable_zoom: bool = True\n    \n    def validate(self) -> None:\n        \"\"\"Validate visualization configuration parameters.\"\"\"\n        # TODO: Check color_scheme is in allowed values (hot, cold, aqua, etc.)\n        # TODO: Validate min_width_pixels is positive\n        # TODO: Ensure title is reasonable length (<100 chars)\n        pass\n\n@dataclass\nclass ProfilerConfig:\n    \"\"\"Top-level profiler configuration containing all component settings.\"\"\"\n    sampling: SamplingConfig = None\n    symbols: SymbolConfig = None\n    visualization: VisualizationConfig = None\n    output_directory: str = \"./profiler_output\"\n    \n    def __post_init__(self):\n        \"\"\"Initialize default configurations for unspecified components.\"\"\"\n        if self.sampling is None:\n            self.sampling = SamplingConfig()\n        if self.symbols is None:\n            self.symbols = SymbolConfig()\n        if self.visualization is None:\n            self.visualization = VisualizationConfig()\n    \n    @classmethod\n    def from_json(cls, config_path: str) -> 'ProfilerConfig':\n        \"\"\"Load configuration from JSON file with validation and defaults.\"\"\"\n        # TODO: Read JSON file and handle file not found errors gracefully\n        # TODO: Parse JSON with error handling for malformed files\n        # TODO: Create config objects from dictionary data\n        # TODO: Run validation on all configuration sections\n        # TODO: Return populated ProfilerConfig instance\n        # Hint: Use **dict unpacking to create dataclass instances from JSON\n        raise NotImplementedError(\"Implement JSON configuration loading\")\n    \n    def to_json(self, config_path: str) -> None:\n        \"\"\"Save configuration to JSON file with pretty formatting.\"\"\"\n        # TODO: Convert config to dictionary using asdict()\n        # TODO: Write JSON with proper indentation for readability\n        # TODO: Handle file write errors gracefully\n        # TODO: Create parent directories if they don't exist\n        pass\n    \n    def validate(self) -> None:\n        \"\"\"Validate entire configuration and all components.\"\"\"\n        # TODO: Call validate() on each component configuration\n        # TODO: Check output_directory is writable\n        # TODO: Verify configuration consistency across components\n        pass\n\ndef load_default_config() -> ProfilerConfig:\n    \"\"\"Load default configuration, falling back to built-in defaults.\"\"\"\n    # TODO: Try loading from ~/.profiler/config.json first\n    # TODO: Fall back to /etc/profiler/config.json for system defaults\n    # TODO: If no config files exist, return ProfilerConfig() with defaults\n    # TODO: Log which configuration source was used\n    return ProfilerConfig()\n```\n\n#### Utility Infrastructure\n\nProvide common utilities that support the non-functional goals around logging, performance measurement, and error handling.\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nUtility functions supporting profiler operations and non-functional requirements.\nHandles logging, timing, formatting, and common operations.\n\"\"\"\n\nimport logging\nimport time\nimport sys\nfrom contextlib import contextmanager\nfrom typing import Generator, Optional\nfrom pathlib import Path\n\ndef setup_logging(level: str = \"INFO\", log_file: Optional[str] = None) -> None:\n    \"\"\"Configure logging system for profiler operations.\"\"\"\n    # TODO: Convert level string to logging constant (DEBUG, INFO, WARNING, ERROR)\n    # TODO: Create formatter with timestamp, level, and message\n    # TODO: Add console handler for interactive usage\n    # TODO: Add file handler if log_file is specified\n    # TODO: Set up logger hierarchy for different components (sampler, symbols, etc.)\n    pass\n\n@contextmanager\ndef timer_context(operation_name: str) -> Generator[None, None, None]:\n    \"\"\"Context manager for timing operations and logging performance.\"\"\"\n    # TODO: Record start time using time.perf_counter()\n    # TODO: Log operation start at DEBUG level\n    # TODO: Yield control to wrapped operation\n    # TODO: Calculate elapsed time and log at INFO level\n    # TODO: Handle exceptions and log timing even if operation fails\n    # Hint: This supports the <2% overhead goal by measuring profiler impact\n    start_time = time.perf_counter()\n    try:\n        yield\n    finally:\n        elapsed = time.perf_counter() - start_time\n        logging.info(f\"{operation_name} completed in {elapsed:.3f}s\")\n\ndef format_bytes(size_bytes: int) -> str:\n    \"\"\"Format byte count as human-readable string (KB, MB, GB).\"\"\"\n    # TODO: Handle negative sizes gracefully\n    # TODO: Use 1024-based units (KiB, MiB, GiB) for accuracy\n    # TODO: Choose appropriate precision (0 decimals for bytes, 1-2 for larger units)\n    # TODO: Return string like \"1.5 MiB\" or \"42 bytes\"\n    # This supports memory profiling goal of tracking allocation sizes\n    if size_bytes < 1024:\n        return f\"{size_bytes} bytes\"\n    # TODO: Implement remaining unit conversions\n    return f\"{size_bytes} bytes\"  # Placeholder\n\ndef format_percentage(value: float, total: float) -> str:\n    \"\"\"Format value as percentage of total with appropriate precision.\"\"\"\n    # TODO: Handle division by zero gracefully (return \"0.0%\")\n    # TODO: Calculate percentage with floating point precision\n    # TODO: Choose precision based on magnitude (0.01% vs 15.2% vs 99%)\n    # TODO: Return formatted string like \"15.2%\" or \"<0.01%\"\n    if total == 0:\n        return \"0.0%\"\n    percentage = (value / total) * 100\n    return f\"{percentage:.1f}%\"\n\ndef ensure_output_directory(output_path: str) -> Path:\n    \"\"\"Create output directory and return Path object, handling errors gracefully.\"\"\"\n    # TODO: Convert string to Path object for robust path handling\n    # TODO: Create directory and any necessary parent directories\n    # TODO: Handle permission errors with helpful error messages\n    # TODO: Check if path exists but is not a directory (error case)\n    # TODO: Return Path object for use by calling code\n    path = Path(output_path)\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n\ndef check_process_permissions(pid: int) -> bool:\n    \"\"\"Check if profiler has sufficient permissions to attach to process.\"\"\"\n    # TODO: Check if target process exists using /proc/{pid}\n    # TODO: Verify read permissions on /proc/{pid}/maps and /proc/{pid}/mem\n    # TODO: For other users' processes, verify profiler is running as root\n    # TODO: Return True if profiling should succeed, False otherwise\n    # This supports the reliability goal of graceful permission handling\n    return True  # Placeholder - implement permission checking\n```\n\n#### Milestone Verification Checkpoints\n\nEach milestone should have clear verification criteria that confirm the implementation meets our functional goals.\n\n**Milestone 1 Checkpoint (Stack Sampling):**\n- Run `python -m profiler.sampler --test-mode --frequency 100 --duration 5` against a CPU-intensive test program\n- Expected: Capture ~500 samples (5 seconds × 100Hz) with <1% loss rate\n- Verify: Each sample contains valid stack frames with instruction pointers\n- Test signal safety: Run against multi-threaded programs without crashes\n- Performance: Verify <2% overhead on CPU-intensive workloads\n\n**Milestone 2 Checkpoint (Symbol Resolution):**\n- Process samples from Milestone 1 through symbol resolver\n- Expected: >95% symbol resolution rate for debug-enabled binaries\n- Verify: Function names are human-readable, not raw addresses\n- Test: Include C++ programs to verify name demangling works\n- Performance: Symbol resolution completes in <1 second for 1000 samples\n\n**Milestone 3 Checkpoint (Flame Graphs):**\n- Generate flame graph from processed samples\n- Expected: Interactive SVG file loads in web browser\n- Verify: Zoom and search functionality works correctly\n- Test: Function widths represent relative execution time accurately\n- Visual: Color coding distinguishes user code from library functions\n\n**Milestone 4 Checkpoint (Memory Profiling):**\n- Profile a program with known memory leaks\n- Expected: Detect all obvious leaks with allocation call stacks\n- Verify: Track allocation sizes accurately throughout execution\n- Test: Generate memory allocation flame graph showing hot allocation sites\n- Performance: <10MB overhead for tracking 10,000 allocations\n\n\n## High-Level Architecture\n\n> **Milestone(s):** Foundation for all milestones (1-4) — establishes the core architectural components and their relationships that enable stack sampling, symbol resolution, flame graph generation, and memory profiling\n\n### Mental Model: The Observatory Network\n\nThink of this profiler system as a **distributed observatory network** studying a distant star system (your running program). Just as astronomers use multiple specialized instruments working in concert—telescopes for imaging, spectrometers for composition analysis, photometers for brightness measurement—our profiler employs four specialized components that collaborate to create a complete picture of program performance.\n\nThe **Sampler** acts like the main telescope, periodically capturing snapshots of the program's execution state at precise intervals. The **Symbolizer** functions as the spectrometer, analyzing the raw data to identify what each captured element actually represents in human-readable terms. The **Aggregator** serves as the data processing center, combining thousands of individual observations into meaningful patterns and statistics. Finally, the **Visualizer** works like the publication department, transforming complex datasets into intuitive visual representations that reveal insights at a glance.\n\nThis observatory metaphor captures a crucial architectural principle: **separation of concerns through specialized components**. Each component excels at one specific aspect of the profiling process, and their interfaces are designed for clean data handoffs. This modular design allows us to optimize each component independently, swap implementations as needed, and reason about the system's behavior at different scales.\n\nThe architecture also embodies the **observer paradox** principle from physics—the act of observation inevitably affects the system being observed. Our design minimizes this effect by keeping the observation components (Sampler) as lightweight as possible while pushing the heavy computational work (symbol resolution, aggregation, visualization) to offline processing phases that don't impact the target program's performance.\n\n### Component Overview\n\nThe profiler system consists of four primary components that form a **data processing pipeline** from raw execution samples to rich visualizations. Each component has distinct responsibilities, well-defined interfaces, and specific performance characteristics that collectively enable comprehensive performance analysis with minimal overhead.\n\n![System Component Architecture](./diagrams/system-components.svg)\n\n#### Core Component Responsibilities\n\n| Component | Primary Responsibility | Input Data | Output Data | Performance Characteristic |\n|-----------|------------------------|------------|-------------|---------------------------|\n| **Sampler** | Capture execution state snapshots | Running process PID, sampling config | Raw stack samples with timestamps | Ultra-low latency (< 10μs per sample) |\n| **Symbolizer** | Resolve addresses to human-readable names | Raw samples + debug information | Symbolized samples with function names | I/O intensive (symbol table parsing) |\n| **Aggregator** | Combine samples into statistical summaries | Symbolized samples | Aggregated call trees and statistics | Memory intensive (tree construction) |\n| **Visualizer** | Generate interactive visual representations | Aggregated data | SVG flame graphs and reports | CPU intensive (coordinate calculations) |\n\nEach component is designed as a **pure transformation function** at its core—taking well-defined input data structures and producing well-defined output structures. This functional approach enables easy testing, parallel processing, and composition of different profiling workflows.\n\n#### Component Interaction Patterns\n\nThe components interact through three primary patterns that balance performance, flexibility, and maintainability:\n\n**Sequential Pipeline Processing** represents the most common workflow where each component processes the complete output of the previous stage. This pattern optimizes for simplicity and enables comprehensive post-processing analysis. For example, after sampling completes, the entire sample set undergoes symbol resolution, then aggregation, then visualization in sequence.\n\n**Streaming Pipeline Processing** handles large datasets that don't fit in memory by processing data in chunks. The Sampler produces batches of samples that flow through each subsequent component in overlapping time windows. This pattern is essential for long-running profiles or high-frequency sampling scenarios.\n\n**Caching and Incremental Processing** optimizes repeated operations by maintaining persistent state between profiling sessions. The Symbolizer caches resolved symbols across runs, while the Aggregator can incrementally update flame graphs as new samples arrive. This pattern significantly improves performance for interactive profiling workflows.\n\n> **Key Architectural Insight**: The pipeline design allows each component to be independently optimized for its specific computational characteristics—the Sampler for minimal latency, the Symbolizer for I/O throughput, the Aggregator for memory efficiency, and the Visualizer for rendering quality.\n\n#### Cross-Cutting Concerns\n\nSeveral concerns span multiple components and require coordinated design decisions:\n\n**Configuration Management** flows through all components via the `ProfilerConfig` hierarchy. Each component receives its specific configuration subset but can access global settings like output directories and logging levels. This approach balances component independence with system-wide consistency.\n\n**Error Handling and Resilience** follows a **graceful degradation** principle where component failures don't cascade to abort the entire profiling session. For instance, if symbol resolution fails for some addresses, those samples appear with raw addresses rather than causing profile generation to fail entirely.\n\n**Resource Management** coordinates memory usage across components to stay within system limits. The Sampler uses fixed-size circular buffers, the Symbolizer implements bounded caches, and the Aggregator can switch to disk-based storage for large datasets.\n\n**Observability and Debugging** provides instrumentation points in each component for diagnosing profiler behavior itself. This includes timing measurements, sample counts, cache hit rates, and error frequencies that help identify bottlenecks in the profiling pipeline.\n\n### Architecture Decision Records\n\n> **Decision: Separate Components vs. Monolithic Architecture**\n> - **Context**: Profiling involves distinct computational phases with different performance characteristics and failure modes\n> - **Options Considered**: Single integrated binary, separate components with IPC, modular library with pluggable interfaces\n> - **Decision**: Modular library architecture with separate classes/modules for each component\n> - **Rationale**: Enables independent optimization of each phase, simplifies testing through mocking interfaces, allows for future distributed processing, and provides clear separation of concerns for maintainability\n> - **Consequences**: Slightly more complex data marshaling between components, but gains significant flexibility for testing, optimization, and feature development\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Monolithic Binary | Simple deployment, no IPC overhead | Difficult to test individual phases, limited optimization opportunities | No |\n| Separate Processes | True isolation, can distribute across machines | IPC complexity, serialization overhead, deployment complexity | No |\n| Modular Library | Clean interfaces, easy testing, single deployment | Shared address space, need careful resource management | **Yes** |\n\n> **Decision: Push vs. Pull Data Flow**\n> - **Context**: Components need to coordinate data transfer while maintaining loose coupling\n> - **Options Considered**: Push-based callbacks, pull-based iterators, hybrid message queues\n> - **Decision**: Push-based interfaces with pull-based internal implementation\n> - **Rationale**: Push interfaces provide simple function call semantics for the common case while internal pull mechanisms enable streaming and memory management for large datasets\n> - **Consequences**: Slightly more complex interface design but enables both simple batch processing and efficient streaming workflows\n\n> **Decision: Synchronous vs. Asynchronous Processing**\n> - **Context**: Profiling can generate large amounts of data that may not fit in memory\n> - **Options Considered**: Fully synchronous pipeline, fully asynchronous with callbacks, hybrid approach\n> - **Decision**: Synchronous interfaces with asynchronous internal implementation where needed\n> - **Rationale**: Synchronous interfaces are easier to understand and debug, while internal async processing can be added transparently for performance-critical sections like I/O\n> - **Consequences**: Simpler API surface but requires careful design to avoid blocking operations in performance-critical paths\n\n#### Component Interface Design Principles\n\nThe interfaces between components follow several key design principles that emerged from analyzing profiler performance bottlenecks and failure modes:\n\n**Type Safety Over Performance** means all inter-component data transfer uses strongly-typed structures rather than raw bytes or generic containers. While this adds some serialization overhead, it eliminates entire classes of bugs related to data format mismatches and makes the system much easier to debug.\n\n**Immutable Data Structures** ensure that once a component produces output, it cannot be accidentally modified by downstream components. This enables safe parallel processing and eliminates race conditions, though it requires careful memory management to avoid excessive copying.\n\n**Error Context Preservation** requires that each component augment errors with its own context rather than just propagating generic failures. This creates rich error messages that help users understand exactly where profiling failed and why.\n\n**Resource Lifecycle Management** makes each component responsible for cleaning up its own resources, with clear ownership transfer semantics at component boundaries. This prevents resource leaks even when profiling encounters errors or is interrupted.\n\n### Recommended File Structure\n\nThe codebase organization reflects the component architecture while providing clear separation between core profiling logic, infrastructure concerns, and user-facing interfaces. This structure supports both development workflow efficiency and long-term maintainability as the profiler grows in complexity.\n\n```\nprofiler/\n├── README.md                           # Project overview and quick start\n├── requirements.txt                    # Python dependencies\n├── setup.py                           # Installation configuration\n├── pyproject.toml                     # Modern Python project metadata\n├── \n├── profiler/                          # Main package\n│   ├── __init__.py                    # Package exports and version\n│   ├── config/                        # Configuration management\n│   │   ├── __init__.py\n│   │   ├── models.py                  # ProfilerConfig, SamplingConfig, etc.\n│   │   ├── loader.py                  # from_json, to_json functions\n│   │   └── defaults.py                # Default configuration values\n│   │\n│   ├── sampling/                      # Stack Sampling Component (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── sampler.py                 # Main Sampler class\n│   │   ├── stack_unwinder.py          # Stack frame walking logic\n│   │   ├── signal_handler.py          # SIGPROF signal handling\n│   │   └── sample_storage.py          # Sample collection and buffering\n│   │\n│   ├── symbols/                       # Symbol Resolution Component (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── symbolizer.py              # Main Symbolizer class\n│   │   ├── elf_parser.py              # ELF binary and symbol table parsing\n│   │   ├── dwarf_reader.py            # DWARF debug information processing\n│   │   ├── symbol_cache.py            # Address-to-symbol caching\n│   │   └── cpp_demangler.py           # C++ name demangling\n│   │\n│   ├── aggregation/                   # Data Aggregation Component (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── aggregator.py              # Main Aggregator class\n│   │   ├── stack_folder.py            # Stack folding and merging logic\n│   │   ├── call_tree.py               # Hierarchical call tree construction\n│   │   └── statistics.py             # Sample counting and percentage calculations\n│   │\n│   ├── visualization/                 # Flame Graph Generation Component (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── visualizer.py              # Main Visualizer class\n│   │   ├── flame_graph.py             # SVG flame graph generation\n│   │   ├── svg_builder.py             # SVG DOM construction utilities\n│   │   ├── color_schemes.py           # Color coding for different function types\n│   │   └── interactive.py             # JavaScript for zoom/search functionality\n│   │\n│   ├── memory/                        # Memory Profiling Component (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── memory_profiler.py         # Main memory tracking class\n│   │   ├── allocation_tracker.py      # Malloc/free interception\n│   │   ├── leak_detector.py           # Memory leak identification\n│   │   └── allocation_flame_graph.py  # Memory-specific visualizations\n│   │\n│   ├── core/                          # Shared infrastructure\n│   │   ├── __init__.py\n│   │   ├── data_models.py             # Sample, StackFrame, Symbol, Profile classes\n│   │   ├── utils.py                   # format_bytes, format_percentage, timer_context\n│   │   ├── logging.py                 # setup_logging and profiler-specific loggers\n│   │   └── exceptions.py              # Custom exception classes\n│   │\n│   └── cli/                           # Command-line interface\n│       ├── __init__.py\n│       ├── main.py                    # Main CLI entry point\n│       ├── commands/                  # Subcommand implementations\n│       │   ├── __init__.py\n│       │   ├── profile.py             # profile_process command\n│       │   ├── symbolize.py           # symbolize_profile command\n│       │   └── visualize.py           # generate_flame_graph command\n│       └── output.py                  # Output formatting utilities\n│\n├── tests/                             # Test suite\n│   ├── __init__.py\n│   ├── conftest.py                    # Pytest configuration and fixtures\n│   ├── unit/                          # Unit tests for individual components\n│   │   ├── test_sampler.py\n│   │   ├── test_symbolizer.py\n│   │   ├── test_aggregator.py\n│   │   ├── test_visualizer.py\n│   │   └── test_memory_profiler.py\n│   ├── integration/                   # Integration tests across components\n│   │   ├── test_full_pipeline.py\n│   │   └── test_memory_tracking.py\n│   └── fixtures/                      # Test data and sample programs\n│       ├── sample_programs/           # Test programs to profile\n│       ├── expected_outputs/          # Reference flame graphs and reports\n│       └── debug_symbols/             # Test binaries with debug info\n│\n├── examples/                          # Usage examples and tutorials\n│   ├── basic_profiling.py             # Simple profiling example\n│   ├── memory_leak_detection.py       # Memory profiling example\n│   ├── custom_visualization.py        # Advanced flame graph customization\n│   └── config_examples/               # Sample configuration files\n│       ├── high_frequency.json        # High-frequency sampling config\n│       ├── memory_focused.json        # Memory-heavy profiling config\n│       └── production.json            # Low-overhead production config\n│\n├── docs/                              # Documentation\n│   ├── architecture.md               # This design document\n│   ├── api_reference.md              # API documentation\n│   ├── troubleshooting.md            # Common issues and solutions\n│   └── performance_tuning.md         # Profiler optimization guide\n│\n└── scripts/                          # Development and deployment scripts\n    ├── install_deps.sh               # Dependency installation\n    ├── run_tests.sh                  # Test suite runner\n    ├── benchmark_profiler.sh         # Performance benchmarking\n    └── generate_docs.sh              # Documentation generation\n```\n\n#### File Organization Rationale\n\nThis structure reflects several key organizational principles that support both development efficiency and long-term maintainability:\n\n**Component-Based Directory Structure** mirrors the architectural components directly, making it easy for developers to locate functionality and understand system boundaries. Each major component gets its own top-level directory under the main package, with clear ownership of related functionality.\n\n**Separation of Core Logic and Infrastructure** distinguishes between domain-specific profiling logic (sampling, symbols, etc.) and cross-cutting infrastructure concerns (configuration, logging, utilities). This separation enables easier testing and reuse of infrastructure components.\n\n**Clear Public API Surface** through the `__init__.py` files that explicitly define what each module exports. This prevents accidental coupling to internal implementation details and makes it easier to refactor code within modules without breaking external users.\n\n**Test Organization Matching Source Structure** with unit tests organized by component and integration tests covering cross-component workflows. This makes it easy to run focused test suites during development and ensures comprehensive coverage.\n\n**Example-Driven Documentation** through the examples directory that shows realistic usage patterns rather than just API reference material. These examples serve as both documentation and integration tests for common workflows.\n\n#### Module Dependency Guidelines\n\nThe file structure enforces several dependency rules that maintain architectural integrity:\n\n**Core Module Independence** ensures that the `core/` directory contains only foundational types and utilities with no dependencies on specific profiling components. This enables safe importing of data models and utilities from any component.\n\n**Component Isolation** means components should primarily depend on the core module and external libraries, not directly on each other. Cross-component communication happens through well-defined data types in the core module.\n\n**CLI as Thin Orchestration Layer** keeps command-line interface code focused on argument parsing and component orchestration rather than embedding business logic. This enables easy creation of alternative interfaces (web UI, programmatic API) without duplicating functionality.\n\n**Test Dependency Direction** allows tests to depend on any source module but prevents source modules from depending on test utilities. This keeps the production code clean while enabling comprehensive testing infrastructure.\n\n### Implementation Guidance\n\nThe implementation of this architecture requires careful attention to both the component interfaces and the infrastructure that supports them. The following guidance provides concrete starting points and patterns that support the architectural principles while avoiding common pitfalls.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Recommended for Learning |\n|-----------|---------------|-----------------|--------------------------|\n| **Configuration** | JSON files + Python dict | YAML with schema validation (Pydantic) | JSON + dict (simple parsing) |\n| **Signal Handling** | Python signal module | Custom C extension with signal masks | Python signal module |\n| **Stack Unwinding** | Python traceback module | libunwind or custom frame walking | Python traceback (limited depth) |\n| **ELF Parsing** | pyelftools library | Custom binary parser | pyelftools (handles complexity) |\n| **SVG Generation** | String templates + formatting | XML DOM library (lxml) | String templates (direct control) |\n| **Memory Interception** | LD_PRELOAD wrapper script | Python ctypes hooks | LD_PRELOAD (easier debugging) |\n\n#### Configuration Infrastructure Starter Code\n\n```python\n# profiler/config/models.py\nfrom dataclasses import dataclass\nfrom typing import List, Optional\nimport json\n\n@dataclass\nclass SamplingConfig:\n    \"\"\"Configuration for statistical sampling behavior.\"\"\"\n    frequency_hz: int = 100\n    max_stack_depth: int = 64\n    include_kernel: bool = False\n    target_overhead_percent: float = 2.0\n    \n    def validate(self) -> None:\n        \"\"\"Validate configuration values and raise ValueError for invalid settings.\"\"\"\n        if not (1 <= self.frequency_hz <= 10000):\n            raise ValueError(f\"frequency_hz must be 1-10000, got {self.frequency_hz}\")\n        if not (1 <= self.max_stack_depth <= 256):\n            raise ValueError(f\"max_stack_depth must be 1-256, got {self.max_stack_depth}\")\n        if not (0.1 <= self.target_overhead_percent <= 50.0):\n            raise ValueError(f\"target_overhead_percent must be 0.1-50.0, got {self.target_overhead_percent}\")\n\n@dataclass\nclass SymbolConfig:\n    \"\"\"Configuration for address-to-symbol resolution.\"\"\"\n    enable_dwarf: bool = True\n    cache_symbols: bool = True\n    demangle_cpp: bool = True\n    symbol_search_paths: List[str] = None\n    \n    def __post_init__(self):\n        if self.symbol_search_paths is None:\n            self.symbol_search_paths = [\"/usr/lib/debug\", \"/usr/local/lib/debug\"]\n\n@dataclass\nclass VisualizationConfig:\n    \"\"\"Configuration for flame graph generation.\"\"\"\n    color_scheme: str = \"hot\"\n    min_width_pixels: int = 1\n    title: str = \"CPU Profile\"\n    enable_search: bool = True\n    enable_zoom: bool = True\n\n@dataclass\nclass ProfilerConfig:\n    \"\"\"Top-level profiler configuration combining all component settings.\"\"\"\n    sampling: SamplingConfig\n    symbols: SymbolConfig\n    visualization: VisualizationConfig\n    output_directory: str = \"./profiler_output\"\n    \n    @classmethod\n    def from_json(cls, config_path: str) -> 'ProfilerConfig':\n        \"\"\"Load configuration from JSON file.\"\"\"\n        with open(config_path, 'r') as f:\n            data = json.load(f)\n        \n        return cls(\n            sampling=SamplingConfig(**data.get('sampling', {})),\n            symbols=SymbolConfig(**data.get('symbols', {})),\n            visualization=VisualizationConfig(**data.get('visualization', {})),\n            output_directory=data.get('output_directory', './profiler_output')\n        )\n    \n    def to_json(self, config_path: str) -> None:\n        \"\"\"Save configuration to JSON file.\"\"\"\n        data = {\n            'sampling': self.sampling.__dict__,\n            'symbols': self.symbols.__dict__,\n            'visualization': self.visualization.__dict__,\n            'output_directory': self.output_directory\n        }\n        with open(config_path, 'w') as f:\n            json.dump(data, f, indent=2)\n```\n\n#### Core Data Model Infrastructure\n\n```python\n# profiler/core/data_models.py\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Dict, Any\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass StackFrame:\n    \"\"\"Single frame in a call stack.\"\"\"\n    address: int\n    function_name: Optional[str] = None\n    filename: Optional[str] = None\n    line_number: Optional[int] = None\n    module_name: Optional[str] = None\n    \n    def is_resolved(self) -> bool:\n        \"\"\"Check if this frame has been symbolized.\"\"\"\n        return self.function_name is not None\n\n@dataclass\nclass Sample:\n    \"\"\"Single stack trace capture with metadata.\"\"\"\n    sample_id: str\n    timestamp: datetime\n    pid: int\n    tid: int\n    stack_frames: List[StackFrame]\n    \n    def __post_init__(self):\n        if not self.sample_id:\n            self.sample_id = str(uuid.uuid4())\n\n@dataclass\nclass Profile:\n    \"\"\"Complete profiling session results.\"\"\"\n    session_id: str\n    start_time: datetime\n    end_time: Optional[datetime]\n    target_pid: int\n    samples: List[Sample]\n    metadata: Dict[str, Any]\n    \n    def duration_seconds(self) -> float:\n        \"\"\"Calculate profile duration in seconds.\"\"\"\n        if self.end_time is None:\n            return 0.0\n        return (self.end_time - self.start_time).total_seconds()\n    \n    def sample_count(self) -> int:\n        \"\"\"Get total number of samples collected.\"\"\"\n        return len(self.samples)\n```\n\n#### Utility Infrastructure\n\n```python\n# profiler/core/utils.py\nimport time\nimport logging\nfrom contextlib import contextmanager\nfrom typing import Generator\n\ndef format_bytes(size_bytes: int) -> str:\n    \"\"\"Format byte count as human readable string.\"\"\"\n    if size_bytes == 0:\n        return \"0 B\"\n    \n    units = ['B', 'KB', 'MB', 'GB', 'TB']\n    size = float(size_bytes)\n    unit_index = 0\n    \n    while size >= 1024.0 and unit_index < len(units) - 1:\n        size /= 1024.0\n        unit_index += 1\n    \n    return f\"{size:.1f} {units[unit_index]}\"\n\ndef format_percentage(value: float, total: float) -> str:\n    \"\"\"Format value as percentage with appropriate precision.\"\"\"\n    if total == 0:\n        return \"0.00%\"\n    \n    percentage = (value / total) * 100.0\n    if percentage >= 10.0:\n        return f\"{percentage:.1f}%\"\n    elif percentage >= 1.0:\n        return f\"{percentage:.2f}%\"\n    else:\n        return f\"{percentage:.3f}%\"\n\n@contextmanager\ndef timer_context(operation_name: str) -> Generator[None, None, None]:\n    \"\"\"Context manager for timing operations.\"\"\"\n    logger = logging.getLogger('profiler.timing')\n    start_time = time.time()\n    \n    try:\n        logger.debug(f\"Starting {operation_name}\")\n        yield\n    finally:\n        duration = time.time() - start_time\n        logger.info(f\"Completed {operation_name} in {duration:.3f}s\")\n\n# profiler/core/logging.py\nimport logging\nimport sys\nfrom typing import Optional\n\ndef setup_logging(level: str = \"INFO\", log_file: Optional[str] = None) -> None:\n    \"\"\"Configure logging system for profiler components.\"\"\"\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    \n    # Configure root logger\n    root_logger = logging.getLogger('profiler')\n    root_logger.setLevel(getattr(logging, level.upper()))\n    \n    # Console handler\n    console_handler = logging.StreamHandler(sys.stderr)\n    console_handler.setFormatter(formatter)\n    root_logger.addHandler(console_handler)\n    \n    # File handler if specified\n    if log_file:\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setFormatter(formatter)\n        root_logger.addHandler(file_handler)\n    \n    # Component-specific loggers\n    for component in ['sampling', 'symbols', 'aggregation', 'visualization', 'memory']:\n        logger = logging.getLogger(f'profiler.{component}')\n        logger.setLevel(getattr(logging, level.upper()))\n```\n\n#### Core Component Interface Skeletons\n\n```python\n# profiler/sampling/sampler.py\nfrom typing import List\nfrom profiler.core.data_models import Profile, Sample\nfrom profiler.config.models import SamplingConfig\n\nclass Sampler:\n    \"\"\"Statistical sampling component for capturing call stacks.\"\"\"\n    \n    def __init__(self, config: SamplingConfig):\n        self.config = config\n        # TODO: Initialize signal handler setup\n        # TODO: Initialize sample storage buffer\n        # TODO: Set up timer for sampling frequency\n    \n    def profile_process(self, pid: int, duration_seconds: float) -> Profile:\n        \"\"\"Collect profiling samples from target process.\n        \n        Args:\n            pid: Process ID to profile\n            duration_seconds: How long to collect samples\n            \n        Returns:\n            Profile containing all collected samples\n        \"\"\"\n        # TODO 1: Validate that target process exists and is accessible\n        # TODO 2: Install SIGPROF signal handler in target process\n        # TODO 3: Configure timer to fire at configured frequency_hz\n        # TODO 4: Start timer and begin sample collection\n        # TODO 5: Sleep for duration_seconds while samples accumulate\n        # TODO 6: Stop timer and disable signal handler\n        # TODO 7: Collect all buffered samples and return Profile\n        # Hint: Use signal.alarm() for timer setup\n        # Hint: Signal handler must be async-signal-safe (no malloc)\n        pass\n\n# profiler/symbols/symbolizer.py  \nfrom profiler.core.data_models import Profile\nfrom profiler.config.models import SymbolConfig\n\nclass Symbolizer:\n    \"\"\"Address-to-symbol resolution component.\"\"\"\n    \n    def __init__(self, config: SymbolConfig):\n        self.config = config\n        # TODO: Initialize symbol cache\n        # TODO: Set up ELF parser\n        # TODO: Configure DWARF reader if enabled\n    \n    def symbolize_profile(self, profile: Profile) -> Profile:\n        \"\"\"Resolve addresses to function names for all samples.\n        \n        Args:\n            profile: Profile with raw address samples\n            \n        Returns:\n            Profile with resolved function names and source locations\n        \"\"\"\n        # TODO 1: Load symbol tables for target process binary\n        # TODO 2: Load symbol tables for all shared libraries  \n        # TODO 3: For each sample in profile.samples:\n        # TODO 4:   For each stack frame in sample.stack_frames:\n        # TODO 5:     Look up address in symbol cache\n        # TODO 6:     If not cached, resolve via ELF + DWARF\n        # TODO 7:     Update frame with function_name, filename, line_number\n        # TODO 8:     Store result in symbol cache\n        # TODO 9: Return profile with all frames symbolized\n        # Hint: Use pyelftools for ELF parsing\n        # Hint: Cache negative lookups to avoid repeated failed resolutions\n        pass\n```\n\n#### Language-Specific Implementation Notes\n\n**Signal Handling in Python**: Use the `signal` module for SIGPROF installation, but be aware that Python's signal handling has limitations. The signal handler must be extremely lightweight and avoid calling most Python functions that might trigger garbage collection or memory allocation.\n\n**Stack Unwinding Options**: Python's built-in `traceback` module works well for Python code but cannot capture native C extensions or kernel frames. For more complete stack traces, consider using the `py-spy` approach of reading `/proc/PID/maps` and walking frame pointers manually.\n\n**ELF Parsing Tools**: The `pyelftools` library handles most ELF parsing complexity and DWARF debug information reading. Install with `pip install pyelftools`. For performance-critical applications, consider caching parsed symbols to disk.\n\n**Memory Interception**: Python's `ctypes` library can intercept malloc/free calls, but LD_PRELOAD with a simple C wrapper is often more reliable for comprehensive allocation tracking.\n\n#### Common Pitfalls and Solutions\n\n⚠️ **Pitfall: Circular Import Dependencies Between Components**\nComponent modules that import each other create circular dependencies that prevent Python from loading the modules. This typically happens when components need to call each other's methods directly.\n**Solution**: Use dependency injection through constructor parameters or rely on the core data models for communication. Components should only import from `core/` and external libraries, not from sibling components.\n\n⚠️ **Pitfall: Configuration Object Mutation**\nIf components modify their configuration objects during runtime, it becomes impossible to reproduce profiling results or understand what settings were actually used.\n**Solution**: Make configuration objects immutable after creation (use `frozen=True` in dataclasses) and create new configuration instances for any modifications rather than mutating existing ones.\n\n⚠️ **Pitfall: Inconsistent Error Handling Across Components**\nWhen each component handles errors differently, it becomes difficult for users to understand what went wrong and how to fix it. Some components might fail silently while others crash loudly.\n**Solution**: Define a common exception hierarchy in `core/exceptions.py` and establish consistent error handling patterns. Each component should catch its specific errors and re-raise them as profiler-specific exceptions with added context.\n\n⚠️ **Pitfall: Resource Leaks in Component Cleanup**\nComponents that open files, create threads, or allocate memory but don't clean up properly can cause resource leaks that accumulate over multiple profiling sessions.\n**Solution**: Use Python context managers (`with` statements) for all resource management and implement `__enter__` and `__exit__` methods on component classes to ensure proper cleanup even when exceptions occur.\n\n\n## Data Model\n\n> **Milestone(s):** All milestones (1-4) — these data structures underpin stack sampling, symbol resolution, flame graph generation, and memory profiling\n\n![Data Model Relationships](./diagrams/data-model-relationships.svg)\n\n### Mental Model: The Evidence Collection System\n\nThink of the profiler's data model as a comprehensive evidence collection system for a performance investigation. Just as a detective gathers different types of evidence (photographs, witness statements, forensic reports, timelines), our profiler collects different types of performance data that all interconnect to tell the complete story.\n\nThe **raw samples** are like crime scene photographs — they capture exactly what was happening at a specific moment in time, preserving the call stack \"scene\" with all its details. The **symbol information** acts like a witness database — it helps us identify who the \"suspects\" (functions) are by translating anonymous addresses into recognizable names and locations. The **memory allocation records** are like financial transaction logs — they track every resource exchange (malloc/free) with timestamps and amounts. Finally, the **aggregated flame graph data** resembles the detective's final case file — all the evidence organized and cross-referenced to reveal patterns and highlight the most significant findings.\n\nThis mental model helps explain why our data structures are designed with specific relationships: just as evidence must maintain chain of custody and cross-reference properly, our profiling data must preserve the connections between samples, symbols, and allocations while enabling efficient aggregation and analysis.\n\n### Sample and Stack Structures\n\nThe foundation of our profiler lies in accurately representing captured call stacks and their associated metadata. These data structures must balance completeness with efficiency, since we'll be creating thousands of samples per second during active profiling.\n\n#### Core Sample Representation\n\nThe `Sample` structure captures a single point-in-time snapshot of a thread's execution state. Each sample represents one \"photograph\" of the call stack taken during statistical sampling.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| timestamp | float | Unix timestamp with microsecond precision when sample was captured |\n| thread_id | int | Thread identifier that was sampled (OS thread ID) |\n| process_id | int | Process identifier containing the sampled thread |\n| stack_frames | list[StackFrame] | Ordered list of stack frames from innermost (leaf) to outermost (root) |\n| cpu_id | int | CPU core number where the sample was captured (-1 if unknown) |\n| sample_weight | int | Number of profiling events this sample represents (usually 1 for statistical sampling) |\n| context_switches | int | Number of context switches since last sample (if available) |\n| sample_type | str | Type of sample: \"cpu\", \"wall\", \"memory\", or \"custom\" |\n\nThe `timestamp` field uses floating-point Unix time to provide microsecond precision, which is essential for correlating samples with external events and understanding temporal patterns. The `thread_id` and `process_id` fields enable multi-process and multi-threaded profiling scenarios, allowing us to separate and aggregate samples by execution context.\n\nThe `stack_frames` list maintains strict ordering from leaf to root, meaning `stack_frames[0]` contains the function that was actively executing when the sample was captured, and `stack_frames[-1]` contains the program's entry point (typically `main`). This ordering convention simplifies flame graph generation and stack folding algorithms.\n\n#### Stack Frame Representation\n\nEach `StackFrame` represents one level of the call stack, containing both raw address information and resolved symbolic data.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| address | int | Raw instruction pointer address where execution was sampled |\n| function_name | str | Resolved function name, or hex address string if resolution failed |\n| filename | str | Source code filename containing this function (empty string if unavailable) |\n| line_number | int | Source code line number within the file (0 if unavailable) |\n| module_name | str | Name of executable or shared library containing this address |\n| module_offset | int | Offset within the module where this address is located |\n| inlined_frames | list[InlinedFrame] | List of inlined function calls at this address (from DWARF info) |\n| is_kernel | bool | True if this frame represents kernel code execution |\n\nThe `address` field preserves the raw instruction pointer value, which serves as the primary key for symbol resolution and enables address-based aggregation. Even after symbol resolution completes, we retain the original address for debugging and advanced analysis.\n\nThe symbol resolution fields (`function_name`, `filename`, `line_number`) may be populated asynchronously after initial sample capture. This design allows the sampling component to operate at maximum speed without blocking on symbol lookups, which can be expensive I/O operations.\n\nThe `module_name` and `module_offset` fields support debugging scenarios where multiple versions of the same library are loaded, or when analyzing core dumps where absolute addresses are meaningless but module-relative offsets remain valid.\n\n#### Inlined Function Handling\n\nModern compilers aggressively inline functions for performance, but this creates challenges for profiling since multiple logical functions may be executing at a single instruction address. The `InlinedFrame` structure captures this information when available from DWARF debug data.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| function_name | str | Name of the inlined function |\n| filename | str | Source file containing the inlined function definition |\n| line_number | int | Line number where the inlined function is defined |\n| call_filename | str | Source file containing the call site that was inlined |\n| call_line_number | int | Line number of the call site that was inlined |\n\n> **Architecture Decision: Separate Inlined Frame Storage**\n> - **Context**: Compiler inlining means multiple logical function calls can exist at one instruction address\n> - **Options Considered**: \n>   1. Flatten inlined functions into separate StackFrame entries\n>   2. Store inlined functions as nested data within StackFrame\n>   3. Ignore inlined function information entirely\n> - **Decision**: Store as nested `inlined_frames` list within StackFrame\n> - **Rationale**: Preserves the actual runtime call stack structure while maintaining inlined function visibility. Flattening would create \"fake\" addresses that don't exist at runtime, while ignoring inlined functions loses valuable debugging information for heavily optimized code.\n> - **Consequences**: Flame graph generation must handle the nested structure, but we get accurate attribution of time to inlined functions without distorting the actual runtime stack.\n\n#### Sample Collection and Batching\n\nDuring high-frequency sampling, creating individual `Sample` objects for every captured stack would generate excessive memory allocation overhead. Our design uses a batching strategy to amortize this cost.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| samples | list[Sample] | Collected samples in chronological order |\n| start_time | float | Timestamp of first sample in this batch |\n| end_time | float | Timestamp of last sample in this batch |\n| dropped_samples | int | Number of samples lost due to signal handler overrun |\n| target_process | str | Command line or executable name of profiled process |\n| sampling_frequency | int | Configured sampling rate in Hz for this batch |\n| total_sample_time | float | Cumulative time spent in sampling signal handler |\n\nThe `SampleBatch` structure groups samples collected during a time window, typically 1-10 seconds depending on sampling frequency and memory constraints. This batching enables efficient disk I/O when persisting samples and provides natural boundaries for streaming analysis.\n\nThe `dropped_samples` field tracks sampling overhead and signal handler performance. When the signal handler takes too long to complete stack unwinding, the kernel may deliver the next SIGPROF before the previous handler finishes, causing sample loss. This metric helps detect when sampling frequency exceeds system capabilities.\n\n### Symbol and Debug Information\n\nSymbol resolution transforms raw instruction pointer addresses into human-readable function names, source locations, and debugging metadata. Our symbol data structures optimize for both lookup performance and memory efficiency, since a typical profiling session may resolve millions of unique addresses.\n\n#### Symbol Table Representation\n\nThe `Symbol` structure represents one resolved function symbol, containing all available debugging information for a specific address or address range.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| start_address | int | Starting address of this symbol's code range |\n| end_address | int | Ending address of this symbol's code range (exclusive) |\n| function_name | str | Demangled function name (original mangled name in raw_name) |\n| raw_name | str | Original symbol name from ELF symbol table (before C++ demangling) |\n| source_file | str | Primary source file containing this function definition |\n| line_ranges | list[LineRange] | Mapping from address ranges to source line numbers |\n| parameter_types | list[str] | Function parameter type names (from DWARF if available) |\n| return_type | str | Function return type name (from DWARF if available) |\n| is_inlined | bool | True if this function is only available as inlined instances |\n| compilation_unit | str | Source file that was compiled to produce this symbol |\n\nThe address range design (`start_address`, `end_address`) enables efficient range-based lookups using binary search or interval trees. Most profiling queries ask \"what function contains address X?\" rather than \"what is the exact symbol at address X?\", so range-based storage matches the access pattern.\n\nFunction signature information (`parameter_types`, `return_type`) comes from DWARF debugging data when available, enabling rich IDE-like experiences in profiler UIs. This information helps distinguish between overloaded functions and provides context for performance analysis.\n\n#### Line Number Information\n\nSource line attribution requires mapping instruction addresses to specific lines within source files. The `LineRange` structure captures this mapping efficiently.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| start_address | int | First instruction address mapped to this source line |\n| end_address | int | Last instruction address mapped to this source line (exclusive) |\n| line_number | int | Source line number within the file |\n| column_number | int | Column number within the source line (0 if unavailable) |\n| is_statement | bool | True if this address corresponds to a source statement boundary |\n| is_prologue_end | bool | True if this address marks the end of function prologue |\n| is_epilogue_begin | bool | True if this address marks the beginning of function epilogue |\n\nThe `is_statement` flag helps distinguish between compiler-generated instructions and actual source code statements. When users set breakpoints or analyze performance at the source level, they typically care about statement boundaries rather than individual assembly instructions.\n\nPrologue and epilogue markers enable more accurate profiling attribution. Time spent in function prologues (setting up stack frames) and epilogues (cleanup) represents function call overhead rather than the function's core logic, so advanced analysis can separate these costs.\n\n#### Module and Binary Information\n\nThe `Module` structure represents one executable file or shared library, containing metadata necessary for symbol resolution and address translation.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| name | str | Module name (basename of file, e.g., \"libc.so.6\") |\n| path | str | Full filesystem path to the module file |\n| base_address | int | Virtual memory address where this module is loaded |\n| size | int | Size of the module's memory mapping in bytes |\n| build_id | str | Unique identifier for this specific build (from ELF build-id) |\n| symbols | dict[int, Symbol] | Symbol table mapping start addresses to Symbol objects |\n| has_debug_info | bool | True if DWARF debug information is available |\n| architecture | str | Target architecture (e.g., \"x86_64\", \"aarch64\") |\n| load_time | float | Timestamp when this module was loaded (for dynamic libraries) |\n\nThe `build_id` field provides definitive version identification, which is crucial when profiling systems with multiple versions of the same library or when analyzing offline profile data. Build IDs prevent symbol resolution errors caused by version mismatches between the profiled binary and the debugging session.\n\nThe `base_address` enables translation between file offsets (used in symbol tables) and runtime virtual addresses (captured in samples). Address Space Layout Randomization (ASLR) means the same executable will load at different base addresses on each run, so this translation is essential for symbol resolution.\n\n> **Architecture Decision: Lazy Symbol Loading Strategy**\n> - **Context**: Large applications may contain millions of symbols, but profiling typically only encounters a small subset\n> - **Options Considered**:\n>   1. Load all symbols from all modules at profiler startup\n>   2. Load symbols on-demand as addresses are encountered during resolution\n>   3. Pre-load symbols only for the main executable, lazy-load for libraries\n> - **Decision**: Hybrid approach — pre-load main executable symbols, lazy-load library symbols on first access\n> - **Rationale**: Main executable symbols are frequently accessed and relatively small. Library symbols are numerous but sparsely accessed, so lazy loading reduces memory usage and startup time. Full eager loading would consume excessive memory and slow profiler startup.\n> - **Consequences**: Symbol resolution has variable latency (first access to a library is slower), but overall memory usage scales with actual profiling patterns rather than total available symbols.\n\n#### Symbol Cache and Performance\n\nSymbol resolution involves expensive operations like ELF file parsing, DWARF processing, and string demangling. The `SymbolCache` structure optimizes repeated lookups and manages memory usage.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| address_to_symbol | dict[int, Symbol] | Direct mapping from instruction addresses to resolved symbols |\n| module_cache | dict[str, Module] | Cache of loaded module information by build ID |\n| demangled_names | dict[str, str] | Cache of demangled C++ function names |\n| miss_cache | set[int] | Set of addresses known to have no symbol information |\n| cache_size_bytes | int | Current memory usage of all cached data |\n| max_cache_size | int | Maximum allowed cache size before eviction begins |\n| hit_count | int | Number of successful cache lookups (for performance metrics) |\n| miss_count | int | Number of cache misses requiring expensive resolution |\n\nThe `miss_cache` prevents repeated expensive lookups for addresses that have no symbol information (common in JIT-compiled code, dynamically generated code, or stripped binaries). Recording negative results eliminates redundant file I/O and parsing attempts.\n\nCache eviction uses a hybrid strategy: least-recently-used (LRU) for individual symbols, but never evicts entire modules unless memory pressure is severe. This design reflects the access pattern where recently seen addresses are likely to be seen again (temporal locality), but module metadata has high setup cost and should be preserved.\n\n### Memory Allocation Structures\n\nMemory profiling tracks heap allocations throughout program execution, recording allocation sites, sizes, and lifetimes to identify memory leaks and usage patterns. These data structures must handle millions of allocation events with minimal overhead to avoid skewing the program's memory behavior.\n\n#### Allocation Event Tracking\n\nThe `Allocation` structure represents one heap allocation event, capturing the allocation context and metadata necessary for leak detection and usage analysis.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| allocation_id | int | Unique identifier for this allocation (typically the returned pointer value) |\n| size | int | Number of bytes requested in the allocation call |\n| actual_size | int | Actual bytes allocated by the heap (may be larger due to alignment/bookkeeping) |\n| timestamp | float | Unix timestamp when allocation occurred |\n| thread_id | int | Thread ID that performed the allocation |\n| allocation_stack | list[StackFrame] | Call stack leading to malloc/new/etc. |\n| is_freed | bool | True if this allocation has been freed |\n| free_timestamp | float | Unix timestamp when deallocation occurred (0.0 if not freed) |\n| free_thread_id | int | Thread ID that performed the deallocation (-1 if not freed) |\n| allocation_type | str | Type of allocation: \"malloc\", \"calloc\", \"realloc\", \"new\", \"new[]\" |\n\nThe dual size tracking (`size` vs `actual_size`) helps identify heap fragmentation and memory manager overhead. Many allocators round up requests to alignment boundaries or add metadata headers, so the actual memory consumption may significantly exceed requested amounts.\n\nThe `allocation_id` typically uses the returned pointer value as a unique identifier, which simplifies tracking through the malloc/free lifecycle. However, pointer reuse (where a freed address is returned by a subsequent malloc) requires careful handling to avoid incorrectly matching allocations with frees from previous allocations.\n\nStack trace capture at allocation sites enables powerful analysis of memory usage patterns. Unlike CPU profiling, where we sample periodically, memory profiling captures a stack trace for every allocation, providing complete call path information for every byte allocated.\n\n#### Memory Usage Timeline\n\nThe `MemorySnapshot` structure captures heap state at regular intervals, enabling visualization of memory usage over time and identification of memory growth trends.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| timestamp | float | Unix timestamp when this snapshot was captured |\n| total_allocated | int | Cumulative bytes allocated since profiling began |\n| total_freed | int | Cumulative bytes freed since profiling began |\n| live_bytes | int | Current bytes allocated but not yet freed |\n| live_allocations | int | Current number of allocations not yet freed |\n| heap_size | int | Total heap size from system (if available) |\n| fragmentation_bytes | int | Bytes lost to heap fragmentation (heap_size - live_bytes) |\n| allocation_rate | float | Recent allocation rate in bytes per second |\n| free_rate | float | Recent deallocation rate in bytes per second |\n\nTimeline snapshots enable detection of memory leaks (continuously increasing `live_bytes`), allocation bursts (spikes in `allocation_rate`), and fragmentation issues (growing gap between `heap_size` and `live_bytes`). This temporal view complements the detailed per-allocation data.\n\nThe rate calculations (`allocation_rate`, `free_rate`) use exponential smoothing over recent samples to provide stable measurements despite the bursty nature of memory allocations. Raw rates would fluctuate wildly, making trend detection difficult.\n\n#### Leak Detection and Classification\n\nThe `MemoryLeak` structure represents a detected memory leak, combining allocation information with analysis of why the allocation is considered leaked.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| allocation | Allocation | The leaked allocation record |\n| leak_confidence | float | Confidence score (0.0-1.0) that this is actually a leak |\n| leak_category | str | Classification: \"definite\", \"probable\", \"possible\", \"reachable\" |\n| allocation_age | float | Time in seconds since allocation occurred |\n| similar_leaks | int | Number of other leaks with identical call stack |\n| total_leaked_bytes | int | Total bytes leaked by this call stack pattern |\n| detection_method | str | How this leak was identified: \"unreachable\", \"exit_scan\", \"periodic_scan\" |\n| suppression_matched | str | Name of suppression rule that matches this leak (empty if not suppressed) |\n\nLeak classification reflects different levels of certainty about whether an allocation represents a true bug. \"Definite\" leaks are allocations with no remaining pointers anywhere in the program's memory. \"Probable\" leaks have pointers that exist but appear to be in freed memory or other unlikely locations. \"Possible\" leaks have pointers but in locations that suggest they may be false positives (like uninitialized memory that happens to contain the right bit pattern).\n\nThe `similar_leaks` and `total_leaked_bytes` fields enable aggregation of leak reports. Instead of reporting 10,000 individual leaked strings, we can report \"10,000 leaks totaling 500KB from `parse_config()` at line 42\", which provides more actionable information.\n\n> **Architecture Decision: Allocation Tracking Strategy**\n> - **Context**: Memory profiling must intercept every malloc/free call without significantly impacting performance or memory usage\n> - **Options Considered**:\n>   1. LD_PRELOAD wrapper that replaces malloc/free with instrumented versions\n>   2. Compiler instrumentation that adds tracking code at every allocation site\n>   3. Dynamic binary instrumentation using tools like Intel Pin\n>   4. Operating system-level tracking using kernel tracing facilities\n> - **Decision**: LD_PRELOAD approach with efficient data structures and batched reporting\n> - **Rationale**: LD_PRELOAD works with existing binaries without recompilation, has predictable overhead, and provides complete allocation coverage. Compiler instrumentation requires source code access and recompilation. Dynamic instrumentation has higher overhead. OS-level tracking lacks call stack information.\n> - **Consequences**: Easy integration with existing applications, but limited to dynamically linked binaries. Static binaries and programs that use custom allocators require different approaches.\n\n#### Allocation Site Analysis\n\nThe `AllocationSite` structure aggregates multiple allocations that originate from the same code location, enabling identification of the highest-impact allocation sources.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| call_stack_hash | int | Hash of the allocation call stack for grouping |\n| representative_stack | list[StackFrame] | Full call stack for one allocation from this site |\n| total_allocations | int | Number of allocations performed from this call stack |\n| total_bytes | int | Cumulative bytes allocated from this call stack |\n| peak_live_bytes | int | Maximum bytes simultaneously live from this call stack |\n| peak_live_count | int | Maximum simultaneous live allocations from this call stack |\n| average_size | float | Average allocation size from this call stack |\n| lifetime_distribution | list[int] | Histogram of allocation lifetimes in time buckets |\n| first_seen | float | Timestamp of first allocation from this call stack |\n| last_seen | float | Timestamp of most recent allocation from this call stack |\n\nCall stack hashing (`call_stack_hash`) enables efficient grouping of allocations with identical origins. The hash typically includes function names and line numbers from the top N frames of the call stack, balancing between specificity and grouping effectiveness.\n\nLifetime distribution analysis reveals allocation patterns that inform optimization strategies. Short-lived allocations might benefit from stack allocation or object pooling, while long-lived allocations might indicate opportunities for lazy initialization or more efficient data structures.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Excessive Memory Overhead from Metadata**\nMany implementations store too much metadata per sample or allocation, causing the profiler to consume more memory than the program being profiled. Calculate the expected memory usage: at 1000Hz sampling with 10-frame stacks, you'll generate 36MB of sample data per hour (assuming 1KB per sample). Design your data structures to minimize per-sample overhead and implement batching or streaming to disk.\n\n⚠️ **Pitfall: Inadequate Address Space Layout Randomization (ASLR) Handling**\nStoring absolute addresses without accounting for ASLR breaks symbol resolution when analyzing profile data on a different system or after a program restart. Always store module-relative offsets alongside absolute addresses, and include module base addresses and build IDs in your data model. This enables symbol resolution even when the binary loads at a different address.\n\n⚠️ **Pitfall: Race Conditions in Memory Allocation Tracking**\nUsing the returned pointer address directly as an allocation ID creates race conditions when addresses are reused. A common bug is matching a free() call to the wrong allocation because the same address was returned by a previous malloc/free cycle. Include allocation sequence numbers or timestamps in your allocation IDs to distinguish between different uses of the same address.\n\n⚠️ **Pitfall: Ignoring Compiler Optimizations in Stack Traces**\nModern compilers perform aggressive optimizations like inlining, tail call optimization, and frame pointer omission that distort call stacks. Your data model must handle missing frame pointers (use DWARF CFI for unwinding), inlined functions (store nested inline information), and optimized-away frames (mark synthetic frames). Without this, flame graphs will show incorrect call relationships and missing functions.\n\n⚠️ **Pitfall: Inefficient Symbol Resolution Caching**\nSymbol resolution is expensive, but naive caching strategies can consume excessive memory. A common mistake is caching every resolved address individually instead of caching at the module level. Cache symbol tables per-module and use range-based lookups instead of per-address entries. Also implement cache eviction policies, or long-running profiling sessions will exhaust system memory.\n\n### Implementation Guidance\n\nThis section provides concrete implementation patterns and starter code for the data model components, focusing on Python as the primary language while highlighting key design decisions that apply to all languages.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Data Serialization | JSON with Python `json` module | Protocol Buffers with `protobuf` library |\n| Symbol Parsing | `pyelftools` library for ELF/DWARF | Custom C extension with `libelf` and `libdw` |\n| Memory Management | Python lists and dicts with periodic cleanup | `numpy` arrays for sample data, `sqlite3` for large datasets |\n| Caching Strategy | Simple `dict` with size limits | `functools.lru_cache` or Redis for persistent caching |\n| Performance Monitoring | Basic timing with `time.time()` | `cProfile` integration with custom metrics |\n\n#### Recommended File Structure\n\n```\nprofiler/\n├── data_model/\n│   ├── __init__.py              ← Export main types\n│   ├── sample.py                ← Sample and StackFrame classes\n│   ├── symbol.py                ← Symbol resolution data structures\n│   ├── memory.py                ← Memory allocation tracking structures\n│   ├── cache.py                 ← Symbol and data caching implementations\n│   └── serialization.py        ← Save/load profile data to disk\n├── collectors/\n│   ├── stack_sampler.py         ← Stack sampling implementation\n│   ├── symbol_resolver.py       ← Symbol resolution implementation\n│   └── memory_tracker.py       ← Memory allocation tracking\n├── analysis/\n│   ├── flame_graph.py           ← Flame graph generation\n│   └── leak_detector.py        ← Memory leak analysis\n└── utils/\n    ├── elf_parser.py            ← ELF file parsing utilities\n    └── dwarf_reader.py          ← DWARF debug info reader\n```\n\n#### Core Data Structure Implementation\n\n**Complete Sample Data Structures (sample.py):**\n\n```python\n\"\"\"\nCore data structures for representing profiling samples and call stacks.\nProvides efficient storage and manipulation of captured execution state.\n\"\"\"\n\nimport time\nfrom dataclasses import dataclass, field\nfrom typing import List, Optional, Dict, Any\nfrom enum import Enum\n\n\nclass SampleType(Enum):\n    \"\"\"Types of profiling samples that can be captured.\"\"\"\n    CPU = \"cpu\"\n    WALL = \"wall\" \n    MEMORY = \"memory\"\n    CUSTOM = \"custom\"\n\n\n@dataclass\nclass StackFrame:\n    \"\"\"Represents one frame in a call stack with symbol information.\"\"\"\n    \n    address: int                           # Raw instruction pointer address\n    function_name: str = \"\"               # Resolved function name (empty if unresolved)\n    filename: str = \"\"                    # Source file containing this function\n    line_number: int = 0                  # Source line number (0 if unknown)\n    module_name: str = \"\"                 # Executable/library containing this address\n    module_offset: int = 0                # Offset within the module\n    inlined_frames: List['InlinedFrame'] = field(default_factory=list)\n    is_kernel: bool = False               # True for kernel code execution\n    \n    def __post_init__(self):\n        \"\"\"Validate frame data and set defaults.\"\"\"\n        if self.address < 0:\n            raise ValueError(f\"Invalid negative address: {self.address}\")\n        if not self.function_name and self.address > 0:\n            self.function_name = f\"0x{self.address:x}\"  # Fallback to hex address\n\n\n@dataclass \nclass InlinedFrame:\n    \"\"\"Represents an inlined function call within a stack frame.\"\"\"\n    \n    function_name: str                    # Name of inlined function\n    filename: str                         # Source file of inlined function\n    line_number: int                      # Line number of inlined function definition\n    call_filename: str = \"\"               # Source file containing the call site\n    call_line_number: int = 0             # Line number of inlined call site\n\n\n@dataclass\nclass Sample:\n    \"\"\"Individual stack trace capture with timing and context metadata.\"\"\"\n    \n    timestamp: float                      # Unix timestamp with microsecond precision\n    thread_id: int                        # OS thread identifier\n    process_id: int                       # OS process identifier  \n    stack_frames: List[StackFrame]        # Stack trace from leaf to root\n    cpu_id: int = -1                      # CPU core number (-1 if unknown)\n    sample_weight: int = 1                # Number of events this sample represents\n    context_switches: int = 0             # Context switches since last sample\n    sample_type: SampleType = SampleType.CPU\n    \n    def __post_init__(self):\n        \"\"\"Validate sample data and normalize timestamps.\"\"\"\n        if self.timestamp <= 0:\n            self.timestamp = time.time()\n        if not self.stack_frames:\n            raise ValueError(\"Sample must contain at least one stack frame\")\n        if self.sample_weight < 1:\n            raise ValueError(f\"Sample weight must be positive: {self.sample_weight}\")\n\n\n@dataclass\nclass SampleBatch:\n    \"\"\"Collection of samples with metadata for batch processing.\"\"\"\n    \n    samples: List[Sample]                 # Samples in chronological order\n    start_time: float                     # Timestamp of first sample\n    end_time: float                       # Timestamp of last sample\n    dropped_samples: int = 0              # Samples lost due to overrun\n    target_process: str = \"\"              # Command line of profiled process\n    sampling_frequency: int = DEFAULT_FREQUENCY_HZ  # Configured sample rate\n    total_sample_time: float = 0.0        # Time spent in sampling overhead\n    \n    def add_sample(self, sample: Sample) -> None:\n        \"\"\"Add a sample to this batch, updating timestamps.\"\"\"\n        # TODO 1: Validate sample timestamp is reasonable (not far in past/future)\n        # TODO 2: Update start_time if this is the first sample or earlier than current start\n        # TODO 3: Update end_time if this sample is later than current end\n        # TODO 4: Append sample to samples list\n        # TODO 5: Keep samples sorted by timestamp for efficient processing\n        pass\n    \n    def get_duration(self) -> float:\n        \"\"\"Return the time span covered by samples in this batch.\"\"\"\n        # TODO: Return end_time - start_time, handling empty batch case\n        pass\n    \n    def get_sample_rate(self) -> float:\n        \"\"\"Calculate actual sampling rate achieved by this batch.\"\"\"\n        # TODO: Return len(samples) / get_duration(), handling division by zero\n        pass\n```\n\n**Symbol Resolution Data Structures (symbol.py):**\n\n```python\n\"\"\"\nData structures for symbol resolution and debug information management.\nHandles mapping from addresses to function names and source locations.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Optional, Set\nimport hashlib\n\n\n@dataclass\nclass LineRange:\n    \"\"\"Maps address range to source code line information.\"\"\"\n    \n    start_address: int                    # First instruction mapped to this line\n    end_address: int                      # Last instruction mapped to this line (exclusive)\n    line_number: int                      # Source line number\n    column_number: int = 0                # Column within line (0 if unavailable)\n    is_statement: bool = True             # True if address corresponds to statement boundary\n    is_prologue_end: bool = False         # True if address marks end of function prologue\n    is_epilogue_begin: bool = False       # True if address marks start of function epilogue\n\n\n@dataclass\nclass Symbol:\n    \"\"\"Complete symbol information for a function or code range.\"\"\"\n    \n    start_address: int                    # Starting address of symbol's code\n    end_address: int                      # Ending address (exclusive)\n    function_name: str                    # Demangled function name\n    raw_name: str                         # Original mangled name from symbol table\n    source_file: str = \"\"                 # Primary source file for this function\n    line_ranges: List[LineRange] = field(default_factory=list)\n    parameter_types: List[str] = field(default_factory=list)  # From DWARF\n    return_type: str = \"\"                 # From DWARF\n    is_inlined: bool = False              # True if function exists only inlined\n    compilation_unit: str = \"\"            # Source file that was compiled\n    \n    def contains_address(self, address: int) -> bool:\n        \"\"\"Check if address falls within this symbol's range.\"\"\"\n        # TODO: Return True if start_address <= address < end_address\n        pass\n    \n    def get_line_number(self, address: int) -> int:\n        \"\"\"Find source line number for specific address within symbol.\"\"\"\n        # TODO 1: Search line_ranges for range containing address\n        # TODO 2: Return line_number from matching LineRange\n        # TODO 3: Return 0 if no line mapping found\n        pass\n\n\n@dataclass\nclass Module:\n    \"\"\"Represents one executable or shared library with symbol information.\"\"\"\n    \n    name: str                             # Module basename (e.g., \"libc.so.6\")\n    path: str                             # Full filesystem path\n    base_address: int                     # Virtual memory load address\n    size: int                             # Size of module mapping in bytes\n    build_id: str                         # Unique build identifier\n    symbols: Dict[int, Symbol] = field(default_factory=dict)  # start_address -> Symbol\n    has_debug_info: bool = False          # True if DWARF debug info available\n    architecture: str = \"x86_64\"         # Target architecture\n    load_time: float = 0.0                # When module was loaded\n    \n    def find_symbol(self, address: int) -> Optional[Symbol]:\n        \"\"\"Find symbol containing the given address.\"\"\"\n        # TODO 1: Calculate module-relative address: address - base_address\n        # TODO 2: Binary search symbols dict for symbol containing relative address\n        # TODO 3: Return matching Symbol or None if not found\n        # Hint: Use bisect module for efficient range searches\n        pass\n    \n    def add_symbol(self, symbol: Symbol) -> None:\n        \"\"\"Add symbol to this module's symbol table.\"\"\"\n        # TODO 1: Validate symbol addresses are within module range\n        # TODO 2: Check for overlapping symbols and warn/resolve conflicts\n        # TODO 3: Add to symbols dict using start_address as key\n        pass\n\n\n@dataclass\nclass SymbolCache:\n    \"\"\"Cache for resolved symbols with memory management and performance tracking.\"\"\"\n    \n    address_to_symbol: Dict[int, Symbol] = field(default_factory=dict)\n    module_cache: Dict[str, Module] = field(default_factory=dict)  # build_id -> Module\n    demangled_names: Dict[str, str] = field(default_factory=dict)  # raw -> demangled\n    miss_cache: Set[int] = field(default_factory=set)              # Known missing addresses\n    cache_size_bytes: int = 0             # Current memory usage estimate\n    max_cache_size: int = 100 * 1024 * 1024  # 100MB default limit\n    hit_count: int = 0                    # Successful lookups\n    miss_count: int = 0                   # Failed lookups requiring resolution\n    \n    def lookup_symbol(self, address: int) -> Optional[Symbol]:\n        \"\"\"Look up symbol for address, returning cached result if available.\"\"\"\n        # TODO 1: Check address_to_symbol cache for direct hit\n        # TODO 2: If hit, increment hit_count and return symbol\n        # TODO 3: Check miss_cache to avoid expensive re-lookup of known misses\n        # TODO 4: If miss, increment miss_count and return None\n        # TODO 5: Consider LRU eviction if cache is approaching size limit\n        pass\n    \n    def cache_symbol(self, address: int, symbol: Optional[Symbol]) -> None:\n        \"\"\"Cache resolved symbol result (or miss) for future lookups.\"\"\"\n        # TODO 1: If symbol is None, add address to miss_cache\n        # TODO 2: If symbol exists, add to address_to_symbol cache\n        # TODO 3: Update cache_size_bytes estimate\n        # TODO 4: Trigger eviction if cache exceeds max_cache_size\n        pass\n    \n    def get_hit_rate(self) -> float:\n        \"\"\"Calculate cache hit rate for performance monitoring.\"\"\"\n        # TODO: Return hit_count / (hit_count + miss_count), handle division by zero\n        pass\n```\n\n#### Memory Allocation Tracking Implementation\n\n**Memory Profiling Data Structures (memory.py):**\n\n```python\n\"\"\"\nData structures for tracking memory allocations and detecting leaks.\nProvides comprehensive allocation lifecycle management and analysis.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Set, Optional\nfrom enum import Enum\nimport time\n\n\nclass AllocationType(Enum):\n    \"\"\"Types of heap allocation calls.\"\"\"\n    MALLOC = \"malloc\"\n    CALLOC = \"calloc\"\n    REALLOC = \"realloc\"\n    NEW = \"new\"\n    NEW_ARRAY = \"new[]\"\n\n\nclass LeakCategory(Enum):\n    \"\"\"Classification levels for detected memory leaks.\"\"\"\n    DEFINITE = \"definite\"     # No remaining pointers to allocation\n    PROBABLE = \"probable\"     # Pointers exist but in suspicious locations\n    POSSIBLE = \"possible\"     # Pointers exist but may be false positives\n    REACHABLE = \"reachable\"   # Still reachable but not freed at exit\n\n\n@dataclass\nclass Allocation:\n    \"\"\"Record of a single heap allocation with lifecycle tracking.\"\"\"\n    \n    allocation_id: int                    # Unique ID (typically pointer address)\n    size: int                             # Requested allocation size\n    actual_size: int                      # Actual bytes allocated by heap\n    timestamp: float                      # When allocation occurred\n    thread_id: int                        # Thread that performed allocation\n    allocation_stack: List[StackFrame]    # Call stack at allocation site\n    allocation_type: AllocationType = AllocationType.MALLOC\n    \n    # Deallocation tracking\n    is_freed: bool = False                # True after free() called\n    free_timestamp: float = 0.0           # When deallocation occurred\n    free_thread_id: int = -1              # Thread that performed free\n    \n    def get_lifetime(self) -> float:\n        \"\"\"Calculate allocation lifetime in seconds.\"\"\"\n        # TODO 1: If not freed, return current time - timestamp\n        # TODO 2: If freed, return free_timestamp - timestamp\n        # TODO 3: Handle edge case where free_timestamp is invalid\n        pass\n    \n    def is_long_lived(self, threshold_seconds: float = 10.0) -> bool:\n        \"\"\"Check if allocation has lived longer than threshold.\"\"\"\n        # TODO: Compare get_lifetime() with threshold_seconds\n        pass\n\n\n@dataclass\nclass MemorySnapshot:\n    \"\"\"Point-in-time view of heap memory usage and statistics.\"\"\"\n    \n    timestamp: float                      # When snapshot was captured\n    total_allocated: int                  # Cumulative bytes allocated\n    total_freed: int                      # Cumulative bytes freed\n    live_bytes: int                       # Currently allocated bytes\n    live_allocations: int                 # Currently allocated objects\n    heap_size: int = 0                    # Total heap size from system\n    allocation_rate: float = 0.0          # Recent allocation rate (bytes/sec)\n    free_rate: float = 0.0                # Recent free rate (bytes/sec)\n    \n    def get_fragmentation_bytes(self) -> int:\n        \"\"\"Calculate estimated heap fragmentation.\"\"\"\n        # TODO: Return heap_size - live_bytes (if heap_size available)\n        pass\n    \n    def get_fragmentation_ratio(self) -> float:\n        \"\"\"Calculate fragmentation as percentage of heap size.\"\"\"\n        # TODO: Return get_fragmentation_bytes() / heap_size (handle division by zero)\n        pass\n\n\n@dataclass\nclass MemoryLeak:\n    \"\"\"Detected memory leak with classification and analysis.\"\"\"\n    \n    allocation: Allocation                # The leaked allocation\n    leak_confidence: float                # Confidence score 0.0-1.0\n    leak_category: LeakCategory           # Classification of leak type\n    allocation_age: float                 # Seconds since allocation\n    similar_leaks: int = 0                # Other leaks with same call stack\n    total_leaked_bytes: int = 0           # Total bytes from this call pattern\n    detection_method: str = \"unreachable\" # How leak was identified\n    suppression_matched: str = \"\"         # Suppression rule name if applicable\n    \n    def get_stack_signature(self) -> str:\n        \"\"\"Generate unique signature for this leak's call stack.\"\"\"\n        # TODO 1: Extract function names from allocation.allocation_stack\n        # TODO 2: Create hash from top N frames (typically 8-10)\n        # TODO 3: Return hex string of hash for grouping similar leaks\n        pass\n\n\n@dataclass  \nclass AllocationSite:\n    \"\"\"Aggregated statistics for allocations from same call stack.\"\"\"\n    \n    call_stack_hash: int                  # Hash of allocation call stack\n    representative_stack: List[StackFrame] # Example stack from this site\n    total_allocations: int = 0            # Number of allocations\n    total_bytes: int = 0                  # Cumulative bytes allocated\n    peak_live_bytes: int = 0              # Maximum simultaneous live bytes\n    peak_live_count: int = 0              # Maximum simultaneous live allocations\n    lifetime_distribution: List[int] = field(default_factory=list)  # Histogram buckets\n    first_seen: float = 0.0               # Timestamp of first allocation\n    last_seen: float = 0.0                # Timestamp of most recent allocation\n    \n    def add_allocation(self, allocation: Allocation) -> None:\n        \"\"\"Update statistics with new allocation from this site.\"\"\"\n        # TODO 1: Increment total_allocations counter\n        # TODO 2: Add allocation.size to total_bytes\n        # TODO 3: Update first_seen if this is earlier (or first allocation)\n        # TODO 4: Update last_seen with allocation.timestamp\n        # TODO 5: Update lifetime_distribution when allocation is freed\n        pass\n    \n    def get_average_size(self) -> float:\n        \"\"\"Calculate average allocation size from this site.\"\"\"\n        # TODO: Return total_bytes / total_allocations (handle division by zero)\n        pass\n    \n    def is_active(self, current_time: float, inactive_threshold: float = 60.0) -> bool:\n        \"\"\"Check if this allocation site has been used recently.\"\"\"\n        # TODO: Return True if (current_time - last_seen) < inactive_threshold\n        pass\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Verification (Stack Sampling Data Model):**\n```bash\n# Test basic sample creation and validation\npython -m pytest tests/test_sample.py -v\n\n# Expected output:\n# test_sample_creation - PASS (validates Sample constructor)\n# test_stack_frame_validation - PASS (validates StackFrame address handling)\n# test_sample_batch_operations - PASS (validates SampleBatch add/sort operations)\n\n# Manual verification:\npython -c \"\nfrom data_model.sample import Sample, StackFrame\nimport time\n\n# Create test sample with realistic stack\nframes = [\n    StackFrame(0x401234, 'inner_function', 'main.c', 45),\n    StackFrame(0x401190, 'outer_function', 'main.c', 23),  \n    StackFrame(0x401000, 'main', 'main.c', 10)\n]\nsample = Sample(time.time(), 12345, 678, frames)\nprint(f'Sample captured at {sample.timestamp} with {len(sample.stack_frames)} frames')\n\"\n```\n\n**Milestone 2 Verification (Symbol Resolution Data Model):**\n```bash\n# Test symbol resolution data structures\npython -m pytest tests/test_symbol.py -v\n\n# Expected output:\n# test_symbol_address_ranges - PASS (validates Symbol.contains_address())\n# test_module_symbol_lookup - PASS (validates Module.find_symbol()) \n# test_symbol_cache_hit_rate - PASS (validates SymbolCache performance tracking)\n\n# Manual verification:\npython -c \"\nfrom data_model.symbol import Symbol, Module\n\n# Create test module with symbol\nmodule = Module('test.exe', '/tmp/test', 0x400000, 4096, 'build123')\nsymbol = Symbol(0x401000, 0x401100, 'test_function', 'test_function')\nmodule.add_symbol(symbol)\n\nfound = module.find_symbol(0x401050)  # Address within symbol range\nprint(f'Found symbol: {found.function_name if found else None}')\n\"\n```\n\n**Milestone 4 Verification (Memory Allocation Data Model):**\n```bash  \n# Test memory tracking data structures\npython -m pytest tests/test_memory.py -v\n\n# Expected output:\n# test_allocation_lifecycle - PASS (validates Allocation lifetime tracking)\n# test_memory_snapshot_calculations - PASS (validates MemorySnapshot fragmentation)\n# test_allocation_site_aggregation - PASS (validates AllocationSite statistics)\n\n# Manual verification:\npython -c \"\nfrom data_model.memory import Allocation, MemorySnapshot, AllocationType\nimport time\n\n# Create test allocation\nalloc = Allocation(0x7f8b4c001000, 1024, 1024, time.time(), 12345, [])\nsnapshot = MemorySnapshot(time.time(), 1024, 0, 1024, 1, 2048)\n\nprint(f'Allocation lifetime: {alloc.get_lifetime():.3f}s')\nprint(f'Heap fragmentation: {snapshot.get_fragmentation_ratio():.1%}')\n\"\n```\n\n#### Debugging Tips for Data Model Issues\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Memory usage grows without bound | Missing cache eviction in SymbolCache | Check cache_size_bytes and hit/miss ratios | Implement LRU eviction when max_cache_size exceeded |\n| Symbol resolution returns wrong function names | ASLR not handled correctly | Compare module base_address with actual load address from /proc/pid/maps | Store and use module-relative addresses for symbol lookup |\n| Stack frames missing or truncated | Frame pointer omission or corruption | Check if binary compiled with -fomit-frame-pointer, inspect assembly | Use DWARF unwinding instead of frame pointer walking |\n| Allocation/free mismatches in leak detection | Pointer reuse causing ID collisions | Check if allocation_id values repeat after free | Include allocation sequence number in ID generation |\n| Sample timestamps inconsistent | Clock source changes or NTP adjustments | Compare sample timestamps with system clock, check for jumps | Use monotonic clock source (time.monotonic) instead of wall clock |\n| Inlined function information missing | DWARF debug info not available or not parsed | Check has_debug_info flag, verify debug symbols installed | Install debug packages or compile with -g flag |\n\n\n## Stack Sampling Component\n\n> **Milestone(s):** Milestone 1 — Stack Sampling: Periodically sample call stacks using signal-based interruption to capture program execution state with configurable frequency and minimal overhead\n\n### Mental Model: Photography Metaphor\n\nThink of stack sampling as taking photographs of a moving process. Just as a photographer captures snapshots of a running race to understand the motion and positions of runners, a profiler captures snapshots of a program's call stack to understand its execution behavior. Each photograph (sample) shows where the runners (threads) are at that exact moment in time. By taking many photographs at regular intervals, we can reconstruct the overall pattern of the race (program execution) and identify where runners spend most of their time (performance hotspots).\n\nThe photographer must balance several factors: taking photos too frequently might slow down the race (overhead), while taking them too infrequently might miss important moments (undersampling). The camera's shutter speed (signal handler execution time) must be fast enough not to interfere with the race itself. Sometimes the photographer might miss a shot due to technical issues (dropped samples), and occasionally the lighting conditions make it hard to identify specific runners (symbol resolution challenges).\n\nThis analogy helps us understand the core challenges of statistical sampling: we're observing a dynamic system without significantly altering its behavior, and we must infer overall patterns from discrete observations. The **observer paradox** applies here — the act of measurement can change what we're measuring, so minimizing overhead is crucial for accurate profiling.\n\n### Signal-Based Sampling\n\nStack sampling relies on **statistical sampling** through periodic interruption of the target process using timer signals. The most common approach uses `SIGPROF`, a signal specifically designed for profiling that delivers at regular intervals based on process CPU time consumption, not wall-clock time. This ensures that profiling samples correlate with actual CPU usage rather than idle time.\n\nThe sampling mechanism operates through several coordinated components. First, we configure an interval timer using `setitimer()` with `ITIMER_PROF` to deliver `SIGPROF` signals at our desired **sampling frequency**. When the signal arrives, the kernel interrupts the target process and invokes our signal handler, which captures a snapshot of the current call stack. The signal handler must execute quickly and safely, storing the captured stack frames for later processing.\n\n**Signal Handler Safety and Async-Safe Operations**\n\nSignal handlers operate in a severely restricted execution environment. They can only call **async-signal-safe** functions, which excludes most standard library functions including `malloc()`, `printf()`, and most system calls. This restriction exists because the signal can arrive at any point during program execution, potentially interrupting non-reentrant functions and causing deadlocks or corruption.\n\nOur signal handler must use only async-safe operations like `write()` for logging and pre-allocated data structures for storing samples. We cannot dynamically allocate memory during signal handling, so we must pre-allocate a circular buffer for samples and use atomic operations to manage the buffer indices safely across multiple threads.\n\n> **Architecture Decision Record: Signal vs Threading Approach**\n\n> **Decision: Signal-Based Sampling with SIGPROF**\n> - **Context**: Need to periodically interrupt target process to capture call stacks with minimal overhead and accurate timing\n> - **Options Considered**:\n>   1. Signal-based sampling with `SIGPROF` and `setitimer()`\n>   2. Separate profiler thread with periodic sleep and `ptrace()` attachment\n>   3. Instrumentation-based sampling with compiler-inserted hooks\n> - **Decision**: Signal-based sampling with `SIGPROF`\n> - **Rationale**: Signal approach provides deterministic timing based on CPU consumption rather than wall-clock time, automatically handles multi-threaded programs by interrupting whichever thread is running, and avoids the complexity of external process attachment. Timer signals are designed specifically for this use case.\n> - **Consequences**: Enables accurate CPU-time-based profiling but restricts signal handler to async-safe operations only. Requires careful buffer management and atomic operations for thread safety.\n\n| Sampling Approach | Pros | Cons |\n|-------------------|------|------|\n| SIGPROF signals | CPU-time based, automatic thread handling, kernel support | Limited to async-safe operations, signal delivery overhead |\n| ptrace() attachment | Full debugging capabilities, external process control | High overhead, requires separate process, complex setup |\n| Compiler instrumentation | Rich metadata access, precise control points | Requires recompilation, significant overhead, code bloat |\n\n**Timer Configuration and Frequency Management**\n\nThe sampling frequency directly impacts the trade-off between profiling accuracy and overhead. Higher frequencies provide more detailed profiles but consume more CPU cycles and may perturb the target program's behavior. The `SamplingConfig` structure captures these parameters:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `frequency_hz` | int | Samples per second, typically 10Hz to 10KHz range |\n| `max_stack_depth` | int | Maximum call stack frames to capture per sample |\n| `include_kernel` | bool | Whether to capture kernel space stack frames |\n| `target_overhead_percent` | float | Desired profiling overhead as percentage of CPU time |\n\nThe timer setup process involves several steps. First, we install a signal handler for `SIGPROF` using `sigaction()` with appropriate flags to ensure reliable signal delivery. Next, we configure the interval timer using `setitimer(ITIMER_PROF, &timer_spec, NULL)` where `timer_spec` specifies both the initial delay and recurring interval. The timer automatically accounts for CPU time consumption, pausing during I/O waits and resuming when the process consumes CPU cycles.\n\n> **Critical Insight**: `ITIMER_PROF` measures CPU time, not wall-clock time. A process sleeping in `read()` won't receive signals, but a process spinning in a tight loop will receive them at the configured rate. This behavior is exactly what we want for CPU profiling.\n\n**Multi-Threading Considerations**\n\nSignal-based sampling in multi-threaded programs requires careful consideration of signal delivery semantics. In modern POSIX systems, signals are delivered to the entire process, and the kernel selects one thread to handle each signal delivery. This means `SIGPROF` will interrupt whichever thread is currently running, providing automatic load balancing across threads without explicit thread tracking.\n\nHowever, this creates challenges for sample storage. Multiple threads might simultaneously execute the signal handler if multiple cores are involved, requiring thread-safe data structures for the sample buffer. We use a lock-free circular buffer with atomic compare-and-swap operations to manage buffer indices, avoiding mutex operations that are not async-safe.\n\nThe sample capture process must also record which thread was interrupted. We obtain the thread ID using `pthread_self()` within the signal handler and store it in the `Sample` structure. This enables per-thread analysis and helps identify thread-specific performance bottlenecks.\n\n### Stack Frame Unwinding\n\nOnce a signal interrupts execution, we must quickly traverse the call stack to capture the sequence of function calls that led to the current execution point. **Stack unwinding** reconstructs this call chain by following frame pointers or using debug information to navigate from the current stack frame back through each calling function.\n\n**Frame Pointer-Based Unwinding**\n\nThe most common unwinding approach relies on frame pointers, which are register values that point to stack frames for each function call. In x86-64 architecture, the frame pointer is stored in the `%rbp` register, and each stack frame contains a pointer to the previous frame, creating a linked list structure through the stack.\n\nThe unwinding algorithm follows these steps:\n\n1. Obtain the current frame pointer from the interrupted execution context provided by the signal handler\n2. Read the return address from the current stack frame to identify the calling function\n3. Follow the frame pointer chain to the previous stack frame\n4. Repeat until reaching the stack bottom or maximum depth limit\n5. Store each discovered instruction pointer in a `StackFrame` structure\n\nHowever, frame pointer unwinding has significant limitations. Modern compilers often omit frame pointers as an optimization, using the saved space for additional register variables. This optimization, enabled by `-fomit-frame-pointer` in GCC, breaks the frame pointer chain and makes traditional unwinding impossible.\n\n> ⚠️ **Pitfall: Missing Frame Pointers**\n> Many production binaries are compiled with frame pointer omission for performance. This breaks simple stack unwinding and results in truncated profiles showing only the interrupted function. Always compile profiling targets with `-fno-omit-frame-pointer` or use DWARF-based unwinding for accurate results.\n\n**DWARF-Based Unwinding for Optimized Code**\n\nWhen frame pointers are unavailable, we must use **debug symbols** and DWARF (Debug With Arbitrary Record Format) information to reconstruct the call stack. DWARF provides detailed unwinding instructions that describe how to locate the previous frame's registers and return address for each function, even in heavily optimized code.\n\nDWARF unwinding is significantly more complex than frame pointer traversal:\n\n1. Parse the `.eh_frame` or `.debug_frame` sections from the executable and shared libraries\n2. Build a table of unwinding rules indexed by instruction pointer ranges\n3. For each frame, look up the appropriate unwinding rules based on the current instruction pointer\n4. Execute the DWARF virtual machine instructions to compute the previous frame's registers\n5. Use the computed return address to continue unwinding\n\nThis approach works with optimized code but requires substantial implementation effort and has higher runtime overhead. Many production profilers use libraries like `libunwind` or `libdwarf` to handle the complexity of DWARF unwinding.\n\n> **Architecture Decision Record: Unwinding Strategy**\n\n> **Decision: Hybrid Unwinding with Frame Pointer Fallback**\n> - **Context**: Need reliable stack unwinding for both optimized and debug builds with minimal signal handler overhead\n> - **Options Considered**:\n>   1. Frame pointer only (simple but unreliable with optimized code)\n>   2. DWARF-only unwinding (reliable but complex and slow)\n>   3. Hybrid approach with frame pointer primary, DWARF fallback\n> - **Decision**: Hybrid approach starting with frame pointer unwinding, falling back to DWARF when chains break\n> - **Rationale**: Frame pointer unwinding is fast and sufficient for debug builds and unoptimized code. DWARF fallback handles optimized production binaries. Hybrid approach balances simplicity and reliability.\n> - **Consequences**: Requires implementing both unwinding methods but provides best performance for common cases while maintaining accuracy for production deployments.\n\n| Unwinding Method | Speed | Reliability | Implementation Complexity |\n|------------------|--------|-------------|---------------------------|\n| Frame pointers | Fast | Poor with optimizations | Low |\n| DWARF CFI | Slow | High | High |\n| Hybrid approach | Medium | High | Medium |\n\n**Signal Context and Register Access**\n\nThe signal handler receives execution context through a `ucontext_t` structure that contains the interrupted program's register state. This context provides the starting point for stack unwinding by giving us access to the stack pointer (`%rsp`), frame pointer (`%rbp`), and instruction pointer (`%rip`) at the moment of interruption.\n\nAccessing these registers requires platform-specific code, as register layout differs between architectures. On x86-64 Linux, we extract registers from `uctx->uc_mcontext.gregs[]` array using architecture-specific indices. The instruction pointer gives us the current execution location, while the stack and frame pointers provide starting points for unwinding.\n\n**Sample Storage During Signal Handling**\n\nSince signal handlers cannot use dynamic memory allocation, we must pre-allocate storage for captured samples. The profiler maintains a circular buffer of `Sample` structures, using atomic operations to manage producer and consumer indices safely across multiple threads.\n\nThe `Sample` structure captures all information needed for later analysis:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `timestamp` | float | Time when sample was captured (seconds since epoch) |\n| `thread_id` | int | Thread ID of interrupted execution |\n| `process_id` | int | Process ID of target program |\n| `stack_frames` | List[StackFrame] | Captured call stack frames |\n| `cpu_id` | int | CPU core where sample was taken |\n| `sample_weight` | int | Weight for weighted sampling (usually 1) |\n| `context_switches` | int | Number of context switches since last sample |\n| `sample_type` | SampleType | Type of sampling event (CPU, timer, etc.) |\n\nEach `StackFrame` within the sample contains:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `address` | int | Raw instruction pointer address |\n| `function_name` | str | Resolved function name (empty during capture) |\n| `filename` | str | Source file name (resolved later) |\n| `line_number` | int | Source line number (resolved later) |\n| `module_name` | str | Executable or shared library name |\n| `module_offset` | int | Offset within the module |\n| `inlined_frames` | List[InlinedFrame] | Inlined function information |\n| `is_kernel` | bool | Whether this frame is in kernel space |\n\nThe signal handler populates only the `address`, `module_name`, `module_offset`, and `is_kernel` fields. Symbol resolution happens later in a separate thread to avoid async-unsafe operations during signal handling.\n\n### Architecture Decision Records\n\n> **Architecture Decision Record: Sample Buffer Management**\n\n> **Decision: Lock-Free Circular Buffer with Atomic Operations**\n> - **Context**: Signal handlers need thread-safe storage for captured samples but cannot use mutexes or other blocking synchronization primitives\n> - **Options Considered**:\n>   1. Pre-allocated arrays with per-thread separation\n>   2. Lock-free circular buffer with atomic indices\n>   3. Signal masking with single-threaded sample storage\n> - **Decision**: Lock-free circular buffer using atomic compare-and-swap for index management\n> - **Rationale**: Provides thread safety without blocking operations, automatically balances load across threads, and handles overflow gracefully by overwriting oldest samples. Atomic operations are async-safe and have minimal overhead.\n> - **Consequences**: Enables high-frequency sampling without signal handler blocking, but requires careful memory ordering and may lose samples under extreme load. Buffer size must be tuned to prevent overflow during processing delays.\n\n> **Architecture Decision Record: Kernel Stack Sampling**\n\n> **Decision: Optional Kernel Stack Capture via /proc Interface**\n> - **Context**: CPU hotspots may exist in kernel code during system calls, but capturing kernel stacks requires additional privileges and mechanism\n> - **Options Considered**:\n>   1. User-space only sampling (simple but incomplete view)\n>   2. Kernel stack via /proc/PID/stack reading during signal handler\n>   3. eBPF-based kernel stack capture (requires modern kernel)\n> - **Decision**: Optional kernel stack capture by reading /proc/PID/stack when include_kernel is enabled\n> - **Rationale**: Provides kernel visibility without requiring eBPF support, can be enabled/disabled based on analysis needs, and works on older kernels. Reading /proc is async-safe and relatively fast.\n> - **Consequences**: Requires additional file I/O during signal handling but provides complete execution visibility. May require elevated privileges for some kernel stack access.\n\n> **Architecture Decision Record: Thread-Specific vs Process-Wide Sampling**\n\n> **Decision: Process-Wide Sampling with Thread ID Recording**\n> - **Context**: Multi-threaded programs need profiling that can identify per-thread hotspots while maintaining implementation simplicity\n> - **Options Considered**:\n>   1. Separate timer per thread with thread-specific handlers\n>   2. Process-wide timer with automatic thread selection\n>   3. Manual thread iteration with ptrace attachment\n> - **Decision**: Single process-wide ITIMER_PROF timer with thread ID recording in each sample\n> - **Rationale**: Kernel automatically delivers signals to whichever thread is consuming CPU time, providing natural load balancing. Thread ID in each sample enables per-thread analysis during post-processing. Avoids complex thread management and multiple timer coordination.\n> - **Consequences**: Simplifies implementation and automatically focuses on active threads, but may undersample threads with infrequent CPU usage. Thread creation/destruction during profiling is handled transparently.\n\n**Sampling Frequency and Overhead Trade-offs**\n\nThe choice of sampling frequency represents the fundamental trade-off in statistical profiling: accuracy versus overhead. Higher frequencies provide more detailed profiles with better statistical significance, but increase the CPU time consumed by signal handling and stack unwinding.\n\n| Frequency Range | Use Case | Typical Overhead | Statistical Accuracy |\n|-----------------|----------|------------------|----------------------|\n| 10-50 Hz | Production profiling | <0.5% | Good for major hotspots |\n| 100-500 Hz | Development profiling | 1-3% | Detailed function analysis |\n| 1-10 KHz | Micro-benchmarking | 5-15% | High-resolution profiling |\n\nThe `TARGET_OVERHEAD_PERCENT` constant guides automatic frequency selection when overhead limits are more important than absolute frequency. The profiler can dynamically adjust frequency based on observed signal handler execution time, increasing frequency when handlers complete quickly and reducing it when overhead exceeds targets.\n\n**Signal Delivery Reliability and Dropped Samples**\n\nSignal delivery is not guaranteed, and samples may be dropped under several conditions. High system load can delay signal delivery beyond the timer interval, causing missed samples. Signal handlers that execute too slowly may still be running when the next signal arrives, leading to signal coalescing where multiple timer events result in only one signal delivery.\n\nThe profiler tracks dropped samples by comparing the expected sample count (based on elapsed time and configured frequency) with the actual samples collected. The `SampleBatch` structure records this information:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `samples` | List[Sample] | Successfully captured samples |\n| `start_time` | float | Profiling session start timestamp |\n| `end_time` | float | Profiling session end timestamp |\n| `dropped_samples` | int | Estimated number of missed samples |\n| `target_process` | str | Process name or PID being profiled |\n| `sampling_frequency` | int | Configured sampling rate in Hz |\n| `total_sample_time` | float | Cumulative time spent in signal handlers |\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Async-Unsafe Operations in Signal Handler**\n\nThe most dangerous mistake is calling non-async-safe functions within the signal handler. Functions like `malloc()`, `free()`, `printf()`, and most standard library calls can cause deadlocks if the signal interrupts the same function being called from the main program thread.\n\n**Why it's wrong**: If the signal handler calls `malloc()` while the main thread is already inside `malloc()`, both will attempt to acquire the same internal mutex, causing an unrecoverable deadlock.\n\n**How to fix**: Use only async-safe functions listed in `signal-safety(7)`. Pre-allocate all data structures, use atomic operations for synchronization, and defer complex processing to a separate thread outside the signal handler.\n\n⚠️ **Pitfall: Sampling Bias in Tight Loops**\n\nStatistical sampling can miss or underrepresent very short functions that execute quickly relative to the sampling period. Conversely, functions that block on I/O may be overrepresented if using wall-clock-based timers instead of CPU-time-based timers.\n\n**Why it's wrong**: A function that executes for 0.1ms but runs 1000 times per second consumes 10% of CPU time but might never be sampled if the sampling frequency is too low. This leads to incomplete profiles that miss actual hotspots.\n\n**How to fix**: Use `ITIMER_PROF` for CPU-time-based sampling rather than `ITIMER_REAL`. Choose sampling frequencies high enough to capture short functions multiple times. Consider weighted sampling where sample counts are adjusted based on elapsed time between samples.\n\n⚠️ **Pitfall: Ignoring Stack Unwinding Failures**\n\nStack unwinding can fail due to corrupted frame pointers, missing debug information, or execution in signal handlers or dynamically generated code. Silently ignoring these failures results in truncated profiles that underrepresent complex call chains.\n\n**Why it's wrong**: If unwinding consistently fails after the first few frames, the profile will show most time spent in leaf functions rather than revealing the calling context that led to those functions. This makes it impossible to identify the high-level code paths responsible for performance issues.\n\n**How to fix**: Implement robust error detection during unwinding, track unwinding failure rates, and provide fallback strategies. Log unwinding failures for analysis, and consider hybrid approaches that combine multiple unwinding methods for better reliability.\n\n⚠️ **Pitfall: Excessive Signal Handler Overhead**\n\nPerforming too much work in the signal handler itself can create a feedback loop where profiling overhead becomes the dominant CPU consumer, distorting the profile results.\n\n**Why it's wrong**: If the signal handler takes 1ms to execute and runs at 1KHz frequency, it consumes 100% CPU time, making meaningful profiling impossible. The overhead becomes self-amplifying as more signal handling creates more apparent hotspots in signal handling code.\n\n**How to fix**: Minimize signal handler work to address capture and storage only. Move symbol resolution, stack analysis, and complex processing to separate threads. Monitor signal handler execution time and automatically reduce sampling frequency if overhead exceeds targets. Use efficient data structures and avoid memory allocations during signal handling.\n\n⚠️ **Pitfall: Inadequate Buffer Sizing for High-Frequency Sampling**\n\nThe circular buffer for storing samples must be sized appropriately for the sampling frequency and processing speed. Undersized buffers cause sample loss, while oversized buffers consume excessive memory.\n\n**Why it's wrong**: A 10KHz sampling rate generates 10,000 samples per second. If each sample contains 20 stack frames, that's 200,000 addresses per second. A buffer holding only 1,000 samples will overflow in 0.1 seconds, losing most profiling data.\n\n**How to fix**: Size buffers based on maximum expected sampling rate multiplied by processing delay. Implement watermark monitoring that warns when buffer usage exceeds safe thresholds. Consider multiple buffers with background processing to maintain continuous sampling during analysis phases.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Signal Handling | Python `signal` module with ctypes for stack walking | C extension module with libunwind integration |\n| Stack Unwinding | Frame pointer walking with ctypes memory access | DWARF-based unwinding with pyelftools and libunwind |\n| Sample Storage | Collections.deque with threading.Lock | Lock-free circular buffer using multiprocessing.Array |\n| Timer Management | signal.setitimer() with ITIMER_PROF | Custom timer thread with more precise control |\n| Cross-Platform | Linux-specific implementation using /proc | Abstract platform layer supporting Linux, macOS, Windows |\n\nFor learning purposes, start with the simple options using Python's built-in capabilities, then enhance with advanced techniques as needed for production use.\n\n#### Recommended File Structure\n\n```\nprofiler/\n├── sampling/\n│   ├── __init__.py\n│   ├── sampler.py              ← Main sampling logic and configuration\n│   ├── signal_handler.py       ← Signal handler implementation\n│   ├── stack_unwinder.py       ← Stack frame unwinding logic\n│   ├── sample_buffer.py        ← Thread-safe sample storage\n│   └── platform/\n│       ├── __init__.py\n│       ├── linux.py            ← Linux-specific signal and stack handling\n│       └── common.py           ← Platform-independent utilities\n├── data_model/\n│   ├── __init__.py\n│   ├── sample.py               ← Sample and StackFrame data structures\n│   └── config.py               ← SamplingConfig and ProfilerConfig\n└── utils/\n    ├── __init__.py\n    ├── timing.py               ← Timer utilities and overhead measurement\n    └── logging.py              ← Async-safe logging for signal handlers\n```\n\n#### Infrastructure Starter Code\n\n**Platform Detection and Signal Utilities** (`profiler/sampling/platform/linux.py`):\n\n```python\nimport os\nimport signal\nimport struct\nimport ctypes\nfrom ctypes import c_void_p, c_int, c_ulong\nfrom typing import Optional, List\n\n# Linux-specific constants\nITIMER_PROF = 2\nSIGPROF = 27\n\nclass RegisterContext:\n    \"\"\"Represents CPU register state at signal delivery.\"\"\"\n    def __init__(self, rip: int, rsp: int, rbp: int):\n        self.instruction_pointer = rip\n        self.stack_pointer = rsp\n        self.frame_pointer = rbp\n\ndef extract_signal_context(signum: int, frame) -> RegisterContext:\n    \"\"\"Extract register context from Python signal frame.\n    \n    Note: Python's signal frame is limited compared to full ucontext_t.\n    For production use, consider a C extension for complete register access.\n    \"\"\"\n    # Python frame gives us limited context\n    if frame is None:\n        raise ValueError(\"No frame context available\")\n    \n    # Extract what we can from Python frame object\n    code_obj = frame.f_code\n    instruction_pointer = id(code_obj)  # Approximation for demo\n    \n    # In real implementation, use ctypes to access ucontext_t\n    # This is a simplified version for educational purposes\n    return RegisterContext(\n        rip=instruction_pointer,\n        rsp=0,  # Would extract from ucontext_t in production\n        rbp=0   # Would extract from ucontext_t in production\n    )\n\ndef setup_profiling_signal() -> None:\n    \"\"\"Configure signal handling for profiling.\"\"\"\n    # Ensure signal handler runs with minimal restrictions\n    signal.siginterrupt(signal.SIGPROF, False)\n\ndef read_proc_stack(pid: int) -> List[str]:\n    \"\"\"Read kernel stack from /proc/PID/stack if available.\"\"\"\n    try:\n        with open(f'/proc/{pid}/stack', 'r') as f:\n            return [line.strip() for line in f if line.strip()]\n    except (OSError, IOError):\n        return []  # Kernel stack not available\n\nclass TimerConfig:\n    \"\"\"ITIMER configuration for profiling signals.\"\"\"\n    def __init__(self, frequency_hz: int):\n        self.interval_sec = 1.0 / frequency_hz\n        self.initial_sec = self.interval_sec\n\ndef set_profiling_timer(config: TimerConfig) -> None:\n    \"\"\"Start ITIMER_PROF timer for regular SIGPROF delivery.\"\"\"\n    signal.setitimer(\n        signal.ITIMER_PROF,\n        config.initial_sec,\n        config.interval_sec\n    )\n\ndef clear_profiling_timer() -> None:\n    \"\"\"Stop profiling timer.\"\"\"\n    signal.setitimer(signal.ITIMER_PROF, 0)\n```\n\n**Thread-Safe Sample Buffer** (`profiler/sampling/sample_buffer.py`):\n\n```python\nimport threading\nimport time\nfrom collections import deque\nfrom typing import List, Optional\nfrom dataclasses import dataclass\n\nfrom profiler.data_model.sample import Sample\n\n@dataclass\nclass BufferStats:\n    \"\"\"Statistics about sample buffer usage and performance.\"\"\"\n    total_samples: int = 0\n    dropped_samples: int = 0\n    max_buffer_size: int = 0\n    current_buffer_size: int = 0\n    \n    def get_drop_rate(self) -> float:\n        \"\"\"Calculate percentage of dropped samples.\"\"\"\n        if self.total_samples == 0:\n            return 0.0\n        return (self.dropped_samples / self.total_samples) * 100.0\n\nclass SampleBuffer:\n    \"\"\"Thread-safe circular buffer for storing captured samples.\n    \n    Uses deque with maxlen for automatic overflow handling.\n    Thread safety provided by explicit locking since signal handlers\n    cannot use lock-free algorithms safely in Python.\n    \"\"\"\n    \n    def __init__(self, max_size: int = 10000):\n        self._buffer = deque(maxlen=max_size)\n        self._lock = threading.Lock()\n        self._stats = BufferStats()\n        self._max_size = max_size\n        \n    def add_sample(self, sample: Sample) -> bool:\n        \"\"\"Add sample to buffer.\n        \n        Returns:\n            True if sample was stored, False if buffer full and sample dropped.\n        \"\"\"\n        with self._lock:\n            if len(self._buffer) >= self._max_size:\n                self._stats.dropped_samples += 1\n                return False\n                \n            self._buffer.append(sample)\n            self._stats.total_samples += 1\n            self._stats.current_buffer_size = len(self._buffer)\n            \n            if self._stats.current_buffer_size > self._stats.max_buffer_size:\n                self._stats.max_buffer_size = self._stats.current_buffer_size\n                \n            return True\n    \n    def get_samples(self, max_count: Optional[int] = None) -> List[Sample]:\n        \"\"\"Extract samples from buffer for processing.\n        \n        Args:\n            max_count: Maximum samples to extract (None for all).\n            \n        Returns:\n            List of samples in FIFO order.\n        \"\"\"\n        with self._lock:\n            if max_count is None:\n                samples = list(self._buffer)\n                self._buffer.clear()\n            else:\n                samples = []\n                for _ in range(min(max_count, len(self._buffer))):\n                    if self._buffer:\n                        samples.append(self._buffer.popleft())\n            \n            self._stats.current_buffer_size = len(self._buffer)\n            return samples\n    \n    def get_stats(self) -> BufferStats:\n        \"\"\"Get current buffer statistics.\"\"\"\n        with self._lock:\n            return BufferStats(\n                total_samples=self._stats.total_samples,\n                dropped_samples=self._stats.dropped_samples,\n                max_buffer_size=self._stats.max_buffer_size,\n                current_buffer_size=len(self._buffer)\n            )\n```\n\n#### Core Logic Skeleton Code\n\n**Main Sampler Implementation** (`profiler/sampling/sampler.py`):\n\n```python\nimport signal\nimport time\nimport threading\nfrom typing import Optional, Callable\n\nfrom profiler.data_model.config import SamplingConfig\nfrom profiler.data_model.sample import Sample, SampleBatch\nfrom profiler.sampling.signal_handler import ProfilerSignalHandler\nfrom profiler.sampling.sample_buffer import SampleBuffer\nfrom profiler.sampling.platform.linux import set_profiling_timer, clear_profiling_timer, TimerConfig\n\nclass StackSampler:\n    \"\"\"Captures call stacks at regular intervals using signal-based interruption.\"\"\"\n    \n    def __init__(self, config: SamplingConfig):\n        self.config = config\n        self.buffer = SampleBuffer(max_size=config.frequency_hz * 60)  # 1 minute buffer\n        self.signal_handler = ProfilerSignalHandler(self.buffer, config)\n        self.is_sampling = False\n        self.start_time: Optional[float] = None\n        \n    def start_sampling(self, target_pid: Optional[int] = None) -> None:\n        \"\"\"Begin stack sampling of target process.\n        \n        Args:\n            target_pid: Process ID to profile (None for current process).\n        \"\"\"\n        if self.is_sampling:\n            raise RuntimeError(\"Sampling already active\")\n            \n        # TODO 1: Validate sampling configuration parameters\n        # - Check frequency_hz is within reasonable range (1-10000)\n        # - Verify max_stack_depth is positive and < 1000\n        # - Ensure target process exists if pid specified\n        \n        # TODO 2: Install signal handler for SIGPROF\n        # - Use signal.signal(signal.SIGPROF, self.signal_handler.handle_signal)\n        # - Store previous handler for restoration\n        \n        # TODO 3: Configure and start profiling timer\n        # - Create TimerConfig with desired frequency\n        # - Call set_profiling_timer() to begin signal delivery\n        \n        # TODO 4: Record sampling session metadata\n        # - Set self.start_time = time.time()\n        # - Mark self.is_sampling = True\n        # - Log sampling start with configuration details\n        \n        pass  # Student implements\n        \n    def stop_sampling(self) -> SampleBatch:\n        \"\"\"Stop sampling and return collected samples.\n        \n        Returns:\n            SampleBatch containing all captured samples and metadata.\n        \"\"\"\n        if not self.is_sampling:\n            raise RuntimeError(\"No active sampling session\")\n            \n        # TODO 1: Stop timer signal delivery\n        # - Call clear_profiling_timer() to stop SIGPROF signals\n        \n        # TODO 2: Restore previous signal handler\n        # - Restore signal.SIGPROF to previous handler\n        \n        # TODO 3: Collect all buffered samples\n        # - Call self.buffer.get_samples() to extract samples\n        # - Get buffer statistics for dropped sample count\n        \n        # TODO 4: Calculate session statistics\n        # - Compute actual sampling duration = time.time() - self.start_time\n        # - Calculate achieved sample rate = len(samples) / duration\n        # - Estimate dropped samples from timer frequency vs actual samples\n        \n        # TODO 5: Create and return SampleBatch\n        # - Populate all metadata fields from session\n        # - Include buffer statistics and timing information\n        # - Mark self.is_sampling = False\n        \n        pass  # Student implements\n        \n    def get_current_stats(self) -> dict:\n        \"\"\"Get current sampling statistics without stopping.\"\"\"\n        # TODO 1: Check if sampling is active\n        # TODO 2: Get buffer statistics from self.buffer.get_stats()\n        # TODO 3: Calculate elapsed time and current sample rate\n        # TODO 4: Return dictionary with current metrics\n        pass  # Student implements\n```\n\n**Signal Handler Implementation** (`profiler/sampling/signal_handler.py`):\n\n```python\nimport os\nimport time\nimport signal\nfrom typing import List\n\nfrom profiler.data_model.sample import Sample, StackFrame, SampleType\nfrom profiler.data_model.config import SamplingConfig\nfrom profiler.sampling.stack_unwinder import StackUnwinder\nfrom profiler.sampling.sample_buffer import SampleBuffer\nfrom profiler.sampling.platform.linux import extract_signal_context, read_proc_stack\n\nclass ProfilerSignalHandler:\n    \"\"\"Signal handler for capturing stack samples during SIGPROF delivery.\"\"\"\n    \n    def __init__(self, sample_buffer: SampleBuffer, config: SamplingConfig):\n        self.buffer = sample_buffer\n        self.config = config\n        self.unwinder = StackUnwinder(config.max_stack_depth)\n        self.sample_count = 0\n        \n    def handle_signal(self, signum: int, frame) -> None:\n        \"\"\"Signal handler called on SIGPROF delivery.\n        \n        CRITICAL: This function runs in signal context and can only use\n        async-safe operations. No malloc, no locks, minimal processing.\n        \"\"\"\n        # TODO 1: Validate signal number and frame context\n        # - Check signum == signal.SIGPROF\n        # - Ensure frame is not None\n        # - Return early if invalid (avoid exceptions in signal handler)\n        \n        # TODO 2: Capture basic sample metadata\n        # - Get current timestamp using time.time() (async-safe)\n        # - Get thread ID using threading.get_ident()\n        # - Get process ID using os.getpid()\n        # - Increment self.sample_count atomically\n        \n        # TODO 3: Extract execution context from signal frame\n        # - Call extract_signal_context(signum, frame)\n        # - Handle any exceptions silently (return early)\n        \n        # TODO 4: Unwind call stack from current context\n        # - Call self.unwinder.unwind_stack(context)\n        # - Limit unwinding time to avoid signal handler delays\n        # - Set timeout based on target overhead percentage\n        \n        # TODO 5: Capture kernel stack if enabled\n        # - Check self.config.include_kernel\n        # - Call read_proc_stack(os.getpid()) if enabled\n        # - Append kernel frames to stack_frames list\n        \n        # TODO 6: Create sample object and store in buffer\n        # - Create Sample with all captured information\n        # - Call self.buffer.add_sample(sample)\n        # - Handle buffer full condition silently (don't raise exceptions)\n        \n        # TODO 7: Handle any errors gracefully\n        # - Catch all exceptions and return silently\n        # - Never call malloc, printf, or other unsafe functions\n        # - Log errors to pre-allocated error counter only\n        \n        pass  # Student implements\n```\n\n**Stack Unwinding Implementation** (`profiler/sampling/stack_unwinder.py`):\n\n```python\nimport ctypes\nfrom typing import List, Optional\nfrom profiler.data_model.sample import StackFrame\nfrom profiler.sampling.platform.linux import RegisterContext\n\nclass StackUnwinder:\n    \"\"\"Unwinds call stacks using frame pointer traversal.\"\"\"\n    \n    def __init__(self, max_depth: int = 64):\n        self.max_depth = max_depth\n        \n    def unwind_stack(self, context: RegisterContext) -> List[StackFrame]:\n        \"\"\"Unwind call stack from given execution context.\n        \n        Args:\n            context: CPU register state from signal delivery.\n            \n        Returns:\n            List of stack frames from current function back to main().\n        \"\"\"\n        # TODO 1: Initialize unwinding from current context\n        # - Start with instruction_pointer from context\n        # - Set current_frame_ptr = context.frame_pointer\n        # - Create empty frames list for results\n        \n        # TODO 2: Follow frame pointer chain\n        # - Loop while current_frame_ptr is valid and depth < max_depth\n        # - Read return address from frame_ptr + sizeof(void*)\n        # - Read next frame pointer from frame_ptr + 0\n        # - Use ctypes to safely access memory addresses\n        \n        # TODO 3: Create StackFrame for each discovered frame\n        # - Set address to instruction pointer value\n        # - Determine module_name from address range\n        # - Calculate module_offset = address - module_base\n        # - Mark is_kernel based on address range\n        \n        # TODO 4: Handle frame pointer validation\n        # - Check frame pointers are aligned (typically 8-byte alignment)\n        # - Verify frame pointers increase monotonically (stack grows down)\n        # - Stop unwinding if frame pointer seems corrupted\n        \n        # TODO 5: Detect unwinding completion\n        # - Stop when frame pointer becomes NULL or invalid\n        # - Stop when return address is NULL (reached bottom)\n        # - Stop when maximum depth reached\n        \n        # TODO 6: Handle memory access errors\n        # - Catch segmentation faults from invalid memory access\n        # - Return partial stack if unwinding fails partway\n        # - Never raise exceptions (called from signal handler)\n        \n        pass  # Student implements\n        \n    def _read_memory_safe(self, address: int, size: int) -> Optional[bytes]:\n        \"\"\"Safely read memory from target process.\n        \n        Args:\n            address: Memory address to read from.\n            size: Number of bytes to read.\n            \n        Returns:\n            Memory contents or None if read fails.\n        \"\"\"\n        # TODO: Implement safe memory reading using ctypes\n        # - Use ctypes.c_void_p to access raw memory\n        # - Handle access violations gracefully\n        # - Return None for any read failures\n        pass  # Student implements\n        \n    def _is_valid_frame_pointer(self, ptr: int) -> bool:\n        \"\"\"Check if frame pointer looks valid.\n        \n        Args:\n            ptr: Frame pointer value to validate.\n            \n        Returns:\n            True if pointer seems valid for unwinding.\n        \"\"\"\n        # TODO: Implement frame pointer validation\n        # - Check alignment (usually 8-byte aligned on x86-64)\n        # - Verify address is in reasonable stack range\n        # - Ensure pointer is not NULL\n        pass  # Student implements\n```\n\n#### Milestone Checkpoint\n\nAfter implementing the stack sampling component, verify correct operation with these tests:\n\n**Basic Functionality Test**:\n```bash\npython -c \"\nfrom profiler.sampling.sampler import StackSampler\nfrom profiler.data_model.config import SamplingConfig\n\nconfig = SamplingConfig(frequency_hz=100, max_stack_depth=20, include_kernel=False, target_overhead_percent=2.0)\nsampler = StackSampler(config)\n\nsampler.start_sampling()\ntime.sleep(5)  # Let it sample for 5 seconds\nbatch = sampler.stop_sampling()\n\nprint(f'Captured {len(batch.samples)} samples')\nprint(f'Drop rate: {batch.dropped_samples}/{batch.dropped_samples + len(batch.samples)}')\nprint(f'Sample rate: {len(batch.samples) / (batch.end_time - batch.start_time):.1f} Hz')\n\"\n```\n\n**Expected Output**:\n- Should capture approximately 500 samples (100 Hz × 5 seconds)\n- Drop rate should be 0% for this light test\n- Sample rate should be close to configured 100 Hz\n- Each sample should have 3-10 stack frames (depending on call depth)\n\n**Manual Verification**:\n1. Run a CPU-intensive Python program in background\n2. Profile it for 10 seconds at 1000 Hz\n3. Verify samples contain diverse instruction addresses\n4. Check that sampling stops cleanly without hanging\n\n**Signs of Problems**:\n- **Zero samples captured**: Signal handler not installing correctly or timer not firing\n- **All samples have 1 frame**: Stack unwinding failing, probably due to frame pointer issues\n- **High drop rate (>5%)**: Buffer too small or signal handler taking too long\n- **Segmentation faults**: Memory access errors in stack unwinding, need better validation\n- **Program hangs**: Signal handler deadlock, probably calling non-async-safe functions\n\n\n## Symbol Resolution Component\n\n> **Milestone(s):** Milestone 2 — Symbol Resolution: Convert raw addresses to human-readable function names and source locations by parsing ELF binaries, loading symbol tables, and processing DWARF debug information\n\n![Symbol Resolution Process](./diagrams/symbol-resolution-flow.svg)\n\n### Mental Model: Address Book Lookup\n\nThink of symbol resolution like looking up addresses in a comprehensive phone book system. When you have a raw memory address from a stack sample, it's like having a street address but no idea what business or person lives there. The symbol resolution process is like having multiple phone books (ELF symbol tables, DWARF debug information, shared library maps) that help you translate that cryptic address into meaningful information: \"Oh, this address corresponds to the `calculate_tax` function in `tax_processor.cpp` at line 142.\"\n\nJust as a phone book lookup might involve checking the main directory first, then consulting specialized business directories, and finally looking up detailed contact information, symbol resolution follows a hierarchical lookup process. First, we determine which binary or shared library contains the address (like finding the right phone book). Then we search the symbol table to find the function name (like finding the business name). Finally, we consult DWARF debug information to get precise source file and line number details (like getting the exact office suite number).\n\nThe challenge is that this \"phone book\" system must be extremely fast because we're doing thousands of lookups per second during profiling. Modern programs load dozens of shared libraries, each with thousands of symbols, creating a massive address space that changes as libraries are loaded and unloaded. We need intelligent caching and efficient data structures to make these lookups fast enough that symbol resolution doesn't become a bottleneck in our profiling pipeline.\n\nAdditionally, just as some buildings might not be listed in phone books (unlisted numbers or new constructions), some code addresses might not have symbols available. This happens with stripped binaries, optimized code, or dynamically generated code. Our symbol resolution system must gracefully handle these cases and provide useful fallback information.\n\n### ELF Binary and Symbol Table Parsing\n\nThe foundation of symbol resolution lies in understanding the **Executable and Linkable Format (ELF)**, which is the standard binary format for executables and shared libraries on Linux systems. Every compiled program contains structured metadata that maps memory addresses to function names, and our profiler must parse this information efficiently.\n\n**ELF Structure and Symbol Tables**\n\nAn ELF binary contains multiple sections, but for symbol resolution we primarily care about the `.symtab` (symbol table), `.dynsym` (dynamic symbol table), and `.strtab` (string table) sections. The symbol table contains entries that map address ranges to symbol names, while the string table holds the actual function name strings to save space through deduplication.\n\nEach symbol table entry contains crucial information for address resolution:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| st_name | uint32 | Offset into string table for symbol name |\n| st_value | uint64 | Symbol address (or offset within section) |\n| st_size | uint64 | Size of symbol in bytes |\n| st_info | uint8 | Symbol type and binding information |\n| st_other | uint8 | Symbol visibility |\n| st_shndx | uint16 | Section index this symbol belongs to |\n\nThe symbol resolution process begins by loading these tables into memory and building efficient lookup structures. We cannot simply iterate through symbols for each address lookup because that would be too slow for production profiling.\n\n**Address Space Layout Randomization (ASLR) Handling**\n\nModern Linux systems use ASLR to randomize the base addresses where executables and shared libraries are loaded. This security feature means that the addresses in our stack samples are **runtime addresses**, while the addresses in ELF symbol tables are **file offsets** or **virtual addresses** from the original linking process.\n\nTo resolve this discrepancy, we must determine the **base address** where each binary or shared library was actually loaded at runtime. This information is available through the `/proc/[pid]/maps` file, which shows the memory mappings for a running process:\n\n```\n7f8b4c000000-7f8b4c021000 r-xp 00000000 08:01 1234567 /lib/x86_64-linux-gnu/ld-2.31.so\n7f8b4c021000-7f8b4c022000 r--p 00021000 08:01 1234567 /lib/x86_64-linux-gnu/ld-2.31.so\n```\n\nEach line provides the runtime address range, permissions, file offset, device, inode, and file path. By parsing this information, we can calculate the **load bias** (difference between runtime base address and ELF virtual address) for each module.\n\n**Symbol Lookup Algorithm**\n\nThe core symbol lookup algorithm operates through the following steps:\n\n1. **Module Identification**: Given a runtime address, search through loaded modules to find which binary or shared library contains this address by checking if the address falls within any module's memory range.\n\n2. **Address Translation**: Convert the runtime address to a file-relative address by subtracting the module's base address and accounting for any load bias.\n\n3. **Symbol Table Search**: Use binary search on the sorted symbol table to find the symbol whose address range contains our target address. Symbols are sorted by start address to enable efficient searching.\n\n4. **Symbol Validation**: Verify that the address falls within the symbol's size range (`st_value <= address < st_value + st_size`). Some symbols may have zero size, requiring special handling.\n\n5. **Name Resolution**: Use the string table offset (`st_name`) to retrieve the actual function name string.\n\n**Module Loading and Caching**\n\nOur `Module` data structure represents a single binary or shared library:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| name | str | Module name (filename without path) |\n| path | str | Full filesystem path to binary |\n| base_address | int | Runtime base address where module is loaded |\n| size | int | Total size of module in memory |\n| build_id | str | Unique identifier for this binary version |\n| symbols | Dict[int, Symbol] | Map from start address to symbol information |\n| has_debug_info | bool | Whether DWARF debug information is available |\n| architecture | str | Target architecture (x86_64, aarch64, etc.) |\n| load_time | float | Timestamp when module was first loaded |\n\nThe module loading process involves several stages. First, we parse the ELF header to validate the file format and extract basic information like architecture and entry point. Next, we iterate through the section headers to locate symbol table sections. For each symbol table, we read all symbol entries and build our internal symbol map, sorting by address for efficient lookup.\n\n**C++ Symbol Demangling**\n\nCompiled C++ code uses **name mangling** to encode function signatures, namespaces, and template instantiations into unique symbol names. A simple C++ function like `MyClass::calculate(int, double)` might appear in the symbol table as `_ZN7MyClass9calculateEid`. For human-readable profiling output, we must **demangle** these names back to their original form.\n\nThe demangling process uses the platform's demangling library (typically `libc++abi` or `libstdc++`) to convert mangled names. Since demangling can be expensive, we cache the results in our `SymbolCache`:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| demangled_names | Dict[str, str] | Cache mapping mangled names to demangled versions |\n| hit_count | int | Number of successful cache lookups |\n| miss_count | int | Number of cache misses requiring computation |\n\n> **Design Insight**: Symbol demangling can consume significant CPU time during symbol resolution, especially for heavily templated C++ code. Aggressive caching of demangled names is essential for maintaining profiling performance. We also provide configuration options to disable demangling entirely for performance-critical scenarios where raw mangled names are acceptable.\n\n### DWARF Debug Information\n\nWhile ELF symbol tables provide function names and address ranges, **DWARF debug information** contains much richer metadata about the source code structure. DWARF enables us to map instruction addresses not just to function names, but to specific source file names, line numbers, and even column positions. This information transforms raw addresses into actionable debugging data.\n\n**DWARF Structure and Compilation Units**\n\nDWARF debug information is organized into **compilation units**, each representing a single source file that was compiled. Within each compilation unit, we find **Debug Information Entries (DIEs)** that describe functions, variables, types, and source line mappings.\n\nThe most critical DWARF sections for symbol resolution are:\n\n| Section | Purpose | Content |\n|---------|---------|---------|\n| .debug_info | Core debug data | Function definitions, variable types, compilation units |\n| .debug_line | Line number mapping | Maps instruction addresses to source file:line:column |\n| .debug_abbrev | Abbreviation table | Compression scheme for debug_info section |\n| .debug_str | String table | Shared string storage for debug information |\n| .debug_ranges | Address ranges | Non-contiguous address ranges for optimized code |\n\n**Line Number Program Execution**\n\nThe `.debug_line` section contains a state machine program that generates the complete mapping from instruction addresses to source locations. This compact encoding allows the compiler to efficiently represent line number information even for heavily optimized code where instructions from different source lines might be interleaved.\n\nThe line number state machine maintains several registers:\n\n| Register | Type | Description |\n|----------|------|-------------|\n| address | uint64 | Current instruction address |\n| file | uint32 | Index into file name table |\n| line | uint32 | Current source line number |\n| column | uint32 | Current column number within line |\n| is_stmt | bool | Whether this address corresponds to a statement boundary |\n| basic_block | bool | Whether this address starts a basic block |\n| end_sequence | bool | Whether this ends a sequence of instructions |\n\nOur DWARF parser executes this state machine program and builds a sorted table of line number entries. Each entry in our `LineRange` structure captures the relationship between code addresses and source locations:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| start_address | int | Beginning of address range for this source line |\n| end_address | int | End of address range (exclusive) |\n| line_number | int | Source file line number |\n| column_number | int | Column within the source line |\n| is_statement | bool | True if address represents a source statement boundary |\n| is_prologue_end | bool | True if function prologue ends at this address |\n| is_epilogue_begin | bool | True if function epilogue begins at this address |\n\n**Handling Optimized and Inlined Code**\n\nModern compiler optimizations significantly complicate symbol resolution. **Function inlining** means that code from one function appears directly within another function's instruction stream. **Dead code elimination** removes unreachable code, creating gaps in the address space. **Instruction reordering** can cause instructions from different source lines to be interleaved.\n\nDWARF handles inlined functions through special DIE entries that describe the inlining relationship. Our `InlinedFrame` structure captures this information:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| function_name | str | Name of the inlined function |\n| filename | str | Source file containing the inlined function |\n| line_number | int | Line number where function is defined |\n| call_filename | str | Source file containing the call site |\n| call_line_number | int | Line number of the inlining call site |\n\nWhen resolving an address that falls within inlined code, we must construct a chain of `InlinedFrame` entries representing the complete inlining stack. This allows flame graphs to accurately represent the logical call structure even when physical function calls have been optimized away.\n\n**DWARF Parsing Performance Optimizations**\n\nParsing complete DWARF information for large binaries can be extremely slow, potentially taking several seconds for large C++ applications. Since profiling must have low latency, we implement several optimization strategies:\n\n**Lazy Loading**: We parse only the compilation unit headers initially, deferring detailed parsing until we actually need symbol information for addresses within that unit. This reduces startup time when profiling applications that only execute code from a small subset of the binary.\n\n**Address Range Indexing**: We build an index mapping address ranges to compilation units, allowing us to quickly determine which unit contains a given address without scanning through all units linearly.\n\n**Line Number Caching**: Since line number programs can be expensive to execute repeatedly, we cache the complete line number table for compilation units that we've already processed.\n\n**Incremental Parsing**: For applications that load shared libraries dynamically, we parse DWARF information incrementally as new libraries are loaded rather than attempting to parse everything upfront.\n\n### Architecture Decision Records\n\n> **Decision: Symbol Lookup Data Structure**\n> - **Context**: Need to efficiently resolve thousands of addresses per second during profiling. Linear search through symbol tables would be too slow for production use.\n> - **Options Considered**: \n>   1. Linear search through unsorted symbol list\n>   2. Hash table mapping addresses to symbols\n>   3. Sorted symbol array with binary search\n>   4. Interval tree for overlapping address ranges\n> - **Decision**: Sorted symbol array with binary search\n> - **Rationale**: Provides O(log n) lookup performance with minimal memory overhead. Hash tables would require exact address matches, but we need range queries. Interval trees add complexity without significant performance benefits for typical symbol table sizes.\n> - **Consequences**: Enables fast symbol resolution with predictable performance characteristics. Requires sorting symbols during module loading, adding slight initialization cost.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Linear search | Simple implementation, no preprocessing | O(n) lookup time, unusable for large binaries |\n| Hash table | O(1) average lookup time | Requires exact address matches, no range queries |\n| Binary search | O(log n) lookup, low memory overhead | Requires sorted array, O(n log n) preprocessing |\n| Interval tree | Handles overlapping ranges efficiently | Complex implementation, higher memory usage |\n\n> **Decision: Symbol Cache Strategy**\n> - **Context**: Symbol resolution involves expensive operations like ELF parsing, DWARF processing, and string demangling. Without caching, repeated lookups become a performance bottleneck.\n> - **Options Considered**:\n>   1. No caching - resolve every address freshly\n>   2. Simple LRU cache with fixed size\n>   3. Multi-level cache with different policies for hits vs misses\n>   4. Persistent symbol cache across profiling sessions\n> - **Decision**: Multi-level cache with LRU for symbols and separate miss cache\n> - **Rationale**: Hot addresses in typical programs follow power law distribution - small number of addresses account for majority of samples. Miss cache prevents repeated expensive lookups for addresses with no symbols (common in optimized binaries).\n> - **Consequences**: Dramatically improves symbol resolution performance after warmup period. Adds memory overhead and cache management complexity.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| No caching | Simple, no memory overhead | Extremely poor performance, repeated expensive work |\n| LRU cache | Good hit rates for hot addresses | Still slow for repeated misses |\n| Multi-level cache | Optimizes both hits and misses | More complex implementation |\n| Persistent cache | Fast across sessions | Cache invalidation complexity, disk storage |\n\n> **Decision: ASLR and Load Bias Handling**\n> - **Context**: Modern systems randomize load addresses for security. Raw addresses from stack samples don't match addresses in ELF symbol tables.\n> - **Options Considered**:\n>   1. Parse /proc/[pid]/maps at startup and assume static layout\n>   2. Re-read /proc/[pid]/maps periodically to detect changes\n>   3. Hook into dynamic linker notifications\n>   4. Use ptrace to monitor memory mapping changes\n> - **Decision**: Parse /proc/[pid]/maps at startup with periodic refresh\n> - **Rationale**: Most profiling sessions target processes with stable memory layouts after initialization. Periodic refresh catches dynamic library loading without excessive overhead. Hooking into linker adds complexity and ptrace requires elevated privileges.\n> - **Consequences**: Works well for typical profiling scenarios. May miss short-lived dynamic libraries loaded between refresh intervals.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Static startup parsing | Simple, low overhead | Misses dynamic library loading |\n| Periodic refresh | Catches most library changes | Slight performance overhead |\n| Linker hooking | Real-time updates | Complex implementation, fragile |\n| ptrace monitoring | Complete accuracy | Requires root privileges, high overhead |\n\n> **Decision: DWARF Processing Strategy**\n> - **Context**: DWARF debug information can be massive (gigabytes for large C++ applications). Full parsing is too slow for interactive profiling.\n> - **Options Considered**:\n>   1. Parse all DWARF information at startup\n>   2. Lazy parsing - only process DWARF for addresses we actually encounter\n>   3. Background thread pre-parsing popular compilation units\n>   4. External symbol server with pre-processed DWARF data\n> - **Decision**: Lazy parsing with background thread optimization\n> - **Rationale**: Most profiling sessions only exercise small fraction of total code. Lazy parsing provides good performance for typical use cases. Background thread can speculatively parse compilation units for hot addresses.\n> - **Consequences**: First lookup for an address may be slower due to DWARF parsing overhead. Memory usage scales with actual profiling coverage rather than total binary size.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Full startup parsing | Consistent lookup performance | Extremely slow startup, high memory usage |\n| Lazy parsing | Fast startup, memory efficient | Variable lookup latency |\n| Background pre-parsing | Good compromise on latency | Complex thread coordination |\n| External symbol server | Very fast, shared across teams | Infrastructure complexity, network dependency |\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Ignoring ASLR When Resolving Addresses**\n\nMany developers assume that addresses from stack samples can be directly compared with addresses from ELF symbol tables. This works on older systems or when ASLR is disabled, but fails on modern Linux distributions where ASLR is enabled by default.\n\n**Why it's wrong**: ASLR randomizes the base addresses where executables and shared libraries are loaded. The virtual addresses in ELF files represent the original link-time layout, while runtime addresses include a random offset. Directly comparing these addresses will result in no symbol matches.\n\n**How to fix**: Always parse `/proc/[pid]/maps` to determine the actual load addresses of modules. Calculate the load bias by subtracting the ELF virtual address from the runtime base address. Apply this bias when translating sample addresses for symbol lookup.\n\n**Example symptom**: Symbol resolution returns no results despite having proper debug symbols, or returns symbols from completely wrong functions.\n\n⚠️ **Pitfall: Linear Search Through Large Symbol Tables**\n\nDevelopers often implement symbol resolution by iterating through all symbols in a module until finding one that contains the target address. This appears to work during initial testing with small programs but becomes prohibitively slow with real applications.\n\n**Why it's wrong**: Large C++ applications can have hundreds of thousands of symbols. Linear search creates O(n) lookup time, making symbol resolution the bottleneck in profiling performance. When profiling at 1000 Hz, even 1ms per symbol lookup is too slow.\n\n**How to fix**: Sort symbols by start address during module loading. Use binary search to find the containing symbol in O(log n) time. Consider building additional indexes for very large symbol tables.\n\n**Example symptom**: Profiler becomes unusably slow when targeting large applications, or symbol resolution takes longer than the actual profiling.\n\n⚠️ **Pitfall: Not Handling Stripped Binaries Gracefully**\n\nProduction binaries are often stripped of symbol tables to reduce size and prevent reverse engineering. Developers sometimes assume symbol tables will always be available and crash or return confusing errors when encountering stripped binaries.\n\n**Why it's wrong**: Stripped binaries have no `.symtab` section or have empty symbol tables. Code that assumes symbol availability will fail or return incorrect results. This makes the profiler unusable for many production environments.\n\n**How to fix**: Always check whether symbol sections exist before attempting to parse them. Provide fallback behavior for stripped binaries, such as showing module name and offset instead of function name. Consider supporting external debug symbol files.\n\n**Example symptom**: Profiler crashes with \"section not found\" errors, or shows no function names for any addresses in the target application.\n\n⚠️ **Pitfall: Inefficient String Handling in Symbol Names**\n\nSymbol names, especially mangled C++ names, can be quite long. Developers sometimes copy these strings repeatedly during symbol resolution, creating memory allocation pressure and garbage collection overhead in managed languages.\n\n**Why it's wrong**: String copying during hot path operations can become a significant performance bottleneck. Memory allocations in the symbol resolution path can trigger garbage collection at unpredictable times, causing profiling hiccups.\n\n**How to fix**: Use string interning or reference-based approaches to avoid copying symbol names. Cache demangled names to avoid repeated demangling operations. Consider using string views or slices that reference the original string table data.\n\n**Example symptom**: High memory allocation rates during profiling, garbage collection pauses in managed language implementations, or unexpectedly slow symbol resolution.\n\n⚠️ **Pitfall: Not Caching DWARF Parsing Results**\n\nDWARF debug information parsing is computationally expensive, involving state machine execution and complex data structure traversal. Developers sometimes parse DWARF information fresh for every address lookup, causing severe performance problems.\n\n**Why it's wrong**: DWARF parsing can take milliseconds per compilation unit. If the profiler repeatedly looks up addresses from the same compilation unit (which is common due to locality), this creates excessive CPU overhead.\n\n**How to fix**: Cache parsed line number tables and compilation unit information. Build indexes mapping address ranges to compilation units to avoid scanning through all units. Use lazy parsing to defer DWARF processing until actually needed.\n\n**Example symptom**: Profiler uses excessive CPU time for symbol resolution, profiling overhead becomes unacceptably high, or symbol resolution latency varies dramatically between addresses.\n\n⚠️ **Pitfall: Race Conditions in Multi-Threaded Symbol Resolution**\n\nWhen profiling multi-threaded applications, symbol resolution might be called concurrently from multiple threads. Developers sometimes share symbol caches and data structures without proper synchronization, leading to crashes or corrupted data.\n\n**Why it's wrong**: Symbol cache updates, module loading, and DWARF parsing involve complex data structure modifications that are not atomic. Concurrent access can lead to inconsistent state, use-after-free errors, or corrupt cache entries.\n\n**How to fix**: Use appropriate synchronization primitives (mutexes, read-write locks) to protect shared symbol resolution state. Consider using lock-free data structures for high-performance scenarios. Design the API to minimize contention between threads.\n\n**Example symptom**: Intermittent crashes during symbol resolution, corrupted function names in output, or deadlocks when multiple threads perform symbol lookups simultaneously.\n\n### Implementation Guidance\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|----------------|\n| ELF Parsing | pyelftools library (pure Python) | Custom parser with mmap for performance |\n| DWARF Processing | pyelftools DWARF reader | libdwarf bindings or custom parser |\n| Symbol Caching | Python dict with manual LRU | Redis or memcached for distributed caching |\n| Address Translation | Simple arithmetic with /proc/maps | libunwind for robust stack unwinding |\n| String Demangling | subprocess calls to c++filt | Direct bindings to libiberty or libc++abi |\n\n**Recommended File Structure:**\n\n```\nprofiler/\n  symbolizer/\n    __init__.py                 ← Public API exports\n    symbolizer.py              ← Main Symbolizer class and high-level API\n    elf_parser.py              ← ELF binary parsing and symbol extraction\n    dwarf_parser.py            ← DWARF debug information processing\n    symbol_cache.py            ← Symbol caching and performance optimization\n    module_loader.py           ← Module loading and ASLR handling\n    address_resolver.py        ← Core address-to-symbol resolution logic\n    demangler.py              ← C++ symbol demangling utilities\n    tests/\n      test_symbolizer.py       ← Integration tests for full symbolization\n      test_elf_parser.py       ← Unit tests for ELF parsing\n      test_dwarf_parser.py     ← Unit tests for DWARF processing\n      test_symbol_cache.py     ← Unit tests for caching behavior\n      fixtures/                ← Test binaries with known symbols\n        simple_cpp_program     ← Basic C++ program with debug info\n        stripped_binary        ← Production binary without symbols\n        inlined_functions      ← Binary with aggressive inlining\n```\n\n**Infrastructure Starter Code:**\n\n```python\n# symbolizer/elf_parser.py - Complete ELF parsing implementation\nimport mmap\nimport struct\nfrom typing import Dict, List, Optional, NamedTuple\nfrom pathlib import Path\n\nclass ELFSymbol(NamedTuple):\n    \"\"\"Represents a single symbol from ELF symbol table.\"\"\"\n    name: str\n    start_address: int\n    size: int\n    symbol_type: int\n    binding: int\n\nclass ELFParser:\n    \"\"\"Parses ELF binaries to extract symbol information.\"\"\"\n    \n    def __init__(self, binary_path: str):\n        self.binary_path = Path(binary_path)\n        self.symbols: Dict[int, ELFSymbol] = {}\n        self.is_64bit = True\n        self.byte_order = '<'  # Little endian\n        \n    def parse_symbols(self) -> Dict[int, ELFSymbol]:\n        \"\"\"Parse all symbols from the ELF binary.\"\"\"\n        try:\n            with open(self.binary_path, 'rb') as f:\n                with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n                    # Parse ELF header to determine format\n                    if not self._validate_elf_header(mm):\n                        return {}\n                    \n                    # Extract section headers\n                    sections = self._parse_section_headers(mm)\n                    \n                    # Find symbol table sections\n                    symtab = sections.get('.symtab')\n                    strtab = sections.get('.strtab')\n                    \n                    if symtab and strtab:\n                        return self._parse_symbol_table(mm, symtab, strtab)\n                    \n                    return {}\n        except (IOError, OSError, struct.error):\n            return {}\n    \n    def _validate_elf_header(self, mm: mmap.mmap) -> bool:\n        \"\"\"Validate ELF magic and extract basic format info.\"\"\"\n        if len(mm) < 64 or mm[:4] != b'\\x7fELF':\n            return False\n        \n        # Determine 32-bit vs 64-bit and endianness\n        self.is_64bit = mm[4] == 2\n        self.byte_order = '<' if mm[5] == 1 else '>'\n        return True\n    \n    def _parse_section_headers(self, mm: mmap.mmap) -> Dict[str, tuple]:\n        \"\"\"Parse section headers and return mapping of names to info.\"\"\"\n        # Implementation details for parsing ELF section headers\n        # Returns dict mapping section names to (offset, size, type) tuples\n        sections = {}\n        \n        # Parse ELF header to get section header table location\n        header_fmt = self.byte_order + ('Q' if self.is_64bit else 'L')\n        e_shoff_offset = 40 if self.is_64bit else 32\n        e_shentsize_offset = 58 if self.is_64bit else 46\n        e_shnum_offset = 60 if self.is_64bit else 48\n        e_shstrndx_offset = 62 if self.is_64bit else 50\n        \n        e_shoff = struct.unpack(header_fmt, mm[e_shoff_offset:e_shoff_offset+8])[0]\n        e_shentsize = struct.unpack(self.byte_order + 'H', \n                                   mm[e_shentsize_offset:e_shentsize_offset+2])[0]\n        e_shnum = struct.unpack(self.byte_order + 'H', \n                               mm[e_shnum_offset:e_shnum_offset+2])[0]\n        e_shstrndx = struct.unpack(self.byte_order + 'H', \n                                  mm[e_shstrndx_offset:e_shstrndx_offset+2])[0]\n        \n        # Parse section headers and build name mapping\n        for i in range(e_shnum):\n            header_offset = e_shoff + i * e_shentsize\n            if header_offset + e_shentsize > len(mm):\n                break\n                \n            # Parse section header fields we care about\n            sh_name_offset = struct.unpack(self.byte_order + 'L', \n                                         mm[header_offset:header_offset+4])[0]\n            sh_type = struct.unpack(self.byte_order + 'L', \n                                   mm[header_offset+4:header_offset+8])[0]\n            \n            if self.is_64bit:\n                sh_offset = struct.unpack(self.byte_order + 'Q', \n                                        mm[header_offset+24:header_offset+32])[0]\n                sh_size = struct.unpack(self.byte_order + 'Q', \n                                       mm[header_offset+32:header_offset+40])[0]\n            else:\n                sh_offset = struct.unpack(self.byte_order + 'L', \n                                        mm[header_offset+16:header_offset+20])[0]\n                sh_size = struct.unpack(self.byte_order + 'L', \n                                       mm[header_offset+20:header_offset+24])[0]\n            \n            # Get section name from string table\n            if i == e_shstrndx:\n                continue  # Skip string table header itself\n                \n            # We'll implement section name lookup in a full implementation\n            # For now, recognize sections by type\n            if sh_type == 2:  # SHT_SYMTAB\n                sections['.symtab'] = (sh_offset, sh_size, sh_type)\n            elif sh_type == 3:  # SHT_STRTAB\n                sections['.strtab'] = (sh_offset, sh_size, sh_type)\n        \n        return sections\n    \n    def _parse_symbol_table(self, mm: mmap.mmap, symtab_info: tuple, \n                           strtab_info: tuple) -> Dict[int, ELFSymbol]:\n        \"\"\"Parse symbol table entries and resolve names.\"\"\"\n        symbols = {}\n        symtab_offset, symtab_size, _ = symtab_info\n        strtab_offset, strtab_size, _ = strtab_info\n        \n        # Symbol table entry size depends on architecture\n        sym_size = 24 if self.is_64bit else 16\n        num_symbols = symtab_size // sym_size\n        \n        for i in range(num_symbols):\n            sym_offset = symtab_offset + i * sym_size\n            if sym_offset + sym_size > len(mm):\n                break\n            \n            # Parse symbol entry\n            if self.is_64bit:\n                st_name, st_info, st_other, st_shndx, st_value, st_size = \\\n                    struct.unpack(self.byte_order + 'LBBHQQ', \n                                 mm[sym_offset:sym_offset+24])\n            else:\n                st_name, st_value, st_size, st_info, st_other, st_shndx = \\\n                    struct.unpack(self.byte_order + 'LLLBBH', \n                                 mm[sym_offset:sym_offset+16])\n            \n            # Skip symbols with no size or invalid addresses\n            if st_size == 0 or st_value == 0:\n                continue\n            \n            # Extract symbol name from string table\n            if st_name < strtab_size:\n                name_start = strtab_offset + st_name\n                name_end = mm.find(b'\\x00', name_start)\n                if name_end != -1:\n                    symbol_name = mm[name_start:name_end].decode('utf-8', \n                                                               errors='replace')\n                    \n                    symbol = ELFSymbol(\n                        name=symbol_name,\n                        start_address=st_value,\n                        size=st_size,\n                        symbol_type=st_info & 0xf,\n                        binding=st_info >> 4\n                    )\n                    symbols[st_value] = symbol\n        \n        return symbols\n\n# symbolizer/symbol_cache.py - Complete caching implementation\nfrom typing import Dict, Optional, Set\nimport time\nfrom collections import OrderedDict\n\nclass SymbolCache:\n    \"\"\"High-performance cache for symbol resolution results.\"\"\"\n    \n    def __init__(self, max_cache_size: int = 1024 * 1024):  # 1MB default\n        self.address_to_symbol: OrderedDict[int, Optional[Symbol]] = OrderedDict()\n        self.module_cache: Dict[str, Module] = {}\n        self.demangled_names: Dict[str, str] = {}\n        self.miss_cache: Set[int] = set()\n        self.max_cache_size = max_cache_size\n        self.hit_count = 0\n        self.miss_count = 0\n        self.last_cleanup = time.time()\n    \n    def lookup_symbol(self, address: int) -> Optional[Symbol]:\n        \"\"\"Look up cached symbol or return None for miss.\"\"\"\n        # Check miss cache first (faster than symbol lookup)\n        if address in self.miss_cache:\n            self.miss_count += 1\n            return None\n        \n        # Check symbol cache\n        if address in self.address_to_symbol:\n            self.hit_count += 1\n            # Move to end for LRU\n            symbol = self.address_to_symbol.pop(address)\n            self.address_to_symbol[address] = symbol\n            return symbol\n        \n        self.miss_count += 1\n        return None\n    \n    def cache_symbol(self, address: int, symbol: Optional[Symbol]) -> None:\n        \"\"\"Cache symbol result or miss for future lookups.\"\"\"\n        if symbol is None:\n            self.miss_cache.add(address)\n            # Limit miss cache size to prevent memory bloat\n            if len(self.miss_cache) > 10000:\n                self.miss_cache = set(list(self.miss_cache)[-5000:])\n        else:\n            self.address_to_symbol[address] = symbol\n            self._cleanup_if_needed()\n    \n    def get_hit_rate(self) -> float:\n        \"\"\"Calculate symbol cache hit rate percentage.\"\"\"\n        total_requests = self.hit_count + self.miss_count\n        return (self.hit_count / total_requests * 100) if total_requests > 0 else 0.0\n    \n    def _cleanup_if_needed(self) -> None:\n        \"\"\"Remove old entries if cache is too large.\"\"\"\n        current_size = len(self.address_to_symbol) * 64  # Rough size estimate\n        if current_size > self.max_cache_size:\n            # Remove oldest 25% of entries\n            remove_count = len(self.address_to_symbol) // 4\n            for _ in range(remove_count):\n                self.address_to_symbol.popitem(last=False)\n```\n\n**Core Logic Skeleton:**\n\n```python\n# symbolizer/symbolizer.py - Main symbolization logic to implement\nclass Symbolizer:\n    \"\"\"Main symbol resolution engine for profiler.\"\"\"\n    \n    def __init__(self, config: SymbolConfig):\n        self.config = config\n        self.symbol_cache = SymbolCache()\n        self.modules: Dict[str, Module] = {}\n        self.process_maps: Dict[int, List[tuple]] = {}\n        \n    def symbolize_profile(self, profile: Profile) -> Profile:\n        \"\"\"Resolve addresses to function names for all samples in profile.\"\"\"\n        # TODO 1: Extract target process ID from profile metadata\n        # TODO 2: Load process memory maps using _load_process_maps()\n        # TODO 3: For each sample in profile.sample_batch.samples:\n        #         - Call symbolize_stack_frames() on sample.stack_frames\n        #         - Update sample with resolved symbol information\n        # TODO 4: Return profile with populated function names and source info\n        # Hint: Process all samples to batch module loading efficiently\n        pass\n    \n    def symbolize_stack_frames(self, stack_frames: List[StackFrame]) -> List[StackFrame]:\n        \"\"\"Resolve symbol information for a list of stack frames.\"\"\"\n        # TODO 1: For each frame in stack_frames:\n        #         - Check symbol_cache.lookup_symbol() first for performance\n        #         - If cache miss, call _resolve_address() to find symbol\n        #         - Update frame with function_name, filename, line_number\n        #         - Cache result using symbol_cache.cache_symbol()\n        # TODO 2: Handle special cases like kernel frames (is_kernel=True)\n        # TODO 3: Process inlined functions if DWARF info available\n        # TODO 4: Return updated stack_frames with symbol information\n        # Hint: Batch process frames from same module for efficiency\n        pass\n    \n    def _resolve_address(self, address: int, process_id: int) -> Optional[Symbol]:\n        \"\"\"Core address resolution logic - find symbol for given address.\"\"\"\n        # TODO 1: Find which module contains this address using _find_module()\n        # TODO 2: If no module found, return None (cache as miss)\n        # TODO 3: Calculate file-relative address by subtracting module base\n        # TODO 4: Search module symbols using binary search on sorted addresses\n        # TODO 5: If symbol found, enhance with DWARF info if available\n        # TODO 6: Apply C++ demangling if enabled in config\n        # Hint: Use Module.find_symbol() method for efficient lookup\n        pass\n    \n    def _load_process_maps(self, process_id: int) -> None:\n        \"\"\"Parse /proc/[pid]/maps to get module load addresses.\"\"\"\n        # TODO 1: Read /proc/{process_id}/maps file\n        # TODO 2: Parse each line to extract: start_addr, end_addr, perms, path\n        # TODO 3: Filter for executable regions (perms contains 'x')\n        # TODO 4: For each executable mapping:\n        #         - Create Module object if not already loaded\n        #         - Parse ELF symbols using ELFParser if first time\n        #         - Calculate load bias (runtime_addr - elf_virtual_addr)\n        #         - Store in self.modules and self.process_maps\n        # TODO 5: Handle shared libraries and ASLR properly\n        # Hint: Cache parsed modules across different processes\n        pass\n    \n    def _find_module(self, address: int, process_id: int) -> Optional[Module]:\n        \"\"\"Find which module contains the given runtime address.\"\"\"\n        # TODO 1: Get process memory maps for process_id\n        # TODO 2: Binary search through sorted address ranges\n        # TODO 3: Check if address falls within any module's range\n        # TODO 4: Return Module object or None if not found\n        # Hint: Consider caching recent lookups for hot addresses\n        pass\n    \n    def _enhance_with_dwarf(self, symbol: Symbol, module: Module) -> Symbol:\n        \"\"\"Add source file and line number info using DWARF debug data.\"\"\"\n        # TODO 1: Check if module.has_debug_info is True\n        # TODO 2: Load DWARF parser for this module (lazy loading)\n        # TODO 3: Execute line number program to get address->line mapping\n        # TODO 4: Find line number entry containing symbol address\n        # TODO 5: Update symbol with source_file and line_ranges\n        # TODO 6: Handle inlined functions and create InlinedFrame entries\n        # Hint: Cache parsed line number tables for performance\n        pass\n```\n\n**Milestone Checkpoint:**\n\nAfter implementing symbol resolution, verify correct behavior:\n\n**Expected Command**: `python -m profiler.symbolizer.tests.test_symbolizer`\n\n**Expected Output**:\n```\nSymbol Resolution Tests\n✓ ELF parsing extracts correct symbol count\n✓ Address resolution maps to correct function names  \n✓ DWARF processing provides source line numbers\n✓ Symbol caching improves lookup performance\n✓ C++ demangling produces readable names\n✓ ASLR handling works with randomized addresses\nCache hit rate: 85.2% (target: >80%)\n```\n\n**Manual Verification Steps**:\n1. Create a simple C++ program with debug info: `g++ -g -o test_program test.cpp`\n2. Run symbolizer on known addresses: `addr2line -e test_program <address>` \n3. Compare symbolizer output with addr2line results\n4. Verify that stripped binaries fail gracefully without crashes\n\n**Signs of Problems**:\n- Function names are all \"unknown\" or missing despite having symbols\n- Source line numbers are incorrect or missing  \n- Performance is slower than 1000 lookups per second\n- Cache hit rate is below 70% after warmup period\n- Crashes when processing stripped binaries or invalid addresses\n\n\n## Flame Graph Generation Component\n\n> **Milestone(s):** Milestone 3 — Flame Graph Generation: Aggregate captured stack samples and create interactive SVG flame graph visualizations that enable developers to understand program hotspots and call relationships through hierarchical visualization\n\n### Mental Model: Family Tree Visualization\n\nThink of flame graph generation like creating a family tree from scattered birth certificates. You have thousands of individual samples, each representing a captured call stack at a specific moment in time. Each sample is like a birth certificate that says \"function A called function B called function C.\" Your job is to gather all these individual records and build a comprehensive family tree that shows which functions are related to each other and how frequently those relationships occur.\n\nJust as a family tree shows ancestral relationships with the oldest generation at the bottom and newer generations stacked above, a flame graph displays call relationships with the program entry point at the bottom and deeper function calls stacked vertically. The width of each \"family branch\" represents how many descendants (samples) belong to that lineage, making it immediately obvious which code paths are most heavily trafficked.\n\nThe key insight is that flame graphs transform temporal data (samples collected over time) into spatial data (visual hierarchies). Instead of reading through thousands of individual stack traces, developers can see the \"big picture\" of their program's execution patterns at a glance. Hot code paths appear as wide horizontal bands, while infrequently called functions appear as thin slivers or disappear entirely if they fall below the visualization threshold.\n\n### Stack Folding and Aggregation\n\nStack folding represents the core algorithmic challenge of flame graph generation: converting thousands or millions of individual stack samples into a hierarchical tree structure that accurately represents call frequencies and relationships. This process involves three fundamental operations: stack signature generation, hierarchical aggregation, and weight calculation.\n\n**Stack signature generation** creates unique identifiers for each distinct call stack pattern. The aggregator processes each `Sample` by concatenating the `function_name` fields from its `stack_frames` list, creating a stack signature string. For example, a stack containing frames [\"main\", \"process_request\", \"parse_json\", \"malloc\"] becomes the signature \"main;process_request;parse_json;malloc\". This semicolon-delimited format, known as folded stack format, enables efficient grouping of identical call patterns.\n\nThe signature generation algorithm handles several critical edge cases. Inlined functions from `InlinedFrame` structures must be properly expanded into the signature to maintain call hierarchy accuracy. Kernel frames marked with `is_kernel=True` receive special prefixes to distinguish them from user-space functions. Address-only frames that failed symbol resolution get represented as hex addresses to prevent information loss.\n\n**Hierarchical aggregation** builds the flame graph tree structure by processing stack signatures in a specific order. The aggregator maintains a tree where each node represents a unique function call context. Unlike traditional call trees that group by function name alone, flame graph nodes represent the full calling context — the same function called from different code paths becomes separate nodes in the tree.\n\nThe aggregation algorithm processes each stack signature from bottom to top, creating or updating tree nodes along the path. For the signature \"main;process_request;parse_json;malloc\", the algorithm first finds or creates a root node for \"main\", then finds or creates a child node \"process_request\" under \"main\", and so forth. Each node maintains a sample count that gets incremented when matching signatures are encountered.\n\n> **Critical Design Insight:** The stack folding algorithm must preserve calling context, not just function identity. A function called from two different code paths must appear as separate nodes in the flame graph tree to accurately represent the program's execution patterns.\n\n**Weight calculation** determines the visual width of each flame graph rectangle based on the aggregated sample counts. The algorithm calculates weights recursively, where each node's weight equals the sum of its direct sample count plus the weights of all its children. This ensures that parent nodes accurately represent the cumulative time spent in their entire call subtree.\n\nThe weight calculation must handle sample weights correctly when individual samples have different durations or importance. The `sample_weight` field in each `Sample` allows for weighted aggregation where some samples count more heavily than others. This becomes crucial when dealing with adaptive sampling rates or when merging profiles with different sampling frequencies.\n\n| Aggregation Operation | Input | Output | Purpose |\n|----------------------|-------|---------|---------|\n| Signature Generation | List[StackFrame] | str | Create unique identifier for call stack pattern |\n| Tree Building | List[str] | FlameNode | Build hierarchical tree from folded signatures |\n| Weight Calculation | FlameNode | int | Calculate cumulative sample counts for visualization |\n| Width Normalization | FlameNode, total_samples | float | Convert sample counts to pixel widths |\n| Color Assignment | FlameNode | str | Assign colors based on function category or module |\n\nThe folded stack format output becomes a critical interface point for the flame graph generation system. This format, popularized by Brendan Gregg's flame graph tools, enables interoperability with existing visualization tools and provides a human-readable intermediate representation for debugging aggregation logic.\n\n> **Decision: Folded Stack Format**\n> - **Context**: Need standardized intermediate format between aggregation and visualization\n> - **Options Considered**: Custom binary format, JSON tree structure, folded stack text format\n> - **Decision**: Adopt folded stack text format with sample counts\n> - **Rationale**: Industry standard format enables tool interoperability, human-readable for debugging, compact representation, widely supported by existing flame graph tools\n> - **Consequences**: Enables integration with external tools but requires parsing step for custom visualizations\n\n### Interactive SVG Generation\n\nInteractive SVG generation transforms the aggregated flame graph tree into a scalable vector graphics document that supports user interaction through embedded JavaScript. This process involves coordinate calculation, SVG element generation, and interactive feature implementation.\n\n**Coordinate calculation** maps the logical flame graph tree structure onto a two-dimensional pixel coordinate system. The algorithm performs a recursive tree traversal, calculating the x-coordinate and width for each node based on its cumulative sample weight, and the y-coordinate based on its depth in the call hierarchy.\n\nThe coordinate system uses a bottom-up layout where the root node (typically main) appears at the bottom of the visualization and deeper call stack levels appear higher on the y-axis. Each stack level has a fixed height defined by `min_width_pixels` in the `VisualizationConfig`, typically 16-20 pixels to accommodate readable function names.\n\nWidth calculation requires careful normalization to ensure the entire flame graph fits within the target SVG viewport. The algorithm calculates each node's width as: `node_width = (node_weight / total_samples) * viewport_width`. Nodes with widths below `min_width_pixels` get filtered out to prevent visual clutter and improve rendering performance.\n\n| Coordinate Calculation | Formula | Purpose |\n|------------------------|---------|---------|\n| Node Width | (node_weight / total_samples) * viewport_width | Proportional width based on sample frequency |\n| Node X Position | parent_x + cumulative_child_widths | Horizontal positioning within parent |\n| Node Y Position | stack_depth * rectangle_height | Vertical positioning by call depth |\n| Text X Position | node_x + (node_width / 2) | Center text within rectangle |\n| Text Y Position | node_y + (rectangle_height / 2) + (font_size / 3) | Vertically center text with baseline adjustment |\n\n**SVG element generation** creates the actual XML structure for the flame graph visualization. Each flame graph node becomes an SVG `<rect>` element with calculated coordinates and a `<text>` element for the function name. The generator groups related elements using `<g>` tags to enable hierarchical styling and interaction handling.\n\nThe SVG generation algorithm implements several optimization techniques to manage large flame graphs with thousands of nodes. Text elements include `textLength` attributes to prevent overflow beyond rectangle boundaries. Long function names get truncated with ellipsis indicators while preserving tooltips that show full names. Rectangle elements receive data attributes containing metadata like sample counts and percentages for interactive features.\n\nColor assignment uses configurable schemes defined in `VisualizationConfig.color_scheme` to distinguish different categories of code. Common schemes include module-based coloring (different colors for user code, system libraries, kernel functions) and hash-based coloring (consistent colors for the same function across different contexts).\n\n**Interactive feature implementation** embeds JavaScript directly into the SVG document to enable zoom, search, and tooltip functionality without requiring external dependencies. The interaction system responds to mouse events on flame graph rectangles and provides several user interface capabilities.\n\nZoom functionality allows users to focus on specific portions of large flame graphs by clicking on any rectangle to make it the new root of the visualization. The zoom implementation recalculates coordinates and scales all elements to fit the viewport, effectively creating a \"drill-down\" interaction that helps users explore deep call stacks.\n\nSearch functionality highlights all rectangles containing user-specified function names or patterns. The search implementation uses JavaScript regular expressions to match against the text content of each flame graph node, applying highlighting styles to matching elements and providing navigation between search results.\n\n| Interactive Feature | Trigger | Behavior | Implementation |\n|---------------------|---------|----------|----------------|\n| Rectangle Hover | Mouse enter/leave | Show tooltip with function details | JavaScript event listeners + CSS transitions |\n| Rectangle Click | Mouse click | Zoom to clicked function as new root | Coordinate recalculation + SVG transformation |\n| Search Box | Text input | Highlight matching function names | RegExp matching + CSS class application |\n| Reset Zoom | Button click | Return to full flame graph view | Restore original coordinate system |\n| Export Data | Button click | Download folded stack format | Generate text file from current view |\n\n> **Decision: Embedded JavaScript vs External Framework**\n> - **Context**: Need interactive features in flame graph visualization\n> - **Options Considered**: React/Vue.js web application, D3.js visualization framework, embedded SVG JavaScript\n> - **Decision**: Embed JavaScript directly in SVG documents\n> - **Rationale**: Self-contained files require no external dependencies, faster loading for large graphs, simpler deployment and sharing, reduced complexity for basic interactions\n> - **Consequences**: Limited to basic interactions but enables standalone flame graph files that work anywhere\n\n### Architecture Decision Records\n\nThe flame graph generation component involves several critical architectural decisions that significantly impact performance, usability, and maintainability. These decisions establish the foundation for how aggregated stack data transforms into interactive visualizations.\n\n> **Decision: SVG vs Canvas vs HTML for Visualization**\n> - **Context**: Need to render potentially thousands of rectangles with text labels in web browsers efficiently\n> - **Options Considered**: SVG with embedded interactivity, HTML5 Canvas with JavaScript, HTML div elements with CSS positioning\n> - **Decision**: SVG with embedded JavaScript for interactivity\n> - **Rationale**: SVG provides vector scaling without pixelation, built-in text rendering with proper font metrics, CSS styling capabilities, accessibility features for screen readers, and ability to embed JavaScript for interactions while remaining printable\n> - **Consequences**: Better print quality and accessibility than Canvas, simpler than HTML positioning, but potentially slower rendering for extremely large graphs (>10k rectangles)\n\n| Visualization Technology | Pros | Cons | Chosen? |\n|-------------------------|------|------|---------|\n| SVG + JavaScript | Vector scaling, accessibility, printable, embedded interactivity | Memory usage for large graphs, complex coordinate calculations | ✅ Yes |\n| HTML5 Canvas | High performance rendering, pixel-perfect control | Poor text rendering, no accessibility, requires complex hit detection | ❌ No |\n| HTML + CSS | Simple layout, good performance | Poor print quality, complex positioning math, limited text overflow handling | ❌ No |\n\n> **Decision: Bottom-Up vs Top-Down Flame Graph Orientation**\n> - **Context**: Stack samples represent call chains from program entry point to deepest function call\n> - **Options Considered**: Bottom-up layout (main at bottom), top-down layout (main at top), sidewise layout (main at left)\n> - **Decision**: Bottom-up layout with main function at bottom of visualization\n> - **Rationale**: Matches traditional flame graph conventions established by Brendan Gregg, intuitive \"flames rise upward\" mental model, consistent with stack unwinding direction, enables easy visual identification of leaf functions\n> - **Consequences**: Follows industry standards enabling tool compatibility but may feel inverted to developers used to call tree visualizations\n\n> **Decision: Fixed vs Dynamic Rectangle Heights**\n> - **Context**: Need to balance readability with information density in flame graph visualization\n> - **Options Considered**: Fixed height for all rectangles, dynamic height based on sample count, adaptive height based on function name length\n> - **Decision**: Fixed rectangle height with configurable pixel size\n> - **Rationale**: Consistent visual rhythm makes patterns easier to identify, simplifies coordinate calculations, ensures text readability at all zoom levels, prevents visual bias toward high-sample functions\n> - **Consequences**: Efficient rendering and clear readability but some visual information loss compared to area-proportional representations\n\n| Rectangle Sizing Approach | Pros | Cons | Chosen? |\n|---------------------------|------|------|---------|\n| Fixed Height | Consistent visual rhythm, simple math, good text readability | Less information density than proportional sizing | ✅ Yes |\n| Dynamic Height | More information in same space, visually emphasizes hot functions | Complex calculations, text sizing issues, visual bias | ❌ No |\n| Adaptive Height | Optimizes for text content, handles long names better | Inconsistent appearance, complex layout algorithm | ❌ No |\n\n> **Decision: Client-Side vs Server-Side Interactivity**\n> - **Context**: Users need zoom, search, and tooltip functionality in flame graphs\n> - **Options Considered**: Server-side rendering with form submissions, client-side JavaScript with DOM manipulation, hybrid approach with progressive enhancement\n> - **Decision**: Pure client-side JavaScript embedded in SVG documents\n> - **Rationale**: Eliminates server round-trips for interactions, enables offline usage of saved flame graphs, reduces server load, provides instant responsiveness for zoom and search operations\n> - **Consequences**: Self-contained flame graph files but requires JavaScript-enabled browsers and increases initial file size\n\n### Common Pitfalls\n\nFlame graph generation involves several algorithmic and implementation challenges that commonly trip up developers building profiler visualizations. Understanding these pitfalls helps avoid subtle bugs that can produce misleading or incorrect flame graphs.\n\n⚠️ **Pitfall: Incorrect Width Calculations Leading to Visual Gaps**\n\nDevelopers frequently make floating-point precision errors when calculating rectangle widths, leading to visual gaps or overlaps in the flame graph. This occurs when the sum of child node widths doesn't exactly equal the parent node width due to rounding errors in the width calculation formula.\n\nThe problem manifests when converting from sample counts (integers) to pixel coordinates (floats). A parent node with 1000 samples and three children with 333, 333, and 334 samples respectively may have child widths that don't sum to exactly the parent width after pixel conversion. This creates visible gaps that users interpret as missing data or profiler bugs.\n\n**Fix:** Implement width correction algorithms that distribute rounding errors across child nodes. Calculate all child widths first, then adjust the rightmost child's width to ensure the sum exactly matches the parent width: `children[-1].width += parent.width - sum(child.width for child in children)`.\n\n⚠️ **Pitfall: Stack Signature Hash Collisions Corrupting Aggregation**\n\nWhen using hash-based aggregation for performance optimization, developers sometimes use weak hash functions that produce collisions for different call stacks. This causes the aggregator to merge samples from completely different code paths, creating flame graphs that show incorrect call relationships.\n\nHash collisions typically occur when using simple string hash functions on folded stack signatures, especially for programs with many similar function names or deep call stacks. The collision rate increases dramatically with large sample counts, leading to subtle aggregation errors that are difficult to detect through casual inspection.\n\n**Fix:** Use cryptographic hash functions like SHA-256 for stack signature generation, or avoid hashing entirely by using the full folded stack string as the aggregation key. For performance-critical applications, implement collision detection by storing both the hash and the original stack signature, falling back to string comparison when hash collisions occur.\n\n⚠️ **Pitfall: Memory Explosion from Inefficient Tree Storage**\n\nNaive tree implementations can consume excessive memory when storing large numbers of flame graph nodes, especially for programs with deep call stacks or many distinct code paths. This occurs when each tree node stores redundant information or uses inefficient pointer structures.\n\nThe problem becomes severe with large-scale profiling where millions of samples create hundreds of thousands of distinct flame graph nodes. Storing full function names, file paths, and metadata in every node can consume gigabytes of memory and cause profiler crashes or system resource exhaustion.\n\n**Fix:** Implement string interning for function names and file paths to eliminate duplicate storage. Use compact node representations with integer IDs referencing shared string tables. Consider tree compression techniques that merge nodes with single children to reduce depth and memory usage.\n\n⚠️ **Pitfall: Text Rendering Performance Degradation with Large Graphs**\n\nSVG text rendering becomes a significant performance bottleneck when flame graphs contain thousands of text elements, leading to slow browser rendering and poor user interaction responsiveness. This problem compounds when using complex fonts or when the browser must calculate text metrics for layout.\n\nThe performance issue becomes noticeable with flame graphs containing more than 5,000-10,000 visible rectangles. Browsers struggle to render all the text elements smoothly, causing laggy zoom operations and poor scrolling performance that makes the flame graph difficult to use.\n\n**Fix:** Implement level-of-detail rendering that only shows text for rectangles above a minimum width threshold. Use `visibility: hidden` for text in small rectangles rather than removing elements entirely. Consider lazy text rendering that only creates text elements for currently visible portions of large flame graphs.\n\n⚠️ **Pitfall: Color Scheme Accessibility Issues**\n\nDevelopers often choose color schemes that look appealing on their development monitors but create accessibility problems for users with color vision deficiencies or different display settings. Red-green color schemes are particularly problematic, as they become indistinguishable for users with deuteranopia or protanopia.\n\nThe accessibility issue extends beyond color blindness to include low-contrast combinations that become unreadable on different monitors or in bright lighting conditions. Poor color choices can make flame graphs effectively unusable for significant portions of the user base.\n\n**Fix:** Use colorbrewer-style palettes designed for accessibility and data visualization. Implement multiple color scheme options including high-contrast modes. Provide alternative visual encoding through patterns or textures in addition to color. Test color schemes with accessibility simulation tools and actual users with color vision deficiencies.\n\n| Common Color Scheme Issues | Problem | Solution |\n|----------------------------|---------|----------|\n| Red-Green Combinations | Invisible to ~8% of male users | Use blue-orange or purple-green alternatives |\n| Low Contrast | Unreadable in bright lighting | Ensure 3:1 minimum contrast ratio |\n| Too Many Colors | Cognitive overload, no meaning | Limit to 8-12 distinct colors with clear categories |\n| Inconsistent Mapping | Same function different colors | Use deterministic color assignment algorithm |\n\n⚠️ **Pitfall: Interactive Feature State Corruption**\n\nJavaScript state management in interactive flame graphs can become corrupted when users perform rapid interactions like multiple zoom operations or overlapping search queries. This leads to flame graphs stuck in incorrect zoom states or search highlights that don't clear properly.\n\nState corruption typically occurs when asynchronous operations overlap or when event handlers don't properly clean up previous state before applying new changes. Users may find themselves unable to reset the flame graph to its original state or encountering JavaScript errors that break interactivity.\n\n**Fix:** Implement proper state management with explicit state transitions and cleanup procedures. Use debouncing for rapid user interactions. Provide explicit reset functionality that restores the flame graph to a known good state. Add error boundaries that gracefully handle JavaScript exceptions without breaking the entire visualization.\n\n### Implementation Guidance\n\nThe flame graph generation component bridges the gap between aggregated profiling data and interactive visualizations that developers can use to understand program behavior. This section provides concrete implementation strategies and starter code for building robust flame graph generation.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| SVG Generation | String concatenation with templates | XML library with proper escaping (xml.etree.ElementTree) |\n| Tree Aggregation | Dictionary-based grouping | Trie data structure with path compression |\n| Coordinate Math | Direct calculation with floating point | Fixed-point arithmetic for precision |\n| Color Schemes | Hardcoded RGB values | Colorbrewer palettes with accessibility support |\n| JavaScript Embedding | Template strings with substitution | Separate .js files with build-time inlining |\n| Output Format | Single SVG file | Multi-file bundle with CSS and JS separation |\n\n#### Recommended File Structure\n\nThe flame graph generation component should be organized to separate aggregation logic, coordinate calculation, SVG generation, and interactive features:\n\n```\nprofiler/\n  flame_graph/\n    __init__.py                 ← public API exports\n    aggregator.py               ← stack folding and tree building logic\n    coordinates.py              ← pixel coordinate calculation\n    svg_generator.py            ← SVG element creation and formatting\n    interactive.py              ← JavaScript code for zoom/search features\n    color_schemes.py            ← predefined color palettes and assignment\n    templates/                  ← SVG and JavaScript template files\n      flame_graph_template.svg\n      interactive_features.js\n      default_styles.css\n    test/\n      test_aggregation.py       ← unit tests for tree building\n      test_coordinates.py       ← coordinate calculation tests\n      test_svg_generation.py    ← SVG output validation\n      sample_profiles.py        ← test data for integration tests\n```\n\n#### Infrastructure Starter Code\n\n**Stack Aggregation Foundation** (`aggregator.py`):\n\n```python\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\nfrom collections import defaultdict\n\n@dataclass\nclass FlameNode:\n    \"\"\"Represents a single node in the flame graph tree.\"\"\"\n    function_name: str\n    sample_count: int\n    self_count: int\n    total_count: int\n    children: Dict[str, 'FlameNode']\n    parent: Optional['FlameNode']\n    depth: int\n    module_name: str\n    \n    def __post_init__(self):\n        if self.children is None:\n            self.children = {}\n    \n    def add_child(self, name: str, module: str = \"\") -> 'FlameNode':\n        \"\"\"Add or get child node with given function name.\"\"\"\n        if name not in self.children:\n            self.children[name] = FlameNode(\n                function_name=name,\n                sample_count=0,\n                self_count=0,\n                total_count=0,\n                children={},\n                parent=self,\n                depth=self.depth + 1,\n                module_name=module\n            )\n        return self.children[name]\n    \n    def calculate_totals(self) -> int:\n        \"\"\"Recursively calculate total sample counts including children.\"\"\"\n        self.total_count = self.self_count\n        for child in self.children.values():\n            self.total_count += child.calculate_totals()\n        return self.total_count\n\nclass StackAggregator:\n    \"\"\"Converts individual stack samples into aggregated flame graph tree.\"\"\"\n    \n    def __init__(self):\n        self.root = FlameNode(\n            function_name=\"<root>\",\n            sample_count=0,\n            self_count=0,\n            total_count=0,\n            children={},\n            parent=None,\n            depth=0,\n            module_name=\"\"\n        )\n        self.folded_stacks: Dict[str, int] = defaultdict(int)\n    \n    def add_sample(self, sample: 'Sample') -> None:\n        \"\"\"Process a single sample and add it to the aggregated tree.\"\"\"\n        # Convert stack frames to folded stack signature\n        signature = self._create_stack_signature(sample.stack_frames)\n        self.folded_stacks[signature] += sample.sample_weight\n        \n        # Build tree path for this stack\n        current_node = self.root\n        for frame in reversed(sample.stack_frames):  # Bottom-up traversal\n            child_node = current_node.add_child(\n                frame.function_name, \n                frame.module_name\n            )\n            child_node.sample_count += sample.sample_weight\n            current_node = child_node\n        \n        # Increment self count for leaf node\n        current_node.self_count += sample.sample_weight\n    \n    def _create_stack_signature(self, frames: List['StackFrame']) -> str:\n        \"\"\"Create folded stack signature from stack frames.\"\"\"\n        # TODO: Handle inlined frames by expanding them into signature\n        # TODO: Add special prefixes for kernel frames\n        # TODO: Use hex addresses for unresolved symbols\n        pass\n    \n    def get_folded_output(self) -> str:\n        \"\"\"Export aggregated data in folded stack format.\"\"\"\n        lines = []\n        for signature, count in self.folded_stacks.items():\n            lines.append(f\"{signature} {count}\")\n        return \"\\n\".join(lines)\n    \n    def finalize(self) -> FlameNode:\n        \"\"\"Complete aggregation and return root node with calculated totals.\"\"\"\n        self.root.calculate_totals()\n        return self.root\n```\n\n**Color Scheme Management** (`color_schemes.py`):\n\n```python\nimport hashlib\nfrom typing import Dict, List, Tuple\nfrom enum import Enum\n\nclass ColorScheme(Enum):\n    \"\"\"Available color schemes for flame graph visualization.\"\"\"\n    CATEGORY = \"category\"      # Color by function category (user/system/kernel)\n    MODULE = \"module\"          # Color by module/library\n    HASH = \"hash\"             # Deterministic hash-based coloring\n    HEAT = \"heat\"             # Hot/cold based on sample frequency\n\nclass ColorAssigner:\n    \"\"\"Assigns colors to flame graph nodes based on configured scheme.\"\"\"\n    \n    # Colorbrewer-inspired palettes optimized for accessibility\n    CATEGORY_COLORS = {\n        \"user\": \"#1f77b4\",      # Blue for user code\n        \"system\": \"#ff7f0e\",    # Orange for system libraries  \n        \"kernel\": \"#2ca02c\",    # Green for kernel functions\n        \"jit\": \"#d62728\",       # Red for JIT compiled code\n        \"unknown\": \"#9467bd\"    # Purple for unresolved symbols\n    }\n    \n    MODULE_PALETTE = [\n        \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\",\n        \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"\n    ]\n    \n    def __init__(self, scheme: ColorScheme = ColorScheme.CATEGORY):\n        self.scheme = scheme\n        self.module_colors: Dict[str, str] = {}\n        self.color_index = 0\n    \n    def get_color(self, node: FlameNode) -> str:\n        \"\"\"Get color for flame graph node based on current scheme.\"\"\"\n        if self.scheme == ColorScheme.CATEGORY:\n            return self._get_category_color(node)\n        elif self.scheme == ColorScheme.MODULE:\n            return self._get_module_color(node.module_name)\n        elif self.scheme == ColorScheme.HASH:\n            return self._get_hash_color(node.function_name)\n        else:\n            return \"#1f77b4\"  # Default blue\n    \n    def _get_category_color(self, node: FlameNode) -> str:\n        \"\"\"Determine color based on function category.\"\"\"\n        # TODO: Implement category detection logic\n        # TODO: Check for kernel function patterns\n        # TODO: Identify system library vs user code\n        pass\n    \n    def _get_module_color(self, module_name: str) -> str:\n        \"\"\"Assign consistent color per module.\"\"\"\n        if module_name not in self.module_colors:\n            color = self.MODULE_PALETTE[self.color_index % len(self.MODULE_PALETTE)]\n            self.module_colors[module_name] = color\n            self.color_index += 1\n        return self.module_colors[module_name]\n    \n    def _get_hash_color(self, function_name: str) -> str:\n        \"\"\"Generate deterministic color from function name hash.\"\"\"\n        hash_value = int(hashlib.md5(function_name.encode()).hexdigest()[:6], 16)\n        hue = hash_value % 360\n        return self._hsl_to_hex(hue, 70, 50)  # Fixed saturation and lightness\n    \n    def _hsl_to_hex(self, h: int, s: int, l: int) -> str:\n        \"\"\"Convert HSL color values to hex string.\"\"\"\n        # TODO: Implement HSL to RGB conversion\n        # TODO: Format as hex color string\n        pass\n```\n\n#### Core Logic Skeleton Code\n\n**Coordinate Calculation Engine** (`coordinates.py`):\n\n```python\nfrom typing import List, Tuple\nfrom dataclasses import dataclass\n\n@dataclass\nclass Rectangle:\n    \"\"\"Represents a flame graph rectangle with pixel coordinates.\"\"\"\n    x: float\n    y: float\n    width: float\n    height: float\n    node: FlameNode\n    color: str\n    text_x: float\n    text_y: float\n    \nclass CoordinateCalculator:\n    \"\"\"Calculates pixel coordinates for flame graph rectangles.\"\"\"\n    \n    def __init__(self, viewport_width: int, viewport_height: int, \n                 rectangle_height: int = 18, min_width: float = 0.5):\n        self.viewport_width = viewport_width\n        self.viewport_height = viewport_height\n        self.rectangle_height = rectangle_height\n        self.min_width = min_width\n    \n    def calculate_coordinates(self, root: FlameNode) -> List[Rectangle]:\n        \"\"\"Calculate pixel coordinates for all flame graph rectangles.\"\"\"\n        rectangles = []\n        \n        # TODO 1: Validate root node has calculated totals\n        # TODO 2: Calculate scaling factor from samples to pixels\n        # TODO 3: Perform recursive traversal starting from root\n        # TODO 4: For each node, calculate x position within parent\n        # TODO 5: Calculate width based on sample proportion\n        # TODO 6: Skip nodes below minimum width threshold\n        # TODO 7: Calculate text positioning within rectangle\n        # TODO 8: Add rectangle to output list\n        # Hint: Use depth-first traversal to maintain proper ordering\n        \n        return rectangles\n    \n    def _calculate_node_coordinates(self, node: FlameNode, parent_x: float, \n                                  parent_width: float, depth: int, \n                                  total_samples: int) -> Rectangle:\n        \"\"\"Calculate coordinates for a single node.\"\"\"\n        # TODO 1: Calculate proportional width based on sample count\n        # TODO 2: Determine x position within parent bounds\n        # TODO 3: Calculate y position from depth and rectangle height\n        # TODO 4: Handle text positioning and truncation\n        # TODO 5: Return Rectangle with calculated coordinates\n        pass\n    \n    def _calculate_children_layout(self, node: FlameNode, node_x: float,\n                                 node_width: float, total_samples: int) -> List[Tuple[FlameNode, float, float]]:\n        \"\"\"Calculate layout positions for all children of a node.\"\"\"\n        # TODO 1: Sort children by sample count (largest first)\n        # TODO 2: Calculate cumulative x positions for children\n        # TODO 3: Distribute any rounding error to rightmost child\n        # TODO 4: Return list of (child_node, x_position, width) tuples\n        pass\n```\n\n**SVG Generation Framework** (`svg_generator.py`):\n\n```python\nfrom typing import List, TextIO\nimport xml.etree.ElementTree as ET\n\nclass SVGFlameGraphGenerator:\n    \"\"\"Generates interactive SVG flame graph from rectangle coordinates.\"\"\"\n    \n    def __init__(self, config: VisualizationConfig):\n        self.config = config\n        self.svg_width = 1200\n        self.svg_height = 800\n    \n    def generate_svg(self, rectangles: List[Rectangle], output_path: str) -> None:\n        \"\"\"Generate complete SVG flame graph file.\"\"\"\n        # TODO 1: Create root SVG element with viewBox and dimensions\n        # TODO 2: Add CSS styles for rectangles, text, and interactions\n        # TODO 3: Generate rectangle and text elements for each flame node\n        # TODO 4: Embed JavaScript code for zoom and search functionality\n        # TODO 5: Add search UI elements (search box, reset button)\n        # TODO 6: Write complete SVG document to file\n        # Hint: Use xml.etree.ElementTree for proper XML generation\n        pass\n    \n    def _create_rectangle_group(self, rect: Rectangle) -> ET.Element:\n        \"\"\"Create SVG group containing rectangle and text elements.\"\"\"\n        # TODO 1: Create <g> group element with data attributes\n        # TODO 2: Add <rect> element with coordinates and styling\n        # TODO 3: Add <text> element with function name and positioning\n        # TODO 4: Include tooltip title element for hover information\n        # TODO 5: Return completed group element\n        pass\n    \n    def _embed_interactive_features(self, root_svg: ET.Element) -> None:\n        \"\"\"Add JavaScript code for zoom, search, and tooltip functionality.\"\"\"\n        # TODO 1: Create <script> element with JavaScript code\n        # TODO 2: Add event listeners for rectangle clicks (zoom)\n        # TODO 3: Implement search highlighting functionality\n        # TODO 4: Add tooltip positioning and content logic\n        # TODO 5: Include reset zoom functionality\n        pass\n    \n    def _generate_css_styles(self) -> str:\n        \"\"\"Generate CSS styles for flame graph elements.\"\"\"\n        return \"\"\"\n        <style>\n        .flame-rect {\n            stroke: #000;\n            stroke-width: 0.5px;\n            cursor: pointer;\n        }\n        .flame-text {\n            font-family: Verdana, sans-serif;\n            font-size: 12px;\n            text-anchor: middle;\n            dominant-baseline: central;\n            pointer-events: none;\n        }\n        .flame-rect:hover {\n            stroke: #00f;\n            stroke-width: 1px;\n        }\n        .search-highlight {\n            stroke: #ff0;\n            stroke-width: 2px;\n        }\n        </style>\n        \"\"\"\n```\n\n#### Milestone Checkpoint\n\nAfter implementing the flame graph generation component, verify correct functionality with these checkpoints:\n\n**Aggregation Verification:**\n```bash\npython -m pytest profiler/flame_graph/test/test_aggregation.py -v\n```\nExpected behavior: All aggregation tests pass, including edge cases like empty stacks, single-frame stacks, and deeply nested call chains. The folded stack output should match expected format with correct sample counts.\n\n**Coordinate Calculation Test:**\n```bash\npython -c \"\nfrom profiler.flame_graph.coordinates import CoordinateCalculator\nfrom profiler.flame_graph.aggregator import FlameNode\n# Create simple test tree and verify coordinate calculation\ncalc = CoordinateCalculator(1000, 600)\n# Should produce rectangles with correct proportional widths\n\"\n```\n\n**SVG Generation Validation:**\n1. Generate a flame graph from sample profile data\n2. Open the resulting SVG file in a web browser\n3. Verify rectangles display correctly with proportional widths\n4. Test zoom functionality by clicking on rectangles\n5. Test search functionality with known function names\n6. Verify tooltip information appears on hover\n\n**Manual Integration Test:**\nCreate a simple test program with known call patterns, profile it with your stack sampler, and generate a flame graph. The resulting visualization should clearly show the expected call relationships and sample distributions.\n\nSigns of correct implementation:\n- Rectangle widths accurately represent sample proportions\n- Function names appear centered and readable\n- Zoom operations correctly recalculate coordinates\n- Search highlighting works for partial name matches\n- Color scheme appropriately distinguishes function categories\n\nCommon signs of problems:\n- Visual gaps between rectangles (width calculation errors)\n- Overlapping rectangles (coordinate calculation bugs)\n- Missing or garbled text (SVG text positioning issues)\n- Broken interactivity (JavaScript errors in console)\n- Inconsistent colors for same functions (color assignment problems)\n\n![Flame Graph Generation Pipeline](./diagrams/flame-graph-generation.svg)\n\n\n## Memory Profiling Component\n\n> **Milestone(s):** Milestone 4 — Memory Profiling: Track heap allocations and detect memory leaks using function interposition to identify allocation patterns, heavy allocation sites, and leaked memory\n\n### Mental Model: Library Book Checkout\n\nThink of memory allocation tracking like a library's book checkout system. When patrons (code) want to borrow books (memory), they must register with the librarian (allocation interceptor) who records their name (call stack), the book title (allocation size), and checkout time (timestamp). The librarian maintains a detailed ledger (allocation metadata) of who has what books and when they took them.\n\nJust as a library can identify overdue books by comparing checkout records against returns, memory leak detection works by tracking allocations without corresponding free operations. The library knows books are missing when they don't appear in returned stacks after a reasonable time. Similarly, the profiler identifies memory leaks by finding allocations that persist throughout program execution without being freed.\n\nThe librarian also notices patterns: certain patrons (functions) consistently check out many books (heavy allocators), some subjects are more popular (allocation hot spots), and some books never get returned (definite leaks). This systematic tracking transforms chaotic borrowing activity into actionable insights about library usage, just as allocation tracking reveals memory usage patterns in running programs.\n\nMemory profiling faces the unique challenge of intercepting every allocation and deallocation in a running program while maintaining comprehensive metadata about each operation. Unlike stack sampling which observes execution state periodically, allocation tracking must capture every memory operation to provide complete coverage for leak detection and allocation analysis.\n\n### Allocation Function Interposition\n\n**Function interposition** provides the mechanism to intercept calls to memory allocation functions like `malloc`, `calloc`, `realloc`, and `free`. The profiler inserts itself between application code and the standard library's memory management functions, creating an opportunity to record allocation metadata before delegating to the real allocation functions.\n\nThe interposition layer acts as a transparent proxy that preserves the exact semantics of the original allocation functions while adding profiling instrumentation. When application code calls `malloc(1024)`, the interposed version captures the call stack, records allocation metadata, calls the real `malloc`, stores tracking information keyed by the returned pointer, and returns the allocated address to the application.\n\n**Allocation tracking metadata** requires careful design to balance completeness against overhead. Each `Allocation` record contains essential information for leak detection and performance analysis:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| allocation_id | int | Unique identifier for this allocation |\n| size | int | Requested allocation size in bytes |\n| actual_size | int | Actual allocated size (may include alignment padding) |\n| timestamp | float | Time when allocation occurred |\n| thread_id | int | Thread that performed the allocation |\n| allocation_stack | List[StackFrame] | Call stack at allocation site |\n| allocation_type | AllocationType | malloc, calloc, realloc, new, etc. |\n| is_freed | bool | Whether this allocation has been freed |\n| free_timestamp | float | Time when allocation was freed (if applicable) |\n| free_thread_id | int | Thread that performed the free (if applicable) |\n\n**Stack trace capture at allocation sites** provides the crucial context needed to identify where memory is being allocated in the source code. Unlike stack sampling which captures arbitrary execution points, allocation stack traces always represent meaningful code locations where memory allocation decisions occurred. The profiler must unwind the call stack synchronously during each allocation call, capturing the complete calling context from the allocation site back to the program entry point.\n\nThe allocation stack trace serves multiple analysis purposes: identifying allocation hot spots (functions that allocate large amounts of memory), understanding allocation call patterns (which high-level operations trigger many allocations), and providing debugging context for memory leaks (the exact code path that allocated leaked memory).\n\n**Allocation site aggregation** groups individual allocations by their call stack signature to identify patterns in memory usage. An `AllocationSite` represents all allocations that occurred from the same calling context:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| call_stack_hash | int | Hash of the call stack for grouping |\n| representative_stack | List[StackFrame] | Example call stack for this site |\n| total_allocations | int | Number of allocations from this site |\n| total_bytes | int | Total bytes allocated from this site |\n| peak_live_bytes | int | Maximum bytes live simultaneously |\n| peak_live_count | int | Maximum allocations live simultaneously |\n| lifetime_distribution | List[int] | Histogram of allocation lifetimes |\n| first_seen | float | Time of first allocation from this site |\n| last_seen | float | Time of most recent allocation from this site |\n\n> **Decision: LD_PRELOAD vs Link-Time Interposition**\n> - **Context**: Multiple mechanisms exist for intercepting allocation functions, each with different implementation complexity and runtime characteristics\n> - **Options Considered**: LD_PRELOAD dynamic interposition, link-time symbol interposition, binary rewriting, compile-time instrumentation\n> - **Decision**: Use LD_PRELOAD for primary interposition with fallback detection for static linking\n> - **Rationale**: LD_PRELOAD provides transparent interposition without requiring recompilation, works with existing binaries, and allows profiling arbitrary processes. Link-time approaches require build system integration and source access.\n> - **Consequences**: Some allocations in static constructors or early initialization may be missed, requires shared library implementation, limited effectiveness with statically linked binaries\n\n| Interposition Method | Pros | Cons | Use Case |\n|---------------------|------|------|----------|\n| LD_PRELOAD | Works with existing binaries, no recompilation | Misses static constructors, library loading order issues | General purpose profiling |\n| Link-time symbols | Catches all allocations, reliable ordering | Requires build integration, source access needed | Development-time profiling |\n| Binary rewriting | Complete coverage, works post-build | Complex implementation, architecture specific | Specialized analysis tools |\n\n**Memory allocation flame graphs** extend the flame graph visualization concept to show memory allocation patterns rather than CPU sampling. Instead of displaying which functions consume CPU time most frequently, allocation flame graphs show which call paths allocate the most memory. The width of each flame graph segment represents the total bytes allocated from that calling context, enabling developers to quickly identify memory-intensive code paths.\n\nThe allocation flame graph aggregates `AllocationSite` data using the same hierarchical folding algorithm as CPU flame graphs, but weights each call stack by `total_bytes` rather than sample count. This visualization reveals allocation patterns that complement CPU profiling: functions may allocate substantial memory without consuming significant CPU time, or brief CPU spikes may trigger large allocation bursts.\n\n### Memory Leak Detection\n\n**Memory leak identification** requires distinguishing between legitimate long-lived allocations and genuine leaks where memory is allocated but never freed. The profiler maintains a live allocation set containing all allocations that have not yet been freed, tracking their age and allocation context to classify potential leaks.\n\nLeak detection operates on several principles: allocations that persist for extended periods without being freed may indicate leaks, allocations from the same call site that accumulate without corresponding frees suggest systematic leaks, and allocations that grow without bound over time indicate unbounded memory growth patterns.\n\n**Leak confidence scoring** addresses the fundamental challenge that not all long-lived allocations represent bugs. Global data structures, caches, and configuration objects may legitimately persist throughout program execution. The `MemoryLeak` structure includes confidence scoring to help developers prioritize investigation:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| allocation | Allocation | The potentially leaked allocation |\n| leak_confidence | float | Confidence score from 0.0 to 1.0 |\n| leak_category | LeakCategory | Classification of leak type |\n| allocation_age | float | How long allocation has been live |\n| similar_leaks | int | Count of similar allocations from same site |\n| total_leaked_bytes | int | Total bytes from this leak site |\n| detection_method | str | Which heuristic identified this leak |\n| suppression_matched | str | Suppression rule that matched (if any) |\n\n**Leak categorization** helps developers understand different types of memory problems. `LeakCategory` distinguishes between definite leaks (allocations with no remaining references), possible leaks (allocations with questionable reference patterns), reachable leaks (allocations still referenced but logically leaked), and growth patterns (accumulating allocations suggesting unbounded growth).\n\n> **Decision: Leak Detection Heuristics vs Reference Tracking**\n> - **Context**: Different approaches exist for identifying memory leaks, ranging from simple time-based heuristics to comprehensive reference graph analysis\n> - **Options Considered**: Age-based heuristics, reference counting, mark-and-sweep analysis, static analysis integration\n> - **Decision**: Implement age-based and growth-pattern heuristics with optional reference tracking\n> - **Rationale**: Heuristics provide good coverage with minimal overhead, while full reference tracking requires significant complexity and memory overhead. Many real leaks exhibit clear temporal patterns.\n> - **Consequences**: Some false positives from long-lived legitimate allocations, requires manual tuning of age thresholds, may miss complex reference cycle leaks\n\n**Memory usage timeline tracking** captures heap behavior over time through periodic `MemorySnapshot` recordings. These snapshots provide insight into allocation patterns, memory growth trends, and correlation between program phases and memory usage:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| timestamp | float | When this snapshot was captured |\n| total_allocated | int | Cumulative bytes allocated since start |\n| total_freed | int | Cumulative bytes freed since start |\n| live_bytes | int | Currently allocated bytes (total - freed) |\n| live_allocations | int | Number of allocations currently active |\n| heap_size | int | Total heap size from OS perspective |\n| allocation_rate | float | Recent allocation rate in bytes per second |\n| free_rate | float | Recent deallocation rate in bytes per second |\n\nTimeline analysis reveals memory usage patterns that single-point measurements cannot capture: steady memory growth indicating leaks, periodic allocation spikes corresponding to specific operations, memory fragmentation through heap size versus live bytes comparison, and allocation rate imbalances where allocation consistently exceeds deallocation.\n\n**Suppression and filtering** mechanisms help focus leak detection on actionable issues by filtering out known false positives and expected long-lived allocations. Suppression rules match allocation call stacks against patterns, allowing developers to mark specific allocation sites as expected long-lived allocations.\n\nSuppression configuration supports call stack pattern matching, allocation size thresholds, and lifetime exemptions. For example, a suppression rule might ignore allocations from `initialize_global_config()` that exceed 24 hours in lifetime, or filter out allocations smaller than 64 bytes that persist longer than program startup phase.\n\n### Architecture Decision Records\n\n> **Decision: Allocation Metadata Storage Strategy**\n> - **Context**: Profiler must maintain metadata for every live allocation, potentially millions of records, requiring efficient storage and lookup\n> - **Options Considered**: Hash table with pointer keys, red-black tree sorted by address, separate metadata heap, embedded metadata in allocation headers\n> - **Decision**: Hash table with allocation pointer as key, separate metadata heap for allocation records\n> - **Rationale**: Hash table provides O(1) lookup performance for malloc/free operations, separate heap prevents metadata corruption from application bugs, pointer keys enable direct lookup without address translation\n> - **Consequences**: Additional memory overhead for hash table and metadata heap, potential hash collisions requiring collision handling, metadata heap fragmentation over time\n\n| Storage Strategy | Pros | Cons | Memory Overhead |\n|------------------|------|------|-----------------|\n| Hash table | O(1) lookup, simple implementation | Hash collisions, memory overhead | ~200% for metadata |\n| Red-black tree | Sorted iteration, predictable performance | O(log n) lookup, complex balancing | ~150% for metadata |\n| Embedded headers | Low overhead, cache locality | Corrupted by application bugs | ~10% for headers |\n\n> **Decision: Thread Safety in Allocation Tracking**\n> - **Context**: Multi-threaded programs allocate memory concurrently, requiring thread-safe metadata management without introducing contention or deadlocks\n> - **Options Considered**: Global mutex for all operations, per-thread allocation tables, lock-free hash table, thread-local buffering with periodic merging\n> - **Decision**: Thread-local allocation tables with global merger thread for aggregation\n> - **Rationale**: Thread-local tables eliminate contention during allocation/free operations while preserving global view through periodic merging. Avoids deadlocks in signal handlers and recursive allocation scenarios.\n> - **Consequences**: Delayed visibility of allocations across threads, memory overhead for per-thread tables, complexity in merger thread synchronization\n\n> **Decision: Handling Recursive Allocation Calls**\n> - **Context**: Allocation tracking code itself may trigger memory allocations (stack unwinding, metadata storage), creating infinite recursion if not handled carefully\n> - **Options Considered**: Thread-local recursion flag, pre-allocated metadata buffers, async-safe allocation tracking, allocation call filtering\n> - **Decision**: Thread-local recursion detection with pre-allocated emergency buffers\n> - **Rationale**: Recursion flag prevents infinite loops, emergency buffers ensure tracking continues even when normal allocation fails, maintains complete allocation coverage\n> - **Consequences**: Small overhead for recursion checking on every allocation, limited capacity in emergency scenarios, potential metadata loss under extreme memory pressure\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Recursive malloc calls during stack unwinding**\n\nThe most dangerous pitfall in allocation interception occurs when the stack unwinding code itself triggers memory allocations, creating infinite recursion. This happens because stack unwinding may need to allocate memory for symbol resolution, debug information parsing, or internal data structures, which triggers the interposed malloc, which attempts stack unwinding, creating a cycle.\n\nThe problem manifests as stack overflow crashes or hanging programs when profiling begins. Developers often miss this because the recursion only occurs during profiling, not during normal program execution. The issue is particularly subtle because it may only happen for specific allocation sites or under certain conditions.\n\n**Solution**: Implement thread-local recursion detection using a simple boolean flag. When entering the allocation interceptor, check if the current thread is already processing an allocation. If so, delegate directly to the real malloc without any tracking. Use pre-allocated buffers for essential stack unwinding operations to avoid allocation dependencies.\n\n⚠️ **Pitfall: Thread safety violations in metadata management**\n\nMulti-threaded programs create complex synchronization challenges for allocation tracking. The common mistake is using inadequate synchronization (like simple mutexes) which leads to deadlocks when malloc is called from signal handlers, during library loading, or from within other locked code sections. Global mutex protection can also create severe contention bottlenecks.\n\nSymptoms include programs hanging during initialization, deadlocks under memory pressure, or metadata corruption in multi-threaded scenarios. These issues are particularly hard to debug because they may only occur under specific timing conditions or high thread contention.\n\n**Solution**: Use thread-local allocation tracking tables that require no synchronization during allocation/free operations. Implement a separate merger thread that periodically collects and aggregates data from all thread-local tables using lock-free or carefully ordered synchronization. Ensure all metadata operations are async-safe for signal handler compatibility.\n\n⚠️ **Pitfall: Excessive memory overhead from tracking metadata**\n\nAllocation tracking can consume substantial memory overhead, sometimes exceeding the memory usage of the application being profiled. This occurs when the tracking metadata (call stacks, timestamps, allocation records) requires more space than the tracked allocations themselves, especially for programs with many small allocations.\n\nThe problem is particularly severe for applications that make millions of small allocations, where each 16-byte allocation might require 200+ bytes of tracking metadata. This can lead to out-of-memory conditions or severely degraded performance due to increased memory pressure.\n\n**Solution**: Implement sampling for small allocations (track every Nth allocation under certain size thresholds), use memory-efficient data structures for metadata storage, and provide configurable limits on metadata memory usage. Consider aggregating very small allocations by call site rather than tracking individually.\n\n⚠️ **Pitfall: Missing allocations from static constructors and early initialization**\n\nLD_PRELOAD interposition misses allocations that occur during static constructor execution or early program initialization, before the preloaded library is fully initialized. This happens because static constructors run before main() and potentially before the profiler can set up its interception hooks.\n\nThe result is incomplete allocation tracking that misses some allocations but sees their corresponding free operations, leading to negative allocation counts or false leak reports. This is particularly problematic for C++ programs with extensive static initialization.\n\n**Solution**: Implement early initialization detection and delayed tracking startup. Use library constructor attributes to initialize profiling as early as possible. Consider alternative interposition methods (like link-time interposition) for comprehensive coverage when needed.\n\n⚠️ **Pitfall: Incorrect leak classification of legitimate long-lived allocations**\n\nMemory leak detection often generates false positives by flagging legitimate long-lived allocations as potential leaks. Global configuration objects, cached data, and persistent data structures are not leaks even if they persist throughout program execution. Poor leak classification creates noise that obscures real memory problems.\n\nThis manifests as leak reports for allocations that are intentionally never freed, such as program configuration, static lookup tables, or singleton objects. Developers waste time investigating these false positives instead of focusing on genuine memory leaks.\n\n**Solution**: Implement sophisticated leak classification using allocation patterns, call stack analysis, and configurable suppression rules. Allow developers to mark specific allocation sites or call stack patterns as expected long-lived allocations. Use growth-based detection rather than purely time-based heuristics.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Function Interposition | LD_PRELOAD with dlsym symbol resolution | Binary rewriting with Intel Pin or DynamoRIO |\n| Metadata Storage | Python dictionary with allocation pointer keys | Custom hash table with memory pool allocation |\n| Stack Unwinding | Python traceback module (limited accuracy) | libunwind for precise native stack traces |\n| Memory Tracking | Simple allocation/free counter | Full allocation site analysis with lifetime histograms |\n| Leak Detection | Age-based heuristics with configurable thresholds | Reference graph analysis with mark-and-sweep |\n\n#### Recommended File Structure\n\n```\nprofiler/\n  memory/\n    __init__.py                    ← main memory profiler interface\n    interceptor.py                 ← allocation function interposition\n    tracker.py                     ← allocation metadata management\n    leak_detector.py               ← memory leak identification\n    allocation_sites.py            ← allocation site aggregation\n    memory_flame.py                ← memory allocation flame graphs\n    native_interceptor.c           ← C extension for LD_PRELOAD\n    malloc_intercept.so            ← compiled interposition library\n  tests/\n    test_memory_profiling.py       ← memory profiler test suite\n    test_programs/\n      leaky_program.c              ← test program with intentional leaks\n      allocation_heavy.py          ← Python program with allocation patterns\n```\n\n#### Infrastructure Starter Code\n\n**Complete LD_PRELOAD allocation interceptor** (native_interceptor.c):\n```c\n#define _GNU_SOURCE\n#include <dlfcn.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <pthread.h>\n#include <execinfo.h>\n\n// Function pointers to real allocation functions\nstatic void* (*real_malloc)(size_t) = NULL;\nstatic void (*real_free)(void*) = NULL;\nstatic void* (*real_realloc)(void*, size_t) = NULL;\nstatic void* (*real_calloc)(size_t, size_t) = NULL;\n\n// Thread-local recursion detection\nstatic __thread int in_malloc_hook = 0;\n\n// Initialize real function pointers\nstatic void init_hooks(void) {\n    if (real_malloc) return;\n    \n    real_malloc = dlsym(RTLD_NEXT, \"malloc\");\n    real_free = dlsym(RTLD_NEXT, \"free\");\n    real_realloc = dlsym(RTLD_NEXT, \"realloc\");\n    real_calloc = dlsym(RTLD_NEXT, \"calloc\");\n    \n    if (!real_malloc || !real_free || !real_realloc || !real_calloc) {\n        fprintf(stderr, \"Error: failed to load real allocation functions\\n\");\n        exit(1);\n    }\n}\n\n// Capture call stack (simplified version)\nstatic int capture_backtrace(void** buffer, int max_frames) {\n    return backtrace(buffer, max_frames);\n}\n\n// Send allocation info to Python profiler via named pipe or shared memory\nstatic void record_allocation(void* ptr, size_t size, void** backtrace, int frame_count) {\n    // TODO: Implement communication with Python profiler\n    // Could use named pipe, shared memory, or direct Python C API calls\n}\n\nstatic void record_deallocation(void* ptr) {\n    // TODO: Implement deallocation recording\n}\n\n// Malloc interceptor\nvoid* malloc(size_t size) {\n    init_hooks();\n    \n    // Prevent recursion during stack capture\n    if (in_malloc_hook) {\n        return real_malloc(size);\n    }\n    \n    // Call real malloc first\n    void* result = real_malloc(size);\n    \n    // Record allocation with stack trace\n    if (result) {\n        in_malloc_hook = 1;\n        void* backtrace_buffer[64];\n        int frame_count = capture_backtrace(backtrace_buffer, 64);\n        record_allocation(result, size, backtrace_buffer, frame_count);\n        in_malloc_hook = 0;\n    }\n    \n    return result;\n}\n\n// Free interceptor\nvoid free(void* ptr) {\n    init_hooks();\n    \n    if (ptr && !in_malloc_hook) {\n        in_malloc_hook = 1;\n        record_deallocation(ptr);\n        in_malloc_hook = 0;\n    }\n    \n    real_free(ptr);\n}\n\n// Similar interceptors for realloc and calloc...\n```\n\n**Complete Python metadata tracker** (tracker.py):\n```python\nimport threading\nimport time\nfrom typing import Dict, List, Optional, Set\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict\nimport weakref\n\n@dataclass\nclass Allocation:\n    allocation_id: int\n    size: int\n    actual_size: int\n    timestamp: float\n    thread_id: int\n    allocation_stack: List['StackFrame']\n    allocation_type: str\n    is_freed: bool = False\n    free_timestamp: float = 0.0\n    free_thread_id: int = 0\n\n    def get_lifetime(self) -> float:\n        \"\"\"Calculate allocation lifetime in seconds\"\"\"\n        if self.is_freed:\n            return self.free_timestamp - self.timestamp\n        return time.time() - self.timestamp\n\n    def is_long_lived(self, threshold_seconds: float) -> bool:\n        \"\"\"Check if allocation exceeds lifetime threshold\"\"\"\n        return self.get_lifetime() > threshold_seconds\n\n@dataclass\nclass AllocationSite:\n    call_stack_hash: int\n    representative_stack: List['StackFrame']\n    total_allocations: int = 0\n    total_bytes: int = 0\n    peak_live_bytes: int = 0\n    peak_live_count: int = 0\n    lifetime_distribution: List[int] = field(default_factory=list)\n    first_seen: float = 0.0\n    last_seen: float = 0.0\n\n    def add_allocation(self, allocation: Allocation) -> None:\n        \"\"\"Update allocation site statistics with new allocation\"\"\"\n        self.total_allocations += 1\n        self.total_bytes += allocation.size\n        self.last_seen = allocation.timestamp\n        \n        if self.first_seen == 0.0:\n            self.first_seen = allocation.timestamp\n\n    def get_average_size(self) -> float:\n        \"\"\"Calculate average allocation size from site\"\"\"\n        if self.total_allocations == 0:\n            return 0.0\n        return self.total_bytes / self.total_allocations\n\nclass AllocationTracker:\n    def __init__(self):\n        self._live_allocations: Dict[int, Allocation] = {}  # ptr -> Allocation\n        self._allocation_sites: Dict[int, AllocationSite] = {}  # hash -> site\n        self._allocation_counter = 0\n        self._lock = threading.RLock()\n        self._thread_local = threading.local()\n\n    def record_allocation(self, ptr: int, size: int, stack_frames: List['StackFrame']) -> None:\n        \"\"\"Record a new allocation\"\"\"\n        # TODO 1: Generate unique allocation ID\n        # TODO 2: Create Allocation object with current timestamp and thread ID\n        # TODO 3: Calculate stack hash for allocation site grouping\n        # TODO 4: Update or create AllocationSite for this stack\n        # TODO 5: Store allocation in live allocations dict\n        # TODO 6: Update allocation site statistics\n        pass\n\n    def record_deallocation(self, ptr: int) -> None:\n        \"\"\"Record a deallocation\"\"\"\n        # TODO 1: Look up allocation by pointer\n        # TODO 2: Mark allocation as freed with timestamp\n        # TODO 3: Update allocation site statistics\n        # TODO 4: Remove from live allocations\n        pass\n\n    def get_live_allocations(self) -> List[Allocation]:\n        \"\"\"Get all currently live allocations\"\"\"\n        with self._lock:\n            return list(self._live_allocations.values())\n\n    def get_allocation_sites(self) -> List[AllocationSite]:\n        \"\"\"Get all allocation sites sorted by total bytes\"\"\"\n        with self._lock:\n            sites = list(self._allocation_sites.values())\n            return sorted(sites, key=lambda s: s.total_bytes, reverse=True)\n```\n\n#### Core Logic Skeleton Code\n\n**Memory leak detector** (leak_detector.py):\n```python\nfrom enum import Enum\nfrom typing import List, Dict, Set\nimport time\n\nclass LeakCategory(Enum):\n    DEFINITE_LEAK = \"definite\"\n    POSSIBLE_LEAK = \"possible\" \n    REACHABLE_LEAK = \"reachable\"\n    GROWTH_PATTERN = \"growth\"\n\n@dataclass\nclass MemoryLeak:\n    allocation: Allocation\n    leak_confidence: float\n    leak_category: LeakCategory\n    allocation_age: float\n    similar_leaks: int\n    total_leaked_bytes: int\n    detection_method: str\n    suppression_matched: str = \"\"\n\nclass LeakDetector:\n    def __init__(self, age_threshold: float = 300.0, growth_threshold: int = 1000):\n        self.age_threshold = age_threshold\n        self.growth_threshold = growth_threshold\n        self.suppression_rules: List[Dict] = []\n\n    def detect_leaks(self, live_allocations: List[Allocation], \n                     allocation_sites: List[AllocationSite]) -> List[MemoryLeak]:\n        \"\"\"Detect memory leaks from live allocations and sites\"\"\"\n        # TODO 1: Identify age-based potential leaks (allocations older than threshold)\n        # TODO 2: Group similar leaks by call stack hash  \n        # TODO 3: Calculate confidence scores based on allocation patterns\n        # TODO 4: Identify growth patterns from allocation sites\n        # TODO 5: Apply suppression rules to filter false positives\n        # TODO 6: Classify leaks by category (definite, possible, reachable)\n        # TODO 7: Sort leaks by confidence and total leaked bytes\n        pass\n\n    def analyze_growth_patterns(self, sites: List[AllocationSite]) -> List[MemoryLeak]:\n        \"\"\"Identify allocation sites showing unbounded growth\"\"\"\n        # TODO 1: Find sites with high allocation rate and low free rate\n        # TODO 2: Calculate growth velocity over time windows\n        # TODO 3: Identify sites exceeding growth thresholds\n        # TODO 4: Create MemoryLeak entries for growth patterns\n        pass\n\n    def calculate_leak_confidence(self, allocation: Allocation, \n                                  similar_count: int) -> float:\n        \"\"\"Calculate confidence score for potential leak\"\"\"\n        # TODO 1: Factor in allocation age (older = higher confidence)\n        # TODO 2: Consider number of similar unfree'd allocations\n        # TODO 3: Analyze allocation call stack for leak-prone patterns\n        # TODO 4: Account for allocation size (larger = higher impact)\n        # TODO 5: Return confidence score between 0.0 and 1.0\n        pass\n```\n\n#### Milestone Checkpoint\n\nAfter implementing allocation interception and basic tracking:\n\n1. **Compile the LD_PRELOAD library**: `gcc -shared -fPIC native_interceptor.c -o malloc_intercept.so -ldl`\n\n2. **Test with a simple program**: \n   ```bash\n   LD_PRELOAD=./malloc_intercept.so ./test_program\n   ```\n\n3. **Expected behavior**: The program should run normally but with allocation/deallocation events being recorded. You should see allocation tracking output or be able to query live allocations.\n\n4. **Verification steps**:\n   - Confirm no crashes or hangs during program execution\n   - Verify allocation and deallocation events are captured\n   - Check that call stacks are properly recorded\n   - Test with multi-threaded programs to verify thread safety\n\n5. **Common issues**:\n   - **Infinite recursion**: Program hangs or crashes immediately → Check recursion detection\n   - **Missing symbols**: \"symbol not found\" errors → Verify dlsym calls and linking\n   - **Metadata corruption**: Inconsistent allocation counts → Review thread synchronization\n\n#### Language-Specific Hints\n\n- **Use `ctypes` or `cffi`** to interface between Python profiler and C interception library\n- **Shared memory or named pipes** provide efficient communication channel for allocation events\n- **Memory mapping with `mmap`** enables low-overhead metadata storage\n- **Threading.local()** provides thread-safe storage for per-thread allocation data\n- **Weak references** help avoid reference cycles in allocation tracking metadata\n- **Signal handling** requires async-safe code in allocation interceptors\n- **Process forking** requires careful cleanup and re-initialization of tracking state\n\n\n## Interactions and Data Flow\n\n> **Milestone(s):** All milestones (1-4) — orchestrates the complete data pipeline from stack sampling through symbol resolution to flame graph generation and memory leak detection\n\n### Mental Model: The Assembly Line\n\nThink of the profiler as a sophisticated manufacturing assembly line where raw materials (memory addresses and timing data) flow through specialized stations that progressively refine and transform them into finished products (flame graphs and memory reports). Just as an automotive assembly line has welding stations, paint booths, and quality control checkpoints, our profiler has sampling stations, symbolization workbenches, and aggregation facilities. Each station has a specific job, operates at its own pace, and hands off partially completed work to the next station. The key insight is that data flows in one primary direction, but stations can operate concurrently and maintain their own buffers to handle varying processing speeds.\n\nThe assembly line metaphor helps us understand three critical aspects of profiler data flow: **buffering** (stations need input queues to handle bursty work), **backpressure** (when downstream stations get overwhelmed, upstream stations must slow down or drop work), and **quality control** (each station validates its inputs and outputs to prevent defective data from corrupting the final product).\n\n![System Component Architecture](./diagrams/system-components.svg)\n\n### Profiling Data Pipeline\n\nThe profiling data pipeline represents the core data transformation sequence that converts raw execution observations into actionable performance insights. This pipeline operates as a series of connected stages, each with specific responsibilities, performance characteristics, and failure modes.\n\n#### Primary Pipeline Stages\n\nThe main profiling pipeline consists of four sequential stages that process data in distinct phases:\n\n| Stage | Input | Output | Processing Time | Buffer Capacity |\n|-------|-------|--------|----------------|-----------------|\n| **Stack Sampling** | Signal interrupts | Raw `Sample` objects | 1-10 microseconds | 10,000 samples |\n| **Symbol Resolution** | `Sample` with addresses | `Sample` with function names | 100-1000 microseconds | 1,000 samples |\n| **Stack Aggregation** | Individual samples | `FlameNode` tree | 10-100 microseconds | Unlimited (streaming) |\n| **Visualization** | Aggregated tree | SVG flame graph | 1-10 milliseconds | N/A (file output) |\n\n**Stage 1: Stack Sampling Collection**\n\nThe sampling stage operates as a high-frequency data collector that captures execution snapshots at regular intervals. When a `SIGPROF` timer signal arrives, the signal handler executes in an async-safe context and must complete its work within microseconds to avoid distorting the target program's behavior.\n\nThe sampling process follows this sequence:\n\n1. **Signal Delivery**: The kernel delivers `SIGPROF` to the target process based on the configured `TimerConfig` interval\n2. **Context Capture**: The signal handler extracts the `RegisterContext` from the interrupted execution state\n3. **Stack Unwinding**: Frame pointer traversal builds a `List[StackFrame]` representing the current call chain\n4. **Sample Creation**: A complete `Sample` object is constructed with timestamp, thread ID, and captured stack frames\n5. **Buffer Storage**: The sample is added to a thread-safe ring buffer using atomic operations\n6. **Overflow Handling**: If the buffer is full, either the oldest sample is evicted or the new sample is dropped based on configured policy\n\n> **Critical Design Insight**: The sampling stage operates under severe constraints because it runs in signal handler context. It cannot perform any operations that might block, allocate memory, or acquire locks. This forces us to pre-allocate all data structures and use only async-safe functions.\n\n**Stage 2: Symbol Resolution Processing**\n\nSymbol resolution transforms raw memory addresses into human-readable function names and source locations. This stage operates asynchronously from sampling and can afford higher latency because it doesn't run in signal handler context.\n\nThe symbol resolution pipeline processes samples in batches:\n\n1. **Batch Extraction**: Pull a batch of raw samples from the sampling buffer (typically 100-1000 samples)\n2. **Address Collection**: Extract unique addresses from all `StackFrame` objects in the batch to minimize duplicate symbol lookups\n3. **Cache Lookup**: Query the `SymbolCache` for each address to avoid expensive ELF parsing for previously resolved symbols\n4. **ELF Resolution**: For cache misses, parse the appropriate `Module` to find the containing `Symbol`\n5. **DWARF Processing**: If debug information is available, extract source file names and line numbers from `LineRange` data\n6. **Frame Enrichment**: Update each `StackFrame` with resolved `function_name`, `filename`, and `line_number`\n7. **Cache Population**: Store newly resolved symbols in the cache for future lookups\n\n> **Decision: Batch Processing Strategy**\n> - **Context**: Individual sample processing has high per-sample overhead due to symbol table parsing\n> - **Options Considered**: \n>   - Process samples individually as they arrive\n>   - Batch samples for bulk processing\n>   - Stream processing with mini-batches\n> - **Decision**: Use batch processing with configurable batch sizes (default 500 samples)\n> - **Rationale**: Batching amortizes symbol table parsing cost across multiple samples and enables address deduplication\n> - **Consequences**: Introduces processing latency but reduces CPU overhead by 10-50x for symbol-heavy workloads\n\n**Stage 3: Stack Aggregation and Folding**\n\nThe aggregation stage transforms individual stack samples into hierarchical call trees suitable for flame graph visualization. This process must preserve calling context while merging identical call paths to show frequency patterns.\n\nThe aggregation algorithm operates as a streaming tree builder:\n\n1. **Root Initialization**: Create a root `FlameNode` representing the entire profiling session\n2. **Sample Processing**: For each symbolized `Sample`, traverse its `stack_frames` from bottom (main) to top (leaf function)\n3. **Path Traversal**: Starting from the root node, follow or create child nodes for each frame in the call stack\n4. **Weight Accumulation**: Increment `sample_count` for each node along the traversed path\n5. **Self-Time Tracking**: Update `self_count` only for the leaf node representing the actual interrupted function\n6. **Metadata Preservation**: Attach module names and other attributes to nodes for visualization coloring\n\nThe folded stack format provides an intermediate representation that captures the essential aggregation information:\n\n```\nmain;parse_config;load_json;malloc 145\nmain;parse_config;validate_schema;check_required 89\nmain;process_data;compute_hash;sha256_update 234\n```\n\nEach line represents a unique call path with its accumulated sample count, enabling downstream tools to reconstruct the calling hierarchy.\n\n**Stage 4: Visualization Generation**\n\nThe final stage converts the aggregated flame tree into an interactive SVG visualization. This stage performs coordinate calculations, color assignment, and interactive feature embedding.\n\nThe visualization pipeline executes these steps:\n\n1. **Tree Traversal**: Perform depth-first traversal of the `FlameNode` tree to calculate cumulative widths\n2. **Coordinate Mapping**: Convert logical sample counts to pixel coordinates using the configured flame graph dimensions\n3. **Rectangle Generation**: Create `Rectangle` objects for each visible node (filtering out rectangles below `MIN_WIDTH_THRESHOLD`)\n4. **Color Assignment**: Apply the selected `ColorScheme` to distinguish different modules, function types, or call frequencies\n5. **SVG Construction**: Generate SVG elements with embedded JavaScript for zoom and search functionality\n6. **Interactive Features**: Add event handlers for mouse hover tooltips, click zoom, and text search highlighting\n\n#### Pipeline Performance Characteristics\n\nThe profiling pipeline exhibits different performance characteristics at each stage that affect overall system behavior:\n\n| Metric | Sampling | Symbolization | Aggregation | Visualization |\n|--------|----------|---------------|-------------|---------------|\n| **Throughput** | 10K samples/sec | 1K samples/sec | 50K samples/sec | 10 graphs/sec |\n| **Latency** | 10 microseconds | 1 millisecond | 100 microseconds | 100 milliseconds |\n| **Memory Usage** | 1KB per sample | 10MB symbol cache | 100KB tree | 50KB SVG |\n| **CPU Overhead** | 0.1% per 100Hz | 5-20% during resolution | 1-2% during aggregation | Negligible |\n\n> **Bottleneck Analysis**: Symbol resolution typically becomes the pipeline bottleneck due to ELF parsing overhead. The system uses adaptive batching and aggressive caching to mitigate this limitation.\n\n![Profiler State Machine](./diagrams/profiler-state-machine.svg)\n\n#### Error Propagation and Recovery\n\nThe pipeline implements a comprehensive error handling strategy that prevents failures in one stage from corrupting downstream processing:\n\n| Error Type | Detection Point | Recovery Strategy | Data Impact |\n|------------|----------------|-------------------|-------------|\n| **Signal Handler Crash** | Sampling stage | Restart sampling with reduced frequency | Lost samples during restart |\n| **Symbol Parse Failure** | Symbolization stage | Mark frames as unresolved, continue processing | Missing function names, addresses shown |\n| **Memory Exhaustion** | Any stage | Drop oldest data, trigger garbage collection | Reduced profiling window |\n| **File System Errors** | Visualization stage | Retry with temporary directory | Delayed output generation |\n\n### Memory Tracking Data Flow\n\nThe memory profiling data flow operates in parallel with stack sampling but follows a different architectural pattern based on **event-driven interception** rather than periodic sampling. This approach captures every allocation and deallocation event, providing complete memory usage visibility at the cost of higher runtime overhead.\n\n![Memory Allocation Tracking](./diagrams/memory-tracking-sequence.svg)\n\n#### Memory Tracking Architecture\n\nMemory profiling operates through function interposition, where the profiler intercepts calls to allocation functions like `malloc`, `calloc`, `realloc`, and `free`. This interception happens at the dynamic linking level using `LD_PRELOAD` to substitute profiler versions of these functions.\n\n**Interposition Mechanism**\n\nThe memory tracking system implements a transparent proxy layer that wraps standard allocation functions:\n\n1. **Dynamic Loading**: At process startup, `LD_PRELOAD` causes the dynamic linker to load profiler allocation functions before the standard library versions\n2. **Function Forwarding**: Profiler functions perform tracking operations then forward to the real allocation functions using `dlsym(RTLD_NEXT, \"malloc\")`\n3. **Metadata Association**: Each allocation gets associated with tracking metadata without modifying the returned pointer\n4. **Thread Safety**: All tracking operations use thread-local storage and atomic operations to handle concurrent allocations\n\n**Allocation Event Processing**\n\nWhen an allocation function is called, the memory tracker follows this processing sequence:\n\n1. **Stack Capture**: Immediately capture the current call stack to identify the allocation site\n2. **Allocation Forwarding**: Call the real allocation function to obtain memory and actual size\n3. **Metadata Creation**: Create an `Allocation` object with size, timestamp, thread ID, and captured stack\n4. **Hash Table Storage**: Store allocation metadata in a thread-safe hash table keyed by returned pointer\n5. **Site Aggregation**: Update the corresponding `AllocationSite` statistics for this call stack signature\n6. **Memory Accounting**: Update global memory counters and per-thread allocation rates\n\n**Deallocation Event Processing**\n\nFree operations trigger a parallel deallocation tracking sequence:\n\n1. **Metadata Lookup**: Find the `Allocation` object associated with the freed pointer\n2. **Lifetime Calculation**: Compute allocation lifetime and update lifetime distribution statistics\n3. **Site Updates**: Decrement live allocation counts for the corresponding `AllocationSite`\n4. **Metadata Cleanup**: Remove allocation metadata and mark as freed to detect double-free errors\n5. **Leak Prevention**: Update leak detection heuristics based on allocation age and frequency patterns\n\n#### Memory Data Structures and Flow\n\nThe memory tracking system maintains several interconnected data structures that provide different analytical perspectives:\n\n| Data Structure | Purpose | Update Frequency | Memory Overhead |\n|----------------|---------|------------------|-----------------|\n| **Active Allocations Map** | Track live allocations | Every malloc/free | 64 bytes per allocation |\n| **Allocation Sites Index** | Aggregate by call stack | Every malloc | 256 bytes per unique site |\n| **Memory Timeline** | Historical usage patterns | Every 100ms | 32 bytes per snapshot |\n| **Leak Candidates List** | Potential memory leaks | Every leak scan | 128 bytes per suspected leak |\n\n**Allocation Site Aggregation**\n\nThe memory profiler groups allocations by their call stack signatures to identify allocation hotspots and patterns. This aggregation process enables developers to find the source code locations responsible for the most memory usage.\n\nThe site aggregation algorithm:\n\n1. **Stack Signature**: Generate a hash of the complete call stack using function addresses or resolved names\n2. **Site Lookup**: Find or create an `AllocationSite` entry for this signature\n3. **Statistics Update**: Increment counters for total allocations, bytes allocated, and peak usage\n4. **Lifetime Tracking**: Update the lifetime distribution histogram for allocations from this site\n5. **Growth Detection**: Compare current allocation rate to historical averages to detect growth patterns\n\n> **Decision: Call Stack Hashing Strategy**\n> - **Context**: Need to efficiently group allocations by identical call stacks without storing full stack copies\n> - **Options Considered**:\n>   - Hash raw addresses (fast but breaks with ASLR)\n>   - Hash resolved function names (slower but stable)\n>   - Hybrid approach with address-based fast path and name-based fallback\n> - **Decision**: Use hybrid hashing with resolved names as canonical signature\n> - **Rationale**: Provides stable grouping across program runs while maintaining performance for hot allocation sites\n> - **Consequences**: Requires symbol resolution during allocation tracking, adding 10-50μs overhead per unique site\n\n#### Leak Detection Algorithm\n\nMemory leak detection operates as a background analysis process that examines allocation patterns to identify problematic memory usage. The leak detector runs periodically (every 10-60 seconds) and applies multiple heuristics to classify allocations.\n\n**Leak Classification Heuristics**\n\nThe leak detection system applies several analytical techniques:\n\n| Heuristic | Description | Confidence Weight | False Positive Rate |\n|-----------|-------------|-------------------|-------------------|\n| **Age-Based** | Allocations older than threshold without free | 0.3 | High (long-lived data structures) |\n| **Growth Pattern** | Allocation sites with unbounded growth rates | 0.5 | Medium (caches and buffers) |\n| **Reference Analysis** | Allocations with no discoverable references | 0.8 | Low (requires heap scanning) |\n| **Frequency Anomaly** | Sites with sudden allocation rate increases | 0.4 | Medium (legitimate growth spurts) |\n\n**Leak Confidence Scoring**\n\nEach potential leak receives a confidence score between 0.0 and 1.0 based on multiple factors:\n\n1. **Allocation Age**: Longer-lived allocations receive higher leak scores, but with diminishing returns after 1 hour\n2. **Site Growth Rate**: Allocation sites showing exponential or linear growth patterns get elevated scores\n3. **Reachability**: Allocations not reachable from stack or global variables receive maximum scores\n4. **Similar Patterns**: Multiple allocations from the same site with identical behavior increase collective confidence\n5. **Suppression Rules**: User-defined patterns can reduce scores for known false positives\n\n**Memory Usage Timeline**\n\nThe memory profiler maintains a timeline of memory usage that enables trend analysis and growth pattern detection:\n\n1. **Snapshot Collection**: Every 100ms, capture current memory usage statistics including heap size, allocation rate, and fragmentation\n2. **Trend Analysis**: Apply sliding window analysis to detect growth trends, allocation spikes, and usage plateaus\n3. **Anomaly Detection**: Flag unusual patterns like sudden memory spikes or allocation rate changes\n4. **Correlation Analysis**: Associate memory usage changes with specific allocation sites and code paths\n\n### Output Formats and APIs\n\nThe profiler system supports multiple output formats and integration APIs to accommodate different analysis workflows and external tooling. The output system operates as the final stage of both profiling pipelines and must handle format conversion, data serialization, and external tool compatibility.\n\n#### Primary Output Formats\n\nThe profiler generates several output formats optimized for different use cases:\n\n| Format | Primary Use Case | File Extension | Size (typical) | Generation Time |\n|--------|------------------|----------------|----------------|-----------------|\n| **Interactive SVG** | Developer analysis | `.svg` | 500KB - 5MB | 100-500ms |\n| **Folded Stack Format** | Tool interoperability | `.folded` | 100KB - 1MB | 10-50ms |\n| **JSON Profile Data** | Programmatic analysis | `.json` | 1MB - 10MB | 50-200ms |\n| **Memory Report HTML** | Leak analysis | `.html` | 200KB - 2MB | 200-800ms |\n| **Raw Sample Data** | Custom processing | `.samples` | 10MB - 100MB | 20-100ms |\n\n**Interactive SVG Flame Graphs**\n\nThe SVG flame graph format serves as the primary visualization output for performance analysis. These files embed interactive JavaScript that enables zoom, search, and tooltip functionality without requiring external dependencies.\n\nSVG flame graph structure:\n\n1. **Document Header**: SVG dimensions, viewport settings, and embedded CSS styles for consistent appearance\n2. **Rectangle Elements**: Each `<rect>` element represents a function call with position, size, and color encoding\n3. **Text Labels**: Function names positioned within rectangles, with truncation handling for narrow functions\n4. **Interactive Script**: Embedded JavaScript handling mouse events, zoom operations, and search highlighting\n5. **Metadata Comments**: Profiling session information, sample counts, and generation parameters embedded as XML comments\n\nThe interactive features include:\n\n- **Click Zoom**: Clicking any rectangle zooms to show that function as the root with proportional child scaling\n- **Reset View**: Double-click background to return to full flame graph view\n- **Text Search**: Search box highlights matching function names with yellow background\n- **Hover Tooltips**: Display full function name, sample count, and percentage for truncated labels\n- **Permalink Generation**: URL fragments preserve zoom state for sharing specific flame graph views\n\n**Folded Stack Format**\n\nThe folded stack format provides a compact text representation that's compatible with external flame graph tools and enables custom analysis scripting:\n\n```\nmain;parse_config;json_parse;malloc 423\nmain;parse_config;json_parse;strdup 156  \nmain;process_data;hash_compute;sha256_init 234\nmain;process_data;hash_compute;sha256_update 1847\nmain;process_data;hash_compute;sha256_final 089\n```\n\nEach line contains:\n- **Call Stack Path**: Semicolon-separated function names from root to leaf\n- **Sample Count**: Number of times this exact call path was observed during profiling\n- **Optional Metadata**: Additional fields like module names or source locations can be appended\n\n**JSON Profile Data**\n\nThe JSON format provides complete profiling data in a structured format suitable for programmatic analysis and integration with performance monitoring systems:\n\n```json\n{\n  \"profiling_session\": {\n    \"start_time\": 1672531200.0,\n    \"duration_seconds\": 30.0,\n    \"target_process\": \"my_application\",\n    \"sampling_frequency\": 100,\n    \"total_samples\": 3000\n  },\n  \"flame_tree\": {\n    \"function_name\": \"main\",\n    \"sample_count\": 3000,\n    \"self_count\": 45,\n    \"children\": [...]\n  },\n  \"hot_functions\": [...],\n  \"memory_profile\": {...}\n}\n```\n\n**Memory Report HTML**\n\nMemory profiling generates comprehensive HTML reports that combine allocation analysis, leak detection, and usage trends in a single document:\n\n1. **Executive Summary**: Top allocation sites, total memory usage, and leak count overview\n2. **Allocation Hotspots**: Table of functions allocating the most memory with stack traces\n3. **Memory Leaks**: Detailed leak reports with confidence scores and recommended fixes\n4. **Usage Timeline**: Interactive charts showing memory usage over time\n5. **Allocation Patterns**: Analysis of allocation size distributions and lifetime patterns\n\n#### API Integration Points\n\nThe profiler provides several API integration mechanisms for embedding profiling capabilities in larger systems:\n\n**Python API Interface**\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `profile_process()` | `pid: int, duration: float` | `Profile` | Collect samples from running process |\n| `profile_function()` | `func: callable, *args` | `Profile` | Profile single function execution |\n| `load_profile()` | `filename: str` | `Profile` | Load previously saved profile data |\n| `generate_flame_graph()` | `profile: Profile, output: str` | `None` | Generate SVG flame graph file |\n| `detect_memory_leaks()` | `profile: Profile` | `List[MemoryLeak]` | Run leak detection analysis |\n| `export_folded_stacks()` | `profile: Profile` | `str` | Convert to folded stack format |\n\n**Configuration API**\n\nThe profiler accepts configuration through multiple channels:\n\n| Configuration Source | Priority | Format | Use Case |\n|---------------------|----------|---------|----------|\n| **Command Line Arguments** | Highest | `--sampling-freq=100` | Interactive profiling sessions |\n| **Configuration File** | Medium | JSON/YAML | Reproducible profiling setups |\n| **Environment Variables** | Low | `PROFILER_FREQ=100` | Container and CI environments |\n| **Programmatic API** | Highest | `ProfilerConfig` object | Embedded profiling |\n\n**External Tool Integration**\n\nThe profiler supports integration with external performance analysis tools through standard interfaces:\n\n| Integration | Interface | Data Flow | Benefits |\n|-------------|-----------|-----------|----------|\n| **perf Integration** | Import perf.data files | External → Profiler | Leverage hardware counters |\n| **Grafana Dashboard** | Prometheus metrics export | Profiler → External | Real-time monitoring |\n| **FlameGraph Scripts** | Folded stack format | Profiler → External | Brendan Gregg's toolchain |\n| **IDE Plugins** | JSON API over HTTP | Bidirectional | In-editor performance analysis |\n\n> **Design Philosophy**: The output system emphasizes **format interoperability** over proprietary formats. This decision enables integration with existing performance toolchains while providing native visualizations for immediate analysis.\n\n#### Data Export Pipeline\n\nThe output generation pipeline operates as a final transformation stage that converts internal profiler data structures into external formats:\n\n1. **Data Validation**: Verify profile completeness and consistency before export\n2. **Format Selection**: Choose appropriate output format based on user requirements and data characteristics\n3. **Template Processing**: Apply formatting templates and styling for human-readable outputs\n4. **Optimization**: Compress data, remove redundant information, and optimize for target file size\n5. **Metadata Injection**: Add profiling session information, generation timestamps, and tool versions\n6. **File Generation**: Write formatted output to specified destination with atomic operations\n\n**Performance Considerations**\n\nOutput generation performance varies significantly by format:\n\n- **SVG Generation**: Dominated by coordinate calculations and JavaScript embedding (100-500ms for 10K samples)\n- **JSON Export**: Limited by serialization overhead and pretty-printing (50-200ms for 10K samples)\n- **Folded Format**: Fastest export due to simple text generation (10-50ms for 10K samples)\n- **HTML Reports**: Slowest due to template processing and embedded charts (200-800ms for complex reports)\n\n![Sampling Sequence](./diagrams/sampling-sequence.svg)\n\n### Implementation Guidance\n\nThis implementation guidance provides concrete code structures and technology recommendations for building the profiler data pipeline and output systems.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **Pipeline Orchestration** | Python threading with Queue | AsyncIO with aiofiles |\n| **Data Serialization** | JSON with built-in library | MessagePack or Protocol Buffers |\n| **SVG Generation** | String templating | XML library with DOM manipulation |\n| **Memory Interposition** | ctypes with LD_PRELOAD | Custom C extension module |\n| **Symbol Resolution** | pyelftools library | Custom ELF parser with mmap |\n| **Interactive Features** | Embedded JavaScript | WebAssembly for complex operations |\n\n#### Recommended File Structure\n\n```\nprofiler/\n  src/\n    profiler/\n      pipeline/\n        __init__.py\n        sampler.py           ← Signal-based stack sampling\n        symbolizer.py        ← Address to symbol resolution  \n        aggregator.py        ← Stack folding and tree building\n        visualizer.py        ← SVG flame graph generation\n        memory_tracker.py    ← Allocation interception\n      data/\n        __init__.py\n        structures.py        ← Core data classes (Sample, StackFrame, etc.)\n        buffers.py          ← Thread-safe ring buffers\n        cache.py            ← Symbol and metadata caching\n      output/\n        __init__.py\n        formats.py          ← Export format implementations\n        svg_generator.py    ← Interactive SVG creation\n        report_generator.py ← HTML memory reports\n      utils/\n        __init__.py\n        elf_parser.py       ← Symbol table parsing utilities\n        signal_handling.py  ← Async-safe signal operations\n  tests/\n    test_pipeline.py\n    test_memory_tracking.py\n    test_output_formats.py\n  examples/\n    basic_profiling.py\n    memory_leak_demo.py\n```\n\n#### Core Pipeline Infrastructure\n\n**Complete Pipeline Coordinator**\n\n```python\nimport threading\nimport queue\nimport time\nfrom typing import Optional, List, Dict, Any\nfrom dataclasses import dataclass, field\nfrom concurrent.futures import ThreadPoolExecutor\n\n@dataclass\nclass PipelineStats:\n    \"\"\"Statistics for monitoring pipeline performance and health.\"\"\"\n    samples_collected: int = 0\n    samples_symbolized: int = 0\n    samples_aggregated: int = 0\n    dropped_samples: int = 0\n    symbol_cache_hits: int = 0\n    symbol_cache_misses: int = 0\n    processing_errors: int = 0\n    last_error: Optional[str] = None\n    pipeline_start_time: float = field(default_factory=time.time)\n    \n    def get_processing_rate(self) -> float:\n        \"\"\"Calculate samples processed per second since pipeline start.\"\"\"\n        elapsed = time.time() - self.pipeline_start_time\n        return self.samples_collected / elapsed if elapsed > 0 else 0.0\n    \n    def get_error_rate(self) -> float:\n        \"\"\"Calculate error rate as percentage of total samples.\"\"\"\n        total = self.samples_collected + self.processing_errors\n        return (self.processing_errors / total * 100.0) if total > 0 else 0.0\n\nclass ProfilerPipeline:\n    \"\"\"\n    Coordinates the complete profiling pipeline from sampling to output generation.\n    Manages concurrent processing stages with proper error handling and backpressure.\n    \"\"\"\n    \n    def __init__(self, config: ProfilerConfig):\n        self.config = config\n        self.stats = PipelineStats()\n        \n        # Inter-stage communication queues with bounded capacity\n        self.sample_queue = queue.Queue(maxsize=10000)\n        self.symbolized_queue = queue.Queue(maxsize=5000)\n        self.aggregated_queue = queue.Queue(maxsize=1000)\n        \n        # Pipeline components (imported from respective modules)\n        self.sampler = StackSampler(config.sampling)\n        self.symbolizer = AddressSymbolizer(config.symbols)\n        self.aggregator = StackAggregator()\n        self.visualizer = FlameGraphGenerator(config.visualization)\n        \n        # Control flags and synchronization\n        self.is_running = False\n        self.shutdown_event = threading.Event()\n        self.stage_threads: List[threading.Thread] = []\n        \n    def start_profiling(self, target_pid: int, duration_seconds: float) -> None:\n        \"\"\"\n        Start the complete profiling pipeline for specified target and duration.\n        \n        Args:\n            target_pid: Process ID to profile\n            duration_seconds: How long to collect samples\n        \"\"\"\n        # TODO 1: Validate target process exists and is accessible\n        # TODO 2: Start sampling thread with configured frequency and target PID\n        # TODO 3: Start symbolization worker thread pool (2-4 threads)\n        # TODO 4: Start aggregation thread for real-time stack folding\n        # TODO 5: Set up shutdown timer for specified duration\n        # TODO 6: Initialize all pipeline queues and reset statistics\n        pass\n        \n    def stop_profiling(self) -> Profile:\n        \"\"\"\n        Stop profiling pipeline and return collected profile data.\n        \n        Returns:\n            Complete Profile object with all processed samples\n        \"\"\"\n        # TODO 1: Signal all stages to stop processing new data\n        # TODO 2: Wait for queues to drain with reasonable timeout\n        # TODO 3: Join all worker threads to ensure clean shutdown\n        # TODO 4: Collect final statistics and validate data consistency\n        # TODO 5: Build and return complete Profile object\n        # Hint: Use shutdown_event and queue.join() for graceful shutdown\n        pass\n    \n    def _sampling_stage(self, target_pid: int) -> None:\n        \"\"\"Sampling stage worker that collects raw stack samples.\"\"\"\n        # TODO 1: Set up signal handler for SIGPROF using signal.signal()\n        # TODO 2: Configure interval timer with configured frequency\n        # TODO 3: Enter sampling loop until shutdown_event is set\n        # TODO 4: Handle sampling errors gracefully and update statistics\n        # TODO 5: Place samples in sample_queue with timeout handling\n        pass\n    \n    def _symbolization_stage(self) -> None:\n        \"\"\"Symbolization stage worker that resolves addresses to function names.\"\"\"\n        # TODO 1: Pull batches of samples from sample_queue \n        # TODO 2: Extract unique addresses to minimize symbol lookup overhead\n        # TODO 3: Resolve addresses using symbolizer with caching\n        # TODO 4: Update samples with resolved function names and line numbers\n        # TODO 5: Place symbolized samples in symbolized_queue\n        # TODO 6: Handle symbol resolution errors by marking frames as unresolved\n        pass\n    \n    def _aggregation_stage(self) -> None:\n        \"\"\"Aggregation stage worker that builds flame graph tree structure.\"\"\"\n        # TODO 1: Pull symbolized samples from symbolized_queue\n        # TODO 2: Process each sample through stack aggregation algorithm\n        # TODO 3: Update flame tree nodes with sample counts\n        # TODO 4: Handle memory pressure by periodically compacting tree\n        # TODO 5: Place intermediate results in aggregated_queue for visualization\n        pass\n```\n\n**Thread-Safe Sample Buffer**\n\n```python\nimport threading\nfrom collections import deque\nfrom typing import List, Optional\nimport time\n\nclass RingBuffer:\n    \"\"\"\n    Thread-safe ring buffer optimized for high-frequency sample collection.\n    Implements lock-free operations where possible for minimal overhead.\n    \"\"\"\n    \n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.buffer = deque(maxlen=capacity)\n        self.lock = threading.RLock()  # Allow recursive locking\n        self.dropped_count = 0\n        self.total_added = 0\n        \n    def add_sample(self, sample: Sample) -> bool:\n        \"\"\"\n        Add sample to buffer, dropping oldest if at capacity.\n        \n        Returns:\n            True if sample was added, False if dropped due to errors\n        \"\"\"\n        # TODO 1: Validate sample has required fields (timestamp, stack_frames)\n        # TODO 2: Acquire buffer lock with timeout to prevent blocking\n        # TODO 3: Add sample to deque (automatically evicts oldest if full)\n        # TODO 4: Update statistics counters atomically\n        # TODO 5: Return success status\n        # Hint: Use with self.lock: for automatic lock management\n        pass\n    \n    def get_samples(self, max_count: int) -> List[Sample]:\n        \"\"\"\n        Extract up to max_count samples from buffer for processing.\n        \n        Args:\n            max_count: Maximum number of samples to extract\n            \n        Returns:\n            List of samples removed from buffer (may be fewer than max_count)\n        \"\"\"\n        # TODO 1: Acquire buffer lock \n        # TODO 2: Calculate actual extraction count (min of max_count and buffer size)\n        # TODO 3: Extract samples from left side of deque (oldest first)\n        # TODO 4: Return extracted samples as list\n        # Hint: Use popleft() in loop or convert to list and clear portion\n        pass\n    \n    def get_stats(self) -> BufferStats:\n        \"\"\"Get current buffer statistics for monitoring.\"\"\"\n        # TODO 1: Create BufferStats object with current metrics\n        # TODO 2: Include total_added, dropped_count, current size\n        # TODO 3: Calculate buffer utilization percentage\n        # TODO 4: Return statistics object\n        pass\n```\n\n#### Memory Tracking Infrastructure\n\n**Complete Allocation Tracker with Interposition**\n\n```python\nimport ctypes\nimport ctypes.util\nfrom typing import Dict, Optional, Set\nimport threading\nimport hashlib\nimport traceback\nimport atexit\n\nclass AllocationTracker:\n    \"\"\"\n    Memory allocation tracker using function interposition to monitor heap usage.\n    Intercepts malloc, free, realloc calls and maintains allocation metadata.\n    \"\"\"\n    \n    def __init__(self):\n        # Load libc and get original allocation functions\n        libc_path = ctypes.util.find_library(\"c\")\n        self.libc = ctypes.CDLL(libc_path)\n        \n        # Function prototypes for original allocation functions  \n        self.original_malloc = self.libc.malloc\n        self.original_free = self.libc.free\n        self.original_realloc = self.libc.realloc\n        \n        # Allocation tracking data structures\n        self.active_allocations: Dict[int, Allocation] = {}\n        self.allocation_sites: Dict[str, AllocationSite] = {}\n        self.memory_timeline: List[MemorySnapshot] = []\n        \n        # Thread safety and recursion prevention\n        self.tracker_lock = threading.RLock()\n        self.in_tracker = threading.local()  # Prevent recursion\n        \n        # Register cleanup handler\n        atexit.register(self._generate_final_report)\n    \n    def intercept_malloc(self, size: int) -> int:\n        \"\"\"\n        Intercept malloc calls to track allocations.\n        \n        Args:\n            size: Requested allocation size in bytes\n            \n        Returns:\n            Pointer to allocated memory (as integer address)\n        \"\"\"\n        # TODO 1: Check for recursion using threading.local to prevent infinite loops\n        # TODO 2: Call original malloc to get actual memory\n        # TODO 3: Capture current call stack using traceback or inspect\n        # TODO 4: Calculate stack signature for allocation site tracking\n        # TODO 5: Create Allocation object with metadata\n        # TODO 6: Store allocation in active_allocations dict\n        # TODO 7: Update allocation site statistics\n        # TODO 8: Return original pointer unchanged\n        # Hint: Use getattr(self.in_tracker, 'active', False) to check recursion\n        pass\n    \n    def intercept_free(self, ptr: int) -> None:\n        \"\"\"\n        Intercept free calls to track deallocations.\n        \n        Args:\n            ptr: Pointer being freed (as integer address)  \n        \"\"\"\n        # TODO 1: Call original free first to avoid use-after-free\n        # TODO 2: Look up allocation metadata in active_allocations\n        # TODO 3: If found, calculate allocation lifetime\n        # TODO 4: Update allocation site lifetime statistics\n        # TODO 5: Remove allocation from active_allocations\n        # TODO 6: Mark allocation as freed with timestamp\n        # Hint: Handle case where ptr is not found (double free or untracked allocation)\n        pass\n        \n    def detect_leaks(self) -> List[MemoryLeak]:\n        \"\"\"\n        Analyze active allocations to detect potential memory leaks.\n        \n        Returns:\n            List of MemoryLeak objects with confidence scores\n        \"\"\"\n        # TODO 1: Iterate through all active allocations\n        # TODO 2: Calculate allocation age and check against thresholds\n        # TODO 3: Group allocations by allocation site for pattern analysis\n        # TODO 4: Apply leak detection heuristics (age, growth, reachability)\n        # TODO 5: Calculate confidence scores for each suspected leak\n        # TODO 6: Create MemoryLeak objects with detailed information\n        # TODO 7: Sort leaks by confidence score and return high-confidence leaks\n        pass\n    \n    def _calculate_stack_signature(self, stack_frames: List[str]) -> str:\n        \"\"\"Generate unique signature for call stack to identify allocation sites.\"\"\"\n        # TODO 1: Join stack frame strings with separator\n        # TODO 2: Calculate MD5 or SHA256 hash of joined string\n        # TODO 3: Return hash as hexadecimal string\n        # Hint: Use hashlib.md5(stack_string.encode()).hexdigest()\n        pass\n    \n    def _capture_call_stack(self) -> List[StackFrame]:\n        \"\"\"Capture current call stack for allocation site identification.\"\"\"\n        # TODO 1: Use traceback.extract_stack() to get current call stack\n        # TODO 2: Filter out tracker internal functions\n        # TODO 3: Convert traceback frames to StackFrame objects\n        # TODO 4: Resolve function names and file locations\n        # TODO 5: Return list of StackFrame objects\n        pass\n```\n\n#### Output Format Generation\n\n**SVG Flame Graph Generator**\n\n```python\nimport xml.etree.ElementTree as ET\nfrom typing import List, Tuple\nimport json\n\nclass InteractiveSVGGenerator:\n    \"\"\"\n    Generates interactive SVG flame graphs with embedded JavaScript for zoom and search.\n    Optimizes for file size and rendering performance.\n    \"\"\"\n    \n    def __init__(self, config: VisualizationConfig):\n        self.config = config\n        self.width = 1200  # Default canvas width\n        self.height = 600  # Default canvas height\n        self.colors = self._load_color_scheme(config.color_scheme)\n        \n    def generate_svg(self, flame_tree: FlameNode, output_path: str) -> None:\n        \"\"\"\n        Generate complete interactive SVG flame graph file.\n        \n        Args:\n            flame_tree: Root node of aggregated call tree\n            output_path: File path for generated SVG\n        \"\"\"\n        # TODO 1: Calculate coordinates for all visible rectangles\n        # TODO 2: Create SVG root element with viewbox and dimensions\n        # TODO 3: Add CSS styles for consistent appearance\n        # TODO 4: Generate rectangle elements with colors and positions\n        # TODO 5: Add text labels with truncation for narrow rectangles\n        # TODO 6: Embed interactive JavaScript for zoom and search\n        # TODO 7: Add metadata comments with profiling session info\n        # TODO 8: Write complete SVG to output file with pretty formatting\n        pass\n    \n    def calculate_coordinates(self, root: FlameNode) -> List[Rectangle]:\n        \"\"\"\n        Calculate pixel coordinates for all flame graph rectangles.\n        \n        Args:\n            root: Root flame graph node\n            \n        Returns:\n            List of Rectangle objects with calculated positions and sizes\n        \"\"\"\n        # TODO 1: Traverse flame tree depth-first to calculate total widths\n        # TODO 2: Calculate width scale factor (pixels per sample)\n        # TODO 3: Assign x-coordinates based on cumulative child widths\n        # TODO 4: Assign y-coordinates based on tree depth\n        # TODO 5: Filter out rectangles below minimum width threshold\n        # TODO 6: Create Rectangle objects with final pixel coordinates\n        # TODO 7: Assign colors based on configured color scheme\n        # Hint: Use recursive traversal to maintain parent-child positioning\n        pass\n    \n    def _embed_javascript(self) -> str:\n        \"\"\"Generate JavaScript code for interactive features.\"\"\"\n        # TODO 1: Create zoom functionality for click-to-zoom behavior\n        # TODO 2: Implement search highlighting with text matching\n        # TODO 3: Add tooltip display for hover events\n        # TODO 4: Include reset view functionality\n        # TODO 5: Add keyboard shortcuts for common operations\n        # TODO 6: Return complete JavaScript as string for embedding\n        pass\n```\n\n#### Milestone Checkpoints\n\n**After implementing the basic pipeline (Milestones 1-2):**\n```bash\npython -m profiler.examples.basic_profiling --pid 1234 --duration 10\n```\nExpected output:\n- Console shows sampling rate and symbol resolution progress\n- Generates `profile_1234.svg` with basic flame graph\n- Symbol cache hit rate should exceed 80% for typical programs\n\n**After implementing memory tracking (Milestone 4):**\n```bash\nLD_PRELOAD=./profiler/memory_tracker.so python memory_hungry_app.py\n```\nExpected behavior:\n- Memory report generated showing top allocation sites\n- Leak detection identifies allocations without matching frees\n- Timeline shows memory usage growth patterns\n\n**Integration testing:**\n```bash\npython -m pytest tests/test_pipeline.py -v\n```\nExpected test results:\n- All pipeline stages process samples without data loss\n- Error handling gracefully manages symbol resolution failures\n- Memory tracking correctly associates allocations with call sites\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** All milestones (1-4) — robust error handling underpins reliable stack sampling, symbol resolution, flame graph generation, and memory profiling across all failure scenarios\n\n### Mental Model: The Safety Net System\n\nThink of error handling in a profiler like a comprehensive safety net system for a trapeze performance. Just as trapeze artists have multiple safety nets at different levels, primary nets to catch most falls, and emergency protocols when nets fail, our profiler must have layered error detection and recovery mechanisms. The primary safety nets catch common issues like missing symbols or failed signal delivery. Secondary nets handle more serious problems like corrupted debug information or allocation tracking failures. Emergency protocols ensure graceful degradation when multiple systems fail simultaneously, always prioritizing the stability of the target process being profiled.\n\nThe key insight is that profiler errors must never compromise the target application — we are observers, not participants, and our failures should be invisible to the observed system. This constraint shapes every aspect of our error handling strategy.\n\n### Sampling Error Scenarios\n\n**Stack sampling operates in a fundamentally hostile environment** — signal handlers with severe restrictions, racing against target process execution, and working with potentially corrupted or incomplete stack data. The **signal-based interruption** mechanism creates numerous failure modes that require sophisticated detection and recovery strategies.\n\n#### Signal Delivery Failures\n\nSignal delivery represents the most fundamental failure point in statistical sampling. When the kernel cannot deliver `SIGPROF` signals reliably, our sampling becomes incomplete or biased, leading to inaccurate profile results.\n\n| Failure Mode | Detection Strategy | Recovery Action | Impact on Profile Quality |\n|--------------|-------------------|-----------------|---------------------------|\n| Signal blocked by target | Monitor signal queue depth, detect missed intervals | Switch to alternative sampling method, warn user | High - creates blind spots in profile |\n| Signal handler crashed | Segmentation fault or illegal instruction in handler | Disable sampling, save partial results | Critical - profiling stops completely |\n| Signal delivery delayed | Compare expected vs actual sample timestamps | Adjust frequency estimation, flag timing issues | Medium - affects accuracy of timing data |\n| Target process in syscall | Detect kernel stack samples without user frames | Continue sampling, increase syscall visibility | Low - kernel time still captured |\n| Signal interrupted by another signal | Detect nested signal handler execution | Use signal masking, defer processing | Medium - may lose individual samples |\n\nThe most insidious failure mode occurs when signals are consistently delayed or dropped during specific execution patterns. For example, tight computational loops with disabled interrupts can create **sampling bias** where expensive code paths appear underrepresented in the profile results.\n\n**Signal Handler Safety Violations**\n\nSignal handlers operate under severe restrictions — they can only safely call **async-safe** functions. Violations of these restrictions cause unpredictable crashes or data corruption in the target process.\n\n| Unsafe Operation | Why It's Dangerous | Safe Alternative | Detection Method |\n|------------------|-------------------|------------------|------------------|\n| malloc/free calls | Non-reentrant, can deadlock on heap locks | Pre-allocated fixed-size buffers | Static analysis of handler code |\n| File I/O operations | May block or corrupt file descriptors | Lock-free ring buffer to separate thread | Monitor handler execution time |\n| Complex library calls | Unknown reentrancy, may call unsafe functions | Minimal processing, defer complex work | Code review and testing |\n| Floating point operations | May corrupt FPU state | Avoid FP math in signal context | Compiler warnings and analysis |\n| Dynamic memory allocation | Heap corruption in multi-threaded scenarios | Stack allocation or pre-allocated pools | Runtime detection of malloc calls |\n\n> **Critical Design Principle**: Signal handlers should do the absolute minimum work required to capture the stack state, then delegate all complex processing to a separate thread operating in normal execution context.\n\n#### Stack Unwinding Errors\n\n**Stack unwinding** reconstructs the call chain by following frame pointers or interpreting DWARF unwind information. Multiple failure modes can produce incomplete or incorrect call stacks.\n\n**Frame Pointer Chain Corruption**\n\nFrame pointer corruption creates the most common stack unwinding failures. The chain of frame pointers can be broken by compiler optimizations, corrupted memory, or non-standard calling conventions.\n\n| Corruption Type | Symptoms | Detection Logic | Recovery Strategy |\n|-----------------|----------|-----------------|-------------------|\n| NULL frame pointer | Stack trace truncated prematurely | Check for NULL before dereferencing | Accept truncated stack, flag as incomplete |\n| Circular frame pointer | Infinite loop in unwinding | Track visited addresses, detect cycles | Break cycle, report partial stack |\n| Invalid memory address | Segmentation fault during unwinding | Validate address ranges before access | Stop unwinding, use partial stack |\n| Optimized away frame pointer | Missing intermediate functions | Compare with DWARF info if available | Use DWARF unwinding as fallback |\n| Stack buffer overflow | Frame pointers point to corrupted data | Sanity check frame pointer values | Abort unwinding, flag security issue |\n\nThe unwinding algorithm must validate each frame pointer before dereferencing to prevent crashes in the signal handler:\n\n1. Check that the frame pointer falls within valid stack memory ranges for the thread\n2. Verify that the return address extracted from the frame appears in executable memory\n3. Ensure forward progress — each frame pointer must be greater than the previous\n4. Limit maximum stack depth to prevent infinite loops or excessive processing time\n5. Stop unwinding if any validation fails, preserving the partial stack captured so far\n\n**DWARF Unwinding Failures**\n\nDWARF-based unwinding provides more robust stack reconstruction but introduces additional failure modes related to debug information parsing and interpretation.\n\n| DWARF Issue | Error Symptoms | Detection Method | Fallback Strategy |\n|-------------|----------------|------------------|-------------------|\n| Missing .debug_frame section | No unwind info available | Check ELF section headers | Fall back to frame pointer unwinding |\n| Corrupted DWARF data | Parse errors or invalid opcodes | Validate DWARF structure during parsing | Skip to next frame or abort unwinding |\n| Unsupported DWARF version | Parser cannot interpret format | Check version field in section header | Use older parser version or skip |\n| Complex unwind expressions | Cannot evaluate CFA expressions | Monitor expression evaluation depth | Simplify expression or use approximation |\n| Inconsistent debug info | DWARF contradicts actual stack layout | Cross-validate with frame pointer data | Trust runtime data over debug info |\n\n> **Decision: Hybrid Unwinding Strategy**\n> - **Context**: Both frame pointer and DWARF unwinding have distinct failure modes and complementary strengths\n> - **Options Considered**: \n>   1. Frame pointer only (simple, fast, but unreliable with optimized code)\n>   2. DWARF only (complete, but complex and can fail with corrupted debug info)\n>   3. Hybrid approach using both methods with cross-validation\n> - **Decision**: Implement hybrid unwinding with frame pointer as primary method and DWARF as validation/fallback\n> - **Rationale**: Frame pointers provide fast, reliable unwinding for most cases, while DWARF catches optimized code and provides validation. Cross-validation detects corruption early.\n> - **Consequences**: Increased complexity but much higher reliability across different compilation scenarios\n\n#### Buffer Overflow and Sample Loss\n\nHigh-frequency sampling can overwhelm the sample collection buffers, leading to dropped samples and distorted profile results. The `RingBuffer` component handles overflow gracefully but requires monitoring to detect when sample loss becomes significant.\n\n| Overflow Scenario | Detection Metrics | Mitigation Strategy | Quality Impact |\n|-------------------|-------------------|-------------------|----------------|\n| Burst sampling | `dropped_count` increases rapidly | Increase buffer size, reduce frequency | Medium - may miss burst patterns |\n| Sustained overload | `total_added` >> samples processed | Add backpressure to sampling loop | High - systematic bias in results |\n| Memory pressure | Buffer allocation fails | Use fixed pre-allocated buffers | Low - graceful capacity limitation |\n| Processing lag | Symbolization cannot keep up | Separate processing into pipeline stages | Medium - increased latency |\n\nThe `BufferStats` structure tracks buffer health and enables adaptive frequency adjustment:\n\n| Metric | Calculation | Warning Threshold | Action Required |\n|--------|-------------|-------------------|-----------------|\n| Drop Rate | `dropped_count / total_added` | > 5% | Reduce sampling frequency or increase buffer size |\n| Fill Ratio | `current_buffer_size / max_buffer_size` | > 80% | Increase processing rate or buffer capacity |\n| Processing Lag | Time between sample capture and processing | > 100ms | Optimize symbol resolution or add parallelism |\n| Memory Usage | Total bytes in all buffers | > 100MB | Implement sample compression or streaming |\n\n### Symbol Resolution Failures\n\n**Symbol resolution** transforms raw instruction pointer addresses into meaningful function names and source locations. This process depends on external debug information and binary metadata, creating numerous failure modes that require graceful degradation strategies.\n\n#### Missing Debug Symbols\n\nThe most common symbol resolution failure occurs when debug symbols are stripped from binaries or unavailable in standard search paths. Applications deployed in production environments typically strip debug information to reduce binary size, making detailed profiling challenging.\n\n| Missing Symbol Type | Impact on Profiling | Detection Method | Graceful Degradation |\n|-------------------|-------------------|------------------|---------------------|\n| Function names | Raw addresses only | Symbol table parsing fails | Display addresses with module+offset |\n| Source file names | No file context | DWARF parsing returns empty | Show function name without file info |\n| Line numbers | No precise location | Line number table missing | Show function name and file only |\n| Inline function info | Inlining hidden | DWARF inline info absent | Report outermost function only |\n| Template specializations | Generic names | C++ demangling incomplete | Show mangled name with partial demangling |\n\nThe `SymbolCache` must handle symbol lookup failures elegantly while providing useful fallback information:\n\n| Failure Case | Cache Behavior | Fallback Display Format | User Experience |\n|--------------|----------------|------------------------|-----------------|\n| No symbol found | Cache miss result to avoid repeated lookups | `<unknown>+0x1234 [libfoo.so]` | Clear indication of missing symbol |\n| Partial symbol info | Cache available fields, mark incomplete | `malloc (libc.so.6)` | Useful but incomplete information |\n| Corrupted symbol data | Mark symbol as invalid, skip caching | `<corrupted>+0x5678 [binary]` | Safe fallback without crashes |\n| Address outside module | Detect invalid address range | `<invalid address 0x7fff1234>` | Clear error indication |\n\n**Address Space Layout Randomization (ASLR) Complications**\n\nASLR randomizes the load addresses of shared libraries and executables, requiring **load bias** calculation to map runtime addresses back to symbol table addresses. Incorrect bias calculations produce symbol lookup failures or incorrect symbol attribution.\n\n| ASLR Issue | Symptoms | Detection Logic | Correction Strategy |\n|------------|----------|-----------------|-------------------|\n| Incorrect load bias | Symbols offset by constant amount | Compare expected vs actual symbol addresses | Recalculate bias from runtime library mapping |\n| PIE binary handling | Main executable symbols not found | Main program addresses don't resolve | Parse /proc/pid/maps for executable base address |\n| Dynamic library reloading | Previously resolved symbols become invalid | Symbol addresses change between samples | Invalidate cache, reload symbol tables |\n| Nested address spaces | Container or VM address translation | Symbols resolve to wrong functions | Detect virtualization, adjust address mapping |\n\nThe `Module` structure tracks load-time information to handle ASLR correctly:\n\n| Module Field | Purpose | Update Trigger | Validation Method |\n|--------------|---------|----------------|-------------------|\n| `base_address` | Runtime load address of module | Library load/unload events | Cross-check with /proc/pid/maps |\n| `load_time` | When module was loaded | dlopen() interception | Compare with sample timestamps |\n| `build_id` | Unique identifier for binary version | Module registration | Match against symbol file build ID |\n| `architecture` | Target CPU architecture | Binary header parsing | Validate against current process architecture |\n\n#### Corrupted Debug Information\n\nDebug information can become corrupted due to build system errors, file system corruption, or incompatible debugging formats. Corrupted DWARF data causes parsing failures that must be detected and handled without crashing the profiler.\n\n**DWARF Parsing Errors**\n\nDWARF debug information uses a complex hierarchical format that can become corrupted in subtle ways. Robust parsing requires validation at multiple levels and graceful error recovery.\n\n| Corruption Type | Parse Error | Validation Check | Recovery Action |\n|-----------------|-------------|------------------|-----------------|\n| Invalid section headers | Cannot locate debug sections | Verify ELF section table integrity | Skip DWARF, use symbol table only |\n| Truncated debug data | Premature end of data | Check section size vs data consumed | Use partial data, mark as incomplete |\n| Invalid DWARF opcodes | Unknown instruction in unwind info | Validate opcode against DWARF standard | Skip invalid instruction, continue parsing |\n| Circular references | DIE references create loops | Track visited DIEs during traversal | Break cycle, mark incomplete |\n| Version mismatch | Unsupported DWARF version | Check version field in section header | Use compatible parser subset |\n\nThe symbol resolution pipeline implements defensive parsing with multiple validation layers:\n\n1. **ELF Structure Validation**: Verify section headers, string tables, and symbol table format before parsing\n2. **DWARF Header Validation**: Check compilation unit headers, version compatibility, and section boundaries  \n3. **Parse Tree Validation**: Detect circular references, invalid offsets, and malformed DIE hierarchies\n4. **Cross-Reference Validation**: Verify that address ranges and line number tables are consistent\n5. **Runtime Validation**: Confirm that resolved symbols produce reasonable results during profiling\n\n> **Decision: Defensive Parsing with Graceful Degradation**\n> - **Context**: Corrupted debug information can crash the profiler or produce misleading results, but partial information is often still valuable\n> - **Options Considered**:\n>   1. Strict parsing that fails fast on any corruption (reliable but loses all data)\n>   2. Permissive parsing that attempts to work around corruption (risky but preserves more data)\n>   3. Layered validation with graceful degradation (balanced approach)\n> - **Decision**: Implement layered validation that preserves partial information while marking quality levels\n> - **Rationale**: Partial profiling information is usually better than no information, but users need to understand data quality limitations\n> - **Consequences**: More complex parsing logic but higher reliability and better user experience under adverse conditions\n\n#### Symbol Cache Corruption\n\nThe `SymbolCache` maintains large amounts of metadata that can become corrupted due to memory errors, race conditions, or logic bugs. Cache corruption manifests as incorrect symbol resolution, crashes during lookup, or memory leaks.\n\n| Corruption Scenario | Symptoms | Detection Method | Recovery Strategy |\n|--------------------|----------|------------------|-------------------|\n| Hash table corruption | Lookups return wrong symbols | Cross-validate results with fresh lookups | Rebuild cache from scratch |\n| Memory overrun | Cache grows unboundedly | Monitor `cache_size_bytes` vs `max_cache_size` | Implement LRU eviction, cap growth |\n| Race condition | Inconsistent cache state | Detect concurrent modification patterns | Add fine-grained locking or lock-free structures |\n| Reference counting errors | Use-after-free or memory leaks | Track object lifecycle with debugging builds | Implement reference counting discipline |\n| Address mapping errors | Symbols resolve to wrong addresses | Validate resolved addresses against known good data | Flush cache, reload symbol tables |\n\n**Cache Health Monitoring**\n\nThe symbol cache includes comprehensive health monitoring to detect corruption early and trigger recovery actions before user-visible failures occur.\n\n| Health Metric | Calculation | Warning Threshold | Recovery Action |\n|---------------|-------------|-------------------|-----------------|\n| Hit Rate Degradation | `hit_count / (hit_count + miss_count)` | < 80% (normally 95%+) | Clear cache, warm with common symbols |\n| Cache Size Growth | `cache_size_bytes` growth rate | > 10MB/minute | Enable aggressive eviction |\n| Lookup Time Increase | Average time per `lookup_symbol()` call | > 100μs (normally < 10μs) | Rebuild cache with optimized structure |\n| Corruption Detection | Checksum validation of critical structures | Any checksum mismatch | Flush corrupted cache segment |\n\n### Memory Tracking Edge Cases\n\n**Memory profiling** operates through **function interposition**, intercepting allocation and deallocation calls to track heap usage patterns. This approach creates complex interactions with the target application's memory management, threading model, and error handling that require sophisticated edge case handling.\n\n#### Allocation Function Interposition Failures\n\nFunction interposition using `LD_PRELOAD` can fail in numerous ways that lead to incomplete or incorrect memory tracking. These failures often manifest as missing allocations, double-free detection errors, or crashes in the allocation tracking logic.\n\n**Interception Bypass Scenarios**\n\nApplications can bypass malloc interception through static linking, direct system calls, or alternative memory allocation mechanisms that don't go through the standard library functions.\n\n| Bypass Method | Detection Strategy | Tracking Workaround | Impact Assessment |\n|---------------|-------------------|-------------------|-------------------|\n| Static linking | Monitor for untracked allocations via heap growth | Hook mmap/brk syscalls directly | Medium - misses malloc details but tracks total heap |\n| Alternative allocators | Detect usage of tcmalloc, jemalloc, etc. | Hook alternative allocator APIs | High - completely missing allocation data |\n| Direct syscall usage | Monitor mmap/munmap system calls | Use ptrace or eBPF for syscall interception | Low - unusual in normal applications |\n| Stack allocations | Large stack usage without heap allocations | Monitor stack growth via /proc/pid/stat | Low - stack usage typically bounded |\n| Memory mapped files | mmap usage that bypasses malloc | Hook mmap family of functions | Medium - can represent significant memory usage |\n\n**Recursive Allocation Detection**\n\nThe allocation tracker itself needs memory for metadata storage, creating the risk of recursive malloc calls that can deadlock or cause infinite recursion. This represents one of the most dangerous failure modes in memory profiling.\n\n| Recursion Source | Risk Level | Prevention Method | Recovery Strategy |\n|------------------|------------|-------------------|-------------------|\n| Metadata allocation | High - immediate deadlock | Use thread-local state to detect recursion | Disable tracking for recursive calls |\n| Stack trace capture | Medium - can trigger symbol resolution | Pre-allocate stack trace buffers | Limit stack trace depth |\n| Hash table operations | High - dynamic resize triggers malloc | Use fixed-size hash tables or custom allocators | Fall back to simplified tracking |\n| Logging operations | Low - typically uses stack allocation | Avoid dynamic allocation in log paths | Disable logging during tracking |\n| Signal handler malloc | Critical - undefined behavior | Never allocate memory in signal handlers | Use lock-free data structures |\n\nThe `AllocationTracker` uses thread-local storage to prevent recursive tracking:\n\n| Thread-Local Field | Purpose | Critical Section | Recovery Behavior |\n|-------------------|---------|------------------|-------------------|\n| `in_tracker` | Recursion detection flag | Set during malloc interception | Skip tracking, allow original malloc |\n| `recursion_depth` | Track nested calls | Increment on entry, decrement on exit | Abort tracking if depth > 3 |\n| `buffer_offset` | Current position in pre-allocated buffer | Updated during metadata writes | Reset on buffer overflow |\n| `error_count` | Track allocation tracking failures | Increment on any error | Disable tracking if errors > 100 |\n\n#### Memory Leak Detection False Positives\n\nLeak detection algorithms must distinguish between genuine memory leaks and legitimate long-lived allocations. False positives create noise that obscures real issues, while false negatives allow actual leaks to go undetected.\n\n**Long-Lived vs Leaked Allocations**\n\nMany applications legitimately allocate memory that persists for the entire program lifetime. The leak detector must avoid flagging these allocations as leaks while still catching genuine problems.\n\n| Allocation Pattern | Leak Likelihood | Classification Logic | User Guidance |\n|-------------------|-----------------|---------------------|---------------|\n| Initialization phase allocations | Low - likely legitimate | Age > program_lifetime * 0.8 → not leak | Flag as \"program lifetime allocation\" |\n| Growing allocation sites | High - potential leak | `total_bytes` increasing over time → likely leak | Report growth rate and call stack |\n| Cache-like patterns | Medium - depends on bounds | Check if growth plateaus → cache, continues → leak | Monitor allocation rate over time |\n| Error handling allocations | Low - typically cleaned up | Correlate with error events → legitimate | Cross-check with exception handling |\n| Thread-local allocations | Medium - may persist per thread | Check thread lifetime vs allocation lifetime | Report per-thread statistics |\n\n**Suppression Rules and False Positive Management**\n\nProduction applications often have known allocations that appear as leaks but are intentional or unavoidable. A suppression system allows users to filter these known issues while preserving detection of new problems.\n\n| Suppression Type | Matching Logic | Configuration Format | Maintenance Strategy |\n|------------------|----------------|---------------------|----------------------|\n| Call stack pattern | Match function names in allocation stack | Regex pattern against folded stack | Version control suppression files |\n| Allocation size | Filter allocations of specific sizes | Size range or exact byte count | Regular review to prevent over-suppression |\n| Source location | Suppress leaks from specific code locations | File path and line number ranges | Update suppressions with code changes |\n| Time-based | Ignore leaks detected during startup/shutdown | Time window relative to program lifecycle | Adjust windows based on application behavior |\n| Thread-based | Suppress leaks from specific thread types | Thread name or creation stack pattern | Monitor for new thread types |\n\n> **Decision: Confidence-Based Leak Classification**\n> - **Context**: Binary leak/not-leak classification produces too many false positives and negatives for practical use\n> - **Options Considered**:\n>   1. Binary classification (definite leak or not leak)\n>   2. Three-tier system (definite, possible, unlikely)\n>   3. Continuous confidence score with user-configurable thresholds\n> - **Decision**: Implement confidence scoring with multiple evidence sources\n> - **Rationale**: Allows users to adjust sensitivity based on their tolerance for false positives vs false negatives\n> - **Consequences**: More complex implementation but much more practical for real-world usage\n\n#### Allocation Metadata Corruption\n\nThe allocation tracking system maintains metadata for every active allocation, creating a large amount of state that can become corrupted. Metadata corruption leads to incorrect leak detection, crashes during deallocation, or memory usage miscalculations.\n\n**Metadata Integrity Validation**\n\nEach allocation record includes validation information to detect corruption early and prevent cascading failures.\n\n| Validation Check | Implementation | Trigger Frequency | Recovery Action |\n|------------------|----------------|-------------------|-----------------|\n| Magic number validation | Store known pattern at beginning of metadata | Every metadata access | Mark allocation as corrupted, skip processing |\n| Checksum verification | CRC32 of allocation record fields | Periodic validation pass | Rebuild metadata from partial information |\n| Cross-reference validation | Verify allocation_id matches hash table key | During lookup operations | Remove inconsistent entries |\n| Range validation | Check that allocation addresses fall within heap | Before deallocation processing | Flag as potential corruption |\n| Thread ID validation | Verify thread_id corresponds to known thread | During thread-local operations | Update with current thread or mark invalid |\n\n**Metadata Storage Corruption Recovery**\n\nWhen metadata storage becomes corrupted, the tracker must continue operating while minimizing data loss and preventing crashes.\n\n| Corruption Scenario | Detection Method | Immediate Response | Long-term Recovery |\n|-------------------|------------------|-------------------|-------------------|\n| Hash table corruption | Lookup operations return invalid data | Switch to linear search through backup storage | Rebuild hash table from valid entries |\n| Memory pool corruption | Allocation of new metadata fails | Use emergency allocation pool | Compact and defragment memory pool |\n| Index corruption | Cannot locate allocation records | Scan all allocation entries sequentially | Rebuild index from allocation metadata |\n| Thread synchronization corruption | Lock operations fail or deadlock | Use lock-free fallback operations | Reset synchronization primitives |\n\n![Error Detection and Recovery](./diagrams/error-handling-flow.svg)\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Ignoring Signal Handler Safety**\nSignal handlers have severe restrictions on what functions they can safely call. Calling malloc, printf, or any non-async-safe function from a signal handler can cause deadlocks or crashes in the target process. The solution is to do minimal work in the signal handler — just capture the stack state and defer all complex processing to a separate thread.\n\n⚠️ **Pitfall: Not Handling Stripped Binaries**\nProduction binaries often have debug symbols stripped to reduce size. Attempting to parse DWARF information from stripped binaries will fail. Always check for the presence of debug sections before attempting to parse them, and provide graceful fallback to symbol table information or address+offset display.\n\n⚠️ **Pitfall: Recursive Malloc in Allocation Tracking**\nThe allocation tracker needs memory to store metadata about allocations, but calling malloc from the malloc hook creates infinite recursion. Use thread-local flags to detect recursion and either use pre-allocated buffers or temporarily disable tracking for the tracker's own allocations.\n\n⚠️ **Pitfall: Assuming Symbol Lookup Always Succeeds**\nSymbol resolution can fail for many reasons — missing debug info, ASLR complications, corrupted data. Always have fallback display formats that show addresses and module information even when symbol names cannot be resolved. Users need to see something meaningful rather than blank entries or crashes.\n\n⚠️ **Pitfall: Not Validating Address Ranges During Stack Unwinding**\nStack unwinding can encounter corrupted frame pointers that point to invalid memory addresses. Dereferencing invalid pointers in a signal handler will crash the target process. Always validate that frame pointers fall within legitimate stack ranges before dereferencing them.\n\n⚠️ **Pitfall: Treating All Allocations as Potential Leaks**\nMany applications legitimately allocate memory that lives for the entire program duration. Flagging all long-lived allocations as leaks creates too much noise. Implement confidence scoring that considers allocation patterns, timing, and growth characteristics to distinguish likely leaks from legitimate long-lived allocations.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Error Detection | Basic exception handling with try/catch blocks | Comprehensive error codes with structured logging |\n| Signal Safety | Manual async-safe function checking | Static analysis tools for signal handler validation |\n| Corruption Detection | Simple checksums (CRC32) | ECC memory protection or hardware watchpoints |\n| Cache Validation | Periodic full cache rebuilds | Incremental validation with self-healing data structures |\n| Leak Detection | Simple reference counting | Machine learning classification with confidence scoring |\n\n#### Recommended File Structure\n\n```python\nprofiler/\n├── error_handling/\n│   ├── __init__.py                    ← Error handling module exports\n│   ├── sampling_errors.py             ← Stack sampling error recovery\n│   ├── symbol_errors.py               ← Symbol resolution error handling\n│   ├── memory_errors.py               ← Memory tracking error management\n│   ├── error_reporter.py              ← Centralized error reporting and logging\n│   └── recovery_strategies.py         ← Automated recovery implementations\n├── validation/\n│   ├── __init__.py                    ← Validation utilities\n│   ├── stack_validator.py             ← Stack unwinding validation\n│   ├── symbol_validator.py            ← Symbol resolution validation  \n│   ├── cache_validator.py             ← Cache integrity checking\n│   └── metadata_validator.py          ← Allocation metadata validation\n└── tests/\n    ├── test_error_scenarios.py        ← Error injection and recovery testing\n    ├── test_corruption_detection.py   ← Data corruption simulation\n    └── test_graceful_degradation.py   ← Degradation behavior verification\n```\n\n#### Infrastructure Starter Code\n\n**Complete Error Reporting System** (`error_reporter.py`):\n\n```python\nimport logging\nimport time\nimport threading\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom typing import Optional, Dict, List, Callable\nfrom collections import defaultdict, deque\n\nclass ErrorSeverity(Enum):\n    \"\"\"Error severity levels for prioritization and handling.\"\"\"\n    INFO = \"info\"\n    WARNING = \"warning\" \n    ERROR = \"error\"\n    CRITICAL = \"critical\"\n\nclass ErrorCategory(Enum):\n    \"\"\"Categories of profiler errors for classification.\"\"\"\n    SAMPLING = \"sampling\"\n    SYMBOL_RESOLUTION = \"symbol_resolution\"\n    MEMORY_TRACKING = \"memory_tracking\"\n    CACHE_CORRUPTION = \"cache_corruption\"\n    BUFFER_OVERFLOW = \"buffer_overflow\"\n\n@dataclass\nclass ErrorReport:\n    \"\"\"Complete error report with context and recovery information.\"\"\"\n    error_id: str\n    category: ErrorCategory\n    severity: ErrorSeverity\n    message: str\n    timestamp: float\n    context: Dict[str, any]\n    stack_trace: Optional[str]\n    recovery_action: Optional[str]\n    similar_error_count: int\n\nclass ErrorReporter:\n    \"\"\"Centralized error reporting and recovery coordination.\"\"\"\n    \n    def __init__(self, max_error_history: int = 1000):\n        self.max_error_history = max_error_history\n        self.error_history: deque = deque(maxlen=max_error_history)\n        self.error_counts: Dict[str, int] = defaultdict(int)\n        self.recovery_handlers: Dict[ErrorCategory, List[Callable]] = defaultdict(list)\n        self.suppression_rules: List[Dict] = []\n        self.lock = threading.RLock()\n        \n        # Setup logging\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n        self.logger = logging.getLogger('profiler.errors')\n    \n    def report_error(self, category: ErrorCategory, severity: ErrorSeverity, \n                    message: str, context: Optional[Dict] = None, \n                    stack_trace: Optional[str] = None) -> ErrorReport:\n        \"\"\"Report an error and trigger appropriate recovery actions.\"\"\"\n        with self.lock:\n            # Generate unique error ID based on category and message\n            error_signature = f\"{category.value}:{hash(message)}\"\n            self.error_counts[error_signature] += 1\n            \n            # Create error report\n            error_report = ErrorReport(\n                error_id=error_signature,\n                category=category,\n                severity=severity,\n                message=message,\n                timestamp=time.time(),\n                context=context or {},\n                stack_trace=stack_trace,\n                recovery_action=None,\n                similar_error_count=self.error_counts[error_signature]\n            )\n            \n            # Check suppression rules\n            if self._is_suppressed(error_report):\n                return error_report\n            \n            # Add to history\n            self.error_history.append(error_report)\n            \n            # Log error\n            self._log_error(error_report)\n            \n            # Trigger recovery if available\n            recovery_action = self._trigger_recovery(error_report)\n            error_report.recovery_action = recovery_action\n            \n            return error_report\n    \n    def register_recovery_handler(self, category: ErrorCategory, \n                                handler: Callable[[ErrorReport], str]):\n        \"\"\"Register a recovery handler for specific error categories.\"\"\"\n        with self.lock:\n            self.recovery_handlers[category].append(handler)\n    \n    def add_suppression_rule(self, rule: Dict):\n        \"\"\"Add rule to suppress specific error patterns.\"\"\"\n        with self.lock:\n            self.suppression_rules.append(rule)\n    \n    def get_error_statistics(self) -> Dict:\n        \"\"\"Get comprehensive error statistics for monitoring.\"\"\"\n        with self.lock:\n            total_errors = len(self.error_history)\n            if total_errors == 0:\n                return {\"total_errors\": 0}\n            \n            recent_errors = [e for e in self.error_history \n                           if time.time() - e.timestamp < 300]  # Last 5 minutes\n            \n            stats = {\n                \"total_errors\": total_errors,\n                \"recent_errors\": len(recent_errors),\n                \"error_rate\": len(recent_errors) / 300.0,  # Errors per second\n                \"categories\": defaultdict(int),\n                \"severities\": defaultdict(int),\n                \"top_errors\": []\n            }\n            \n            # Count by category and severity\n            for error in self.error_history:\n                stats[\"categories\"][error.category.value] += 1\n                stats[\"severities\"][error.severity.value] += 1\n            \n            # Top error types by frequency\n            top_errors = sorted(self.error_counts.items(), \n                              key=lambda x: x[1], reverse=True)[:10]\n            stats[\"top_errors\"] = top_errors\n            \n            return dict(stats)\n    \n    def _is_suppressed(self, error_report: ErrorReport) -> bool:\n        \"\"\"Check if error matches any suppression rules.\"\"\"\n        for rule in self.suppression_rules:\n            if self._matches_rule(error_report, rule):\n                return True\n        return False\n    \n    def _matches_rule(self, error_report: ErrorReport, rule: Dict) -> bool:\n        \"\"\"Check if error matches a specific suppression rule.\"\"\"\n        # Simple pattern matching - can be extended\n        if \"category\" in rule and error_report.category.value != rule[\"category\"]:\n            return False\n        if \"message_pattern\" in rule and rule[\"message_pattern\"] not in error_report.message:\n            return False\n        if \"max_count\" in rule and error_report.similar_error_count <= rule[\"max_count\"]:\n            return False\n        return True\n    \n    def _log_error(self, error_report: ErrorReport):\n        \"\"\"Log error with appropriate level and formatting.\"\"\"\n        log_message = f\"[{error_report.category.value}] {error_report.message}\"\n        if error_report.context:\n            log_message += f\" Context: {error_report.context}\"\n        \n        if error_report.severity == ErrorSeverity.CRITICAL:\n            self.logger.critical(log_message)\n        elif error_report.severity == ErrorSeverity.ERROR:\n            self.logger.error(log_message)\n        elif error_report.severity == ErrorSeverity.WARNING:\n            self.logger.warning(log_message)\n        else:\n            self.logger.info(log_message)\n    \n    def _trigger_recovery(self, error_report: ErrorReport) -> Optional[str]:\n        \"\"\"Trigger registered recovery handlers for the error category.\"\"\"\n        handlers = self.recovery_handlers.get(error_report.category, [])\n        if not handlers:\n            return None\n        \n        for handler in handlers:\n            try:\n                recovery_description = handler(error_report)\n                if recovery_description:\n                    self.logger.info(f\"Recovery action taken: {recovery_description}\")\n                    return recovery_description\n            except Exception as e:\n                self.logger.error(f\"Recovery handler failed: {e}\")\n        \n        return None\n\n# Global error reporter instance\nerror_reporter = ErrorReporter()\n```\n\n**Complete Validation Framework** (`validation/__init__.py`):\n\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import Any, List, Optional, Dict\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass ValidationResult(Enum):\n    \"\"\"Validation results with increasing severity.\"\"\"\n    VALID = \"valid\"\n    WARNING = \"warning\" \n    ERROR = \"error\"\n    CORRUPTED = \"corrupted\"\n\n@dataclass\nclass ValidationIssue:\n    \"\"\"Description of a validation problem found.\"\"\"\n    result: ValidationResult\n    message: str\n    context: Dict[str, Any]\n    fix_suggestion: Optional[str] = None\n\nclass Validator(ABC):\n    \"\"\"Base class for all data validation implementations.\"\"\"\n    \n    @abstractmethod\n    def validate(self, data: Any) -> List[ValidationIssue]:\n        \"\"\"Validate data and return list of issues found.\"\"\"\n        pass\n    \n    def is_valid(self, data: Any) -> bool:\n        \"\"\"Quick check if data passes validation.\"\"\"\n        issues = self.validate(data)\n        return all(issue.result in [ValidationResult.VALID, ValidationResult.WARNING] \n                  for issue in issues)\n    \n    def get_worst_result(self, data: Any) -> ValidationResult:\n        \"\"\"Get the most severe validation result.\"\"\"\n        issues = self.validate(data)\n        if not issues:\n            return ValidationResult.VALID\n        \n        # Return worst result found\n        severities = [ValidationResult.VALID, ValidationResult.WARNING, \n                     ValidationResult.ERROR, ValidationResult.CORRUPTED]\n        worst = ValidationResult.VALID\n        for issue in issues:\n            if severities.index(issue.result) > severities.index(worst):\n                worst = issue.result\n        return worst\n\ndef validate_address_range(address: int, min_addr: int, max_addr: int, \n                          name: str = \"address\") -> List[ValidationIssue]:\n    \"\"\"Validate that an address falls within expected range.\"\"\"\n    issues = []\n    \n    if address < min_addr or address > max_addr:\n        issues.append(ValidationIssue(\n            result=ValidationResult.ERROR,\n            message=f\"{name} 0x{address:x} outside valid range [0x{min_addr:x}, 0x{max_addr:x}]\",\n            context={\"address\": address, \"min_addr\": min_addr, \"max_addr\": max_addr},\n            fix_suggestion=\"Check address calculation or memory mapping\"\n        ))\n    \n    return issues\n\ndef validate_not_null(value: Any, name: str = \"value\") -> List[ValidationIssue]:\n    \"\"\"Validate that a value is not None or NULL.\"\"\"\n    issues = []\n    \n    if value is None or (isinstance(value, int) and value == 0):\n        issues.append(ValidationIssue(\n            result=ValidationResult.ERROR,\n            message=f\"{name} is null or zero\",\n            context={\"value\": value},\n            fix_suggestion=\"Initialize value before use\"\n        ))\n    \n    return issues\n\ndef validate_buffer_bounds(buffer_size: int, max_size: int, \n                          current_usage: int) -> List[ValidationIssue]:\n    \"\"\"Validate buffer size and usage are within bounds.\"\"\"\n    issues = []\n    \n    if buffer_size > max_size:\n        issues.append(ValidationIssue(\n            result=ValidationResult.ERROR,\n            message=f\"Buffer size {buffer_size} exceeds maximum {max_size}\",\n            context={\"buffer_size\": buffer_size, \"max_size\": max_size},\n            fix_suggestion=\"Increase max_size or reduce buffer requirements\"\n        ))\n    \n    if current_usage > buffer_size:\n        issues.append(ValidationIssue(\n            result=ValidationResult.CORRUPTED,\n            message=f\"Buffer usage {current_usage} exceeds size {buffer_size}\",\n            context={\"usage\": current_usage, \"size\": buffer_size},\n            fix_suggestion=\"Buffer overflow detected - check bounds checking\"\n        ))\n    \n    usage_ratio = current_usage / buffer_size if buffer_size > 0 else 0\n    if usage_ratio > 0.9:\n        issues.append(ValidationIssue(\n            result=ValidationResult.WARNING,\n            message=f\"Buffer {usage_ratio*100:.1f}% full, approaching capacity\",\n            context={\"usage_ratio\": usage_ratio},\n            fix_suggestion=\"Consider increasing buffer size or improving processing rate\"\n        ))\n    \n    return issues\n```\n\n#### Core Logic Skeleton Code\n\n**Sampling Error Recovery** (`sampling_errors.py`):\n\n```python\nfrom typing import Optional, List\nfrom dataclasses import dataclass\nimport signal\nimport time\nimport threading\nfrom ..data_model import Sample, StackFrame, RegisterContext, BufferStats\nfrom ..validation import Validator, ValidationIssue, ValidationResult\nfrom ..error_handling import error_reporter, ErrorCategory, ErrorSeverity\n\nclass StackValidator(Validator):\n    \"\"\"Validates stack frames and call chains for corruption.\"\"\"\n    \n    def __init__(self, min_stack_addr: int, max_stack_addr: int):\n        self.min_stack_addr = min_stack_addr\n        self.max_stack_addr = max_stack_addr\n    \n    def validate(self, stack_frames: List[StackFrame]) -> List[ValidationIssue]:\n        \"\"\"Validate entire call stack for consistency and corruption.\"\"\"\n        issues = []\n        \n        # TODO 1: Check that stack is not empty\n        # TODO 2: Validate each frame address is within stack bounds  \n        # TODO 3: Check for circular references in frame pointer chain\n        # TODO 4: Verify forward progress (each frame deeper in stack)\n        # TODO 5: Validate instruction pointers are in executable memory\n        # TODO 6: Check for suspiciously long call chains (> MAX_STACK_DEPTH)\n        # TODO 7: Detect frame pointer corruption patterns\n        \n        return issues\n\nclass SamplingErrorRecovery:\n    \"\"\"Handles errors and recovery during stack sampling operations.\"\"\"\n    \n    def __init__(self, config: 'SamplingConfig'):\n        self.config = config\n        self.consecutive_failures = 0\n        self.last_successful_sample = time.time()\n        self.signal_delivery_failures = 0\n        self.stack_validator = None  # Initialize with actual stack bounds\n        \n    def handle_signal_delivery_failure(self, target_pid: int, \n                                     expected_samples: int, \n                                     actual_samples: int) -> bool:\n        \"\"\"Handle failed or delayed signal delivery to target process.\"\"\"\n        \n        # TODO 1: Calculate signal delivery success rate\n        # TODO 2: Check if failure rate exceeds threshold (> 10%)\n        # TODO 3: Determine likely cause (blocked signals, process state, etc.)\n        # TODO 4: Report error with appropriate severity level\n        # TODO 5: Decide whether to continue sampling or abort\n        # TODO 6: Implement adaptive frequency reduction if needed\n        # TODO 7: Return True if recovery successful, False if should abort\n        \n        return False  # Placeholder\n    \n    def recover_from_stack_corruption(self, context: RegisterContext, \n                                    partial_stack: List[StackFrame]) -> Optional[List[StackFrame]]:\n        \"\"\"Attempt to recover usable stack information from corrupted unwind.\"\"\"\n        \n        # TODO 1: Validate existing frames in partial stack\n        # TODO 2: Attempt alternative unwinding method (DWARF vs frame pointer)\n        # TODO 3: Check if instruction pointer is in known good location\n        # TODO 4: Truncate stack at first sign of corruption\n        # TODO 5: Add synthetic frame for current function if possible\n        # TODO 6: Mark recovered stack with quality indicator\n        # TODO 7: Return best possible stack or None if completely unusable\n        \n        return None  # Placeholder\n    \n    def handle_buffer_overflow(self, buffer_stats: BufferStats) -> str:\n        \"\"\"Handle sample buffer overflow with appropriate recovery strategy.\"\"\"\n        \n        # TODO 1: Calculate current buffer utilization and drop rate\n        # TODO 2: Determine if overflow is transient burst or sustained overload\n        # TODO 3: Implement emergency sample dropping with priority preservation\n        # TODO 4: Reduce sampling frequency if sustained overload detected\n        # TODO 5: Report buffer health statistics to user\n        # TODO 6: Return description of recovery action taken\n        \n        return \"recovery_action_description\"  # Placeholder\n    \n    def validate_sample_integrity(self, sample: Sample) -> bool:\n        \"\"\"Validate that a captured sample contains reasonable data.\"\"\"\n        \n        # TODO 1: Check sample timestamp is reasonable (not in future, not too old)\n        # TODO 2: Validate thread_id and process_id are positive integers\n        # TODO 3: Ensure stack_frames list is not empty and not too long\n        # TODO 4: Validate each stack frame using StackValidator\n        # TODO 5: Check sample_weight is positive\n        # TODO 6: Return True only if sample passes all validation checks\n        \n        return False  # Placeholder\n```\n\n**Symbol Resolution Error Handling** (`symbol_errors.py`):\n\n```python\nfrom typing import Optional, Dict, List\nimport hashlib\nfrom ..data_model import Symbol, Module, SymbolCache, ELFSymbol\nfrom ..validation import Validator, ValidationIssue, ValidationResult\nfrom ..error_handling import error_reporter, ErrorCategory, ErrorSeverity\n\nclass SymbolErrorRecovery:\n    \"\"\"Handles symbol resolution failures and cache corruption recovery.\"\"\"\n    \n    def __init__(self, symbol_cache: SymbolCache):\n        self.symbol_cache = symbol_cache\n        self.fallback_display_formats = {\n            \"no_symbol\": \"<unknown>+0x{offset:x} [{module}]\",\n            \"partial_symbol\": \"{function} ({module})\", \n            \"corrupted\": \"<corrupted>+0x{offset:x} [{module}]\",\n            \"invalid_address\": \"<invalid address 0x{address:x}>\"\n        }\n        \n    def handle_missing_debug_symbols(self, module_path: str, \n                                   address: int) -> Optional[str]:\n        \"\"\"Generate fallback display when debug symbols are unavailable.\"\"\"\n        \n        # TODO 1: Check if module has any symbol table information\n        # TODO 2: Calculate offset within module for address\n        # TODO 3: Look for nearest symbol before address\n        # TODO 4: Format fallback string with available information\n        # TODO 5: Return formatted string or None if address is invalid\n        \n        return None  # Placeholder\n    \n    def detect_aslr_bias_error(self, module: Module, \n                             test_addresses: List[int]) -> Optional[int]:\n        \"\"\"Detect incorrect ASLR bias calculation and compute correct bias.\"\"\"\n        \n        # TODO 1: Try resolving test addresses with current bias\n        # TODO 2: If resolution fails, scan /proc/pid/maps for actual load address\n        # TODO 3: Calculate correct bias from runtime vs link-time addresses\n        # TODO 4: Validate new bias resolves test addresses correctly\n        # TODO 5: Return correct bias or None if unable to determine\n        \n        return None  # Placeholder\n    \n    def recover_from_cache_corruption(self, corruption_type: str) -> bool:\n        \"\"\"Recover symbol cache from detected corruption.\"\"\"\n        \n        # TODO 1: Determine extent of corruption (partial vs complete)\n        # TODO 2: Save any validated cache entries to backup storage\n        # TODO 3: Clear corrupted cache segments\n        # TODO 4: Reload symbol tables from original binary files\n        # TODO 5: Rebuild cache with saved entries and fresh data\n        # TODO 6: Validate rebuilt cache passes integrity checks\n        # TODO 7: Return True if recovery successful\n        \n        return False  # Placeholder\n    \n    def validate_dwarf_parsing(self, dwarf_data: bytes, \n                             expected_checksum: Optional[str] = None) -> ValidationResult:\n        \"\"\"Validate DWARF debug information before parsing.\"\"\"\n        \n        # TODO 1: Check DWARF section headers for correct magic numbers\n        # TODO 2: Validate version number is supported\n        # TODO 3: Verify section sizes match header declarations  \n        # TODO 4: Check for truncated data or premature EOF\n        # TODO 5: Validate optional checksum if provided\n        # TODO 6: Return validation result with severity level\n        \n        return ValidationResult.VALID  # Placeholder\n    \n    def generate_symbol_quality_report(self) -> Dict[str, any]:\n        \"\"\"Generate comprehensive report on symbol resolution quality.\"\"\"\n        \n        # TODO 1: Calculate symbol cache hit/miss rates\n        # TODO 2: Count symbols by resolution quality (complete, partial, missing)\n        # TODO 3: Identify modules with poor symbol coverage\n        # TODO 4: Report DWARF parsing success/failure rates\n        # TODO 5: List top addresses that failed resolution\n        # TODO 6: Return structured report dictionary\n        \n        return {}  # Placeholder\n```\n\n**Memory Tracking Error Management** (`memory_errors.py`):\n\n```python\nfrom typing import Optional, List, Set\nimport threading\nfrom ctypes import CDLL\nfrom ..data_model import Allocation, AllocationSite, MemoryLeak, LeakCategory\nfrom ..error_handling import error_reporter, ErrorCategory, ErrorSeverity\n\nclass AllocationTracker:\n    \"\"\"Tracks memory allocations with comprehensive error handling.\"\"\"\n    \n    def __init__(self):\n        self.active_allocations: Dict[int, Allocation] = {}\n        self.allocation_sites: Dict[str, AllocationSite] = {}\n        self.tracker_lock = threading.RLock()\n        self.in_tracker = threading.local()  # Recursion detection\n        self.error_counts = {\"recursion\": 0, \"corruption\": 0, \"overflow\": 0}\n        \n        # Initialize recursion detection\n        self.in_tracker.active = False\n        \n    def detect_recursive_malloc(self) -> bool:\n        \"\"\"Detect if we're already inside allocation tracking to prevent recursion.\"\"\"\n        \n        # TODO 1: Check thread-local recursion flag\n        # TODO 2: Return True if recursion detected\n        # TODO 3: Increment error counter for monitoring\n        \n        return False  # Placeholder\n    \n    def validate_allocation_metadata(self, allocation: Allocation) -> List[str]:\n        \"\"\"Validate allocation metadata for corruption or inconsistency.\"\"\"\n        \n        # TODO 1: Check allocation_id is positive and unique\n        # TODO 2: Validate size and actual_size are reasonable\n        # TODO 3: Check timestamp is not in future\n        # TODO 4: Validate thread_id exists and is positive  \n        # TODO 5: Check stack frames are properly formatted\n        # TODO 6: Return list of validation error messages\n        \n        return []  # Placeholder\n    \n    def recover_from_metadata_corruption(self, corrupted_allocations: Set[int]) -> int:\n        \"\"\"Recover from corrupted allocation metadata.\"\"\"\n        \n        # TODO 1: Remove clearly corrupted allocation records\n        # TODO 2: Attempt to reconstruct metadata from partial information\n        # TODO 3: Scan heap for allocations missing from tracking\n        # TODO 4: Update allocation site statistics after cleanup\n        # TODO 5: Reset corruption detection mechanisms\n        # TODO 6: Return number of allocations successfully recovered\n        \n        return 0  # Placeholder\n    \n    def classify_leak_confidence(self, allocation: Allocation, \n                                similar_leaks: int) -> float:\n        \"\"\"Calculate confidence score for potential memory leak.\"\"\"\n        \n        # TODO 1: Consider allocation age relative to program lifetime\n        # TODO 2: Check if allocation site shows growth pattern\n        # TODO 3: Look for similar allocations that were never freed\n        # TODO 4: Consider allocation size and frequency\n        # TODO 5: Check if allocation occurred during error handling\n        # TODO 6: Return confidence score between 0.0 and 1.0\n        \n        return 0.0  # Placeholder\n    \n    def handle_allocation_failure(self, size: int, stack_frames: List[StackFrame]) -> None:\n        \"\"\"Handle case where malloc succeeds but tracking allocation fails.\"\"\"\n        \n        # TODO 1: Log allocation failure with context information\n        # TODO 2: Attempt to allocate tracking metadata with backup method\n        # TODO 3: If backup fails, increment unknown allocation counter\n        # TODO 4: Consider disabling tracking if failure rate too high\n        # TODO 5: Report failure through error reporting system\n        \n        pass  # Placeholder\n```\n\n#### Milestone Checkpoints\n\n**Error Handling Validation Checkpoints:**\n\nAfter implementing error handling for each milestone:\n\n**Milestone 1 - Stack Sampling Error Handling:**\n- **Test Command**: `python -m pytest tests/test_sampling_errors.py -v`\n- **Expected Behavior**: \n  - Signal delivery failures detected and reported\n  - Stack corruption handled without crashing target process\n  - Buffer overflow triggers frequency reduction\n  - Sample validation rejects clearly corrupted data\n- **Manual Verification**:\n  - Run profiler on process with blocked signals → should report delivery failures\n  - Profile optimized binary with missing frame pointers → should gracefully degrade\n  - Set very high sampling frequency → should detect buffer overflow and adapt\n\n**Milestone 2 - Symbol Resolution Error Handling:**\n- **Test Command**: `python -m pytest tests/test_symbol_errors.py -v`\n- **Expected Behavior**:\n  - Missing debug symbols produce fallback display formats\n  - ASLR bias errors detected and corrected automatically  \n  - Cache corruption triggers rebuild without data loss\n  - DWARF parsing failures handled gracefully\n- **Manual Verification**:\n  - Profile stripped binary → should show `<unknown>+offset` format\n  - Profile with corrupted cache → should detect and recover\n  - Run with invalid symbol search paths → should report missing symbols\n\n**Milestone 3 - Flame Graph Error Handling:**\n- **Test Command**: `python -m pytest tests/test_flame_graph_errors.py -v`\n- **Expected Behavior**:\n  - Incomplete symbol resolution produces partial but usable flame graphs\n  - Coordinate calculation handles edge cases without crashes\n  - SVG generation continues with missing or corrupted data\n- **Manual Verification**:\n  - Generate flame graph with mostly missing symbols → should complete with fallback names\n  - Create flame graph with extremely deep call stacks → should handle without overflow\n\n**Milestone 4 - Memory Tracking Error Handling:**\n- **Test Command**: `python -m pytest tests/test_memory_errors.py -v`\n- **Expected Behavior**:\n  - Recursive malloc calls detected and handled safely\n  - Metadata corruption detected and recovered from\n  - Leak classification handles false positives appropriately\n- **Manual Verification**:\n  - Profile application with complex allocation patterns → should avoid recursion\n  - Inject metadata corruption → should detect and recover\n  - Run on application with legitimate long-lived allocations → should not flag as leaks\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | Diagnosis Method | Fix Strategy |\n|---------|--------------|------------------|--------------|\n| Profiler crashes target process | Unsafe signal handler operations | Check signal handler for non-async-safe calls | Use only async-safe functions, defer complex work |\n| Missing samples during CPU-intensive periods | Signal delivery blocked or delayed | Monitor signal delivery success rates | Increase signal priority, check target process state |\n| Symbol resolution returns wrong functions | Incorrect ASLR bias calculation | Cross-validate addresses with /proc/pid/maps | Recalculate load bias, update module base addresses |\n| Cache hit rate suddenly drops | Cache corruption or invalidation | Check cache integrity, validate stored symbols | Clear cache, rebuild from symbol tables |\n| Memory tracker causes infinite recursion | Malloc called from within malloc hook | Enable recursion detection logging | Use thread-local flags, pre-allocate metadata buffers |\n| Leak detection reports false positives | Legitimate long-lived allocations flagged | Analyze allocation patterns and lifetimes | Implement confidence scoring, add suppression rules |\n| Stack unwinding produces truncated stacks | Frame pointer corruption or missing info | Validate frame pointers before dereferencing | Add bounds checking, implement DWARF fallback |\n| Buffer overflow causes sample loss | Processing cannot keep up with sampling | Monitor buffer utilization and processing rates | Reduce sampling frequency, add processing parallelism |\n\n\n## Testing Strategy\n\n> **Milestone(s):** All milestones (1-4) — comprehensive testing strategy ensures reliable stack sampling, accurate symbol resolution, correct flame graph generation, and robust memory profiling across diverse runtime conditions\n\n### Mental Model: The Quality Assurance Laboratory\n\nThink of testing a profiler like running a medical laboratory that analyzes blood samples. Just as a lab needs multiple types of tests — unit tests for individual reagents, integration tests for complete diagnostic workflows, and validation tests against known medical conditions — our profiler testing strategy operates at multiple levels. Unit tests verify individual components work in isolation (like testing if a single reagent changes color correctly), integration tests ensure the complete profiling pipeline produces accurate results (like running a full blood panel), and milestone verification confirms each development stage delivers expected capabilities (like validating diagnostic accuracy against known patient conditions). The challenge is that unlike static blood samples, our profiler must accurately measure living, dynamic programs while introducing minimal measurement disturbance.\n\nThe testing strategy must address the **observer paradox** inherent in profiling tools: the act of measurement potentially changes the behavior being measured. This requires carefully designed test scenarios that validate profiler accuracy without introducing measurement artifacts that could mask real bugs or create false failures.\n\n### Unit Testing Approach\n\nUnit testing focuses on validating individual profiler components in isolation using controlled, deterministic test inputs. This approach eliminates external dependencies like signal delivery timing, symbol file availability, or target process behavior that could introduce non-deterministic test failures.\n\n#### Stack Sampling Component Testing\n\nThe `StackSampler` component requires careful unit testing because it operates through signal delivery and stack unwinding — inherently system-dependent operations. The testing strategy isolates core logic from system interactions by providing mock contexts and controlled stack configurations.\n\n| Test Category | Mock Component | Test Focus | Example Scenarios |\n|---------------|----------------|------------|-------------------|\n| Signal Context Extraction | Python signal frame | Register extraction accuracy | Valid frame pointer, null stack pointer, corrupted context |\n| Stack Frame Unwinding | Memory layout simulation | Frame pointer traversal | Deep recursion, leaf functions, corrupted frame chains |\n| Sample Buffer Management | Controlled sample injection | Buffer overflow handling | Capacity limits, concurrent access, sample ordering |\n| Timer Configuration | Mock timer interface | Frequency validation | Valid ranges, boundary conditions, frequency conversion |\n| Thread Safety | Concurrent test harness | Signal handler safety | Multiple threads sampling, signal delivery races |\n\nThe unit tests create synthetic stack configurations that represent common execution patterns: recursive function calls, deeply nested library calls, mixed user/kernel stacks, and edge cases like empty stacks or single-frame stacks. These controlled scenarios enable deterministic validation of stack unwinding logic without depending on actual program execution.\n\n```python\n# Example test data structure for controlled stack scenarios\nSYNTHETIC_STACKS = {\n    'simple_recursion': [\n        {'address': 0x400000, 'frame_pointer': 0x7fff1000, 'expected_function': 'main'},\n        {'address': 0x400100, 'frame_pointer': 0x7fff0f80, 'expected_function': 'recursive_func'},\n        {'address': 0x400120, 'frame_pointer': 0x7fff0f00, 'expected_function': 'recursive_func'}\n    ],\n    'library_calls': [\n        {'address': 0x400000, 'frame_pointer': 0x7fff1000, 'expected_function': 'main'},\n        {'address': 0x7f8000000, 'frame_pointer': 0x7fff0f80, 'expected_function': 'libc_function'},\n        {'address': 0x7f8000100, 'frame_pointer': 0x7fff0f00, 'expected_function': 'kernel_syscall'}\n    ]\n}\n```\n\n#### Symbol Resolution Component Testing\n\nThe `Symbolizer` component testing focuses on address-to-symbol mapping accuracy across different binary formats and debug information scenarios. Unit tests use crafted ELF files and symbol tables to validate parsing logic without depending on system-installed binaries.\n\n| Test Category | Mock Input | Validation Focus | Edge Cases |\n|---------------|------------|------------------|------------|\n| ELF Parsing | Minimal ELF binaries | Section header parsing | Corrupted headers, missing sections, malformed entries |\n| Symbol Table Loading | Crafted symbol tables | Address range calculation | Overlapping symbols, zero-size symbols, duplicate names |\n| DWARF Processing | Synthetic debug info | Line number mapping | Inlined functions, optimized code, missing line info |\n| Address Resolution | Known address sets | Lookup accuracy | Boundary addresses, unmapped regions, ASLR offsets |\n| Cache Management | Controlled lookup patterns | Hit/miss ratios | Cache eviction, concurrent access, memory pressure |\n\nThe unit testing approach generates minimal ELF files containing only essential sections needed for symbol resolution testing. This eliminates dependencies on specific system libraries while enabling comprehensive validation of parsing logic.\n\n> **Key Testing Insight**: Symbol resolution unit tests must validate both successful resolution paths and graceful failure handling. A robust profiler continues operating when encountering stripped binaries, corrupted debug information, or missing symbol files — common conditions in production environments.\n\n#### Flame Graph Generation Component Testing\n\nThe `FlameGraphGenerator` component testing validates stack aggregation algorithms and SVG coordinate calculation logic using deterministic sample sets. Unit tests focus on mathematical correctness of aggregation and layout algorithms rather than visual appearance.\n\n| Test Category | Input Data | Algorithm Validation | Expected Output |\n|---------------|------------|---------------------|-----------------|\n| Stack Aggregation | Synthetic sample sets | Tree construction accuracy | Correct node hierarchy, accurate sample counts |\n| Folded Stack Generation | Known call patterns | Text format compliance | Standard folded format, proper escaping, count accuracy |\n| Coordinate Calculation | Mock flame trees | Rectangle positioning | Non-overlapping rectangles, proportional widths, proper nesting |\n| Color Assignment | Various node types | Color scheme consistency | Deterministic colors, category mapping, contrast validation |\n| SVG Generation | Simple flame trees | XML structure validation | Valid SVG syntax, proper scaling, embedded JavaScript |\n\nThe unit testing strategy creates controlled sample distributions that exercise aggregation edge cases: single-sample stacks, identical call patterns with different frequencies, deeply nested call chains, and wide call trees with many siblings at each level.\n\n#### Memory Profiling Component Testing\n\nThe `AllocationTracker` component testing requires careful simulation of malloc/free patterns without actual memory allocation. Unit tests use mock allocation interfaces and controlled allocation sequences to validate tracking logic.\n\n| Test Category | Mock Interface | Tracking Validation | Leak Detection |\n|---------------|----------------|---------------------|----------------|\n| Allocation Recording | Fake malloc implementation | Metadata accuracy | Size tracking, stack capture, timestamp recording |\n| Deallocation Matching | Controlled free patterns | Allocation pairing | Matching allocation/deallocation pairs, orphaned frees |\n| Leak Classification | Synthetic allocation trees | Confidence scoring | Definite leaks, possible leaks, reachable allocations |\n| Growth Pattern Detection | Time-series allocation data | Trend analysis | Linear growth, exponential growth, periodic patterns |\n| Thread Safety | Concurrent allocation simulation | Race condition detection | Metadata corruption, double-free detection |\n\n> **Decision: Mock-Based Allocation Testing**\n> - **Context**: Memory profiling tests need to validate allocation tracking without actual heap operations that could interfere with test process memory management\n> - **Options Considered**: \n>   1. Mock malloc/free with fake pointer arithmetic\n>   2. Custom memory pool with real allocation tracking\n>   3. Process isolation with real malloc interception\n> - **Decision**: Mock malloc/free with controlled pointer generation\n> - **Rationale**: Enables deterministic test scenarios, eliminates memory management complications in test process, allows exhaustive edge case testing without heap fragmentation concerns\n> - **Consequences**: Tests validate tracking logic accuracy but require separate integration testing for real malloc interception behavior\n\n### Integration Testing\n\nIntegration testing validates the complete profiler pipeline using real target processes and actual system interactions. This testing layer ensures components work correctly together and handle realistic execution environments with proper signal delivery, symbol file parsing, and memory allocation patterns.\n\n#### End-to-End Profiling Pipeline Testing\n\nThe integration testing approach uses purpose-built test programs that exhibit known execution patterns, enabling validation of complete profiling accuracy from sample collection through flame graph generation.\n\n**Test Program Categories:**\n\n| Program Type | Execution Pattern | Expected Profile Characteristics | Validation Points |\n|--------------|-------------------|----------------------------------|-------------------|\n| CPU Intensive | Tight computation loops | High sample concentration in compute functions | Sample distribution accuracy, stack depth consistency |\n| I/O Heavy | File/network operations | Samples distributed across I/O and kernel functions | Kernel stack capture, blocking operation handling |\n| Memory Allocator | Intensive malloc/free patterns | Clear allocation hotspots, leak detection | Allocation site identification, leak classification accuracy |\n| Multi-threaded | Concurrent execution | Per-thread sample separation, shared code identification | Thread attribution, sampling fairness |\n| Dynamic Loading | Runtime library loading | Symbol resolution for loaded libraries | Dynamic symbol updates, ASLR handling |\n\nThe integration test harness executes these test programs under profiler control while monitoring both profiler behavior and test program execution characteristics. This dual monitoring approach detects measurement artifacts introduced by profiling overhead.\n\n**Sample Program: CPU Intensive Fibonacci Calculator**\n\nThis test program implements recursive Fibonacci calculation with known execution characteristics that enable validation of stack sampling accuracy and symbol resolution correctness.\n\n```python\n# Test program execution pattern\ndef fibonacci_test():\n    \"\"\"Test program with predictable call stack patterns\"\"\"\n    # Expected profile: 80% time in recursive_fibonacci\n    # Expected stack depth: 20-30 frames for fib(25)\n    # Expected call tree: main -> fibonacci_test -> recursive_fibonacci\n    return recursive_fibonacci(25)\n```\n\nThe integration test validates that profiler output matches expected execution characteristics: recursive_fibonacci should consume approximately 80% of samples, maximum stack depth should reach 25-30 frames, and the call tree hierarchy should reflect the recursive calling pattern.\n\n#### Real-World Program Profiling\n\nIntegration testing includes profiling actual applications with known performance characteristics to validate profiler accuracy in realistic scenarios. These tests use applications where performance bottlenecks are well-understood, enabling verification of profiler analysis correctness.\n\n| Application Type | Known Bottlenecks | Profiler Validation | Success Criteria |\n|------------------|-------------------|---------------------|------------------|\n| Web Server | Request parsing, database queries | Hotspot identification accuracy | Top functions match known bottlenecks |\n| Image Processor | Pixel manipulation loops, memory allocation | CPU and memory profile correlation | High allocation sites align with processing functions |\n| Database Engine | Index operations, buffer management | Mixed CPU/memory profiling | Lock contention and allocation patterns visible |\n| Scientific Computing | Mathematical libraries, vectorized operations | Deep call stacks, optimized code | SIMD functions identified, proper attribution |\n\nThe integration testing framework automatically profiles these applications under controlled workloads and compares profiler output against expected performance patterns. Automated validation checks verify that known performance bottlenecks appear prominently in flame graphs and allocation tracking identifies expected memory-intensive code paths.\n\n#### Cross-Platform Validation\n\nThe integration test suite validates profiler behavior across different operating system configurations, compiler toolchains, and runtime environments to ensure broad compatibility.\n\n**Platform Test Matrix:**\n\n| Platform | Compiler | Debug Info | Signal Support | Validation Focus |\n|----------|----------|------------|----------------|------------------|\n| Linux x86_64 | GCC | DWARF 4 | SIGPROF | Baseline functionality |\n| Linux ARM64 | GCC | DWARF 5 | SIGPROF | Architecture differences |\n| Linux x86_64 | Clang | DWARF 4 | SIGPROF | Compiler variations |\n| macOS x86_64 | Clang | DWARF 4 | SIGPROF | Darwin signal handling |\n| Linux (stripped) | GCC | None | SIGPROF | Graceful degradation |\n\nEach platform configuration runs the complete integration test suite to validate consistent profiler behavior across environments. Platform-specific tests verify proper handling of architectural differences like calling conventions, signal delivery mechanisms, and debug information formats.\n\n#### Performance Impact Measurement\n\nIntegration testing includes overhead measurement to ensure profiler operation remains within acceptable performance impact boundaries defined in project goals. The testing framework measures both profiler resource consumption and target application performance degradation.\n\n**Overhead Measurement Framework:**\n\n| Metric | Measurement Method | Acceptable Threshold | Recovery Action |\n|--------|-------------------|---------------------|-----------------|\n| CPU Overhead | Target process CPU time comparison | < 2% increase | Reduce sampling frequency |\n| Memory Overhead | Profiler process RSS measurement | < 50MB for typical workloads | Implement sample streaming |\n| Sample Loss Rate | Dropped samples vs. expected samples | < 1% under normal load | Increase buffer capacity |\n| Latency Impact | Request processing time measurement | < 5% increase for web workloads | Optimize signal handler |\n| Startup Overhead | Process initialization time | < 100ms additional startup time | Lazy symbol loading |\n\nThe integration test framework automatically measures these overhead metrics during profiling sessions and validates that measurements remain within acceptable bounds. Tests that exceed overhead thresholds trigger automated analysis to identify performance regression sources.\n\n> **Critical Integration Testing Principle**: Integration tests must validate profiler accuracy while simultaneously monitoring profiler impact on target processes. A profiler that produces accurate results but significantly alters program behavior fails to meet real-world usability requirements.\n\n### Milestone Verification Checkpoints\n\nMilestone verification provides structured validation points that confirm each development stage delivers expected functionality before proceeding to subsequent milestones. Each checkpoint includes automated testing, manual verification steps, and expected output validation.\n\n#### Milestone 1: Stack Sampling Verification\n\nThe first milestone checkpoint validates that stack sampling infrastructure correctly captures call stacks at configurable frequencies with minimal overhead and proper signal handling.\n\n**Automated Verification Tests:**\n\n| Test Name | Validation Focus | Success Criteria | Failure Diagnosis |\n|-----------|------------------|------------------|-------------------|\n| `test_sampling_frequency` | Timer accuracy | Measured frequency within 5% of configured | Check timer configuration, signal delivery |\n| `test_stack_depth_limits` | Stack unwinding bounds | Respects max_stack_depth configuration | Verify frame pointer traversal logic |\n| `test_signal_handler_safety` | Async-safe operations | No crashes during intensive sampling | Review signal handler implementation |\n| `test_thread_targeting` | Thread-specific sampling | Samples only from target thread | Check signal delivery targeting |\n| `test_kernel_stack_capture` | Kernel frame inclusion | Captures kernel frames when available | Verify kernel stack access permissions |\n\n**Manual Verification Procedure:**\n\n1. **Start Simple Target Process**: Launch a test program with known execution pattern (recursive function calls)\n2. **Configure Profiler**: Set sampling frequency to 100Hz with maximum stack depth of 50 frames\n3. **Collect Samples**: Profile target process for 10 seconds to gather approximately 1000 samples\n4. **Validate Sample Distribution**: Verify samples show expected function frequency distribution\n5. **Check Overhead Impact**: Confirm target process performance degradation remains under 2%\n\n**Expected Output Characteristics:**\n\n```\nSampling Statistics:\n- Target Process: fibonacci_recursive (PID 12345)\n- Configured Frequency: 100Hz\n- Actual Sample Rate: 98.7Hz (within tolerance)\n- Total Samples Collected: 987\n- Average Stack Depth: 23.4 frames\n- Kernel Frames Captured: 156 (15.8%)\n- Signal Delivery Failures: 2 (0.2%)\n- Overhead Estimate: 1.3%\n```\n\n**Milestone 1 Success Criteria:**\n\n- Sample collection rate within 5% of configured frequency\n- No signal handler crashes during extended sampling periods\n- Stack depth distribution matches target program characteristics\n- Overhead measurements below 2% CPU impact\n- Thread-specific sampling correctly isolates target thread activity\n\n#### Milestone 2: Symbol Resolution Verification\n\nThe second milestone checkpoint validates that symbol resolution correctly converts raw addresses to function names and source locations across different binary formats and debug information scenarios.\n\n**Automated Verification Tests:**\n\n| Test Name | Validation Focus | Success Criteria | Failure Diagnosis |\n|-----------|------------------|------------------|-------------------|\n| `test_elf_symbol_loading` | Binary parsing accuracy | All expected symbols loaded from test binary | Check ELF parsing logic, symbol table access |\n| `test_address_resolution` | Address-to-symbol mapping | Known addresses resolve to expected function names | Verify symbol lookup algorithm, address ranges |\n| `test_dwarf_line_numbers` | Source location accuracy | Addresses map to correct source files and line numbers | Check DWARF parsing, line number tables |\n| `test_shared_library_symbols` | Dynamic library support | Resolves symbols from loaded shared libraries | Verify library enumeration, ASLR handling |\n| `test_symbol_cache_performance` | Cache hit rates | Cache hit rate above 80% for repeated lookups | Tune cache size, eviction policy |\n\n**Manual Verification Procedure:**\n\n1. **Prepare Test Binary**: Compile test program with debug information using `-g` flag\n2. **Load Symbol Information**: Initialize symbolizer with test binary and verify symbol count\n3. **Resolve Known Addresses**: Test address resolution for main function, library calls, and edge cases\n4. **Validate Source Mapping**: Confirm DWARF line number mapping for several known code locations\n5. **Test Graceful Degradation**: Verify behavior with stripped binaries and missing debug information\n\n**Expected Output Characteristics:**\n\n```\nSymbol Resolution Statistics:\n- Binary: /tmp/test_program (ELF 64-bit)\n- Symbols Loaded: 1,247 functions\n- Debug Information: DWARF 4 (available)\n- Address Resolution Success Rate: 94.2%\n- Cache Hit Rate: 87.3%\n- Average Lookup Time: 0.12ms\n- Missing Symbols: 73 (stripped library functions)\n- Source File Coverage: 89.6% of samples\n```\n\n**Milestone 2 Success Criteria:**\n\n- Successfully loads symbols from ELF binaries with standard toolchains\n- Resolves over 90% of addresses from debug-enabled binaries\n- Provides graceful fallback for addresses without available symbols\n- Symbol cache achieves hit rates above 80% during typical profiling\n- DWARF parsing correctly maps addresses to source files and line numbers\n\n#### Milestone 3: Flame Graph Generation Verification\n\nThe third milestone checkpoint validates that flame graph generation correctly aggregates stack samples and produces interactive visualizations that accurately represent program execution patterns.\n\n**Automated Verification Tests:**\n\n| Test Name | Validation Focus | Success Criteria | Failure Diagnosis |\n|-----------|------------------|------------------|-------------------|\n| `test_stack_aggregation` | Sample folding accuracy | Identical stacks properly merged with correct counts | Check aggregation algorithm, stack comparison logic |\n| `test_flame_tree_construction` | Hierarchical structure | Tree reflects calling relationships accurately | Verify parent-child relationships, node creation |\n| `test_svg_coordinate_calculation` | Layout mathematics | Rectangle positions and widths match sample proportions | Check coordinate calculation, scaling logic |\n| `test_interactive_features` | SVG functionality | Zoom and search features work correctly | Test JavaScript embedding, event handling |\n| `test_color_scheme_consistency` | Visual coherence | Colors consistently represent function categories | Verify color assignment algorithm |\n\n**Manual Verification Procedure:**\n\n1. **Generate Test Profile**: Create profile data with known stack patterns and sample distributions\n2. **Build Flame Graph**: Generate SVG flame graph and verify visual structure matches expectations\n3. **Validate Proportions**: Confirm rectangle widths accurately represent relative sample counts\n4. **Test Interactivity**: Verify zoom functionality and search features work in web browser\n5. **Check Color Coding**: Ensure consistent color assignment for function categories\n\n**Expected Output Characteristics:**\n\n```\nFlame Graph Generation Statistics:\n- Input Samples: 10,000 stack traces\n- Unique Call Stacks: 1,247 distinct patterns\n- Aggregated Nodes: 3,891 flame graph nodes\n- Maximum Stack Depth: 42 frames\n- SVG File Size: 2.3MB\n- Rectangle Count: 3,891 drawable elements\n- Color Categories: User (45%), Libraries (38%), Kernel (17%)\n- Generation Time: 0.8 seconds\n```\n\n**Milestone 3 Success Criteria:**\n\n- Stack aggregation correctly merges identical call patterns\n- Flame graph proportions accurately reflect sample distribution\n- Interactive features (zoom, search) function correctly in standard browsers\n- Color coding consistently distinguishes function categories\n- Generated SVG files load and render properly across different viewing environments\n\n#### Milestone 4: Memory Profiling Verification\n\nThe fourth milestone checkpoint validates that memory profiling correctly tracks allocations, detects leaks, and identifies allocation hotspots with acceptable overhead for allocation-intensive programs.\n\n**Automated Verification Tests:**\n\n| Test Name | Validation Focus | Success Criteria | Failure Diagnosis |\n|-----------|------------------|------------------|-------------------|\n| `test_allocation_interception` | Function hooking | All malloc/free calls captured correctly | Check LD_PRELOAD setup, hook installation |\n| `test_allocation_tracking` | Metadata accuracy | Allocation size and stack traces recorded properly | Verify tracking data structures, thread safety |\n| `test_leak_detection_accuracy` | Leak classification | Correctly identifies definite vs. possible leaks | Check leak detection algorithm, reachability analysis |\n| `test_allocation_site_analysis` | Hotspot identification | Top allocation sites ranked by total bytes correctly | Verify aggregation logic, call stack hashing |\n| `test_memory_overhead` | Tracking impact | Metadata overhead remains below 10% of tracked allocations | Optimize tracking structures, measure overhead |\n\n**Manual Verification Procedure:**\n\n1. **Prepare Allocation Test Program**: Create program with known allocation patterns and intentional leaks\n2. **Enable Memory Tracking**: Launch program with allocation interception enabled\n3. **Execute Allocation Workload**: Run program through allocation-intensive operations\n4. **Analyze Allocation Report**: Verify hotspot identification and leak detection accuracy\n5. **Validate Overhead Impact**: Confirm memory tracking overhead remains acceptable\n\n**Expected Output Characteristics:**\n\n```\nMemory Profiling Statistics:\n- Tracked Allocations: 45,672 malloc calls\n- Peak Live Allocations: 12,389 active allocations\n- Total Bytes Allocated: 247.8 MB\n- Detected Leaks: 23 definite, 7 possible\n- Top Allocation Site: image_processing.c:142 (45.2 MB total)\n- Average Allocation Size: 5,428 bytes\n- Allocation Tracking Overhead: 7.3% memory increase\n- Processing Time: 2.1 seconds analysis\n```\n\n**Milestone 4 Success Criteria:**\n\n- Allocation interception captures all heap operations without missed calls\n- Leak detection accurately identifies intentional leaks in test programs\n- Allocation site analysis correctly ranks hotspots by memory consumption\n- Memory tracking overhead remains below 10% for typical allocation patterns\n- Memory profiling integrates with existing flame graph generation for combined analysis\n\n> **Comprehensive Milestone Validation**: Each milestone builds upon previous achievements, requiring regression testing to ensure new functionality doesn't break existing capabilities. The final validation confirms all four milestones work together as an integrated profiling system.\n\n### Implementation Guidance\n\nThe testing infrastructure requires careful setup to handle the unique challenges of testing a profiling tool. The implementation provides both automated test frameworks and manual verification procedures that developers can use to validate their profiler implementation at each development stage.\n\n#### Technology Recommendations\n\n| Test Component | Simple Option | Advanced Option |\n|----------------|---------------|-----------------|\n| Unit Testing Framework | `pytest` with basic assertions | `pytest` with `pytest-mock` and `hypothesis` property testing |\n| Process Management | `subprocess` module for test program control | `psutil` for detailed process monitoring and resource tracking |\n| Binary Generation | Hand-crafted minimal ELF files | `pyelftools` for programmatic ELF construction |\n| SVG Validation | String parsing and basic XML checks | `lxml` with XSD schema validation for proper SVG structure |\n| Performance Measurement | Simple time/memory comparisons | `py-spy` or similar for independent profiler validation |\n| Mock Data Generation | Static test data files | `factory_boy` for dynamic test data generation |\n\n#### Recommended File Structure\n\nThe testing infrastructure should be organized to support both component isolation and integration testing workflows:\n\n```\nprofiler-project/\n├── src/\n│   ├── profiler/\n│   │   ├── sampling.py          # Stack sampling implementation\n│   │   ├── symbols.py           # Symbol resolution implementation\n│   │   ├── flamegraph.py        # Flame graph generation\n│   │   └── memory.py            # Memory profiling implementation\n│   └── common/\n│       ├── data_structures.py   # Core data types\n│       └── config.py            # Configuration management\n├── tests/\n│   ├── unit/\n│   │   ├── test_sampling.py     # Stack sampling unit tests\n│   │   ├── test_symbols.py      # Symbol resolution unit tests\n│   │   ├── test_flamegraph.py   # Flame graph unit tests\n│   │   └── test_memory.py       # Memory profiling unit tests\n│   ├── integration/\n│   │   ├── test_end_to_end.py   # Complete profiling pipeline tests\n│   │   ├── test_real_programs.py # Real application profiling tests\n│   │   └── test_performance.py  # Overhead measurement tests\n│   ├── fixtures/\n│   │   ├── test_programs/       # Purpose-built test applications\n│   │   ├── sample_binaries/     # Test ELF files with known symbols\n│   │   └── expected_outputs/    # Reference flame graphs and reports\n│   └── conftest.py              # Pytest configuration and shared fixtures\n├── tools/\n│   ├── test_program_builder.py  # Generates test programs with known patterns\n│   ├── overhead_monitor.py      # Measures profiler performance impact\n│   └── milestone_validator.py   # Automated milestone checkpoint verification\n└── docs/\n    └── testing_guide.md         # Manual testing procedures and troubleshooting\n```\n\n#### Infrastructure Starter Code\n\n**Complete Test Program Generator** (handles the complexity of creating programs with predictable execution patterns):\n\n```python\n# tools/test_program_builder.py\n\"\"\"Generates test programs with known execution characteristics for profiler validation.\"\"\"\n\nimport os\nimport subprocess\nimport tempfile\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any\n\n@dataclass\nclass TestProgramSpec:\n    \"\"\"Specification for generating a test program with predictable behavior.\"\"\"\n    name: str\n    execution_pattern: str  # 'cpu_intensive', 'io_heavy', 'memory_allocator', 'recursive'\n    runtime_seconds: float\n    expected_hotspots: List[str]  # Function names that should appear prominently in profile\n    allocation_pattern: Dict[str, Any]  # Memory allocation characteristics\n\nclass TestProgramBuilder:\n    \"\"\"Builds test programs with known execution patterns for profiler validation.\"\"\"\n    \n    def __init__(self, output_dir: str = \"/tmp/profiler_test_programs\"):\n        self.output_dir = output_dir\n        os.makedirs(output_dir, exist_ok=True)\n    \n    def build_cpu_intensive_program(self, spec: TestProgramSpec) -> str:\n        \"\"\"Generate CPU-intensive test program with predictable hotspots.\"\"\"\n        program_code = f'''\n#include <stdio.h>\n#include <time.h>\n\n// Expected hotspot: recursive_fibonacci should consume ~80% of samples\nlong recursive_fibonacci(int n) {{\n    if (n <= 1) return n;\n    return recursive_fibonacci(n-1) + recursive_fibonacci(n-2);\n}}\n\n// Expected hotspot: busy_computation should consume ~15% of samples  \nvoid busy_computation(int iterations) {{\n    volatile long sum = 0;\n    for (int i = 0; i < iterations; i++) {{\n        sum += i * i;\n    }}\n}}\n\nint main() {{\n    clock_t start = clock();\n    while ((double)(clock() - start) / CLOCKS_PER_SEC < {spec.runtime_seconds}) {{\n        // This creates predictable call stack pattern for validation\n        recursive_fibonacci(20);  // Creates deep recursive stacks\n        busy_computation(1000);   // Creates flat computation profile\n    }}\n    return 0;\n}}\n'''\n        return self._compile_program(spec.name, program_code)\n    \n    def build_memory_allocator_program(self, spec: TestProgramSpec) -> str:\n        \"\"\"Generate memory-intensive test program with known allocation patterns.\"\"\"\n        program_code = f'''\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <string.h>\n\n// Expected allocation hotspot: large_allocations\nvoid* large_allocations(size_t count, size_t size) {{\n    void** ptrs = malloc(count * sizeof(void*));\n    for (size_t i = 0; i < count; i++) {{\n        ptrs[i] = malloc(size);\n        memset(ptrs[i], 0, size);  // Touch allocated memory\n    }}\n    return ptrs;\n}}\n\n// Expected leak: intentional_leak never frees allocated memory\nvoid intentional_leak(size_t size) {{\n    void* ptr = malloc(size);\n    memset(ptr, 0xAB, size);\n    // Intentionally not freed - should appear in leak report\n}}\n\nint main() {{\n    clock_t start = clock();\n    void* large_ptr = NULL;\n    \n    while ((double)(clock() - start) / CLOCKS_PER_SEC < {spec.runtime_seconds}) {{\n        // Pattern: large allocations that get freed\n        large_ptr = large_allocations(100, 1024);\n        free(large_ptr);\n        \n        // Pattern: small leaks that accumulate  \n        intentional_leak(64);\n        \n        // Pattern: temporary allocations with short lifetime\n        void* temp = malloc(256);\n        free(temp);\n    }}\n    \n    return 0;\n}}\n'''\n        return self._compile_program(spec.name, program_code, debug_symbols=True)\n    \n    def _compile_program(self, name: str, source_code: str, debug_symbols: bool = True) -> str:\n        \"\"\"Compile test program and return path to executable.\"\"\"\n        source_path = os.path.join(self.output_dir, f\"{name}.c\")\n        binary_path = os.path.join(self.output_dir, name)\n        \n        with open(source_path, 'w') as f:\n            f.write(source_code)\n        \n        compile_cmd = ['gcc', '-o', binary_path, source_path]\n        if debug_symbols:\n            compile_cmd.extend(['-g', '-O1'])  # Light optimization to keep realistic\n        \n        result = subprocess.run(compile_cmd, capture_output=True, text=True)\n        if result.returncode != 0:\n            raise RuntimeError(f\"Compilation failed: {result.stderr}\")\n        \n        return binary_path\n\n    def create_standard_test_suite(self) -> Dict[str, str]:\n        \"\"\"Create complete set of standard test programs.\"\"\"\n        test_specs = [\n            TestProgramSpec(\"cpu_intensive\", \"recursive\", 5.0, \n                          [\"recursive_fibonacci\", \"busy_computation\"], {}),\n            TestProgramSpec(\"memory_allocator\", \"allocation\", 3.0,\n                          [\"large_allocations\", \"intentional_leak\"], \n                          {\"leak_size\": 64, \"large_alloc_size\": 1024})\n        ]\n        \n        programs = {}\n        for spec in test_specs:\n            if spec.execution_pattern == \"recursive\":\n                programs[spec.name] = self.build_cpu_intensive_program(spec)\n            elif spec.execution_pattern == \"allocation\":\n                programs[spec.name] = self.build_memory_allocator_program(spec)\n        \n        return programs\n```\n\n**Complete Overhead Measurement Framework** (measures profiler impact on target processes):\n\n```python\n# tools/overhead_monitor.py\n\"\"\"Measures profiler overhead and validates performance impact stays within bounds.\"\"\"\n\nimport time\nimport psutil\nimport subprocess\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nfrom contextlib import contextmanager\n\n@dataclass\nclass PerformanceMetrics:\n    \"\"\"Performance measurements for overhead analysis.\"\"\"\n    cpu_time_seconds: float\n    memory_rss_bytes: int\n    wall_clock_seconds: float\n    context_switches: int\n    page_faults: int\n\n@dataclass\nclass OverheadReport:\n    \"\"\"Comparison of performance with and without profiling.\"\"\"\n    baseline_metrics: PerformanceMetrics\n    profiled_metrics: PerformanceMetrics\n    cpu_overhead_percent: float\n    memory_overhead_bytes: int\n    acceptable_overhead: bool\n    \nclass OverheadMonitor:\n    \"\"\"Measures and validates profiler performance overhead.\"\"\"\n    \n    def __init__(self, max_cpu_overhead: float = 2.0, max_memory_mb: float = 50.0):\n        self.max_cpu_overhead = max_cpu_overhead\n        self.max_memory_mb = max_memory_mb\n    \n    def measure_baseline_performance(self, test_program_path: str, \n                                   runtime_seconds: float) -> PerformanceMetrics:\n        \"\"\"Run test program without profiling to establish baseline performance.\"\"\"\n        return self._run_and_measure(test_program_path, runtime_seconds)\n    \n    def measure_profiled_performance(self, test_program_path: str, \n                                   runtime_seconds: float,\n                                   profiler_config: Dict) -> PerformanceMetrics:\n        \"\"\"Run test program under profiler and measure performance impact.\"\"\"\n        # TODO 1: Launch profiler with specified configuration\n        # TODO 2: Start target program as child process  \n        # TODO 3: Monitor both profiler and target process metrics\n        # TODO 4: Stop profiling after runtime_seconds\n        # TODO 5: Return combined performance metrics\n        # Hint: Use psutil to monitor both processes simultaneously\n        pass\n    \n    def _run_and_measure(self, program_path: str, runtime_seconds: float) -> PerformanceMetrics:\n        \"\"\"Execute program and collect detailed performance metrics.\"\"\"\n        start_time = time.time()\n        \n        # Start process and get initial measurements\n        process = subprocess.Popen([program_path])\n        psutil_process = psutil.Process(process.pid)\n        \n        initial_cpu_times = psutil_process.cpu_times()\n        initial_memory = psutil_process.memory_info()\n        initial_ctx_switches = psutil_process.num_ctx_switches()\n        \n        # Wait for completion\n        process.wait()\n        \n        # Get final measurements\n        final_cpu_times = psutil_process.cpu_times()\n        final_memory = psutil_process.memory_info()\n        final_ctx_switches = psutil_process.num_ctx_switches()\n        \n        wall_clock = time.time() - start_time\n        \n        return PerformanceMetrics(\n            cpu_time_seconds=final_cpu_times.user - initial_cpu_times.user,\n            memory_rss_bytes=max(final_memory.rss, initial_memory.rss),\n            wall_clock_seconds=wall_clock,\n            context_switches=final_ctx_switches.voluntary - initial_ctx_switches.voluntary,\n            page_faults=final_memory.rss // 4096  # Rough estimate\n        )\n    \n    def generate_overhead_report(self, baseline: PerformanceMetrics, \n                               profiled: PerformanceMetrics) -> OverheadReport:\n        \"\"\"Compare baseline vs profiled performance and validate overhead bounds.\"\"\"\n        cpu_overhead = ((profiled.cpu_time_seconds - baseline.cpu_time_seconds) \n                       / baseline.cpu_time_seconds * 100)\n        memory_overhead = profiled.memory_rss_bytes - baseline.memory_rss_bytes\n        \n        acceptable = (cpu_overhead <= self.max_cpu_overhead and \n                     memory_overhead <= self.max_memory_mb * 1024 * 1024)\n        \n        return OverheadReport(\n            baseline_metrics=baseline,\n            profiled_metrics=profiled,\n            cpu_overhead_percent=cpu_overhead,\n            memory_overhead_bytes=memory_overhead,\n            acceptable_overhead=acceptable\n        )\n```\n\n#### Core Logic Testing Skeletons\n\n**Stack Sampling Test Framework** (validates sampling accuracy and signal handling):\n\n```python\n# tests/unit/test_sampling.py\n\"\"\"Unit tests for stack sampling component with mock signal handling.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, patch, MagicMock\nfrom profiler.sampling import StackSampler, SamplingConfig, Sample, StackFrame\n\nclass TestStackSampler:\n    \"\"\"Test stack sampling with controlled signal scenarios.\"\"\"\n    \n    def test_sampling_frequency_accuracy(self):\n        \"\"\"Validate timer configuration produces expected sampling rate.\"\"\"\n        config = SamplingConfig(frequency_hz=100, max_stack_depth=50)\n        sampler = StackSampler(config)\n        \n        # TODO 1: Mock timer interface to control signal delivery timing\n        # TODO 2: Start sampling for known duration (e.g., 1 second)\n        # TODO 3: Count delivered signals and calculate actual frequency\n        # TODO 4: Assert actual frequency within 5% of configured frequency\n        # TODO 5: Verify timer cleanup on sampling stop\n        # Hint: Use unittest.mock.patch to mock signal.alarm and signal.signal\n        pass\n    \n    def test_stack_unwinding_accuracy(self):\n        \"\"\"Validate stack frame traversal with synthetic call stacks.\"\"\"\n        sampler = StackSampler(SamplingConfig(frequency_hz=10, max_stack_depth=10))\n        \n        # Mock execution context representing recursive function calls\n        mock_frames = [\n            {'address': 0x400000, 'frame_pointer': 0x7fff1000, 'function': 'main'},\n            {'address': 0x400100, 'frame_pointer': 0x7fff0f80, 'function': 'recursive_func'},  \n            {'address': 0x400120, 'frame_pointer': 0x7fff0f00, 'function': 'recursive_func'}\n        ]\n        \n        # TODO 1: Create mock register context from synthetic frame data\n        # TODO 2: Call stack unwinding logic with mock context\n        # TODO 3: Verify returned stack frames match expected sequence\n        # TODO 4: Assert frame pointer traversal follows correct chain\n        # TODO 5: Validate stack depth limit enforcement\n        # Hint: Mock the signal frame parameter passed to signal handler\n        pass\n    \n    @patch('profiler.sampling.signal')\n    def test_signal_handler_safety(self, mock_signal):\n        \"\"\"Verify signal handler only uses async-safe operations.\"\"\"\n        sampler = StackSampler(SamplingConfig(frequency_hz=1000, max_stack_depth=20))\n        \n        # TODO 1: Install signal handler and verify registration\n        # TODO 2: Simulate rapid signal delivery to test concurrency\n        # TODO 3: Verify no malloc/free calls in signal handler path\n        # TODO 4: Check that sample buffer operations are atomic\n        # TODO 5: Validate proper signal mask handling\n        # Hint: Monitor syscalls used during signal handling\n        pass\n\n    def test_sample_buffer_overflow_handling(self):\n        \"\"\"Validate graceful behavior when sample buffer reaches capacity.\"\"\"\n        config = SamplingConfig(frequency_hz=1000, max_stack_depth=10)  # High frequency\n        sampler = StackSampler(config)\n        \n        # TODO 1: Configure small buffer size to force overflow\n        # TODO 2: Generate more samples than buffer capacity  \n        # TODO 3: Verify oldest samples discarded when buffer full\n        # TODO 4: Check that overflow counter increments correctly\n        # TODO 5: Ensure no memory corruption during overflow\n        # Hint: Use mock samples to control buffer filling\n        pass\n```\n\n**Symbol Resolution Test Framework** (validates address-to-symbol mapping):\n\n```python\n# tests/unit/test_symbols.py\n\"\"\"Unit tests for symbol resolution with synthetic ELF data.\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom profiler.symbols import Symbolizer, SymbolConfig, Symbol, Module\n\nclass TestSymbolizer:\n    \"\"\"Test symbol resolution with controlled binary data.\"\"\"\n    \n    def test_elf_symbol_table_parsing(self):\n        \"\"\"Validate ELF symbol table parsing with synthetic binary.\"\"\"\n        config = SymbolConfig(enable_dwarf=False, cache_symbols=True)\n        symbolizer = Symbolizer(config)\n        \n        # Create synthetic ELF data with known symbol layout\n        synthetic_symbols = [\n            {'name': 'main', 'address': 0x400000, 'size': 0x100, 'type': 'FUNC'},\n            {'name': 'helper_func', 'address': 0x400100, 'size': 0x50, 'type': 'FUNC'},\n            {'name': 'global_var', 'address': 0x600000, 'size': 0x8, 'type': 'OBJECT'}\n        ]\n        \n        # TODO 1: Mock ELF file reading to return synthetic symbol data\n        # TODO 2: Load symbols from mock binary file  \n        # TODO 3: Verify all expected symbols loaded with correct addresses\n        # TODO 4: Test symbol lookup for addresses within symbol ranges\n        # TODO 5: Validate handling of symbols with zero size\n        # Hint: Use pyelftools structure mocking for ELF parsing\n        pass\n    \n    def test_address_resolution_with_aslr(self):\n        \"\"\"Validate symbol lookup handles ASLR address offsets correctly.\"\"\" \n        symbolizer = Symbolizer(SymbolConfig(cache_symbols=True))\n        \n        # Mock module loaded with ASLR offset\n        base_symbols = [\n            {'name': 'func1', 'link_address': 0x1000, 'size': 0x100},\n            {'name': 'func2', 'link_address': 0x1100, 'size': 0x80}\n        ]\n        aslr_offset = 0x7f0000000000  # Typical ASLR base\n        \n        # TODO 1: Create module with ASLR-adjusted symbol addresses\n        # TODO 2: Test address lookup with runtime addresses (link + offset)\n        # TODO 3: Verify correct symbol returned for offset addresses\n        # TODO 4: Test address ranges at symbol boundaries  \n        # TODO 5: Validate cache consistency with ASLR adjustments\n        # Hint: Mock /proc/pid/maps parsing for runtime address discovery\n        pass\n    \n    def test_dwarf_line_number_mapping(self):\n        \"\"\"Validate DWARF debug information parsing for source locations.\"\"\"\n        config = SymbolConfig(enable_dwarf=True, cache_symbols=False)\n        symbolizer = Symbolizer(config)\n        \n        # Synthetic DWARF line number table\n        line_info = [\n            {'address': 0x400000, 'file': 'main.c', 'line': 10, 'column': 5},\n            {'address': 0x400010, 'file': 'main.c', 'line': 11, 'column': 9},\n            {'address': 0x400020, 'file': 'helper.c', 'line': 25, 'column': 1}\n        ]\n        \n        # TODO 1: Mock DWARF parsing to return synthetic line information\n        # TODO 2: Test address-to-source mapping for known addresses\n        # TODO 3: Verify file name and line number accuracy\n        # TODO 4: Test handling of addresses between line number entries\n        # TODO 5: Validate graceful handling of missing line information\n        # Hint: Mock dwarf.DWARFInfo parsing methods\n        pass\n\n    def test_symbol_cache_performance(self):\n        \"\"\"Validate symbol cache hit rates and eviction behavior.\"\"\"\n        config = SymbolConfig(cache_symbols=True, symbol_search_paths=[\"/tmp\"])\n        symbolizer = Symbolizer(config)\n        \n        # TODO 1: Populate cache with known symbol set\n        # TODO 2: Perform repeated lookups and measure hit rate\n        # TODO 3: Test cache eviction under memory pressure\n        # TODO 4: Verify cache consistency after evictions\n        # TODO 5: Measure lookup performance improvement from caching\n        # Hint: Control cache size to force eviction scenarios\n        pass\n```\n\n#### Milestone Checkpoint Implementation\n\n**Automated Milestone Validation** (verifies each development stage):\n\n```python\n# tools/milestone_validator.py\n\"\"\"Automated validation for profiler implementation milestones.\"\"\"\n\nimport os\nimport subprocess\nimport json\nimport time\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass\n\n@dataclass  \nclass MilestoneResult:\n    \"\"\"Results from milestone validation check.\"\"\"\n    milestone_name: str\n    passed: bool\n    test_results: Dict[str, bool]\n    performance_metrics: Dict[str, float]\n    error_messages: List[str]\n    recommendations: List[str]\n\nclass MilestoneValidator:\n    \"\"\"Validates profiler implementation against milestone requirements.\"\"\"\n    \n    def __init__(self, test_program_dir: str = \"/tmp/profiler_test_programs\"):\n        self.test_program_dir = test_program_dir\n        self.validation_results = []\n    \n    def validate_milestone_1_stack_sampling(self) -> MilestoneResult:\n        \"\"\"Validate Milestone 1: Stack sampling implementation.\"\"\"\n        test_results = {}\n        performance_metrics = {}\n        error_messages = []\n        \n        # TODO 1: Test sampling frequency accuracy (within 5% of target)\n        # TODO 2: Validate stack depth limits enforcement  \n        # TODO 3: Check signal handler safety (no crashes under load)\n        # TODO 4: Measure sampling overhead (should be < 2%)\n        # TODO 5: Test thread-specific targeting capability\n        # Hint: Use test programs from TestProgramBuilder\n        \n        # Example validation structure:\n        try:\n            # Run cpu_intensive test program under profiler\n            test_program = os.path.join(self.test_program_dir, \"cpu_intensive\")\n            if not os.path.exists(test_program):\n                error_messages.append(\"Test program not found - run TestProgramBuilder first\")\n                return MilestoneResult(\"Milestone 1\", False, {}, {}, error_messages, [])\n            \n            # Validate sampling works\n            sampling_result = self._test_basic_sampling(test_program)\n            test_results[\"basic_sampling\"] = sampling_result.success\n            performance_metrics[\"sampling_frequency\"] = sampling_result.measured_frequency\n            \n        except Exception as e:\n            error_messages.append(f\"Sampling validation failed: {str(e)}\")\n        \n        passed = all(test_results.values()) and len(error_messages) == 0\n        recommendations = self._generate_milestone_1_recommendations(test_results, performance_metrics)\n        \n        return MilestoneResult(\"Milestone 1\", passed, test_results, \n                             performance_metrics, error_messages, recommendations)\n    \n    def validate_milestone_2_symbol_resolution(self) -> MilestoneResult:\n        \"\"\"Validate Milestone 2: Symbol resolution implementation.\"\"\"\n        # TODO 1: Test ELF symbol loading from test binaries\n        # TODO 2: Validate address-to-function name resolution accuracy\n        # TODO 3: Check DWARF line number mapping functionality\n        # TODO 4: Test shared library symbol resolution\n        # TODO 5: Measure symbol cache performance metrics\n        pass\n    \n    def validate_milestone_3_flame_graphs(self) -> MilestoneResult:\n        \"\"\"Validate Milestone 3: Flame graph generation.\"\"\"\n        # TODO 1: Test stack aggregation produces correct sample counts\n        # TODO 2: Validate flame graph tree structure reflects call hierarchy  \n        # TODO 3: Check SVG generation creates valid XML structure\n        # TODO 4: Test interactive features (zoom, search) work in browsers\n        # TODO 5: Verify color coding consistency across different profiles\n        pass\n    \n    def validate_milestone_4_memory_profiling(self) -> MilestoneResult:\n        \"\"\"Validate Milestone 4: Memory profiling implementation.\"\"\"\n        # TODO 1: Test allocation interception captures all malloc/free calls\n        # TODO 2: Validate leak detection finds intentional leaks in test programs\n        # TODO 3: Check allocation site ranking by memory consumption\n        # TODO 4: Measure memory tracking overhead (should be < 10%)\n        # TODO 5: Test integration with flame graph generation\n        pass\n    \n    def _test_basic_sampling(self, test_program_path: str) -> Any:\n        \"\"\"Test basic sampling functionality with controlled program.\"\"\"\n        # This would implement actual sampling test logic\n        # Returns object with success flag and measured metrics\n        pass\n    \n    def _generate_milestone_1_recommendations(self, test_results: Dict[str, bool], \n                                            metrics: Dict[str, float]) -> List[str]:\n        \"\"\"Generate specific recommendations for improving Milestone 1 implementation.\"\"\"\n        recommendations = []\n        \n        if not test_results.get(\"basic_sampling\", True):\n            recommendations.append(\"Check signal handler installation - use signal.signal(signal.SIGPROF, handler)\")\n        \n        if metrics.get(\"sampling_frequency\", 0) < 95:  # Less than 95% of target frequency\n            recommendations.append(\"Sampling frequency too low - check timer configuration and signal delivery\")\n        \n        if metrics.get(\"overhead_percent\", 10) > 2:\n            recommendations.append(\"Overhead too high - optimize signal handler, reduce stack unwinding work\")\n        \n        return recommendations\n```\n\nThis comprehensive testing strategy ensures profiler reliability across all development stages while providing clear validation criteria and debugging guidance for each milestone. The combination of automated testing, manual verification, and structured checkpoints enables systematic profiler development with confidence in correctness and performance characteristics.\n\n\n## Debugging Guide\n\n> **Milestone(s):** All milestones (1-4) — debugging techniques and common issue resolution for stack sampling, symbol resolution, flame graph generation, and memory profiling implementation\n\n### Mental Model: The Medical Diagnosis Approach\n\nThink of debugging a profiler like being a doctor diagnosing a complex patient. The profiler has multiple interconnected systems (sampling, symbols, visualization, memory tracking) that can fail independently or cascade into system-wide problems. Like a doctor, you need systematic diagnostic techniques: observing symptoms, running targeted tests, understanding how systems interact, and applying targeted treatments while monitoring for side effects.\n\nJust as a doctor doesn't randomly prescribe medicine but follows a diagnostic process—gathering symptoms, forming hypotheses, running tests, narrowing possibilities—debugging a profiler requires methodical investigation. Some symptoms are obvious (crashes, missing data), while others are subtle (slight sampling bias, memory leaks in the profiler itself). The key is building diagnostic intuition about which symptoms point to which underlying causes.\n\nThe profiler's complexity comes from its dual nature: it must be transparent to the target program (observer paradox) while capturing detailed execution information under tight performance constraints. This creates debugging challenges unique to systems programming—race conditions in signal handlers, symbol resolution that depends on external debug information, and visualization bugs that only appear with specific call patterns.\n\n### Stack Sampling Issues\n\nStack sampling represents the most critical and error-prone component because it operates under severe constraints: signal handlers must be async-safe, stack unwinding must handle corrupted or incomplete stack frames, and sampling must maintain precise timing while avoiding observer paradox effects. Understanding these failure modes and their diagnostic signatures enables rapid problem resolution.\n\n#### Signal Handler Problems\n\nSignal delivery failures manifest in multiple ways that require different diagnostic approaches. The most common pattern is **missing samples** where the profiler receives fewer samples than expected based on the configured sampling frequency. This typically indicates that signals are being dropped, blocked, or handled incorrectly.\n\n**Signal delivery verification** starts with comparing expected vs. actual sample counts. If you configure 100Hz sampling for 10 seconds, you should receive approximately 1000 samples, allowing for some variance due to system scheduling. Significant deviations (less than 90% of expected samples) indicate signal delivery problems.\n\nThe target process might be blocking `SIGPROF` signals, either intentionally through signal masking or accidentally through long-running system calls. Processes that spend significant time in uninterruptible system calls (like disk I/O) won't receive timer signals during those periods. You can detect this by monitoring the process's state in `/proc/[pid]/stat` and looking for extended periods in \"D\" (uninterruptible sleep) state.\n\n**Signal handler safety violations** cause the most dangerous and hard-to-reproduce bugs. Signal handlers operate in a restricted environment where only async-safe functions are permitted. Calling non-async-safe functions like `malloc`, `printf`, or complex library functions can cause deadlocks, memory corruption, or crashes that appear randomly and are difficult to debug.\n\n> **Critical Insight**: Signal handler bugs often manifest as intermittent hangs or crashes that seem unrelated to profiling. The target program might hang during a `malloc` call because the signal handler interrupted another `malloc` and then called a non-async-safe function that tries to acquire the same malloc lock.\n\nCommon async-safety violations include:\n\n| Violation | Symptom | Detection Method | Fix |\n|-----------|---------|------------------|-----|\n| Dynamic memory allocation | Random hangs in malloc/free | Check signal handler for malloc calls | Pre-allocate buffers, use async-safe alternatives |\n| Printf/logging calls | Deadlocks in output functions | Look for stdio calls in handler | Use write() system call or defer logging |\n| Complex library calls | Crashes in unexpected locations | Review handler for non-async-safe functions | Minimize handler work, defer to main thread |\n| Mutex operations | Deadlocks on shared resources | Check for lock acquisition in handler | Use atomic operations or lock-free data structures |\n\n**Timer configuration errors** appear when the profiler cannot establish the requested sampling frequency. This happens when the requested frequency exceeds system capabilities (attempting 10KHz on a system that can only deliver 1KHz), when multiple profilers compete for timer resources, or when the process lacks sufficient privileges for high-frequency profiling.\n\n#### Stack Unwinding Failures\n\nStack unwinding transforms the current execution context into a meaningful call chain, but this process can fail in numerous ways that require careful diagnosis. **Frame pointer corruption** represents the most common unwinding failure, where the linked list of stack frames contains invalid pointers that cause segmentation faults or infinite loops during unwinding.\n\nModern compilers often optimize away frame pointers for performance, making traditional frame pointer walking impossible. When frame pointers are missing, the unwinder must fall back to DWARF debug information or heuristic-based unwinding, both of which have higher failure rates and performance costs.\n\n**Stripped binary handling** creates scenarios where no symbol information exists for critical parts of the call stack. Stripped binaries contain no symbol table or debug information, so addresses can only be attributed to anonymous memory regions. The profiler must gracefully handle these scenarios by displaying addresses in hex format while continuing to unwind the stack above and below the stripped regions.\n\n**Inlined function handling** complicates unwinding because a single instruction pointer might correspond to multiple logical function calls. The compiler inlines small functions directly into their callers, eliminating the actual function call. DWARF debug information contains inline records that map instruction addresses to multiple function entries, but parsing this information correctly requires sophisticated logic.\n\nStack unwinding performance directly affects profiler overhead and accuracy. **Slow unwinding** can cause the profiler to miss subsequent timer signals, creating sampling bias toward functions that are expensive to unwind. Fast leaf functions might be underrepresented if their stacks unwind quickly, while functions with deep or complex call chains might appear overrepresented due to unwinding latency.\n\n> **Design Insight**: The goal isn't perfect stack traces but statistically representative sampling. It's better to capture 95% of samples with 90% accuracy than to capture 50% of samples with 100% accuracy, because sampling bias from missed samples creates more analysis errors than minor unwinding inaccuracies.\n\nCommon unwinding failures and their diagnostic signatures:\n\n| Failure Mode | Symptom | Root Cause | Diagnostic Approach |\n|--------------|---------|------------|-------------------|\n| Segfault during unwind | Profiler crashes with SIGSEGV | Corrupted frame pointers | Check frame pointer chain validity before dereferencing |\n| Infinite unwind loops | Profiler hangs, stack traces grow without bound | Circular frame pointer references | Implement cycle detection and maximum depth limits |\n| Missing symbols in traces | Hex addresses instead of function names | Stripped binaries or missing debug info | Verify symbol availability and implement fallback display |\n| Truncated stack traces | Incomplete call chains | Unwinding stopped at invalid frame | Check unwinding termination conditions and error handling |\n| Biased sampling patterns | Some functions never appear despite being active | Unwinding failures causing sample drops | Monitor unwinding success/failure rates per module |\n\n#### Buffer Management and Data Integrity\n\nSample collection operates under strict performance constraints that make buffer management critical. **Buffer overflow** occurs when the profiler generates samples faster than they can be processed by downstream components. This creates backpressure that must be handled through intelligent dropping policies rather than simply blocking sample collection.\n\nThe sample buffer acts as a decoupling mechanism between the high-frequency sampling process and the lower-frequency symbol resolution and aggregation processes. Buffer sizing requires balancing memory usage against the ability to handle processing bursts without dropping samples.\n\n**Sample corruption** can occur during buffer operations, especially in multi-threaded environments where producer and consumer threads access the buffer concurrently. Corruption manifests as invalid addresses in stack frames, nonsensical timestamps, or impossible thread/process IDs that cause downstream processing failures.\n\nLock-free buffer implementations avoid blocking in signal handlers but introduce subtle correctness issues around memory ordering and ABA problems. Traditional locked implementations risk deadlock if a signal arrives while the main thread holds the buffer lock.\n\n### Symbol Resolution Issues\n\nSymbol resolution transforms raw instruction addresses into human-readable function names and source locations, but this process depends on external debug information that may be missing, corrupted, or incorrectly formatted. Understanding symbol resolution failure modes enables both robust error handling and accurate diagnosis of profiling anomalies.\n\n#### Missing Debug Symbols\n\nThe most common symbol resolution problem is **missing debug information**, which manifests as hex addresses instead of function names in flame graphs. This occurs when binaries are stripped of symbol tables, when debug packages aren't installed, or when dynamic libraries are loaded from non-standard locations without corresponding debug information.\n\nDebug information distribution varies significantly across operating systems and deployment environments. Development systems typically have debug symbols available, while production systems often strip symbols to reduce binary size and deployment complexity. This creates a debugging paradox where performance problems are most critical in production environments that have the least debugging information.\n\n**Symbol package management** becomes critical for effective profiling workflows. Most Linux distributions separate debug symbols into optional packages (like `-dbg` or `-debuginfo` packages) that must be explicitly installed. Missing debug packages for system libraries like libc create large gaps in profiling data where critical functions appear as anonymous address ranges.\n\nDynamic library symbol resolution requires understanding the runtime linking process. Libraries loaded via `dlopen()` might not have their symbols immediately available, especially if they're loaded from non-standard paths or with `RTLD_LOCAL` visibility. The profiler must track library load events and refresh its symbol tables dynamically.\n\n**JIT-compiled code** presents special challenges because traditional debug information doesn't exist at compile time. Language runtimes like Python, Java, and JavaScript generate machine code at runtime, but this code exists only in memory without corresponding debug files. Advanced profilers can integrate with runtime symbol APIs, but this requires language-specific knowledge and cooperation from the target process.\n\nCommon missing symbol scenarios:\n\n| Scenario | Manifestation | Underlying Cause | Resolution Strategy |\n|----------|---------------|------------------|-------------------|\n| Stripped production binaries | Hex addresses for main application functions | Symbols removed during build/deploy | Install debug packages or rebuild with symbols |\n| Missing system library symbols | Core library functions show as addresses | Debug packages not installed | Install distribution debug packages |\n| Dynamic library symbols unavailable | Shared library calls appear anonymous | Library loaded from non-standard path | Configure symbol search paths or use LD_DEBUG |\n| JIT code without symbols | Runtime-generated code shows as raw addresses | No debug info for generated code | Integrate with language-specific symbol APIs |\n| Kernel symbols missing | System call and kernel functions anonymous | Kernel debug info not available | Install kernel debug packages or enable kallsyms |\n\n#### Address Resolution Problems\n\n**Address Space Layout Randomization (ASLR)** complicates symbol resolution by randomizing the base addresses where executables and libraries are loaded. The profiler captures instruction pointers from the live process, but symbol tables contain link-time addresses that don't account for ASLR offsets. Resolving symbols requires calculating the correct offset between runtime and link-time addresses.\n\nASLR bias calculation failures create systematic symbol resolution errors where all addresses in a module are offset by a constant amount. This typically manifests as symbols being attributed to the wrong functions, often offset by exactly the ASLR randomization amount. Detecting this requires comparing resolved addresses against expected function boundaries and validating that instruction addresses fall within reasonable symbol ranges.\n\n**Shared library base address tracking** becomes complex when libraries are mapped multiple times at different addresses, or when address spaces contain multiple versions of the same library. Each mapping requires its own ASLR bias calculation, and the profiler must determine which mapping corresponds to each captured instruction pointer.\n\nPosition-Independent Executable (PIE) binaries randomize even the main executable's base address, extending ASLR complications beyond shared libraries. Older profiling tools that assumed fixed executable base addresses fail completely with PIE binaries, producing entirely incorrect symbol attribution.\n\n**Memory mapping changes** during profiling can invalidate cached symbol resolution information. When the target process loads or unloads shared libraries, previous address-to-symbol mappings become invalid. The profiler must detect these changes and refresh its symbol tables, but detecting mapping changes requires either polling `/proc/[pid]/maps` or integrating with dynamic linker notifications.\n\n#### Symbol Cache Performance\n\nSymbol resolution represents a significant computational cost that must be amortized through intelligent caching strategies. **Cache miss cascades** occur when similar addresses repeatedly miss the cache, causing expensive symbol lookups for every sample. This typically happens when the cache size is too small for the working set of addresses, or when the cache replacement policy doesn't account for profiling access patterns.\n\nProfiling access patterns differ significantly from typical program locality patterns. Instead of temporal locality (recently accessed addresses being accessed again), profiling exhibits **hot spot locality** where certain functions generate many samples but new addresses are constantly introduced as program execution progresses.\n\n**Cache coherency** becomes critical when the target process loads or unloads libraries during profiling. Cached symbol information can become stale, causing incorrect symbol attribution. The profiler must either invalidate relevant cache entries when mapping changes are detected, or implement cache entries with validity periods that account for potential mapping changes.\n\nSymbol lookup performance varies dramatically based on the search strategy and data structures used. Linear searches through symbol tables create O(n) lookup costs that become prohibitive for large binaries. Binary search reduces this to O(log n), but requires maintaining sorted symbol tables and handling overlapping symbol ranges correctly.\n\n**Debug information parsing overhead** can dominate symbol resolution performance, especially for DWARF debug information which can be significantly larger than the actual executable code. Lazy parsing strategies load debug information on-demand, but create unpredictable latency spikes. Eager parsing provides consistent performance but requires substantial memory overhead and startup time.\n\n### Memory Tracking Issues\n\nMemory profiling operates by intercepting allocation functions and tracking metadata for each allocation, but this instrumentation introduces complex failure modes related to recursion, thread safety, and metadata management. Understanding these failure modes is critical for building robust memory profilers and accurately interpreting memory profiling results.\n\n#### Allocation Interception Problems\n\n**Recursive allocation calls** represent the most dangerous memory tracking failure mode. When the memory tracker intercepts `malloc()` and then calls `malloc()` internally to allocate tracking metadata, it creates infinite recursion that typically manifests as stack overflow crashes. This recursion can be subtle—calling any function that internally allocates memory (like `printf()` for logging) can trigger recursive allocation.\n\nPreventing recursion requires careful design of the interception mechanism. Thread-local storage can track whether the current thread is already inside the memory tracker, allowing recursive calls to bypass tracking. However, this approach risks missing allocations that occur during tracking operations, creating gaps in allocation coverage.\n\n**Function interposition mechanisms** each have distinct failure modes and compatibility issues. `LD_PRELOAD` interposition works by replacing dynamic library symbols, but fails for statically linked binaries or programs that use alternative allocation mechanisms. Binary patching approaches can handle static linking but require architecture-specific knowledge and may conflict with security mechanisms like code signing.\n\nDynamic symbol interposition using `dlsym(RTLD_NEXT, \"malloc\")` provides more robust interception but introduces startup ordering dependencies. The memory tracker must obtain function pointers to the original allocation functions before any allocation occurs, creating bootstrap challenges during program initialization.\n\n**Multiple allocator support** complicates interception because modern programs often use multiple allocation mechanisms simultaneously. Standard `malloc/free`, C++ `new/delete`, custom memory pools, and garbage-collected languages all manage memory differently. The profiler must intercept all relevant allocation points to provide complete allocation tracking.\n\nCommon interception failure modes:\n\n| Failure Mode | Symptom | Root Cause | Prevention Strategy |\n|--------------|---------|------------|-------------------|\n| Infinite recursion | Stack overflow in malloc | Tracker allocates during interception | Use pre-allocated buffers or thread-local recursion detection |\n| Missing static allocations | Some allocations not tracked | LD_PRELOAD doesn't affect static linking | Combine multiple interposition techniques |\n| Bootstrap ordering issues | Crashes during program startup | Tracker not ready when first allocation occurs | Initialize tracker before main() execution |\n| Custom allocator bypass | Large allocations missing from tracking | Program uses non-standard allocators | Instrument additional allocation functions |\n| Thread creation race | Missing allocations in new threads | Interception not ready when thread starts | Ensure thread-safe tracker initialization |\n\n#### Memory Leak Detection Challenges\n\n**False positive leaks** occur when the leak detection algorithm incorrectly identifies legitimate long-lived allocations as memory leaks. This happens most commonly with allocations that are freed during program shutdown, after leak detection has run. Global data structures, caches, and singleton objects typically exhibit this pattern, creating noise in leak reports that obscures real leaks.\n\nDistinguishing true leaks from false positives requires understanding allocation lifetime patterns and program structure. **Reachable allocations** are those that could theoretically be freed because the program still holds pointers to them, while **definitely lost** allocations have no remaining pointers. However, determining reachability requires sophisticated analysis that may not be practical in a performance-oriented profiler.\n\n**Growth pattern detection** attempts to identify memory leaks by looking for allocation sites with continuously increasing memory usage over time. This approach avoids the complexities of reachability analysis but can misidentify legitimate growth patterns (like caches that grow to a steady state) as memory leaks.\n\nLeak detection timing affects both accuracy and performance overhead. **Continuous leak detection** provides real-time feedback but requires maintaining extensive metadata for all active allocations. **Snapshot-based detection** reduces overhead by analyzing allocation patterns at discrete intervals, but may miss short-lived leaks that occur between snapshots.\n\n**Suppression rules** help filter known false positives from leak reports, but maintaining suppression databases requires ongoing effort and can mask real leaks if rules are too broad. Effective suppression rules balance specificity (avoiding false positives) with maintainability (avoiding overly complex rule sets).\n\n#### Metadata Management and Corruption\n\nMemory tracking requires storing metadata for each allocation, but this metadata storage can become corrupted through various mechanisms, creating incorrect leak reports and profiler crashes. **Metadata corruption** typically manifests as impossible allocation sizes, invalid stack traces, or crashes when accessing allocation tracking data structures.\n\nConcurrent access to allocation metadata from multiple threads creates race conditions that can corrupt tracking data structures. **Thread safety** in memory tracking requires careful synchronization that doesn't introduce deadlock risks with the allocation functions being intercepted. Fine-grained locking reduces contention but increases complexity and the potential for lock ordering issues.\n\n**Memory overhead** from tracking metadata can become significant for programs with many small allocations. Each tracked allocation requires storing at least the allocation size, timestamp, and call stack information. For programs that make millions of small allocations, metadata overhead can exceed the overhead of the original allocations.\n\nMetadata storage strategies involve trade-offs between accuracy, performance, and memory usage:\n\n| Strategy | Memory Overhead | Performance Impact | Accuracy | Use Case |\n|----------|-----------------|-------------------|----------|----------|\n| Full stack traces | High (100+ bytes per allocation) | Moderate (backtrace capture cost) | Excellent | Development debugging |\n| Compressed stack signatures | Medium (20-50 bytes per allocation) | Low (hash calculation cost) | Good | Production profiling |\n| Sampling-based tracking | Low (only track subset of allocations) | Very low | Fair | High-throughput applications |\n| Statistical estimation | Very low (aggregate statistics only) | Minimal | Limited | Real-time monitoring |\n\n**Heap fragmentation tracking** requires monitoring not just allocation patterns but also the layout of the heap memory space. This involves understanding how the underlying allocator (malloc implementation) manages memory regions and detecting when allocator behavior contributes to fragmentation issues.\n\n### Debugging Tools and Techniques\n\nEffective profiler debugging requires specialized tools and techniques that account for the unique challenges of debugging a debugging tool. The profiler operates under strict performance constraints while interacting with low-level system interfaces, creating debugging scenarios that don't occur in typical application development.\n\n#### Logging and Observability\n\n**Structured logging** for profiler components must balance diagnostic value against performance overhead. Traditional logging approaches that write to files or stdout can introduce significant latency that affects profiling accuracy. Profiler logging typically requires asynchronous, lock-free logging mechanisms that defer formatting and I/O operations to background threads.\n\nLog level management becomes critical because profiler debugging often requires detailed trace-level information, but enabling verbose logging in production environments can overwhelm log storage and processing systems. Dynamic log level adjustment allows enabling detailed logging for specific components or time periods without restarting the profiler.\n\n**Metrics collection** provides observability into profiler behavior and performance characteristics. Key metrics include sampling rates achieved vs. configured, symbol resolution cache hit rates, buffer utilization levels, and processing latency distributions. These metrics help identify performance bottlenecks and configuration issues before they affect profiling accuracy.\n\nProfiler metrics should be exported in formats compatible with standard monitoring systems (Prometheus, StatsD, etc.) to enable integration with existing observability infrastructure. This allows correlating profiler performance with overall system metrics and detecting environmental factors that affect profiling.\n\nEssential profiler metrics to track:\n\n| Metric Category | Specific Metrics | Purpose | Alert Thresholds |\n|-----------------|------------------|---------|------------------|\n| Sampling Performance | Achieved vs configured frequency, signal delivery success rate | Detect sampling issues | <90% of configured rate |\n| Symbol Resolution | Cache hit rate, lookup latency distribution, missing symbol rate | Monitor resolution performance | <80% cache hit rate |\n| Buffer Management | Buffer utilization, overflow events, processing latency | Prevent data loss | >90% buffer utilization |\n| Memory Tracking | Metadata overhead, allocation tracking coverage, leak detection runtime | Monitor tracking efficiency | >10% metadata overhead |\n| Overall Health | Error rates, crash frequency, profiler memory usage growth | System stability | Any crash events |\n\n#### Diagnostic Test Programs\n\n**Synthetic test programs** enable controlled testing of profiler components under known conditions. These programs generate predictable execution patterns, allocation behaviors, and call stack structures that allow validating profiler accuracy and identifying performance issues.\n\nCPU-intensive test programs should generate recognizable hot spots that appear prominently in flame graphs. Simple programs with tight loops, recursive functions, and known call patterns allow verifying that sampling captures expected execution patterns. Mathematical computations (prime number generation, matrix operations) provide sustained CPU usage with predictable profiling signatures.\n\n**Memory allocation test programs** create controlled allocation patterns that exercise leak detection and allocation tracking capabilities. These programs should include definite memory leaks, false positive scenarios (allocations freed at shutdown), and various allocation sizes and patterns. Memory stress tests with many small allocations help validate metadata management under load.\n\nMulti-threaded test programs verify that profiler components handle concurrency correctly. Thread synchronization patterns, shared data structures, and inter-thread communication create complex execution patterns that can expose race conditions and signal handling issues in the profiler itself.\n\n**Regression test suites** capture known profiler behaviors and detect when changes break existing functionality. These tests should include both positive cases (verifying correct behavior) and negative cases (ensuring graceful handling of error conditions). Automated regression testing prevents introducing bugs when adding features or optimizing performance.\n\n#### Interactive Debugging Techniques\n\n**Live profiler inspection** allows examining profiler state while it's actively collecting data. This might involve attaching debuggers to the profiler process itself, though this creates observer paradox issues where debugging the profiler affects its behavior. Non-intrusive inspection through shared memory regions or Unix domain sockets provides visibility without affecting sampling accuracy.\n\n**Flame graph analysis techniques** help identify profiling anomalies and validate profiler accuracy. Unexpected flame graph patterns (missing expected functions, impossible call relationships, skewed sample distributions) often indicate profiler bugs rather than target program behavior. Comparing flame graphs from the same program using different profilers can identify systematic biases or errors.\n\n**Symbol resolution validation** involves comparing resolved symbols against known ground truth. Running profilers on programs with known function names and call patterns allows detecting symbol resolution errors. Debugging information validators can check that resolved symbols are consistent with available debug data.\n\n**Memory tracking validation** requires comparing allocation tracking results against known allocation patterns. Programs with controlled allocation behaviors allow verifying that all allocations are captured and that leak detection identifies only actual leaks. Allocation tracking can be validated by instrumenting test programs with manual allocation counting.\n\nDebugging workflow recommendations:\n\n| Issue Category | Initial Diagnosis | Deep Investigation | Validation Approach |\n|----------------|-------------------|-------------------|-------------------|\n| Missing samples | Check signal delivery and handler installation | Trace signal handling with strace/ltrace | Compare with external profiler results |\n| Symbol resolution failures | Verify debug package installation and paths | Examine ELF headers and DWARF data with objdump | Test with simple programs with known symbols |\n| Memory tracking gaps | Check function interposition and threading | Analyze allocation patterns with allocator debugging | Compare with valgrind or AddressSanitizer |\n| Performance overhead | Measure overhead with controlled workloads | Profile the profiler itself | Validate against overhead budgets |\n| Flame graph anomalies | Review aggregation logic and sample processing | Trace data flow through processing pipeline | Generate flame graphs for known call patterns |\n\n#### Recovery and Graceful Degradation\n\n**Error recovery strategies** must maintain profiling functionality even when individual components fail. Component isolation ensures that symbol resolution failures don't prevent sample collection, and that visualization errors don't corrupt collected profiling data. Each component should have fallback behaviors that provide reduced functionality rather than complete failure.\n\n**Graceful degradation** involves detecting when profiling overhead exceeds acceptable limits and automatically reducing profiling intensity. This might involve decreasing sampling frequency, disabling expensive symbol resolution, or switching to statistical sampling modes that maintain basic functionality with lower overhead.\n\n**State recovery** after profiler crashes or restarts requires persisting critical profiling state to stable storage. Sample buffers, symbol caches, and allocation tracking metadata should be recoverable to avoid losing profiling data during profiler restarts. However, recovery mechanisms must not introduce additional overhead during normal operation.\n\n### Implementation Guidance\n\nBuilding robust debugging capabilities into a profiler requires implementing systematic error detection, logging, and recovery mechanisms that provide visibility into profiler behavior without compromising performance or accuracy.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Logging Framework | Python logging module with async handlers | Structured logging with JSON output to centralized systems |\n| Metrics Collection | Simple counters with periodic output | Prometheus client library with custom metrics |\n| Error Tracking | Exception logging with stack traces | Error aggregation with Sentry or similar service |\n| Diagnostic Tools | Basic print debugging and manual testing | Automated test harnesses with known-good baselines |\n| State Inspection | JSON dumps of internal state | Live debugging APIs with minimal overhead |\n| Performance Monitoring | Basic timing measurements | Detailed performance profiling of the profiler itself |\n\n#### Recommended File Structure\n\n```python\nprofiler/\n  debugging/\n    __init__.py                    ← debugging utilities exports\n    logger.py                      ← structured logging setup\n    metrics.py                     ← profiler metrics collection\n    validators.py                  ← data validation utilities\n    test_programs/                 ← synthetic test programs\n      cpu_intensive.py             ← CPU profiling test cases\n      memory_patterns.py           ← memory allocation test patterns\n      threading_stress.py          ← multi-threaded test scenarios\n    diagnostics/\n      signal_debugging.py          ← signal handler diagnostics\n      symbol_validation.py         ← symbol resolution testing\n      memory_validation.py         ← allocation tracking validation\n    recovery/\n      error_handlers.py            ← error recovery mechanisms\n      state_persistence.py         ← profiler state backup/restore\n```\n\n#### Core Infrastructure Code\n\nComplete logging infrastructure that handles the unique requirements of profiler debugging:\n\n```python\nimport logging\nimport asyncio\nimport json\nimport time\nimport threading\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom collections import defaultdict, deque\nfrom enum import Enum\n\nclass LogLevel(Enum):\n    DEBUG = \"debug\"\n    INFO = \"info\"\n    WARNING = \"warning\"\n    ERROR = \"error\"\n    CRITICAL = \"critical\"\n\n@dataclass\nclass ProfilerLogEvent:\n    timestamp: float\n    level: LogLevel\n    component: str\n    message: str\n    context: Dict[str, Any]\n    thread_id: int\n    stack_trace: Optional[str] = None\n\nclass AsyncProfilerLogger:\n    \"\"\"High-performance async logger designed for profiler debugging.\"\"\"\n    \n    def __init__(self, max_buffer_size: int = 10000):\n        self.max_buffer_size = max_buffer_size\n        self.log_buffer = deque(maxlen=max_buffer_size)\n        self.buffer_lock = threading.Lock()\n        self.dropped_count = 0\n        self.background_task = None\n        self.shutdown_event = threading.Event()\n        \n    def start_background_logging(self, output_file: str):\n        \"\"\"Start background thread for async log processing.\"\"\"\n        self.output_file = output_file\n        self.background_task = threading.Thread(target=self._background_worker, daemon=True)\n        self.background_task.start()\n    \n    def _background_worker(self):\n        \"\"\"Background thread that processes log events.\"\"\"\n        with open(self.output_file, 'w') as f:\n            while not self.shutdown_event.is_set():\n                events_to_write = []\n                \n                with self.buffer_lock:\n                    while self.log_buffer and len(events_to_write) < 100:\n                        events_to_write.append(self.log_buffer.popleft())\n                \n                for event in events_to_write:\n                    json.dump(asdict(event), f)\n                    f.write('\\n')\n                    f.flush()\n                \n                if not events_to_write:\n                    time.sleep(0.01)  # Small delay when no events\n    \n    def log_event(self, level: LogLevel, component: str, message: str, \n                  context: Optional[Dict[str, Any]] = None):\n        \"\"\"Log event with minimal latency impact.\"\"\"\n        event = ProfilerLogEvent(\n            timestamp=time.time(),\n            level=level,\n            component=component,\n            message=message,\n            context=context or {},\n            thread_id=threading.get_ident()\n        )\n        \n        with self.buffer_lock:\n            if len(self.log_buffer) >= self.max_buffer_size:\n                self.dropped_count += 1\n                return False\n            \n            self.log_buffer.append(event)\n            return True\n\nclass ProfilerMetrics:\n    \"\"\"Lightweight metrics collection for profiler components.\"\"\"\n    \n    def __init__(self):\n        self.counters = defaultdict(int)\n        self.histograms = defaultdict(list)\n        self.gauges = {}\n        self.start_time = time.time()\n        self.lock = threading.Lock()\n    \n    def increment_counter(self, name: str, value: int = 1, labels: Optional[Dict[str, str]] = None):\n        \"\"\"Thread-safe counter increment.\"\"\"\n        key = self._make_key(name, labels)\n        with self.lock:\n            self.counters[key] += value\n    \n    def record_histogram(self, name: str, value: float, labels: Optional[Dict[str, str]] = None):\n        \"\"\"Record histogram value with automatic trimming.\"\"\"\n        key = self._make_key(name, labels)\n        with self.lock:\n            self.histograms[key].append(value)\n            # Keep only recent values to prevent unbounded growth\n            if len(self.histograms[key]) > 1000:\n                self.histograms[key] = self.histograms[key][-1000:]\n    \n    def set_gauge(self, name: str, value: float, labels: Optional[Dict[str, str]] = None):\n        \"\"\"Set gauge value.\"\"\"\n        key = self._make_key(name, labels)\n        with self.lock:\n            self.gauges[key] = value\n    \n    def _make_key(self, name: str, labels: Optional[Dict[str, str]]) -> str:\n        \"\"\"Create metric key from name and labels.\"\"\"\n        if not labels:\n            return name\n        label_str = ','.join(f\"{k}={v}\" for k, v in sorted(labels.items()))\n        return f\"{name}{{{label_str}}}\"\n    \n    def export_metrics(self) -> Dict[str, Any]:\n        \"\"\"Export all metrics for external consumption.\"\"\"\n        with self.lock:\n            return {\n                'counters': dict(self.counters),\n                'gauges': dict(self.gauges),\n                'histograms': {k: {\n                    'count': len(v),\n                    'min': min(v) if v else 0,\n                    'max': max(v) if v else 0,\n                    'avg': sum(v) / len(v) if v else 0\n                } for k, v in self.histograms.items()},\n                'uptime_seconds': time.time() - self.start_time\n            }\n\n# Global instances for profiler-wide use\nprofiler_logger = AsyncProfilerLogger()\nprofiler_metrics = ProfilerMetrics()\n\ndef setup_profiler_debugging(log_file: str, metrics_export_interval: int = 60):\n    \"\"\"Initialize profiler debugging infrastructure.\"\"\"\n    profiler_logger.start_background_logging(log_file)\n    \n    # Start metrics export timer\n    def export_metrics():\n        while True:\n            time.sleep(metrics_export_interval)\n            metrics = profiler_metrics.export_metrics()\n            profiler_logger.log_event(LogLevel.INFO, \"metrics\", \"periodic_export\", metrics)\n    \n    metrics_thread = threading.Thread(target=export_metrics, daemon=True)\n    metrics_thread.start()\n```\n\nComplete validation framework for profiler data integrity:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Any, Optional\nfrom enum import Enum\n\nclass ValidationResult(Enum):\n    PASS = \"pass\"\n    WARN = \"warning\"\n    FAIL = \"failure\"\n\n@dataclass\nclass ValidationIssue:\n    result: ValidationResult\n    message: str\n    context: Dict[str, Any]\n    fix_suggestion: Optional[str] = None\n\nclass ProfilerDataValidator:\n    \"\"\"Comprehensive validation for profiler data structures.\"\"\"\n    \n    def validate_sample_batch(self, batch: 'SampleBatch') -> List[ValidationIssue]:\n        \"\"\"Validate sample batch for common issues.\"\"\"\n        issues = []\n        \n        # TODO 1: Check timestamp ordering within batch\n        # TODO 2: Validate all samples have reasonable thread/process IDs\n        # TODO 3: Check for duplicate samples (same timestamp + thread)\n        # TODO 4: Validate stack frame addresses are in reasonable ranges\n        # TODO 5: Check sampling frequency matches expected rate\n        \n        return issues\n    \n    def validate_symbol_resolution(self, symbols: List['Symbol']) -> List[ValidationIssue]:\n        \"\"\"Validate symbol resolution results.\"\"\"\n        issues = []\n        \n        # TODO 1: Check for overlapping symbol address ranges\n        # TODO 2: Validate symbol names are not empty or malformed\n        # TODO 3: Check that file paths exist and are readable\n        # TODO 4: Validate line numbers are within file bounds\n        # TODO 5: Check for reasonable symbol sizes\n        \n        return issues\n    \n    def validate_memory_allocations(self, allocations: List['Allocation']) -> List[ValidationIssue]:\n        \"\"\"Validate memory allocation tracking data.\"\"\"\n        issues = []\n        \n        # TODO 1: Check allocation IDs are unique and sequential\n        # TODO 2: Validate allocation sizes are positive and reasonable\n        # TODO 3: Check timestamps are monotonically increasing\n        # TODO 4: Validate thread IDs exist in process\n        # TODO 5: Check stack traces are complete and valid\n        \n        return issues\n    \n    def validate_flame_graph_data(self, root: 'FlameNode') -> List[ValidationIssue]:\n        \"\"\"Validate flame graph tree structure.\"\"\"\n        issues = []\n        \n        # TODO 1: Check tree structure is acyclic\n        # TODO 2: Validate sample counts sum correctly at each level\n        # TODO 3: Check all nodes have valid function names\n        # TODO 4: Validate parent-child relationships are consistent\n        # TODO 5: Check depth limits are respected\n        \n        return issues\n```\n\n#### Core Debugging Utilities\n\nEssential debugging utilities that profiler components can use:\n\n```python\nclass DebugContext:\n    \"\"\"Context manager for debugging profiler operations.\"\"\"\n    \n    def __init__(self, operation_name: str, component: str):\n        self.operation_name = operation_name\n        self.component = component\n        self.start_time = None\n        self.context_data = {}\n    \n    def __enter__(self):\n        self.start_time = time.time()\n        profiler_logger.log_event(LogLevel.DEBUG, self.component, \n                                f\"Starting {self.operation_name}\", self.context_data)\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        duration = time.time() - self.start_time\n        self.context_data['duration_seconds'] = duration\n        \n        if exc_type:\n            profiler_logger.log_event(LogLevel.ERROR, self.component,\n                                    f\"Failed {self.operation_name}: {exc_val}\", self.context_data)\n            profiler_metrics.increment_counter(f\"{self.component}_errors\")\n        else:\n            profiler_logger.log_event(LogLevel.DEBUG, self.component,\n                                    f\"Completed {self.operation_name}\", self.context_data)\n        \n        profiler_metrics.record_histogram(f\"{self.component}_operation_duration\", duration)\n    \n    def add_context(self, key: str, value: Any):\n        \"\"\"Add context information for debugging.\"\"\"\n        self.context_data[key] = value\n\ndef handle_signal_delivery_failure(target_pid: int, expected_samples: int, actual_samples: int) -> bool:\n    \"\"\"Handle failed signal delivery and determine recovery strategy.\"\"\"\n    # TODO 1: Calculate sample delivery success rate\n    # TODO 2: Check if target process is in uninterruptible sleep\n    # TODO 3: Verify signal mask configuration\n    # TODO 4: Adjust sampling frequency if delivery rate too low\n    # TODO 5: Return True if recovery possible, False if should abort\n    pass\n\ndef recover_from_stack_corruption(context: 'RegisterContext', partial_stack: List['StackFrame']) -> Optional[List['StackFrame']]:\n    \"\"\"Attempt to recover usable stack from corrupted unwind.\"\"\"\n    # TODO 1: Validate existing stack frames for reasonableness\n    # TODO 2: Attempt alternative unwinding methods (DWARF vs frame pointer)\n    # TODO 3: Use heuristics to repair corrupted frame pointer chains\n    # TODO 4: Fill gaps with anonymous frames if necessary\n    # TODO 5: Return repaired stack or None if unrecoverable\n    pass\n\ndef detect_recursive_malloc() -> bool:\n    \"\"\"Detect recursion in allocation tracking.\"\"\"\n    # TODO 1: Check thread-local recursion flag\n    # TODO 2: Examine call stack for malloc/free functions\n    # TODO 3: Return True if recursion detected\n    pass\n```\n\n#### Milestone Validation Checkpoints\n\nAfter implementing each milestone, use these validation procedures:\n\n**Milestone 1 - Stack Sampling Validation:**\n```bash\n# Test basic sampling functionality\npython -m profiler.debugging.validators validate_milestone_1_stack_sampling\n\n# Expected output: \n# - Sampling rate within 10% of configured rate\n# - Stack traces contain reasonable function addresses\n# - No signal delivery failures or handler crashes\n# - Buffer utilization stays below 90%\n```\n\n**Milestone 2 - Symbol Resolution Validation:**\n```bash\n# Test symbol resolution with known binaries  \npython -m profiler.debugging.validators validate_milestone_2_symbol_resolution\n\n# Expected output:\n# - >95% of addresses resolve to function names\n# - Symbol cache hit rate >80% after warmup\n# - No symbol overlaps or invalid address ranges\n# - DWARF parsing completes without errors\n```\n\n**Milestone 3 - Flame Graph Validation:**\n```bash\n# Test flame graph generation\npython -m profiler.debugging.validators validate_milestone_3_flame_graphs\n\n# Expected output:\n# - SVG file generates without errors\n# - Sample counts sum correctly at each level\n# - Interactive features (zoom, search) work\n# - Color schemes render distinctly\n```\n\n**Milestone 4 - Memory Profiling Validation:**\n```bash\n# Test memory tracking\npython -m profiler.debugging.validators validate_milestone_4_memory_profiling\n\n# Expected output:\n# - All allocations captured without recursion\n# - Leak detection identifies only actual leaks\n# - Memory overhead <10% of tracked allocations\n# - No metadata corruption detected\n\n```\n\n\n## Future Extensions\n\n> **Milestone(s):** Future directions building on all milestones (1-4) — extending the profiler with advanced profiling features and scalability enhancements beyond the core stack sampling, symbol resolution, flame graph generation, and memory profiling capabilities\n\n### Mental Model: The Observatory Expansion\n\nThink of the current profiler as a personal telescope in your backyard — it can observe nearby stars (local processes) with good detail using basic optical instruments (stack sampling and memory tracking). Future extensions transform this into a full observatory complex: adding specialized instruments like radio telescopes (hardware performance counters) to detect different phenomena, building an array of synchronized telescopes (distributed profiling) to observe larger cosmic events (distributed systems), and installing real-time streaming equipment (live analysis) to broadcast discoveries as they happen. Each extension leverages the solid foundation of the original telescope while expanding its reach and capabilities.\n\nThe architectural foundation we've built provides natural extension points for these enhancements. The modular component design with clear data flow pipelines allows new data sources to integrate seamlessly, while the symbol resolution and visualization infrastructure can adapt to display new types of profiling information without fundamental redesign.\n\n### Advanced Profiling Features\n\nAdvanced profiling features extend the core capabilities by adding new data sources and analysis techniques that provide deeper insights into program behavior. These extensions leverage the existing sampling, symbolization, and visualization infrastructure while introducing specialized collection mechanisms and enhanced analysis algorithms.\n\n#### Hardware Performance Counters Integration\n\nHardware performance counters represent specialized CPU registers that track low-level execution events like cache misses, branch mispredictions, memory stall cycles, and instruction throughput. Modern processors expose hundreds of these counters through performance monitoring units, providing visibility into microarchitectural behavior that software-based sampling cannot observe.\n\n> **Decision: Event-Based Sampling with Hardware Counters**\n> - **Context**: Software timer sampling provides call stack visibility but misses microarchitectural bottlenecks like cache behavior, branch prediction efficiency, and memory bandwidth utilization that significantly impact performance\n> - **Options Considered**: \n>   - Separate hardware counter tool requiring manual correlation\n>   - Integrated counter sampling synchronized with stack sampling  \n>   - Pure hardware event sampling without stack context\n> - **Decision**: Integrate hardware counter sampling with existing stack sampling using Linux perf_event_open system calls\n> - **Rationale**: Synchronizing hardware events with call stack context enables attributing microarchitectural costs to specific functions, providing actionable optimization guidance that neither approach delivers alone\n> - **Consequences**: Requires elevated privileges for counter access, adds complexity to sample correlation, but enables root cause analysis of performance bottlenecks invisible to software sampling\n\nThe integration extends the existing `Sample` data structure to include hardware event counts collected alongside each stack trace. The sampler component configures performance monitoring counters using the perf_event_open system call, enabling overflow sampling where hardware events trigger sample collection rather than timer signals. This approach captures both the call stack context and the associated hardware costs in a single sample.\n\n| Hardware Counter Type | Event Examples | Performance Insight | Integration Method |\n|---------------------|----------------|-------------------|------------------|\n| Cache Performance | L1/L2/L3 cache misses, cache references | Memory access efficiency, data locality issues | Counter overflow triggers stack sample |\n| Branch Prediction | Branch instructions, branch misses | Control flow predictability, loop efficiency | Sample includes branch statistics |\n| Memory Subsystem | Memory loads, stores, bandwidth utilization | Memory bottleneck identification | Memory event sampling with stack context |\n| Instruction Pipeline | Instructions retired, stall cycles | CPU utilization efficiency, pipeline bubbles | Instruction-based sampling frequency |\n| Power and Thermal | CPU energy consumption, thermal throttling | Power efficiency analysis, thermal constraints | Energy-aware profiling periods |\n\nThe flame graph visualization adapts to display hardware event data through enhanced color coding and tooltip information. Instead of showing only sample counts, flame graph nodes can represent cache miss rates, instructions per cycle, or energy consumption per function. The interactive SVG generation includes additional overlays that switch between different hardware event views, enabling developers to correlate software structure with microarchitectural behavior.\n\n#### Custom Event Sampling\n\nCustom event sampling enables profiling application-specific events and user-defined performance metrics beyond standard CPU and memory behavior. This extension allows developers to instrument critical application logic with custom sampling points that integrate seamlessly with existing profiling infrastructure.\n\nThe implementation introduces a custom event registration API that applications can use to define domain-specific sampling events. These events integrate with the existing sampling infrastructure by extending the `SampleType` enumeration to include user-defined event categories. Custom events can trigger additional stack capture or annotate existing samples with application context.\n\n| Custom Event Category | Example Events | Use Case | Integration Approach |\n|----------------------|----------------|---------|---------------------|\n| Application Logic | Database query completion, cache operations | Business logic profiling | Event-driven stack sampling |\n| Resource Usage | File I/O operations, network requests | I/O bottleneck analysis | Asynchronous event correlation |\n| User Interactions | UI event processing, request handling | User experience optimization | Event timestamp correlation |\n| System Integration | External service calls, message processing | Distributed system analysis | Cross-process event tracking |\n| Performance Metrics | Custom latency measurements, throughput counters | Domain-specific optimization | Metric annotation of samples |\n\nThe symbol resolution component extends to handle custom event symbols by maintaining an application-provided symbol registry. This registry maps custom event identifiers to human-readable names and metadata, enabling flame graph visualization of application-specific profiling data with the same symbolic richness as system-level profiling.\n\n#### Multi-Language Support\n\nMulti-language support enables profiling polyglot applications that combine multiple programming languages within a single process or across cooperating processes. Modern applications frequently integrate Python, Go, Rust, C++, JavaScript, and other languages, requiring profiler extensions that understand each language's runtime characteristics and calling conventions.\n\nThe symbol resolution component extends to handle language-specific symbol formats and runtime environments. Each language runtime provides different mechanisms for stack unwinding and symbol lookup, requiring specialized unwinding strategies that integrate with the core profiler infrastructure.\n\n| Language Runtime | Stack Unwinding Method | Symbol Resolution | Integration Challenges |\n|-----------------|----------------------|-------------------|----------------------|\n| Python | Python C API frame walking | Python bytecode to source mapping | GIL interaction, bytecode interpretation |\n| Go | Runtime stack scanner | Go symbol table format | Goroutine multiplexing, runtime symbols |\n| Rust | DWARF unwinding | Cargo symbol resolution | Name mangling, trait object symbols |\n| JavaScript (V8) | V8 profiler API | JIT code mapping | Dynamic compilation, optimized code |\n| Java (JVM) | JVMTI interface | Class file symbol mapping | JIT compilation, class loading |\n\nThe implementation maintains language-specific unwinding modules that register with the core sampling infrastructure. When unwinding encounters a frame from a specific language runtime, it delegates to the appropriate language-specific unwinder that understands the runtime's frame layout and symbol conventions. The unified flame graph visualization displays mixed-language call stacks with color coding to distinguish language boundaries.\n\nThe aggregation component handles language interoperability by normalizing symbol names and call conventions across language boundaries. This normalization enables accurate aggregation of call stacks that cross language boundaries while preserving the ability to drill down into language-specific implementation details.\n\n#### Advanced Memory Analysis\n\nAdvanced memory analysis extends basic allocation tracking with sophisticated analysis techniques that provide deeper insights into memory usage patterns and performance characteristics. These extensions analyze temporal allocation patterns, memory access behaviors, and heap fragmentation to identify optimization opportunities beyond simple leak detection.\n\nThe memory profiling component enhances allocation tracking with temporal analysis that identifies memory usage trends and allocation lifecycle patterns. This analysis correlates allocation timing with application behavior to identify memory hotspots and allocation inefficiencies.\n\n| Analysis Technique | Memory Insight | Implementation Approach | Visualization Method |\n|--------------------|----------------|------------------------|---------------------|\n| Allocation Lifetime Analysis | Memory holding time distributions | Timestamp-based tracking | Allocation duration histograms |\n| Spatial Locality Analysis | Memory access pattern efficiency | Address-based clustering | Memory layout visualization |\n| Temporal Allocation Patterns | Memory usage trends over time | Time-series allocation tracking | Memory usage timeline graphs |\n| Heap Fragmentation Analysis | Memory layout efficiency | Free space tracking | Fragmentation heatmaps |\n| Memory Access Profiling | Cache-friendly allocation patterns | Hardware counter correlation | Access pattern flame graphs |\n\nThe enhanced memory tracking correlates allocation patterns with performance counters to identify memory access inefficiencies. By combining allocation site information with cache miss counters, the profiler can identify data structures that cause cache thrashing or memory bandwidth bottlenecks, providing optimization guidance that basic allocation tracking cannot deliver.\n\n### Scalability and Performance\n\nScalability and performance extensions address the fundamental limitations of single-process profiling by enabling large-scale profiling deployments and real-time analysis capabilities. These extensions transform the profiler from a development tool into a production monitoring system capable of continuous performance analysis across distributed systems.\n\n#### Distributed Profiling\n\nDistributed profiling enables coordinated profiling across multiple processes, machines, and services in a distributed system. This extension provides visibility into system-wide performance characteristics and cross-service interaction patterns that single-process profiling cannot capture.\n\n> **Decision: Federated Profiling Architecture**\n> - **Context**: Modern applications consist of hundreds of microservices across dozens of machines, making single-process profiling inadequate for understanding system-wide performance bottlenecks and service interaction costs\n> - **Options Considered**:\n>   - Centralized profiling server collecting all samples\n>   - Federated profiling with hierarchical aggregation\n>   - Independent profilers with offline correlation\n> - **Decision**: Implement federated profiling with local aggregation and hierarchical sample merging\n> - **Rationale**: Centralized collection creates network bottlenecks and single points of failure, while offline correlation loses temporal relationships; federated architecture scales horizontally while preserving cross-service correlation\n> - **Consequences**: Requires distributed coordination protocols and consistent timestamp synchronization, but enables scalable system-wide profiling with preserved causal relationships\n\nThe distributed profiling implementation extends the existing profiler with cluster coordination capabilities that enable synchronized profiling across multiple processes and machines. Each node runs a local profiler instance that coordinates with a cluster controller to synchronize profiling periods and aggregate results hierarchically.\n\n| Distribution Component | Responsibility | Implementation | Coordination Method |\n|----------------------|----------------|----------------|-------------------|\n| Cluster Controller | Profiling coordination, result aggregation | Central coordinator service | HTTP API with profiler agents |\n| Profiler Agent | Local profiling, sample preprocessing | Extended core profiler | gRPC communication with controller |\n| Sample Aggregator | Cross-node sample merging | Distributed aggregation service | Consistent hashing for data sharding |\n| Distributed Storage | Profile data persistence | Distributed file system | Object storage with metadata indexing |\n| Timeline Synchronizer | Cross-node timestamp correlation | NTP-based time synchronization | Timestamp adjustment protocols |\n\nThe distributed flame graph visualization combines samples from multiple services into unified visualizations that show cross-service call relationships. The flame graph generation component extends to handle distributed call stacks where individual stack frames may originate from different processes or machines, requiring correlation based on distributed tracing identifiers.\n\n#### Streaming Data Processing\n\nStreaming data processing enables real-time profiling analysis with continuous sample processing and live visualization updates. This extension transforms the profiler from a batch analysis tool into a real-time monitoring system that provides immediate feedback on performance changes and anomalies.\n\nThe streaming implementation replaces the batch processing pipeline with a continuous stream processing architecture that analyzes samples as they arrive. This architecture enables real-time anomaly detection, live flame graph updates, and immediate alerting on performance degradations.\n\n| Streaming Component | Processing Function | Implementation Technology | Performance Characteristic |\n|--------------------|-------------------|-------------------------|--------------------------|\n| Sample Stream Processor | Real-time sample analysis | Event stream processing framework | Sub-second processing latency |\n| Live Aggregation Engine | Continuous flame graph updates | Sliding window aggregation | Configurable window sizes |\n| Anomaly Detection | Performance regression identification | Statistical change detection | Real-time alert generation |\n| Live Visualization | Dynamic flame graph updates | WebSocket-based updates | Interactive real-time displays |\n| Stream Storage | Continuous profile archiving | Time-series database | Compressed sample storage |\n\nThe streaming aggregation maintains sliding window aggregates that enable real-time flame graph generation without requiring complete sample collection cycles. The aggregation windows adapt automatically based on sampling rate and available system resources, balancing analysis latency with resource consumption.\n\n#### Real-Time Analysis\n\nReal-time analysis extends streaming processing with advanced analytics that detect performance anomalies, identify regression patterns, and provide automated optimization recommendations. This extension enables proactive performance management with immediate feedback on code changes and deployment impacts.\n\nThe real-time analysis engine implements statistical models that establish performance baselines and detect significant deviations from expected behavior. These models adapt continuously to evolving application behavior while maintaining sensitivity to genuine performance regressions.\n\n| Analysis Capability | Detection Method | Response Action | Implementation Approach |\n|--------------------|-----------------|----------------|----------------------|\n| Performance Regression | Statistical change detection | Automated alerting | Baseline comparison algorithms |\n| Hotspot Evolution | Call stack pattern analysis | Optimization recommendations | Machine learning classification |\n| Memory Leak Prediction | Allocation trend extrapolation | Preventive warnings | Time-series forecasting |\n| Capacity Planning | Resource usage projection | Scaling recommendations | Predictive modeling |\n| Root Cause Analysis | Anomaly correlation | Automated diagnosis | Causal inference algorithms |\n\nThe real-time visualization adapts to display analysis results with live annotations and recommendations overlaid on flame graphs. The interactive SVG generation includes real-time highlighting of performance anomalies and optimization opportunities, enabling immediate identification of performance issues without manual analysis.\n\n### Extension Architecture Integration\n\nThe extension architecture leverages the modular design established in the core profiler to enable seamless integration of advanced features without disrupting existing functionality. Each extension integrates through well-defined plugin interfaces that maintain backward compatibility while enabling progressive feature adoption.\n\nThe plugin architecture extends the core `ProfilerConfig` structure with extension-specific configuration sections that enable selective feature activation. Extensions register with the main profiler through standardized interfaces that define data flow integration points and configuration requirements.\n\n| Integration Point | Extension Interface | Data Flow Impact | Configuration Method |\n|------------------|-------------------|------------------|-------------------|\n| Sample Collection | Custom samplers | Additional sample sources | Sampler plugin registration |\n| Symbol Resolution | Language-specific resolvers | Extended symbol lookup | Resolver plugin configuration |\n| Data Aggregation | Custom aggregators | Enhanced data processing | Aggregation pipeline extension |\n| Visualization | Advanced renderers | Extended output formats | Visualization plugin selection |\n| Analysis Engine | Custom analyzers | Real-time processing | Analysis pipeline registration |\n\nThe backward compatibility strategy ensures that existing profiler deployments continue functioning unchanged when extensions are available but not activated. The extension loading mechanism validates compatibility and gracefully degrades functionality when required dependencies are unavailable.\n\n> The fundamental insight enabling these extensions is that profiling is fundamentally a data pipeline problem — samples flow from collection through processing to visualization. By designing clean interfaces between pipeline stages, we enable arbitrary extensions at each stage without disrupting the overall architecture. This modularity transforms the profiler from a fixed-function tool into an extensible platform for performance analysis.\n\n### Common Extension Pitfalls\n\n⚠️ **Pitfall: Extension Compatibility Breaking**\nAdding extensions that modify core data structures without maintaining backward compatibility breaks existing tooling and configurations. This happens when extensions directly modify `Sample` or `StackFrame` structures instead of extending them through composition. The fix involves designing extension data as separate structures that attach to core types without modifying their existing fields, using composition patterns that preserve API stability.\n\n⚠️ **Pitfall: Performance Regression from Extensions**\nHeavy-weight extensions can introduce significant overhead that defeats the profiler's low-impact design goals. This occurs when extensions perform expensive operations in sampling hot paths or maintain large in-memory state. The solution requires careful performance budget allocation for each extension and lazy loading strategies that defer expensive operations outside critical sampling paths.\n\n⚠️ **Pitfall: Extension Configuration Complexity**\nMultiple extensions with independent configuration systems create an overwhelming configuration burden that makes the profiler difficult to deploy and maintain. This happens when each extension introduces its own configuration format and validation logic. The fix involves designing unified configuration schemas that provide sensible defaults and configuration validation that helps users understand extension interactions and conflicts.\n\n⚠️ **Pitfall: Distributed Profiling Clock Synchronization**\nDistributed profiling without proper clock synchronization produces meaningless cross-service correlation and timeline analysis. This occurs when different machines have significant clock skew that corrupts temporal relationships between samples. The solution requires implementing clock synchronization protocols and timestamp adjustment algorithms that account for network latency and clock drift across distributed profiling nodes.\n\n### Implementation Guidance\n\nThe extension implementation builds upon the existing profiler infrastructure while adding new capabilities through plugin interfaces and enhanced data processing pipelines. The following guidance provides concrete implementation strategies for the major extension categories.\n\n#### Technology Recommendations\n\n| Extension Category | Simple Option | Advanced Option |\n|-------------------|---------------|-----------------|\n| Hardware Counters | Linux perf_event_open syscalls | Intel PCM library integration |\n| Custom Events | Function pointer registration | Dynamic instrumentation (eBPF) |\n| Multi-Language | Language-specific APIs | Universal unwinding libraries |\n| Distributed Profiling | HTTP REST coordination | gRPC streaming coordination |\n| Streaming Processing | In-process queues | Apache Kafka integration |\n| Real-Time Analysis | Statistical algorithms | Machine learning frameworks |\n\n#### Recommended File Structure\n\n```\nprofiler/\n  cmd/\n    profiler/main.py           ← main profiler entry point\n    cluster-controller/main.py  ← distributed profiling coordinator\n  core/\n    sampling/sampler.py        ← core sampling infrastructure\n    symbols/resolver.py        ← core symbol resolution\n    visualization/flame_graph.py ← core flame graph generation\n  extensions/\n    hardware/\n      perf_counters.py         ← hardware counter integration\n      counter_sampler.py       ← hardware event sampling\n    languages/\n      python_unwinder.py       ← Python-specific stack unwinding\n      go_unwinder.py           ← Go runtime integration\n      language_registry.py     ← multi-language coordination\n    distributed/\n      cluster_coordinator.py   ← distributed profiling coordination\n      agent_client.py          ← profiler agent communication\n      sample_aggregator.py     ← cross-node sample merging\n    streaming/\n      stream_processor.py      ← real-time sample processing\n      live_aggregator.py       ← streaming aggregation engine\n      anomaly_detector.py      ← performance anomaly detection\n    analysis/\n      regression_detector.py   ← performance regression analysis\n      optimizer.py             ← automated optimization recommendations\n  plugins/\n    __init__.py                ← plugin discovery and loading\n    interfaces.py              ← plugin interface definitions\n    registry.py                ← extension registration system\n```\n\n#### Hardware Counter Integration Infrastructure\n\n```python\n\"\"\"\nHardware performance counter integration using Linux perf_event_open.\nProvides complete infrastructure for hardware event sampling.\n\"\"\"\nimport ctypes\nimport os\nimport struct\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\nfrom core.sampling.sampler import BaseSampler, Sample, StackFrame\n\n# Hardware counter event definitions from linux/perf_event.h\nPERF_COUNT_HW_CPU_CYCLES = 0\nPERF_COUNT_HW_INSTRUCTIONS = 1\nPERF_COUNT_HW_CACHE_REFERENCES = 2\nPERF_COUNT_HW_CACHE_MISSES = 3\nPERF_COUNT_HW_BRANCH_INSTRUCTIONS = 4\nPERF_COUNT_HW_BRANCH_MISSES = 5\n\n@dataclass\nclass HardwareEvent:\n    event_type: int\n    config: int\n    sample_period: int\n    name: str\n\n@dataclass  \nclass HardwareCounters:\n    cycles: int = 0\n    instructions: int = 0\n    cache_references: int = 0\n    cache_misses: int = 0\n    branch_instructions: int = 0\n    branch_misses: int = 0\n    \n    def get_ipc(self) -> float:\n        \"\"\"Instructions per cycle calculation.\"\"\"\n        return self.instructions / self.cycles if self.cycles > 0 else 0.0\n    \n    def get_cache_miss_rate(self) -> float:\n        \"\"\"Cache miss rate percentage.\"\"\" \n        return (self.cache_misses / self.cache_references * 100.0 \n                if self.cache_references > 0 else 0.0)\n\nclass HardwareCounterSampler(BaseSampler):\n    \"\"\"Hardware counter sampling using perf_event_open.\"\"\"\n    \n    def __init__(self, target_pid: int, events: List[HardwareEvent]):\n        super().__init__(target_pid)\n        self.events = events\n        self.event_fds: List[int] = []\n        self.counter_values = HardwareCounters()\n        \n    def start_sampling(self, target_pid: int) -> None:\n        \"\"\"Start hardware counter sampling.\"\"\"\n        # TODO: Open perf_event_open file descriptors for each hardware event\n        # TODO: Configure event sampling periods and overflow notifications  \n        # TODO: Set up signal handler for counter overflow events\n        # TODO: Enable counter collection and start monitoring\n        # Hint: Use ctypes to call perf_event_open syscall directly\n        \n    def handle_counter_overflow(self, signum: int, frame) -> None:\n        \"\"\"Handle hardware counter overflow signal.\"\"\"\n        # TODO: Read current counter values from perf event file descriptors\n        # TODO: Capture current call stack using existing stack unwinding\n        # TODO: Create Sample with both stack frames and hardware counter data\n        # TODO: Store sample in collection buffer for later processing\n        \n    def read_counter_values(self) -> HardwareCounters:\n        \"\"\"Read current hardware counter values.\"\"\" \n        # TODO: Read counter values from each perf event file descriptor\n        # TODO: Parse counter data from kernel perf event format\n        # TODO: Update HardwareCounters structure with current values\n        # TODO: Return complete counter snapshot\n        pass\n        \n    def stop_sampling(self) -> List[Sample]:\n        \"\"\"Stop hardware counter sampling.\"\"\"\n        # TODO: Disable hardware counter collection\n        # TODO: Close perf event file descriptors\n        # TODO: Return collected samples with hardware counter data\n        pass\n```\n\n#### Custom Event Sampling Framework\n\n```python\n\"\"\"\nCustom event sampling framework for application-specific profiling.\nEnables user-defined events to trigger stack sampling.\n\"\"\"\nfrom typing import Callable, Dict, Any, Optional\nfrom dataclasses import dataclass, field\nimport threading\nimport time\nfrom core.sampling.sampler import Sample, StackFrame\n\n@dataclass\nclass CustomEvent:\n    event_id: str\n    event_name: str\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    timestamp: float = field(default_factory=time.time)\n    thread_id: int = field(default_factory=threading.get_ident)\n\nclass CustomEventRegistry:\n    \"\"\"Registry for custom profiling events.\"\"\"\n    \n    def __init__(self):\n        self.event_handlers: Dict[str, Callable] = {}\n        self.event_samples: List[Sample] = []\n        self.sampling_enabled = False\n        \n    def register_event(self, event_id: str, handler: Callable[[CustomEvent], None]):\n        \"\"\"Register custom event handler.\"\"\"\n        # TODO: Validate event_id is unique and handler is callable\n        # TODO: Store event handler in registry with event_id as key\n        # TODO: Set up event triggering mechanism for registered events\n        pass\n        \n    def trigger_event(self, event_id: str, metadata: Dict[str, Any] = None) -> Optional[Sample]:\n        \"\"\"Trigger custom event and optionally capture stack.\"\"\"\n        # TODO: Create CustomEvent instance with provided metadata\n        # TODO: Capture current call stack if sampling is enabled\n        # TODO: Call registered event handler with event data\n        # TODO: Return Sample with custom event context if stack captured\n        pass\n        \n    def enable_sampling(self, capture_stacks: bool = True):\n        \"\"\"Enable stack capture for custom events.\"\"\"\n        # TODO: Enable sampling flag to capture stacks on event triggers\n        # TODO: Configure stack capture depth and filtering options\n        pass\n\n# Usage example for application integration\ndef setup_custom_events():\n    \"\"\"Example setup for application-specific custom events.\"\"\"\n    registry = CustomEventRegistry()\n    \n    # Database query profiling\n    def db_query_handler(event: CustomEvent):\n        query_time = event.metadata.get('duration_ms', 0)\n        if query_time > 100:  # Log slow queries\n            print(f\"Slow query detected: {query_time}ms\")\n            \n    registry.register_event('db_query', db_query_handler)\n    \n    # Cache operation profiling  \n    def cache_handler(event: CustomEvent):\n        hit_rate = event.metadata.get('hit_rate', 0)\n        if hit_rate < 0.8:  # Alert on low hit rates\n            print(f\"Low cache hit rate: {hit_rate:.2%}\")\n            \n    registry.register_event('cache_operation', cache_handler)\n    \n    return registry\n```\n\n#### Multi-Language Stack Unwinding\n\n```python\n\"\"\"\nMulti-language stack unwinding supporting Python, Go, Rust, and C/C++.\nCoordinates language-specific unwinding strategies.\n\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional, Dict, Any\nfrom core.symbols.resolver import StackFrame\nimport ctypes\n\nclass LanguageUnwinder(ABC):\n    \"\"\"Base class for language-specific stack unwinding.\"\"\"\n    \n    @abstractmethod\n    def can_unwind_frame(self, frame_address: int) -> bool:\n        \"\"\"Check if this unwinder can handle the given frame.\"\"\"\n        pass\n        \n    @abstractmethod  \n    def unwind_stack(self, context: Any) -> List[StackFrame]:\n        \"\"\"Unwind stack using language-specific method.\"\"\"\n        pass\n        \n    @abstractmethod\n    def get_language_name(self) -> str:\n        \"\"\"Return language name for this unwinder.\"\"\"\n        pass\n\nclass PythonUnwinder(LanguageUnwinder):\n    \"\"\"Python-specific stack unwinding using interpreter frames.\"\"\"\n    \n    def can_unwind_frame(self, frame_address: int) -> bool:\n        # TODO: Check if frame_address points to Python interpreter code\n        # TODO: Validate frame address against Python runtime memory ranges\n        # TODO: Return True if this appears to be a Python frame\n        pass\n        \n    def unwind_stack(self, context: Any) -> List[StackFrame]:\n        # TODO: Access Python interpreter frame chain using C API\n        # TODO: Extract Python function names and source file information\n        # TODO: Convert Python bytecode locations to source line numbers  \n        # TODO: Build StackFrame list with Python-specific symbol information\n        pass\n        \n    def get_language_name(self) -> str:\n        return \"Python\"\n\nclass GoUnwinder(LanguageUnwinder):\n    \"\"\"Go-specific stack unwinding using runtime stack scanner.\"\"\"\n    \n    def can_unwind_frame(self, frame_address: int) -> bool:\n        # TODO: Check if frame_address is within Go executable memory\n        # TODO: Look for Go runtime stack management symbols\n        # TODO: Validate against known Go calling conventions\n        pass\n        \n    def unwind_stack(self, context: Any) -> List[StackFrame]:\n        # TODO: Use Go runtime stack scanning to find frame boundaries\n        # TODO: Parse Go symbol table format for function names\n        # TODO: Handle Go goroutine stack switching and runtime calls\n        # TODO: Build StackFrame list with Go-specific naming conventions\n        pass\n        \n    def get_language_name(self) -> str:\n        return \"Go\"\n\nclass MultiLanguageUnwinder:\n    \"\"\"Coordinates unwinding across multiple language runtimes.\"\"\"\n    \n    def __init__(self):\n        self.unwinders: List[LanguageUnwinder] = []\n        self.language_cache: Dict[int, LanguageUnwinder] = {}\n        \n    def register_unwinder(self, unwinder: LanguageUnwinder):\n        \"\"\"Register language-specific unwinder.\"\"\"\n        # TODO: Add unwinder to registry with priority ordering\n        # TODO: Validate unwinder implements required interface methods\n        # TODO: Clear language cache when new unwinders are added\n        pass\n        \n    def unwind_mixed_stack(self, context: Any) -> List[StackFrame]:\n        \"\"\"Unwind stack handling multiple language transitions.\"\"\"\n        # TODO: Start with native unwinding to get initial frame addresses\n        # TODO: For each frame, find appropriate language-specific unwinder\n        # TODO: Use cached unwinder for previously seen frame addresses\n        # TODO: Merge language-specific frames into unified stack trace\n        # TODO: Handle transitions between different language runtimes\n        pass\n```\n\n#### Distributed Profiling Coordination\n\n```python\n\"\"\"\nDistributed profiling coordination using hierarchical sample aggregation.\nProvides cluster-wide profiling with local preprocessing.\n\"\"\"\nimport asyncio\nimport json\nfrom typing import Dict, List, Set\nfrom dataclasses import dataclass, asdict\nimport aiohttp\nfrom core.sampling.sampler import Profile, Sample\n\n@dataclass\nclass ProfilerNode:\n    node_id: str\n    address: str\n    port: int\n    capabilities: Set[str]\n    last_heartbeat: float\n\n@dataclass\nclass ProfilingSession:\n    session_id: str\n    target_processes: Dict[str, int]  # node_id -> pid\n    duration_seconds: float\n    sampling_config: Dict[str, Any]\n    start_time: float\n\nclass ClusterController:\n    \"\"\"Coordinates distributed profiling across multiple nodes.\"\"\"\n    \n    def __init__(self, listen_port: int = 8080):\n        self.listen_port = listen_port\n        self.active_nodes: Dict[str, ProfilerNode] = {}\n        self.profiling_sessions: Dict[str, ProfilingSession] = {}\n        self.session_results: Dict[str, List[Profile]] = {}\n        \n    async def start_distributed_session(self, \n                                       session_config: Dict[str, Any]) -> str:\n        \"\"\"Start coordinated profiling across cluster.\"\"\"\n        # TODO: Generate unique session ID and validate configuration\n        # TODO: Select appropriate nodes based on target processes\n        # TODO: Send synchronized start commands to selected nodes\n        # TODO: Configure consistent sampling parameters across nodes\n        # TODO: Return session ID for tracking profiling progress\n        pass\n        \n    async def collect_session_results(self, session_id: str) -> Profile:\n        \"\"\"Collect and merge profiling results from all nodes.\"\"\"\n        # TODO: Wait for completion signals from all participating nodes\n        # TODO: Retrieve Profile data from each node via HTTP API\n        # TODO: Merge sample data while preserving temporal relationships\n        # TODO: Aggregate symbol information across nodes\n        # TODO: Generate unified Profile with cross-service call stacks\n        pass\n        \n    async def handle_node_heartbeat(self, node_data: Dict[str, Any]):\n        \"\"\"Process heartbeat from profiler agent node.\"\"\"\n        # TODO: Update node status and capabilities in active_nodes\n        # TODO: Check for session assignments that need node participation\n        # TODO: Send pending profiling commands to newly available nodes\n        pass\n\nclass ProfilerAgent:\n    \"\"\"Local profiler agent that coordinates with cluster controller.\"\"\"\n    \n    def __init__(self, node_id: str, controller_address: str):\n        self.node_id = node_id\n        self.controller_address = controller_address\n        self.local_profiler = None\n        self.active_sessions: Dict[str, Profile] = {}\n        \n    async def start_agent(self):\n        \"\"\"Start profiler agent and register with controller.\"\"\"\n        # TODO: Initialize local profiler with agent configuration\n        # TODO: Register with cluster controller and report capabilities\n        # TODO: Start heartbeat loop to maintain controller connection\n        # TODO: Listen for profiling session commands from controller\n        pass\n        \n    async def execute_profiling_session(self, session_config: Dict[str, Any]) -> Profile:\n        \"\"\"Execute local profiling session as part of distributed session.\"\"\"\n        # TODO: Configure local profiler using session parameters  \n        # TODO: Start profiling target process specified in session config\n        # TODO: Run profiling for configured duration with synchronized timing\n        # TODO: Collect and preprocess samples before sending to controller\n        # TODO: Return Profile data for aggregation with other nodes\n        pass\n```\n\n#### Streaming Analysis Pipeline\n\n```python\n\"\"\"\nStreaming analysis pipeline for real-time profiling data processing.\nProvides continuous sample analysis with live anomaly detection.\n\"\"\"\nimport asyncio\nimport queue\nfrom typing import AsyncGenerator, Dict, List, Callable\nfrom dataclasses import dataclass\nimport statistics\nfrom collections import deque, defaultdict\nfrom core.sampling.sampler import Sample, Profile\n\n@dataclass\nclass PerformanceBaseline:\n    function_name: str\n    average_samples: float\n    std_deviation: float\n    confidence_interval: float\n    observation_count: int\n\n@dataclass\nclass PerformanceAnomaly:\n    function_name: str\n    current_samples: int\n    expected_samples: float\n    deviation_magnitude: float\n    anomaly_type: str  # 'spike', 'drop', 'trend'\n    confidence: float\n\nclass StreamProcessor:\n    \"\"\"Processes profiling samples in real-time streaming fashion.\"\"\"\n    \n    def __init__(self, window_size_seconds: int = 60):\n        self.window_size = window_size_seconds\n        self.sample_windows: deque = deque(maxlen=100)  # Last 100 windows\n        self.function_baselines: Dict[str, PerformanceBaseline] = {}\n        self.anomaly_callbacks: List[Callable[[PerformanceAnomaly], None]] = []\n        \n    async def process_sample_stream(self, sample_stream: AsyncGenerator[Sample, None]):\n        \"\"\"Process continuous stream of profiling samples.\"\"\"\n        # TODO: Group incoming samples into time-based windows\n        # TODO: Aggregate samples within each window for analysis\n        # TODO: Update performance baselines with new sample data\n        # TODO: Detect anomalies by comparing current vs baseline patterns\n        # TODO: Trigger registered callbacks when anomalies are detected\n        pass\n        \n    def update_baselines(self, window_samples: List[Sample]):\n        \"\"\"Update performance baselines with new sample window.\"\"\"\n        # TODO: Count samples per function in current window\n        # TODO: Update running statistics for each function's baseline\n        # TODO: Calculate confidence intervals using statistical methods\n        # TODO: Adjust baseline sensitivity based on sample variance\n        pass\n        \n    def detect_anomalies(self, current_samples: Dict[str, int]) -> List[PerformanceAnomaly]:\n        \"\"\"Detect performance anomalies against established baselines.\"\"\"\n        # TODO: Compare current sample counts vs baseline expectations\n        # TODO: Calculate statistical significance of deviations  \n        # TODO: Classify anomaly types (spike, drop, trend change)\n        # TODO: Generate PerformanceAnomaly objects with confidence scores\n        # TODO: Filter anomalies below configured confidence thresholds\n        pass\n\nclass LiveFlameGraphGenerator:\n    \"\"\"Generates live flame graphs from streaming sample data.\"\"\"\n    \n    def __init__(self, update_interval_seconds: int = 5):\n        self.update_interval = update_interval_seconds\n        self.live_aggregator = None\n        self.websocket_clients: Set[WebSocket] = set()\n        \n    async def start_live_updates(self, sample_stream: AsyncGenerator[Sample, None]):\n        \"\"\"Start live flame graph updates from sample stream.\"\"\"\n        # TODO: Initialize live aggregation with sliding window\n        # TODO: Process samples continuously and update aggregation\n        # TODO: Generate flame graph updates at configured intervals\n        # TODO: Broadcast flame graph updates to connected WebSocket clients\n        # TODO: Handle client connections and disconnections gracefully\n        pass\n        \n    def generate_incremental_update(self, new_samples: List[Sample]) -> Dict[str, Any]:\n        \"\"\"Generate incremental flame graph update from new samples.\"\"\"\n        # TODO: Update live aggregation tree with new sample data\n        # TODO: Calculate changes in sample counts since last update\n        # TODO: Generate delta update containing only changed nodes\n        # TODO: Format update for efficient WebSocket transmission\n        # TODO: Include performance anomaly annotations in updates\n        pass\n```\n\n#### Milestone Checkpoint: Extension Validation\n\nAfter implementing extensions, validate functionality with these checkpoints:\n\n**Hardware Counter Extension:**\n- Run: `python -m profiler.extensions.hardware --target-pid <PID> --duration 30 --counters cycles,instructions,cache-misses`\n- Expected: Flame graph with hardware counter annotations showing IPC and cache miss rates\n- Verify: Counter values correlate with CPU-intensive vs memory-intensive functions\n\n**Distributed Profiling Extension:**\n- Run cluster controller: `python -m profiler.extensions.distributed.controller --port 8080`\n- Run agents on multiple machines: `python -m profiler.extensions.distributed.agent --controller http://controller:8080`\n- Start distributed session: `curl -X POST http://controller:8080/sessions -d '{\"targets\": {...}}'`\n- Expected: Unified flame graph combining samples from all participating nodes\n- Verify: Cross-service call relationships appear correctly in merged visualization\n\n**Streaming Analysis Extension:**\n- Run: `python -m profiler.extensions.streaming --live-updates --anomaly-detection`\n- Expected: Live flame graph updates in web browser with real-time anomaly highlighting\n- Verify: Performance spikes and drops trigger immediate visual annotations\n\nEach extension should integrate seamlessly with existing profiler functionality while providing enhanced capabilities that justify the additional complexity.\n\n### Implementation Guidance\n\nThe extension implementation leverages the existing profiler's plugin architecture to add advanced capabilities without disrupting core functionality. Extensions integrate through well-defined interfaces that maintain backward compatibility while enabling progressive feature adoption.\n\n#### Debugging Extension Integration\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Extension fails to load | Missing dependencies or interface mismatch | Check extension registration logs and interface compatibility | Install missing dependencies and verify interface implementation |\n| Hardware counters show zero values | Insufficient permissions or unsupported hardware | Test perf_event_open with elevated privileges | Run with CAP_SYS_ADMIN or configure /proc/sys/kernel/perf_event_paranoid |\n| Distributed profiling loses samples | Network issues or clock synchronization | Check network connectivity and NTP synchronization | Configure reliable network and NTP time synchronization |\n| Streaming updates lag significantly | Processing pipeline bottleneck | Monitor queue sizes and processing rates | Increase processing parallelism or reduce sample rate |\n| Multi-language unwinding crashes | Stack corruption or unsupported runtime | Enable debug logging for language unwinders | Add runtime version checks and graceful fallback handling |\n\n\n## Glossary\n\n> **Milestone(s):** All milestones (1-4) — comprehensive terminology and definitions supporting stack sampling, symbol resolution, flame graph generation, and memory profiling implementation\n\n### Mental Model: The Technical Dictionary\n\nThink of this glossary as a technical dictionary for a specialized domain. Just as a medical dictionary defines terms like \"myocardial infarction\" with precise clinical meaning, this glossary provides exact definitions for profiling terminology. Each term has specific meaning within the context of performance profiling that differs from general computing usage. For example, \"sampling\" in profiling specifically means \"statistical sampling of execution state\" rather than general data sampling.\n\n### Core Profiling Concepts\n\nThe fundamental concepts that underpin all profiling activities form the foundation for understanding how performance measurement systems operate.\n\n**Statistical sampling** refers to the periodic observation of program execution state at regular intervals to build a representative picture of program behavior. Unlike exhaustive instrumentation that records every event, statistical sampling captures snapshots at predetermined frequencies, trading completeness for minimal overhead. The key insight is that sufficiently frequent sampling provides statistically valid approximations of actual program behavior while maintaining acceptable performance impact.\n\n**Instrumentation** involves modifying code or runtime behavior to record execution events as they occur. This can take the form of compiler-inserted probes, runtime library interposition, or dynamic binary modification. Instrumentation provides complete event coverage but introduces observer paradox effects where the measurement overhead changes the behavior being measured.\n\n**Observer paradox** describes the fundamental challenge where measurement overhead alters the behavior being profiled. Heavy instrumentation can change timing relationships, memory allocation patterns, and cache behavior, making the profiled execution unrepresentative of normal operation. Effective profilers minimize this paradox through low-overhead collection techniques.\n\n**Overhead** quantifies the performance cost imposed by profiling measurement collection, typically expressed as percentage CPU time increase or memory consumption. Target overhead levels for production profiling usually stay below 2-5% to maintain system responsiveness while gathering useful performance data.\n\n### Stack Sampling Terminology\n\nStack sampling involves capturing execution context at regular intervals using timer-based interruption mechanisms.\n\n**Stack sampling** means capturing the complete call stack at regular intervals using timer signals to interrupt program execution. Each sample provides a snapshot of the current function call hierarchy, from the innermost executing function up through all calling functions to the program entry point. Accumulated samples reveal which code paths consume the most execution time.\n\n**Sampling frequency** specifies the rate of stack captures per second measured in Hz. Common frequencies range from 10Hz for low-overhead collection to 10KHz for detailed analysis. Higher frequencies provide better time resolution but increase measurement overhead and data volume. The choice involves balancing precision against performance impact.\n\n**Signal-based interruption** uses operating system timer signals like `SIGPROF` to periodically interrupt program execution for stack capture. The timer mechanism ensures deterministic sampling intervals independent of program control flow, preventing sampling bias toward particular code patterns or execution paths.\n\n**Stack unwinding** describes the process of walking frame pointers or debug information to reconstruct the complete call chain from the current execution point. This involves traversing linked stack frames backward from the interrupted function through all calling functions to build the complete call hierarchy.\n\n**Frame pointer** refers to the processor register pointing to the current function's stack frame structure. Frame pointers enable reliable stack traversal by providing a linked list of activation records. However, compiler optimizations may eliminate frame pointers, requiring alternative unwinding mechanisms like DWARF debug information.\n\n**Async-safe** describes functions safe to call from signal handlers without causing deadlocks or corruption. Signal handlers execute in an unpredictable context and must avoid non-reentrant functions like `malloc`, `printf`, or mutex operations. Stack sampling signal handlers must use only async-safe operations for reliable data collection.\n\n### Symbol Resolution Terminology\n\nSymbol resolution converts raw memory addresses into human-readable function names and source code locations.\n\n**Symbol resolution** involves converting raw memory addresses captured during sampling into human-readable function names and source code locations. This process requires parsing debug information, symbol tables, and handling address space layout randomization to provide meaningful profiling output.\n\n**Debug symbols** contain metadata mapping memory addresses to source code locations and function information. This includes function names, parameter types, source file names, line numbers, and variable locations. Debug symbols enable rich profiling output but significantly increase binary size.\n\n**ASLR (Address Space Layout Randomization)** randomizes the memory layout of program components for security purposes. This means the same function loads at different virtual addresses between program runs. Symbol resolution must account for ASLR by calculating load bias between link-time and runtime addresses.\n\n**DWARF (Debug Information Format)** provides a standardized format for encoding source-level debugging information in object files. DWARF includes line number tables mapping addresses to source locations, call frame information for stack unwinding, and variable location descriptions. Modern symbol resolution relies heavily on DWARF data.\n\n**ELF (Executable and Linkable Format)** defines the binary format for executables and shared libraries on Unix-like systems. ELF files contain symbol tables, debug sections, and program headers needed for symbol resolution. Profilers must parse ELF structure to extract symbol information.\n\n**Demangling** converts mangled C++ symbol names back to readable form. C++ compilers encode function overloading, namespaces, and template parameters into symbol names using complex name mangling schemes. Demangling reverses this process to display human-readable function names in profiling output.\n\n**Load bias** represents the offset between link-time virtual addresses and actual runtime load addresses. ASLR and dynamic linking cause programs to load at different addresses than specified during linking. Symbol resolution must calculate and apply load bias to correctly map runtime addresses to symbols.\n\n### Flame Graph Terminology\n\nFlame graphs provide hierarchical visualization of profiling data showing call stack relationships and frequency.\n\n**Flame graph** displays a hierarchical visualization showing call stack frequency and relationships. Functions appear as horizontal rectangles where width represents time spent (sample count) and vertical position shows call depth. This creates a flame-like appearance with the main function at the bottom and leaf functions at the top.\n\n**Stack folding** converts individual stack traces into aggregated signature counts by creating unique identifiers for each call stack sequence. Multiple samples with identical call stacks get merged into a single entry with accumulated sample counts, reducing data volume while preserving call context.\n\n**Folded stack format** uses semicolon-delimited text to represent call stacks with sample counts. Each line contains a complete call stack from bottom to top with function names separated by semicolons, followed by a space and sample count. This format enables efficient aggregation and flame graph generation.\n\n**Coordinate calculation** maps logical tree structures to pixel positions for visualization. This involves calculating rectangle coordinates based on sample counts, determining appropriate scaling factors, and handling text layout within flame graph rectangles. Proper coordinate calculation ensures accurate visual representation of profiling data.\n\n**Interactive SVG** provides scalable vector graphics with embedded JavaScript for user interactions. Interactive flame graphs support zooming into specific subtrees, searching for function names, and displaying detailed information on hover. SVG format ensures crisp rendering at any zoom level.\n\n**Color scheme** defines systematic color assignment strategies for visual distinction between different categories of functions. Common schemes include category-based coloring (user code vs. libraries vs. kernel), module-based coloring, or hash-based coloring for consistent function identification across different flame graphs.\n\n**Stack signature** creates unique identifier strings from call stack sequences for aggregation purposes. Signatures typically concatenate function names in call order to create hash keys for grouping identical stacks. Proper signature generation enables efficient stack folding and flame graph construction.\n\n**Hierarchical aggregation** builds tree structures that preserve calling context while accumulating sample counts. Each tree node represents a function at a specific call depth, with children representing functions called from that context. Sample counts propagate upward to show inclusive time spent in each subtree.\n\n**Weight calculation** determines visual width based on cumulative sample counts to accurately represent time proportions. Rectangle width in flame graphs must accurately reflect the percentage of total time spent in each function relative to siblings at the same call depth.\n\n**Bottom-up layout** orientates flame graphs with the main function at the bottom and leaf functions at the top. This layout matches the natural stack growth direction and provides intuitive visualization where deeper call stacks appear higher in the graph.\n\n### Memory Profiling Terminology\n\nMemory profiling involves tracking allocation patterns and detecting memory leaks through runtime interposition.\n\n**Function interposition** intercepts calls to library functions like `malloc` and `free` to track memory operations. This can be implemented through `LD_PRELOAD` library replacement, dynamic symbol interposition, or compile-time instrumentation. Interposition enables comprehensive allocation tracking without source code modification.\n\n**Allocation metadata** contains tracking information for each memory allocation including size, timestamp, thread ID, and call stack context. This metadata enables leak detection, allocation site analysis, and memory usage pattern identification. Metadata overhead must be minimized to avoid significant memory consumption.\n\n**Leak detection** identifies allocations without corresponding free operations by analyzing allocation metadata at program termination or specific checkpoints. True leaks require distinguishing between definitely lost memory and memory that remains reachable but was never explicitly freed.\n\n**Allocation site** refers to the unique call stack location where memory allocation occurs. Grouping allocations by site enables identification of problematic allocation patterns, excessive allocation frequency, or growing memory usage trends. Allocation site analysis helps prioritize memory optimization efforts.\n\n**Recursion detection** prevents infinite loops in allocation tracking when the tracking system itself triggers additional allocations. Memory profilers must use thread-local storage or other mechanisms to detect when they are executing within their own allocation tracking code to avoid recursive instrumentation.\n\n**Thread-local storage** provides per-thread data storage for tracking allocation context without requiring locks or atomic operations. This enables efficient allocation metadata management in multi-threaded programs while avoiding synchronization overhead that could affect program timing.\n\n**Suppression rules** define patterns to filter false positive leaks from analysis results. These rules identify allocation sites known to produce intentional long-lived allocations that appear as leaks but represent normal program behavior. Suppressions improve signal-to-noise ratio in leak reports.\n\n**Growth patterns** identify allocation sites with unbounded memory growth that may indicate resource leaks even if individual allocations are properly freed. These patterns detect scenarios where allocation rate exceeds free rate, leading to gradual memory consumption increases over time.\n\n### Error Handling and Recovery Terminology\n\nRobust profiling systems require comprehensive error handling and graceful degradation strategies.\n\n**Graceful degradation** maintains core functionality despite errors or missing data by falling back to simplified behavior when full functionality is unavailable. For example, symbol resolution might display raw addresses when debug symbols are missing, or flame graphs might use simplified color schemes when detailed categorization fails.\n\n**Backpressure** occurs when downstream processing stages become overwhelmed and upstream stages must slow down or drop work to prevent memory exhaustion. Profiling pipelines implement backpressure handling through bounded queues, sample dropping policies, and flow control mechanisms.\n\n### Performance Analysis Terminology\n\nAdvanced profiling involves hardware performance monitoring and anomaly detection capabilities.\n\n**Hardware performance counters** are specialized CPU registers that track execution events like instruction counts, cache misses, branch predictions, and memory access patterns. These counters provide detailed microarchitectural insights beyond basic timing information available through software sampling.\n\n**Event-based sampling** triggers sample collection based on hardware events rather than fixed time intervals. For example, sampling every 10,000 cache misses provides insight into cache-sensitive code patterns regardless of execution time. Event-based sampling reveals performance characteristics invisible to time-based sampling.\n\n**Custom event sampling** enables application-specific profiling events for domain-specific performance analysis. Applications can register custom events and trigger sample collection at semantically meaningful points like transaction boundaries, request completion, or algorithm phases.\n\n**Multi-language profiling** involves profiling polyglot applications that execute across multiple runtime environments like native code, JVM, Python interpreter, and JavaScript engines. This requires coordinating profiling data collection across different execution environments and unifying results for coherent analysis.\n\n**Performance baseline** establishes normal performance characteristics for comparison against current measurements. Baselines enable detection of performance regressions, identification of unusual behavior patterns, and validation that optimizations produce expected improvements.\n\n**Anomaly detection** identifies significant deviations from established performance baselines using statistical analysis. This enables automated identification of performance issues, unusual execution patterns, or potential optimization opportunities without manual analysis of profiling data.\n\n### Distributed Profiling Terminology\n\nLarge-scale profiling systems require coordination across multiple processes and machines.\n\n**Distributed profiling** coordinates profiling data collection across multiple processes or machines to provide system-wide performance visibility. This involves timestamp synchronization, distributed sample aggregation, and unified visualization of multi-node profiling results.\n\n**Streaming data processing** enables real-time continuous analysis of profiling samples as they are collected rather than batch processing after collection completion. Streaming processing supports live profiling dashboards, real-time anomaly detection, and immediate feedback on performance changes.\n\n**Federated profiling** implements hierarchical distributed profiling architectures where local profiling agents aggregate data before forwarding to central collection systems. This approach scales profiling data collection across large systems while managing network bandwidth and central processing requirements.\n\n**Clock synchronization** maintains consistent timestamps across distributed profiling nodes to enable accurate temporal correlation of events. Without proper clock synchronization, distributed profiling data cannot be meaningfully aggregated or analyzed for causality relationships.\n\n### Data Structure and Algorithm Terminology\n\nImplementation requires understanding of core data structures and algorithms used throughout profiling systems.\n\nThe following table defines key data structure concepts used throughout the profiler implementation:\n\n| Term | Definition | Usage Context |\n|------|------------|---------------|\n| Ring buffer | Fixed-size circular buffer for sample storage with overflow handling | Sample collection buffering |\n| Hash table | Key-value mapping for fast symbol and allocation lookups | Symbol caches, allocation tracking |\n| Binary search tree | Ordered tree structure for efficient address range queries | Symbol table organization |\n| Trie structure | Prefix tree for efficient string matching and completion | Function name search indexing |\n| Priority queue | Ordered queue for processing items by importance or timestamp | Sample processing prioritization |\n| Bloom filter | Probabilistic data structure for fast membership testing | Symbol cache miss optimization |\n| LRU cache | Least-recently-used cache eviction policy for bounded memory usage | Symbol cache management |\n| Copy-on-write | Memory optimization technique sharing data until modification | Sample batch optimization |\n\n### Implementation Constants and Defaults\n\nThe following table defines standard constants and default values used throughout the profiler implementation:\n\n| Constant | Value | Description |\n|----------|--------|-------------|\n| `DEFAULT_FREQUENCY_HZ` | 100 | Default sampling frequency in samples per second |\n| `MAX_STACK_DEPTH` | 128 | Maximum call stack frames to capture per sample |\n| `TARGET_OVERHEAD_PERCENT` | 2.0 | Target profiling overhead as percentage of CPU time |\n| `DEFAULT_RECTANGLE_HEIGHT` | 18 | Default flame graph rectangle height in pixels |\n| `MIN_WIDTH_THRESHOLD` | 0.5 | Minimum rectangle width in pixels for flame graph display |\n| `DEFAULT_WINDOW_SIZE` | 60 | Default time window in seconds for analysis |\n| `ANOMALY_CONFIDENCE_THRESHOLD` | 0.95 | Confidence threshold for performance anomaly detection |\n| `PERF_COUNT_HW_CPU_CYCLES` | 0 | Hardware performance counter for CPU cycles |\n| `PERF_COUNT_HW_INSTRUCTIONS` | 1 | Hardware performance counter for instructions executed |\n| `PERF_COUNT_HW_CACHE_REFERENCES` | 2 | Hardware performance counter for cache references |\n| `PERF_COUNT_HW_CACHE_MISSES` | 3 | Hardware performance counter for cache misses |\n\n### System Integration Terminology\n\nProfilers must integrate with operating system facilities and development toolchains.\n\n**Signal delivery** describes the mechanism by which the operating system delivers timer signals to target processes for stack sampling. Understanding signal delivery behavior is crucial for reliable sampling, especially in multi-threaded programs where signals may be delivered to arbitrary threads.\n\n**Dynamic linking** enables runtime loading and symbol resolution of shared libraries. Profilers must track dynamically loaded libraries and update symbol tables when libraries are loaded or unloaded during program execution.\n\n**Process attachment** allows profilers to connect to already-running processes rather than requiring restart under profiler control. This capability enables profiling of long-running services, debugging production issues, and ad-hoc performance analysis.\n\n**Container profiling** involves profiling applications running within containerized environments where traditional profiling techniques may be limited by container security policies, namespace isolation, or resource constraints.\n\n### Visualization and User Interface Terminology\n\nEffective profiling requires intuitive visualization and interaction mechanisms.\n\n**Zooming** enables users to focus on specific portions of flame graphs by expanding selected regions to fill the display area. Proper zooming maintains visual context while providing detailed examination of performance hotspots.\n\n**Search functionality** allows users to quickly locate specific functions within large flame graphs through text matching and highlighting. Search typically supports substring matching, regular expressions, and navigation between multiple matches.\n\n**Tooltip display** provides detailed information when users hover over flame graph elements, including exact sample counts, percentages, source file locations, and function signatures. Tooltips enhance usability without cluttering the visual display.\n\n**Color coding** systematically assigns colors to distinguish different categories of functions, modules, or performance characteristics. Effective color coding enables quick visual identification of patterns and reduces cognitive load during analysis.\n\n### Quality Assurance Terminology\n\nProfiler development requires comprehensive testing and validation strategies.\n\n**Regression testing** validates that profiler functionality continues working correctly as implementation evolves. This includes testing against known workloads with expected results, performance overhead validation, and compatibility testing across different environments.\n\n**Stress testing** validates profiler behavior under extreme conditions like very high sampling frequencies, large call stacks, rapid allocation patterns, or resource-constrained environments. Stress testing reveals breaking points and failure modes.\n\n**Accuracy validation** compares profiler results against known ground truth or reference implementations to ensure measurement correctness. This involves synthetic workloads with predictable behavior and cross-validation with established profiling tools.\n\n**Overhead measurement** quantifies the performance impact of profiling on target applications through controlled before-and-after comparisons. Overhead measurements must account for different workload characteristics and system configurations.\n\n### Implementation Guidance\n\n#### Technology Stack Selection\n\nThe following table provides technology recommendations for implementing different aspects of the profiler:\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Signal handling | Python signal module | Custom C extension for signal handlers |\n| Binary parsing | pyelftools library | Custom ELF parser with mmap |\n| Symbol management | dictionaries with linear search | B-tree or radix tree implementation |\n| SVG generation | string formatting with templates | XML library with DOM manipulation |\n| Memory tracking | ctypes with LD_PRELOAD | Custom malloc implementation |\n| Threading | threading module with locks | multiprocessing for isolation |\n| Configuration | JSON files with dict parsing | YAML with schema validation |\n| Logging | Python logging module | Structured logging with correlation IDs |\n\n#### Project File Organization\n\nOrganize the profiler implementation following this recommended directory structure:\n\n```\ncpu_memory_profiler/\n  __init__.py                     ← package initialization\n  cli/\n    main.py                       ← command line interface\n    config.py                     ← configuration management\n  core/\n    sampler.py                    ← stack sampling implementation\n    symbolizer.py                 ← symbol resolution implementation  \n    aggregator.py                 ← flame graph aggregation\n    memory_tracker.py             ← memory profiling implementation\n  data/\n    models.py                     ← data structure definitions\n    serialization.py              ← data format handling\n  visualization/\n    flame_graph.py                ← SVG generation\n    color_schemes.py              ← color mapping logic\n  utils/\n    elf_parser.py                 ← ELF binary parsing utilities\n    signal_utils.py               ← signal handling utilities\n    time_utils.py                 ← timestamp and timing utilities\n  tests/\n    test_sampler.py               ← sampling component tests\n    test_symbolizer.py            ← symbol resolution tests\n    test_memory.py                ← memory profiling tests\n    test_integration.py           ← end-to-end integration tests\n    fixtures/                     ← test data and programs\n  examples/\n    basic_profiling.py            ← simple usage examples\n    advanced_config.py            ← complex configuration examples\n```\n\n#### Core Data Structures Implementation\n\nComplete implementation of essential profiler data structures:\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Optional, Any, Set\nfrom enum import Enum\nimport time\nimport threading\n\n@dataclass\nclass StackFrame:\n    \"\"\"Represents a single frame in a call stack.\"\"\"\n    address: int\n    function_name: str = \"\"\n    filename: str = \"\"\n    line_number: int = -1\n    module_name: str = \"\"\n    module_offset: int = 0\n    inlined_frames: List['InlinedFrame'] = field(default_factory=list)\n    is_kernel: bool = False\n\n@dataclass  \nclass InlinedFrame:\n    \"\"\"Represents an inlined function within a stack frame.\"\"\"\n    function_name: str\n    filename: str\n    line_number: int\n    call_filename: str\n    call_line_number: int\n\nclass SampleType(Enum):\n    \"\"\"Types of profiling samples.\"\"\"\n    CPU_TIME = \"cpu_time\"\n    WALL_TIME = \"wall_time\" \n    MEMORY_ALLOCATION = \"memory_allocation\"\n    CUSTOM_EVENT = \"custom_event\"\n\n@dataclass\nclass Sample:\n    \"\"\"A single profiling sample with complete context.\"\"\"\n    timestamp: float\n    thread_id: int\n    process_id: int\n    stack_frames: List[StackFrame]\n    cpu_id: int = -1\n    sample_weight: int = 1\n    context_switches: int = 0\n    sample_type: SampleType = SampleType.CPU_TIME\n    \n    def __post_init__(self):\n        if self.timestamp <= 0:\n            self.timestamp = time.time()\n\nclass AllocationType(Enum):\n    \"\"\"Types of memory allocations.\"\"\"\n    MALLOC = \"malloc\"\n    CALLOC = \"calloc\"\n    REALLOC = \"realloc\"\n    NEW = \"new\"\n    NEW_ARRAY = \"new[]\"\n\nclass LeakCategory(Enum):\n    \"\"\"Categories of memory leaks.\"\"\"\n    DEFINITE_LEAK = \"definite_leak\"\n    POSSIBLE_LEAK = \"possible_leak\"\n    REACHABLE_LEAK = \"reachable_leak\"\n    GROWTH_PATTERN = \"growth_pattern\"\n\n@dataclass\nclass Allocation:\n    \"\"\"Tracks a single memory allocation.\"\"\"\n    allocation_id: int\n    size: int\n    actual_size: int\n    timestamp: float\n    thread_id: int\n    allocation_stack: List[StackFrame]\n    allocation_type: AllocationType\n    is_freed: bool = False\n    free_timestamp: float = -1\n    free_thread_id: int = -1\n    \n    def get_lifetime(self) -> float:\n        \"\"\"Calculate allocation lifetime in seconds.\"\"\"\n        if not self.is_freed:\n            return time.time() - self.timestamp\n        return self.free_timestamp - self.timestamp\n```\n\n#### Configuration Management\n\nComplete configuration system with validation and defaults:\n\n```python\nimport json\nfrom pathlib import Path\nfrom typing import List\n\n@dataclass\nclass SamplingConfig:\n    \"\"\"Configuration for stack sampling.\"\"\"\n    frequency_hz: int = 100\n    max_stack_depth: int = 128\n    include_kernel: bool = False\n    target_overhead_percent: float = 2.0\n    \n    def validate(self) -> List[str]:\n        \"\"\"Validate configuration values.\"\"\"\n        issues = []\n        if not 1 <= self.frequency_hz <= 10000:\n            issues.append(\"frequency_hz must be between 1 and 10000\")\n        if not 1 <= self.max_stack_depth <= 512:\n            issues.append(\"max_stack_depth must be between 1 and 512\")\n        if not 0.1 <= self.target_overhead_percent <= 50.0:\n            issues.append(\"target_overhead_percent must be between 0.1 and 50.0\")\n        return issues\n\n@dataclass\nclass SymbolConfig:\n    \"\"\"Configuration for symbol resolution.\"\"\"\n    enable_dwarf: bool = True\n    cache_symbols: bool = True\n    demangle_cpp: bool = True\n    symbol_search_paths: List[str] = field(default_factory=lambda: [\"/usr/lib/debug\"])\n    \n@dataclass\nclass VisualizationConfig:\n    \"\"\"Configuration for flame graph generation.\"\"\"\n    color_scheme: str = \"category\"\n    min_width_pixels: int = 1\n    title: str = \"CPU Profile\"\n    enable_search: bool = True\n    enable_zoom: bool = True\n\n@dataclass\nclass ProfilerConfig:\n    \"\"\"Complete profiler configuration.\"\"\"\n    sampling: SamplingConfig = field(default_factory=SamplingConfig)\n    symbols: SymbolConfig = field(default_factory=SymbolConfig)\n    visualization: VisualizationConfig = field(default_factory=VisualizationConfig)\n    output_directory: str = \"./profiler_output\"\n    \n    @classmethod\n    def from_json(cls, config_path: str) -> 'ProfilerConfig':\n        \"\"\"Load configuration from JSON file.\"\"\"\n        # TODO: Implement JSON loading with error handling\n        # TODO: Validate all configuration sections\n        # TODO: Apply defaults for missing values\n        # TODO: Return populated ProfilerConfig instance\n        pass\n        \n    def to_json(self, config_path: str) -> None:\n        \"\"\"Save configuration to JSON file.\"\"\"\n        # TODO: Convert dataclass to dictionary\n        # TODO: Write JSON file with proper formatting\n        # TODO: Handle file system errors gracefully\n        pass\n```\n\n#### Essential Profiling Pipeline Skeleton\n\nCore profiling coordination with detailed implementation guidance:\n\n```python\nimport signal\nimport ctypes\nfrom queue import Queue, Empty\nfrom threading import Thread, Event\nfrom collections import deque, defaultdict\n\nclass ProfilerPipeline:\n    \"\"\"Coordinates the complete profiling pipeline.\"\"\"\n    \n    def __init__(self, config: ProfilerConfig):\n        self.config = config\n        self.stats = PipelineStats()\n        self.sample_queue = Queue(maxsize=10000)\n        self.symbolized_queue = Queue(maxsize=5000)\n        self.aggregated_queue = Queue(maxsize=1000)\n        self._stop_event = Event()\n        \n    def start_profiling(self, target_pid: int, duration_seconds: float) -> None:\n        \"\"\"Start the complete profiling pipeline.\"\"\"\n        # TODO: Validate target process exists and is accessible\n        # TODO: Start sampling thread with signal-based interruption\n        # TODO: Start symbol resolution thread processing sample queue\n        # TODO: Start aggregation thread building flame graph data\n        # TODO: Set up timer for duration-based stopping\n        # TODO: Initialize pipeline statistics tracking\n        pass\n        \n    def stop_profiling(self) -> 'Profile':\n        \"\"\"Stop profiling pipeline and return collected data.\"\"\"\n        # TODO: Signal all threads to stop processing\n        # TODO: Drain remaining samples from all queues\n        # TODO: Finalize symbol resolution for remaining samples\n        # TODO: Complete aggregation and generate final flame graph\n        # TODO: Collect and return comprehensive Profile object\n        pass\n\nclass RingBuffer:\n    \"\"\"Lock-free ring buffer for high-frequency sample collection.\"\"\"\n    \n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.buffer = deque(maxlen=capacity)\n        self.lock = threading.RLock()\n        self.dropped_count = 0\n        self.total_added = 0\n        \n    def add_sample(self, sample: Sample) -> bool:\n        \"\"\"Add sample to buffer, returning False if dropped.\"\"\"\n        # TODO: Acquire lock for thread-safe access\n        # TODO: Check if buffer is at capacity\n        # TODO: Drop oldest sample if necessary and increment dropped_count\n        # TODO: Add new sample to buffer\n        # TODO: Update total_added counter\n        # TODO: Return success/failure status\n        pass\n```\n\n#### Symbol Resolution Utilities\n\nComplete ELF parsing and symbol management implementation:\n\n```python\nimport mmap\nfrom typing import BinaryIO\nimport struct\n\nclass ELFParser:\n    \"\"\"Parses ELF binaries for symbol information.\"\"\"\n    \n    def __init__(self, binary_path: str):\n        self.binary_path = binary_path\n        self.symbols = {}\n        self.load_bias = 0\n        \n    def parse_symbol_table(self) -> Dict[int, Symbol]:\n        \"\"\"Parse ELF symbol table and return symbol mappings.\"\"\"\n        # TODO: Open binary file with mmap for efficient access\n        # TODO: Parse ELF header to locate symbol table sections\n        # TODO: Iterate through symbol table entries\n        # TODO: Extract symbol name, address, size, and type\n        # TODO: Build Symbol objects with complete metadata\n        # TODO: Return dictionary mapping addresses to symbols\n        pass\n        \n    def parse_dwarf_debug_info(self) -> Dict[int, LineRange]:\n        \"\"\"Parse DWARF debug information for line number mappings.\"\"\"\n        # TODO: Locate .debug_line section in ELF file\n        # TODO: Parse DWARF line number program header\n        # TODO: Execute line number program to build address-to-line mappings\n        # TODO: Create LineRange objects with source file information\n        # TODO: Return mapping from addresses to source locations\n        pass\n\nclass SymbolCache:\n    \"\"\"LRU cache for resolved symbols with miss tracking.\"\"\"\n    \n    def __init__(self, max_size: int = 100000):\n        self.address_to_symbol = {}\n        self.module_cache = {}\n        self.demangled_names = {}\n        self.miss_cache = set()\n        self.max_cache_size = max_size\n        self.hit_count = 0\n        self.miss_count = 0\n        \n    def lookup_symbol(self, address: int) -> Optional[Symbol]:\n        \"\"\"Look up cached symbol or return None for cache miss.\"\"\"\n        # TODO: Check if address is in miss cache (known failures)\n        # TODO: Look up symbol in address_to_symbol cache\n        # TODO: Update hit/miss statistics\n        # TODO: Implement LRU eviction if cache exceeds max_size\n        # TODO: Return cached symbol or None\n        pass\n```\n\n#### Milestone Validation Checkpoints\n\nAfter implementing each milestone, validate functionality using these specific tests:\n\n**Milestone 1 Validation - Stack Sampling:**\n```bash\n# Expected: Successful sample collection with configurable frequency\npython -m cpu_memory_profiler.tests.test_sampler\n# Should output: \"Collected X samples at Y Hz frequency\"\n# Manual verification: Profile a simple CPU-bound loop for 5 seconds\npython examples/basic_profiling.py --target-pid 1234 --duration 5\n```\n\n**Milestone 2 Validation - Symbol Resolution:**\n```bash\n# Expected: Raw addresses converted to function names\npython -m cpu_memory_profiler.tests.test_symbolizer  \n# Should output: Function names instead of hex addresses\n# Manual verification: Symbols should include main(), library functions\n```\n\n**Milestone 3 Validation - Flame Graph Generation:**\n```bash\n# Expected: Interactive SVG flame graph file generated\npython examples/generate_flame_graph.py --input profile.data --output flame.svg\n# Should output: flame.svg file viewable in web browser with zoom/search\n```\n\n**Milestone 4 Validation - Memory Profiling:**\n```bash\n# Expected: Memory allocations tracked with leak detection\npython -m cpu_memory_profiler.tests.test_memory\n# Should output: Allocation sites and detected leaks\n# Manual verification: Profile program with known memory leaks\n```\n\n#### Common Implementation Pitfalls\n\n⚠️ **Pitfall: Signal Handler Safety Violations**\n\nMany developers incorrectly call non-async-safe functions from signal handlers, causing deadlocks or corruption. Signal handlers can only safely call a limited set of functions listed in signal-safety(7).\n\n**Wrong approach:** Calling `malloc()`, `printf()`, or acquiring locks in signal handlers.\n\n**Correct approach:** Use only async-safe functions and pre-allocated buffers. Copy minimal data in the signal handler and defer complex processing to safe contexts.\n\n⚠️ **Pitfall: Ignoring ASLR in Symbol Resolution**\n\nForgetting to calculate load bias causes symbol resolution to fail because runtime addresses don't match symbol table addresses.\n\n**Wrong approach:** Directly using symbol table addresses for runtime address lookup.\n\n**Correct approach:** Calculate load bias by comparing actual module load address with symbol table base address, then apply bias to all symbol lookups.\n\n⚠️ **Pitfall: Recursive Allocation Tracking**\n\nMemory profilers that use `malloc()` internally for tracking data structures trigger recursive allocation calls, leading to stack overflow or infinite loops.\n\n**Wrong approach:** Using standard allocation functions in tracking code.\n\n**Correct approach:** Use thread-local flags to detect recursion and pre-allocated buffers or alternative allocation strategies for tracking metadata.\n"}