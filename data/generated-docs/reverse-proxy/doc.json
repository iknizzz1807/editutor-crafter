{"html":"<h1 id=\"reverse-proxy-design-document\">Reverse Proxy: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A high-performance reverse proxy that accepts client connections, forwards requests to backend servers, and returns responses, solving the key challenge of efficiently managing concurrent connections while providing load balancing, caching, and SSL termination. The system handles the complexities of HTTP protocol parsing, connection pooling, and asynchronous I/O to maximize throughput and minimize latency.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - this foundational understanding applies throughout the entire reverse proxy implementation journey.</p>\n</blockquote>\n<p>Building a reverse proxy might seem straightforward at first glance - accept requests, forward them to backend servers, and return responses. However, beneath this simple description lies a complex system that must handle thousands of concurrent connections, parse intricate HTTP protocols, manage connection lifecycles, and maintain high performance under varying load conditions. Understanding why reverse proxies are essential and what makes them architecturally challenging provides the foundation for making informed design decisions throughout the implementation process.</p>\n<h3 id=\"the-reverse-proxy-problem\">The Reverse Proxy Problem</h3>\n<p>Think of a reverse proxy as a sophisticated receptionist in a large corporate building. When visitors arrive, the receptionist doesn&#39;t just blindly direct them to any available employee. Instead, she maintains detailed knowledge about which departments are currently busy, which employees are out sick, and which meeting rooms have the best equipment for specific types of meetings. She makes intelligent decisions about where to route each visitor based on their needs, current building capacity, and the availability of resources. Additionally, she remembers frequent visitors and can quickly access their preferred meeting locations from her files, avoiding the need to walk through the entire building directory each time.</p>\n<p>This analogy captures the essence of what a <strong>reverse proxy</strong> accomplishes in network architecture. Unlike a forward proxy that sits between clients and the internet (acting on behalf of clients), a reverse proxy sits between clients and backend servers, acting on behalf of the servers. The proxy becomes the single point of contact for clients, while intelligently distributing their requests across multiple backend servers based on various criteria such as server health, current load, and request characteristics.</p>\n<p>The fundamental challenge that reverse proxies solve is the <strong>many-to-many connection problem</strong>. Consider a web service that needs to handle 10,000 concurrent users, but each backend server can only handle 1,000 connections effectively. Without a reverse proxy, you would need to either over-provision individual servers (wasteful and expensive) or implement complex client-side load balancing logic (brittle and difficult to update). The reverse proxy elegantly solves this by maintaining a smaller number of persistent connections to backend servers while handling the full volume of client connections on the frontend.</p>\n<p>However, implementing this solution introduces several architectural challenges that make reverse proxy development particularly complex:</p>\n<p><strong>Connection State Management Challenge</strong>: A reverse proxy must simultaneously manage two distinct connection contexts - the client-facing connection and the backend-facing connection. Each connection exists in its own lifecycle with different states (connecting, reading request, forwarding, reading response, writing response, closing), and these states must be carefully synchronized. The proxy cannot simply pass bytes between connections because it needs to understand the HTTP protocol structure to make intelligent routing decisions and handle error scenarios gracefully.</p>\n<p><strong>Protocol Parsing and Transformation Challenge</strong>: HTTP appears simple on the surface, but the protocol contains numerous edge cases and variations that must be handled correctly. The proxy must parse incoming requests completely enough to extract routing information (Host headers, URL paths), while simultaneously preserving the original request structure for forwarding. Additionally, the proxy must handle protocol version differences - a client might connect via HTTP/2 while the backend server only supports HTTP/1.1, requiring protocol translation.</p>\n<p><strong>Asynchronous I/O Complexity</strong>: To achieve high performance, a reverse proxy cannot afford to block threads waiting for I/O operations. This necessitates an event-driven architecture using asynchronous I/O primitives like <code>epoll</code> on Linux or <code>kqueue</code> on BSD systems. However, asynchronous programming introduces complexity in error handling, connection lifecycle management, and state tracking. The proxy must handle partial reads and writes gracefully, manage timeouts across multiple concurrent operations, and ensure that connection state remains consistent even when I/O operations complete in unpredictable orders.</p>\n<p><strong>Memory Management and Resource Limits</strong>: Each active connection requires memory for buffers, connection state, and potentially cached data. A reverse proxy handling thousands of connections must carefully manage memory usage to avoid exhaustion. This includes implementing efficient buffer reuse strategies, setting appropriate limits on request sizes and connection counts, and ensuring that slow or malicious clients cannot consume unbounded resources through techniques like slowloris attacks.</p>\n<p><strong>Backend Health and Failure Handling</strong>: Unlike simple load balancers that can assume backend servers are always available, a production reverse proxy must handle backend failures gracefully. This includes detecting when backend servers become unavailable, removing them from the active pool, and implementing retry logic with appropriate backoff strategies. The proxy must also handle partial failures - situations where a backend server accepts a connection but fails during request processing.</p>\n<p>The interplay between these challenges creates emergent complexity. For example, when a backend server fails during request processing, the proxy must simultaneously clean up the backend connection, maintain the client connection, generate an appropriate error response, update its load balancing state, and ensure that any cached data related to the failed request is invalidated. Managing these interdependent concerns requires careful architectural planning and robust error handling throughout the system.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<h3 id=\"existing-solutions-analysis\">Existing Solutions Analysis</h3>\n<p>Understanding how existing reverse proxy implementations approach these challenges provides valuable context for design decisions. Each solution makes different trade-offs between performance, complexity, and feature richness, reflecting the diverse requirements of their target environments.</p>\n<p><strong>NGINX</strong> represents the dominant approach in production environments, built around an event-driven architecture using a master-worker process model. The master process handles configuration loading and worker process management, while worker processes handle actual request processing using asynchronous I/O. NGINX achieves exceptional performance by avoiding thread-per-connection models and instead using a small number of worker processes (typically one per CPU core) that handle thousands of connections each through event loops.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>NGINX Approach</th>\n<th>Strengths</th>\n<th>Weaknesses</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Architecture</td>\n<td>Master-worker with event loops</td>\n<td>Excellent performance, proven scalability</td>\n<td>Complex configuration, C codebase hard to modify</td>\n</tr>\n<tr>\n<td>Memory Model</td>\n<td>Shared memory pools</td>\n<td>Low memory overhead per connection</td>\n<td>Memory pool tuning requires expertise</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Declarative config files</td>\n<td>Powerful and flexible</td>\n<td>Complex syntax, requires restarts for changes</td>\n</tr>\n<tr>\n<td>Extensibility</td>\n<td>C modules</td>\n<td>High performance modules</td>\n<td>High barrier to entry for custom logic</td>\n</tr>\n</tbody></table>\n<p>NGINX&#39;s design philosophy prioritizes performance and memory efficiency above ease of development. Its configuration system, while powerful, requires deep understanding of HTTP semantics and NGINX-specific concepts. The C-based module system enables high-performance extensions but creates a significant barrier for developers who need custom business logic in their reverse proxy.</p>\n<p><strong>HAProxy</strong> takes a different approach, focusing specifically on load balancing with extensive health checking and traffic management features. Built around a single-threaded event loop model, HAProxy excels at connection management and provides sophisticated algorithms for backend server selection.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>HAProxy Approach</th>\n<th>Strengths</th>\n<th>Weaknesses</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Architecture</td>\n<td>Single-threaded event loop</td>\n<td>Predictable performance, simpler debugging</td>\n<td>Limited CPU scalability on multi-core systems</td>\n</tr>\n<tr>\n<td>Load Balancing</td>\n<td>Advanced algorithms</td>\n<td>Comprehensive health checks, detailed statistics</td>\n<td>Less general-purpose than NGINX</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Specialized DSL</td>\n<td>Optimized for load balancing use cases</td>\n<td>Learning curve for complex routing rules</td>\n</tr>\n<tr>\n<td>Observability</td>\n<td>Built-in statistics</td>\n<td>Excellent monitoring capabilities</td>\n<td>Limited extensibility for custom metrics</td>\n</tr>\n</tbody></table>\n<p>HAProxy&#39;s single-threaded model provides predictable performance characteristics and simplifies reasoning about connection state, but limits its ability to fully utilize multi-core systems for CPU-intensive operations like SSL termination.</p>\n<p><strong>Envoy</strong> represents a modern approach designed for cloud-native environments, built with observability, dynamic configuration, and service mesh integration as core requirements. Written in C++, Envoy uses a multi-threaded architecture with careful attention to lock-free data structures and thread-local storage.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Envoy Approach</th>\n<th>Strengths</th>\n<th>Weaknesses</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Architecture</td>\n<td>Multi-threaded with thread-local workers</td>\n<td>Good multi-core utilization</td>\n<td>More complex than single-threaded designs</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>gRPC-based dynamic config</td>\n<td>Can update configuration without restarts</td>\n<td>Requires additional infrastructure (control plane)</td>\n</tr>\n<tr>\n<td>Extensibility</td>\n<td>C++ filters and WASM</td>\n<td>Flexible extension model</td>\n<td>C++ expertise required for native extensions</td>\n</tr>\n<tr>\n<td>Observability</td>\n<td>Built-in metrics and tracing</td>\n<td>Excellent for microservices environments</td>\n<td>Higher resource overhead than simpler proxies</td>\n</tr>\n</tbody></table>\n<p>Envoy&#39;s dynamic configuration capabilities enable sophisticated deployment patterns but require additional infrastructure to manage the configuration distribution, making it more complex for simple use cases.</p>\n<p><strong>Cloud Load Balancers</strong> (like AWS ALB, Google Cloud Load Balancing) represent fully managed solutions that abstract away the implementation complexity entirely. These services handle scaling, health checking, and SSL certificate management automatically, but provide limited customization options.</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Cloud Load Balancers</th>\n<th>Strengths</th>\n<th>Weaknesses</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Architecture</td>\n<td>Fully managed</td>\n<td>No operational overhead</td>\n<td>Vendor lock-in, limited customization</td>\n</tr>\n<tr>\n<td>Scalability</td>\n<td>Automatic scaling</td>\n<td>Handles traffic spikes transparently</td>\n<td>Cost can be unpredictable</td>\n</tr>\n<tr>\n<td>Features</td>\n<td>Integrated with cloud services</td>\n<td>SSL management, DDoS protection</td>\n<td>Less control over routing logic</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Web UI or APIs</td>\n<td>Easy to get started</td>\n<td>Advanced configurations may hit limitations</td>\n</tr>\n</tbody></table>\n<p>The managed approach eliminates operational complexity but sacrifices the ability to implement custom business logic or optimize for specific use cases.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: The choice between these approaches depends heavily on the specific requirements and constraints of your environment. NGINX excels in high-performance scenarios with relatively static configurations. HAProxy provides superior load balancing algorithms and health checking for traditional server environments. Envoy offers the most flexibility for dynamic, cloud-native environments. Managed solutions work well when standardized features meet your requirements and operational simplicity is prioritized over customization.</p>\n</blockquote>\n<p>For our educational implementation, we need to balance learning value with implementation complexity. Our design will draw inspiration from NGINX&#39;s event-driven architecture for its proven performance characteristics, while incorporating some of Envoy&#39;s modularity concepts to make the codebase more approachable for learning purposes.</p>\n<blockquote>\n<p><strong>Decision: Event-Driven Architecture with Modular Components</strong></p>\n<ul>\n<li><strong>Context</strong>: We need an architecture that demonstrates production-quality concepts while remaining understandable for educational purposes</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Thread-per-connection model (simple but poor performance)</li>\n<li>Single-threaded event loop (simple but limited scalability)</li>\n<li>Multi-threaded event-driven with worker pools (complex but realistic)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Multi-threaded event-driven architecture with clearly separated components</li>\n<li><strong>Rationale</strong>: This approach teaches modern high-performance patterns while keeping each component focused and testable. The modular design allows learners to understand each piece independently before seeing how they interact.</li>\n<li><strong>Consequences</strong>: Higher initial complexity but better representation of production systems. Each component can be developed and tested independently, making the learning process more manageable.</li>\n</ul>\n</blockquote>\n<p>The architecture decision above shapes our entire implementation approach. Rather than building a monolithic proxy, we&#39;ll create distinct components (HTTP Parser, Connection Manager, Load Balancer, Cache Engine, SSL Termination) that communicate through well-defined interfaces. This mirrors how production systems achieve maintainability and testability while handling the inherent complexity of high-performance network programming.</p>\n<p>Understanding these existing solutions and their trade-offs provides essential context for the design decisions we&#39;ll make throughout our implementation. Each component we build will face similar challenges to those solved by NGINX, HAProxy, and Envoy, but our solutions will prioritize learning clarity and implementation understandability while still demonstrating the fundamental concepts that make production reverse proxies successful.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance bridges the gap between understanding reverse proxy concepts and building a working system. The recommendations here focus on practical technology choices and project organization that will support learning while building toward a production-quality architecture.</p>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Parsing</td>\n<td>Manual state machine with character-by-character parsing</td>\n<td>HTTP parser library (http-parser, picohttpparser)</td>\n</tr>\n<tr>\n<td>Async I/O</td>\n<td>Basic <code>select()</code> or <code>poll()</code> with non-blocking sockets</td>\n<td>Platform-specific <code>epoll</code>/<code>kqueue</code> with event libraries</td>\n</tr>\n<tr>\n<td>SSL/TLS</td>\n<td>OpenSSL with basic certificate loading</td>\n<td>mbedTLS or BoringSSL with advanced features</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Simple key-value file parsing</td>\n<td>JSON/YAML with schema validation</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Printf-style logging to stdout/files</td>\n<td>Structured logging with log levels and rotation</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>Standard malloc/free with careful tracking</td>\n<td>Custom memory pools and arena allocators</td>\n</tr>\n</tbody></table>\n<p>For learning purposes, start with the simple options to understand the underlying concepts, then migrate to advanced options as your understanding deepens. The simple options expose more of the fundamental mechanisms, while advanced options provide production-ready performance and features.</p>\n<p><strong>B. Recommended Project Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>reverse-proxy/\n├── src/\n│   ├── main.c                    ← Entry point and main event loop\n│   ├── config/\n│   │   ├── config.h              ← Configuration data structures\n│   │   ├── config.c              ← Configuration file parsing\n│   │   └── config_test.c         ← Configuration parsing tests\n│   ├── http/\n│   │   ├── parser.h              ← HTTP parsing interface\n│   │   ├── parser.c              ← HTTP request/response parsing\n│   │   ├── message.h             ← HTTP message data structures\n│   │   └── parser_test.c         ← HTTP parsing unit tests\n│   ├── connection/\n│   │   ├── manager.h             ← Connection management interface\n│   │   ├── manager.c             ← Connection lifecycle and pooling\n│   │   ├── pool.h                ← Connection pool data structures\n│   │   └── connection_test.c     ← Connection management tests\n│   ├── loadbalancer/\n│   │   ├── balancer.h            ← Load balancing algorithms interface\n│   │   ├── roundrobin.c          ← Round-robin implementation\n│   │   ├── healthcheck.h         ← Health checking interface\n│   │   └── balancer_test.c       ← Load balancing tests\n│   ├── cache/\n│   │   ├── cache.h               ← Cache engine interface\n│   │   ├── lru.c                 ← LRU cache implementation\n│   │   ├── cache_control.h       ← HTTP cache control parsing\n│   │   └── cache_test.c          ← Cache functionality tests\n│   ├── ssl/\n│   │   ├── termination.h         ← SSL termination interface\n│   │   ├── termination.c         ← TLS context and SNI handling\n│   │   └── ssl_test.c            ← SSL termination tests\n│   └── util/\n│       ├── buffer.h              ← Dynamic buffer management\n│       ├── buffer.c              ← Buffer implementation\n│       ├── logger.h              ← Logging utilities\n│       ├── logger.c              ← Logging implementation\n│       └── hashtable.h           ← Hash table for caching\n├── config/\n│   ├── proxy.conf                ← Example configuration file\n│   └── ssl/\n│       ├── server.crt            ← Example SSL certificate\n│       └── server.key            ← Example private key\n├── tests/\n│   ├── integration/              ← End-to-end tests\n│   └── fixtures/                 ← Test data and mock servers\n├── docs/\n│   └── api.md                    ← Component interfaces documentation\n├── Makefile                      ← Build configuration\n└── README.md                     ← Setup and usage instructions</code></pre></div>\n\n<p>This structure separates concerns clearly, making it easier to understand and test individual components. Each component directory contains its interface header, implementation, and tests, following the principle that related code should live together.</p>\n<p><strong>C. Infrastructure Starter Code:</strong></p>\n<p>The following utilities handle cross-cutting concerns that every component needs, allowing you to focus on the core reverse proxy logic rather than reimplementing basic infrastructure.</p>\n<p><strong>Dynamic Buffer Management</strong> (<code>src/util/buffer.h</code> and <code>src/util/buffer.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stddef.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Dynamic buffer for handling variable-length HTTP messages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\">data;</span><span style=\"color:#6A737D\">          // Buffer memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> capacity;</span><span style=\"color:#6A737D\">     // Total allocated size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> length;</span><span style=\"color:#6A737D\">       // Current data length</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> position;</span><span style=\"color:#6A737D\">     // Current read/write position</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} Buffer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize a new buffer with initial capacity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> buffer_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> initial_capacity</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Ensure buffer has at least required_capacity bytes available</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> buffer_ensure_capacity</span><span style=\"color:#E1E4E8\">(Buffer </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> required_capacity</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Append data to buffer, growing if necessary</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> buffer_append</span><span style=\"color:#E1E4E8\">(Buffer </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> length</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Read data from buffer starting at current position</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> buffer_read</span><span style=\"color:#E1E4E8\">(Buffer </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">dest</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> max_length</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Reset buffer position to beginning for reading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_rewind</span><span style=\"color:#E1E4E8\">(Buffer </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Clear buffer contents but preserve allocated memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_clear</span><span style=\"color:#E1E4E8\">(Buffer </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free buffer and all associated memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_destroy</span><span style=\"color:#E1E4E8\">(Buffer </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Logging Infrastructure</strong> (<code>src/util/logger.h</code> and <code>src/util/logger.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_DEBUG </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_INFO </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_WARN </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_ERROR </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LogLevel;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize logging system with minimum level and output file</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> logger_init</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">min_level</span><span style=\"color:#E1E4E8\">, FILE </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">output</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Log formatted message with specified level</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_log</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">format</span><span style=\"color:#E1E4E8\">, ...);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Convenience macros for common logging patterns</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_DEBUG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_DEBUG, component, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_INFO</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...)  </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_INFO, component, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_WARN</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...)  </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_WARN, component, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_ERROR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_ERROR, component, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Shutdown logging system and close files</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_shutdown</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Hash Table for Caching</strong> (<code>src/util/hashtable.h</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stddef.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> HashTable HashTable;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Create hash table with specified initial capacity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> hashtable_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> initial_capacity</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Insert key-value pair, returns false if out of memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> hashtable_put</span><span style=\"color:#E1E4E8\">(HashTable </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">ht</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">value</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Retrieve value for key, returns NULL if not found</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> hashtable_get</span><span style=\"color:#E1E4E8\">(HashTable </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">ht</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Remove entry for key, returns true if key existed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> hashtable_remove</span><span style=\"color:#E1E4E8\">(HashTable </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">ht</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">key</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Get current number of entries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> hashtable_size</span><span style=\"color:#E1E4E8\">(HashTable </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">ht</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free hash table and all keys (values must be freed by caller)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> hashtable_destroy</span><span style=\"color:#E1E4E8\">(HashTable </span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\">ht</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p>These utilities provide the foundational infrastructure that every reverse proxy component requires. The buffer management handles dynamic memory allocation for HTTP messages, the logging system enables debugging and operational monitoring, and the hash table supports caching and configuration lookups.</p>\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<p>For the main event loop and component coordination, provide structure without implementation:</p>\n<p><strong>Main Event Loop</strong> (<code>src/main.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"config/config.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"connection/manager.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"util/logger.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> argc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#F97583\">[]</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Parse command line arguments for config file path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Load configuration from file using config_load()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Initialize logger with configured log level and output</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Create connection manager with configured listen address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Initialize SSL contexts if SSL termination is enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Enter main event loop calling connection_manager_run()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Handle shutdown signals gracefully (SIGTERM, SIGINT)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Clean up resources and close all connections before exit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use signal handlers to set a global shutdown flag</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Configuration Loading</strong> (<code>src/config/config.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"config.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> config_load</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char</span><span style=\"color:#F97583\"> *</span><span style=\"color:#FFAB70\">config_file_path</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Open configuration file and handle file not found errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Parse listen address and port from config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Parse backend server list with weights and health check URLs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Parse SSL settings including certificate paths and cipher suites</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Parse cache settings including max size and default TTL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate all configuration values for sanity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Return populated ProxyConfig struct or NULL on error</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Start with simple key=value format, expand to JSON later</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints for C:</strong></p>\n<ul>\n<li><strong>Socket Programming</strong>: Use <code>socket(AF_INET, SOCK_STREAM, 0)</code> for TCP sockets, set <code>SO_REUSEADDR</code> to avoid &quot;Address already in use&quot; errors during development</li>\n<li><strong>Non-blocking I/O</strong>: Set sockets to non-blocking mode with <code>fcntl(sockfd, F_SETFL, O_NONBLOCK)</code> and handle <code>EAGAIN</code>/<code>EWOULDBLOCK</code> return codes</li>\n<li><strong>Memory Management</strong>: Always pair <code>malloc()</code> with <code>free()</code>, consider using <code>valgrind</code> to detect memory leaks during development</li>\n<li><strong>String Handling</strong>: Use <code>strncpy()</code> instead of <code>strcpy()</code> and always null-terminate strings manually, HTTP headers are case-insensitive so implement case-insensitive comparison</li>\n<li><strong>Error Handling</strong>: Check return values from all system calls, use <code>errno</code> and <code>strerror()</code> to provide meaningful error messages</li>\n<li><strong>Event-Driven I/O</strong>: Start with <code>select()</code> for portability, then optimize with <code>epoll()</code> on Linux or <code>kqueue()</code> on BSD systems for better performance</li>\n</ul>\n<p><strong>F. Milestone Checkpoint:</strong></p>\n<p>After implementing the basic project structure and infrastructure components:</p>\n<p><strong>What to Run:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> clean</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">make</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./reverse-proxy</span><span style=\"color:#9ECBFF\"> config/proxy.conf</span></span></code></pre></div>\n\n<p><strong>Expected Output:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>[INFO] Starting reverse proxy on 0.0.0.0:8080\n[INFO] Loaded 3 backend servers from configuration\n[INFO] SSL termination enabled with certificate: config/ssl/server.crt\n[INFO] Cache enabled with 100MB maximum size\n[INFO] Ready to accept connections</code></pre></div>\n\n<p><strong>What to Verify Manually:</strong></p>\n<ol>\n<li>Start a simple HTTP server on port 8081 (can use Python&#39;s <code>python -m http.server 8081</code>)</li>\n<li>Configure your proxy to forward to localhost:8081</li>\n<li>Send a request to your proxy: <code>curl -v http://localhost:8080/</code></li>\n<li>Verify the proxy forwards the request and returns the backend&#39;s response</li>\n<li>Check logs to see request processing information</li>\n</ol>\n<p><strong>Signs Something is Wrong:</strong></p>\n<ul>\n<li><strong>&quot;Address already in use&quot; error</strong>: Another process is using the port, or you forgot to set <code>SO_REUSEADDR</code></li>\n<li><strong>Connection refused</strong>: Check that backend servers are actually running and accessible</li>\n<li><strong>Segmentation fault</strong>: Likely a memory management issue, run with <code>valgrind</code> to identify the problem</li>\n<li><strong>Hanging requests</strong>: Probably an issue with non-blocking I/O handling or event loop logic</li>\n</ul>\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Proxy accepts connections but never responds</td>\n<td>Event loop not processing read events</td>\n<td>Add debug logging to event handlers</td>\n<td>Check <code>select()</code>/<code>epoll()</code> event masks</td>\n</tr>\n<tr>\n<td>High CPU usage with no traffic</td>\n<td>Busy loop in event handling</td>\n<td>Profile with <code>top</code> or <code>htop</code></td>\n<td>Add proper blocking on empty event queues</td>\n</tr>\n<tr>\n<td>Memory usage grows continuously</td>\n<td>Memory leaks in connection handling</td>\n<td>Run with <code>valgrind --leak-check=full</code></td>\n<td>Review buffer allocation and cleanup</td>\n</tr>\n<tr>\n<td>Requests timeout randomly</td>\n<td>Backend connection pool exhaustion</td>\n<td>Log connection pool statistics</td>\n<td>Implement connection limits and queuing</td>\n</tr>\n<tr>\n<td>SSL handshake failures</td>\n<td>Certificate or cipher suite issues</td>\n<td>Check OpenSSL error messages</td>\n<td>Verify certificate validity and supported ciphers</td>\n</tr>\n</tbody></table>\n<p>This implementation guidance provides a solid foundation for beginning the reverse proxy implementation. The modular structure and infrastructure components allow you to focus on learning the core concepts of each component without getting bogged down in repetitive utility code. As you implement each milestone, you&#39;ll build upon this foundation while gaining deep understanding of how production reverse proxies handle the complexities of high-performance network programming.</p>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - this section establishes the scope boundaries that guide implementation decisions throughout the entire project lifecycle.</p>\n</blockquote>\n<p>Building a reverse proxy is like constructing a high-performance traffic control system for a busy metropolitan area. Just as a traffic control center must decide which roads to build, which intersections to prioritize, and which advanced features to include versus which to defer, our reverse proxy implementation requires clear boundaries about what functionality to include in our initial design versus what to leave for future iterations.</p>\n<p>The challenge with reverse proxy development lies in the vast scope of potential features. Modern production reverse proxies like NGINX and HAProxy include hundreds of configuration directives, dozens of load balancing algorithms, sophisticated rate limiting, WebSocket proxying, HTTP/3 support, Lua scripting capabilities, and complex SSL certificate management. Attempting to implement everything would result in an overly complex system that never reaches completion. Instead, we must carefully choose a focused subset of functionality that provides a solid foundation while remaining achievable within reasonable development timeframes.</p>\n<p>Think of this goals definition as drawing the blueprint boundaries for our traffic control system. We&#39;re deciding whether to build a basic intersection with traffic lights (core HTTP forwarding), add highway on-ramps (load balancing), include parking structures (caching), and install toll booths (SSL termination), while consciously deciding not to build subway systems (complex routing rules) or airport terminals (advanced features) in our initial version.</p>\n<h3 id=\"core-functional-goals\">Core Functional Goals</h3>\n<p>Our reverse proxy implementation focuses on five fundamental capabilities that represent the essential building blocks of any production reverse proxy system. These goals directly align with our milestone structure and provide measurable success criteria for each development phase.</p>\n<p><strong>HTTP Request Forwarding and Response Relay</strong></p>\n<p>The primary goal involves implementing a robust HTTP proxy core that can accept incoming client connections, parse HTTP requests completely, forward those requests to configured backend servers, and relay the backend responses back to clients. This functionality forms the foundation upon which all other features build.</p>\n<p>The system must handle both HTTP/1.1 and HTTP/2 protocol versions, supporting the complete request-response cycle including method extraction, header parsing, body handling, and proper connection management. This includes correctly implementing HTTP semantics for chunked transfer encoding, content-length validation, and connection keep-alive behavior.</p>\n<p>Success criteria include the ability to proxy any valid HTTP request without modification to the request semantics, maintain request fidelity during forwarding, and properly handle various HTTP methods including GET, POST, PUT, DELETE, and HEAD requests. The proxy must preserve all client headers while adding appropriate forwarding headers like <code>X-Forwarded-For</code> and <code>Via</code>.</p>\n<p><strong>Load Balancing and Backend Distribution</strong></p>\n<p>The second core goal implements intelligent request distribution across multiple backend servers using proven load balancing algorithms. This capability transforms our simple proxy into a scalable traffic distribution system capable of handling high-volume applications.</p>\n<p>The implementation must support multiple distribution strategies including round-robin for even distribution, least-connections for optimal resource utilization, weighted distribution for heterogeneous backend capacity, and IP hash for session affinity requirements. Each algorithm addresses different operational needs and scaling patterns.</p>\n<p>Health checking integration ensures that only healthy backends receive traffic by implementing periodic health checks against configured endpoints, automatically removing failed backends from the active pool, and restoring them when health checks succeed. This provides automatic failover capabilities without manual intervention.</p>\n<p><strong>Connection Pooling and Resource Management</strong></p>\n<p>The third goal focuses on efficient resource utilization through persistent connection management. Rather than establishing new TCP connections for each request, the system maintains pools of reusable connections to backend servers, dramatically reducing connection establishment overhead and improving overall throughput.</p>\n<p>Connection pooling involves maintaining separate pools for each backend server, implementing configurable pool size limits to prevent resource exhaustion, handling connection timeouts through idle connection eviction, and validating connection health before reuse. The pooling strategy must balance resource efficiency with connection freshness.</p>\n<p>The system must gracefully handle pool exhaustion scenarios by either creating temporary connections or queuing requests, depending on configuration policies. Connection lifecycle management includes proper cleanup of idle connections and handling of backend connection failures.</p>\n<p><strong>HTTP Response Caching</strong></p>\n<p>The fourth goal implements intelligent response caching to reduce backend load and improve client response times. The caching system must respect HTTP caching semantics while providing significant performance improvements for cacheable content.</p>\n<p>Cache implementation includes generating unique cache keys from request attributes, storing responses with appropriate TTL values based on <code>Cache-Control</code> headers, supporting cache invalidation through both time-based expiry and explicit purge operations, and properly handling conditional requests using ETags and <code>If-Modified-Since</code> headers.</p>\n<p>The system must distinguish between cacheable and non-cacheable responses, respecting directives like <code>no-cache</code>, <code>no-store</code>, and <code>private</code>. Cache storage utilizes memory-based storage with LRU eviction policies when size limits are reached.</p>\n<p><strong>SSL Termination and Certificate Management</strong></p>\n<p>The fifth goal provides secure HTTPS connection handling through SSL/TLS termination at the proxy layer. This allows backend servers to operate with plain HTTP while presenting encrypted endpoints to clients, simplifying backend infrastructure while maintaining security.</p>\n<p>SSL termination includes loading X.509 certificates and private keys from PEM files, supporting Server Name Indication (SNI) for multi-domain hosting, implementing strong cipher suite selection, enforcing minimum TLS version requirements, and providing automatic HTTP-to-HTTPS redirects for security.</p>\n<p>Certificate management supports runtime certificate reloading without process restarts, proper certificate chain validation, and secure private key handling. The system must support multiple certificates for different domains while selecting the appropriate certificate based on SNI during TLS handshake.</p>\n<h3 id=\"performance-and-quality-goals\">Performance and Quality Goals</h3>\n<p>Beyond functional capabilities, our reverse proxy must meet specific performance and reliability standards that enable production deployment scenarios. These quality goals ensure the system can handle real-world traffic patterns and operational requirements.</p>\n<p><strong>Throughput and Latency Targets</strong></p>\n<p>The system must handle at least 10,000 concurrent connections with sub-millisecond proxy overhead added to backend response times. This performance target ensures the proxy doesn&#39;t become a bottleneck in high-traffic applications while maintaining responsive user experiences.</p>\n<p>Latency measurements exclude backend processing time and network transit delays, focusing specifically on proxy overhead including request parsing, routing decisions, connection management, and response forwarding. The target assumes properly tuned operating system settings and adequate hardware resources.</p>\n<p>Memory usage must remain bounded and predictable under load, with configurable limits for connection pools, cache storage, and request buffering. The system should avoid memory leaks and implement proper resource cleanup to support long-running operation.</p>\n<p><strong>Reliability and Error Handling</strong></p>\n<p>The proxy must provide robust error handling and graceful degradation capabilities, ensuring that individual backend failures don&#39;t affect overall system availability. Error handling includes proper timeout management, circuit breaker patterns for failing backends, and appropriate error responses to clients.</p>\n<p>Logging and monitoring integration provides operational visibility through structured log output, metrics collection for key performance indicators, and debugging information for troubleshooting. The system must support configurable log levels and external monitoring system integration.</p>\n<p>Recovery mechanisms handle various failure scenarios including backend connection failures, SSL certificate errors, configuration reload failures, and resource exhaustion conditions. Each failure mode requires specific detection and recovery strategies.</p>\n<h3 id=\"explicit-non-goals\">Explicit Non-Goals</h3>\n<p>Clearly defining what our reverse proxy will NOT implement is equally important as defining its goals. These non-goals establish scope boundaries that prevent feature creep and maintain implementation focus on core capabilities.</p>\n<p><strong>Advanced Routing and Traffic Management</strong></p>\n<p>Our implementation explicitly excludes complex routing features found in advanced reverse proxies and API gateways. We will not implement URL rewriting capabilities, complex path-based routing rules, regular expression matching for request routing, or header-based routing decisions beyond basic host header handling.</p>\n<p>Rate limiting and traffic shaping features are excluded from the initial implementation. While these capabilities are valuable in production environments, they add significant complexity to the core proxy logic and can be implemented as future extensions without affecting the fundamental architecture.</p>\n<p>Authentication and authorization features including OAuth integration, JWT validation, API key management, and access control lists are outside our scope. These features typically require integration with external identity systems and add substantial complexity to the request processing pipeline.</p>\n<p><strong>Protocol Extensions and Advanced Features</strong></p>\n<p>WebSocket proxying support is explicitly excluded due to the different connection semantics and state management requirements. WebSocket connections require long-lived, bidirectional communication that differs significantly from standard HTTP request-response patterns.</p>\n<p>HTTP/3 and QUIC protocol support are not included in the initial implementation. While these protocols represent the future of web communication, they require specialized libraries and significantly more complex implementation than HTTP/1.1 and HTTP/2.</p>\n<p>Compression and content modification features including gzip compression, content transcoding, and response body modification are excluded. These features require streaming content processing and add complexity to the response handling pipeline.</p>\n<p><strong>Operational and Management Features</strong></p>\n<p>Administrative interfaces including REST APIs for configuration management, web-based dashboards, and runtime configuration modification are not included. The system will use file-based configuration with restart-required configuration changes.</p>\n<p>Advanced monitoring features including Prometheus metrics export, distributed tracing integration, and detailed performance profiling are excluded from the core implementation. Basic logging provides operational visibility without requiring complex monitoring infrastructure.</p>\n<p>Clustering and high availability features including configuration synchronization across multiple proxy instances, shared state management, and automatic failover are outside our scope. The system focuses on single-instance operation with external load balancing for high availability.</p>\n<p><strong>Security and Compliance Features</strong></p>\n<p>Advanced security features including request filtering, SQL injection detection, cross-site scripting protection, and other web application firewall capabilities are excluded. These features require deep content inspection and complex rule engines.</p>\n<p>Certificate authority integration, automatic certificate provisioning through ACME protocol, and certificate rotation automation are not included. The system supports manual certificate management through file-based configuration.</p>\n<p>Compliance features including detailed audit logging, request/response recording, and regulatory compliance reporting are outside our implementation scope.</p>\n<h3 id=\"architecture-decision-records\">Architecture Decision Records</h3>\n<p>The following decisions establish fundamental design principles that guide implementation choices throughout the development process.</p>\n<blockquote>\n<p><strong>Decision: Event-Driven Architecture with Asynchronous I/O</strong></p>\n<ul>\n<li><strong>Context</strong>: Reverse proxies must handle thousands of concurrent connections efficiently without blocking on slow operations like backend requests or SSL handshakes.</li>\n<li><strong>Options Considered</strong>: Thread-per-connection model, process-per-connection model, event-driven model with epoll/kqueue</li>\n<li><strong>Decision</strong>: Event-driven architecture using non-blocking I/O and event loops</li>\n<li><strong>Rationale</strong>: Thread-per-connection models consume excessive memory (8KB+ per thread stack) and suffer context switching overhead with thousands of connections. Event-driven models achieve higher concurrency with lower resource usage.</li>\n<li><strong>Consequences</strong>: Requires careful state management and non-blocking operation implementation, but enables handling 10,000+ concurrent connections efficiently.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Architecture Model</th>\n<th>Memory per Connection</th>\n<th>Context Switch Overhead</th>\n<th>Max Connections</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Thread-per-connection</td>\n<td>~8KB+ stack</td>\n<td>High with many threads</td>\n<td>~1,000</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Process-per-connection</td>\n<td>~1MB+ per process</td>\n<td>Very high</td>\n<td>~100</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Event-driven</td>\n<td>~1KB connection state</td>\n<td>Minimal</td>\n<td>10,000+</td>\n<td><strong>Yes</strong></td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: In-Memory Caching with LRU Eviction</strong></p>\n<ul>\n<li><strong>Context</strong>: Response caching requires balancing cache hit rates with memory usage and implementation complexity.</li>\n<li><strong>Options Considered</strong>: In-memory hash table, Redis external cache, disk-based cache with memory index</li>\n<li><strong>Decision</strong>: In-memory hash table with LRU eviction policy</li>\n<li><strong>Rationale</strong>: In-memory storage provides microsecond access times without network round trips. LRU eviction provides good hit rates for web traffic patterns. External caches add network latency and operational complexity.</li>\n<li><strong>Consequences</strong>: Cache size limited by available memory, but provides excellent performance and simple implementation.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Caching Strategy</th>\n<th>Access Latency</th>\n<th>Scalability</th>\n<th>Operational Complexity</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>In-memory hash table</td>\n<td>Microseconds</td>\n<td>Limited by RAM</td>\n<td>Low</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>External Redis</td>\n<td>Milliseconds</td>\n<td>High</td>\n<td>Medium</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Disk with memory index</td>\n<td>Milliseconds</td>\n<td>Very high</td>\n<td>High</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: File-Based Configuration with Restart-Required Reload</strong></p>\n<ul>\n<li><strong>Context</strong>: Configuration management requires balancing operational flexibility with implementation complexity.</li>\n<li><strong>Options Considered</strong>: File-based with restart, file-based with hot reload, API-based runtime configuration</li>\n<li><strong>Decision</strong>: File-based configuration requiring process restart for changes</li>\n<li><strong>Rationale</strong>: File-based configuration integrates well with configuration management tools and version control. Hot reload requires complex state synchronization and error handling. API-based configuration requires additional security and persistence mechanisms.</li>\n<li><strong>Consequences</strong>: Configuration changes require brief service interruption, but implementation remains simple and reliable.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Configuration Method</th>\n<th>Change Latency</th>\n<th>Implementation Complexity</th>\n<th>Version Control</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File + restart</td>\n<td>~1 second downtime</td>\n<td>Low</td>\n<td>Excellent</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>File + hot reload</td>\n<td>Immediate</td>\n<td>High</td>\n<td>Good</td>\n<td>No</td>\n</tr>\n<tr>\n<td>API-based runtime</td>\n<td>Immediate</td>\n<td>Very high</td>\n<td>Poor</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h3 id=\"success-criteria-and-validation\">Success Criteria and Validation</h3>\n<p>Each goal requires specific, measurable criteria that validate successful implementation and provide clear checkpoints for development progress.</p>\n<p><strong>Functional Validation Criteria</strong></p>\n<p>HTTP proxy functionality validation involves testing complete request-response cycles with various HTTP methods, header combinations, and body types. Success requires bit-for-bit response fidelity compared to direct backend communication, proper forwarding header addition, and correct error handling for invalid requests.</p>\n<p>Load balancing validation tests distribution algorithms with multiple backend servers, verifying even distribution for round-robin, connection-aware routing for least-connections, and proper weight respect for weighted algorithms. Health checking validation requires automatic backend removal during simulated failures and restoration when health checks succeed.</p>\n<p>Connection pooling validation measures connection reuse rates, pool size management under load, and proper connection cleanup during idle periods. Cache validation tests hit rates for repeated requests, proper TTL expiration, and correct cache-control header respect.</p>\n<p>SSL termination validation requires successful TLS handshake completion, proper certificate selection based on SNI, and secure cipher suite negotiation. Backend communication validation ensures plain HTTP forwarding works correctly after SSL termination.</p>\n<p><strong>Performance Validation Benchmarks</strong></p>\n<p>Throughput testing uses tools like <code>ab</code> (Apache Bench) or <code>wrk</code> to generate sustained load and measure requests per second under various connection counts. Target performance includes maintaining 95th percentile response times under 1ms proxy overhead with 1,000 concurrent connections.</p>\n<p>Memory usage testing validates bounded memory growth under sustained load, proper cleanup of idle resources, and absence of memory leaks during extended operation. Connection pool efficiency testing measures connection reuse rates and pool hit ratios.</p>\n<p>Cache effectiveness testing measures hit rates for typical web traffic patterns and validates proper memory usage under various cache sizes. SSL performance testing ensures TLS handshake overhead remains acceptable under load.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The goals and non-goals established in this section guide every architectural and implementation decision throughout the reverse proxy development process. Understanding these boundaries helps maintain focus on core capabilities while avoiding scope creep that could derail the project.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Parsing</td>\n<td>Custom parser with state machine</td>\n<td>libhttp-parser library</td>\n</tr>\n<tr>\n<td>TLS Implementation</td>\n<td>OpenSSL with basic configuration</td>\n<td>mbedTLS with advanced features</td>\n</tr>\n<tr>\n<td>Event Loop</td>\n<td>select() system call</td>\n<td>epoll (Linux) / kqueue (BSD)</td>\n</tr>\n<tr>\n<td>Configuration Format</td>\n<td>INI-style key-value pairs</td>\n<td>YAML with validation schema</td>\n</tr>\n<tr>\n<td>Logging Framework</td>\n<td>fprintf to stderr/file</td>\n<td>Structured JSON logging</td>\n</tr>\n</tbody></table>\n<h4 id=\"core-configuration-structure\">Core Configuration Structure</h4>\n<p>The configuration system forms the foundation that enables all proxy functionality. A well-designed configuration structure supports the goals while maintaining simplicity and clarity.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Complete configuration structure supporting all goals</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Server configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> listen_address</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> listen_port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> worker_threads;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // SSL configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> ssl_enabled;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> ssl_cert_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> ssl_key_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> ssl_ca_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> ssl_min_version;</span><span style=\"color:#6A737D\">  // Minimum TLS version</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Backend server configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> backend_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        char</span><span style=\"color:#FFAB70\"> address</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> weight;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> health_check_interval;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        char</span><span style=\"color:#FFAB70\"> health_check_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#FFAB70\">backends</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Load balancing configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        LB_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        LB_LEAST_CONNECTIONS,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        LB_WEIGHTED_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        LB_IP_HASH</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } lb_algorithm;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Cache configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> cache_enabled;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> cache_max_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> cache_default_ttl;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> cache_exclude_patterns</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Connection pooling configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> pool_max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> pool_idle_timeout;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> pool_connect_timeout;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Logging configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LogLevel log_level;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> log_file_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> log_requests;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyConfig;</span></span></code></pre></div>\n\n<h4 id=\"configuration-loading-implementation\">Configuration Loading Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Configuration loader that validates goals compliance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> config_load</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> config_file_path</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Open configuration file with error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Parse each configuration section (server, ssl, backends, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Validate backend configuration has at least one server</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Validate SSL configuration if SSL is enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set default values for optional parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate port numbers are in valid ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Validate file paths exist and are readable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Allocate and populate ProxyConfig structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Close configuration file and return config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use fopen(), fgets(), and sscanf() for simple parsing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\">  // Placeholder for implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"goal-validation-checklist\">Goal Validation Checklist</h4>\n<p>The following validation steps ensure implementation stays within defined goals and meets all success criteria:</p>\n<p><strong>Milestone 1 Validation - HTTP Proxy Core</strong></p>\n<ul>\n<li>Start proxy server on configured port</li>\n<li>Send HTTP GET request using curl or similar tool</li>\n<li>Verify response matches direct backend response exactly</li>\n<li>Check proxy logs show request processing</li>\n<li>Test with various HTTP methods (GET, POST, PUT, DELETE)</li>\n<li>Verify <code>X-Forwarded-For</code> header is added to forwarded requests</li>\n</ul>\n<p><strong>Milestone 2 Validation - Load Balancing</strong></p>\n<ul>\n<li>Configure multiple backend servers in different states</li>\n<li>Send multiple requests and verify round-robin distribution</li>\n<li>Stop one backend server and verify traffic redirects automatically</li>\n<li>Check health check logs show backend status changes</li>\n<li>Test weighted distribution with different backend weights</li>\n</ul>\n<p><strong>Milestone 3 Validation - Connection Pooling</strong></p>\n<ul>\n<li>Enable connection pooling in configuration</li>\n<li>Send multiple requests to same backend</li>\n<li>Monitor connection counts to verify reuse</li>\n<li>Test pool size limits by exceeding max connections</li>\n<li>Verify idle connections get cleaned up after timeout</li>\n</ul>\n<p><strong>Milestone 4 Validation - Caching</strong></p>\n<ul>\n<li>Enable caching with reasonable size limit</li>\n<li>Send same GET request multiple times</li>\n<li>Verify subsequent requests return faster (cache hits)</li>\n<li>Check cache hit/miss statistics in logs</li>\n<li>Test cache expiration with short TTL values</li>\n</ul>\n<p><strong>Milestone 5 Validation - SSL Termination</strong></p>\n<ul>\n<li>Configure SSL certificate and enable HTTPS</li>\n<li>Connect using https:// URL and verify certificate</li>\n<li>Check backend receives plain HTTP requests</li>\n<li>Test SNI with multiple domain certificates</li>\n<li>Verify HTTP requests redirect to HTTPS</li>\n</ul>\n<h4 id=\"common-implementation-pitfalls\">Common Implementation Pitfalls</h4>\n<p>⚠️ <strong>Pitfall: Scope Creep Beyond Defined Goals</strong>\nMany developers attempt to add features not included in the goals, such as complex routing rules or authentication mechanisms. This leads to incomplete core functionality and extended development timelines. Stay focused on the five core goals and implement them completely before considering extensions.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Performance Goals During Development</strong>\nImplementing features without considering performance implications can result in a functionally correct but unusable proxy. Test performance early and often, ensuring each milestone meets latency and throughput targets before proceeding to the next.</p>\n<p>⚠️ <strong>Pitfall: Over-Engineering Configuration System</strong>\nAttempting to build a sophisticated configuration system with hot reloading, validation schemas, and complex nesting violates the non-goals and adds unnecessary complexity. Use simple file-based configuration that covers the required functionality without extra features.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Error Handling Strategy</strong>\nFocusing only on happy path scenarios without implementing comprehensive error handling for network failures, backend timeouts, and resource exhaustion. Define specific error handling strategies for each goal and implement them consistently.</p>\n<p>The goals and non-goals established here serve as the north star for all implementation decisions. When facing design choices or feature requests, refer back to these boundaries to maintain project focus and ensure successful delivery of core reverse proxy functionality.</p>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - the architectural foundation established here guides implementation decisions across HTTP proxy core, load balancing, connection pooling, caching, and SSL termination components.</p>\n</blockquote>\n<p>Building a reverse proxy is like designing the traffic control system for a busy metropolitan area. Just as traffic lights, road signs, and interchange ramps must work together seamlessly to move thousands of vehicles efficiently from origin to destination, our reverse proxy must coordinate multiple specialized components to route HTTP requests from clients to backend servers and return responses reliably. The architectural challenge lies not just in handling individual requests, but in managing thousands of concurrent connections, making intelligent routing decisions, maintaining performance under load, and gracefully handling failures - all while appearing as a single, responsive service to clients.</p>\n<p>The reverse proxy sits at a critical network chokepoint, making architectural decisions that directly impact system scalability, reliability, and performance. Unlike a simple forwarding service, our proxy must simultaneously act as an HTTP server accepting client connections, an HTTP client making backend requests, a load balancer distributing traffic intelligently, a cache providing fast response delivery, and an SSL termination point handling cryptographic operations. Each of these roles requires specialized logic, yet they must integrate seamlessly to process requests with minimal latency and maximum throughput.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<p>The event-driven architecture we employ mirrors how modern operating systems handle I/O operations. Rather than dedicating one thread per connection (which would exhaust system resources with thousands of concurrent clients), our proxy uses asynchronous, non-blocking I/O with event loops - similar to how a single air traffic controller can manage multiple aircraft simultaneously by responding to events (radio calls, radar updates, weather changes) as they occur rather than giving each plane dedicated attention.</p>\n<h3 id=\"component-overview\">Component Overview</h3>\n<p>The reverse proxy architecture consists of five primary components working in concert, each with distinct responsibilities that collectively enable high-performance request processing. Think of these components as specialized departments in a logistics company: the mail sorting facility (HTTP Parser) processes incoming packages, the route planning department (Load Balancer) decides which delivery truck to use, the dispatcher (Connection Manager) manages the vehicle fleet, the warehouse (Cache Engine) stores frequently requested items for quick access, and the security checkpoint (SSL Termination) handles package verification and unwrapping.</p>\n<p>The <strong>HTTP Parser Component</strong> serves as the protocol translation layer, responsible for interpreting the stream of bytes received from client connections and constructing well-formed HTTP requests that can be processed by other components. This component must handle the complexities of HTTP/1.1 and HTTP/2 protocols, including chunked transfer encoding, connection keep-alive semantics, and header field parsing. The parser maintains state machines for each connection to track parsing progress and handle partial reads that commonly occur with TCP streams. Beyond basic parsing, this component validates request syntax, extracts routing information, and prepares request objects that downstream components can process efficiently.</p>\n<table>\n<thead>\n<tr>\n<th>Responsibility</th>\n<th>Description</th>\n<th>Input</th>\n<th>Output</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Parsing</td>\n<td>Convert raw TCP data streams into structured HTTP request objects</td>\n<td>Raw bytes from client connections</td>\n<td><code>HttpRequest</code> structures with parsed headers, method, path, and body</td>\n</tr>\n<tr>\n<td>Response Construction</td>\n<td>Build HTTP response messages from backend responses and proxy metadata</td>\n<td>Backend responses, cache entries, error conditions</td>\n<td>Formatted HTTP response bytes for client transmission</td>\n</tr>\n<tr>\n<td>Protocol Handling</td>\n<td>Support HTTP/1.1 and HTTP/2 protocol variations</td>\n<td>Various HTTP protocol versions and features</td>\n<td>Consistent internal request/response representation</td>\n</tr>\n<tr>\n<td>Header Manipulation</td>\n<td>Add proxy-specific headers like X-Forwarded-For and Via</td>\n<td>Original client requests</td>\n<td>Enriched requests with proxy headers for backend forwarding</td>\n</tr>\n<tr>\n<td>Connection State Tracking</td>\n<td>Maintain parsing state for each active connection</td>\n<td>Connection events and data arrivals</td>\n<td>Updated connection parsing states and completion notifications</td>\n</tr>\n</tbody></table>\n<p>The <strong>Connection Manager Component</strong> orchestrates the lifecycle of network connections, acting as both a client connection acceptor and a backend connection pool manager. This component implements the challenging task of maintaining persistent connections to backend servers while efficiently serving thousands of concurrent clients. The connection manager must balance resource utilization against performance, deciding when to create new backend connections, when to reuse existing ones, and when to close idle connections to free system resources. It also handles connection health monitoring, ensuring that stale or broken connections are detected and removed before they can impact request processing.</p>\n<table>\n<thead>\n<tr>\n<th>Responsibility</th>\n<th>Description</th>\n<th>Managed Resources</th>\n<th>Key Algorithms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Client Connection Acceptance</td>\n<td>Accept and manage incoming client connections on listen socket</td>\n<td>Client socket file descriptors, connection state objects</td>\n<td>Accept loop with non-blocking I/O and connection queuing</td>\n</tr>\n<tr>\n<td>Backend Connection Pooling</td>\n<td>Maintain reusable connections to backend servers</td>\n<td>Connection pools per backend, idle connection timers</td>\n<td>Pool size management, connection validation, timeout handling</td>\n</tr>\n<tr>\n<td>Connection Lifecycle Management</td>\n<td>Track connection states from establishment to closure</td>\n<td>Connection state machines, resource cleanup timers</td>\n<td>State transition handling, graceful connection termination</td>\n</tr>\n<tr>\n<td>Resource Limit Enforcement</td>\n<td>Prevent resource exhaustion through connection limits</td>\n<td>File descriptor limits, memory usage tracking</td>\n<td>Connection counting, admission control, backpressure mechanisms</td>\n</tr>\n<tr>\n<td>Health Monitoring</td>\n<td>Detect and handle connection failures</td>\n<td>Connection health status, failure detection timers</td>\n<td>Heartbeat checking, failure pattern recognition, automatic cleanup</td>\n</tr>\n</tbody></table>\n<p>The <strong>Load Balancer Component</strong> implements intelligent request distribution across available backend servers, making real-time routing decisions based on server health, current load, and configured algorithms. This component must maintain up-to-date knowledge of backend server status while making routing decisions quickly enough to avoid introducing significant latency. The load balancer coordinates with the connection manager to ensure selected backends have available connections and can handle additional requests without becoming overwhelmed.</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Selection Criteria</th>\n<th>State Maintained</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Round Robin</td>\n<td>Sequential server selection with wraparound</td>\n<td>Current position index, server list</td>\n<td>Equal capacity servers, simple distribution</td>\n</tr>\n<tr>\n<td>Least Connections</td>\n<td>Server with fewest active connections</td>\n<td>Active connection count per server</td>\n<td>Variable request processing times</td>\n</tr>\n<tr>\n<td>Weighted Round Robin</td>\n<td>Server selection based on assigned capacity weights</td>\n<td>Weight values, weighted position tracking</td>\n<td>Servers with different capacity levels</td>\n</tr>\n<tr>\n<td>IP Hash</td>\n<td>Consistent server selection based on client IP</td>\n<td>Hash ring or consistent hashing state</td>\n<td>Session affinity requirements</td>\n</tr>\n<tr>\n<td>Health Check Integration</td>\n<td>Exclude unhealthy servers from selection</td>\n<td>Server health status, last check timestamps</td>\n<td>Automatic failure detection and recovery</td>\n</tr>\n</tbody></table>\n<p>The <strong>Cache Engine Component</strong> provides intelligent HTTP response caching to reduce backend load and improve client response times. This component must respect HTTP caching semantics while implementing efficient cache storage and retrieval mechanisms. The cache engine works closely with the HTTP parser to extract cache-control directives and with the load balancer to determine when cache misses require backend requests. Cache management involves complex decisions around what to cache, how long to retain cached responses, and when to invalidate or refresh cached content.</p>\n<table>\n<thead>\n<tr>\n<th>Cache Operation</th>\n<th>Decision Factors</th>\n<th>Storage Requirements</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache Key Generation</td>\n<td>Request method, URL, relevant headers (Vary)</td>\n<td>Unique key per cacheable request variant</td>\n<td>Fast key computation and collision avoidance</td>\n</tr>\n<tr>\n<td>Cacheability Assessment</td>\n<td>Cache-Control headers, request method, response status</td>\n<td>Header parsing state, policy configuration</td>\n<td>Quick cache policy evaluation</td>\n</tr>\n<tr>\n<td>Storage and Retrieval</td>\n<td>TTL management, LRU eviction, size limits</td>\n<td>In-memory hash tables, expiration queues</td>\n<td>Sub-millisecond lookup and storage operations</td>\n</tr>\n<tr>\n<td>Cache Invalidation</td>\n<td>TTL expiration, explicit purge commands</td>\n<td>Expiration timestamps, invalidation triggers</td>\n<td>Automatic cleanup without blocking request processing</td>\n</tr>\n<tr>\n<td>Conditional Request Support</td>\n<td>ETag and Last-Modified header handling</td>\n<td>Cached response metadata, validation tokens</td>\n<td>Bandwidth savings through 304 Not Modified responses</td>\n</tr>\n</tbody></table>\n<p>The <strong>SSL Termination Component</strong> handles the complexities of TLS connection establishment, certificate management, and cryptographic operations required for HTTPS support. This component must efficiently perform TLS handshakes, validate certificates, support Server Name Indication (SNI) for multi-domain hosting, and decrypt incoming requests for processing by other components. SSL termination involves significant computational overhead, requiring careful resource management and optimization to maintain high throughput.</p>\n<table>\n<thead>\n<tr>\n<th>SSL Operation</th>\n<th>Technical Requirements</th>\n<th>Security Considerations</th>\n<th>Performance Factors</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>TLS Handshake Processing</td>\n<td>Cipher suite negotiation, certificate presentation</td>\n<td>Strong cipher selection, protocol version enforcement</td>\n<td>Handshake latency, connection establishment time</td>\n</tr>\n<tr>\n<td>Certificate Management</td>\n<td>Multiple certificate loading, SNI support</td>\n<td>Private key security, certificate chain validation</td>\n<td>Certificate lookup speed, memory usage</td>\n</tr>\n<tr>\n<td>Session Management</td>\n<td>TLS session resumption, session ticket handling</td>\n<td>Session key security, replay attack prevention</td>\n<td>Session cache efficiency, resumption success rate</td>\n</tr>\n<tr>\n<td>Cryptographic Operations</td>\n<td>Bulk encryption/decryption, MAC verification</td>\n<td>Constant-time operations, side-channel resistance</td>\n<td>Cipher performance, hardware acceleration utilization</td>\n</tr>\n<tr>\n<td>Protocol Security</td>\n<td>TLS version enforcement, vulnerability mitigation</td>\n<td>Known attack prevention, security patch integration</td>\n<td>Security overhead vs. performance trade-offs</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Event-Driven vs. Thread-Per-Connection Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Reverse proxies must handle thousands of concurrent connections efficiently, requiring a choice between traditional threading models and event-driven architectures</li>\n<li><strong>Options Considered</strong>: Thread-per-connection, thread pool with blocking I/O, event-driven with non-blocking I/O</li>\n<li><strong>Decision</strong>: Event-driven architecture with non-blocking I/O and event loops</li>\n<li><strong>Rationale</strong>: Thread-per-connection models consume excessive memory (8KB+ stack per thread) and CPU context switching overhead with thousands of connections. Event-driven architectures can handle 10,000+ concurrent connections in a single process with minimal resource overhead</li>\n<li><strong>Consequences</strong>: Requires more complex state management and asynchronous programming patterns, but enables horizontal scalability and efficient resource utilization</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Architecture Option</th>\n<th>Memory Usage</th>\n<th>Scalability Limit</th>\n<th>Context Switching Overhead</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Thread-per-connection</td>\n<td>8KB+ per connection</td>\n<td>~1,000 connections</td>\n<td>High (kernel thread scheduling)</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Thread pool + blocking I/O</td>\n<td>Fixed pool memory</td>\n<td>Limited by pool size</td>\n<td>Medium (thread pool contention)</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Event-driven + non-blocking I/O</td>\n<td>~1KB per connection</td>\n<td>10,000+ connections</td>\n<td>Minimal (user-space event loop)</td>\n<td><strong>Yes</strong></td>\n</tr>\n</tbody></table>\n<p>The components communicate through well-defined interfaces using message passing and shared data structures. The HTTP Parser produces <code>HttpRequest</code> objects consumed by the Load Balancer for routing decisions. The Connection Manager provides connection handles that other components use for I/O operations. The Cache Engine intercepts requests and responses, potentially short-circuiting the normal backend forwarding path. The SSL Termination component acts as a preprocessor, decrypting requests before they reach the HTTP Parser and encrypting responses before client transmission.</p>\n<h3 id=\"recommended-file-structure\">Recommended File Structure</h3>\n<p>Organizing the reverse proxy codebase requires careful consideration of component boundaries, shared dependencies, and testing requirements. The file structure should reflect the architectural components while providing clear separation of concerns and enabling independent development and testing of each component. Think of the file organization as creating dedicated workshop areas for different craftspeople - each component gets its own space with the tools it needs, while shared utilities remain accessible to all.</p>\n<p>The recommended structure follows the principle of <strong>component-based organization</strong> where each major architectural component gets its own directory containing implementation files, tests, and component-specific utilities. This approach enables parallel development, simplifies testing by isolating component dependencies, and makes the codebase easier to navigate for developers working on specific features.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>reverse-proxy/\n├── cmd/\n│   └── proxy/\n│       └── main.c                    ← Application entry point, server initialization\n├── src/\n│   ├── core/\n│   │   ├── proxy.h                   ← Main proxy server structure and lifecycle\n│   │   ├── proxy.c\n│   │   ├── config.h                  ← ProxyConfig definition and loading\n│   │   ├── config.c\n│   │   ├── logger.h                  ← Logging system with LogLevel enum\n│   │   └── logger.c\n│   ├── http/\n│   │   ├── parser.h                  ← HTTP request/response parsing\n│   │   ├── parser.c\n│   │   ├── request.h                 ← HttpRequest and HttpResponse structures\n│   │   ├── request.c\n│   │   ├── response.h\n│   │   └── response.c\n│   ├── connection/\n│   │   ├── manager.h                 ← Connection lifecycle management\n│   │   ├── manager.c\n│   │   ├── pool.h                    ← Backend connection pooling\n│   │   ├── pool.c\n│   │   ├── client.h                  ← Client connection handling\n│   │   └── client.c\n│   ├── loadbalancer/\n│   │   ├── balancer.h                ← Load balancing algorithms\n│   │   ├── balancer.c\n│   │   ├── health.h                  ← Health checking system\n│   │   ├── health.c\n│   │   ├── algorithms.h              ← Round-robin, least-connections, weighted\n│   │   └── algorithms.c\n│   ├── cache/\n│   │   ├── engine.h                  ← Cache storage and retrieval\n│   │   ├── engine.c\n│   │   ├── policies.h                ← Cache-control header handling\n│   │   ├── policies.c\n│   │   ├── storage.h                 ← LRU eviction and memory management\n│   │   └── storage.c\n│   ├── ssl/\n│   │   ├── termination.h             ← SSL/TLS context management\n│   │   ├── termination.c\n│   │   ├── certificates.h            ← Certificate loading and SNI support\n│   │   ├── certificates.c\n│   │   ├── handshake.h               ← TLS handshake processing\n│   │   └── handshake.c\n│   ├── utils/\n│   │   ├── buffer.h                  ← Buffer structure and operations\n│   │   ├── buffer.c\n│   │   ├── hashtable.h               ← HashTable implementation\n│   │   ├── hashtable.c\n│   │   ├── string.h                  ← String manipulation utilities\n│   │   ├── string.c\n│   │   ├── network.h                 ← Socket utilities and address handling\n│   │   └── network.c\n│   └── common/\n│       ├── types.h                   ← Common type definitions and constants\n│       ├── errors.h                  ← Error codes and error handling macros\n│       └── constants.h               ← System constants like SO_REUSEADDR, O_NONBLOCK\n├── tests/\n│   ├── unit/\n│   │   ├── test_http_parser.c        ← Unit tests for HTTP parsing components\n│   │   ├── test_connection_manager.c\n│   │   ├── test_load_balancer.c\n│   │   ├── test_cache_engine.c\n│   │   └── test_ssl_termination.c\n│   ├── integration/\n│   │   ├── test_request_flow.c       ← End-to-end request processing tests\n│   │   ├── test_backend_integration.c\n│   │   └── test_ssl_integration.c\n│   └── fixtures/\n│       ├── test_configs/             ← Test configuration files\n│       ├── certificates/             ← Test SSL certificates\n│       └── responses/                ← Sample HTTP responses for testing\n├── config/\n│   ├── proxy.conf                    ← Main configuration file template\n│   ├── ssl/\n│   │   ├── server.crt               ← SSL certificate files\n│   │   ├── server.key\n│   │   └── ca.crt\n│   └── backends.conf                 ← Backend server definitions\n├── scripts/\n│   ├── build.sh                      ← Build automation scripts\n│   ├── test.sh                       ← Test execution scripts\n│   └── generate_certs.sh             ← SSL certificate generation for testing\n├── docs/\n│   ├── api.md                        ← Component API documentation\n│   ├── configuration.md              ← Configuration file format and options\n│   └── deployment.md                 ← Deployment and operations guide\n├── Makefile                          ← Build system configuration\n└── README.md                         ← Project overview and quick start guide</code></pre></div>\n\n<p>The <strong>core</strong> directory contains the fundamental proxy server infrastructure, including the main <code>ProxyConfig</code> structure that holds all configuration parameters, the logging system with <code>LogLevel</code> enumeration, and the primary server lifecycle management. These components provide the foundation that all other components depend on, similar to how a building&#39;s foundation supports all upper floors.</p>\n<p>The <strong>http</strong> directory encapsulates all HTTP protocol handling, including request and response parsing, header manipulation, and protocol version negotiation. The separation between parsing logic and data structures allows for easier testing and potential future support for additional protocols. The <code>HttpRequest</code> and <code>HttpResponse</code> structures defined here become the standard data interchange format between all proxy components.</p>\n<p>The <strong>connection</strong> directory manages the complex lifecycle of network connections, separating client connection handling from backend connection pooling. This separation allows independent optimization of client-facing and backend-facing connection strategies. The connection manager coordinates between these subsystems to ensure efficient resource utilization and proper connection cleanup.</p>\n<p>The <strong>loadbalancer</strong> directory implements request distribution logic, health checking, and backend server management. The separation between general balancing logic and specific algorithms allows easy addition of new load balancing strategies without modifying core balancing infrastructure. Health checking gets its own module because it requires independent timing and state management.</p>\n<p>The <strong>cache</strong> directory contains HTTP caching implementation, separated into cache storage mechanisms and HTTP cache policy enforcement. This separation allows the storage engine to be optimized independently of cache policy logic, and enables potential future backends like Redis or memcached without changing cache policy handling.</p>\n<p>The <strong>ssl</strong> directory handles all aspects of TLS termination, from certificate management to cryptographic operations. The modular structure allows different SSL implementations or hardware acceleration to be integrated by replacing specific modules while maintaining the same interface to other components.</p>\n<blockquote>\n<p><strong>Decision: Component Directory Structure vs. Feature-Based Structure</strong></p>\n<ul>\n<li><strong>Context</strong>: Large codebases can be organized by architectural components or by user-facing features, each with different navigation and development implications</li>\n<li><strong>Options Considered</strong>: Component-based directories (http/, ssl/, cache/), feature-based directories (proxying/, load-balancing/, caching/), flat structure</li>\n<li><strong>Decision</strong>: Component-based directory structure with clear architectural boundaries</li>\n<li><strong>Rationale</strong>: Component-based organization maps directly to system architecture, enabling parallel development by different team members, clear testing boundaries, and easier code navigation when debugging specific component issues</li>\n<li><strong>Consequences</strong>: Requires well-defined interfaces between components and may require some code duplication, but provides better separation of concerns and development scalability</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Organization Option</th>\n<th>Developer Navigation</th>\n<th>Testing Isolation</th>\n<th>Parallel Development</th>\n<th>Chosen</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Component-based (http/, ssl/, cache/)</td>\n<td>Easy to find component-specific code</td>\n<td>Clear test boundaries per component</td>\n<td>Multiple developers per component</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>Feature-based (proxying/, load-balancing/)</td>\n<td>Code scattered across components</td>\n<td>Complex cross-component test setup</td>\n<td>Feature conflicts across components</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Flat structure (all files in src/)</td>\n<td>Simple but becomes unwieldy</td>\n<td>Difficult to isolate component tests</td>\n<td>High merge conflict probability</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p>The <strong>utils</strong> directory provides shared infrastructure components like <code>Buffer</code> management, <code>HashTable</code> implementation, and network utilities that multiple components require. These utilities are designed to be reusable and thoroughly tested since they form the building blocks for higher-level functionality.</p>\n<p>The <strong>tests</strong> directory structure mirrors the main source organization, providing unit tests for individual components and integration tests that verify cross-component interactions. The <strong>fixtures</strong> subdirectory contains test data, configuration files, and certificates needed for comprehensive testing scenarios.</p>\n<p>⚠️ <strong>Pitfall: Circular Dependencies Between Components</strong>\nA common architectural mistake is creating circular dependencies where Component A includes Component B&#39;s headers, and Component B includes Component A&#39;s headers. This often happens when the connection manager needs to call load balancer functions, and the load balancer needs to access connection manager state. The compiler cannot resolve these circular includes, leading to compilation errors and unclear component boundaries. To fix this, define clear interface boundaries using forward declarations in headers and only include necessary headers in implementation files. Use dependency inversion by having both components depend on abstract interfaces rather than concrete implementations.</p>\n<p>⚠️ <strong>Pitfall: Overly Complex Include Hierarchies</strong>\nWithout careful header organization, you might end up with headers that transitively include dozens of other headers, leading to long compilation times and unclear dependencies. For example, if <code>connection/manager.h</code> includes <code>loadbalancer/balancer.h</code>, which includes <code>cache/engine.h</code>, then every file using the connection manager gets all cache engine dependencies. Keep header files minimal by using forward declarations for pointer types and only including what&#39;s directly needed. Move complex includes to implementation (.c) files where they don&#39;t propagate to other compilation units.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Error Handling Across Components</strong>\nDifferent components might use different error reporting mechanisms - some returning error codes, others using errno, others logging errors directly. This inconsistency makes error handling unpredictable and debugging difficult. Establish consistent error handling patterns in the <code>common/errors.h</code> file and ensure all components use the same error reporting mechanisms. Define standard error codes and ensure every component function has clearly documented error conditions and return value semantics.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The reverse proxy implementation requires careful selection of technologies and development practices that support high-performance, concurrent network programming. The C programming language provides the fine-grained control over memory management and system resources necessary for building efficient network services, while requiring disciplined development practices to avoid common pitfalls.</p>\n<p><strong>A. Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Loop</td>\n<td><code>select()</code> or <code>poll()</code> system calls</td>\n<td><code>epoll</code> (Linux) or <code>kqueue</code> (BSD/macOS) for scalability</td>\n</tr>\n<tr>\n<td>TLS Implementation</td>\n<td>OpenSSL 1.1.1+ with basic configuration</td>\n<td>OpenSSL 3.0+ with advanced features and hardware acceleration</td>\n</tr>\n<tr>\n<td>HTTP/2 Support</td>\n<td>HTTP/1.1 only for initial implementation</td>\n<td>nghttp2 library for full HTTP/2 support</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>Standard <code>malloc()</code>/<code>free()</code> with careful tracking</td>\n<td>Memory pools or custom allocators for performance</td>\n</tr>\n<tr>\n<td>Configuration Format</td>\n<td>Simple key-value pairs in text files</td>\n<td>JSON or YAML with validation and schema support</td>\n</tr>\n<tr>\n<td>Logging System</td>\n<td><code>fprintf()</code> to log files with manual formatting</td>\n<td>Structured logging with log rotation and remote targets</td>\n</tr>\n</tbody></table>\n<p><strong>B. Development Environment Setup</strong></p>\n<p>For building the reverse proxy, establish a development environment that supports concurrent programming and network testing:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Required development tools and libraries</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> build-essential</span><span style=\"color:#9ECBFF\"> gcc</span><span style=\"color:#9ECBFF\"> libc6-dev</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> libssl-dev</span><span style=\"color:#6A737D\">         # OpenSSL for TLS support</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> libev-dev</span><span style=\"color:#6A737D\">          # libev for efficient event loops</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> valgrind</span><span style=\"color:#6A737D\">          # Memory leak detection</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> wireshark-dev</span><span style=\"color:#6A737D\">     # Network traffic analysis tools</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sudo</span><span style=\"color:#9ECBFF\"> apt-get</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> nginx</span><span style=\"color:#6A737D\">             # Reference implementation for testing</span></span></code></pre></div>\n\n<p><strong>C. Core Infrastructure Starter Code</strong></p>\n<p>The following infrastructure components provide tested foundations that support the main reverse proxy logic without requiring implementation from scratch:</p>\n<p><strong>Buffer Management System</strong> (<code>src/utils/buffer.h</code> and <code>src/utils/buffer.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stddef.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> data;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> capacity;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> length;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> position;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} Buffer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Create new buffer with specified initial capacity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> buffer_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> initial_capacity</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Append data to buffer, expanding capacity if needed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> buffer_append</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> data_len</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Read data from buffer starting at current position</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> buffer_read</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> dest</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> max_len</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Reset buffer position to beginning for reading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_rewind</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Ensure buffer has at least min_capacity space available</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> buffer_ensure_capacity</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> min_capacity</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free buffer and associated memory</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_destroy</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Check if buffer has data available for reading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> inline</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> buffer_has_data</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> buf->position </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> buf->length;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Get number of bytes available for reading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> inline</span><span style=\"color:#F97583\"> size_t</span><span style=\"color:#B392F0\"> buffer_available</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> buf->length </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> buf->position;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Hash Table Implementation</strong> (<code>src/utils/hashtable.h</code> and <code>src/utils/hashtable.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stddef.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> HashTable HashTable;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Create hash table with specified number of buckets</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> hashtable_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> bucket_count</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Insert key-value pair (takes ownership of key string)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> hashtable_put</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> value</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Retrieve value by key, returns NULL if not found</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> hashtable_get</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Remove entry by key, returns old value or NULL</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> hashtable_remove</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Check if key exists in table</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> hashtable_contains</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Get current number of entries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> hashtable_size</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free hash table and all keys (values are caller's responsibility)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> hashtable_destroy</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Iterator for walking all entries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> table;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> bucket_index;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void*</span><span style=\"color:#E1E4E8\"> current_entry;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HashTableIterator;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HashTableIterator </span><span style=\"color:#B392F0\">hashtable_iterator_create</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> hashtable_iterator_next</span><span style=\"color:#E1E4E8\">(HashTableIterator</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> iter</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char**</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void**</span><span style=\"color:#FFAB70\"> value</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Logging System</strong> (<code>src/core/logger.h</code> and <code>src/core/logger.c</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdarg.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_DEBUG </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_INFO </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_WARN </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_ERROR </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LogLevel;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize logging system with minimum level and output file</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> logger_init</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">min_level</span><span style=\"color:#E1E4E8\">, FILE</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> output_file</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Log formatted message with specified level, source file, and line</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_log</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> source_file</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> line</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> format</span><span style=\"color:#E1E4E8\">, ...);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Convenience macros that automatically include file and line information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_DEBUG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">fmt</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_DEBUG, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, fmt, ##</span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_INFO</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">fmt</span><span style=\"color:#E1E4E8\">, ...)  </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_INFO, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, fmt, ##</span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_WARN</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">fmt</span><span style=\"color:#E1E4E8\">, ...)  </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_WARN, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, fmt, ##</span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_ERROR</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">fmt</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_ERROR, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, fmt, ##</span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Clean up logging system resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_shutdown</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Change log level at runtime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_set_level</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">new_level</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>D. Core Proxy Structure Skeleton</strong></p>\n<p>The main proxy server structure provides the foundation for component integration:</p>\n<p><strong>Main Proxy Server</strong> (<code>src/core/proxy.h</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"config.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../http/parser.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../connection/manager.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../loadbalancer/balancer.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../cache/engine.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../ssl/termination.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> config;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> conn_manager;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> load_balancer;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheEngine</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cache_engine;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> ssl_context;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> listen_fd;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> worker_thread_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t*</span><span style=\"color:#E1E4E8\"> worker_threads;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyServer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize proxy server with configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> proxy_server_create</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Start proxy server and begin accepting connections</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> proxy_server_start</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Main event loop processing connections and requests  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> proxy_server_run</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 1: Create epoll/kqueue event loop for handling I/O events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 2: Accept new client connections and add to connection manager</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 3: Process readable connections by parsing HTTP requests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 4: Route requests through load balancer to select backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 5: Check cache for existing responses before forwarding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 6: Forward cache misses to selected backend servers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 7: Process backend responses and update cache if appropriate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 8: Send responses back to clients and manage connection state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 9: Handle connection timeouts and cleanup closed connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 10: Gracefully handle shutdown signals and resource cleanup</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Stop proxy server and clean up resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> proxy_server_stop</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free proxy server and all associated resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> proxy_server_destroy</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Configuration Management</strong> (<code>src/core/config.h</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stddef.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"logger.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_LEAST_CONNECTIONS, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_WEIGHTED_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_IP_HASH</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LoadBalancingAlgorithm;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> address</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> weight;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> enabled;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} BackendServer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> listen_address</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> listen_port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> worker_threads;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> ssl_enabled;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> ssl_cert_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> ssl_key_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> ssl_ca_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> ssl_min_version;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> backend_count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer </span><span style=\"color:#FFAB70\">backends</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LoadBalancingAlgorithm lb_algorithm;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> cache_enabled;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> cache_max_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> cache_default_ttl;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> cache_exclude_patterns</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> pool_max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> pool_idle_timeout;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> pool_connect_timeout;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LogLevel log_level;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> log_file_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> log_requests;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyConfig;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Load configuration from file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> config_load</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> config_file_path</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 1: Open and parse configuration file line by line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 2: Parse listen address and port settings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 3: Parse SSL certificate paths and TLS configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 4: Parse backend server list with addresses, ports, and weights</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 5: Parse load balancing algorithm selection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 6: Parse cache settings and exclusion patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 7: Parse connection pool configuration parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 8: Parse logging configuration and validate log file paths</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 9: Validate all configuration values for consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// TODO 10: Return populated ProxyConfig structure or NULL on error</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Validate configuration for consistency and required values</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> config_validate</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free configuration structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> config_destroy</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Implementation Hints</strong></p>\n<p><strong>Socket Programming Best Practices:</strong></p>\n<ul>\n<li>Use <code>SO_REUSEADDR</code> socket option to allow rapid server restarts: <code>setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &amp;opt, sizeof(opt))</code></li>\n<li>Set sockets to non-blocking mode with <code>fcntl(fd, F_SETFL, O_NONBLOCK)</code> for event-driven I/O</li>\n<li>Handle <code>EAGAIN</code> and <code>EWOULDBLOCK</code> errors gracefully in non-blocking operations</li>\n<li>Use <code>TCP_NODELAY</code> to disable Nagle&#39;s algorithm for low-latency forwarding</li>\n</ul>\n<p><strong>Memory Management Strategies:</strong></p>\n<ul>\n<li>Always pair <code>malloc()</code> calls with corresponding <code>free()</code> calls to prevent memory leaks</li>\n<li>Set pointers to <code>NULL</code> after freeing to avoid double-free errors</li>\n<li>Use <code>valgrind</code> during development to detect memory leaks and buffer overflows</li>\n<li>Consider object pools for frequently allocated/deallocated structures like HTTP requests</li>\n</ul>\n<p><strong>Error Handling Patterns:</strong></p>\n<ul>\n<li>Check return values of all system calls and library functions</li>\n<li>Use consistent error codes throughout the application</li>\n<li>Log error conditions with sufficient context for debugging</li>\n<li>Implement graceful degradation when non-critical operations fail</li>\n</ul>\n<p><strong>F. Milestone Checkpoints</strong></p>\n<p><strong>Milestone 1 Checkpoint - HTTP Proxy Core:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Compile and test basic proxy functionality</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> clean</span><span style=\"color:#E1E4E8\"> &#x26;&#x26; </span><span style=\"color:#B392F0\">make</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./proxy</span><span style=\"color:#79B8FF\"> --config=config/test.conf</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test basic request forwarding with curl</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#9ECBFF\"> \"X-Test: milestone1\"</span><span style=\"color:#9ECBFF\"> http://localhost:8080/test</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Response from backend server with X-Forwarded-For header added</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Proxy logs showing request parsing and forwarding</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify error handling</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> http://localhost:8080/nonexistent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Appropriate HTTP error response when backend is unavailable</span></span></code></pre></div>\n\n<p><strong>Architecture Validation Checkpoint:</strong></p>\n<ul>\n<li>Verify each component can be compiled independently without circular dependencies</li>\n<li>Test component interfaces by creating mock implementations</li>\n<li>Run static analysis tools to detect potential issues early</li>\n<li>Validate configuration loading and parsing with various input files</li>\n</ul>\n<p><strong>G. Performance Monitoring Setup</strong></p>\n<p>Establish performance monitoring from the beginning of development to track system behavior under load:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Performance metrics structure for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> requests_processed;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> requests_cached;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> backend_failures;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> ssl_handshakes;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    double</span><span style=\"color:#E1E4E8\"> avg_response_time_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> active_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> backend_connections;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyMetrics;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Expose metrics through HTTP endpoint for monitoring tools</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> metrics_update_request_processed</span><span style=\"color:#E1E4E8\">(ProxyMetrics</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> metrics</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> metrics_update_response_time</span><span style=\"color:#E1E4E8\">(ProxyMetrics</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> metrics</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">double</span><span style=\"color:#FFAB70\"> response_time_ms</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> metrics_export_json</span><span style=\"color:#E1E4E8\">(ProxyMetrics</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> metrics</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> buffer_size</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p>The architectural foundation established here provides a robust platform for implementing each milestone component. The clear separation of concerns, well-defined interfaces, and comprehensive infrastructure support rapid development while maintaining code quality and system reliability. As you progress through each milestone, this architectural framework will guide implementation decisions and ensure component integration proceeds smoothly.</p>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - the data structures defined here form the foundation for HTTP proxy core, load balancing, connection pooling, caching, and SSL termination components.</p>\n</blockquote>\n<p>Think of the data model as the blueprint of a complex building - it defines all the rooms, their purposes, and how they connect to each other. In a reverse proxy, these &quot;rooms&quot; are the data structures that represent HTTP messages, network connections, configuration settings, and runtime state. Just as a building&#39;s blueprint must account for electrical wiring, plumbing, and structural supports, our data model must carefully design structures that support concurrent access, memory efficiency, and protocol compliance.</p>\n<p>The data model serves as the contract between all components in the reverse proxy. When the HTTP parser creates an <code>HttpRequest</code> structure, it must contain all the information the load balancer needs to make routing decisions. When the cache engine stores responses, it must preserve all the metadata the connection manager needs to send data back to clients. This careful orchestration of data structures enables loose coupling between components while maintaining system coherence.</p>\n<h3 id=\"core-data-types\">Core Data Types</h3>\n<p>The core data types form the foundation of HTTP message processing and connection management. These structures must handle the complexities of the HTTP protocol while providing efficient access patterns for high-performance request processing.</p>\n<h4 id=\"buffer-management\">Buffer Management</h4>\n<p>Think of a <code>Buffer</code> as a smart container that grows and shrinks as needed, like a shopping bag that expands when you add items but keeps track of how much space is left. In network programming, data arrives in chunks of unpredictable sizes, and the buffer must efficiently accumulate these pieces while providing fast access to the complete message.</p>\n<p>The <code>Buffer</code> structure provides the foundation for all data handling in the reverse proxy:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>data</td>\n<td>char*</td>\n<td>Pointer to the allocated memory region storing actual data bytes</td>\n</tr>\n<tr>\n<td>capacity</td>\n<td>size_t</td>\n<td>Total allocated memory size in bytes, representing maximum storage before reallocation</td>\n</tr>\n<tr>\n<td>length</td>\n<td>size_t</td>\n<td>Current number of valid data bytes stored in the buffer</td>\n</tr>\n<tr>\n<td>position</td>\n<td>size_t</td>\n<td>Current read/write position within the buffer for streaming operations</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Dynamic Buffer Growth Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Network data arrives in variable-sized chunks, and HTTP messages can range from tiny (200 bytes) to massive (multi-gigabyte uploads)</li>\n<li><strong>Options Considered</strong>: Fixed-size buffers, exponential growth, linear growth</li>\n<li><strong>Decision</strong>: Exponential growth with configurable initial size and maximum capacity</li>\n<li><strong>Rationale</strong>: Exponential growth minimizes reallocation overhead for typical HTTP message sizes while preventing unbounded memory consumption through maximum limits</li>\n<li><strong>Consequences</strong>: Reduces memory copy operations for growing messages but may over-allocate for small messages; requires careful tuning of growth parameters</li>\n</ul>\n</blockquote>\n<p>The buffer implements a position-based streaming interface that enables efficient parsing without copying data. When the HTTP parser reads a request line, it advances the position pointer rather than extracting substrings. This zero-copy approach significantly improves performance for large messages.</p>\n<h4 id=\"http-message-structures\">HTTP Message Structures</h4>\n<p>HTTP messages in a reverse proxy must preserve all protocol semantics while providing efficient access to routing-relevant information. The <code>HttpRequest</code> structure captures the complete client request state:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>method</td>\n<td>char[16]</td>\n<td>HTTP method (GET, POST, PUT, DELETE, etc.) as null-terminated string</td>\n</tr>\n<tr>\n<td>uri</td>\n<td>char[2048]</td>\n<td>Complete request URI including path and query string</td>\n</tr>\n<tr>\n<td>version</td>\n<td>char[16]</td>\n<td>HTTP version string (HTTP/1.1, HTTP/2.0) for protocol compliance</td>\n</tr>\n<tr>\n<td>headers</td>\n<td>HashTable*</td>\n<td>Hash table mapping header names to values for O(1) lookup</td>\n</tr>\n<tr>\n<td>body</td>\n<td>Buffer*</td>\n<td>Request body data for POST/PUT requests, may be NULL for GET</td>\n</tr>\n<tr>\n<td>content_length</td>\n<td>size_t</td>\n<td>Size of request body in bytes, -1 if chunked transfer encoding</td>\n</tr>\n<tr>\n<td>keep_alive</td>\n<td>bool</td>\n<td>Whether connection should remain open after response</td>\n</tr>\n<tr>\n<td>host</td>\n<td>char[256]</td>\n<td>Host header value extracted for routing decisions</td>\n</tr>\n<tr>\n<td>connection_id</td>\n<td>uint64_t</td>\n<td>Unique identifier linking request to client connection</td>\n</tr>\n<tr>\n<td>timestamp</td>\n<td>time_t</td>\n<td>Request arrival time for timeout calculations</td>\n</tr>\n<tr>\n<td>client_ip</td>\n<td>char[46]</td>\n<td>Client IP address for logging and forwarding headers</td>\n</tr>\n</tbody></table>\n<p>The <code>HttpResponse</code> structure mirrors the request format while adding caching metadata:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>status_code</td>\n<td>int</td>\n<td>HTTP status code (200, 404, 500, etc.)</td>\n</tr>\n<tr>\n<td>status_text</td>\n<td>char[128]</td>\n<td>Human-readable status description</td>\n</tr>\n<tr>\n<td>headers</td>\n<td>HashTable*</td>\n<td>Response headers including Content-Type, Cache-Control</td>\n</tr>\n<tr>\n<td>body</td>\n<td>Buffer*</td>\n<td>Response body data to send to client</td>\n</tr>\n<tr>\n<td>content_length</td>\n<td>size_t</td>\n<td>Response body size, may differ from buffer length if compressed</td>\n</tr>\n<tr>\n<td>cache_control</td>\n<td>char[256]</td>\n<td>Cache-Control header value for cache engine decisions</td>\n</tr>\n<tr>\n<td>etag</td>\n<td>char[128]</td>\n<td>ETag header for conditional request validation</td>\n</tr>\n<tr>\n<td>last_modified</td>\n<td>time_t</td>\n<td>Last-Modified timestamp for cache validation</td>\n</tr>\n<tr>\n<td>expires</td>\n<td>time_t</td>\n<td>Response expiration time calculated from cache headers</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Embedded vs. Referenced Header Storage</strong></p>\n<ul>\n<li><strong>Context</strong>: HTTP headers can be numerous (10-50 per message) and variable in size, accessed frequently during processing</li>\n<li><strong>Options Considered</strong>: Embedded fixed arrays, hash table references, linked lists</li>\n<li><strong>Decision</strong>: Hash table references with case-insensitive string keys</li>\n<li><strong>Rationale</strong>: Hash tables provide O(1) header lookup which is critical for processing performance, case-insensitive keys handle HTTP&#39;s case-insensitive header semantics</li>\n<li><strong>Consequences</strong>: Additional memory allocation overhead but significantly faster header access; enables efficient header manipulation and forwarding</li>\n</ul>\n</blockquote>\n<h4 id=\"connection-state-management\">Connection State Management</h4>\n<p>Network connections in a reverse proxy exist in multiple states as they process requests and maintain persistent connections. The connection state machine drives the event loop and determines valid state transitions:</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>IDLE</td>\n<td>Data Available</td>\n<td>READING_REQUEST</td>\n<td>Begin HTTP parsing, start request timeout</td>\n</tr>\n<tr>\n<td>READING_REQUEST</td>\n<td>Complete Request</td>\n<td>FORWARDING</td>\n<td>Select backend, establish upstream connection</td>\n</tr>\n<tr>\n<td>FORWARDING</td>\n<td>Upstream Connected</td>\n<td>READING_RESPONSE</td>\n<td>Send request to backend, start response timeout</td>\n</tr>\n<tr>\n<td>READING_RESPONSE</td>\n<td>Response Complete</td>\n<td>WRITING_RESPONSE</td>\n<td>Begin sending response to client</td>\n</tr>\n<tr>\n<td>WRITING_RESPONSE</td>\n<td>Write Complete</td>\n<td>IDLE or CLOSING</td>\n<td>Return to IDLE if keep-alive, otherwise CLOSING</td>\n</tr>\n<tr>\n<td>Any State</td>\n<td>Error or Timeout</td>\n<td>CLOSING</td>\n<td>Clean up resources, close connections</td>\n</tr>\n</tbody></table>\n<p>The <code>Connection</code> structure maintains all state required for connection lifecycle management:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>client_fd</td>\n<td>int</td>\n<td>File descriptor for client socket connection</td>\n</tr>\n<tr>\n<td>backend_fd</td>\n<td>int</td>\n<td>File descriptor for upstream backend connection, -1 if not connected</td>\n</tr>\n<tr>\n<td>state</td>\n<td>ConnectionState</td>\n<td>Current connection state for event loop processing</td>\n</tr>\n<tr>\n<td>request_buffer</td>\n<td>Buffer*</td>\n<td>Accumulates incoming request data during parsing</td>\n</tr>\n<tr>\n<td>response_buffer</td>\n<td>Buffer*</td>\n<td>Buffers outgoing response data for client transmission</td>\n</tr>\n<tr>\n<td>backend_id</td>\n<td>int</td>\n<td>Index of selected backend server for this request</td>\n</tr>\n<tr>\n<td>created_time</td>\n<td>time_t</td>\n<td>Connection establishment timestamp</td>\n</tr>\n<tr>\n<td>last_activity</td>\n<td>time_t</td>\n<td>Most recent I/O activity for idle timeout detection</td>\n</tr>\n<tr>\n<td>bytes_sent</td>\n<td>uint64_t</td>\n<td>Total bytes transmitted to client for metrics</td>\n</tr>\n<tr>\n<td>bytes_received</td>\n<td>uint64_t</td>\n<td>Total bytes received from client for metrics</td>\n</tr>\n<tr>\n<td>ssl_context</td>\n<td>void*</td>\n<td>OpenSSL context pointer for HTTPS connections, NULL for HTTP</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-metrics-and-monitoring\">Performance Metrics and Monitoring</h4>\n<p>The <code>ProxyMetrics</code> structure aggregates runtime performance data for monitoring and capacity planning:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>requests_processed</td>\n<td>uint64_t</td>\n<td>Total number of requests handled since startup</td>\n</tr>\n<tr>\n<td>requests_cached</td>\n<td>uint64_t</td>\n<td>Number of requests served from cache</td>\n</tr>\n<tr>\n<td>bytes_transferred</td>\n<td>uint64_t</td>\n<td>Total data transferred in both directions</td>\n</tr>\n<tr>\n<td>active_connections</td>\n<td>uint32_t</td>\n<td>Current number of client connections</td>\n</tr>\n<tr>\n<td>backend_failures</td>\n<td>uint64_t</td>\n<td>Count of backend server error responses</td>\n</tr>\n<tr>\n<td>average_response_time</td>\n<td>double</td>\n<td>Rolling average response time in milliseconds</td>\n</tr>\n<tr>\n<td>peak_connections</td>\n<td>uint32_t</td>\n<td>Maximum concurrent connections observed</td>\n</tr>\n<tr>\n<td>uptime_seconds</td>\n<td>uint64_t</td>\n<td>Server uptime for availability calculations</td>\n</tr>\n</tbody></table>\n<h3 id=\"configuration-model\">Configuration Model</h3>\n<p>Configuration management in a reverse proxy requires balancing flexibility with performance. The configuration model must support runtime updates for operational requirements while maintaining type safety and validation.</p>\n<h4 id=\"primary-configuration-structure\">Primary Configuration Structure</h4>\n<p>Think of <code>ProxyConfig</code> as the master control panel for the entire reverse proxy - every knob, switch, and setting that operators need to tune the system&#39;s behavior. Like a car&#39;s dashboard that groups related controls (engine, climate, entertainment), the configuration structure organizes settings by functional area while maintaining a single authoritative source.</p>\n<p>The <code>ProxyConfig</code> structure serves as the single source of truth for all proxy behavior:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>listen_address</td>\n<td>char[256]</td>\n<td>IP address to bind for incoming connections, &quot;0.0.0.0&quot; for all interfaces</td>\n</tr>\n<tr>\n<td>listen_port</td>\n<td>int</td>\n<td>TCP port number for client connections, typically 80 or 443</td>\n</tr>\n<tr>\n<td>max_connections</td>\n<td>int</td>\n<td>Maximum concurrent client connections before rejecting new requests</td>\n</tr>\n<tr>\n<td>worker_threads</td>\n<td>int</td>\n<td>Number of event loop threads for connection processing</td>\n</tr>\n<tr>\n<td>ssl_enabled</td>\n<td>bool</td>\n<td>Whether to enable HTTPS/TLS termination</td>\n</tr>\n<tr>\n<td>ssl_cert_path</td>\n<td>char[512]</td>\n<td>File system path to SSL certificate in PEM format</td>\n</tr>\n<tr>\n<td>ssl_key_path</td>\n<td>char[512]</td>\n<td>File system path to SSL private key file</td>\n</tr>\n<tr>\n<td>ssl_ca_path</td>\n<td>char[512]</td>\n<td>Path to certificate authority bundle for client certificate validation</td>\n</tr>\n<tr>\n<td>ssl_min_version</td>\n<td>int</td>\n<td>Minimum TLS version (1.2, 1.3) for security compliance</td>\n</tr>\n<tr>\n<td>backend_count</td>\n<td>int</td>\n<td>Number of configured backend servers in the cluster</td>\n</tr>\n<tr>\n<td>backends</td>\n<td>BackendServer[32]</td>\n<td>Array of backend server configurations</td>\n</tr>\n<tr>\n<td>lb_algorithm</td>\n<td>LoadBalancingAlgorithm</td>\n<td>Algorithm for distributing requests across backends</td>\n</tr>\n<tr>\n<td>cache_enabled</td>\n<td>bool</td>\n<td>Whether to enable HTTP response caching</td>\n</tr>\n<tr>\n<td>cache_max_size</td>\n<td>size_t</td>\n<td>Maximum cache memory usage in bytes</td>\n</tr>\n<tr>\n<td>cache_default_ttl</td>\n<td>int</td>\n<td>Default cache entry lifetime in seconds</td>\n</tr>\n<tr>\n<td>cache_exclude_patterns</td>\n<td>char[1024]</td>\n<td>Regex patterns for URLs to exclude from caching</td>\n</tr>\n<tr>\n<td>pool_max_connections</td>\n<td>int</td>\n<td>Maximum connections per backend server pool</td>\n</tr>\n<tr>\n<td>pool_idle_timeout</td>\n<td>int</td>\n<td>Seconds to keep idle backend connections alive</td>\n</tr>\n<tr>\n<td>pool_connect_timeout</td>\n<td>int</td>\n<td>Timeout for establishing new backend connections</td>\n</tr>\n<tr>\n<td>log_level</td>\n<td>LogLevel</td>\n<td>Minimum severity level for log message output</td>\n</tr>\n<tr>\n<td>log_file_path</td>\n<td>char[512]</td>\n<td>File system path for log output, stdout if empty</td>\n</tr>\n<tr>\n<td>log_requests</td>\n<td>bool</td>\n<td>Whether to log every HTTP request for auditing</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Static vs. Dynamic Backend Configuration</strong></p>\n<ul>\n<li><strong>Context</strong>: Backend servers may be added, removed, or reconfigured during proxy operation for scaling and maintenance</li>\n<li><strong>Options Considered</strong>: Static array requiring restart, dynamic linked list, configuration file reload</li>\n<li><strong>Decision</strong>: Static array with configuration file reload mechanism</li>\n<li><strong>Rationale</strong>: Static arrays provide predictable memory usage and cache-friendly access patterns; reload mechanism enables updates without losing connection state</li>\n<li><strong>Consequences</strong>: Limits maximum backend count but provides better performance; requires reload coordination to avoid inconsistent state</li>\n</ul>\n</blockquote>\n<h4 id=\"backend-server-configuration\">Backend Server Configuration</h4>\n<p>Each backend server requires comprehensive configuration to support health checking, load balancing, and connection management. The <code>BackendServer</code> structure encapsulates all backend-specific settings:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>hostname</td>\n<td>char[256]</td>\n<td>Backend server hostname or IP address for connection establishment</td>\n</tr>\n<tr>\n<td>port</td>\n<td>int</td>\n<td>TCP port number for backend service, typically 80 or 8080</td>\n</tr>\n<tr>\n<td>weight</td>\n<td>int</td>\n<td>Relative weight for weighted load balancing algorithms (1-100)</td>\n</tr>\n<tr>\n<td>max_connections</td>\n<td>int</td>\n<td>Maximum concurrent connections to this specific backend</td>\n</tr>\n<tr>\n<td>health_check_url</td>\n<td>char[512]</td>\n<td>HTTP endpoint for health check requests (e.g., &quot;/health&quot;)</td>\n</tr>\n<tr>\n<td>health_check_interval</td>\n<td>int</td>\n<td>Seconds between health check probes</td>\n</tr>\n<tr>\n<td>health_check_timeout</td>\n<td>int</td>\n<td>Timeout for health check request completion</td>\n</tr>\n<tr>\n<td>failure_threshold</td>\n<td>int</td>\n<td>Consecutive failures before marking backend unhealthy</td>\n</tr>\n<tr>\n<td>recovery_threshold</td>\n<td>int</td>\n<td>Consecutive successes required to mark backend healthy again</td>\n</tr>\n<tr>\n<td>is_healthy</td>\n<td>bool</td>\n<td>Current health status for load balancing decisions</td>\n</tr>\n<tr>\n<td>last_health_check</td>\n<td>time_t</td>\n<td>Timestamp of most recent health check attempt</td>\n</tr>\n<tr>\n<td>total_requests</td>\n<td>uint64_t</td>\n<td>Lifetime request count for load balancing statistics</td>\n</tr>\n<tr>\n<td>failed_requests</td>\n<td>uint64_t</td>\n<td>Count of requests that resulted in errors</td>\n</tr>\n<tr>\n<td>average_response_time</td>\n<td>double</td>\n<td>Rolling average response time for performance-based routing</td>\n</tr>\n<tr>\n<td>ssl_required</td>\n<td>bool</td>\n<td>Whether backend connections must use HTTPS</td>\n</tr>\n<tr>\n<td>ssl_verify</td>\n<td>bool</td>\n<td>Whether to validate backend SSL certificates</td>\n</tr>\n</tbody></table>\n<p>The backend configuration enables sophisticated load balancing algorithms that consider server capacity, health status, and historical performance. Weight-based distribution allows operators to account for heterogeneous backend hardware, while health checking ensures requests avoid failed servers.</p>\n<h4 id=\"load-balancing-algorithm-configuration\">Load Balancing Algorithm Configuration</h4>\n<p>The <code>LoadBalancingAlgorithm</code> enumeration defines the available request distribution strategies:</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Description</th>\n<th>Use Case</th>\n<th>Considerations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ROUND_ROBIN</td>\n<td>Distributes requests sequentially across healthy backends</td>\n<td>Equal backend capacity</td>\n<td>Simple but ignores server load</td>\n</tr>\n<tr>\n<td>LEAST_CONNECTIONS</td>\n<td>Routes to backend with fewest active connections</td>\n<td>Variable request processing time</td>\n<td>Requires connection count tracking</td>\n</tr>\n<tr>\n<td>WEIGHTED_ROUND_ROBIN</td>\n<td>Distributes based on configured backend weights</td>\n<td>Mixed backend capacity</td>\n<td>Weights must reflect actual performance</td>\n</tr>\n<tr>\n<td>IP_HASH</td>\n<td>Consistent routing based on client IP hash</td>\n<td>Session affinity requirements</td>\n<td>May cause uneven distribution</td>\n</tr>\n<tr>\n<td>RANDOM</td>\n<td>Random selection among healthy backends</td>\n<td>Simple load distribution</td>\n<td>No performance optimization</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Algorithm Selection Criteria</strong></p>\n<ul>\n<li><strong>Context</strong>: Different applications have varying requirements for load distribution and session handling</li>\n<li><strong>Options Considered</strong>: Single algorithm, runtime selection, automatic algorithm selection</li>\n<li><strong>Decision</strong>: Runtime selection with configuration override capability</li>\n<li><strong>Rationale</strong>: Different traffic patterns benefit from different algorithms; operators need flexibility to optimize for their specific workload characteristics</li>\n<li><strong>Consequences</strong>: Increases configuration complexity but enables performance tuning; requires implementation of multiple algorithm variants</li>\n</ul>\n</blockquote>\n<h4 id=\"cache-configuration-model\">Cache Configuration Model</h4>\n<p>Response caching requires careful configuration to balance performance gains with memory usage and cache coherence. The cache configuration integrates with HTTP semantics to provide correct caching behavior:</p>\n<table>\n<thead>\n<tr>\n<th>Configuration Aspect</th>\n<th>Implementation</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache Key Generation</td>\n<td>URL + Host + Vary headers</td>\n<td>Ensures correct cache isolation per content variant</td>\n</tr>\n<tr>\n<td>Size Management</td>\n<td>LRU eviction with memory limits</td>\n<td>Provides predictable memory usage with automatic cleanup</td>\n</tr>\n<tr>\n<td>TTL Calculation</td>\n<td>Min(Cache-Control max-age, configured default)</td>\n<td>Respects HTTP semantics while providing fallback values</td>\n</tr>\n<tr>\n<td>Invalidation Strategy</td>\n<td>Time-based expiry + manual purge</td>\n<td>Supports both automatic and operational cache management</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Cache Key Collisions</strong>\nMany implementations generate cache keys using only the request URL, which causes incorrect cache hits when the same URL serves different content based on request headers like Accept-Encoding or Accept-Language. The cache key must include all headers listed in the response&#39;s Vary header to ensure cache correctness.</p>\n<h4 id=\"logging-and-monitoring-configuration\">Logging and Monitoring Configuration</h4>\n<p>The logging subsystem provides operational visibility into proxy behavior and performance. The <code>LogLevel</code> enumeration controls message verbosity:</p>\n<table>\n<thead>\n<tr>\n<th>Log Level</th>\n<th>Purpose</th>\n<th>Example Messages</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>DEBUG</td>\n<td>Detailed internal state</td>\n<td>Connection state transitions, header parsing details</td>\n</tr>\n<tr>\n<td>INFO</td>\n<td>Normal operational events</td>\n<td>Request processing, backend selection, cache hits</td>\n</tr>\n<tr>\n<td>WARN</td>\n<td>Concerning but recoverable conditions</td>\n<td>Backend failures, retry attempts, cache evictions</td>\n</tr>\n<tr>\n<td>ERROR</td>\n<td>Serious problems requiring attention</td>\n<td>Configuration errors, resource exhaustion, SSL failures</td>\n</tr>\n</tbody></table>\n<p>Request logging captures complete HTTP transaction details for security auditing and traffic analysis. The log format includes client IP, timestamp, request line, response status, processing time, and backend server selection.</p>\n<h3 id=\"common-data-model-pitfalls\">Common Data Model Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Insufficient Buffer Bounds Checking</strong>\nMany implementations allocate fixed-size buffers for HTTP headers and URIs but fail to validate input lengths, leading to buffer overflows. Every buffer operation must check available capacity and handle overflow conditions gracefully, either by rejecting oversized requests or dynamically resizing buffers.</p>\n<p>⚠️ <strong>Pitfall: Memory Leaks in Error Paths</strong>\nComplex data structures like <code>HttpRequest</code> and <code>HttpResponse</code> contain multiple heap-allocated components (buffers, hash tables). Error handling during parsing or processing often forgets to deallocate partially constructed objects, causing memory leaks under failure conditions. Every allocation must have a corresponding cleanup path.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Shared State</strong>\nConfiguration updates and metrics collection occur concurrently with request processing, but many implementations access shared data structures without proper synchronization. The configuration reload process must use atomic updates or reader-writer locks to prevent corruption of active request processing.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent String Handling</strong>\nHTTP protocols require case-insensitive header name comparisons but case-sensitive value handling. Implementations often apply inconsistent string comparison functions, causing header lookup failures or incorrect cache key generation. All header name operations must use case-insensitive comparison while preserving original case for forwarding.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The data model implementation requires careful attention to memory management, thread safety, and performance optimization. The following guidance provides concrete implementation strategies for the core data structures.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash Tables</td>\n<td>Linear probing with string keys</td>\n<td>Robin Hood hashing with SipHash</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>malloc/free with explicit cleanup</td>\n<td>Memory pools with arena allocation</td>\n</tr>\n<tr>\n<td>String Handling</td>\n<td>strdup/strcasecmp with manual bounds</td>\n<td>Interned strings with length prefixes</td>\n</tr>\n<tr>\n<td>Configuration Parsing</td>\n<td>Simple key-value parser</td>\n<td>Full YAML/JSON parser with validation</td>\n</tr>\n<tr>\n<td>Buffer Management</td>\n<td>Exponential growth with realloc</td>\n<td>Ring buffers with memory mapping</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/\n  data/\n    buffer.h              ← Buffer structure and operations\n    buffer.c\n    http_message.h        ← HTTP request/response structures  \n    http_message.c\n    connection.h          ← Connection state management\n    connection.c\n    config.h              ← Configuration structures and loading\n    config.c\n    metrics.h             ← Performance monitoring structures\n    metrics.c\n  utils/\n    hashtable.h           ← Hash table implementation\n    hashtable.c\n    logger.h              ← Logging infrastructure\n    logger.c\n  tests/\n    test_buffer.c         ← Unit tests for data structures\n    test_http_message.c\n    test_config.c</code></pre></div>\n\n<h4 id=\"buffer-implementation\">Buffer Implementation</h4>\n<p>The buffer provides the foundation for all data handling operations. This implementation handles dynamic growth and streaming operations:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> data;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> capacity;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> length;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> position;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} Buffer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Buffer management functions - complete implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> buffer_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> initial_capacity</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate Buffer structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Allocate initial data array with initial_capacity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Initialize capacity, set length and position to 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return NULL if any allocation fails</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> buffer_append</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> data_len</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check if current capacity can hold additional data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If insufficient, calculate new capacity (double until fits)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Reallocate data array with new capacity using realloc</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Copy new data to end of existing content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update length to reflect new data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Always null-terminate for string operations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> buffer_read</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> dest</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> max_len</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Calculate available data from position to length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Determine actual read size (min of available and max_len)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Copy data from buffer starting at position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Advance position by amount read</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Return actual bytes read</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_reset</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Reset length and position to 0, keep allocated memory</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> buffer_destroy</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Free data array if not NULL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Free Buffer structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle NULL buffer parameter gracefully</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"hash-table-infrastructure\">Hash Table Infrastructure</h4>\n<p>HTTP header management requires efficient string-based lookups with case-insensitive keys:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdint.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> HASHTABLE_INITIAL_SIZE</span><span style=\"color:#79B8FF\"> 16</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> HASHTABLE_LOAD_FACTOR</span><span style=\"color:#79B8FF\"> 0.75</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> HashEntry {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> key;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void*</span><span style=\"color:#E1E4E8\"> value;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> HashEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> next;</span><span style=\"color:#6A737D\">  // Chain for collision resolution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HashEntry;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashEntry</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\"> buckets;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HashTable;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> hashtable_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> initial_size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate HashTable structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Allocate array of bucket pointers, initialize to NULL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Set size and count fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return hashtable or NULL on failure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#B392F0\"> hash_string_case_insensitive</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> str</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Implement djb2 hash algorithm</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Convert each character to lowercase before hashing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return hash value for bucket selection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use tolower() for consistent case handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> hashtable_put</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> value</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check if resize needed (count/size > LOAD_FACTOR)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Calculate bucket index using hash_string_case_insensitive</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Search existing chain for key (case-insensitive comparison)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Update existing entry or create new entry in chain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Increment count if new entry added</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strcasecmp for case-insensitive key comparison</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> hashtable_get</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> table</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Calculate bucket index using hash function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Walk chain comparing keys with strcasecmp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Return value if found, NULL otherwise</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"http-message-structures\">HTTP Message Structures</h4>\n<p>Complete HTTP request and response handling with proper resource management:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"buffer.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"hashtable.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> method</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> uri</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">2048</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> version</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> headers;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> body;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> content_length;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> keep_alive;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> host</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> connection_id;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> timestamp;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> client_ip</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">46</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">  // IPv6-compatible</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HttpRequest;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> status_code;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> status_text</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">128</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> headers;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> body;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> content_length;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> cache_control</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> etag</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">128</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_modified;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> expires;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HttpResponse;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> http_request_create</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate HttpRequest structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Initialize all string fields to empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Create headers hash table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set timestamp to current time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Initialize numeric fields to sensible defaults</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> http_request_destroy</span><span style=\"color:#E1E4E8\">(HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Destroy headers hash table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Destroy body buffer if not NULL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Free request structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle NULL parameter gracefully</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> http_request_add_header</span><span style=\"color:#E1E4E8\">(HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> name</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> value</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Validate name and value parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create copies of name and value strings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Add to headers hash table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Handle special headers (Host, Content-Length, Connection)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Extract host for routing, parse content-length, detect keep-alive</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#B392F0\"> http_request_get_header</span><span style=\"color:#E1E4E8\">(HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> name</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Use hashtable_get with case-insensitive lookup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"configuration-management\">Configuration Management</h4>\n<p>Configuration loading and validation with comprehensive error handling:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LEAST_CONNECTIONS,  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WEIGHTED_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    IP_HASH,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RANDOM</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LoadBalancingAlgorithm;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    DEBUG,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    INFO,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    WARN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ERROR</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LogLevel;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> hostname</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> weight;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> health_check_url</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> health_check_interval;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> health_check_timeout;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> failure_threshold;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> recovery_threshold;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> is_healthy;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_health_check;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> total_requests;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> failed_requests;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    double</span><span style=\"color:#E1E4E8\"> average_response_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> ssl_required;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> ssl_verify;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} BackendServer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> config_load</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> config_file</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Open configuration file for reading</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Parse key-value pairs line by line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Populate ProxyConfig structure fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Parse backend server sections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate all configuration values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Return NULL if any validation fails</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use simple \"key=value\" format for easier parsing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> config_validate</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check required fields are not empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Validate port numbers are in valid range (1-65535)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Verify SSL certificate files exist if SSL enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Check at least one backend server is configured</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate backend server configurations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Ensure resource limits are reasonable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use access() to check file existence</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After Data Structures Implementation:</strong></p>\n<ol>\n<li>Run <code>gcc -Wall -Wextra -std=c99 -o test_data tests/test_buffer.c src/data/buffer.c</code></li>\n<li>Execute <code>./test_data</code> - should show all buffer operations working correctly</li>\n<li>Test hash table operations: put/get with case-insensitive keys</li>\n<li>Verify HTTP message creation and header manipulation</li>\n<li>Load sample configuration file and verify all fields populated</li>\n</ol>\n<p><strong>Expected Output:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Buffer tests: PASSED\nHash table tests: PASSED  \nHTTP message tests: PASSED\nConfiguration loading: PASSED\nAll data structure tests completed successfully</code></pre></div>\n\n<p><strong>Signs of Problems:</strong></p>\n<ul>\n<li>Segmentation faults indicate memory management errors</li>\n<li>Hash table get returns NULL for keys that were put</li>\n<li>Configuration validation fails on valid config files</li>\n<li>Memory leaks detected by valgrind during testing</li>\n</ul>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fdata-model-relationships.svg\" alt=\"Data Model Relationships\"></p>\n<h2 id=\"http-parser-component\">HTTP Parser Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1 (HTTP Proxy Core), Milestone 4 (Caching), Milestone 5 (SSL Termination) - the HTTP parser forms the foundation for request processing, cache-control header parsing, and protocol handling across encrypted and unencrypted connections.</p>\n</blockquote>\n<p>The HTTP parser component serves as the linguistic translator of our reverse proxy system. Think of it as a skilled interpreter at the United Nations who must fluently understand multiple dialects of the same language - HTTP/1.1 and HTTP/2 - and accurately convert the spoken words (raw bytes from network sockets) into structured meaning (parsed request and response objects) that other components can work with. Just as an interpreter must handle incomplete sentences, interruptions, and speaking errors gracefully, our parser must handle partial data reads, malformed headers, and protocol violations without crashing the entire system.</p>\n<p>The parser operates as a <strong>stream-based state machine</strong> rather than a simple string processor. This architectural choice stems from the fundamental nature of network communication: data arrives in chunks of unpredictable size, and we cannot assume that a complete HTTP message will arrive in a single network read operation. The parser must maintain state across multiple read operations, gradually building up a complete picture of the incoming request while handling the uncertainty of when the next piece of data will arrive.</p>\n<h3 id=\"parser-architecture\">Parser Architecture</h3>\n<p>The HTTP parser architecture centers around a <strong>finite state machine</strong> that processes incoming byte streams incrementally. Think of this state machine as a factory assembly line where each station (state) performs a specific parsing operation on the data before passing it to the next station. Unlike a traditional assembly line that processes discrete physical objects, our parsing assembly line processes a continuous stream of bytes, gradually building up the final product (a complete <code>HttpRequest</code> structure) as data flows through each processing stage.</p>\n<p>The parser maintains four critical pieces of state information: the current parsing position within the input stream, the current parsing state (which determines what type of data we expect next), a working buffer for accumulating partial data, and the partially constructed request object that gets populated as parsing progresses. This stateful approach allows the parser to handle the fundamental challenge of network programming: data arrives in arbitrary chunk sizes that rarely align with message boundaries.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Frequest-flow-sequence.svg\" alt=\"Request Processing Sequence\"></p>\n<p>The state machine progresses through a well-defined sequence of parsing phases, each responsible for extracting specific components of the HTTP message format. The <strong>request line parsing state</strong> extracts the HTTP method, request URI, and protocol version from the first line of the request. The <strong>header parsing state</strong> iterates through name-value pairs until it encounters the empty line that signals the end of headers. The <strong>body length determination state</strong> examines <code>Content-Length</code> and <code>Transfer-Encoding</code> headers to understand how much request body data to expect. Finally, the <strong>body parsing state</strong> accumulates the request payload according to the length or chunking rules determined in the previous state.</p>\n<p>Each state transition occurs when the parser encounters specific delimiter sequences in the input stream. The transition from request line parsing to header parsing triggers when the parser encounters the <code>\\r\\n</code> sequence that terminates the request line. Similarly, the transition from header parsing to body parsing occurs when the parser encounters the <code>\\r\\n\\r\\n</code> sequence that indicates the end of headers. The parser must handle cases where these delimiter sequences span multiple read operations - for example, when a network read returns data ending with <code>\\r</code> and the next read begins with <code>\\n</code>.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fconnection-state-machine.svg\" alt=\"Connection State Machine\"></p>\n<p>The parser integrates closely with the connection state machine shown in the diagram above. When a connection enters the <code>READING_REQUEST</code> state, it activates the HTTP parser to process incoming bytes. The parser operates incrementally, consuming available data and updating its internal state without blocking the event loop. When the parser completes request parsing, it signals the connection manager to transition the connection to the <code>FORWARDING</code> state, where the load balancer takes over to select an appropriate backend server.</p>\n<p>The following table details each parsing state, its responsibilities, and transition conditions:</p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Purpose</th>\n<th>Input Expected</th>\n<th>Transition Trigger</th>\n<th>Next State</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>PARSING_REQUEST_LINE</td>\n<td>Extract HTTP method, URI, version</td>\n<td>&quot;GET /path HTTP/1.1\\r\\n&quot;</td>\n<td>Found \\r\\n sequence</td>\n<td>PARSING_HEADERS</td>\n<td>Invalid method, malformed URI, unsupported version</td>\n</tr>\n<tr>\n<td>PARSING_HEADERS</td>\n<td>Extract header name-value pairs</td>\n<td>&quot;Host: example.com\\r\\n&quot;</td>\n<td>Found \\r\\n\\r\\n sequence</td>\n<td>DETERMINING_BODY_LENGTH</td>\n<td>Invalid header format, header too long</td>\n</tr>\n<tr>\n<td>DETERMINING_BODY_LENGTH</td>\n<td>Calculate expected body size</td>\n<td>Content-Length or Transfer-Encoding headers</td>\n<td>Length calculated</td>\n<td>PARSING_BODY or PARSING_COMPLETE</td>\n<td>Conflicting length headers, invalid encoding</td>\n</tr>\n<tr>\n<td>PARSING_BODY</td>\n<td>Read request body content</td>\n<td>Raw body bytes or chunked data</td>\n<td>Read expected bytes</td>\n<td>PARSING_COMPLETE</td>\n<td>Body exceeds limits, chunking format error</td>\n</tr>\n<tr>\n<td>PARSING_COMPLETE</td>\n<td>Request ready for forwarding</td>\n<td>No more input expected</td>\n<td>External trigger</td>\n<td>Reset to PARSING_REQUEST_LINE</td>\n<td>N/A</td>\n</tr>\n</tbody></table>\n<p>The parser&#39;s buffer management strategy plays a crucial role in memory efficiency and performance. The parser maintains a single <code>Buffer</code> structure that grows as needed to accommodate the incoming request data. The buffer uses a <strong>sliding window approach</strong> where parsed data gets discarded from the beginning of the buffer while new data gets appended to the end. This approach prevents memory usage from growing unboundedly during long-lived connections that process many sequential requests.</p>\n<p>The buffer management algorithm operates as follows: when the parser completes parsing a particular component (such as the request line), it advances the buffer&#39;s position marker to skip over the consumed data. When the buffer becomes more than half empty due to position advancement, the parser triggers a <strong>buffer compaction</strong> operation that shifts the remaining unparsed data to the beginning of the buffer and resets the position marker to zero. This compaction prevents fragmentation while ensuring that the buffer can continue accepting new data without constant reallocation.</p>\n<p>The parser handles <strong>protocol version detection</strong> by examining the request line&#39;s version field and configuring subsequent parsing behavior accordingly. HTTP/1.1 requests use text-based header parsing with specific rules for handling connection persistence, chunked encoding, and trailer headers. HTTP/2 requests require binary frame parsing with different state transitions and data structures. The parser maintains separate state machines for each protocol version, switching between them based on the detected protocol during request line parsing.</p>\n<p>For HTTP/1.1 parsing, the parser must handle several complex scenarios including <strong>chunked transfer encoding</strong>, where the request body arrives in variable-sized chunks each prefixed with a hexadecimal length indicator. The parser transitions into a sub-state machine for chunked parsing that alternates between reading chunk size lines and chunk data blocks. Each chunk ends with a <code>\\r\\n</code> sequence, and the final chunk has size zero followed by optional trailer headers.</p>\n<h3 id=\"parser-design-decisions\">Parser Design Decisions</h3>\n<p>The architecture of the HTTP parser component required several critical design decisions that fundamentally impact performance, memory usage, and maintainability. Each decision represents a carefully considered trade-off between competing concerns, and understanding the rationale behind these choices provides insight into the engineering principles that guide robust system design.</p>\n<blockquote>\n<p><strong>Decision: Stream-Based vs. Buffer-All Parsing Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: HTTP messages can be arbitrarily large, and network data arrives in unpredictable chunk sizes. We must choose between accumulating complete messages before parsing or parsing incrementally as data arrives.</li>\n<li><strong>Options Considered</strong>: Complete message buffering, incremental stream parsing, hybrid buffering with size limits</li>\n<li><strong>Decision</strong>: Incremental stream-based parsing with sliding buffer windows</li>\n<li><strong>Rationale</strong>: Stream parsing enables constant memory usage regardless of request size, reduces latency by starting processing before complete message arrival, and prevents denial-of-service attacks through memory exhaustion. The complexity of state management is justified by these significant benefits.</li>\n<li><strong>Consequences</strong>: Enables handling of large file uploads and streaming requests, requires sophisticated state machine implementation, complicates error handling and recovery, but provides predictable memory usage patterns.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Buffer Complete Message</td>\n<td>Simple parsing logic, easy error handling, straightforward testing</td>\n<td>Unbounded memory usage, high latency for large requests, DoS vulnerability</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Incremental Stream Parsing</td>\n<td>Constant memory usage, low latency, DoS protection</td>\n<td>Complex state machine, difficult error recovery, testing complexity</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>Hybrid Size-Limited Buffer</td>\n<td>Balanced approach, predictable memory limits</td>\n<td>Arbitrary size limits, still vulnerable to smaller DoS attacks</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Single State Machine vs. Protocol-Specific Parsers</strong></p>\n<ul>\n<li><strong>Context</strong>: The reverse proxy must support both HTTP/1.1 and HTTP/2 protocols, which have fundamentally different message formats (text vs. binary). We need to decide how to structure the parsing logic.</li>\n<li><strong>Options Considered</strong>: Unified state machine handling both protocols, separate parsers per protocol, protocol detection with delegation</li>\n<li><strong>Decision</strong>: Protocol detection with delegation to specialized parsers</li>\n<li><strong>Rationale</strong>: HTTP/1.1 and HTTP/2 have incompatible parsing requirements that would create excessive complexity in a unified parser. Separate parsers allow optimization for each protocol&#39;s characteristics while maintaining clean interfaces.</li>\n<li><strong>Consequences</strong>: Clean separation of concerns, protocol-specific optimizations possible, requires protocol detection logic, slightly higher code complexity, but improved maintainability and performance.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unified State Machine</td>\n<td>Single codebase to maintain, shared parsing infrastructure</td>\n<td>Complex conditional logic, poor performance optimization, difficult testing</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Protocol-Specific Parsers</td>\n<td>Clean separation, optimized for each protocol, maintainable</td>\n<td>Code duplication, requires detection logic, larger codebase</td>\n<td><strong>Yes</strong></td>\n</tr>\n<tr>\n<td>Shared Components</td>\n<td>Some code reuse, moderate complexity</td>\n<td>Forced abstractions, unclear boundaries</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Copy vs. Zero-Copy Header Processing</strong></p>\n<ul>\n<li><strong>Context</strong>: HTTP headers must be extracted from the input stream and made available to other components. We can either copy header data into separate strings or maintain references into the original buffer.</li>\n<li><strong>Options Considered</strong>: Copy all headers to separate strings, zero-copy with buffer references, hybrid approach with selective copying</li>\n<li><strong>Decision</strong>: Selective copying based on header usage patterns</li>\n<li><strong>Rationale</strong>: Critical headers needed by multiple components (Host, Content-Length) benefit from copying to avoid buffer lifetime dependencies. Less frequently accessed headers can use zero-copy references to reduce allocation overhead.</li>\n<li><strong>Consequences</strong>: Optimizes for common case performance, requires careful buffer lifetime management, complicates memory management, but achieves good balance of performance and safety.</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Error Recovery vs. Connection Termination Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Malformed HTTP requests can occur due to client bugs, network corruption, or malicious attacks. We must decide how aggressively to attempt recovery versus terminating problematic connections.</li>\n<li><strong>Options Considered</strong>: Strict RFC compliance with connection termination, lenient parsing with error recovery, configurable strictness levels</li>\n<li><strong>Decision</strong>: Lenient parsing with graceful degradation and connection termination for severe violations</li>\n<li><strong>Rationale</strong>: Internet traffic contains many minor protocol violations from legitimate clients. Overly strict parsing would reject valid traffic, while overly lenient parsing could enable security vulnerabilities. A balanced approach maximizes compatibility while maintaining security.</li>\n<li><strong>Consequences</strong>: Improved client compatibility, requires extensive testing of edge cases, potential security considerations, but achieves good balance of robustness and standards compliance.</li>\n</ul>\n</blockquote>\n<p>The parser&#39;s <strong>buffer management strategy</strong> represents another crucial architectural decision. The sliding window approach chosen here optimizes for long-lived connections that process many requests sequentially. Alternative approaches such as fixed-size circular buffers or linked buffer chains each offer different trade-offs between memory usage, allocation overhead, and implementation complexity.</p>\n<p>The sliding window buffer provides <strong>optimal memory locality</strong> for parsing operations since related data remains contiguous in memory. This locality improves CPU cache performance during header parsing, where the parser frequently scans backward and forward through recently processed data. The compaction mechanism ensures that buffer memory doesn&#39;t grow unboundedly while maintaining the locality benefits.</p>\n<p>Buffer compaction triggers based on a <strong>fractional occupancy threshold</strong> rather than absolute sizes. When the buffer&#39;s unprocessed data occupies less than 25% of the total buffer capacity, the compaction algorithm shifts the remaining data to the beginning of the buffer. This threshold balances compaction overhead against memory efficiency - too frequent compaction wastes CPU cycles, while infrequent compaction wastes memory.</p>\n<p>The parser implements <strong>header validation</strong> according to RFC 9110 specifications while allowing common deviations found in real-world HTTP traffic. Header names must consist only of token characters (alphanumeric plus specific punctuation), while header values allow a broader range of characters including spaces and international characters encoded in UTF-8. The parser rejects headers with null bytes or control characters that could enable request smuggling attacks.</p>\n<h3 id=\"common-parser-pitfalls\">Common Parser Pitfalls</h3>\n<p>HTTP parser implementation contains numerous subtle pitfalls that can lead to security vulnerabilities, compatibility issues, or performance problems. Understanding these common mistakes helps developers avoid well-known traps and build robust, secure parsers that handle the complexities of real-world HTTP traffic.</p>\n<p>⚠️ <strong>Pitfall: Incomplete Read Handling</strong>\nThe most fundamental mistake in HTTP parser implementation involves assuming that network reads will return complete, well-formed data. Beginning developers often write parsing code that expects to receive complete request lines or headers in a single read operation. In reality, TCP provides a byte stream abstraction where data arrives in arbitrary chunk sizes determined by network conditions, buffer sizes, and timing.</p>\n<p>Consider a scenario where a client sends the request line &quot;GET /api/users HTTP/1.1\\r\\n&quot; but the first network read returns only &quot;GET /api/us&quot; and the remainder arrives in subsequent reads. A naive parser that searches for the &quot;\\r\\n&quot; delimiter in the first read will fail to find it and may incorrectly conclude that the request line is malformed. The correct approach involves accumulating data across multiple reads until the complete delimiter sequence is found.</p>\n<p>This pitfall manifests in several ways: prematurely rejecting valid requests due to incomplete data, buffer overruns when assuming data length, and state machine corruption when partial delimiters span read boundaries. The solution requires implementing proper buffering with incremental delimiter detection that can handle delimiter sequences split across read operations.</p>\n<p>⚠️ <strong>Pitfall: HTTP Request Smuggling via Header Parsing</strong>\nHTTP request smuggling represents one of the most serious security vulnerabilities in parser implementation. This attack exploits discrepancies in how different systems parse HTTP messages with ambiguous length information. The vulnerability typically arises from incorrect handling of <code>Content-Length</code> and <code>Transfer-Encoding</code> headers when both are present in the same request.</p>\n<p>RFC 9110 specifies that requests containing both <code>Content-Length</code> and <code>Transfer-Encoding: chunked</code> headers must ignore the <code>Content-Length</code> header and process the request as chunked. However, parsers that prioritize <code>Content-Length</code> over <code>Transfer-Encoding</code> create opportunities for request smuggling. An attacker can craft requests where the reverse proxy and backend server disagree on message boundaries, allowing injection of additional requests into the connection stream.</p>\n<p>The correct implementation must strictly follow the RFC precedence rules: check for <code>Transfer-Encoding: chunked</code> first, and if present, ignore any <code>Content-Length</code> headers. Additionally, the parser must reject requests with multiple <code>Content-Length</code> headers containing different values, as this represents a clear protocol violation that could indicate an attack attempt.</p>\n<p>⚠️ <strong>Pitfall: Memory Exhaustion via Unbounded Buffering</strong>\nParsers that continuously accumulate incoming data without size limits create denial-of-service vulnerabilities where attackers can exhaust server memory by sending extremely large requests. This pitfall commonly occurs in implementations that buffer entire requests before beginning processing, or that fail to implement maximum size limits on headers and request bodies.</p>\n<p>The vulnerability manifests when an attacker sends requests with enormous header sections (for example, a single header with megabytes of data) or claims extremely large content lengths without sending corresponding body data. The parser allocates memory to accommodate the claimed data size but never receives enough data to complete parsing, leaving large buffers allocated indefinitely.</p>\n<p>Mitigation requires implementing strict limits at multiple levels: maximum total header size (typically 8KB-16KB), maximum individual header length, maximum request line length, and maximum request body size. The parser should reject requests that exceed these limits immediately rather than attempting to buffer them. Additionally, implementing timeouts prevents slow-send attacks where attackers send valid data extremely slowly to maintain connections indefinitely.</p>\n<p>⚠️ <strong>Pitfall: Case Sensitivity in Header Names</strong>\nHTTP header names are case-insensitive according to the specification, but many parser implementations perform case-sensitive comparisons when processing headers. This creates compatibility issues where requests with headers like &quot;Content-length&quot; (lowercase &#39;l&#39;) or &quot;HOST&quot; (uppercase) fail to match expected header names.</p>\n<p>The issue becomes particularly problematic when integrating with other HTTP libraries or when forwarding requests to backend servers that may have different case sensitivity behaviors. Some backend servers or frameworks expect specific header name capitalization patterns, leading to subtle failures when the parser normalizes header names differently than expected.</p>\n<p>The correct approach involves normalizing header names to a consistent case (typically lowercase) during parsing while preserving the original case when forwarding requests. Hash table implementations used for header storage must use case-insensitive comparison functions. When extracting headers for processing (such as checking <code>Content-Length</code> for body parsing), use normalized lookups that handle any case variation.</p>\n<p>⚠️ <strong>Pitfall: Improper URI Decoding and Validation</strong>\nRequest URI parsing involves multiple layers of encoding and validation that create numerous opportunities for security vulnerabilities. Common mistakes include performing URL decoding multiple times (double-decoding), failing to validate decoded paths for directory traversal attempts, and incorrectly handling international characters in URIs.</p>\n<p>Double-decoding occurs when the parser URL-decodes the request URI and then passes it to another component that performs additional URL decoding. An attacker can exploit this by encoding malicious sequences multiple times - for example, encoding &quot;../&quot; as &quot;%252e%252e%252f&quot; where the &quot;%25&quot; sequences decode to &quot;%&quot; characters that form new percent-encoded sequences in the second decoding pass.</p>\n<p>Directory traversal attacks exploit insufficient path validation after URL decoding. Attackers encode sequences like &quot;../&quot; to bypass naive string-based filtering, then use the decoded paths to access files outside the intended directory structure. The parser must validate decoded paths to ensure they don&#39;t contain directory traversal sequences or resolve to unauthorized locations.</p>\n<p>International character handling requires careful attention to UTF-8 encoding and normalization. Different UTF-8 sequences can represent the same logical character, creating opportunities for filter bypassing if validation occurs before normalization. The parser must handle UTF-8 decoding errors gracefully and apply consistent normalization rules.</p>\n<p>⚠️ <strong>Pitfall: Chunked Encoding Implementation Errors</strong>\nChunked transfer encoding parsing contains several subtle complexities that frequently trip up implementers. The most common errors involve incorrect hex parsing of chunk sizes, improper handling of chunk extensions, and failure to process trailer headers that may follow the final chunk.</p>\n<p>Chunk size parsing must handle hexadecimal numbers with optional leading zeros and case-insensitive hex digits. However, parsers must also handle chunk extensions - optional parameters that follow the chunk size on the same line separated by semicolons. For example: &quot;1a;charset=utf-8\\r\\n&quot; indicates a chunk of 26 bytes with an extension parameter. Parsers that don&#39;t expect extensions may fail when encountering them.</p>\n<p>The final chunk in a chunked message has size zero and may be followed by trailer headers that use the same syntax as regular headers. These trailers must be parsed and potentially merged with the main header set. Many implementations incorrectly assume that the zero-size chunk marks the absolute end of the message and fail to process trailers.</p>\n<p>Proper chunked encoding implementation requires a sub-state machine that alternates between reading chunk size lines and chunk data blocks. The parser must validate that exactly the specified number of bytes are received for each chunk and that each chunk ends with the correct &quot;\\r\\n&quot; sequence.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The HTTP parser implementation requires careful attention to performance, security, and correctness. This guidance provides concrete recommendations for building a robust parser that handles real-world HTTP traffic while maintaining security and efficiency.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP/1.1 Parser</td>\n<td>Custom state machine with string operations</td>\n<td>Optimized state machine with SIMD string scanning</td>\n</tr>\n<tr>\n<td>HTTP/2 Parser</td>\n<td>HTTP/2 frame parsing library (nghttp2)</td>\n<td>Custom binary frame parser with zero-copy</td>\n</tr>\n<tr>\n<td>Buffer Management</td>\n<td>Dynamic reallocation with memmove compaction</td>\n<td>Ring buffer with scatter-gather I/O</td>\n</tr>\n<tr>\n<td>Header Storage</td>\n<td>Hash table with string keys</td>\n<td>Trie structure with interned strings</td>\n</tr>\n<tr>\n<td>URI Parsing</td>\n<td>Standard library URL parsing</td>\n<td>Custom parser with validation</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/\n  http/\n    parser.c              ← Main parser state machine\n    parser.h              ← Parser interface and structures\n    http1_parser.c        ← HTTP/1.1 specific parsing logic\n    http2_parser.c        ← HTTP/2 frame parsing logic\n    buffer.c              ← Buffer management utilities\n    buffer.h              ← Buffer structure and operations\n    headers.c             ← Header parsing and storage\n    headers.h             ← Header manipulation interface\n    uri_parser.c          ← URI parsing and validation\n    test/\n      test_parser.c       ← Parser unit tests\n      test_buffer.c       ← Buffer management tests\n      test_headers.c      ← Header parsing tests</code></pre></div>\n\n<p><strong>HTTP Parser Core Structures:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stddef.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/types.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Buffer management structure for incremental parsing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> data;</span><span style=\"color:#6A737D\">           // Buffer memory allocation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> capacity;</span><span style=\"color:#6A737D\">      // Total allocated buffer size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> length;</span><span style=\"color:#6A737D\">        // Current data length in buffer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> position;</span><span style=\"color:#6A737D\">      // Current parsing position</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} Buffer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HTTP parser state enumeration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_REQUEST_LINE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_HEADERS,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_DETERMINING_BODY_LENGTH,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_BODY,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_CHUNKED_SIZE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_CHUNKED_DATA,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_COMPLETE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HTTP_PARSING_ERROR</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HttpParserState;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HTTP request structure populated by parser</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> method</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">          // HTTP method (GET, POST, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> uri</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">2048</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">          // Request URI path and query</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> version</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">        // HTTP version (1.1, 2.0)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> headers;</span><span style=\"color:#6A737D\">      // Header name-value pairs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> body;</span><span style=\"color:#6A737D\">            // Request body content</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> content_length;</span><span style=\"color:#6A737D\">   // Content-Length header value</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> chunked;</span><span style=\"color:#6A737D\">            // Transfer-Encoding: chunked flag</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> keep_alive;</span><span style=\"color:#6A737D\">         // Connection persistence flag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HttpRequest;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HTTP parser context maintaining state across reads</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpParserState state;</span><span style=\"color:#6A737D\">       // Current parsing state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> input_buffer;</span><span style=\"color:#6A737D\">        // Accumulated input data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> current_request;</span><span style=\"color:#6A737D\"> // Request being parsed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> bytes_remaining;</span><span style=\"color:#6A737D\">      // Body bytes still expected</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> chunk_size;</span><span style=\"color:#6A737D\">          // Current chunk size (chunked mode)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> chunk_size_parsed;</span><span style=\"color:#6A737D\">     // Chunk size line completion flag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} HttpParser;</span></span></code></pre></div>\n\n<p><strong>Core Parser Infrastructure (Complete Implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Buffer management functions - complete implementation ready to use</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> buffer_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> initial_capacity</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> buf </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(Buffer));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">buf) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    buf->data </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(initial_capacity);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">buf->data) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(buf);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    buf->capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> initial_capacity;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    buf->length </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    buf->position </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> buf;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> buffer_append</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Compact buffer if more than 75% consumed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (buf->position </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> buf->capacity </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#F97583\"> /</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        size_t</span><span style=\"color:#E1E4E8\"> remaining </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> buf->length </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> buf->position;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        memmove</span><span style=\"color:#E1E4E8\">(buf->data, buf->data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> buf->position, remaining);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        buf->length </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> remaining;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        buf->position </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Expand buffer if needed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (buf->length </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> size </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> buf->capacity) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        size_t</span><span style=\"color:#E1E4E8\"> new_capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> buf->capacity </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        char*</span><span style=\"color:#E1E4E8\"> new_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> realloc</span><span style=\"color:#E1E4E8\">(buf->data, new_capacity);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">new_data) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        buf->data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        buf->capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> new_capacity;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(buf->data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> buf->length, data, size);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    buf->length </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> buffer_read</span><span style=\"color:#E1E4E8\">(Buffer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> dest</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> max_size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> available </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> buf->length </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> buf->position;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> to_read </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (available </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> max_size) </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> available </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> max_size;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(dest, buf->data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> buf->position, to_read);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    buf->position </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> to_read;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> to_read;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Header management functions - complete implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> headers_create</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> hashtable_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\"> // Start with 32 header slots</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> headers_add</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> headers</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> name</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> value</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Normalize header name to lowercase for case-insensitive lookup</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> normalized_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(name) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#FFAB70\">name</span><span style=\"color:#E1E4E8\">[i]; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        normalized_name</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> tolower</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">name</span><span style=\"color:#E1E4E8\">[i]);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    normalized_name</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(name)] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> value_copy </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(value) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    strcpy</span><span style=\"color:#E1E4E8\">(value_copy, value);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> result </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> hashtable_put</span><span style=\"color:#E1E4E8\">(headers, normalized_name, value_copy);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">result) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(normalized_name);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(value_copy);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> result;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">char*</span><span style=\"color:#B392F0\"> headers_get</span><span style=\"color:#E1E4E8\">(HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> headers</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> name</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> normalized_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(name) </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#FFAB70\">name</span><span style=\"color:#E1E4E8\">[i]; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        normalized_name</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> tolower</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">name</span><span style=\"color:#E1E4E8\">[i]);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    normalized_name</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(name)] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\0</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">char*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#B392F0\">hashtable_get</span><span style=\"color:#E1E4E8\">(headers, normalized_name);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(normalized_name);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> value;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Parser Core Logic Skeleton (for learner implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Initialize HTTP parser with clean state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Sets up parser context and allocates required buffers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> http_parser_create</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate HttpParser structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Initialize parser state to HTTP_PARSING_REQUEST_LINE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Create input buffer with initial capacity (8KB recommended)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set current_request to NULL (will be allocated per request)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Initialize all numeric fields to 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Return NULL on any allocation failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use buffer_create(8192) for input buffer</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Process incoming data through the parser state machine</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Returns number of bytes consumed, 0 if need more data, -1 on error</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> http_parser_process</span><span style=\"color:#E1E4E8\">(HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Append incoming data to input buffer using buffer_append()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Enter main parsing loop while data available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Switch on parser->state to handle current parsing phase</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: For each state, try to parse expected data format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Advance parser state when delimiter found or length satisfied</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Return consumed byte count or error code</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use find_delimiter() helper to locate \\r\\n sequences</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Handle case where delimiter spans multiple process() calls</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Parse HTTP request line: \"METHOD /path HTTP/version\\r\\n\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Updates parser->current_request with method, URI, and version</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> parse_request_line</span><span style=\"color:#E1E4E8\">(HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Find \\r\\n delimiter in input buffer from current position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If delimiter not found, return false (need more data)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Extract line content between position and delimiter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Split line on spaces to get method, URI, version</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate method against allowed HTTP methods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Validate URI format and length limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Validate HTTP version (1.0, 1.1, 2.0)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Copy parsed values to current_request structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Advance buffer position past \\r\\n delimiter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 10: Return true on successful parsing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strncmp() for method validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Reject URIs longer than 2048 characters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Parse header lines until empty line encountered</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Populates parser->current_request->headers hash table</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> parse_headers</span><span style=\"color:#E1E4E8\">(HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Loop looking for header lines terminated by \\r\\n</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: When find \\r\\n\\r\\n sequence, headers complete</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For each header line, split on first ':' character</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Trim whitespace from header name and value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate header name contains only valid characters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Add header to hash table using headers_add()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Check for special headers: Content-Length, Transfer-Encoding, Connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Set parser flags based on special header values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Advance buffer position past processed headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 10: Return true when all headers parsed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strchr() to find ':' separator in header line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Watch for folded headers (lines starting with space/tab)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Determine request body length from headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Sets parser->content_length and parser->chunked flags</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> determine_body_length</span><span style=\"color:#E1E4E8\">(HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check for Transfer-Encoding: chunked header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If chunked, set parser->chunked = true and return</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check for Content-Length header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If Content-Length present, parse numeric value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Validate Content-Length is non-negative integer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Set parser->content_length and parser->bytes_remaining</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: If no body length indicators, assume no body</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Transition parser state to appropriate body parsing state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strtoul() to parse Content-Length value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Reject requests with both chunked and Content-Length</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Parse fixed-length request body based on Content-Length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Accumulates body data into parser->current_request->body buffer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> parse_fixed_body</span><span style=\"color:#E1E4E8\">(HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Calculate bytes available in input buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Determine how many bytes to consume (min of available and remaining)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Append consumed bytes to request body buffer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Subtract consumed bytes from parser->bytes_remaining</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Advance input buffer position past consumed data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If bytes_remaining reaches 0, parsing complete</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Return false if more body data needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use buffer_append() to add body data to request</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Parse chunked request body with size prefixes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Handles chunk size parsing and data accumulation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#B392F0\"> parse_chunked_body</span><span style=\"color:#E1E4E8\">(HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: If in PARSING_CHUNKED_SIZE state, look for size line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Parse hexadecimal chunk size from line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Handle chunk extensions after semicolon (ignore them)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If chunk size is 0, look for trailer headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If chunk size > 0, transition to PARSING_CHUNKED_DATA</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: In data state, read exactly chunk_size bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: After chunk data, expect \\r\\n delimiter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Repeat size/data cycle until zero-size chunk</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use strtoul() with base 16 for hex chunk size parsing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Each chunk ends with \\r\\n after the data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Language-Specific Implementation Hints:</strong></p>\n<ul>\n<li>Use <code>memmem()</code> function for efficient delimiter searching in binary data rather than <code>strstr()</code> which stops at null bytes</li>\n<li>Implement <code>find_crlf()</code> helper that can find <code>\\r\\n</code> sequences spanning buffer boundaries by checking the last character of previous searches</li>\n<li>Use <code>realloc()</code> for buffer expansion but always check return value and handle failure by keeping original buffer</li>\n<li>For header storage, consider using a trie data structure instead of hash table for better memory efficiency with common header prefixes</li>\n<li>Use <code>tolower()</code> for case-insensitive header comparisons but be aware of locale-specific behavior</li>\n<li>Implement connection timeout handling using <code>alarm()</code> or <code>select()</code> with timeout to prevent slow-read attacks</li>\n<li>Use <code>TCP_NODELAY</code> socket option to reduce latency for small HTTP messages</li>\n<li>Consider using <code>MSG_PEEK</code> flag with <code>recv()</code> to examine data without consuming it during delimiter searches</li>\n</ul>\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the HTTP parser core, verify functionality with these tests:</p>\n<ol>\n<li><p><strong>Basic Request Parsing</strong>: Send &quot;GET /test HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n&quot; and verify the parser extracts method=&quot;GET&quot;, uri=&quot;/test&quot;, version=&quot;HTTP/1.1&quot;, and headers contain Host entry.</p>\n</li>\n<li><p><strong>Chunked Encoding</strong>: Send a chunked request with body &quot;5\\r\\nhello\\r\\n0\\r\\n\\r\\n&quot; and verify the parser correctly assembles &quot;hello&quot; in the body buffer.</p>\n</li>\n<li><p><strong>Partial Read Handling</strong>: Send request data in small chunks (1-2 bytes per write) and verify the parser accumulates data correctly across multiple <code>http_parser_process()</code> calls.</p>\n</li>\n<li><p><strong>Large Header Handling</strong>: Send request with 100+ headers and verify parser doesn&#39;t crash or leak memory.</p>\n</li>\n<li><p><strong>Error Case Handling</strong>: Send malformed requests (invalid methods, missing headers, bad chunk encoding) and verify parser returns appropriate error codes.</p>\n</li>\n</ol>\n<p>Expected output when running <code>make test</code>:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Running HTTP parser tests...\n✓ Basic request parsing\n✓ Chunked transfer encoding  \n✓ Partial data handling\n✓ Large header processing\n✓ Error case validation\n✓ Memory leak detection\nAll parser tests passed!</code></pre></div>\n\n<p>Signs of implementation issues:</p>\n<ul>\n<li><strong>Segmentation faults</strong>: Usually indicate buffer overruns or null pointer dereferences in parsing logic</li>\n<li><strong>Memory leaks</strong>: Check that all allocated buffers and hash table entries are properly freed</li>\n<li><strong>Hanging on partial data</strong>: Parser not handling incomplete reads correctly - verify state machine transitions</li>\n<li><strong>Header corruption</strong>: Case sensitivity issues or incorrect string termination in header processing</li>\n</ul>\n<h2 id=\"connection-manager-component\">Connection Manager Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1 (HTTP Proxy Core), Milestone 3 (Connection Pooling) - the connection manager handles client connections for basic request forwarding and implements connection pooling for efficient backend communication.</p>\n</blockquote>\n<p>Think of the Connection Manager as the <strong>backstage coordinator at a busy restaurant</strong>. When customers arrive, it seats them at tables (establishing client connections), takes their orders (receiving requests), coordinates with the kitchen (backend servers), and ensures the waitstaff (connection pools) efficiently deliver food without constantly running back and forth. Just as a restaurant maintains a staff of waiters who can serve multiple tables without hiring new staff for each customer, the Connection Manager maintains pools of reusable connections to backend servers, avoiding the expensive overhead of establishing new network connections for every request.</p>\n<p>The Connection Manager represents one of the most complex components in our reverse proxy architecture because it must juggle multiple concerns simultaneously: accepting new client connections, maintaining the lifecycle of active connections, pooling backend connections for reuse, and gracefully handling failures at every stage. Unlike simpler HTTP servers that handle one connection at a time, a production reverse proxy must efficiently manage thousands of concurrent connections while maintaining low latency and high throughput.</p>\n<h3 id=\"connection-lifecycle-management\">Connection Lifecycle Management</h3>\n<p>The <strong>connection lifecycle</strong> in our reverse proxy follows a sophisticated state machine that tracks each connection from initial establishment through final cleanup. Understanding this lifecycle is crucial because connections represent expensive system resources (file descriptors, memory buffers, kernel state) that must be carefully managed to prevent resource exhaustion and ensure optimal performance.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fconnection-state-machine.svg\" alt=\"Connection State Machine\"></p>\n<p>Each connection in our system progresses through well-defined states that determine what operations are valid and what data is expected. The connection lifecycle begins when a client establishes a TCP connection to our proxy&#39;s listening socket. At this moment, the connection enters the <code>IDLE</code> state, where it waits for the first HTTP request to arrive. The Connection Manager must track not only the current state but also timing information, buffer contents, and associated metadata for each connection.</p>\n<p>The state transitions are triggered by specific events that occur during request processing. When data arrives on an idle connection, it transitions to <code>READING_REQUEST</code> state, where the HTTP Parser Component begins processing the incoming bytes. Once a complete request is parsed, the connection moves to <code>FORWARDING</code> state while the Load Balancer Component selects a backend server. After successful backend selection, the connection enters <code>READING_RESPONSE</code> state as it waits for the backend&#39;s reply. Finally, it transitions to <code>WRITING_RESPONSE</code> state while sending data back to the client.</p>\n<h4 id=\"connection-state-tracking\">Connection State Tracking</h4>\n<p>The Connection Manager maintains detailed state information for every active connection through the <code>Connection</code> structure. This structure serves as the single source of truth for connection status, timing information, and associated resources.</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>connection_id</td>\n<td>int</td>\n<td>Unique identifier for this connection instance</td>\n</tr>\n<tr>\n<td>client_fd</td>\n<td>int</td>\n<td>File descriptor for client socket</td>\n</tr>\n<tr>\n<td>backend_fd</td>\n<td>int</td>\n<td>File descriptor for backend socket (if assigned)</td>\n</tr>\n<tr>\n<td>state</td>\n<td>ConnectionState</td>\n<td>Current state in the connection lifecycle</td>\n</tr>\n<tr>\n<td>client_addr</td>\n<td>struct sockaddr_in</td>\n<td>Client IP address and port information</td>\n</tr>\n<tr>\n<td>backend_server</td>\n<td>BackendServer*</td>\n<td>Pointer to selected backend server</td>\n</tr>\n<tr>\n<td>request_buffer</td>\n<td>Buffer*</td>\n<td>Buffer containing incoming request data</td>\n</tr>\n<tr>\n<td>response_buffer</td>\n<td>Buffer*</td>\n<td>Buffer containing outgoing response data</td>\n</tr>\n<tr>\n<td>created_time</td>\n<td>time_t</td>\n<td>Timestamp when connection was established</td>\n</tr>\n<tr>\n<td>last_activity</td>\n<td>time_t</td>\n<td>Timestamp of most recent I/O activity</td>\n</tr>\n<tr>\n<td>bytes_read</td>\n<td>size_t</td>\n<td>Total bytes read from client</td>\n</tr>\n<tr>\n<td>bytes_written</td>\n<td>size_t</td>\n<td>Total bytes written to client</td>\n</tr>\n<tr>\n<td>keep_alive</td>\n<td>bool</td>\n<td>Whether connection supports HTTP keep-alive</td>\n</tr>\n<tr>\n<td>pipeline_depth</td>\n<td>int</td>\n<td>Number of pipelined requests in queue</td>\n</tr>\n<tr>\n<td>timeout_ms</td>\n<td>int</td>\n<td>Connection timeout in milliseconds</td>\n</tr>\n</tbody></table>\n<p>The <code>ConnectionState</code> enum defines all possible states a connection can occupy during its lifetime:</p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Description</th>\n<th>Valid Next States</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CONNECTION_IDLE</td>\n<td>Waiting for incoming request</td>\n<td>READING_REQUEST, CLOSING</td>\n</tr>\n<tr>\n<td>CONNECTION_READING_REQUEST</td>\n<td>Parsing incoming HTTP request</td>\n<td>FORWARDING, CLOSING</td>\n</tr>\n<tr>\n<td>CONNECTION_FORWARDING</td>\n<td>Selecting backend and sending request</td>\n<td>READING_RESPONSE, CLOSING</td>\n</tr>\n<tr>\n<td>CONNECTION_READING_RESPONSE</td>\n<td>Waiting for backend response</td>\n<td>WRITING_RESPONSE, CLOSING</td>\n</tr>\n<tr>\n<td>CONNECTION_WRITING_RESPONSE</td>\n<td>Sending response to client</td>\n<td>IDLE (keep-alive), CLOSING</td>\n</tr>\n<tr>\n<td>CONNECTION_CLOSING</td>\n<td>Cleaning up and terminating</td>\n<td>None (terminal state)</td>\n</tr>\n</tbody></table>\n<h4 id=\"connection-timeout-management\">Connection Timeout Management</h4>\n<p>Timeout management prevents connections from consuming resources indefinitely when clients disappear or become unresponsive. The Connection Manager implements multiple timeout mechanisms that operate at different stages of the connection lifecycle. <strong>Read timeouts</strong> protect against slow or malicious clients that send partial requests, <strong>write timeouts</strong> handle cases where clients stop reading response data, and <strong>idle timeouts</strong> clean up keep-alive connections that remain unused.</p>\n<p>The timeout implementation uses a <strong>timer wheel</strong> data structure that efficiently tracks thousands of connections with minimal overhead. Rather than setting individual timers for each connection (which would be expensive in terms of system calls), the timer wheel groups connections by their expiration time and processes entire groups together. This approach scales well as connection counts increase and provides precise timeout handling with minimal CPU overhead.</p>\n<p>When a timeout occurs, the Connection Manager follows a specific cleanup procedure. First, it logs the timeout event with relevant connection details for debugging purposes. Next, it gracefully closes any associated backend connection to prevent resource leaks. Then it sends an appropriate HTTP error response to the client if possible (408 Request Timeout for read timeouts, 502 Bad Gateway for backend timeouts). Finally, it removes the connection from all tracking structures and releases its allocated memory.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The timer wheel timeout mechanism is crucial for handling the &quot;slow loris&quot; attack pattern, where malicious clients open many connections and send requests extremely slowly to exhaust server resources. Without proper timeouts, a single attacker could consume all available connection slots.</p>\n</blockquote>\n<h3 id=\"connection-pooling-strategy\">Connection Pooling Strategy</h3>\n<p>Connection pooling represents the <strong>heart of our performance optimization strategy</strong>. Establishing a new TCP connection to a backend server requires a three-way handshake, DNS resolution (if needed), and potential SSL/TLS negotiation. This overhead can add 50-200ms of latency per request, making it the dominant performance bottleneck in many scenarios. Connection pooling eliminates this overhead by maintaining a pool of pre-established connections that can be immediately reused for new requests.</p>\n<p>Think of connection pooling like a <strong>taxi dispatch system at a busy airport</strong>. Instead of calling a new taxi for each passenger (expensive and slow), the airport maintains a queue of waiting taxis that can immediately pick up the next passenger. When a taxi drops off a passenger at their destination, it returns to the airport queue to serve the next customer. This system maximizes efficiency by reusing expensive resources (taxis/connections) and minimizing wait times (network handshake overhead).</p>\n<h4 id=\"pool-architecture-and-management\">Pool Architecture and Management</h4>\n<p>Our connection pooling system maintains a separate pool for each configured backend server, allowing fine-grained control over connection limits and load distribution. Each pool operates as an independent resource manager with its own allocation policies, health checking, and cleanup procedures.</p>\n<p>The pool management algorithm balances several competing concerns. It must maintain enough idle connections to handle traffic spikes without establishing new connections (which would increase latency). However, it cannot maintain too many idle connections, as they consume memory and file descriptors unnecessarily. The pool must also detect and remove stale connections that have been closed by the backend server or network infrastructure.</p>\n<table>\n<thead>\n<tr>\n<th>Pool Configuration</th>\n<th>Default Value</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>max_connections</td>\n<td>32</td>\n<td>Maximum connections per backend server</td>\n</tr>\n<tr>\n<td>min_idle_connections</td>\n<td>4</td>\n<td>Minimum idle connections to maintain</td>\n</tr>\n<tr>\n<td>max_idle_connections</td>\n<td>16</td>\n<td>Maximum idle connections before cleanup</td>\n</tr>\n<tr>\n<td>idle_timeout_seconds</td>\n<td>300</td>\n<td>Timeout for unused idle connections</td>\n</tr>\n<tr>\n<td>connect_timeout_ms</td>\n<td>5000</td>\n<td>Timeout for establishing new connections</td>\n</tr>\n<tr>\n<td>health_check_interval</td>\n<td>30</td>\n<td>Seconds between connection health checks</td>\n</tr>\n<tr>\n<td>retry_backoff_ms</td>\n<td>1000</td>\n<td>Delay before retrying failed connections</td>\n</tr>\n</tbody></table>\n<p>The connection pool implements a <strong>LIFO (Last-In, First-Out) strategy</strong> for connection reuse. When a connection finishes serving a request, it goes to the front of the idle queue. When a new request needs a connection, it takes from the front of the queue. This strategy improves cache locality and connection warmth, as recently used connections are more likely to have warm CPU caches and network buffers.</p>\n<h4 id=\"connection-pool-operations\">Connection Pool Operations</h4>\n<p>The pool provides several key operations that abstract the complexity of connection management from the rest of the proxy system. These operations handle all aspects of connection lifecycle, from initial allocation through final cleanup.</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>pool_acquire</td>\n<td>backend_server, timeout_ms</td>\n<td>Connection*</td>\n<td>Get available connection from pool</td>\n</tr>\n<tr>\n<td>pool_release</td>\n<td>connection, reusable</td>\n<td>void</td>\n<td>Return connection to pool or close</td>\n</tr>\n<tr>\n<td>pool_create_connection</td>\n<td>backend_server</td>\n<td>Connection*</td>\n<td>Establish new connection to backend</td>\n</tr>\n<tr>\n<td>pool_validate_connection</td>\n<td>connection</td>\n<td>bool</td>\n<td>Check if connection is still healthy</td>\n</tr>\n<tr>\n<td>pool_cleanup_idle</td>\n<td>pool, max_age_seconds</td>\n<td>int</td>\n<td>Remove old idle connections</td>\n</tr>\n<tr>\n<td>pool_get_stats</td>\n<td>pool</td>\n<td>PoolStats*</td>\n<td>Retrieve pool utilization metrics</td>\n</tr>\n<tr>\n<td>pool_set_limits</td>\n<td>pool, max_conn, max_idle</td>\n<td>bool</td>\n<td>Update pool configuration limits</td>\n</tr>\n</tbody></table>\n<p>The <code>pool_acquire</code> operation implements the core connection allocation logic. When a request needs a backend connection, this function first attempts to reuse an idle connection from the pool. If no idle connections are available and the pool hasn&#39;t reached its maximum size, it establishes a new connection. If the pool is at capacity, the operation can either block until a connection becomes available or return an error, depending on the configured behavior.</p>\n<p>Connection validation is critical for pool reliability. The <code>pool_validate_connection</code> function checks whether a pooled connection is still usable before assigning it to a new request. This validation includes checking if the socket is still open, verifying there&#39;s no pending data that would indicate a protocol error, and optionally sending a lightweight health check request to the backend server.</p>\n<p>The <code>pool_release</code> operation handles returning connections to the pool after request completion. If the connection is still healthy and the request completed successfully, it&#39;s marked as available for reuse. However, if an error occurred during request processing, or if the connection shows signs of corruption, it&#39;s immediately closed and removed from the pool.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Connection validation must be extremely lightweight since it occurs on every connection reuse. Expensive validation (like sending HTTP requests) would negate the performance benefits of pooling. Instead, we rely on socket-level checks and occasional background health monitoring.</p>\n</blockquote>\n<h4 id=\"pool-health-management\">Pool Health Management</h4>\n<p>Connection pools require continuous health monitoring because network conditions and backend server states change dynamically. A connection that was healthy when returned to the pool might become stale due to firewall timeouts, server restarts, or network partitions. The health management system proactively identifies and removes unhealthy connections before they can cause request failures.</p>\n<p>The health checking strategy operates on multiple levels. <strong>Passive health checking</strong> monitors connection behavior during normal request processing. If a connection fails during use, it&#39;s immediately removed from the pool and the failure is recorded. <strong>Active health checking</strong> periodically validates idle connections by sending lightweight probe requests or checking socket status. This proactive approach catches problems before they affect user requests.</p>\n<p>Background health checking runs on a separate thread to avoid blocking request processing. The health checker iterates through idle connections in each pool, validating them according to configured criteria. Connections that fail validation are removed from the pool and properly closed. The health checker also implements <strong>backoff strategies</strong> for pools with repeated failures, temporarily reducing health check frequency to avoid overwhelming struggling backend servers.</p>\n<h4 id=\"pool-sizing-and-auto-scaling\">Pool Sizing and Auto-scaling</h4>\n<p>Determining optimal pool sizes requires balancing resource utilization with performance requirements. Small pools may not provide sufficient connection reuse, leading to frequent connection establishment overhead. Large pools waste memory and file descriptors while providing minimal additional benefit. Our pool sizing algorithm adapts dynamically based on observed traffic patterns and backend performance characteristics.</p>\n<p>The auto-scaling mechanism monitors several key metrics to guide sizing decisions. <strong>Connection utilization rates</strong> indicate whether the current pool size adequately serves the request load. <strong>Connection establishment latency</strong> shows whether new connections are expensive enough to justify maintaining larger pools. <strong>Backend response times</strong> help identify when backend servers are becoming overloaded and may benefit from reduced connection counts.</p>\n<p>Pool scaling operates conservatively to avoid oscillation. When scaling up, the system gradually increases pool sizes while monitoring the impact on overall performance. When scaling down, it waits for extended periods of low utilization before reducing pool sizes. This hysteresis prevents the system from constantly adjusting pool sizes in response to normal traffic fluctuations.</p>\n<h3 id=\"connection-management-decisions\">Connection Management Decisions</h3>\n<p>The connection management system involves numerous architectural decisions that significantly impact performance, scalability, and reliability. These decisions represent trade-offs between competing concerns, and understanding the rationale behind each choice is essential for maintaining and extending the system.</p>\n<h4 id=\"connection-state-management-decision\">Connection State Management Decision</h4>\n<blockquote>\n<p><strong>Decision: Centralized Connection State Tracking</strong></p>\n<ul>\n<li><strong>Context</strong>: The system needs to track connection state, timeouts, and metadata for thousands of concurrent connections while supporting efficient lookup and update operations.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Distributed state stored in connection structures</li>\n<li>Centralized state manager with hash table lookup</li>\n<li>Hybrid approach with local caching</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Centralized state manager with hash table-based connection tracking</li>\n<li><strong>Rationale</strong>: Centralized management enables efficient timeout processing, resource cleanup, and system-wide connection limits. Hash table lookup provides O(1) access time regardless of connection count. Centralized design simplifies debugging and monitoring.</li>\n<li><strong>Consequences</strong>: Enables efficient batch processing of timeouts and cleanup operations. Requires careful synchronization for multi-threaded access. Single point of truth for connection state improves debugging capabilities.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Distributed State</td>\n<td>Simple per-connection logic, no synchronization overhead</td>\n<td>Difficult timeout management, hard to enforce global limits</td>\n</tr>\n<tr>\n<td>Centralized Manager</td>\n<td>Efficient batch operations, unified resource management</td>\n<td>Potential synchronization bottleneck, more complex implementation</td>\n</tr>\n<tr>\n<td>Hybrid Caching</td>\n<td>Balance of performance and manageability</td>\n<td>Complex cache coherency, increased memory overhead</td>\n</tr>\n</tbody></table>\n<p>The centralized approach proves superior for production reverse proxy implementations because timeout processing and resource cleanup operations become much more efficient when connection state is co-located. The ability to iterate through all connections for batch timeout processing provides significant performance benefits compared to per-connection timer management.</p>\n<h4 id=\"connection-pooling-algorithm-decision\">Connection Pooling Algorithm Decision</h4>\n<blockquote>\n<p><strong>Decision: Per-Backend LIFO Connection Pools</strong></p>\n<ul>\n<li><strong>Context</strong>: Backend connections must be efficiently reused to minimize connection establishment overhead while maintaining good cache locality and resource utilization.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Global connection pool shared across all backends</li>\n<li>Per-backend FIFO pools for fairness</li>\n<li>Per-backend LIFO pools for cache locality</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Separate LIFO pools for each backend server with configurable limits</li>\n<li><strong>Rationale</strong>: Per-backend pools prevent connection starvation and allow fine-grained configuration. LIFO ordering improves CPU and network cache locality by reusing recently active connections. Separate pools enable backend-specific tuning.</li>\n<li><strong>Consequences</strong>: Improved cache locality and connection warmth. Requires more memory for pool management structures. Enables sophisticated per-backend configuration and monitoring.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Global Pool</td>\n<td>Simple implementation, automatic load balancing</td>\n<td>Connection starvation, no backend-specific tuning</td>\n</tr>\n<tr>\n<td>Per-Backend FIFO</td>\n<td>Fair connection aging, predictable behavior</td>\n<td>Poor cache locality, potentially stale connections</td>\n</tr>\n<tr>\n<td>Per-Backend LIFO</td>\n<td>Optimal cache locality, warm connection reuse</td>\n<td>May not age connections evenly, complex pool management</td>\n</tr>\n</tbody></table>\n<p>The LIFO strategy proves most effective in practice because recently used connections maintain warm CPU caches, established TCP windows, and active network paths. This warmth translates to measurably better performance for subsequent requests compared to connections that have been idle in the pool for extended periods.</p>\n<h4 id=\"timeout-management-decision\">Timeout Management Decision</h4>\n<blockquote>\n<p><strong>Decision: Timer Wheel with Hierarchical Timeouts</strong></p>\n<ul>\n<li><strong>Context</strong>: The system must efficiently handle timeouts for thousands of concurrent connections without excessive CPU overhead or system call frequency.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Per-connection timer threads</li>\n<li>Single timeout thread with sorted timeout list</li>\n<li>Timer wheel with batched timeout processing</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Timer wheel implementation with hierarchical timeout granularity</li>\n<li><strong>Rationale</strong>: Timer wheels provide O(1) timeout insertion and deletion with efficient batch processing. Hierarchical granularity allows precise short-term timeouts and efficient long-term timeouts. Single timeout thread minimizes synchronization overhead.</li>\n<li><strong>Consequences</strong>: Excellent scalability with connection count. Requires more complex timeout data structures. Enables precise timeout handling with minimal CPU overhead.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Per-Connection Timers</td>\n<td>Simple per-connection logic, precise timing</td>\n<td>Excessive system calls, poor scalability</td>\n</tr>\n<tr>\n<td>Sorted Timeout List</td>\n<td>Simple implementation, good precision</td>\n<td>O(log n) insertion cost, potential lock contention</td>\n</tr>\n<tr>\n<td>Timer Wheel</td>\n<td>O(1) operations, excellent scalability</td>\n<td>Complex implementation, less precise for very short timeouts</td>\n</tr>\n</tbody></table>\n<p>The timer wheel approach scales linearly with connection count and provides batch processing opportunities that significantly reduce CPU overhead. The hierarchical design allows the system to handle both short-term request timeouts (measured in seconds) and long-term keep-alive timeouts (measured in minutes) efficiently within the same data structure.</p>\n<h4 id=\"connection-validation-decision\">Connection Validation Decision</h4>\n<blockquote>\n<p><strong>Decision: Lightweight Socket Validation with Background Health Checking</strong></p>\n<ul>\n<li><strong>Context</strong>: Pooled connections must be validated before reuse to prevent request failures, but validation overhead must not negate the performance benefits of connection pooling.</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>No validation (rely on error handling during use)</li>\n<li>Full HTTP health check before each reuse</li>\n<li>Lightweight socket validation with periodic background checks</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Socket-level validation on reuse combined with background HTTP health checking</li>\n<li><strong>Rationale</strong>: Socket validation is extremely fast (single system call) and catches most connection failures. Background health checking proactively identifies problems without adding request latency. Combination provides reliability without performance penalty.</li>\n<li><strong>Consequences</strong>: Minimal validation overhead during request processing. Requires background health checking infrastructure. Provides good balance of reliability and performance.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No Validation</td>\n<td>Zero validation overhead, maximum performance</td>\n<td>High failure rate on reuse, poor user experience</td>\n</tr>\n<tr>\n<td>Full HTTP Validation</td>\n<td>Comprehensive connection testing, high reliability</td>\n<td>Significant overhead negates pooling benefits</td>\n</tr>\n<tr>\n<td>Lightweight + Background</td>\n<td>Fast validation, proactive problem detection</td>\n<td>Complex implementation, requires background threads</td>\n</tr>\n</tbody></table>\n<p>The lightweight validation approach acknowledges that perfect connection validation would be too expensive to perform on every reuse. Instead, it catches the most common failure modes (closed sockets, network errors) quickly and relies on background processes to handle more subtle problems.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Connection Resource Leaks</strong>\nMany implementations fail to properly clean up connections during error conditions, leading to file descriptor exhaustion and memory leaks. This typically occurs when error handling paths don&#39;t properly close both client and backend file descriptors, or when connection tracking structures aren&#39;t properly removed from hash tables during cleanup. The fix involves implementing comprehensive resource cleanup in a single function that handles all cleanup aspects, and ensuring this function is called from every error path. Use a cleanup checklist: close client socket, close backend socket, free buffers, remove from connection manager, log cleanup completion.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Pool Management</strong>\nMulti-threaded access to connection pools often introduces race conditions where the same connection is returned to multiple requests, or connections are returned to pools multiple times. This occurs because pool acquire/release operations aren&#39;t properly synchronized, or because connection state checks and modifications aren&#39;t atomic. The solution requires protecting all pool operations with appropriate locking mechanisms and ensuring connection state transitions are atomic. Use connection-level state flags to prevent double-release scenarios.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Connection Validation Failures</strong>\nSome implementations acquire connections from pools but don&#39;t properly handle validation failures, leading to requests being sent over broken connections. This happens when developers assume pooled connections are always valid, or when validation functions return false but the calling code doesn&#39;t check the return value. The fix requires checking validation results and implementing fallback logic that either retries with a new connection or returns an appropriate error to the client.</p>\n<p>⚠️ <strong>Pitfall: Improper Timeout Configuration</strong>\nSetting timeouts too aggressively causes premature connection termination under normal load, while setting them too generously allows resource exhaustion during attack scenarios. This typically occurs when timeout values are chosen arbitrarily without considering actual network conditions and backend response characteristics. The solution involves implementing adaptive timeout strategies that adjust based on observed latency patterns, and providing different timeout values for different types of operations (connect, read, write, idle).</p>\n<p>⚠️ <strong>Pitfall: Pool Size Misconfiguration</strong>\nMany implementations set static pool sizes that work well under normal conditions but fail during traffic spikes or backend failures. This happens when pool sizes are based on average traffic rather than peak traffic, or when all backend pools use the same configuration regardless of backend capacity differences. The fix requires implementing dynamic pool sizing based on traffic patterns and backend health, with different pool configurations for different backend servers based on their capacity and performance characteristics.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The Connection Manager represents one of the most performance-critical components in the reverse proxy architecture. Efficient implementation requires careful attention to memory management, system call optimization, and concurrent data structure access patterns.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Loop</td>\n<td>select() system call with blocking I/O</td>\n<td>epoll/kqueue with event-driven architecture</td>\n</tr>\n<tr>\n<td>Connection Storage</td>\n<td>Linear array with O(n) lookup</td>\n<td>Hash table with O(1) connection lookup</td>\n</tr>\n<tr>\n<td>Timeout Management</td>\n<td>Per-connection timer threads</td>\n<td>Timer wheel with batch processing</td>\n</tr>\n<tr>\n<td>Thread Safety</td>\n<td>Global mutex protecting all operations</td>\n<td>Fine-grained locking with per-pool mutexes</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>malloc/free for each connection</td>\n<td>Memory pools with pre-allocated connection objects</td>\n</tr>\n<tr>\n<td>Backend Health Checking</td>\n<td>Simple socket validation</td>\n<td>Active HTTP probes with exponential backoff</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/\n  connection/\n    manager.c              ← Main connection manager implementation\n    manager.h              ← Connection manager public interface\n    pool.c                 ← Connection pool implementation\n    pool.h                 ← Connection pool interface\n    timeout.c              ← Timer wheel timeout implementation\n    timeout.h              ← Timeout management interface\n    connection_test.c      ← Unit tests for connection management\n    pool_test.c            ← Unit tests for connection pooling\n  utils/\n    hashtable.c            ← Hash table implementation for connection lookup\n    timer_wheel.c          ← Timer wheel data structure\n    memory_pool.c          ← Memory pool for connection objects</code></pre></div>\n\n<h4 id=\"connection-manager-infrastructure\">Connection Manager Infrastructure</h4>\n<p>The core Connection Manager infrastructure provides the foundation for connection lifecycle management and pool coordination. This infrastructure handles the complex details of event-driven I/O and resource management, allowing the main proxy logic to focus on request processing.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/epoll.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/socket.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;netinet/in.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;fcntl.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;pthread.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Timer wheel implementation for efficient timeout management</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> TimerWheel {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> TimerSlot</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\"> slots;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> slot_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> current_slot;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> slot_duration;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> wheel_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} TimerWheel;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> TimerSlot {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\"> connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> connection_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> capacity;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} TimerSlot;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize timer wheel with specified granularity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">TimerWheel</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> timer_wheel_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> slots</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">time_t</span><span style=\"color:#FFAB70\"> slot_duration</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TimerWheel</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> wheel </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(TimerWheel));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">wheel) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wheel->slots </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(slots, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(TimerSlot</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wheel->slot_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> slots;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wheel->current_slot </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wheel->slot_duration </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> slot_duration;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">wheel->wheel_mutex, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> slots; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wheel->slots[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(TimerSlot));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wheel->slots[i]->connections </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wheel->slots[i]->connection_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        wheel->slots[i]->capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> wheel;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Connection pool implementation with per-backend management</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> ConnectionPool {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> backend;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\"> idle_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> idle_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> active_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> pool_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_cond_t</span><span style=\"color:#E1E4E8\"> pool_condition;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_health_check;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ConnectionPool;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize connection pool for specific backend server</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ConnectionPool</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> connection_pool_create</span><span style=\"color:#E1E4E8\">(BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> max_connections</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionPool</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> pool </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(ConnectionPool));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">pool) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pool->backend </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> backend;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pool->idle_connections </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(max_connections, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pool->idle_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pool->max_connections </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_connections;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pool->active_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    pool->last_health_check </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">pool->pool_mutex, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_cond_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">pool->pool_condition, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> pool;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Connection manager main structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> ConnectionManager {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> epoll_fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> connections;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionPool</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\"> backend_pools;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> pool_count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TimerWheel</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> timeout_wheel;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> timeout_thread;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> manager_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    volatile</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ConnectionManager;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize connection manager with event-driven I/O</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> connection_manager_create</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(ConnectionManager));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">manager) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Create epoll instance for event-driven I/O</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    manager->epoll_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_create1</span><span style=\"color:#E1E4E8\">(EPOLL_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (manager->epoll_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(manager);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Initialize connection tracking hash table</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    manager->connections </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> hashtable_create</span><span style=\"color:#E1E4E8\">(config->max_connections </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Create connection pools for each backend server</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    manager->pool_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config->backend_count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    manager->backend_pools </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(config->backend_count, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(ConnectionPool</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> config->backend_count; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        manager->backend_pools[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> connection_pool_create</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            &#x26;</span><span style=\"color:#E1E4E8\">config->backends[i], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            config->pool_max_connections</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        );</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Initialize timeout management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    manager->timeout_wheel </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> timer_wheel_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">3600</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\"> // 1-hour wheel with 1-second slots</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    manager->running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">manager->manager_mutex, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Start background timeout processing thread</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">manager->timeout_thread, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, timeout_processor, manager);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> manager;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-connection-management-logic\">Core Connection Management Logic</h4>\n<p>The core connection management functions implement the sophisticated state machine and resource tracking required for high-performance connection handling.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Accept new client connection and initialize state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> connection_manager_accept_client</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> listen_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Accept incoming connection using accept4() with SOCK_NONBLOCK flag</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Set TCP_NODELAY socket option to disable Nagle algorithm</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Create new Connection structure and initialize all fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Generate unique connection_id and set initial state to CONNECTION_IDLE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Add connection to epoll interest list for EPOLLIN events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Insert connection into manager's connection hash table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Schedule initial timeout using timer wheel</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Log connection acceptance with client address information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &#x26;flag, sizeof(flag))</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Connection ID can be generated using atomic increment counter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Acquire backend connection from pool or create new one</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> connection_manager_acquire_backend</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                             BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                             int</span><span style=\"color:#FFAB70\"> timeout_ms</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Find connection pool for specified backend server</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Lock pool mutex to ensure thread-safe access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check if idle connection is available in pool</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If idle connection available, validate it's still healthy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If no idle connection and under max limit, create new connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If at max limit, wait on condition variable or return NULL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Mark selected connection as active and remove from idle list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Update pool statistics and unlock mutex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use pthread_mutex_lock() and pthread_cond_timedwait() for waiting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Connection validation can use MSG_PEEK to check socket status</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Return backend connection to pool for reuse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> connection_manager_release_backend</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                      Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> connection</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                      bool</span><span style=\"color:#FFAB70\"> reusable</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Find connection pool based on connection's backend server</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Lock pool mutex for thread-safe modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If connection is reusable and pool not full, add to idle list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If not reusable or pool full, close connection immediately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update pool statistics (decrement active count)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Signal waiting threads using condition variable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Schedule connection for timeout tracking if pooled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Unlock pool mutex and log pool operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use LIFO ordering when adding to idle list for cache locality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Check connection->keep_alive flag to determine reusability</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Process connection state transitions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> connection_manager_handle_event</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> connection</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                   uint32_t</span><span style=\"color:#FFAB70\"> events</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check event type (EPOLLIN, EPOLLOUT, EPOLLERR, EPOLLHUP)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Based on current connection state, determine appropriate action</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For EPOLLIN in IDLE state, transition to READING_REQUEST</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: For EPOLLIN in READING_RESPONSE, continue response processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: For EPOLLOUT in WRITING_RESPONSE, continue response transmission</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: For error events, transition to CLOSING state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Update connection's last_activity timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: If state transition complete, update epoll interest list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use switch statement based on connection->state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Error events (EPOLLERR, EPOLLHUP) always require connection cleanup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Clean up connection and release all resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> connection_manager_close_connection</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> connection</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Remove connection from epoll interest list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Remove connection from timeout tracking (timer wheel)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Close client file descriptor if open</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Close backend file descriptor if open (return to pool if applicable)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Free request and response buffers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Remove connection from manager's hash table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Free connection structure memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Log connection closure with lifetime statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Always check if file descriptors are valid (>= 0) before closing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use hashtable_remove() to clean up connection tracking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"connection-pool-management-implementation\">Connection Pool Management Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Background health checking for pooled connections</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> pool_health_checker</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)arg;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (manager->running) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Sleep for configured health check interval</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Iterate through all backend connection pools</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: For each pool, lock mutex and check idle connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Validate each idle connection using lightweight socket check</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Remove any unhealthy connections from pool</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 6: Log health check results and pool statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 7: Unlock pool mutex before moving to next pool</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 8: Implement exponential backoff for pools with repeated failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use recv(fd, buffer, 0, MSG_PEEK) for non-destructive socket validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Track consecutive health check failures per pool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Timeout processing using timer wheel</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> timeout_processor</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)arg;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TimerWheel</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> wheel </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> manager->timeout_wheel;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (manager->running) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Sleep for timer wheel slot duration (typically 1 second)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Lock timer wheel mutex for thread-safe access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Get current time and calculate which slot to process</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Process all connections in the current timeout slot</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Check each connection's last_activity against timeout limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 6: Close connections that have exceeded their timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 7: Move wheel to next slot and unlock mutex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 8: Log timeout processing statistics periodically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use time(NULL) - connection->last_activity for age calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Different connection states may have different timeout values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Checkpoint: Basic Connection Handling</strong>\nAfter implementing basic connection acceptance and client communication:</p>\n<ul>\n<li>Start the proxy server: <code>./proxy -c proxy.conf</code></li>\n<li>Use netcat to connect: <code>nc localhost 8080</code></li>\n<li>Send HTTP request: <code>GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n</code></li>\n<li>Expected behavior: Connection accepted, request forwarded to backend, response returned</li>\n<li>Verify: Check logs for connection lifecycle events (accept, forward, close)</li>\n<li>Debug signs: If connections hang, check epoll event handling; if responses are incomplete, verify buffer management</li>\n</ul>\n<p><strong>Milestone 3 Checkpoint: Connection Pooling</strong>\nAfter implementing connection pool management:</p>\n<ul>\n<li>Configure multiple backend servers in proxy configuration</li>\n<li>Send burst of requests: <code>for i in {1..100}; do curl -s http://localhost:8080/ &amp; done</code></li>\n<li>Expected behavior: Connections reused across requests, pool statistics showing reuse</li>\n<li>Verify: Monitor pool metrics showing idle/active connection counts</li>\n<li>Debug signs: If performance doesn&#39;t improve, check pool acquisition logic; if connections leak, verify release operations</li>\n</ul>\n<h4 id=\"debugging-connection-management-issues\">Debugging Connection Management Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connection count grows indefinitely</td>\n<td>Resource leak in cleanup path</td>\n<td>Monitor <code>/proc/PID/fd/</code> count and compare with active connections</td>\n<td>Add cleanup validation in error paths, use resource tracking</td>\n</tr>\n<tr>\n<td>High latency despite pooling</td>\n<td>Pool validation too expensive</td>\n<td>Profile connection acquisition time</td>\n<td>Implement lightweight socket validation, reduce health check frequency</td>\n</tr>\n<tr>\n<td>Intermittent connection failures</td>\n<td>Stale connections in pool</td>\n<td>Check backend server connection logs</td>\n<td>Improve connection validation, reduce pool idle timeout</td>\n</tr>\n<tr>\n<td>Memory usage grows over time</td>\n<td>Connection structures not freed</td>\n<td>Use memory profiler to track allocations</td>\n<td>Ensure connection_destroy() called in all cleanup paths</td>\n</tr>\n<tr>\n<td>Deadlock under high load</td>\n<td>Lock ordering issues in pools</td>\n<td>Use thread debugger to identify lock contention</td>\n<td>Implement consistent lock ordering, reduce lock scope</td>\n</tr>\n<tr>\n<td>Backend overload</td>\n<td>Too many concurrent connections</td>\n<td>Monitor backend connection counts</td>\n<td>Implement connection limiting per backend, add backpressure</td>\n</tr>\n</tbody></table>\n<p>This comprehensive Connection Manager implementation provides the foundation for efficient request processing while maintaining the sophisticated resource management required for production reverse proxy deployments.</p>\n<h2 id=\"load-balancer-component\">Load Balancer Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2 (Load Balancing) - implements request distribution across backend servers with health checking and dynamic backend management.</p>\n</blockquote>\n<p>Think of a load balancer as the dispatcher at a busy restaurant during peak hours. When customers arrive, the dispatcher doesn&#39;t just randomly assign them to tables - they consider which servers have the lightest workload, which tables are currently available, and which servers might be on break due to illness. The dispatcher keeps track of each server&#39;s current capacity and health status, ensuring that no single server gets overwhelmed while others sit idle. Similarly, our load balancer component acts as this intelligent dispatcher, examining each incoming request and making smart decisions about which backend server should handle it based on current load, server health, and configured distribution policies.</p>\n<p>The <strong>load balancer component</strong> sits at the heart of our reverse proxy&#39;s request distribution logic, responsible for selecting the most appropriate backend server for each incoming client request. This component must balance multiple competing objectives: distributing load evenly across available servers, respecting server capacity differences, avoiding unhealthy servers, and maintaining session affinity where required. Unlike a simple random selection, the load balancer maintains sophisticated state about each backend server, continuously monitoring their health and performance characteristics to make informed routing decisions.</p>\n<p>The challenge lies in implementing this intelligence efficiently - the load balancer operates in the critical path of every request, so any slowdown here directly impacts client response times. The component must make routing decisions in microseconds while maintaining accurate load statistics, performing health checks, and handling dynamic backend changes without dropping requests. This requires careful algorithm selection, efficient data structures, and robust error handling to ensure that backend failures don&#39;t cascade into client-visible outages.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fload-balancing-flowchart.svg\" alt=\"Load Balancing Decision Flow\"></p>\n<h3 id=\"load-balancing-algorithms\">Load Balancing Algorithms</h3>\n<p>The foundation of effective load balancing lies in choosing the right algorithm for your specific traffic patterns and backend characteristics. Each algorithm makes different assumptions about server capabilities, request costs, and client behavior, leading to vastly different performance outcomes under varying conditions.</p>\n<p><strong>Round-robin algorithm</strong> represents the simplest approach to load distribution, cycling through available backend servers in a fixed order regardless of their current load or capacity. Think of it like dealing cards from a deck - each backend gets the next request in sequence, wrapping back to the first server after reaching the last one. While this approach ensures perfectly even distribution over time, it assumes all servers have identical capacity and all requests require similar processing resources.</p>\n<p>The round-robin implementation maintains a simple counter that tracks the index of the last selected server within the available backend list. For each new request, the algorithm increments this counter modulo the number of healthy backends, ensuring automatic wraparound when reaching the end of the list. This stateless approach makes round-robin extremely fast and memory-efficient, requiring only a single integer of state per upstream group.</p>\n<p>However, round-robin&#39;s simplicity becomes a liability when servers have different capabilities or when request processing times vary significantly. A powerful server with twice the CPU cores of its peers will receive the same number of requests as the weaker machines, leading to suboptimal resource utilization. Similarly, if some requests trigger expensive database queries while others serve cached content, the server unlucky enough to receive multiple expensive requests in sequence may become overloaded while others remain idle.</p>\n<p><strong>Least-connections algorithm</strong> addresses round-robin&#39;s load blindness by tracking the number of active connections to each backend server and preferentially routing new requests to the server with the fewest current connections. This approach assumes that connection count serves as a reasonable proxy for server load - servers handling more concurrent requests are likely under higher load than those with fewer active connections.</p>\n<p>The algorithm maintains a connection counter for each backend server, incrementing the counter when establishing a new connection and decrementing it when connections close or requests complete. For each incoming request, the load balancer scans all healthy backends to find the server with the minimum connection count. In case of ties, the algorithm can break them using secondary criteria such as server ID for deterministic behavior or random selection for additional load spreading.</p>\n<p>Least-connections works particularly well for applications with long-lived connections or requests with highly variable processing times. Web applications that mix quick static file requests with expensive API calls benefit significantly from this approach, as servers can naturally shed load by completing requests quickly rather than being forced to accept new work regardless of their current burden.</p>\n<p>The algorithm does introduce additional complexity and state management overhead compared to round-robin. Each connection establishment and termination requires updating the connection counters in a thread-safe manner, and the backend selection process requires examining all available servers rather than simple arithmetic. However, this overhead is typically insignificant compared to the performance benefits of better load distribution.</p>\n<p><strong>Weighted round-robin algorithm</strong> extends basic round-robin by allowing administrators to assign different weights to backend servers based on their relative capacity or performance characteristics. A server with weight 3 will receive three times as many requests as a server with weight 1, allowing the load balancer to account for hardware differences, geographic proximity, or other capacity factors.</p>\n<p>The implementation uses a more sophisticated counter system that tracks both the current server index and the number of requests sent to that server within its weight allocation. When a server receives its full allocation of requests (equal to its weight), the algorithm advances to the next server and resets the request counter. This ensures that over any complete cycle, each server receives requests proportional to its configured weight.</p>\n<p>Consider a backend pool with three servers having weights 3, 2, and 1 respectively. The distribution pattern over six requests would be: Server A (weight 3) receives requests 1, 2, 3; Server B (weight 2) receives requests 4, 5; Server C (weight 1) receives request 6. This pattern repeats for subsequent request batches, maintaining the 3:2:1 ratio over time while preserving the round-robin property of cycling through all servers.</p>\n<p>Weighted round-robin proves invaluable in heterogeneous environments where backend servers have significantly different capabilities. Cloud deployments often mix instance types with different CPU, memory, and network characteristics, making it critical to account for these differences in load distribution. The algorithm also supports gradual traffic shifting scenarios, such as blue-green deployments where new server versions initially receive low weights that gradually increase as confidence grows.</p>\n<p>The following table compares the characteristics of each load balancing algorithm:</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Complexity</th>\n<th>Memory Usage</th>\n<th>Load Awareness</th>\n<th>Hardware Heterogeneity</th>\n<th>Session Affinity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Round-Robin</td>\n<td>O(1)</td>\n<td>Minimal</td>\n<td>None</td>\n<td>Poor</td>\n<td>Difficult</td>\n</tr>\n<tr>\n<td>Least-Connections</td>\n<td>O(n)</td>\n<td>Moderate</td>\n<td>Good</td>\n<td>Good</td>\n<td>Natural</td>\n</tr>\n<tr>\n<td>Weighted Round-Robin</td>\n<td>O(1)</td>\n<td>Minimal</td>\n<td>None</td>\n<td>Excellent</td>\n<td>Moderate</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Primary Load Balancing Algorithm Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: The reverse proxy must efficiently distribute requests across backend servers while supporting different server capacities and providing good performance under various traffic patterns.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Round-robin only (simplest implementation)</li>\n<li>Least-connections only (best load awareness)</li>\n<li>Multiple algorithms with runtime selection (maximum flexibility)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement all three algorithms with runtime configuration selection</li>\n<li><strong>Rationale</strong>: Different applications have vastly different characteristics - some benefit from round-robin&#39;s simplicity and predictability, others need least-connections&#39; load awareness, and heterogeneous environments require weighted distribution. Supporting multiple algorithms allows the reverse proxy to adapt to diverse deployment scenarios.</li>\n<li><strong>Consequences</strong>: Increases implementation complexity and testing surface area, but provides maximum deployment flexibility and better performance across diverse workloads.</li>\n</ul>\n</blockquote>\n<h3 id=\"health-checking-system\">Health Checking System</h3>\n<p>Health checking forms the critical foundation that prevents the load balancer from routing requests to failed or degraded backend servers. Without robust health checking, even the most sophisticated load balancing algorithm becomes counterproductive, as it may consistently route requests to servers that cannot fulfill them, leading to cascading failures and poor user experience.</p>\n<p>Think of health checking as the reverse proxy&#39;s immune system - it continuously monitors the health of each backend server, detecting problems before they impact client requests, and automatically removing unhealthy servers from the active pool while attempting to rehabilitate them. This system must balance responsiveness (detecting failures quickly) with stability (avoiding false positives that unnecessarily remove healthy servers).</p>\n<p><strong>Active health checking</strong> proactively monitors backend server health by periodically sending synthetic health check requests and evaluating the responses. This approach provides the most reliable health assessment because it exercises the same code paths that real client requests would use, detecting application-level failures that might not be visible through simple network connectivity tests.</p>\n<p>The health checker maintains a separate connection pool for health check requests, isolated from the main request processing to ensure that health checks continue even when the backend server is under heavy load or experiencing connection pool exhaustion. Each backend server receives health check requests at configurable intervals, typically ranging from 5 to 30 seconds depending on the desired failure detection speed and the overhead tolerance.</p>\n<p>Health check requests should target a lightweight endpoint specifically designed for health monitoring rather than expensive application routes. Many applications provide dedicated health check endpoints (such as <code>/health</code> or <code>/ping</code>) that perform essential system checks without the overhead of full request processing. These endpoints typically verify database connectivity, cache availability, and other critical dependencies while returning simple success indicators.</p>\n<p>The health checker evaluates multiple criteria when determining server health status. HTTP response status codes provide the primary indicator - responses in the 200-299 range typically indicate healthy servers, while 5xx errors suggest server problems. However, the system also monitors response times, as servers that respond correctly but very slowly may indicate resource exhaustion or performance degradation that warrants load reduction.</p>\n<p><strong>Failure threshold logic</strong> prevents transient network issues or temporary server hiccups from unnecessarily removing healthy servers from the active pool. Rather than marking servers unhealthy after a single failed health check, the system implements configurable failure thresholds that require multiple consecutive failures before changing server status.</p>\n<p>A typical failure threshold configuration might require three consecutive health check failures before marking a server unhealthy, and five consecutive successes before returning it to service. This asymmetric threshold design reflects the principle that removing servers from service should be conservative (to avoid unnecessary capacity reduction) while returning servers to service should be even more conservative (to avoid repeatedly adding and removing flapping servers).</p>\n<p>The health checking system maintains detailed state for each backend server, tracking not only the current health status but also the history of recent health check results, failure counts, and timing information. This rich state enables sophisticated health assessment logic that can detect patterns such as intermittent failures, gradual performance degradation, or partial service degradation.</p>\n<table>\n<thead>\n<tr>\n<th>Health Check Parameter</th>\n<th>Typical Range</th>\n<th>Purpose</th>\n<th>Impact of Too Low</th>\n<th>Impact of Too High</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Check Interval</td>\n<td>5-30 seconds</td>\n<td>Detection speed vs overhead</td>\n<td>Higher server load</td>\n<td>Slower failure detection</td>\n</tr>\n<tr>\n<td>Timeout</td>\n<td>1-10 seconds</td>\n<td>Unresponsive server detection</td>\n<td>False positives</td>\n<td>Slow detection of hanging servers</td>\n</tr>\n<tr>\n<td>Failure Threshold</td>\n<td>2-5 failures</td>\n<td>Stability vs responsiveness</td>\n<td>Flapping servers</td>\n<td>Slow unhealthy server removal</td>\n</tr>\n<tr>\n<td>Success Threshold</td>\n<td>3-7 successes</td>\n<td>Recovery confidence</td>\n<td>Premature server return</td>\n<td>Slow healthy server recovery</td>\n</tr>\n</tbody></table>\n<p><strong>Graceful degradation</strong> ensures that health check failures don&#39;t immediately impact in-flight requests to the affected backend server. When a server transitions from healthy to unhealthy status, the load balancer stops routing new requests to that server but allows existing connections and requests to complete naturally. This approach prevents abrupt connection termination that could cause client errors while still protecting against sending additional load to problematic servers.</p>\n<p>The system implements a grace period during which unhealthy servers remain in a &quot;draining&quot; state, continuing to handle existing connections while being excluded from new request routing. The duration of this grace period balances client experience (allowing time for requests to complete) with failure isolation (limiting exposure to a potentially failing server).</p>\n<p>For servers that fail health checks but maintain existing connections, the connection manager monitors these connections more aggressively, applying shorter timeouts and more aggressive error detection to prevent hanging connections from consuming resources indefinitely.</p>\n<blockquote>\n<p><strong>Decision: Health Check Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Backend servers can fail in various ways (network issues, application crashes, performance degradation), and the load balancer must detect these failures quickly while avoiding false positives that unnecessarily reduce capacity.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Active HTTP health checks only</li>\n<li>Passive failure detection based on request failures</li>\n<li>Combined active and passive health checking</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement active HTTP health checks with passive failure detection as a backup</li>\n<li><strong>Rationale</strong>: Active health checks provide proactive failure detection and can catch issues before they impact client requests. Passive detection serves as a safety net for failures that might not be caught by periodic health checks, such as servers that pass health checks but fail real requests due to race conditions or resource exhaustion.</li>\n<li><strong>Consequences</strong>: Requires additional implementation complexity and generates constant background traffic to backend servers, but provides the most reliable failure detection and fastest recovery times.</li>\n</ul>\n</blockquote>\n<h3 id=\"load-balancing-decisions\">Load Balancing Decisions</h3>\n<p>The architecture of the load balancing component requires several critical design decisions that fundamentally impact performance, reliability, and operational characteristics. These decisions interact with each other in complex ways, making it essential to understand the trade-offs and select options that align with the overall system goals.</p>\n<p><strong>Backend selection synchronization</strong> addresses the challenge of making load balancing decisions safely in a multi-threaded environment where multiple worker threads may simultaneously attempt to select backend servers for different client requests. The naive approach of protecting the entire backend selection process with a single mutex would create a severe bottleneck, as every request would need to acquire the same lock before proceeding.</p>\n<p>The selected approach uses fine-grained locking with separate mutexes for different aspects of the backend selection process. The backend server list itself is protected by a read-write lock that allows multiple threads to read the list simultaneously while ensuring exclusive access for updates when servers are added, removed, or change health status. Load balancing algorithm state (such as connection counters for least-connections or round-robin positions) uses separate synchronization primitives appropriate to each algorithm&#39;s needs.</p>\n<p>Round-robin algorithm state uses atomic integer operations for the server index counter, eliminating lock contention entirely for the common case of backend selection. Least-connections algorithm requires more complex synchronization because it needs to both read connection counts across all servers and update the selected server&#39;s count, which is handled through a combination of atomic operations for individual counters and brief critical sections for the selection logic.</p>\n<blockquote>\n<p><strong>Decision: Backend Selection Synchronization Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple worker threads need to select backend servers simultaneously, and the backend selection process is in the critical path for request processing performance.</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Single global mutex protecting all backend selection</li>\n<li>Per-algorithm synchronization strategies with minimal locking</li>\n<li>Lock-free algorithms using atomic operations and hazard pointers</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement per-algorithm synchronization with atomic operations where possible and fine-grained locking where necessary</li>\n<li><strong>Rationale</strong>: Single global mutex would create unacceptable performance bottlenecks under high concurrency. Lock-free algorithms provide the best performance but significantly increase implementation complexity and debugging difficulty. Per-algorithm synchronization strikes the right balance of performance and maintainability.</li>\n<li><strong>Consequences</strong>: Requires careful implementation of each algorithm&#39;s synchronization needs and thorough testing for race conditions, but provides good performance scaling with multiple worker threads.</li>\n</ul>\n</blockquote>\n<p><strong>Health check integration</strong> determines how health status changes propagate to the load balancing algorithm and how quickly the system responds to backend server state transitions. The health checking system operates on a different timeline than request processing - health checks occur every few seconds while request routing happens thousands of times per second.</p>\n<p>The integration design uses event-driven health status updates where health check results trigger immediate updates to the load balancing algorithm&#39;s view of available servers. When a server transitions from healthy to unhealthy, the health checker immediately removes it from all load balancing algorithms&#39; active server lists. Conversely, when an unhealthy server recovers, it gets added back to the active lists with appropriate state initialization (such as resetting connection counters for least-connections).</p>\n<p>This event-driven approach ensures that load balancing decisions always reflect the most current health information without requiring the request processing path to perform health status checks. The alternative of having each request check server health status would introduce unacceptable latency and complexity to the critical path.</p>\n<p><strong>Server weight management</strong> for weighted round-robin algorithm requires careful consideration of how weight changes propagate and when they take effect. Changing server weights while the algorithm is actively processing requests could disrupt the distribution pattern or create inconsistent behavior.</p>\n<p>The implementation uses a two-phase weight update process where new weights are staged in a separate configuration structure and then atomically activated during the next algorithm cycle completion. This approach ensures that weight changes take effect cleanly without disrupting ongoing request distribution patterns or creating race conditions between configuration updates and request processing.</p>\n<p>The system also supports dynamic weight adjustment based on server performance metrics, allowing weights to automatically decrease for servers showing signs of stress (such as increasing response times) and increase for servers with excess capacity. This adaptive weighting provides a bridge between the simplicity of weighted round-robin and the load awareness of least-connections.</p>\n<table>\n<thead>\n<tr>\n<th>Synchronization Approach</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Best Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Global Mutex</td>\n<td>Simple implementation, Easy reasoning</td>\n<td>Severe performance bottleneck</td>\n<td>Low-concurrency deployments</td>\n</tr>\n<tr>\n<td>Per-Algorithm Locks</td>\n<td>Balanced complexity/performance</td>\n<td>Still some lock contention</td>\n<td>Most production deployments</td>\n</tr>\n<tr>\n<td>Lock-Free Atomic</td>\n<td>Maximum performance</td>\n<td>High implementation complexity</td>\n<td>Ultra-high performance requirements</td>\n</tr>\n</tbody></table>\n<p><strong>Error handling and fallback logic</strong> defines how the load balancer behaves when all backend servers are unhealthy or when the selected backend server fails after being chosen but before the request is forwarded. These edge cases require careful handling to provide graceful degradation rather than complete service failure.</p>\n<p>When all backend servers in a pool are marked unhealthy, the load balancer implements a &quot;best effort&quot; fallback mode where it continues routing requests to the least-recently-failed servers while continuing aggressive health checking. This approach recognizes that health check failures might represent false positives due to network issues or temporary overload, and that attempting to serve requests is better than refusing all traffic.</p>\n<p>The system maintains a &quot;failure recency&quot; ranking for unhealthy servers, preferring servers that failed more recently (and thus might have a higher chance of recovery) over servers that have been failing for extended periods. This heuristic helps identify servers that might be experiencing transient issues versus those with more serious problems.</p>\n<p>For requests that fail after backend selection (such as connection establishment failures or immediate HTTP errors), the load balancer implements limited retry logic with different backend selection. A request that fails to connect to the initially selected backend server will be retried against up to two additional servers before returning an error to the client. This retry logic uses an exponential backoff delay to avoid overwhelming failing servers while still providing reasonable client response times.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Ignoring Connection State During Server Health Transitions</strong></p>\n<p>Many implementations make the mistake of immediately updating load balancing algorithm state when servers transition between healthy and unhealthy status, without considering the impact on existing connections to those servers. When a server becomes unhealthy, naive implementations might immediately mark all its connections as bad and close them, causing unnecessary client errors for requests that could have completed successfully.</p>\n<p>The correct approach requires coordinating between the health checking system and the connection manager to handle server state transitions gracefully. When a server becomes unhealthy, new requests should stop being routed to it, but existing connections should be allowed to complete normally unless they individually show signs of failure. This requires the load balancer to distinguish between &quot;don&#39;t send new requests here&quot; and &quot;this server is completely unusable.&quot;</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Connection Count Updates</strong></p>\n<p>The least-connections algorithm requires careful synchronization when updating connection counts, particularly during rapid connection establishment and termination. A common mistake is updating connection counts at the wrong time in the connection lifecycle, leading to inaccurate counts that cause poor load distribution or even integer underflow when decrementing counts for connections that weren&#39;t properly registered.</p>\n<p>Connection counts must be updated atomically and at precisely defined points in the connection lifecycle: increment when a connection is successfully established and assigned to a backend server, decrement when the connection is closed or returned to the connection pool. The count update must be paired with the actual connection state change to prevent race conditions where the count and reality diverge.</p>\n<p>⚠️ <strong>Pitfall: Not Handling Backend List Changes During Request Processing</strong></p>\n<p>Backend server lists can change dynamically as servers are added, removed, or change health status. Implementations often fail to properly handle these changes when they occur during active request processing, leading to array bounds errors, null pointer dereferences, or routing requests to servers that no longer exist.</p>\n<p>The solution requires implementing proper read-copy-update semantics for the backend server list, where request processing threads work with stable snapshots of the server list while background threads can safely update the master list. This prevents request processing from being impacted by concurrent backend list modifications while ensuring that changes eventually become visible to new requests.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The load balancer component builds upon the connection manager and HTTP parser to provide intelligent request distribution across backend servers. This component operates entirely within the request processing critical path, so implementation choices directly impact overall proxy performance.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Algorithm Selection</td>\n<td>Single round-robin implementation</td>\n<td>Pluggable algorithm interface with runtime selection</td>\n</tr>\n<tr>\n<td>Health Checking</td>\n<td>Synchronous health checks in main loop</td>\n<td>Dedicated health check thread with async updates</td>\n</tr>\n<tr>\n<td>Backend Configuration</td>\n<td>Static configuration file</td>\n<td>Dynamic backend management with configuration reload</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Simple counters</td>\n<td>Detailed per-backend performance metrics</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>internal/loadbalancer/\n  loadbalancer.go          ← main LoadBalancer struct and public interface\n  algorithms.go            ← load balancing algorithm implementations\n  healthcheck.go           ← health checking system and backend monitoring\n  backend.go               ← BackendServer management and configuration\n  metrics.go               ← load balancing metrics and statistics\n  loadbalancer_test.go     ← unit tests for load balancing logic\n  algorithms_test.go       ← algorithm-specific test cases\n  healthcheck_test.go      ← health checking test scenarios</code></pre></div>\n\n<p><strong>Load Balancer Infrastructure Code:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// LoadBalancer manages request distribution across backend servers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\"> backends;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> backend_count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LoadBalancingAlgorithm algorithm;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Algorithm-specific state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> rr_current_index;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t*</span><span style=\"color:#E1E4E8\"> connection_counts;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t*</span><span style=\"color:#E1E4E8\"> weights;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t*</span><span style=\"color:#E1E4E8\"> current_weights;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Health checking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> health_check_thread;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool*</span><span style=\"color:#E1E4E8\"> backend_healthy;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t*</span><span style=\"color:#E1E4E8\"> last_health_check;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t*</span><span style=\"color:#E1E4E8\"> last_failure_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t*</span><span style=\"color:#E1E4E8\"> failure_count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Synchronization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_rwlock_t</span><span style=\"color:#E1E4E8\"> backends_lock;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> state_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> health_check_interval;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> health_check_timeout;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> failure_threshold;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> success_threshold;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LoadBalancer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Backend server configuration and runtime state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> host</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> weight;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> enabled;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Health check configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> health_check_path</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> health_check_port;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Runtime metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> active_connections;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> total_requests;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> failed_requests;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    double</span><span style=\"color:#E1E4E8\"> avg_response_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_success_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_failure_time;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} BackendServer;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Load balancing algorithm enumeration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_LEAST_CONNECTIONS,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_WEIGHTED_ROUND_ROBIN,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_IP_HASH</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LoadBalancingAlgorithm;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> loadbalancer_create</span><span style=\"color:#E1E4E8\">(BackendServer</span><span style=\"color:#F97583\">**</span><span style=\"color:#FFAB70\"> backends</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">, LoadBalancingAlgorithm </span><span style=\"color:#FFAB70\">algorithm</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> loadbalancer_destroy</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> loadbalancer_start</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> loadbalancer_stop</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> loadbalancer_select_backend</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> loadbalancer_update_connection_count</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> delta</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> loadbalancer_is_backend_healthy</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Core Load Balancing Algorithm Skeletons:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// SelectBackendRoundRobin selects the next backend using round-robin algorithm.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// This algorithm cycles through healthy backends in order, providing even distribution.</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> select_backend_round_robin</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Acquire read lock on backends list to ensure stable access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Count number of healthy backends in current list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If no healthy backends available, return NULL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Use atomic increment on rr_current_index to get next position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Modulo operation to wrap around when reaching end of healthy backends</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Scan from current position to find next healthy backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Handle wraparound case if no healthy backends found after current position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Release read lock and return selected backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use __atomic_fetch_add for thread-safe index increment</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SelectBackendLeastConnections selects backend with minimum active connections.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// This algorithm examines all healthy backends to find the least loaded server.</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> select_backend_least_connections</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Acquire read lock on backends list for stable access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Initialize min_connections to UINT32_MAX and selected_backend to NULL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Iterate through all backends in the list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Skip backends that are marked unhealthy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Read current connection count using atomic operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Compare with current minimum, update if lower</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Handle tie-breaking by preferring backends with lower index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Increment selected backend's connection count atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Release read lock and return selected backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use __atomic_load for reading connection counts safely</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SelectBackendWeightedRoundRobin selects backend based on configured weights.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// This algorithm ensures backends receive requests proportional to their weights.</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> select_backend_weighted_round_robin</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Acquire read lock on backends list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Find backend with highest current_weight among healthy backends</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Select backend with maximum current_weight value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Decrease selected backend's current_weight by sum of all backend weights</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Increase all healthy backends' current_weight by their configured weight</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Handle edge case where all backends have zero weight</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Release read lock and return selected backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: This implements the \"smooth weighted round-robin\" algorithm</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Health Checking System Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// HealthCheckBackend performs a single health check against specified backend.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Returns true if backend responds successfully, false otherwise.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> health_check_backend</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create TCP socket with non-blocking flag</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Set socket timeout using SO_RCVTIMEO and SO_SNDTIMEO</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Connect to backend's health check port (or main port if not specified)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Send HTTP GET request to health check path</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Read HTTP response with timeout handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Parse response status code from response line</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Consider 200-299 status codes as healthy, others as unhealthy</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Close socket and return health status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use poll() or select() for timeout handling during connect and read</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HealthCheckLoop runs continuously in background thread checking all backends.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// This function implements the main health checking logic with configurable intervals.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> health_check_loop</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> lb </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)arg;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Loop while lb->running flag is true</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Sleep for health_check_interval seconds (use nanosleep for precision)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Iterate through all configured backends</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Skip disabled backends in configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Perform health check using health_check_backend function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Update failure/success counts based on health check result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Apply failure_threshold and success_threshold logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Update backend_healthy array when status changes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Log health status changes for operational visibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 10: Update last_health_check timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use compare-and-swap for atomic backend status updates</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// UpdateBackendHealth changes backend health status with proper synchronization.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// This function handles the transition between healthy and unhealthy states.</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> update_backend_health</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> backend_index</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#FFAB70\"> healthy</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Acquire write lock on backends to ensure exclusive access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check if health status is actually changing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update backend_healthy array with new status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Reset failure/success counters when status changes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update last_failure_time or last_success_time as appropriate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Log status change with backend details for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Release write lock</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Only log when status actually changes to avoid log spam</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the load balancer component, verify correct operation by:</p>\n<ol>\n<li><p><strong>Algorithm Testing</strong>: Start the proxy with different load balancing algorithms and send multiple requests. Observe backend selection patterns:</p>\n<ul>\n<li>Round-robin should cycle through backends evenly</li>\n<li>Least-connections should prefer backends with fewer active connections</li>\n<li>Weighted round-robin should respect configured backend weights</li>\n</ul>\n</li>\n<li><p><strong>Health Check Verification</strong>: Stop one backend server and observe health check behavior:</p>\n<ul>\n<li>Requests should stop routing to the failed backend within one health check interval</li>\n<li>Backend should return to service after restarting and passing success threshold</li>\n<li>Check logs for health status change notifications</li>\n</ul>\n</li>\n<li><p><strong>Concurrent Access Testing</strong>: Use load testing tools to send many concurrent requests:</p>\n<ul>\n<li>No race condition errors or crashes should occur</li>\n<li>Backend selection should remain fair under high load</li>\n<li>Health checking should continue operating during heavy traffic</li>\n</ul>\n</li>\n<li><p><strong>Configuration Changes</strong>: Test dynamic backend configuration updates:</p>\n<ul>\n<li>Adding new backends should start receiving requests immediately</li>\n<li>Removing backends should drain existing connections gracefully</li>\n<li>Weight changes should affect distribution in next algorithm cycle</li>\n</ul>\n</li>\n</ol>\n<p>Expected behavior: The load balancer should distribute requests according to the configured algorithm, automatically remove failed backends from service, and handle high concurrency without race conditions or performance degradation.</p>\n<h2 id=\"cache-engine-component\">Cache Engine Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 4 (Caching) - implements HTTP response caching with proper cache-control header handling, TTL management, and cache invalidation strategies.</p>\n</blockquote>\n<p>Think of the cache engine as a smart librarian for your reverse proxy. Just as a librarian maintains an organized collection of books, knows which books are popular and should stay on the easy-access shelves, and periodically removes outdated materials, the cache engine stores frequently requested responses, understands HTTP caching rules, and automatically removes stale content. The librarian doesn&#39;t store every book ever requested (space is limited), doesn&#39;t lend out damaged books (respects cache-control directives), and knows when a book&#39;s information is too old to be useful (TTL expiration). This analogy captures the three core responsibilities: intelligent storage decisions, rule-based access control, and proactive cleanup.</p>\n<p>The cache engine sits between the load balancer and backend servers, intercepting requests before they reach the backend and serving cached responses when possible. This positioning allows the cache to dramatically reduce backend load by serving repeated requests from memory, while respecting HTTP semantics ensures clients receive correct, up-to-date responses. The cache engine must balance performance gains against memory usage and cache coherence requirements.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fcache-lookup-flowchart.svg\" alt=\"Cache Lookup and Storage Flow\"></p>\n<h3 id=\"caching-strategy\">Caching Strategy</h3>\n<p>The caching strategy encompasses three fundamental decisions: what to cache, how to organize cached content, and when to remove it. These decisions directly impact both performance gains and memory efficiency.</p>\n<p><strong>Cache Key Generation</strong></p>\n<p>Cache keys uniquely identify cacheable responses and determine whether two requests can share the same cached response. Think of cache keys as precise addresses in a massive warehouse - they must be specific enough to avoid delivering the wrong item, but consistent enough that identical requests always generate the same address.</p>\n<p>The cache key generation process follows a deterministic algorithm that combines multiple request attributes:</p>\n<ol>\n<li><strong>Base Key Construction</strong>: Start with the HTTP method and normalized URI (lowercased, sorted query parameters)</li>\n<li><strong>Header Variation Handling</strong>: Examine the response <code>Vary</code> header to determine which request headers affect the response</li>\n<li><strong>Header Value Incorporation</strong>: For each header listed in <code>Vary</code>, append its value to the cache key</li>\n<li><strong>Authorization Consideration</strong>: Never cache responses for requests containing authorization headers unless explicitly allowed</li>\n<li><strong>Normalization</strong>: Apply consistent encoding and ordering to ensure identical requests produce identical keys</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Key Component</th>\n<th>Source</th>\n<th>Example</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Method</td>\n<td>Request line</td>\n<td><code>GET</code></td>\n<td>Distinguish method semantics</td>\n</tr>\n<tr>\n<td>Normalized URI</td>\n<td>Request line</td>\n<td><code>/api/users?sort=name&amp;limit=10</code></td>\n<td>Core resource identifier</td>\n</tr>\n<tr>\n<td>Vary Headers</td>\n<td>Response Vary + Request</td>\n<td><code>accept-encoding:gzip</code></td>\n<td>Content negotiation</td>\n</tr>\n<tr>\n<td>Host Header</td>\n<td>Request headers</td>\n<td><code>api.example.com</code></td>\n<td>Multi-tenant support</td>\n</tr>\n<tr>\n<td>Query Parameters</td>\n<td>URI query string</td>\n<td><code>limit=10&amp;sort=name</code></td>\n<td>Parameterized requests</td>\n</tr>\n</tbody></table>\n<p><strong>Storage Architecture</strong></p>\n<p>The cache engine uses a two-level storage architecture combining hash table lookup with LRU eviction tracking. This design provides O(1) average-case lookup performance while maintaining efficient memory management.</p>\n<p>The primary storage structure is a hash table mapping cache keys to cache entries. Each cache entry contains the complete HTTP response (status, headers, body) plus metadata for cache management. A separate doubly-linked list tracks access recency for LRU eviction decisions.</p>\n<table>\n<thead>\n<tr>\n<th>Storage Component</th>\n<th>Purpose</th>\n<th>Data Structure</th>\n<th>Access Pattern</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Primary Index</td>\n<td>Fast key lookup</td>\n<td>Hash table</td>\n<td>O(1) average lookup</td>\n</tr>\n<tr>\n<td>Eviction Tracker</td>\n<td>LRU ordering</td>\n<td>Doubly-linked list</td>\n<td>O(1) move-to-head</td>\n</tr>\n<tr>\n<td>Size Monitor</td>\n<td>Memory limits</td>\n<td>Running total</td>\n<td>O(1) size tracking</td>\n</tr>\n<tr>\n<td>TTL Index</td>\n<td>Expiration cleanup</td>\n<td>Min-heap by expiry</td>\n<td>O(log n) expiration</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight</strong>: The two-level architecture separates concerns between access speed (hash table) and replacement policy (LRU list). This separation allows independent optimization of each concern and supports future replacement policy changes without affecting the lookup mechanism.</p>\n</blockquote>\n<p><strong>Eviction Policies</strong></p>\n<p>The cache engine implements multiple eviction triggers to maintain memory limits and data freshness. Eviction operates as a background process triggered by memory pressure or expiration events.</p>\n<p><strong>LRU (Least Recently Used) Eviction</strong> removes the oldest accessed entries when memory limits are reached. Each cache access moves the corresponding entry to the head of the LRU list, maintaining precise access ordering. When eviction is needed, entries are removed from the tail until sufficient space is available.</p>\n<p><strong>TTL (Time-To-Live) Expiration</strong> removes entries that exceed their maximum age, regardless of access patterns. Each cache entry stores an absolute expiration time calculated from the response <code>Cache-Control</code> directives. A background thread periodically scans for expired entries and removes them proactively.</p>\n<p><strong>Size-Based Eviction</strong> prevents individual large responses from consuming excessive memory. Responses exceeding a configurable size threshold are never cached, and existing entries may be evicted if they prevent caching newer, smaller responses.</p>\n<blockquote>\n<p><strong>Decision: Hybrid Eviction Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Different response patterns require different eviction strategies - some content becomes stale (TTL), others are rarely accessed (LRU), and some consume too much memory (size-based)</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>TTL-only eviction with fixed expiration times</li>\n<li>Pure LRU eviction based solely on access patterns</li>\n<li>Hybrid approach combining TTL, LRU, and size constraints</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement hybrid eviction with TTL, LRU, and size-based triggers</li>\n<li><strong>Rationale</strong>: HTTP caching semantics require TTL respect for correctness, LRU provides performance optimization, and size limits prevent memory exhaustion from large responses</li>\n<li><strong>Consequences</strong>: More complex implementation but correctly handles diverse caching scenarios while providing memory safety guarantees</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Eviction Type</th>\n<th>Trigger Condition</th>\n<th>Selection Criteria</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>TTL Expiration</td>\n<td>Entry exceeds max-age</td>\n<td>Absolute expiry time</td>\n<td>O(1) per entry</td>\n</tr>\n<tr>\n<td>LRU Pressure</td>\n<td>Memory limit exceeded</td>\n<td>Least recently accessed</td>\n<td>O(1) per eviction</td>\n</tr>\n<tr>\n<td>Size Rejection</td>\n<td>Response too large</td>\n<td>Individual response size</td>\n<td>O(1) size check</td>\n</tr>\n<tr>\n<td>Proactive Cleanup</td>\n<td>Periodic background</td>\n<td>Batch expired entries</td>\n<td>O(n) scan overhead</td>\n</tr>\n</tbody></table>\n<h3 id=\"http-cache-control-handling\">HTTP Cache-Control Handling</h3>\n<p>HTTP cache-control handling ensures the cache engine respects standard HTTP semantics while maximizing caching opportunities. Think of cache-control directives as traffic signals for cached content - they provide clear rules about when it&#39;s safe to serve cached responses, when fresh validation is required, and when caching is prohibited entirely.</p>\n<p><strong>Cache-Control Directive Processing</strong></p>\n<p>The cache engine parses and evaluates cache-control directives from both request and response headers. Response directives control cachability and expiration, while request directives influence cache lookups and validation requirements.</p>\n<p><strong>Response Cache-Control Evaluation</strong>:</p>\n<ol>\n<li><strong>Parse Response Headers</strong>: Extract and parse the <code>Cache-Control</code> header into individual directives</li>\n<li><strong>Evaluate Cachability</strong>: Check for <code>no-store</code> (never cache), <code>no-cache</code> (cache but validate), and <code>private</code> (cache only in private caches)</li>\n<li><strong>Calculate Expiration</strong>: Use <code>max-age</code> directive or fall back to <code>Expires</code> header for TTL calculation</li>\n<li><strong>Store Validation Info</strong>: Preserve <code>ETag</code> and <code>Last-Modified</code> headers for conditional requests</li>\n<li><strong>Apply Storage Decision</strong>: Cache the response only if cachable according to evaluated directives</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Directive</th>\n<th>Effect on Caching</th>\n<th>TTL Calculation</th>\n<th>Validation Required</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>no-store</code></td>\n<td>Never cache</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td><code>no-cache</code></td>\n<td>Cache with validation</td>\n<td>From max-age/expires</td>\n<td>Always</td>\n</tr>\n<tr>\n<td><code>private</code></td>\n<td>Skip (reverse proxy)</td>\n<td>N/A</td>\n<td>N/A</td>\n</tr>\n<tr>\n<td><code>public</code></td>\n<td>Cache allowed</td>\n<td>From max-age/expires</td>\n<td>When stale</td>\n</tr>\n<tr>\n<td><code>max-age=N</code></td>\n<td>Cache for N seconds</td>\n<td>N seconds</td>\n<td>When stale</td>\n</tr>\n<tr>\n<td><code>must-revalidate</code></td>\n<td>Cache with strict validation</td>\n<td>From max-age/expires</td>\n<td>When stale</td>\n</tr>\n</tbody></table>\n<p><strong>Conditional Request Handling</strong></p>\n<p>Conditional requests allow the cache engine to validate stale entries with backend servers, potentially avoiding full response transfers. The cache engine generates conditional requests using stored validation information and processes 304 Not Modified responses appropriately.</p>\n<p><strong>Conditional Request Generation Process</strong>:</p>\n<ol>\n<li><strong>Check Stale Entry</strong>: Identify cached entries that exceed their max-age but have validation headers</li>\n<li><strong>Generate If-None-Match</strong>: Use stored <code>ETag</code> value to create <code>If-None-Match</code> header</li>\n<li><strong>Generate If-Modified-Since</strong>: Use stored <code>Last-Modified</code> value to create <code>If-Modified-Since</code> header</li>\n<li><strong>Forward Conditional Request</strong>: Send conditional request to backend server with original URI and validation headers</li>\n<li><strong>Process Validation Response</strong>: Handle 304 Not Modified (refresh cache entry) or 200 OK (replace cache entry)</li>\n</ol>\n<blockquote>\n<p><strong>Design Insight</strong>: Conditional requests transform cache misses into cache refreshes, significantly reducing bandwidth usage and backend load. A 304 Not Modified response allows the cache to serve the existing response body while updating expiration information, providing the performance benefits of caching with the correctness guarantees of validation.</p>\n</blockquote>\n<p><strong>Vary Header Processing</strong></p>\n<p>The <code>Vary</code> response header indicates which request headers affect the response content, requiring the cache engine to incorporate these headers into cache key generation. Proper <code>Vary</code> handling prevents serving inappropriate cached responses to clients with different capabilities or preferences.</p>\n<p><strong>Vary Processing Algorithm</strong>:</p>\n<ol>\n<li><strong>Parse Vary Header</strong>: Extract list of header names from the response <code>Vary</code> header</li>\n<li><strong>Extract Request Values</strong>: For each header name in <code>Vary</code>, extract the corresponding value from the original request</li>\n<li><strong>Normalize Values</strong>: Apply consistent case normalization and whitespace handling to header values</li>\n<li><strong>Incorporate into Key</strong>: Append normalized header values to the cache key in deterministic order</li>\n<li><strong>Store Vary Information</strong>: Preserve the complete <code>Vary</code> list with the cached response for future key generation</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Vary Header</th>\n<th>Request Impact</th>\n<th>Key Component</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Accept-Encoding</code></td>\n<td>Content compression</td>\n<td><code>accept-encoding:gzip</code></td>\n<td>Different compressions cached separately</td>\n</tr>\n<tr>\n<td><code>Accept-Language</code></td>\n<td>Content localization</td>\n<td><code>accept-language:en-US</code></td>\n<td>Different languages cached separately</td>\n</tr>\n<tr>\n<td><code>User-Agent</code></td>\n<td>Browser-specific content</td>\n<td><code>user-agent:Mozilla/...</code></td>\n<td>Browser-specific responses</td>\n</tr>\n<tr>\n<td><code>Accept</code></td>\n<td>Content type negotiation</td>\n<td><code>accept:application/json</code></td>\n<td>JSON vs XML responses</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Full Vary Support with Key Segmentation</strong></p>\n<ul>\n<li><strong>Context</strong>: The <code>Vary</code> header allows responses to depend on arbitrary request headers, creating complex cache key requirements</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Ignore <code>Vary</code> headers and cache only the first response variant</li>\n<li>Support limited <code>Vary</code> headers (only common ones like <code>Accept-Encoding</code>)</li>\n<li>Full <code>Vary</code> support with dynamic key generation</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement full <code>Vary</code> support with request header incorporation into cache keys</li>\n<li><strong>Rationale</strong>: Correct HTTP semantics require full <code>Vary</code> support to avoid serving incorrect cached responses to clients with different capabilities</li>\n<li><strong>Consequences</strong>: More complex cache key generation and potentially reduced cache hit rates, but guaranteed correctness for content negotiation scenarios</li>\n</ul>\n</blockquote>\n<h3 id=\"caching-design-decisions\">Caching Design Decisions</h3>\n<p>The cache engine architecture reflects several critical design decisions that balance performance, correctness, and operational complexity. Each decision involves trade-offs between competing requirements.</p>\n<blockquote>\n<p><strong>Decision: In-Memory Cache with LRU Eviction</strong></p>\n<ul>\n<li><strong>Context</strong>: The cache engine needs fast access to cached responses while managing memory limits and avoiding storage complexity</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Pure in-memory hash table with no eviction</li>\n<li>Disk-backed cache with persistent storage</li>\n<li>In-memory cache with LRU eviction</li>\n<li>Tiered cache with memory and disk levels</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: In-memory cache with LRU eviction and configurable size limits</li>\n<li><strong>Rationale</strong>: In-memory storage provides microsecond access times essential for reverse proxy performance, LRU eviction prevents memory exhaustion, and avoiding disk eliminates I/O bottlenecks</li>\n<li><strong>Consequences</strong>: Cache is lost on restart and limited by available memory, but provides maximum performance for actively cached content</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Performance</th>\n<th>Persistence</th>\n<th>Complexity</th>\n<th>Memory Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pure Memory</td>\n<td>Excellent</td>\n<td>None</td>\n<td>Low</td>\n<td>Unbounded</td>\n</tr>\n<tr>\n<td>Disk-Backed</td>\n<td>Poor</td>\n<td>Full</td>\n<td>High</td>\n<td>Bounded</td>\n</tr>\n<tr>\n<td>Memory + LRU</td>\n<td>Excellent</td>\n<td>None</td>\n<td>Medium</td>\n<td>Bounded</td>\n</tr>\n<tr>\n<td>Tiered</td>\n<td>Good</td>\n<td>Partial</td>\n<td>Very High</td>\n<td>Tiered</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Thread-Safe Cache with Read-Write Locks</strong></p>\n<ul>\n<li><strong>Context</strong>: Multiple worker threads need concurrent access to cache data structures for both reads (cache lookups) and writes (cache updates and evictions)</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Single-threaded cache with message passing</li>\n<li>Coarse-grained mutex protecting entire cache</li>\n<li>Fine-grained locking with per-entry locks</li>\n<li>Read-write locks with optimistic concurrency</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Read-write locks with separate locks for cache operations and LRU management</li>\n<li><strong>Rationale</strong>: Cache lookups vastly outnumber updates, making read-write locks optimal for this read-heavy workload with occasional writes</li>\n<li><strong>Consequences</strong>: Excellent read concurrency but potential write contention during eviction storms; requires careful lock ordering to prevent deadlocks</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>Decision: Proactive TTL Cleanup with Background Thread</strong></p>\n<ul>\n<li><strong>Context</strong>: Expired cache entries consume memory and may be served incorrectly if not removed promptly</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Lazy expiration checking only on access</li>\n<li>Periodic full cache scanning for expired entries</li>\n<li>Priority queue with next-expiry tracking</li>\n<li>Background thread with batched cleanup</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Background thread that periodically scans and removes expired entries in batches</li>\n<li><strong>Rationale</strong>: Proactive cleanup prevents memory leaks from expired content, batched processing amortizes scanning costs, and background execution avoids blocking request processing</li>\n<li><strong>Consequences</strong>: Constant low-level CPU overhead for cleanup scanning, but guaranteed memory reclamation and elimination of stale content serving</li>\n</ul>\n</blockquote>\n<p><strong>Cache Engine Data Structures</strong></p>\n<p>The cache engine maintains several interconnected data structures to support fast lookup, efficient eviction, and proper HTTP semantics compliance.</p>\n<table>\n<thead>\n<tr>\n<th>Structure</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Key Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>cache_table</code></td>\n<td><code>HashTable*</code></td>\n<td>Primary cache lookup</td>\n<td>get, put, remove</td>\n</tr>\n<tr>\n<td><code>lru_list</code></td>\n<td><code>LRUList*</code></td>\n<td>Access ordering</td>\n<td>move_to_head, remove_tail</td>\n</tr>\n<tr>\n<td><code>ttl_heap</code></td>\n<td><code>TTLHeap*</code></td>\n<td>Expiration tracking</td>\n<td>peek_expired, remove_expired</td>\n</tr>\n<tr>\n<td><code>cache_mutex</code></td>\n<td><code>pthread_rwlock_t</code></td>\n<td>Concurrency control</td>\n<td>read_lock, write_lock</td>\n</tr>\n<tr>\n<td><code>size_current</code></td>\n<td><code>size_t</code></td>\n<td>Memory usage tracking</td>\n<td>atomic_add, atomic_sub</td>\n</tr>\n<tr>\n<td><code>size_limit</code></td>\n<td><code>size_t</code></td>\n<td>Memory limit</td>\n<td>configuration value</td>\n</tr>\n</tbody></table>\n<p><strong>CacheEngine Structure Definition</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>cache_table</code></td>\n<td><code>HashTable*</code></td>\n<td>Primary storage mapping cache keys to entries</td>\n</tr>\n<tr>\n<td><code>lru_head</code></td>\n<td><code>CacheEntry*</code></td>\n<td>Head of doubly-linked LRU list</td>\n</tr>\n<tr>\n<td><code>lru_tail</code></td>\n<td><code>CacheEntry*</code></td>\n<td>Tail of doubly-linked LRU list</td>\n</tr>\n<tr>\n<td><code>ttl_heap</code></td>\n<td><code>TTLHeap*</code></td>\n<td>Min-heap ordered by expiration time</td>\n</tr>\n<tr>\n<td><code>cache_rwlock</code></td>\n<td><code>pthread_rwlock_t</code></td>\n<td>Reader-writer lock for cache operations</td>\n</tr>\n<tr>\n<td><code>lru_mutex</code></td>\n<td><code>pthread_mutex_t</code></td>\n<td>Mutex protecting LRU list manipulation</td>\n</tr>\n<tr>\n<td><code>size_current</code></td>\n<td><code>size_t</code></td>\n<td>Current total cache size in bytes</td>\n</tr>\n<tr>\n<td><code>size_limit</code></td>\n<td><code>size_t</code></td>\n<td>Maximum allowed cache size</td>\n</tr>\n<tr>\n<td><code>default_ttl</code></td>\n<td><code>time_t</code></td>\n<td>Default TTL for responses without cache headers</td>\n</tr>\n<tr>\n<td><code>cleanup_thread</code></td>\n<td><code>pthread_t</code></td>\n<td>Background thread for TTL cleanup</td>\n</tr>\n<tr>\n<td><code>cleanup_interval</code></td>\n<td><code>int</code></td>\n<td>Seconds between cleanup cycles</td>\n</tr>\n<tr>\n<td><code>hit_count</code></td>\n<td><code>uint64_t</code></td>\n<td>Cache hit counter for metrics</td>\n</tr>\n<tr>\n<td><code>miss_count</code></td>\n<td><code>uint64_t</code></td>\n<td>Cache miss counter for metrics</td>\n</tr>\n<tr>\n<td><code>eviction_count</code></td>\n<td><code>uint64_t</code></td>\n<td>Eviction counter for metrics</td>\n</tr>\n<tr>\n<td><code>running</code></td>\n<td><code>bool</code></td>\n<td>Flag controlling background thread execution</td>\n</tr>\n</tbody></table>\n<p><strong>CacheEntry Structure Definition</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>cache_key</code></td>\n<td><code>char[512]</code></td>\n<td>Unique identifier for cached response</td>\n</tr>\n<tr>\n<td><code>response_status</code></td>\n<td><code>int</code></td>\n<td>HTTP status code of cached response</td>\n</tr>\n<tr>\n<td><code>response_headers</code></td>\n<td><code>HashTable*</code></td>\n<td>Complete response header collection</td>\n</tr>\n<tr>\n<td><code>response_body</code></td>\n<td><code>Buffer*</code></td>\n<td>Response body content</td>\n</tr>\n<tr>\n<td><code>content_length</code></td>\n<td><code>size_t</code></td>\n<td>Size of response body in bytes</td>\n</tr>\n<tr>\n<td><code>created_time</code></td>\n<td><code>time_t</code></td>\n<td>When entry was first cached</td>\n</tr>\n<tr>\n<td><code>last_access</code></td>\n<td><code>time_t</code></td>\n<td>Most recent access timestamp</td>\n</tr>\n<tr>\n<td><code>expires_time</code></td>\n<td><code>time_t</code></td>\n<td>Absolute expiration time</td>\n</tr>\n<tr>\n<td><code>etag</code></td>\n<td><code>char[256]</code></td>\n<td>ETag header value for validation</td>\n</tr>\n<tr>\n<td><code>last_modified</code></td>\n<td><code>char[128]</code></td>\n<td>Last-Modified header for validation</td>\n</tr>\n<tr>\n<td><code>vary_headers</code></td>\n<td><code>char[512]</code></td>\n<td>Comma-separated list of Vary header names</td>\n</tr>\n<tr>\n<td><code>cache_control</code></td>\n<td><code>CacheControl*</code></td>\n<td>Parsed cache-control directives</td>\n</tr>\n<tr>\n<td><code>lru_prev</code></td>\n<td><code>CacheEntry*</code></td>\n<td>Previous entry in LRU list</td>\n</tr>\n<tr>\n<td><code>lru_next</code></td>\n<td><code>CacheEntry*</code></td>\n<td>Next entry in LRU list</td>\n</tr>\n<tr>\n<td><code>ttl_heap_index</code></td>\n<td><code>size_t</code></td>\n<td>Position in TTL expiration heap</td>\n</tr>\n<tr>\n<td><code>entry_size</code></td>\n<td><code>size_t</code></td>\n<td>Total memory consumed by this entry</td>\n</tr>\n<tr>\n<td><code>hit_count</code></td>\n<td><code>uint32_t</code></td>\n<td>Number of times entry was served</td>\n</tr>\n</tbody></table>\n<p><strong>Cache Engine Interface Methods</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>cache_engine_create</code></td>\n<td><code>size_t max_size, int default_ttl</code></td>\n<td><code>CacheEngine*</code></td>\n<td>Initialize cache with size and TTL limits</td>\n</tr>\n<tr>\n<td><code>cache_engine_lookup</code></td>\n<td><code>CacheEngine*, HttpRequest*</code></td>\n<td><code>CacheEntry*</code></td>\n<td>Find cached response for request</td>\n</tr>\n<tr>\n<td><code>cache_engine_store</code></td>\n<td><code>CacheEngine*, char*, HttpResponse*</code></td>\n<td><code>bool</code></td>\n<td>Store response in cache if cacheable</td>\n</tr>\n<tr>\n<td><code>cache_engine_invalidate</code></td>\n<td><code>CacheEngine*, char*</code></td>\n<td><code>bool</code></td>\n<td>Remove specific entry from cache</td>\n</tr>\n<tr>\n<td><code>cache_engine_clear</code></td>\n<td><code>CacheEngine*</code></td>\n<td><code>void</code></td>\n<td>Remove all cached entries</td>\n</tr>\n<tr>\n<td><code>cache_engine_stats</code></td>\n<td><code>CacheEngine*</code></td>\n<td><code>CacheStats*</code></td>\n<td>Retrieve hit/miss/eviction statistics</td>\n</tr>\n<tr>\n<td><code>cache_generate_key</code></td>\n<td><code>HttpRequest*</code></td>\n<td><code>char*</code></td>\n<td>Generate cache key for request</td>\n</tr>\n<tr>\n<td><code>cache_is_cacheable</code></td>\n<td><code>HttpResponse*</code></td>\n<td><code>bool</code></td>\n<td>Determine if response can be cached</td>\n</tr>\n<tr>\n<td><code>cache_is_fresh</code></td>\n<td><code>CacheEntry*, time_t</code></td>\n<td><code>bool</code></td>\n<td>Check if cached entry is still fresh</td>\n</tr>\n<tr>\n<td><code>cache_create_conditional</code></td>\n<td><code>HttpRequest*, CacheEntry*</code></td>\n<td><code>HttpRequest*</code></td>\n<td>Create conditional request for validation</td>\n</tr>\n<tr>\n<td><code>cache_update_from_304</code></td>\n<td><code>CacheEntry*, HttpResponse*</code></td>\n<td><code>void</code></td>\n<td>Update entry from 304 Not Modified</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Caching Non-Cacheable Responses</strong></p>\n<p>Beginning developers often cache every response to maximize hit rates, ignoring HTTP semantics that prohibit caching certain responses. Caching responses with <code>Cache-Control: no-store</code>, responses to authenticated requests, or responses with <code>Set-Cookie</code> headers can cause security vulnerabilities and incorrect behavior.</p>\n<p>This occurs because the caching logic focuses on performance rather than correctness. The cache engine must evaluate cache-control directives, authentication headers, and response characteristics before making storage decisions.</p>\n<p>To avoid this pitfall, implement a comprehensive <code>cache_is_cacheable</code> function that checks all HTTP caching restrictions: verify no <code>no-store</code> directive, ensure no authorization headers in the request unless <code>public</code> is specified, check that the response status code is cacheable (200, 203, 300, 301, 410, etc.), and confirm no <code>Set-Cookie</code> headers unless specifically allowed.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Vary Headers in Cache Keys</strong></p>\n<p>Many implementations generate cache keys using only the request URI, ignoring the response <code>Vary</code> header that indicates which request headers affect the response. This causes the cache to serve incorrect responses to clients with different capabilities or preferences.</p>\n<p>For example, a server might return gzipped content for clients supporting compression and uncompressed content for others, using <code>Vary: Accept-Encoding</code>. Without incorporating the <code>Accept-Encoding</code> header into the cache key, a client that doesn&#39;t support compression might receive a cached gzipped response, causing display errors.</p>\n<p>The solution requires parsing the <code>Vary</code> header from cached responses and incorporating the corresponding request header values into cache key generation. Store the complete <code>Vary</code> header list with each cache entry and use it to generate keys for subsequent requests.</p>\n<p>⚠️ <strong>Pitfall: Serving Stale Content Beyond max-age</strong></p>\n<p>Cache implementations sometimes serve expired content when backend servers are unavailable, violating HTTP semantics unless the response included <code>Cache-Control: stale-while-revalidate</code> or similar directives.</p>\n<p>This happens when error handling logic prioritizes availability over correctness, serving any cached content during backend failures. While this might seem helpful, it can serve dangerously stale content (hours or days old) that no longer represents accurate information.</p>\n<p>Implement proper TTL checking that never serves content beyond its <code>max-age</code> unless the response explicitly allows stale serving. Use conditional requests to validate stale content when possible, and return appropriate 502/503 errors when fresh content cannot be obtained.</p>\n<p>⚠️ <strong>Pitfall: Memory Leaks from Unbounded Cache Growth</strong></p>\n<p>Without proper eviction mechanisms, cache implementations can consume unlimited memory, eventually causing out-of-memory crashes in high-traffic scenarios.</p>\n<p>This occurs when developers implement cache storage without size limits or eviction policies, assuming that cache hit rates will naturally limit memory usage. In reality, diverse request patterns can create large numbers of unique cache entries that collectively exceed available memory.</p>\n<p>Implement comprehensive size tracking that includes both response body size and metadata overhead. Use LRU eviction triggered by configurable memory limits, and consider implementing maximum entry size limits to prevent individual large responses from dominating cache space.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Concurrent Cache Access</strong></p>\n<p>Multi-threaded environments require careful synchronization of cache data structures, but many implementations use insufficient locking that leads to corruption, crashes, or incorrect behavior.</p>\n<p>The most common issue is using a single mutex for all cache operations, creating unnecessary contention between read operations (cache lookups) that could proceed concurrently. Another issue is inconsistent locking between cache lookup and LRU list updates, potentially corrupting the access ordering.</p>\n<p>Use read-write locks that allow concurrent reads while serializing writes. Implement separate locks for cache table operations and LRU list manipulation, but ensure consistent lock ordering to prevent deadlocks. Consider atomic operations for simple counter updates like hit/miss statistics.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The cache engine implementation requires careful attention to memory management, concurrency control, and HTTP semantics compliance. This guidance provides working infrastructure code and detailed implementation skeletons for the core caching logic.</p>\n<p><strong>Technology Recommendations</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hash Table</td>\n<td>Simple chaining with linked lists</td>\n<td>Robin Hood hashing with open addressing</td>\n</tr>\n<tr>\n<td>Memory Management</td>\n<td>malloc/free with manual tracking</td>\n<td>Memory pools with fixed-size allocations</td>\n</tr>\n<tr>\n<td>Threading</td>\n<td>pthread with read-write locks</td>\n<td>Lock-free data structures with hazard pointers</td>\n</tr>\n<tr>\n<td>Time Handling</td>\n<td>time() system calls</td>\n<td>High-resolution timers with cached current time</td>\n</tr>\n<tr>\n<td>HTTP Parsing</td>\n<td>String manipulation with strstr</td>\n<td>Dedicated HTTP header parsing library</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong>:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/\n  cache/\n    cache_engine.h          ← Main cache engine interface\n    cache_engine.c          ← Core cache logic implementation  \n    cache_entry.h           ← Cache entry data structures\n    cache_entry.c           ← Entry lifecycle management\n    cache_key.h             ← Cache key generation\n    cache_key.c             ← Key generation algorithms\n    cache_control.h         ← HTTP cache-control parsing\n    cache_control.c         ← Cache directive evaluation\n    lru_list.h              ← LRU eviction list\n    lru_list.c              ← LRU list operations\n    ttl_heap.h              ← TTL expiration heap\n    ttl_heap.c              ← Heap-based expiration tracking\n    cache_stats.h           ← Cache metrics and statistics\n    cache_stats.c           ← Statistics collection\n  tests/\n    test_cache_engine.c     ← Cache engine unit tests\n    test_cache_key.c        ← Key generation tests\n    test_cache_control.c    ← HTTP directive tests</code></pre></div>\n\n<p><strong>Infrastructure Starter Code</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// cache_control.h - Complete HTTP Cache-Control parsing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#ifndef</span><span style=\"color:#B392F0\"> CACHE_CONTROL_H</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> CACHE_CONTROL_H</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> no_store;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> no_cache;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> must_revalidate;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> private;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> public;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> max_age;</span><span style=\"color:#6A737D\">           // -1 if not specified</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> s_maxage;</span><span style=\"color:#6A737D\">          // -1 if not specified</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> has_etag;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> has_last_modified;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} CacheControl;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Parse Cache-Control header into structured directives</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> cache_control_parse</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> header_value</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Check if response is cacheable based on cache-control directives</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> cache_control_is_cacheable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#FFAB70\"> has_authorization</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Calculate expiration time from cache-control and response headers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">time_t</span><span style=\"color:#B392F0\"> cache_control_calculate_expiry</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                     const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> expires_header</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                     time_t</span><span style=\"color:#FFAB70\"> response_time</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Check if cached entry is fresh at given time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> cache_control_is_fresh</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">time_t</span><span style=\"color:#FFAB70\"> cached_time</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                           time_t</span><span style=\"color:#FFAB70\"> current_time</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> cache_control_destroy</span><span style=\"color:#E1E4E8\">(CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#endif</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// cache_control.c - Implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"cache_control.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;ctype.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> cache_control_parse</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> header_value</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">header_value) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cc </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(CacheControl));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cc->max_age </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cc->s_maxage </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> header_copy </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> strdup</span><span style=\"color:#E1E4E8\">(header_value);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> token </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> strtok</span><span style=\"color:#E1E4E8\">(header_copy, </span><span style=\"color:#9ECBFF\">\",\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (token) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Skip whitespace</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">isspace</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">token)) token</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"no-store\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->no_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"no-cache\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->no_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"must-revalidate\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">15</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->must_revalidate </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"private\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->private </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"public\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->public </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"max-age=\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->max_age </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> atoi</span><span style=\"color:#E1E4E8\">(token </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(token, </span><span style=\"color:#9ECBFF\">\"s-maxage=\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">9</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cc->s_maxage </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> atoi</span><span style=\"color:#E1E4E8\">(token </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 9</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        token </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> strtok</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\",\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    free</span><span style=\"color:#E1E4E8\">(header_copy);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cc;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> cache_control_is_cacheable</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">bool</span><span style=\"color:#FFAB70\"> has_authorization</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Never cache if no-store directive present</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (cc->no_store) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Don't cache authorized requests unless explicitly public</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (has_authorization </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">cc->public) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Don't cache private responses in shared cache (reverse proxy)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (cc->private) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">time_t</span><span style=\"color:#B392F0\"> cache_control_calculate_expiry</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                     const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> expires_header</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                     time_t</span><span style=\"color:#FFAB70\"> response_time</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Use s-maxage for shared caches if present</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (cc->s_maxage </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> response_time </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> cc->s_maxage;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Use max-age if present</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (cc->max_age </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> response_time </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> cc->max_age;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Fall back to Expires header parsing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (expires_header) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Parse HTTP date format - simplified for example</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        struct</span><span style=\"color:#E1E4E8\"> tm tm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strptime</span><span style=\"color:#E1E4E8\">(expires_header, </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">%a</span><span style=\"color:#9ECBFF\">, </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#FDAEB7;font-style:italic\"> %</span><span style=\"color:#9ECBFF\">b </span><span style=\"color:#FDAEB7;font-style:italic\">%</span><span style=\"color:#9ECBFF\">Y </span><span style=\"color:#FDAEB7;font-style:italic\">%</span><span style=\"color:#9ECBFF\">H:</span><span style=\"color:#FDAEB7;font-style:italic\">%</span><span style=\"color:#9ECBFF\">M:</span><span style=\"color:#79B8FF\">%S</span><span style=\"color:#9ECBFF\"> GMT\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">tm)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#B392F0\"> mktime</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">tm);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // No expiration information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> cache_control_is_fresh</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#E1E4E8\"> CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">time_t</span><span style=\"color:#FFAB70\"> cached_time</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                           time_t</span><span style=\"color:#FFAB70\"> current_time</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> max_age </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cc->s_maxage </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> ?</span><span style=\"color:#E1E4E8\"> cc->s_maxage </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> cc->max_age;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (max_age </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // No expiration specified</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> (current_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> cached_time) </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> max_age;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> cache_control_destroy</span><span style=\"color:#E1E4E8\">(CacheControl</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cc</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (cc) </span><span style=\"color:#B392F0\">free</span><span style=\"color:#E1E4E8\">(cc);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// lru_list.h - Complete LRU list implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#ifndef</span><span style=\"color:#B392F0\"> LRU_LIST_H</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LRU_LIST_H</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"cache_entry.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;pthread.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> LRUList {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> head;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> tail;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> lru_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LRUList;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> lru_list_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_move_to_head</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">, CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> entry</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_add_to_head</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">, CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> entry</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> lru_list_remove_tail</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_remove_entry</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">, CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> entry</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_destroy</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#endif</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// lru_list.c</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"lru_list.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> lru_list_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> list </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> calloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(LRUList));</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> list;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_move_to_head</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">, CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> entry</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_lock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Remove from current position</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (entry->lru_prev) entry->lru_prev->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_next;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (entry->lru_next) entry->lru_next->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_prev;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (list->tail </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> entry) list->tail </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_prev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Add to head</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    entry->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    entry->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> list->head;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (list->head) list->head->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    list->head </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">list->tail) list->tail </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_unlock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_add_to_head</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">, CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> entry</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_lock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    entry->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    entry->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> list->head;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (list->head) list->head->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    list->head </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">list->tail) list->tail </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    list->count</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_unlock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> lru_list_remove_tail</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_lock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> list->tail;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (entry) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        list->tail </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_prev;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (list->tail) list->tail->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\"> list->head </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        entry->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        list->count</span><span style=\"color:#F97583\">--</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_unlock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> entry;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_remove_entry</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">, CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> entry</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_lock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (entry->lru_prev) entry->lru_prev->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_next;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (entry->lru_next) entry->lru_next->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_prev;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (list->head </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> entry) list->head </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_next;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (list->tail </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> entry) list->tail </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_prev;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    entry->lru_prev </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> entry->lru_next </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    list->count</span><span style=\"color:#F97583\">--</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_unlock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> lru_list_destroy</span><span style=\"color:#E1E4E8\">(LRUList</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> list</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (list) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        pthread_mutex_destroy</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">list->lru_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(list);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Core Cache Engine Implementation Skeleton</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// cache_engine.c - Core cache logic with detailed TODOs</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"cache_engine.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"cache_control.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"lru_list.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CacheEngine</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> cache_engine_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> max_size</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> default_ttl</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate and initialize CacheEngine structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create hash table with reasonable initial size (e.g., 1024 buckets)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Initialize LRU list for eviction tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Initialize read-write lock for concurrent access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set size limits and TTL defaults from parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Initialize statistics counters (hit_count, miss_count, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Start background cleanup thread for TTL expiration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use hashtable_create(1024) for initial table size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: pthread_rwlock_init for read-write lock initialization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> cache_engine_lookup</span><span style=\"color:#E1E4E8\">(CacheEngine</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> engine</span><span style=\"color:#E1E4E8\">, HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Generate cache key from request (method, URI, headers)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Acquire read lock on cache for thread-safe lookup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Search hash table using generated cache key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If entry found, check if it's still fresh (TTL validation)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If fresh, update access time and move to LRU head</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If stale, consider conditional request creation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Increment hit or miss counters appropriately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Release read lock and return entry (or NULL for miss)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use cache_generate_key(request) for key generation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use cache_control_is_fresh() for TTL checking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> cache_engine_store</span><span style=\"color:#E1E4E8\">(CacheEngine</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> engine</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">, HttpResponse</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> response</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Parse response Cache-Control headers for cachability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check if response is cacheable (no no-store, appropriate status)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Calculate response size including headers and body</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Check if response size exceeds individual entry limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Acquire write lock for cache modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Check if storing would exceed total cache size limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Evict LRU entries until sufficient space available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Create new CacheEntry with response data and metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Insert entry into hash table and add to LRU head</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 10: Update current cache size and storage statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 11: Release write lock and return success status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use cache_control_parse() for Cache-Control evaluation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use lru_list_remove_tail() for eviction when space needed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">char*</span><span style=\"color:#B392F0\"> cache_generate_key</span><span style=\"color:#E1E4E8\">(HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Start with HTTP method and normalized URI</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check for cached response Vary header (if doing validation)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For each header in Vary, append header name and value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Include Host header for virtual hosting support</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Ensure consistent ordering and normalization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Allocate and return null-terminated key string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use fixed-size buffer (512 bytes) for key construction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Normalize header names to lowercase for consistency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> cache_is_cacheable</span><span style=\"color:#E1E4E8\">(HttpResponse</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> response</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Parse Cache-Control header from response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check for no-store directive (never cache)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Check for private directive (not for shared caches)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify response status code is cacheable (200, 301, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Check for Set-Cookie headers (usually not cacheable)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Return true only if all caching requirements met</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use cache_control_parse() for header evaluation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Status codes 200, 203, 300, 301, 410 are typically cacheable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> cache_cleanup_thread</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Cast argument to CacheEngine pointer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Loop while engine->running flag is true</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Sleep for cleanup_interval seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Acquire write lock for cache modification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Scan cache entries for expired TTL values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Remove expired entries from hash table and LRU list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Update cache size and eviction statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Release write lock and continue loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use time(NULL) for current time comparison</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Batch multiple removals in single lock acquisition</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints</strong>:</p>\n<p>After implementing the cache engine core, verify functionality with these checkpoints:</p>\n<ol>\n<li><p><strong>Cache Key Generation</strong>: Create requests with different URIs, methods, and headers. Verify that identical requests generate identical keys and different requests generate different keys.</p>\n</li>\n<li><p><strong>Basic Caching</strong>: Send identical GET requests through the proxy. First request should be forwarded to backend, subsequent requests should be served from cache (verify with backend access logs).</p>\n</li>\n<li><p><strong>Cache-Control Respect</strong>: Send requests for resources with different cache-control headers (<code>no-store</code>, <code>max-age=60</code>, etc.). Verify that uncacheable responses are not cached and cached responses respect TTL limits.</p>\n</li>\n<li><p><strong>Vary Header Handling</strong>: Configure backend to return <code>Vary: Accept-Encoding</code> and send requests with different Accept-Encoding headers. Verify that different encodings are cached separately.</p>\n</li>\n<li><p><strong>LRU Eviction</strong>: Configure small cache size and send requests for more content than cache can hold. Verify that least recently used entries are evicted first.</p>\n</li>\n</ol>\n<p><strong>Debugging Tips</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache never hits</td>\n<td>Key generation inconsistency</td>\n<td>Log generated keys for identical requests</td>\n<td>Ensure header normalization and consistent ordering</td>\n</tr>\n<tr>\n<td>Memory usage grows unbounded</td>\n<td>Missing eviction or TTL cleanup</td>\n<td>Check LRU list size and cleanup thread</td>\n<td>Verify size limit enforcement and cleanup thread operation</td>\n</tr>\n<tr>\n<td>Stale content served</td>\n<td>TTL calculation error</td>\n<td>Log expiry times vs current time</td>\n<td>Fix cache_control_calculate_expiry implementation</td>\n</tr>\n<tr>\n<td>Wrong content for client</td>\n<td>Missing Vary support</td>\n<td>Check if response has Vary header</td>\n<td>Include Vary headers in key generation</td>\n</tr>\n<tr>\n<td>Cache corruption/crashes</td>\n<td>Race condition in concurrent access</td>\n<td>Run with thread sanitizer</td>\n<td>Fix lock ordering and ensure consistent locking</td>\n</tr>\n</tbody></table>\n<h2 id=\"ssl-termination-component\">SSL Termination Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 5 (SSL Termination) - handles HTTPS connections by terminating TLS at the proxy and forwarding decrypted HTTP to backends</p>\n</blockquote>\n<p>Think of SSL termination like a high-security checkpoint at a government building. Visitors arrive with various forms of encrypted identification (SSL certificates), guards at the checkpoint verify their credentials and decrypt their intentions (TLS handshake), then escort them inside using simple internal protocols (plain HTTP to backends). The guards must handle multiple types of credentials (SNI for different domains) and maintain strict security protocols while ensuring smooth traffic flow.</p>\n<p>The <code>SSLTermination</code> component sits at the network edge, accepting encrypted TLS connections from clients and converting them into plain HTTP connections to backend servers. This design choice centralizes certificate management, reduces computational load on backend servers, and enables the proxy to inspect and route HTTP traffic effectively. However, it also creates a critical security boundary that must be implemented with extreme care to prevent vulnerabilities.</p>\n<h3 id=\"tls-context-management\">TLS Context Management</h3>\n<p>The foundation of SSL termination lies in proper TLS context management, which involves setting up cryptographic contexts, loading certificates and private keys, and configuring security parameters. Think of a TLS context as a cryptographic blueprint that defines how the proxy will handle encrypted connections - it specifies which certificates to present, which cipher suites to accept, and how to validate client connections.</p>\n<p>The <code>SSLTermination</code> component maintains multiple TLS contexts to support different domains and security requirements. Each context represents a complete cryptographic configuration for a specific domain or set of domains. The component must handle context creation during startup, dynamic certificate reloading for renewals, and context selection based on incoming connection characteristics.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>contexts</td>\n<td><code>HashTable*</code></td>\n<td>Maps domain names to SSL_CTX structures</td>\n</tr>\n<tr>\n<td>default_context</td>\n<td><code>SSL_CTX*</code></td>\n<td>Fallback context for unmatched SNI requests</td>\n</tr>\n<tr>\n<td>cert_store</td>\n<td><code>X509_STORE*</code></td>\n<td>Certificate authority store for validation</td>\n</tr>\n<tr>\n<td>cipher_list</td>\n<td><code>char[1024]</code></td>\n<td>Configured cipher suite preference string</td>\n</tr>\n<tr>\n<td>min_tls_version</td>\n<td><code>int</code></td>\n<td>Minimum TLS version (TLS_1_2 or TLS_1_3)</td>\n</tr>\n<tr>\n<td>max_tls_version</td>\n<td><code>int</code></td>\n<td>Maximum TLS version for compatibility</td>\n</tr>\n<tr>\n<td>session_cache</td>\n<td><code>SSL_SESSION_CACHE*</code></td>\n<td>Session resumption cache for performance</td>\n</tr>\n<tr>\n<td>context_mutex</td>\n<td><code>pthread_rwlock_t</code></td>\n<td>Synchronizes context access and updates</td>\n</tr>\n<tr>\n<td>cert_reload_thread</td>\n<td><code>pthread_t</code></td>\n<td>Background thread monitoring certificate changes</td>\n</tr>\n<tr>\n<td>reload_interval</td>\n<td><code>int</code></td>\n<td>Certificate file monitoring interval in seconds</td>\n</tr>\n<tr>\n<td>running</td>\n<td><code>bool</code></td>\n<td>Controls background certificate monitoring</td>\n</tr>\n</tbody></table>\n<p>The certificate loading process involves several critical security validations. The component must verify that certificate files are readable, private keys match their corresponding certificates, certificate chains are complete and valid, and file permissions restrict access appropriately. Certificate validation extends beyond basic file parsing to include expiration date checking, key usage validation, and certificate chain verification against trusted authorities.</p>\n<blockquote>\n<p><strong>Decision: OpenSSL vs BoringSSL vs Custom TLS Implementation</strong></p>\n<ul>\n<li><strong>Context</strong>: Need TLS implementation for production reverse proxy handling potentially thousands of concurrent connections</li>\n<li><strong>Options Considered</strong>: OpenSSL (mature, feature-complete), BoringSSL (Google&#39;s fork focused on security), Custom implementation (full control)</li>\n<li><strong>Decision</strong>: OpenSSL with careful version management and security patches</li>\n<li><strong>Rationale</strong>: OpenSSL provides comprehensive TLS support, extensive documentation, and broad platform compatibility. While BoringSSL offers enhanced security, OpenSSL&#39;s maturity and ecosystem support outweigh the benefits for this implementation</li>\n<li><strong>Consequences</strong>: Enables full TLS feature support and easy certificate management but requires staying current with security patches and careful API usage to avoid common pitfalls</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>OpenSSL</td>\n<td>Comprehensive features, extensive docs, broad compatibility</td>\n<td>Large attack surface, complex API, frequent security updates</td>\n<td>✓ Yes</td>\n</tr>\n<tr>\n<td>BoringSSL</td>\n<td>Enhanced security focus, simplified API, Google backing</td>\n<td>Limited documentation, fewer features, potential compatibility issues</td>\n<td>No</td>\n</tr>\n<tr>\n<td>Custom TLS</td>\n<td>Complete control, minimal dependencies, tailored security</td>\n<td>Enormous development effort, high risk of security bugs, maintenance burden</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p>The context initialization process follows a carefully orchestrated sequence to ensure security and reliability:</p>\n<ol>\n<li><strong>Library Initialization</strong>: Initialize OpenSSL library components including random number generators, error strings, and algorithm tables</li>\n<li><strong>Context Creation</strong>: Create SSL_CTX structures for each configured domain using appropriate TLS methods (TLS_server_method for modern compatibility)</li>\n<li><strong>Certificate Loading</strong>: Load X.509 certificates from PEM files, validating format and extracting subject information</li>\n<li><strong>Private Key Loading</strong>: Load corresponding private keys, ensuring they match their certificates through cryptographic validation</li>\n<li><strong>Certificate Chain Verification</strong>: Validate complete certificate chains from leaf certificates to trusted root authorities</li>\n<li><strong>Cipher Suite Configuration</strong>: Configure allowed cipher suites prioritizing modern, secure algorithms like AES-GCM and ChaCha20-Poly1305</li>\n<li><strong>Protocol Version Limits</strong>: Set minimum and maximum TLS versions, typically requiring TLS 1.2 or higher for security</li>\n<li><strong>Session Cache Setup</strong>: Configure session resumption cache to improve performance for returning clients</li>\n<li><strong>SNI Callback Registration</strong>: Register Server Name Indication callback for dynamic certificate selection</li>\n<li><strong>Security Parameter Validation</strong>: Verify all security parameters meet organizational security policies</li>\n</ol>\n<p>Certificate reloading presents unique challenges in a production environment where the proxy cannot afford downtime. The component implements a sophisticated certificate monitoring system that detects file system changes and performs atomic context updates.</p>\n<p>⚠️ <strong>Pitfall: Certificate and Private Key Mismatch</strong>\nLoading certificates and private keys from separate files can result in cryptographic mismatches that only surface during TLS handshakes. The component must verify that each private key corresponds to its certificate by performing a cryptographic validation immediately after loading. Failing to validate this relationship results in TLS handshake failures that are difficult to diagnose in production environments.</p>\n<p>The certificate monitoring system operates through a dedicated background thread that periodically checks certificate file modification times and validates new certificates before performing atomic swaps. This approach ensures that certificate renewals (common with automated systems like Let&#39;s Encrypt) don&#39;t require proxy restarts or service interruptions.</p>\n<p>Certificate storage security requires careful attention to file system permissions and memory management. Private keys must be stored in files readable only by the proxy process user, and private key material in memory should be cleared when contexts are destroyed. The component implements secure memory allocation for key material and ensures that sensitive data doesn&#39;t persist in process memory dumps or swap files.</p>\n<h3 id=\"server-name-indication\">Server Name Indication</h3>\n<p>Server Name Indication (SNI) enables a single proxy instance to serve multiple domains with different SSL certificates, much like how a multilingual receptionist can greet visitors in their preferred language. When clients initiate TLS connections, they include the hostname they&#39;re trying to reach in the SNI extension, allowing the proxy to select the appropriate certificate for that specific domain.</p>\n<p>The SNI implementation centers around a callback mechanism that executes during the TLS handshake process. When a client sends a TLS ClientHello message containing an SNI extension, OpenSSL invokes the proxy&#39;s SNI callback function, providing the requested hostname. The proxy must then locate the appropriate TLS context for that hostname and switch the connection to use the correct certificate and configuration.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fssl-handshake-sequence.svg\" alt=\"SSL Termination and SNI Processing\"></p>\n<p>The SNI selection algorithm handles several complex scenarios including exact hostname matches, wildcard certificate matching, and fallback behavior for unrecognized domains. Wildcard certificates (e.g., *.example.com) require careful pattern matching logic that understands DNS wildcard semantics while maintaining security boundaries.</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Client Action</th>\n<th>Proxy Response</th>\n<th>Next State</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>TLS_HANDSHAKE_INIT</code></td>\n<td>ClientHello with SNI</td>\n<td>Select appropriate certificate context</td>\n<td><code>TLS_CONTEXT_SELECTED</code></td>\n</tr>\n<tr>\n<td><code>TLS_CONTEXT_SELECTED</code></td>\n<td>Continue handshake</td>\n<td>Send ServerHello with selected certificate</td>\n<td><code>TLS_CERTIFICATE_SENT</code></td>\n</tr>\n<tr>\n<td><code>TLS_CERTIFICATE_SENT</code></td>\n<td>Certificate validation</td>\n<td>Process client certificate if required</td>\n<td><code>TLS_KEY_EXCHANGE</code></td>\n</tr>\n<tr>\n<td><code>TLS_KEY_EXCHANGE</code></td>\n<td>Key exchange completion</td>\n<td>Generate session keys</td>\n<td><code>TLS_HANDSHAKE_COMPLETE</code></td>\n</tr>\n<tr>\n<td><code>TLS_HANDSHAKE_COMPLETE</code></td>\n<td>Application data</td>\n<td>Decrypt and forward to backend</td>\n<td><code>TLS_APPLICATION_DATA</code></td>\n</tr>\n</tbody></table>\n<p>The hostname matching logic must handle various edge cases that occur in real-world deployments. International domain names require proper Unicode normalization and IDNA encoding. Case sensitivity variations in hostnames need consistent handling. Port numbers included in Host headers must be stripped when matching against certificate subject names.</p>\n<blockquote>\n<p><strong>Decision: Wildcard Certificate Matching Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to support wildcard certificates (*.example.com) while maintaining security boundaries and preventing certificate misuse</li>\n<li><strong>Options Considered</strong>: Simple string matching, regex-based matching, DNS-compliant wildcard matching</li>\n<li><strong>Decision</strong>: DNS-compliant wildcard matching following RFC 6125 guidelines</li>\n<li><strong>Rationale</strong>: DNS wildcards have specific semantic rules that must be followed for security. Simple string matching can create security vulnerabilities, while regex matching is overkill and potentially slower</li>\n<li><strong>Consequences</strong>: Enables proper wildcard certificate support with strong security guarantees but requires implementing RFC-compliant matching logic</li>\n</ul>\n</blockquote>\n<p>The SNI callback implementation requires thread-safe access to the certificate context map since multiple TLS handshakes may occur simultaneously. The component uses read-write locks to allow concurrent access to the context map while serializing updates during certificate reloads.</p>\n<p>Certificate selection follows a priority order designed to provide the most specific match for each request:</p>\n<ol>\n<li><strong>Exact Hostname Match</strong>: Direct lookup in the context map for the exact requested hostname</li>\n<li><strong>Wildcard Certificate Match</strong>: Check for wildcard certificates that cover the requested domain following DNS wildcard rules</li>\n<li><strong>Subject Alternative Name Match</strong>: Examine SAN extensions in certificates for additional hostname matches</li>\n<li><strong>Default Context Fallback</strong>: Use the default certificate context if no specific match is found</li>\n<li><strong>Connection Termination</strong>: Optionally terminate connections that don&#39;t match any configured certificate</li>\n</ol>\n<p>The wildcard matching algorithm implements RFC 6125 semantics, which specify that wildcards only match a single DNS label and cannot span multiple levels. For example, *.example.com matches api.example.com but not sub.api.example.com. This restriction prevents overly broad certificate matching that could create security vulnerabilities.</p>\n<p>SNI-based certificate selection enables advanced deployment scenarios such as hosting multiple customer domains on a single proxy instance, gradual certificate migrations, and A/B testing of different TLS configurations. However, it also introduces complexity in certificate management and monitoring since each domain requires separate certificate lifecycle management.</p>\n<p>⚠️ <strong>Pitfall: SNI Extension Missing from Client</strong>\nOlder clients or certain automated tools may not include SNI extensions in their TLS handshakes, causing certificate selection to fail or fall back to default certificates. The proxy must handle these cases gracefully by providing a sensible default certificate that can serve the most common domain or by terminating connections with clear error messages that guide clients toward proper SNI support.</p>\n<p>Certificate caching and context pooling optimize performance for high-throughput scenarios where thousands of TLS handshakes occur simultaneously. The component maintains a cache of recently used certificate contexts and pre-computes expensive cryptographic operations where possible.</p>\n<h3 id=\"ssl-termination-decisions\">SSL Termination Decisions</h3>\n<p>The SSL termination component faces numerous architectural decisions that significantly impact security, performance, and operational complexity. These decisions involve trade-offs between security posture, computational efficiency, memory usage, and implementation complexity.</p>\n<blockquote>\n<p><strong>Decision: TLS Version Support Policy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance security with client compatibility, considering that older TLS versions have known vulnerabilities while newer versions aren&#39;t universally supported</li>\n<li><strong>Options Considered</strong>: TLS 1.0+ (maximum compatibility), TLS 1.2+ (security focused), TLS 1.3 only (cutting edge)</li>\n<li><strong>Decision</strong>: TLS 1.2 minimum with TLS 1.3 preferred</li>\n<li><strong>Rationale</strong>: TLS 1.2 provides strong security while maintaining broad client compatibility. TLS 1.3 offers performance and security improvements where supported. TLS 1.0/1.1 have known vulnerabilities and should be deprecated</li>\n<li><strong>Consequences</strong>: Provides strong security posture while maintaining compatibility with 99%+ of modern clients but may reject very old clients that only support deprecated TLS versions</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>TLS Version</th>\n<th>Security Level</th>\n<th>Client Support</th>\n<th>Performance</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>TLS 1.0/1.1</td>\n<td>Weak (deprecated)</td>\n<td>Universal</td>\n<td>Poor</td>\n<td>No</td>\n</tr>\n<tr>\n<td>TLS 1.2+</td>\n<td>Strong</td>\n<td>99%+ modern clients</td>\n<td>Good</td>\n<td>✓ Yes</td>\n</tr>\n<tr>\n<td>TLS 1.3 Only</td>\n<td>Excellent</td>\n<td>80%+ clients</td>\n<td>Excellent</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<p>Cipher suite selection represents another critical security decision that affects both protection strength and computational performance. Modern cipher suites like AES-GCM and ChaCha20-Poly1305 provide authenticated encryption with excellent performance characteristics, while older suites like RC4 and DES have known vulnerabilities.</p>\n<blockquote>\n<p><strong>Decision: Cipher Suite Priority and Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Must choose which encryption algorithms to support, considering security strength, performance characteristics, and client compatibility</li>\n<li><strong>Options Considered</strong>: Server preference ordering, client preference ordering, security-only suites</li>\n<li><strong>Decision</strong>: Server preference with modern AEAD cipher priority</li>\n<li><strong>Rationale</strong>: Server preference allows the proxy to enforce security policy while modern AEAD ciphers provide both security and performance. ChaCha20-Poly1305 offers excellent performance on systems without AES-NI hardware acceleration</li>\n<li><strong>Consequences</strong>: Ensures strong encryption with optimal performance but may need periodic updates as cryptographic recommendations evolve</li>\n</ul>\n</blockquote>\n<p>The preferred cipher suite ordering prioritizes authenticated encryption with associated data (AEAD) ciphers that provide both confidentiality and integrity protection:</p>\n<ol>\n<li><strong>TLS_AES_256_GCM_SHA384</strong>: TLS 1.3 with AES-256 in Galois/Counter Mode</li>\n<li><strong>TLS_CHACHA20_POLY1305_SHA256</strong>: TLS 1.3 with ChaCha20-Poly1305 for ARM/mobile optimization</li>\n<li><strong>TLS_AES_128_GCM_SHA256</strong>: TLS 1.3 with AES-128 for performance-sensitive scenarios</li>\n<li><strong>ECDHE-RSA-AES256-GCM-SHA384</strong>: TLS 1.2 with perfect forward secrecy</li>\n<li><strong>ECDHE-RSA-CHACHA20-POLY1305</strong>: TLS 1.2 ChaCha20 variant for non-AES hardware</li>\n</ol>\n<p>Session resumption configuration balances security and performance by allowing clients to reuse cryptographic session state across multiple connections. This optimization significantly reduces CPU usage and connection establishment latency, particularly important for mobile clients and high-frequency API access patterns.</p>\n<blockquote>\n<p><strong>Decision: Session Resumption and Ticket Rotation</strong></p>\n<ul>\n<li><strong>Context</strong>: Session resumption improves performance by reusing TLS session state, but session tickets must be rotated regularly for security</li>\n<li><strong>Options Considered</strong>: No session resumption (security focused), session IDs only, session tickets with rotation</li>\n<li><strong>Decision</strong>: Session tickets with automatic rotation every 24 hours</li>\n<li><strong>Rationale</strong>: Session tickets provide better scalability than session IDs while rotation prevents long-term session compromise. 24-hour rotation balances security with operational simplicity</li>\n<li><strong>Consequences</strong>: Achieves optimal TLS performance with good security properties but requires implementing ticket key rotation and handling rotation edge cases</li>\n</ul>\n</blockquote>\n<p>Certificate validation and chain building require sophisticated logic to handle the complexities of real-world PKI deployments. Certificate chains may include intermediate certificates, cross-signed roots, and alternative validation paths. The component must build complete validation chains while respecting certificate policies and constraints.</p>\n<p>The certificate chain validation process involves several security-critical steps:</p>\n<ol>\n<li><strong>Certificate Chain Construction</strong>: Build complete chains from leaf certificates to trusted root authorities</li>\n<li><strong>Signature Verification</strong>: Validate cryptographic signatures throughout the certificate chain</li>\n<li><strong>Validity Period Check</strong>: Ensure all certificates are within their valid time ranges</li>\n<li><strong>Revocation Checking</strong>: Optionally check certificate revocation status via CRL or OCSP</li>\n<li><strong>Policy Validation</strong>: Verify certificate policies and key usage constraints</li>\n<li><strong>Hostname Validation</strong>: Confirm certificate subject names match the requested hostname</li>\n</ol>\n<p>Memory management for SSL contexts and session data requires careful attention to prevent both memory leaks and security vulnerabilities. TLS session data contains sensitive cryptographic material that must be cleared when sessions end. Context switching during SNI selection must preserve memory isolation between different domains.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Certificate Chain Validation</strong>\nMany SSL implementations perform minimal certificate validation, checking only basic cryptographic signatures while ignoring critical security constraints like key usage, certificate policies, and validity periods. Production reverse proxies must implement comprehensive validation that matches browser security standards to prevent accepting compromised or misused certificates.</p>\n<p>Performance optimization in SSL termination focuses on reducing per-connection computational overhead while maintaining security properties. Hardware acceleration through AES-NI instructions, optimized cipher suite selection, and connection pooling all contribute to scalable TLS performance.</p>\n<p>The SSL termination component integrates with the broader proxy architecture through well-defined interfaces that isolate TLS complexity from other components. Once TLS connections are established and decrypted, they appear as standard HTTP connections to the HTTP parser and connection manager components.</p>\n<p>Error handling in SSL termination must distinguish between client errors (invalid certificates, unsupported protocols), server configuration errors (missing certificates, expired keys), and network errors (connection timeouts, malformed packets). Each error category requires different logging levels and recovery strategies.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Private Key Exposure in Memory Dumps</strong>\nPrivate key material loaded into process memory can be exposed through core dumps, swap files, or memory debugging tools. The SSL termination component must use secure memory allocation functions (like <code>mlock()</code>) to prevent key material from being written to disk and explicitly clear memory regions containing sensitive data when contexts are destroyed.</p>\n<p>⚠️ <strong>Pitfall: Certificate Expiration Without Monitoring</strong>\nProduction deployments frequently experience outages due to expired certificates that weren&#39;t renewed in time. The component should implement certificate expiration monitoring that logs warnings well before certificates expire and optionally exposes metrics for external monitoring systems to alert on approaching expiration dates.</p>\n<p>⚠️ <strong>Pitfall: Weak Cipher Suite Configuration</strong>\nDefault OpenSSL cipher configurations may include weak or deprecated algorithms for compatibility reasons. Production deployments must explicitly configure cipher suite preferences to exclude vulnerable algorithms like RC4, DES, and export-grade ciphers while prioritizing modern AEAD ciphers.</p>\n<p>⚠️ <strong>Pitfall: Improper SNI Fallback Handling</strong>\nWhen clients don&#39;t provide SNI extensions or request unrecognized hostnames, the proxy must handle these cases gracefully. Falling back to a default certificate that doesn&#39;t match the requested hostname can cause certificate validation errors in clients, while terminating connections may impact legitimate traffic.</p>\n<p>⚠️ <strong>Pitfall: Certificate Reload Race Conditions</strong>\nDynamic certificate reloading during production traffic can create race conditions where some connections use old certificates while others use new ones. The component must implement atomic context switching that ensures all new connections use updated certificates while allowing existing connections to complete with their original contexts.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The SSL termination component requires careful integration with OpenSSL and precise handling of cryptographic material. The implementation balances security requirements with performance needs while maintaining operational simplicity.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>TLS Library</td>\n<td>OpenSSL 1.1.1+ with basic configuration</td>\n<td>OpenSSL 3.0+ with provider architecture</td>\n</tr>\n<tr>\n<td>Certificate Storage</td>\n<td>File-based PEM certificates</td>\n<td>Hardware Security Module (HSM) integration</td>\n</tr>\n<tr>\n<td>Session Management</td>\n<td>In-memory session cache</td>\n<td>Distributed session store with Redis</td>\n</tr>\n<tr>\n<td>Certificate Monitoring</td>\n<td>Filesystem polling with inotify</td>\n<td>Certificate transparency log monitoring</td>\n</tr>\n<tr>\n<td>Performance Optimization</td>\n<td>Basic cipher suite selection</td>\n<td>Hardware acceleration with AES-NI and AVX</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>proxy/\n  src/\n    ssl/\n      ssl_termination.h        ← SSL component interface\n      ssl_termination.c        ← Core SSL termination logic\n      ssl_context.h           ← TLS context management\n      ssl_context.c           ← Context creation and certificate loading\n      ssl_sni.h              ← SNI handling interface\n      ssl_sni.c              ← SNI callback and hostname matching\n      ssl_session.h          ← Session resumption management\n      ssl_session.c          ← Session cache and ticket rotation\n      ssl_utils.h            ← SSL utility functions\n      ssl_utils.c            ← Certificate validation and crypto helpers\n      ssl_config.h           ← SSL configuration structures\n      ssl_config.c           ← Configuration parsing and validation\n    tests/\n      test_ssl_termination.c  ← SSL termination tests\n      test_ssl_context.c      ← Context management tests\n      test_ssl_sni.c         ← SNI handling tests\n      ssl_test_certs/        ← Test certificates and keys\n        test_server.crt\n        test_server.key\n        test_ca.crt\n        wildcard_test.crt\n        wildcard_test.key</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ssl_utils.h - SSL utility functions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#ifndef</span><span style=\"color:#B392F0\"> SSL_UTILS_H</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> SSL_UTILS_H</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;openssl/ssl.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;openssl/x509.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;openssl/x509v3.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;openssl/err.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;openssl/pem.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdbool.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Certificate validation result structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> valid;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> error_message</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> expires_at;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> subject_name</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> issuer_name</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#F97583\"> **</span><span style=\"color:#E1E4E8\">san_entries;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> san_count;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} CertificateInfo;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize OpenSSL library</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Clean up OpenSSL library</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> ssl_utils_cleanup</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Load certificate from PEM file with validation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_utils_load_certificate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> cert_path</span><span style=\"color:#E1E4E8\">, CertificateInfo</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> info</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Load private key from PEM file</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">EVP_PKEY</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_utils_load_private_key</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key_path</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Verify that private key matches certificate</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_verify_key_cert_match</span><span style=\"color:#E1E4E8\">(EVP_PKEY</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">, X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Extract hostname from certificate (CN or SAN)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_extract_hostnames</span><span style=\"color:#E1E4E8\">(X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char***</span><span style=\"color:#FFAB70\"> hostnames</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t*</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Check if hostname matches certificate (with wildcard support)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_hostname_matches_cert</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> hostname</span><span style=\"color:#E1E4E8\">, X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Get certificate expiration time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">time_t</span><span style=\"color:#B392F0\"> ssl_utils_get_cert_expiration</span><span style=\"color:#E1E4E8\">(X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Check if certificate is expired or expiring soon</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_cert_expires_soon</span><span style=\"color:#E1E4E8\">(X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> days_threshold</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Build complete certificate chain</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">STACK_OF</span><span style=\"color:#E1E4E8\">(X509)</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_utils_build_cert_chain</span><span style=\"color:#E1E4E8\">(X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> chain_path</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Configure secure cipher suites</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_set_secure_ciphers</span><span style=\"color:#E1E4E8\">(SSL_CTX</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ctx</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Set up TLS version restrictions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_set_tls_versions</span><span style=\"color:#E1E4E8\">(SSL_CTX</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ctx</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> min_version</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> max_version</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Free certificate info structure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> ssl_utils_free_cert_info</span><span style=\"color:#E1E4E8\">(CertificateInfo</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> info</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#endif</span><span style=\"color:#6A737D\"> // SSL_UTILS_H</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ssl_utils.c - Complete SSL utility implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"ssl_utils.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\"> ssl_initialized </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (ssl_initialized) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    SSL_load_error_strings</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    SSL_library_init</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    OpenSSL_add_all_algorithms</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ssl_initialized </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> ssl_utils_cleanup</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">ssl_initialized) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    EVP_cleanup</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    ERR_free_strings</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ssl_initialized </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_utils_load_certificate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> cert_path</span><span style=\"color:#E1E4E8\">, CertificateInfo</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> info</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FILE</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cert_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> fopen</span><span style=\"color:#E1E4E8\">(cert_path, </span><span style=\"color:#9ECBFF\">\"r\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">cert_file) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (info) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            snprintf</span><span style=\"color:#E1E4E8\">(info->error_message, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(info->error_message), </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"Cannot open certificate file: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, cert_path);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            info->valid </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cert </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> PEM_read_X509</span><span style=\"color:#E1E4E8\">(cert_file, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    fclose</span><span style=\"color:#E1E4E8\">(cert_file);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">cert) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (info) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            snprintf</span><span style=\"color:#E1E4E8\">(info->error_message, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(info->error_message), </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"Cannot parse certificate file: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, cert_path);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            info->valid </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (info) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        info->valid </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        info->expires_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> ssl_utils_get_cert_expiration</span><span style=\"color:#E1E4E8\">(cert);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Extract subject name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X509_NAME</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> subject </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> X509_get_subject_name</span><span style=\"color:#E1E4E8\">(cert);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        X509_NAME_oneline</span><span style=\"color:#E1E4E8\">(subject, info->subject_name, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(info->subject_name));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Extract issuer name</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        X509_NAME</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> issuer </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> X509_get_issuer_name</span><span style=\"color:#E1E4E8\">(cert);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        X509_NAME_oneline</span><span style=\"color:#E1E4E8\">(issuer, info->issuer_name, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(info->issuer_name));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Extract SAN entries</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        ssl_utils_extract_hostnames</span><span style=\"color:#E1E4E8\">(cert, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">info->san_entries, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">info->san_count);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> cert;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">EVP_PKEY</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_utils_load_private_key</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> key_path</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FILE</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> key_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> fopen</span><span style=\"color:#E1E4E8\">(key_path, </span><span style=\"color:#9ECBFF\">\"r\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">key_file) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EVP_PKEY</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> key </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> PEM_read_PrivateKey</span><span style=\"color:#E1E4E8\">(key_file, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    fclose</span><span style=\"color:#E1E4E8\">(key_file);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> key;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_verify_key_cert_match</span><span style=\"color:#E1E4E8\">(EVP_PKEY</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> key</span><span style=\"color:#E1E4E8\">, X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">key </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">cert) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EVP_PKEY</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cert_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> X509_get_pubkey</span><span style=\"color:#E1E4E8\">(cert);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">cert_key) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> result </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> EVP_PKEY_cmp</span><span style=\"color:#E1E4E8\">(key, cert_key);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    EVP_PKEY_free</span><span style=\"color:#E1E4E8\">(cert_key);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> result </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_extract_hostnames</span><span style=\"color:#E1E4E8\">(X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char***</span><span style=\"color:#FFAB70\"> hostnames</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t*</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    STACK_OF</span><span style=\"color:#E1E4E8\">(GENERAL_NAME)</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> san_names </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    san_names </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> X509_get_ext_d2i</span><span style=\"color:#E1E4E8\">(cert, NID_subject_alt_name, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">san_names) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        *</span><span style=\"color:#E1E4E8\">hostnames </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        *</span><span style=\"color:#E1E4E8\">count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Not an error, just no SAN extension</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> san_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> sk_GENERAL_NAME_num</span><span style=\"color:#E1E4E8\">(san_names);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">hostnames </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(san_count </span><span style=\"color:#F97583\">*</span><span style=\"color:#F97583\"> sizeof</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">char*</span><span style=\"color:#E1E4E8\">));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    *</span><span style=\"color:#E1E4E8\">count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> san_count; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        GENERAL_NAME</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> name </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> sk_GENERAL_NAME_value</span><span style=\"color:#E1E4E8\">(san_names, i);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (name->type </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> GEN_DNS) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            char*</span><span style=\"color:#E1E4E8\"> hostname </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">char*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#B392F0\">ASN1_STRING_get0_data</span><span style=\"color:#E1E4E8\">(name->d.dNSName);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">hostnames)[</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">count] </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> strdup</span><span style=\"color:#E1E4E8\">(hostname);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">count)</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    sk_GENERAL_NAME_pop_free</span><span style=\"color:#E1E4E8\">(san_names, GENERAL_NAME_free);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">time_t</span><span style=\"color:#B392F0\"> ssl_utils_get_cert_expiration</span><span style=\"color:#E1E4E8\">(X509</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cert</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ASN1_TIME</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> not_after </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> X509_get_notAfter</span><span style=\"color:#E1E4E8\">(cert);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> tm tm;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#B392F0\">ASN1_TIME_to_tm</span><span style=\"color:#E1E4E8\">(not_after, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">tm)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> mktime</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">tm);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_set_secure_ciphers</span><span style=\"color:#E1E4E8\">(SSL_CTX</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ctx</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#E1E4E8\"> cipher_list </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#B392F0\"> SSL_CTX_set_cipher_list</span><span style=\"color:#E1E4E8\">(ctx, cipher_list) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_utils_set_tls_versions</span><span style=\"color:#E1E4E8\">(SSL_CTX</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ctx</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> min_version</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> max_version</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">SSL_CTX_set_min_proto_version</span><span style=\"color:#E1E4E8\">(ctx, min_version) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">SSL_CTX_set_max_proto_version</span><span style=\"color:#E1E4E8\">(ctx, max_version) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ssl_termination.h - SSL Termination component interface</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#ifndef</span><span style=\"color:#B392F0\"> SSL_TERMINATION_H</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> SSL_TERMINATION_H</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"ssl_utils.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../config.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../hashtable.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;pthread.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> contexts;</span><span style=\"color:#6A737D\">           // Maps domain names to SSL_CTX*</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SSL_CTX</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> default_context;</span><span style=\"color:#6A737D\">     // Fallback context</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> cipher_list</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">       // Configured cipher suites</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> min_tls_version;</span><span style=\"color:#6A737D\">          // Minimum TLS version</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> max_tls_version;</span><span style=\"color:#6A737D\">          // Maximum TLS version</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_rwlock_t</span><span style=\"color:#E1E4E8\"> context_mutex;</span><span style=\"color:#6A737D\"> // Protects context map</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> cert_reload_thread;</span><span style=\"color:#6A737D\"> // Certificate monitoring thread</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> reload_interval;</span><span style=\"color:#6A737D\">          // Reload check interval</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span><span style=\"color:#6A737D\">                 // Component running state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} SSLTermination;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Create and initialize SSL termination component</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_termination_create</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Start SSL termination component (starts background threads)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_termination_start</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Stop SSL termination component and cleanup resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> ssl_termination_stop</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Destroy SSL termination component</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> ssl_termination_destroy</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Create SSL connection wrapper for client socket</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">SSL</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_termination_accept_connection</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> client_fd</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// SNI callback for certificate selection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> ssl_termination_sni_callback</span><span style=\"color:#E1E4E8\">(SSL</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int*</span><span style=\"color:#FFAB70\"> ad</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Reload certificates from disk (for certificate renewal)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_termination_reload_certificates</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#endif</span><span style=\"color:#6A737D\"> // SSL_TERMINATION_H</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// ssl_termination.c - Core SSL termination logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"ssl_termination.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"../logger.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/stat.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_termination_create</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate SSLTermination structure and initialize fields</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Initialize OpenSSL library using ssl_utils_init()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Create hash table for certificate contexts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Initialize read-write lock for thread-safe context access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Load and validate all configured certificates and private keys</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Create SSL_CTX for each certificate domain</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Configure cipher suites and TLS versions for each context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Set up default context for unmatched SNI requests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Register SNI callback for dynamic certificate selection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 10: Validate that all contexts are properly configured</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use config->ssl_cert_path and config->ssl_key_path for certificate loading</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Call ssl_utils_verify_key_cert_match() to ensure key/cert pairs match</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_termination_start</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Set running flag to true</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create certificate reload monitoring thread</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Start background thread with cert_reload_monitor function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Return true if all threads started successfully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use pthread_create() to start the certificate monitoring thread</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">SSL</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> ssl_termination_accept_connection</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> client_fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create new SSL connection using default context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Set file descriptor for SSL connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Configure SSL connection for server mode</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set SNI callback data to point to ssl_term</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Perform SSL handshake with client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Handle handshake errors gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Return established SSL connection or NULL on failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use SSL_new(), SSL_set_fd(), SSL_set_accept_state(), SSL_accept()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Check SSL_get_error() for detailed error information on failure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> ssl_termination_sni_callback</span><span style=\"color:#E1E4E8\">(SSL</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int*</span><span style=\"color:#FFAB70\"> ad</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Cast arg back to SSLTermination pointer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Get requested hostname from SSL connection using SSL_get_servername()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Acquire read lock on context mutex for thread safety</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Look up SSL_CTX for requested hostname in contexts hash table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: If exact match found, set SSL context using SSL_set_SSL_CTX()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: If no exact match, try wildcard certificate matching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: If still no match, use default context (already set)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Release read lock on context mutex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Return SSL_TLSEXT_ERR_OK on success or SSL_TLSEXT_ERR_ALERT_FATAL on error</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use hashtable_get() to look up contexts by hostname</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Implement wildcard matching following DNS wildcard rules (*.domain.com)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> ssl_termination_reload_certificates</span><span style=\"color:#E1E4E8\">(SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Acquire write lock on context mutex to prevent concurrent access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Iterate through all certificate files checking modification times</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: For each modified certificate, load and validate new certificate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Create new SSL_CTX with updated certificate and key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Replace old context in hash table with new context atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Free old SSL_CTX after replacement to prevent memory leaks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Log certificate reload events for operational visibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Release write lock on context mutex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 9: Return true if all reloads successful, false if any failed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use stat() to check file modification times</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Keep track of last reload time to avoid unnecessary work</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing SSL termination, verify functionality with these steps:</p>\n<p><strong>Basic SSL Connection Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test HTTPS connection with self-signed certificate</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">openssl</span><span style=\"color:#9ECBFF\"> s_client</span><span style=\"color:#79B8FF\"> -connect</span><span style=\"color:#9ECBFF\"> localhost:8443</span><span style=\"color:#79B8FF\"> -servername</span><span style=\"color:#9ECBFF\"> test.example.com</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should show certificate details and establish connection</span></span></code></pre></div>\n\n<p><strong>SNI Functionality Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test different hostnames resolve to different certificates</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">openssl</span><span style=\"color:#9ECBFF\"> s_client</span><span style=\"color:#79B8FF\"> -connect</span><span style=\"color:#9ECBFF\"> localhost:8443</span><span style=\"color:#79B8FF\"> -servername</span><span style=\"color:#9ECBFF\"> api.example.com</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">openssl</span><span style=\"color:#9ECBFF\"> s_client</span><span style=\"color:#79B8FF\"> -connect</span><span style=\"color:#9ECBFF\"> localhost:8443</span><span style=\"color:#79B8FF\"> -servername</span><span style=\"color:#9ECBFF\"> web.example.com</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Should show different certificate subjects for different hostnames</span></span></code></pre></div>\n\n<p><strong>Expected Behavior:</strong></p>\n<ul>\n<li>HTTPS connections establish successfully with proper certificate presentation</li>\n<li>SNI selects appropriate certificates based on requested hostname</li>\n<li>Proxy decrypts HTTPS traffic and forwards plain HTTP to backends</li>\n<li>Certificate reload works without restarting the proxy process</li>\n<li>Logs show SSL handshake success/failure events with clear error messages</li>\n</ul>\n<p><strong>Signs of Problems:</strong></p>\n<ul>\n<li>&quot;SSL handshake failed&quot; errors indicate certificate or configuration issues</li>\n<li>&quot;Certificate verification failed&quot; suggests certificate chain problems</li>\n<li>&quot;SNI callback failed&quot; indicates hostname matching logic errors</li>\n<li>Memory leaks during certificate reloading suggest cleanup issues</li>\n</ul>\n<h2 id=\"interactions-and-data-flow\">Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - understanding component interactions is essential for HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).</p>\n</blockquote>\n<p>Think of a reverse proxy as a sophisticated air traffic control system. Just as air traffic controllers coordinate multiple aircraft, runways, and weather services to safely guide planes from departure to destination, a reverse proxy orchestrates multiple components - HTTP parsers, connection managers, load balancers, cache engines, and SSL terminators - to guide client requests through a complex journey to backend servers and back. Each component has specialized responsibilities, but they must communicate seamlessly to deliver a cohesive service. The air traffic analogy helps us understand that timing, coordination, and clear communication protocols between components are absolutely critical for system reliability and performance.</p>\n<p>The interaction patterns between reverse proxy components follow well-defined protocols, much like how air traffic control uses standardized communication procedures. Each component exposes specific interfaces, maintains its own internal state, and participates in the larger request processing workflow. Understanding these interactions is crucial because the reverse proxy&#39;s performance, reliability, and correctness depend entirely on how effectively these components collaborate.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Fsystem-components.svg\" alt=\"System Component Architecture\"></p>\n<h3 id=\"request-processing-flow\">Request Processing Flow</h3>\n<p>The request processing flow represents the complete journey of an HTTP request from client arrival to response delivery, traversing through multiple components in a carefully orchestrated sequence. Think of this flow as a factory assembly line where each station (component) performs specialized operations on the product (HTTP request) before passing it to the next station. However, unlike a simple linear assembly line, the reverse proxy flow includes decision points, parallel processing paths, and feedback loops that make it more sophisticated.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Frequest-flow-sequence.svg\" alt=\"Request Processing Sequence\"></p>\n<p>The request processing begins when a client establishes a connection to the reverse proxy&#39;s listening socket. This initial connection may be either a plain HTTP connection or an HTTPS connection requiring SSL termination. The distinction is crucial because it determines which component handles the initial connection establishment and how the request data flows through the system.</p>\n<h4 id=\"phase-1-connection-establishment-and-initial-processing\">Phase 1: Connection Establishment and Initial Processing</h4>\n<p><strong>Step 1: Client Connection Arrival</strong></p>\n<p>When a client attempts to connect, the reverse proxy&#39;s main event loop detects the incoming connection on the listening socket. The proxy examines the destination port to determine whether this is an HTTP connection (typically port 80) or an HTTPS connection (typically port 443). This determination affects the entire subsequent processing pipeline because HTTPS connections require SSL termination before HTTP parsing can begin.</p>\n<p>For HTTP connections, the <code>ConnectionManager</code> directly accepts the client socket using <code>connection_manager_accept_client()</code>, creating a new <code>Connection</code> structure initialized in the <code>CONNECTION_IDLE</code> state. The connection includes buffers for request and response data, timing information, and state tracking fields that guide subsequent processing decisions.</p>\n<p>For HTTPS connections, the <code>SSLTermination</code> component first accepts the connection using <code>ssl_termination_accept_connection()</code>, which performs the TLS handshake. During this handshake, the SSL termination component examines the Server Name Indication (SNI) extension to select the appropriate SSL certificate for the requested hostname. The <code>ssl_termination_sni_callback()</code> function handles this certificate selection by looking up the hostname in the SSL context hash table and returning the corresponding SSL context.</p>\n<p><strong>Step 2: SSL Termination Processing (HTTPS only)</strong></p>\n<p>For HTTPS connections, the SSL termination process involves several critical steps that must complete successfully before HTTP parsing can begin. The TLS handshake includes cipher suite negotiation, where the client and server agree on encryption algorithms. The <code>SSLTermination</code> component enforces minimum TLS versions and secure cipher suites to maintain security standards.</p>\n<p>Once the TLS handshake completes successfully, the SSL termination component creates an encrypted channel with the client. All subsequent data from the client arrives encrypted and must be decrypted using the established SSL context before passing to other components. The SSL termination component maintains the mapping between client file descriptors and their corresponding SSL contexts, enabling efficient decryption of incoming data.</p>\n<p>The decrypted HTTP data is then passed to the <code>ConnectionManager</code> for further processing, effectively converting the HTTPS connection into an internal HTTP data stream that the rest of the proxy can handle uniformly.</p>\n<p><strong>Step 3: HTTP Request Parsing</strong></p>\n<p>Once the connection is established (and decrypted if necessary), the <code>ConnectionManager</code> transitions the connection to the <code>CONNECTION_READING_REQUEST</code> state and begins accumulating HTTP request data. As data arrives on the client socket, the connection manager appends it to the connection&#39;s request buffer using <code>buffer_append()</code>.</p>\n<p>The HTTP parsing process is stream-based, meaning it processes data incrementally as it arrives rather than waiting for the complete request. The <code>HttpParser</code> component uses a state machine approach with states defined in the <code>HttpParserState</code> enumeration. The parser begins in the <code>HTTP_PARSING_REQUEST_LINE</code> state and processes the incoming data byte by byte.</p>\n<p>The <code>http_parser_process()</code> function examines each byte and makes state transitions based on the current parser state and the incoming character. For example, when parsing the request line, the parser accumulates characters until it encounters a space character, indicating the end of the HTTP method. It then transitions to parsing the URI, accumulates characters until the next space, and continues until it completes the request line with a CRLF sequence.</p>\n<p>Header parsing follows a similar pattern, where the parser accumulates header name and value pairs until it encounters the empty line that separates headers from the message body. The parser handles various HTTP complexities including case-insensitive header names, multi-line header values, and proper handling of the <code>Content-Length</code> and <code>Transfer-Encoding</code> headers that determine body parsing strategy.</p>\n<p><strong>Step 4: Request Validation and Preprocessing</strong></p>\n<p>After successful HTTP parsing, the <code>ConnectionManager</code> performs request validation to ensure the parsed request meets basic correctness requirements. This validation includes verifying that required headers are present, checking URI format validity, and ensuring HTTP version compatibility.</p>\n<p>The connection manager also performs request preprocessing by adding standard reverse proxy headers. The <code>X-Forwarded-For</code> header is added with the client&#39;s IP address, allowing backend servers to identify the original client. The <code>Via</code> header is added to indicate that the request passed through the reverse proxy, following HTTP specification requirements for proxy identification.</p>\n<p>During preprocessing, the connection manager examines the <code>Connection</code> header to determine if the client requested keep-alive behavior. This information is stored in the connection&#39;s <code>keep_alive</code> field and influences connection lifecycle management decisions later in the processing flow.</p>\n<h4 id=\"phase-2-cache-lookup-and-backend-selection\">Phase 2: Cache Lookup and Backend Selection</h4>\n<p><strong>Step 5: Cache Engine Consultation</strong></p>\n<p>Before forwarding the request to backend servers, the reverse proxy consults the <code>CacheEngine</code> to determine if a cached response can satisfy the request. The cache engine performs this lookup using <code>cache_engine_lookup()</code>, which generates a cache key based on the request characteristics.</p>\n<p>The cache key generation process considers multiple request attributes including the HTTP method, complete URI (including query parameters), and specific headers that affect response content. The <code>Vary</code> header from previously cached responses influences which request headers are included in the cache key calculation, ensuring that responses cached for different client capabilities are served appropriately.</p>\n<p>If a cache entry is found, the cache engine validates its freshness using <code>cache_is_fresh()</code>. This validation examines the entry&#39;s expiration time, calculated from <code>Cache-Control</code> directives like <code>max-age</code> and response headers like <code>Expires</code>. Fresh cache entries can be served immediately, bypassing backend server communication entirely.</p>\n<p>For stale cache entries, the cache engine can generate conditional requests using <code>cache_create_conditional()</code>. These conditional requests include <code>If-None-Match</code> headers with the cached response&#39;s ETag or <code>If-Modified-Since</code> headers with the cached response&#39;s last modification time. Conditional requests allow backend servers to respond with <code>304 Not Modified</code> if the content hasn&#39;t changed, saving bandwidth and processing time.</p>\n<p><strong>Step 6: Load Balancer Backend Selection</strong></p>\n<p>When a cache miss occurs or the request cannot be satisfied from cache, the <code>LoadBalancer</code> component selects an appropriate backend server using <code>loadbalancer_select_backend()</code>. The selection process depends on the configured load balancing algorithm and the current health status of backend servers.</p>\n<p>The load balancer first filters the backend server list to exclude servers marked as unhealthy by the health checking system. Unhealthy servers are identified by failed health check attempts or recent request failures that exceed the configured failure threshold.</p>\n<p>For healthy servers, the selection algorithm depends on the configured <code>LoadBalancingAlgorithm</code>. Round-robin selection uses the <code>rr_current_index</code> field to track the next server in rotation, incrementing atomically after each selection to ensure thread-safe operation across concurrent requests. Least-connections selection examines the <code>connection_counts</code> array to identify the backend server with the minimum number of active connections.</p>\n<p>Weighted round-robin selection is more complex, using the <code>current_weights</code> array to implement the weighted round-robin algorithm. Each server&#39;s current weight is incremented by its static weight on each selection, and the server with the highest current weight is chosen. The selected server&#39;s current weight is then decremented by the sum of all server weights, ensuring that servers with higher weights are selected proportionally more often over time.</p>\n<p>The IP hash algorithm provides session affinity by computing a hash of the client&#39;s IP address and using this hash to consistently select the same backend server for requests from the same client. This approach ensures that clients with session state requirements are always directed to the same backend server.</p>\n<h4 id=\"phase-3-backend-communication-and-connection-management\">Phase 3: Backend Communication and Connection Management</h4>\n<p><strong>Step 7: Backend Connection Acquisition</strong></p>\n<p>After backend server selection, the <code>ConnectionManager</code> acquires a connection to the selected backend using <code>connection_manager_acquire_backend()</code>. This function implements connection pooling by first checking if any idle connections to the target backend server exist in the connection pool.</p>\n<p>Connection pools are maintained per backend server in the <code>backend_pools</code> array, with each <code>ConnectionPool</code> structure tracking idle and active connections. The pool uses a LIFO (Last-In, First-Out) strategy for connection reuse, which provides better cache locality because recently used connections are more likely to have warm CPU caches and established network paths.</p>\n<p>When reusing a pooled connection, the connection manager validates the connection&#39;s health by checking if the socket is still readable without data available (indicating a connection reset) and verifying that the connection hasn&#39;t exceeded its maximum idle time. Invalid connections are discarded and replaced with new connections.</p>\n<p>If no suitable pooled connections exist, the connection manager creates a new connection to the backend server. This involves establishing a TCP socket, setting appropriate socket options like <code>TCP_NODELAY</code> to minimize latency, and configuring non-blocking I/O mode for integration with the event-driven architecture.</p>\n<p><strong>Step 8: Request Forwarding</strong></p>\n<p>With a backend connection acquired, the connection manager forwards the HTTP request to the backend server. The forwarding process involves serializing the parsed HTTP request back into the standard HTTP wire format, but with modifications appropriate for backend communication.</p>\n<p>The forwarded request includes the modified headers added during preprocessing, ensuring that backend servers receive client identification information. The connection manager may modify or remove certain headers that are only relevant for client-proxy communication, such as <code>Proxy-Authorization</code> headers.</p>\n<p>Request forwarding handles various HTTP complexities including chunked transfer encoding and request bodies. For requests with <code>Content-Length</code> headers, the connection manager ensures that the specified number of bytes are forwarded to the backend. For chunked requests, the proxy forwards the chunk headers and data while tracking the chunking state to detect the end of the request body.</p>\n<p>During forwarding, the connection transitions to the <code>CONNECTION_FORWARDING</code> state, and the connection manager configures epoll events to monitor both the client connection for additional request data and the backend connection for response data.</p>\n<p><strong>Step 9: Response Processing and Parsing</strong></p>\n<p>When the backend server begins sending response data, the connection manager transitions to the <code>CONNECTION_READING_RESPONSE</code> state and begins accumulating response data in the connection&#39;s response buffer. Response parsing follows a similar pattern to request parsing, using the HTTP parser component to incrementally process the response data.</p>\n<p>The HTTP response parser extracts the status line, response headers, and message body. Special attention is paid to caching-related headers including <code>Cache-Control</code>, <code>Expires</code>, <code>ETag</code>, <code>Last-Modified</code>, and <code>Vary</code>. These headers determine whether the response can be cached and how long it remains valid.</p>\n<p>Response parsing also handles various HTTP response formats including chunked transfer encoding and keep-alive connection management. The parser tracks the response completeness to determine when the entire response has been received from the backend server.</p>\n<h4 id=\"phase-4-response-caching-and-client-delivery\">Phase 4: Response Caching and Client Delivery</h4>\n<p><strong>Step 10: Cache Storage Decision</strong></p>\n<p>After receiving the complete response from the backend server, the <code>CacheEngine</code> evaluates whether the response should be cached using <code>cache_is_cacheable()</code>. This evaluation examines the response status code, HTTP method, and cache-control directives to determine cacheability.</p>\n<p>Cacheable responses are typically successful GET requests (status 200) with explicit caching directives or responses without explicit no-cache directives. The cache engine respects <code>Cache-Control: no-store</code> directives by never storing such responses, and handles <code>Cache-Control: private</code> directives by considering the proxy&#39;s role as a shared cache.</p>\n<p>For cacheable responses, the cache engine calculates the expiration time using <code>cache_control_calculate_expiry()</code>, which considers <code>max-age</code> directives, <code>Expires</code> headers, and heuristic expiration calculations for responses without explicit expiration information.</p>\n<p>The cache storage process using <code>cache_engine_store()</code> involves generating the same cache key used during lookup, creating a <code>CacheEntry</code> structure with the response data and metadata, and inserting the entry into both the hash table for fast lookup and the LRU list for eviction management.</p>\n<p><strong>Step 11: Response Delivery to Client</strong></p>\n<p>The final phase involves delivering the response to the client through the appropriate channel. For HTTP connections, the connection manager writes the response data directly to the client socket. For HTTPS connections, the response data must first pass through SSL encryption using the established SSL context.</p>\n<p>Response delivery handles various client capabilities including HTTP version differences and connection management preferences. The proxy respects the client&#39;s <code>Connection</code> header preferences, maintaining keep-alive connections when requested and possible, or closing connections when appropriate.</p>\n<p>During response delivery, the connection transitions to the <code>CONNECTION_WRITING_RESPONSE</code> state and configures epoll events to monitor the client socket for write readiness. The delivery process handles partial writes and flow control, ensuring that response data is delivered reliably even when client connections have limited receive buffers.</p>\n<p><strong>Step 12: Connection Cleanup and Recycling</strong></p>\n<p>After completing response delivery, the connection manager performs cleanup and recycling operations. Backend connections are returned to the connection pool using <code>connection_manager_release_backend()</code> if they remain healthy and the pool has capacity. This recycling process updates connection statistics and resets connection state for future reuse.</p>\n<p>Client connections are either maintained for additional requests (HTTP keep-alive) or closed based on the HTTP version, client preferences, and error conditions. Keep-alive connections transition back to the <code>CONNECTION_IDLE</code> state and remain registered for read events to detect additional incoming requests.</p>\n<p>The connection manager also updates various statistics including request counts, response times, and error rates. These statistics support monitoring, debugging, and performance optimization activities.</p>\n<h3 id=\"inter-component-communication\">Inter-Component Communication</h3>\n<p>The inter-component communication patterns define how the reverse proxy&#39;s components exchange information, coordinate activities, and maintain consistency across the distributed system architecture. Think of inter-component communication as the nervous system of the reverse proxy, carrying control signals, data messages, and status updates between specialized organs (components) that must work together to maintain the system&#39;s health and functionality.</p>\n<p>Understanding these communication patterns is essential because they determine system performance characteristics, reliability behaviors, and debugging approaches. The communication patterns also define the system&#39;s scalability limits and guide optimization strategies for high-performance deployments.</p>\n<h4 id=\"communication-architecture-and-patterns\">Communication Architecture and Patterns</h4>\n<p>The reverse proxy uses an event-driven communication architecture where components interact through well-defined interfaces rather than direct memory sharing or global variables. This architecture provides isolation between components, enabling independent testing, debugging, and optimization of each component while maintaining clear contracts for inter-component collaboration.</p>\n<p><strong>Message-Based Communication</strong></p>\n<p>Components communicate primarily through structured messages passed via function calls rather than shared memory regions. This approach provides type safety, clear ownership semantics, and explicit error handling paths that improve system reliability and maintainability.</p>\n<table>\n<thead>\n<tr>\n<th>Message Type</th>\n<th>Source Component</th>\n<th>Target Component</th>\n<th>Purpose</th>\n<th>Data Included</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Request</td>\n<td>Connection Manager</td>\n<td>HTTP Parser</td>\n<td>Request parsing initiation</td>\n<td>Raw HTTP data buffer</td>\n</tr>\n<tr>\n<td>Parsed Request</td>\n<td>HTTP Parser</td>\n<td>Connection Manager</td>\n<td>Parsing completion notification</td>\n<td>HttpRequest structure</td>\n</tr>\n<tr>\n<td>Backend Selection</td>\n<td>Connection Manager</td>\n<td>Load Balancer</td>\n<td>Backend server selection</td>\n<td>HttpRequest, client info</td>\n</tr>\n<tr>\n<td>Selected Backend</td>\n<td>Load Balancer</td>\n<td>Connection Manager</td>\n<td>Backend selection result</td>\n<td>BackendServer pointer</td>\n</tr>\n<tr>\n<td>Cache Lookup</td>\n<td>Connection Manager</td>\n<td>Cache Engine</td>\n<td>Cache hit evaluation</td>\n<td>HttpRequest, cache key</td>\n</tr>\n<tr>\n<td>Cache Entry</td>\n<td>Cache Engine</td>\n<td>Connection Manager</td>\n<td>Cache lookup result</td>\n<td>CacheEntry or null</td>\n</tr>\n<tr>\n<td>SSL Handshake</td>\n<td>Connection Manager</td>\n<td>SSL Termination</td>\n<td>TLS connection establishment</td>\n<td>Client socket, SNI hostname</td>\n</tr>\n<tr>\n<td>Decrypted Data</td>\n<td>SSL Termination</td>\n<td>Connection Manager</td>\n<td>Decrypted HTTP data</td>\n<td>Buffer with plain HTTP</td>\n</tr>\n</tbody></table>\n<p><strong>Event-Driven Coordination</strong></p>\n<p>The communication architecture uses event-driven coordination where components register for specific events and respond asynchronously when those events occur. The <code>ConnectionManager</code> serves as the central event coordinator, using epoll-based event monitoring to detect socket events and coordinating responses across multiple components.</p>\n<p>Event-driven coordination enables high concurrency because components don&#39;t block waiting for responses from other components. Instead, components initiate operations and continue processing other tasks while waiting for asynchronous completion notifications.</p>\n<h4 id=\"component-interface-specifications\">Component Interface Specifications</h4>\n<p>Each component exposes well-defined interfaces that specify exactly how other components can interact with it. These interfaces include function signatures, parameter requirements, return value semantics, and error handling behaviors.</p>\n<p><strong>Connection Manager Interfaces</strong></p>\n<p>The <code>ConnectionManager</code> provides the primary coordination interfaces used by other components to participate in request processing workflows.</p>\n<table>\n<thead>\n<tr>\n<th>Interface Method</th>\n<th>Parameters</th>\n<th>Return Value</th>\n<th>Description</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>connection_manager_accept_client</code></td>\n<td><code>ConnectionManager*</code>, <code>int client_fd</code></td>\n<td><code>Connection*</code></td>\n<td>Accept new client connection and initialize state</td>\n<td>Returns NULL on memory allocation failure</td>\n</tr>\n<tr>\n<td><code>connection_manager_acquire_backend</code></td>\n<td><code>ConnectionManager*</code>, <code>BackendServer*</code>, <code>int timeout_ms</code></td>\n<td><code>Connection*</code></td>\n<td>Acquire backend connection from pool or create new</td>\n<td>Returns NULL on connection failure or timeout</td>\n</tr>\n<tr>\n<td><code>connection_manager_release_backend</code></td>\n<td><code>ConnectionManager*</code>, <code>Connection*</code>, <code>bool keep_alive</code></td>\n<td><code>void</code></td>\n<td>Return backend connection to pool or close</td>\n<td>No error return - best effort cleanup</td>\n</tr>\n<tr>\n<td><code>connection_manager_handle_event</code></td>\n<td><code>ConnectionManager*</code>, <code>Connection*</code>, <code>uint32_t events</code></td>\n<td><code>void</code></td>\n<td>Process connection state transition events</td>\n<td>Logs errors but continues processing</td>\n</tr>\n<tr>\n<td><code>connection_manager_close_connection</code></td>\n<td><code>ConnectionManager*</code>, <code>Connection*</code></td>\n<td><code>void</code></td>\n<td>Clean up connection and release resources</td>\n<td>No error return - best effort cleanup</td>\n</tr>\n</tbody></table>\n<p><strong>HTTP Parser Interfaces</strong></p>\n<p>The <code>HttpParser</code> component provides stream-based parsing interfaces that support incremental processing of HTTP data as it arrives from network connections.</p>\n<table>\n<thead>\n<tr>\n<th>Interface Method</th>\n<th>Parameters</th>\n<th>Return Value</th>\n<th>Description</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>http_parser_create</code></td>\n<td><code>void</code></td>\n<td><code>HttpParser*</code></td>\n<td>Initialize new parser instance</td>\n<td>Returns NULL on memory allocation failure</td>\n</tr>\n<tr>\n<td><code>http_parser_process</code></td>\n<td><code>HttpParser*</code>, <code>char* data</code>, <code>size_t length</code></td>\n<td><code>int</code></td>\n<td>Process incoming HTTP data incrementally</td>\n<td>Returns negative on parsing errors</td>\n</tr>\n<tr>\n<td><code>http_request_create</code></td>\n<td><code>void</code></td>\n<td><code>HttpRequest*</code></td>\n<td>Create empty HTTP request structure</td>\n<td>Returns NULL on memory allocation failure</td>\n</tr>\n<tr>\n<td><code>http_request_add_header</code></td>\n<td><code>HttpRequest*</code>, <code>char* name</code>, <code>char* value</code></td>\n<td><code>bool</code></td>\n<td>Add header to request structure</td>\n<td>Returns false on memory allocation failure</td>\n</tr>\n<tr>\n<td><code>http_request_get_header</code></td>\n<td><code>HttpRequest*</code>, <code>char* name</code></td>\n<td><code>char*</code></td>\n<td>Retrieve header value by name</td>\n<td>Returns NULL if header not found</td>\n</tr>\n</tbody></table>\n<p><strong>Load Balancer Interfaces</strong></p>\n<p>The <code>LoadBalancer</code> component provides backend selection interfaces that implement various distribution algorithms and health checking logic.</p>\n<table>\n<thead>\n<tr>\n<th>Interface Method</th>\n<th>Parameters</th>\n<th>Return Value</th>\n<th>Description</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>loadbalancer_select_backend</code></td>\n<td><code>LoadBalancer*</code>, <code>HttpRequest*</code></td>\n<td><code>BackendServer*</code></td>\n<td>Select backend using configured algorithm</td>\n<td>Returns NULL if no healthy backends available</td>\n</tr>\n<tr>\n<td><code>loadbalancer_update_connection_count</code></td>\n<td><code>LoadBalancer*</code>, <code>BackendServer*</code>, <code>int delta</code></td>\n<td><code>void</code></td>\n<td>Update active connection count for backend</td>\n<td>No error return - uses atomic operations</td>\n</tr>\n<tr>\n<td><code>select_backend_round_robin</code></td>\n<td><code>LoadBalancer*</code></td>\n<td><code>BackendServer*</code></td>\n<td>Round-robin backend selection implementation</td>\n<td>Returns NULL if no healthy backends</td>\n</tr>\n<tr>\n<td><code>select_backend_least_connections</code></td>\n<td><code>LoadBalancer*</code></td>\n<td><code>BackendServer*</code></td>\n<td>Least-connections selection implementation</td>\n<td>Returns NULL if no healthy backends</td>\n</tr>\n<tr>\n<td><code>health_check_backend</code></td>\n<td><code>LoadBalancer*</code>, <code>BackendServer*</code></td>\n<td><code>bool</code></td>\n<td>Perform health check against backend</td>\n<td>Returns false on health check failure</td>\n</tr>\n</tbody></table>\n<p><strong>Cache Engine Interfaces</strong></p>\n<p>The <code>CacheEngine</code> component provides caching interfaces that implement HTTP semantics for cache storage, retrieval, and invalidation operations.</p>\n<table>\n<thead>\n<tr>\n<th>Interface Method</th>\n<th>Parameters</th>\n<th>Return Value</th>\n<th>Description</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>cache_engine_lookup</code></td>\n<td><code>CacheEngine*</code>, <code>HttpRequest*</code></td>\n<td><code>CacheEntry*</code></td>\n<td>Find cached response for request</td>\n<td>Returns NULL on cache miss</td>\n</tr>\n<tr>\n<td><code>cache_engine_store</code></td>\n<td><code>CacheEngine*</code>, <code>char* key</code>, <code>HttpResponse*</code></td>\n<td><code>bool</code></td>\n<td>Store response in cache if cacheable</td>\n<td>Returns false if not cacheable or storage failure</td>\n</tr>\n<tr>\n<td><code>cache_engine_invalidate</code></td>\n<td><code>CacheEngine*</code>, <code>char* key</code></td>\n<td><code>bool</code></td>\n<td>Remove specific entry from cache</td>\n<td>Returns false if key not found</td>\n</tr>\n<tr>\n<td><code>cache_generate_key</code></td>\n<td><code>HttpRequest*</code></td>\n<td><code>char*</code></td>\n<td>Generate cache key for request</td>\n<td>Returns NULL on memory allocation failure</td>\n</tr>\n<tr>\n<td><code>cache_is_fresh</code></td>\n<td><code>CacheEntry*</code>, <code>time_t current_time</code></td>\n<td><code>bool</code></td>\n<td>Check if cached entry is still fresh</td>\n<td>No error conditions</td>\n</tr>\n</tbody></table>\n<p><strong>SSL Termination Interfaces</strong></p>\n<p>The <code>SSLTermination</code> component provides TLS-related interfaces for connection establishment, certificate management, and data encryption/decryption operations.</p>\n<table>\n<thead>\n<tr>\n<th>Interface Method</th>\n<th>Parameters</th>\n<th>Return Value</th>\n<th>Description</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ssl_termination_accept_connection</code></td>\n<td><code>SSLTermination*</code>, <code>int client_fd</code></td>\n<td><code>SSL*</code></td>\n<td>Perform TLS handshake for client</td>\n<td>Returns NULL on handshake failure</td>\n</tr>\n<tr>\n<td><code>ssl_termination_sni_callback</code></td>\n<td><code>SSL*</code>, <code>int* alert</code>, <code>void* context</code></td>\n<td><code>int</code></td>\n<td>SNI hostname callback for certificate selection</td>\n<td>Returns error codes for certificate selection failures</td>\n</tr>\n<tr>\n<td><code>ssl_termination_reload_certificates</code></td>\n<td><code>SSLTermination*</code></td>\n<td><code>bool</code></td>\n<td>Reload certificates from disk without restart</td>\n<td>Returns false on certificate loading errors</td>\n</tr>\n<tr>\n<td><code>ssl_utils_load_certificate</code></td>\n<td><code>char* cert_path</code>, <code>CertificateInfo*</code></td>\n<td><code>X509*</code></td>\n<td>Load certificate from PEM file</td>\n<td>Returns NULL on file or parsing errors</td>\n</tr>\n<tr>\n<td><code>ssl_utils_verify_key_cert_match</code></td>\n<td><code>EVP_PKEY*</code>, <code>X509*</code></td>\n<td><code>bool</code></td>\n<td>Verify private key matches certificate</td>\n<td>Returns false on key/certificate mismatch</td>\n</tr>\n</tbody></table>\n<h4 id=\"data-flow-coordination\">Data Flow Coordination</h4>\n<p>The data flow coordination mechanisms ensure that HTTP request and response data moves efficiently between components while maintaining data integrity and proper error handling. The coordination patterns handle various complexities including partial data availability, flow control, and cleanup after errors.</p>\n<p><strong>Request Data Flow</strong></p>\n<p>Request data flows from client connections through multiple processing stages, with each component transforming or enriching the data before passing it to the next stage.</p>\n<table>\n<thead>\n<tr>\n<th>Flow Stage</th>\n<th>Input Data</th>\n<th>Component</th>\n<th>Output Data</th>\n<th>Transformation Applied</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Raw Network Data</td>\n<td>TCP byte stream</td>\n<td>Connection Manager</td>\n<td>Buffered HTTP data</td>\n<td>Socket reading, buffering</td>\n</tr>\n<tr>\n<td>HTTP Parsing</td>\n<td>Buffered HTTP data</td>\n<td>HTTP Parser</td>\n<td>HttpRequest structure</td>\n<td>Protocol parsing, header extraction</td>\n</tr>\n<tr>\n<td>Request Preprocessing</td>\n<td>HttpRequest structure</td>\n<td>Connection Manager</td>\n<td>Enhanced HttpRequest</td>\n<td>Header addition, validation</td>\n</tr>\n<tr>\n<td>Backend Selection</td>\n<td>Enhanced HttpRequest</td>\n<td>Load Balancer</td>\n<td>BackendServer assignment</td>\n<td>Algorithm-based selection</td>\n</tr>\n<tr>\n<td>Cache Consultation</td>\n<td>Enhanced HttpRequest</td>\n<td>Cache Engine</td>\n<td>CacheEntry or cache miss</td>\n<td>Key generation, lookup</td>\n</tr>\n<tr>\n<td>Backend Forwarding</td>\n<td>Enhanced HttpRequest</td>\n<td>Connection Manager</td>\n<td>Serialized HTTP</td>\n<td>Request serialization, transmission</td>\n</tr>\n</tbody></table>\n<p><strong>Response Data Flow</strong></p>\n<p>Response data flows from backend servers back to clients, with caching and SSL encryption stages modifying the data path based on configuration and client capabilities.</p>\n<table>\n<thead>\n<tr>\n<th>Flow Stage</th>\n<th>Input Data</th>\n<th>Component</th>\n<th>Output Data</th>\n<th>Transformation Applied</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Backend Response</td>\n<td>TCP byte stream</td>\n<td>Connection Manager</td>\n<td>Buffered response data</td>\n<td>Socket reading, buffering</td>\n</tr>\n<tr>\n<td>Response Parsing</td>\n<td>Buffered response data</td>\n<td>HTTP Parser</td>\n<td>HttpResponse structure</td>\n<td>Protocol parsing, header extraction</td>\n</tr>\n<tr>\n<td>Cache Storage</td>\n<td>HttpResponse structure</td>\n<td>Cache Engine</td>\n<td>Stored CacheEntry</td>\n<td>Cacheability evaluation, storage</td>\n</tr>\n<tr>\n<td>Client Delivery</td>\n<td>HttpResponse structure</td>\n<td>Connection Manager</td>\n<td>Serialized HTTP</td>\n<td>Response serialization</td>\n</tr>\n<tr>\n<td>SSL Encryption</td>\n<td>Serialized HTTP</td>\n<td>SSL Termination</td>\n<td>Encrypted byte stream</td>\n<td>TLS encryption (HTTPS only)</td>\n</tr>\n<tr>\n<td>Client Transmission</td>\n<td>Encrypted/plain data</td>\n<td>Connection Manager</td>\n<td>Network transmission</td>\n<td>Socket writing, flow control</td>\n</tr>\n</tbody></table>\n<p><strong>Error Propagation Patterns</strong></p>\n<p>Error conditions must be properly propagated between components to ensure that failures are handled gracefully and don&#39;t corrupt system state or cause resource leaks.</p>\n<table>\n<thead>\n<tr>\n<th>Error Source</th>\n<th>Detection Point</th>\n<th>Propagation Path</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Client connection failure</td>\n<td>Connection Manager</td>\n<td>Direct error return</td>\n<td>Connection cleanup, client notification</td>\n</tr>\n<tr>\n<td>HTTP parsing error</td>\n<td>HTTP Parser</td>\n<td>Error return code</td>\n<td>Bad request response, connection close</td>\n</tr>\n<tr>\n<td>Backend selection failure</td>\n<td>Load Balancer</td>\n<td>NULL return value</td>\n<td>Service unavailable response</td>\n</tr>\n<tr>\n<td>Backend connection failure</td>\n<td>Connection Manager</td>\n<td>Connection timeout</td>\n<td>Backend retry or error response</td>\n</tr>\n<tr>\n<td>Cache storage failure</td>\n<td>Cache Engine</td>\n<td>Boolean failure return</td>\n<td>Continue without caching</td>\n</tr>\n<tr>\n<td>SSL handshake failure</td>\n<td>SSL Termination</td>\n<td>NULL SSL context</td>\n<td>Connection close, SSL error logging</td>\n</tr>\n</tbody></table>\n<h4 id=\"synchronization-and-thread-safety\">Synchronization and Thread Safety</h4>\n<p>The inter-component communication must handle concurrent access patterns safely because the reverse proxy processes multiple requests simultaneously across different threads. Each component implements appropriate synchronization mechanisms to protect shared data structures and coordinate access to system resources.</p>\n<p><strong>Component-Level Synchronization</strong></p>\n<p>Each component implements internal synchronization to protect its data structures from concurrent access corruption while minimizing lock contention that could impact performance.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Synchronization Mechanism</th>\n<th>Protected Resources</th>\n<th>Lock Granularity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connection Manager</td>\n<td>Per-connection state locks</td>\n<td>Connection structures, socket operations</td>\n<td>Individual connections</td>\n</tr>\n<tr>\n<td>Load Balancer</td>\n<td>Reader-writer locks</td>\n<td>Backend server list, health status</td>\n<td>Backend array and individual servers</td>\n</tr>\n<tr>\n<td>Cache Engine</td>\n<td>Hash table locks, LRU locks</td>\n<td>Cache entries, eviction lists</td>\n<td>Hash buckets and LRU operations</td>\n</tr>\n<tr>\n<td>SSL Termination</td>\n<td>Context map locks</td>\n<td>SSL contexts, certificate reloading</td>\n<td>SSL context hash table</td>\n</tr>\n<tr>\n<td>HTTP Parser</td>\n<td>No synchronization needed</td>\n<td>Parser state is per-request</td>\n<td>Not applicable - stateless</td>\n</tr>\n</tbody></table>\n<p><strong>Cross-Component Coordination</strong></p>\n<p>Cross-component interactions require careful coordination to avoid deadlocks and ensure consistent system behavior when multiple components must collaborate to complete operations.</p>\n<p>The primary coordination mechanism uses the event-driven architecture where components don&#39;t hold locks while calling other components. Instead, components complete their internal operations, release any held locks, and then invoke other component methods without holding internal locks.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: The event-driven architecture eliminates most cross-component deadlock risks because components don&#39;t hold internal locks while making external calls. This design choice trades some potential performance for significantly improved reliability and debuggability.</p>\n</blockquote>\n<h4 id=\"component-startup-and-shutdown-coordination\">Component Startup and Shutdown Coordination</h4>\n<p>The system startup and shutdown sequences require careful coordination to ensure that components initialize in the correct order and that shutdown occurs gracefully without losing in-flight requests or corrupting persistent state.</p>\n<p><strong>Startup Sequence</strong></p>\n<table>\n<thead>\n<tr>\n<th>Order</th>\n<th>Component</th>\n<th>Initialization Actions</th>\n<th>Dependencies</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Configuration Loading</td>\n<td>Parse config file, validate settings</td>\n<td>File system access</td>\n</tr>\n<tr>\n<td>2</td>\n<td>SSL Termination</td>\n<td>Load certificates, initialize OpenSSL</td>\n<td>Certificate files, OpenSSL library</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Cache Engine</td>\n<td>Initialize hash tables, start cleanup threads</td>\n<td>Memory allocation</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Load Balancer</td>\n<td>Initialize backend list, start health checking</td>\n<td>Backend server network access</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Connection Manager</td>\n<td>Initialize epoll, create listening sockets</td>\n<td>Network socket permissions</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Main Event Loop</td>\n<td>Start request processing</td>\n<td>All other components ready</td>\n</tr>\n</tbody></table>\n<p><strong>Shutdown Sequence</strong></p>\n<table>\n<thead>\n<tr>\n<th>Order</th>\n<th>Component</th>\n<th>Shutdown Actions</th>\n<th>Cleanup Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Main Event Loop</td>\n<td>Stop accepting new connections</td>\n<td>Complete current request processing</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Connection Manager</td>\n<td>Drain existing connections, close sockets</td>\n<td>Wait for request completion timeouts</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Load Balancer</td>\n<td>Stop health checking, update backend status</td>\n<td>Join health check threads</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Cache Engine</td>\n<td>Stop cleanup threads, sync cached data</td>\n<td>Join cleanup threads</td>\n</tr>\n<tr>\n<td>5</td>\n<td>SSL Termination</td>\n<td>Stop certificate reloading, cleanup SSL contexts</td>\n<td>Join certificate threads</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Resource Cleanup</td>\n<td>Free memory, close files, release system resources</td>\n<td>Final system resource release</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The inter-component communication implementation requires careful attention to interface design, error handling, and performance optimization. The following guidance provides concrete implementation strategies for building robust component interactions.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Communication Aspect</th>\n<th>Simple Approach</th>\n<th>Advanced Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Function Interfaces</td>\n<td>Direct function calls with error returns</td>\n<td>Function pointers with callback interfaces</td>\n</tr>\n<tr>\n<td>Data Serialization</td>\n<td>Direct structure passing</td>\n<td>Protocol buffers or JSON serialization</td>\n</tr>\n<tr>\n<td>Event Coordination</td>\n<td>Epoll-based event loops</td>\n<td>Custom event dispatch framework</td>\n</tr>\n<tr>\n<td>Error Handling</td>\n<td>Return codes and errno</td>\n<td>Structured error objects with context</td>\n</tr>\n<tr>\n<td>Inter-thread Communication</td>\n<td>Mutex and condition variables</td>\n<td>Lock-free queues and atomic operations</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>proxy/\n├── src/\n│   ├── main.c                     ← Main event loop and component coordination\n│   ├── interfaces/                ← Component interface definitions\n│   │   ├── connection_manager.h   ← Connection manager interface\n│   │   ├── http_parser.h          ← HTTP parser interface\n│   │   ├── load_balancer.h        ← Load balancer interface\n│   │   ├── cache_engine.h         ← Cache engine interface\n│   │   └── ssl_termination.h      ← SSL termination interface\n│   ├── core/                      ← Core coordination logic\n│   │   ├── proxy_server.c         ← Main server coordination\n│   │   ├── event_dispatcher.c     ← Event routing between components\n│   │   └── error_handling.c       ← Cross-component error handling\n│   └── utils/                     ← Shared utilities\n│       ├── buffer.c               ← Buffer management\n│       ├── hashtable.c            ← Hash table implementation\n│       └── logger.c               ← Logging system</code></pre></div>\n\n<p><strong>Core Event Dispatcher Implementation</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/epoll.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"interfaces/connection_manager.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"interfaces/ssl_termination.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Event dispatcher coordinates between components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> epoll_fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> conn_mgr;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> ssl_term;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} EventDispatcher;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize event dispatcher with component references</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">EventDispatcher</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> event_dispatcher_create</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn_mgr</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                        SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl_term</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EventDispatcher</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> dispatcher </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(EventDispatcher));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">dispatcher) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dispatcher->epoll_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_create1</span><span style=\"color:#E1E4E8\">(EPOLL_CLOEXEC);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (dispatcher->epoll_fd </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(dispatcher);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dispatcher->conn_mgr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> conn_mgr;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dispatcher->ssl_term </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ssl_term;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dispatcher->running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> dispatcher;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Main event processing loop - coordinates all component interactions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> event_dispatcher_run</span><span style=\"color:#E1E4E8\">(EventDispatcher</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> dispatcher</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> epoll_event </span><span style=\"color:#FFAB70\">events</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (dispatcher->running) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> event_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> epoll_wait</span><span style=\"color:#E1E4E8\">(dispatcher->epoll_fd, events, </span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (event_count </span><span style=\"color:#F97583\">==</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (errno </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> EINTR) </span><span style=\"color:#F97583\">continue</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            logger_log</span><span style=\"color:#E1E4E8\">(ERROR, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"epoll_wait failed: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">strerror</span><span style=\"color:#E1E4E8\">(errno));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Process each epoll event</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Determine if event is for client connection, backend connection, or listening socket</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: Route event to appropriate component (ConnectionManager or SSLTermination)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Handle component coordination for complex operations (cache + backend)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Update event monitoring based on connection state changes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use epoll event data to store Connection* pointers for fast lookup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Inter-Component Message Structures</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Standard message header for all inter-component communication</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> message_type;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> message_length;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> transaction_id;</span><span style=\"color:#6A737D\">  // For request tracing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> timestamp;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} MessageHeader;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Cache lookup request message</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MessageHeader header;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> cache_key</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> request;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> conditional_request;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} CacheLookupMessage;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Backend selection request message</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MessageHeader header;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> request;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> sockaddr_in client_addr;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LoadBalancingAlgorithm preferred_algorithm;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} BackendSelectionMessage;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Generic component response message</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MessageHeader header;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> result_code;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> error_message</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void*</span><span style=\"color:#E1E4E8\"> result_data;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ComponentResponse;</span></span></code></pre></div>\n\n<p><strong>Request Processing Coordination</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Coordinate complete request processing across all components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> proxy_process_request</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">, Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> client_conn</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> request </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> backend </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> backend_conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheEntry</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cached_response </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> result </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Parse HTTP request using HttpParser component</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Check cache using CacheEngine component - return cached response if fresh</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Select backend using LoadBalancer component</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Acquire backend connection using ConnectionManager</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Forward request to backend server</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Process backend response and update cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Send response to client (with SSL encryption if needed)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Clean up all resources and update connection pools</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use goto cleanup pattern to ensure proper resource cleanup on any error</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">cleanup:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Always clean up resources regardless of success/failure</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (backend_conn) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        connection_manager_release_backend</span><span style=\"color:#E1E4E8\">(server->conn_mgr, backend_conn, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                         result </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#E1E4E8\"> client_conn->keep_alive);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (request) </span><span style=\"color:#B392F0\">http_request_destroy</span><span style=\"color:#E1E4E8\">(request);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> result;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Component Error Handling Coordination</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Centralized error handling for cross-component operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_NONE </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_PARSE_FAILED,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_BACKEND_UNAVAILABLE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_BACKEND_TIMEOUT,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CACHE_FAILURE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_SSL_HANDSHAKE_FAILED,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CLIENT_DISCONNECTED</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyErrorCode;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Handle errors that span multiple components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> proxy_handle_error</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">, Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> client_conn</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       ProxyErrorCode </span><span style=\"color:#FFAB70\">error_code</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> error_details</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpResponse</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> error_response </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Log error with appropriate severity level</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create appropriate HTTP error response based on error code</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Update component statistics (failed requests, error counts)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Send error response to client (with SSL if needed)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Clean up any partial state in components</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Close client connection if error is unrecoverable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Different error codes require different HTTP status codes and cleanup actions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Component Health Monitoring</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Monitor component health and coordination effectiveness</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> requests_processed;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> cache_hits;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> cache_misses;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> backend_failures;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> ssl_handshake_failures;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    double</span><span style=\"color:#E1E4E8\"> avg_request_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_update;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyStats;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Collect statistics from all components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> proxy_update_statistics</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">, ProxyStats</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> stats</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Collect statistics from ConnectionManager (request counts, timing)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Collect statistics from CacheEngine (hit rates, evictions)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Collect statistics from LoadBalancer (backend health, distribution)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Collect statistics from SSLTermination (handshake success rates)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Calculate derived metrics (success rates, latency percentiles)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Update monitoring endpoints for external systems</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use atomic operations for statistics updates to avoid locks</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints</strong></p>\n<p>After implementing the inter-component communication system, verify correct operation using these checkpoints:</p>\n<ol>\n<li><p><strong>Component Isolation Testing</strong>: Each component should be testable independently by providing mock implementations of other component interfaces. Create mock implementations that return predictable results and verify that each component handles the mock responses correctly.</p>\n</li>\n<li><p><strong>Request Flow Tracing</strong>: Implement transaction ID tracking that follows a single request through all components. Add logging at each component boundary and verify that the transaction ID appears in all log entries for a single request.</p>\n</li>\n<li><p><strong>Error Propagation Verification</strong>: Inject errors at each component interface and verify that errors propagate correctly to the client without corrupting system state or causing resource leaks.</p>\n</li>\n<li><p><strong>Concurrent Request Testing</strong>: Process multiple concurrent requests and verify that component interactions don&#39;t cause race conditions, deadlocks, or data corruption. Monitor for proper connection pool usage and cache consistency.</p>\n</li>\n</ol>\n<p><strong>Common Implementation Pitfalls</strong></p>\n<p>⚠️ <strong>Pitfall: Holding Internal Locks During External Calls</strong>\nComponents should never hold their internal locks while calling methods on other components. This creates deadlock risks when components need to interact bidirectionally. Always complete internal operations and release locks before making external component calls.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Error Handling Across Components</strong>\nEach component must handle errors consistently and provide meaningful error information to callers. Don&#39;t ignore error return values or fail to propagate errors up the call stack. Implement structured error handling that provides context about which component failed and why.</p>\n<p>⚠️ <strong>Pitfall: Resource Ownership Confusion</strong>\nClearly define which component owns each resource and is responsible for cleanup. Use consistent patterns like &quot;creator owns&quot; or &quot;last user owns&quot; throughout the system. Document ownership rules in interface specifications.</p>\n<p>⚠️ <strong>Pitfall: Race Conditions in Component Statistics</strong>\nStatistics updates across components can create race conditions if not properly synchronized. Use atomic operations for simple counters and appropriate locking for complex statistics calculations. Consider using per-thread statistics with periodic aggregation to reduce contention.</p>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - comprehensive error handling is essential across HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).</p>\n</blockquote>\n<p>Think of error handling in a reverse proxy like an air traffic control system managing multiple failure scenarios simultaneously. Just as air traffic controllers must handle plane mechanical failures, weather emergencies, runway closures, and communication blackouts while keeping other flights operating safely, a reverse proxy must gracefully handle client disconnections, backend server failures, network partitions, and SSL certificate problems while continuing to serve other requests. The key insight is that failures are not exceptional cases—they are normal operating conditions that require systematic detection, classification, and recovery strategies.</p>\n<p>Building robust error handling requires understanding that failures cascade through components in predictable patterns. When a backend server fails, it affects the load balancer&#39;s backend selection, the connection manager&#39;s pooled connections, and potentially cached responses that originated from that server. Each failure mode requires specific detection mechanisms, recovery strategies, and graceful degradation approaches to maintain service availability.</p>\n<p>The challenge lies in designing error handling that provides strong guarantees while maintaining performance. Error detection must be fast enough not to impact request latency, recovery mechanisms must activate quickly to minimize service disruption, and fallback strategies must preserve as much functionality as possible during partial system failures.</p>\n<p><img src=\"/api/project/reverse-proxy/architecture-doc/asset?path=diagrams%2Ferror-handling-flowchart.svg\" alt=\"Error Handling and Recovery Flow\"></p>\n<h3 id=\"failure-modes-and-detection\">Failure Modes and Detection</h3>\n<p>Understanding failure modes requires systematically analyzing each point where the reverse proxy interacts with external systems or manages internal state. Think of failure detection like a comprehensive medical diagnostic system—each component must monitor its own vital signs while also coordinating with other components to detect system-wide health issues. The goal is early detection before failures cascade into service outages.</p>\n<p><strong>Client Connection Failures</strong> represent the most common failure category, occurring when clients disconnect unexpectedly, send malformed requests, or violate protocol specifications. These failures require immediate detection to prevent resource leaks and unnecessary backend processing.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Detection Method</th>\n<th>Symptoms</th>\n<th>Root Cause</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Client Disconnect During Request</td>\n<td><code>EPOLLHUP</code> or <code>EPOLLERR</code> events</td>\n<td>Connection state shows <code>CONNECTION_READING_REQUEST</code> but socket closed</td>\n<td>Client closed browser, network timeout, mobile device sleep</td>\n</tr>\n<tr>\n<td>Malformed HTTP Request</td>\n<td>HTTP parser returns <code>HTTP_PARSING_ERROR</code></td>\n<td>Parser unable to extract method, URI, or headers</td>\n<td>Client bug, protocol violation, manual crafting</td>\n</tr>\n<tr>\n<td>Request Size Exceeding Limits</td>\n<td>Buffer allocation failure or size checks</td>\n<td>Request buffer exceeds configured maximum</td>\n<td>Large file upload, DoS attempt, misconfigured client</td>\n</tr>\n<tr>\n<td>Slow Client Attack</td>\n<td>Timer wheel timeout on request reading</td>\n<td>Connection remains in <code>CONNECTION_READING_REQUEST</code> beyond timeout</td>\n<td>Intentional slowloris attack or very slow network</td>\n</tr>\n<tr>\n<td>SSL Handshake Failure</td>\n<td>SSL_accept returns error codes</td>\n<td>TLS negotiation fails during connection establishment</td>\n<td>Wrong certificate, cipher mismatch, protocol version incompatibility</td>\n</tr>\n</tbody></table>\n<p>The detection strategy for client failures centers on the connection state machine monitoring and timeout management. The <code>ConnectionManager</code> tracks each connection&#39;s state and uses the <code>TimerWheel</code> to detect connections that remain in transitional states beyond configured thresholds.</p>\n<p><strong>Backend Server Failures</strong> require more sophisticated detection because they affect multiple concurrent requests and the overall service capacity. Backend failures can be immediate (connection refused) or gradual (increasing response times, partial responses).</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Detection Method</th>\n<th>Symptoms</th>\n<th>Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Backend Server Down</td>\n<td>Connection establishment failure, <code>ECONNREFUSED</code></td>\n<td><code>connect()</code> system call fails immediately</td>\n<td>All requests to this backend fail</td>\n</tr>\n<tr>\n<td>Backend Network Partition</td>\n<td>Connection timeout during establishment</td>\n<td><code>connect()</code> hangs then times out after <code>SO_SNDTIMEO</code></td>\n<td>Backend appears down but may be healthy</td>\n</tr>\n<tr>\n<td>Backend Slow Response</td>\n<td>Response timeout using timer wheel</td>\n<td>Connection stuck in <code>CONNECTION_READING_RESPONSE</code></td>\n<td>Requests queue up, response times increase</td>\n</tr>\n<tr>\n<td>Backend Partial Response</td>\n<td>Incomplete response parsing, unexpected connection close</td>\n<td><code>HttpParser</code> detects incomplete response or connection closes mid-response</td>\n<td>Data corruption, partial service failure</td>\n</tr>\n<tr>\n<td>Backend Health Check Failure</td>\n<td>Active health check request failure</td>\n<td>HTTP request to health check endpoint returns non-200 status</td>\n<td>Backend overloaded or failing internally</td>\n</tr>\n</tbody></table>\n<p>The <code>LoadBalancer</code> component implements comprehensive backend failure detection through both passive monitoring (observing request failures) and active health checking (periodic probe requests). The health checking system maintains failure counters and implements exponential backoff to avoid overwhelming failing backends.</p>\n<blockquote>\n<p><strong>Key Insight</strong>: Backend failure detection must balance responsiveness with stability. Too aggressive failure detection leads to healthy backends being marked down due to temporary network hiccups. Too conservative detection allows failing backends to impact user requests.</p>\n</blockquote>\n<p><strong>Connection Pool Failures</strong> occur when the connection pooling mechanism itself experiences problems, such as resource exhaustion, connection leaks, or pool corruption.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Detection Method</th>\n<th>Symptoms</th>\n<th>Prevention</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connection Pool Exhaustion</td>\n<td>Pool creation fails when <code>active_count + idle_count &gt;= max_connections</code></td>\n<td>New requests wait indefinitely for connections</td>\n<td>Monitor pool utilization, implement connection limits</td>\n</tr>\n<tr>\n<td>Stale Connection Reuse</td>\n<td>Backend connection fails immediately after retrieval from pool</td>\n<td>First request on reused connection gets <code>EPIPE</code> or <code>ECONNRESET</code></td>\n<td>Validate connections before reuse, implement keep-alive timeouts</td>\n</tr>\n<tr>\n<td>Connection Leak</td>\n<td>Pool size grows continuously, connections never returned</td>\n<td><code>active_count</code> increases without corresponding decreases</td>\n<td>Audit connection lifecycle, ensure all code paths release connections</td>\n</tr>\n<tr>\n<td>Pool Lock Contention</td>\n<td>High latency on connection acquisition</td>\n<td>Threads block on <code>pool_mutex</code> for extended periods</td>\n<td>Implement pool sharding, reduce critical section duration</td>\n</tr>\n</tbody></table>\n<p>The <code>ConnectionPool</code> implements connection validation by sending a minimal probe (like TCP <code>MSG_PEEK</code>) before returning connections from the idle pool. Stale connections are discarded and new connections established as needed.</p>\n<p><strong>Caching System Failures</strong> impact performance rather than correctness, but require careful handling to avoid serving stale or corrupted cached responses.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Detection Method</th>\n<th>Symptoms</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache Memory Exhaustion</td>\n<td>Memory allocation failures during cache storage</td>\n<td><code>cache_engine_store()</code> returns false, new entries not cached</td>\n<td>Emergency cache eviction, memory pressure relief</td>\n</tr>\n<tr>\n<td>Cache Corruption</td>\n<td>Checksum validation failure, invalid cache entry structure</td>\n<td>Cache lookup returns malformed response</td>\n<td>Invalidate corrupted entries, fall back to backend</td>\n</tr>\n<tr>\n<td>TTL Heap Corruption</td>\n<td>Heap invariant violations during TTL processing</td>\n<td>Expired entries not evicted, fresh entries evicted prematurely</td>\n<td>Rebuild TTL heap, restart cache cleanup thread</td>\n</tr>\n<tr>\n<td>Cache Lock Deadlock</td>\n<td>Cache operations hang indefinitely</td>\n<td>Threads block on <code>cache_rwlock</code> or <code>lru_mutex</code></td>\n<td>Detect deadlock using timeouts, restart cache subsystem</td>\n</tr>\n</tbody></table>\n<p>The <code>CacheEngine</code> implements defensive programming by validating cache entry integrity before returning cached responses. Corrupted entries are immediately purged and requests fall back to backend servers.</p>\n<p><strong>SSL/TLS Failures</strong> require special handling because they involve cryptographic operations and certificate management with specific security implications.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Mode</th>\n<th>Detection Method</th>\n<th>Symptoms</th>\n<th>Security Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Certificate Expiration</td>\n<td>Certificate validity period check during context creation</td>\n<td>SSL context creation fails, <code>ssl_utils_load_certificate()</code> reports expiration</td>\n<td>Clients receive certificate errors, connections fail</td>\n</tr>\n<tr>\n<td>Private Key Mismatch</td>\n<td>Key-certificate validation during SSL context setup</td>\n<td><code>ssl_utils_verify_key_cert_match()</code> returns false</td>\n<td>SSL handshake failures, authentication problems</td>\n</tr>\n<tr>\n<td>SNI Certificate Missing</td>\n<td>SNI callback unable to find matching certificate</td>\n<td><code>ssl_termination_sni_callback()</code> returns <code>SSL_TLSEXT_ERR_ALERT_FATAL</code></td>\n<td>Wrong certificate served, client warnings</td>\n</tr>\n<tr>\n<td>Cipher Suite Negotiation Failure</td>\n<td>SSL handshake fails during cipher selection</td>\n<td>TLS handshake aborts with cipher-related errors</td>\n<td>Connection establishment fails, compatibility issues</td>\n</tr>\n<tr>\n<td>Certificate Chain Validation Failure</td>\n<td>Chain verification fails during certificate loading</td>\n<td><code>ssl_utils_load_certificate()</code> unable to build trust chain</td>\n<td>Browser security warnings, connection failures</td>\n</tr>\n</tbody></table>\n<p>The <code>SSLTermination</code> component implements certificate monitoring through background validation threads that check certificate expiration dates and reload certificates when files change on disk.</p>\n<blockquote>\n<p><strong>Architecture Decision: Failure Detection Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance early failure detection with system stability and performance</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Reactive detection (detect failures only when they impact requests)</li>\n<li>Proactive detection (active monitoring and health checking)</li>\n<li>Hybrid approach (combine passive observation with active probing)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Hybrid approach with component-specific strategies</li>\n<li><strong>Rationale</strong>: Reactive detection alone misses gradual degradation and allows cascade failures. Pure proactive detection creates excessive monitoring overhead. Hybrid approach provides early warning while minimizing false positives.</li>\n<li><strong>Consequences</strong>: Requires coordination between components for failure state sharing, but provides robust early detection with acceptable overhead.</li>\n</ul>\n</blockquote>\n<h3 id=\"recovery-and-fallback-strategies\">Recovery and Fallback Strategies</h3>\n<p>Recovery strategies must address the fundamental challenge of maintaining service availability while dealing with component failures. Think of this like a hospital emergency response system—when one department fails, other departments must absorb the load while the failed department recovers, all without compromising patient care. The key principle is graceful degradation: the system should lose functionality gradually rather than failing catastrophically.</p>\n<p><strong>Client Connection Recovery</strong> focuses on clean resource management and appropriate error responses that help clients understand and respond to failure conditions.</p>\n<p>When client disconnections are detected during request processing, the recovery strategy prioritizes preventing resource leaks and canceling unnecessary backend processing. The <code>ConnectionManager</code> implements a comprehensive cleanup sequence that releases all resources associated with the failed client connection.</p>\n<table>\n<thead>\n<tr>\n<th>Recovery Scenario</th>\n<th>Detection Point</th>\n<th>Recovery Actions</th>\n<th>Client Response</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Client Disconnect During Request Reading</td>\n<td><code>EPOLLHUP</code> event on client socket</td>\n<td>1. Cancel request parsing 2. Release client connection 3. Clean up request buffers 4. Log disconnect for monitoring</td>\n<td>None (client already disconnected)</td>\n</tr>\n<tr>\n<td>Client Disconnect During Backend Processing</td>\n<td><code>EPOLLHUP</code> during <code>CONNECTION_FORWARDING</code></td>\n<td>1. Cancel backend request 2. Return backend connection to pool 3. Release client connection 4. Update backend statistics</td>\n<td>None (client already disconnected)</td>\n</tr>\n<tr>\n<td>Malformed Request Parsing</td>\n<td>Parser enters <code>HTTP_PARSING_ERROR</code> state</td>\n<td>1. Generate HTTP 400 Bad Request response 2. Include specific error details 3. Close connection (HTTP/1.0) or reset stream (HTTP/2)</td>\n<td>HTTP 400 with error description</td>\n</tr>\n<tr>\n<td>Request Size Limit Exceeded</td>\n<td>Buffer allocation fails or size check triggers</td>\n<td>1. Generate HTTP 413 Payload Too Large 2. Close connection immediately 3. Log oversized request attempt</td>\n<td>HTTP 413 with size limit information</td>\n</tr>\n<tr>\n<td>Client Timeout During Request</td>\n<td>Timer wheel timeout fires</td>\n<td>1. Generate HTTP 408 Request Timeout 2. Close connection 3. Release all associated resources</td>\n<td>HTTP 408 with timeout duration</td>\n</tr>\n</tbody></table>\n<p>The client error response generation follows HTTP specification guidelines to provide actionable feedback. Error responses include specific details about the failure condition and suggested client actions when appropriate.</p>\n<p><strong>Backend Server Recovery</strong> requires sophisticated strategies because backend failures affect multiple concurrent client requests and the overall system capacity. The recovery approach must minimize impact on active requests while restoring service capacity.</p>\n<p>When backend servers fail, the <code>LoadBalancer</code> immediately removes them from the active pool and redistributes their load across remaining healthy backends. This requires careful coordination between the load balancer and connection manager to handle in-flight requests appropriately.</p>\n<table>\n<thead>\n<tr>\n<th>Recovery Scenario</th>\n<th>Detection Trigger</th>\n<th>Immediate Actions</th>\n<th>Long-term Recovery</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Backend Connection Refused</td>\n<td><code>connect()</code> fails with <code>ECONNREFUSED</code></td>\n<td>1. Mark backend unhealthy 2. Select alternative backend 3. Retry request on new backend</td>\n<td>1. Continue health checking 2. Restore to pool when healthy 3. Adjust health check frequency</td>\n</tr>\n<tr>\n<td>Backend Response Timeout</td>\n<td>Timer wheel timeout on response reading</td>\n<td>1. Close backend connection 2. Return connection failure to load balancer 3. Generate HTTP 504 Gateway Timeout for client</td>\n<td>1. Increase backend timeout threshold 2. Monitor for systematic slowness 3. Consider backend capacity issues</td>\n</tr>\n<tr>\n<td>Backend Partial Response</td>\n<td>Parser detects incomplete response</td>\n<td>1. Close corrupted connection 2. Remove from connection pool 3. Retry request if safe (GET, HEAD) 4. Generate HTTP 502 Bad Gateway if not retriable</td>\n<td>1. Monitor for data corruption patterns 2. Investigate backend health 3. Consider network issues</td>\n</tr>\n<tr>\n<td>All Backends Down</td>\n<td>No healthy backends available</td>\n<td>1. Return HTTP 503 Service Unavailable 2. Include Retry-After header 3. Continue health checking all backends</td>\n<td>1. Implement emergency backend discovery 2. Alert operations team 3. Consider maintenance mode</td>\n</tr>\n</tbody></table>\n<p>The backend recovery system implements intelligent retry logic that distinguishes between retriable requests (idempotent operations like GET and HEAD) and non-retriable requests (potentially state-changing operations like POST and PUT). Retriable requests automatically retry on alternative backends, while non-retriable requests return errors to avoid duplicate processing.</p>\n<blockquote>\n<p><strong>Critical Design Principle</strong>: Backend recovery must never amplify failures. When backends are struggling, the recovery system should reduce load rather than increase it through aggressive retries.</p>\n</blockquote>\n<p><strong>Connection Pool Recovery</strong> ensures that connection pooling continues to provide performance benefits even when individual connections fail or pools become corrupted.</p>\n<p>The <code>ConnectionPool</code> implements a self-healing design that automatically adapts to changing backend conditions. When stale connections are detected, the pool discards them and establishes fresh connections. When pool exhaustion occurs, the system gracefully degrades to creating direct connections while working to restore pool capacity.</p>\n<table>\n<thead>\n<tr>\n<th>Recovery Scenario</th>\n<th>Trigger Condition</th>\n<th>Immediate Response</th>\n<th>Pool Restoration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Stale Connection Detection</td>\n<td>Connection validation fails before reuse</td>\n<td>1. Discard stale connection 2. Attempt to create new connection 3. Update pool statistics</td>\n<td>1. Reduce idle timeout to prevent staleness 2. Increase validation frequency 3. Monitor backend keep-alive settings</td>\n</tr>\n<tr>\n<td>Pool Exhaustion</td>\n<td><code>active_count &gt;= max_connections</code> and no idle connections</td>\n<td>1. Block new requests with timeout 2. Create direct connection if possible 3. Monitor for connection returns</td>\n<td>1. Increase pool size if backend can handle it 2. Investigate connection leaks 3. Optimize connection lifecycle</td>\n</tr>\n<tr>\n<td>Pool Lock Contention</td>\n<td>High latency on mutex acquisition</td>\n<td>1. Implement connection request queuing 2. Use timeout on lock acquisition 3. Fall back to direct connections</td>\n<td>1. Implement pool sharding 2. Reduce critical section size 3. Consider lock-free data structures</td>\n</tr>\n<tr>\n<td>Connection Leak Detection</td>\n<td>Pool size grows without bound</td>\n<td>1. Force connection cleanup 2. Log connection allocation traces 3. Implement emergency pool reset</td>\n<td>1. Audit all connection acquisition sites 2. Add connection lifecycle tracking 3. Implement automatic leak detection</td>\n</tr>\n</tbody></table>\n<p>The pool recovery system maintains detailed statistics about connection usage patterns to identify systemic issues. When connection leaks are detected, the system implements emergency pool draining that forcibly closes all connections and rebuilds the pool from scratch.</p>\n<p><strong>Cache System Recovery</strong> focuses on maintaining performance benefits while ensuring data integrity during cache failures.</p>\n<p>When cache system failures occur, the primary strategy is immediate fallback to backend servers while attempting to restore cache functionality in the background. This ensures that service remains available even if caching performance benefits are temporarily lost.</p>\n<table>\n<thead>\n<tr>\n<th>Recovery Scenario</th>\n<th>Failure Detection</th>\n<th>Immediate Fallback</th>\n<th>Cache Restoration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache Memory Exhaustion</td>\n<td>Memory allocation failures during storage</td>\n<td>1. Disable new cache entries 2. Trigger emergency eviction 3. Fall back to backend for all requests</td>\n<td>1. Implement aggressive LRU eviction 2. Reduce cache size limits 3. Monitor memory usage patterns</td>\n</tr>\n<tr>\n<td>Cache Entry Corruption</td>\n<td>Checksum validation failure</td>\n<td>1. Purge corrupted entry immediately 2. Serve request from backend 3. Log corruption details</td>\n<td>1. Investigate corruption patterns 2. Implement cache entry versioning 3. Add redundant storage</td>\n</tr>\n<tr>\n<td>Cache Lock Deadlock</td>\n<td>Timeout on cache operations</td>\n<td>1. Bypass cache for affected requests 2. Restart cache subsystem 3. Serve from backend</td>\n<td>1. Implement deadlock detection 2. Redesign locking hierarchy 3. Add lock timeout mechanisms</td>\n</tr>\n<tr>\n<td>TTL Processing Failure</td>\n<td>Heap corruption or processing errors</td>\n<td>1. Disable TTL-based eviction 2. Implement manual cache clearing 3. Continue serving cached entries</td>\n<td>1. Rebuild TTL heap from scratch 2. Implement heap invariant checking 3. Add TTL processing monitoring</td>\n</tr>\n</tbody></table>\n<p>The cache recovery system implements a &quot;circuit breaker&quot; pattern that automatically disables caching when error rates exceed configurable thresholds. This prevents cache failures from impacting request processing while allowing time for automatic recovery.</p>\n<p><strong>SSL/TLS Recovery</strong> requires special handling due to security implications and the need to maintain encrypted communications.</p>\n<p>When SSL termination failures occur, the system must balance security requirements with service availability. The recovery strategy prioritizes security over availability—it&#39;s better to refuse connections than to serve them with compromised encryption.</p>\n<table>\n<thead>\n<tr>\n<th>Recovery Scenario</th>\n<th>Security Impact</th>\n<th>Immediate Response</th>\n<th>Certificate Recovery</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Certificate Expiration</td>\n<td>High - clients receive security warnings</td>\n<td>1. Disable affected SSL contexts 2. Return HTTP 503 for HTTPS requests 3. Alert operations immediately</td>\n<td>1. Install renewed certificates 2. Reload SSL contexts 3. Resume HTTPS service</td>\n</tr>\n<tr>\n<td>Private Key Compromise</td>\n<td>Critical - potential man-in-the-middle attacks</td>\n<td>1. Immediately disable all SSL contexts 2. Refuse all HTTPS connections 3. Generate new key pairs</td>\n<td>1. Generate new private keys 2. Request new certificates 3. Update all SSL contexts</td>\n</tr>\n<tr>\n<td>SNI Certificate Missing</td>\n<td>Medium - wrong certificate served</td>\n<td>1. Fall back to default certificate 2. Log SNI hostname mismatches 3. Continue service with warnings</td>\n<td>1. Install missing certificates 2. Update SNI configuration 3. Validate certificate coverage</td>\n</tr>\n<tr>\n<td>Cipher Suite Negotiation Failure</td>\n<td>Medium - reduced security or connection failures</td>\n<td>1. Expand cipher suite support 2. Log negotiation failures 3. Maintain secure defaults</td>\n<td>1. Update cipher configuration 2. Test client compatibility 3. Balance security with compatibility</td>\n</tr>\n</tbody></table>\n<p>The SSL recovery system implements automatic certificate monitoring that checks for expiration dates and triggers renewal processes before certificates expire. Certificate reloading happens atomically to avoid service interruption during updates.</p>\n<blockquote>\n<p><strong>Architecture Decision: Error Recovery Philosophy</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance service availability with operational safety during failures</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Fail-fast: Stop processing immediately when errors are detected</li>\n<li>Best-effort: Continue processing with degraded functionality</li>\n<li>Graceful degradation: Systematically reduce functionality while maintaining core service</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Graceful degradation with fail-fast for security-critical failures</li>\n<li><strong>Rationale</strong>: Web services must maintain availability during partial failures, but security violations require immediate protection. Graceful degradation preserves user experience while systematic recovery restores full functionality.</li>\n<li><strong>Consequences</strong>: Requires sophisticated error classification and recovery coordination, but provides optimal balance of availability and safety.</li>\n</ul>\n</blockquote>\n<h3 id=\"common-pitfalls-in-error-handling\">Common Pitfalls in Error Handling</h3>\n<p>⚠️ <strong>Pitfall: Resource Leaks During Error Conditions</strong></p>\n<p>The most common error handling mistake is failing to properly clean up resources when errors occur. This happens because error handling code paths are tested less frequently than success paths, leading to subtle resource leaks that only manifest under stress.</p>\n<p>The specific problem occurs when error handling code returns early without calling cleanup functions, or when cleanup functions themselves can fail and propagate errors. For example, if <code>connection_manager_acquire_backend()</code> fails after allocating a <code>Connection</code> structure but before adding it to the pool, the connection memory and file descriptor leak unless the error path explicitly releases them.</p>\n<p>To avoid this pitfall, implement the &quot;RAII pattern&quot; even in C by using consistent cleanup functions and ensuring every resource acquisition has a corresponding release in all code paths. Structure error handling with goto labels that consolidate cleanup operations:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">ProxyErrorCode </span><span style=\"color:#B392F0\">proxy_process_request</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">, Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> request </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> backend </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> backend_conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> http_request_create</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">request) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        goto</span><span style=\"color:#E1E4E8\"> cleanup_connection;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    backend </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> loadbalancer_select_backend</span><span style=\"color:#E1E4E8\">(server->load_balancer, request);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">backend) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        goto</span><span style=\"color:#E1E4E8\"> cleanup_request;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    backend_conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> connection_manager_acquire_backend</span><span style=\"color:#E1E4E8\">(server->conn_manager, backend, </span><span style=\"color:#79B8FF\">5000</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">backend_conn) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        goto</span><span style=\"color:#E1E4E8\"> cleanup_request;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Process request...</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    connection_manager_release_backend</span><span style=\"color:#E1E4E8\">(server->conn_manager, backend_conn, </span><span style=\"color:#79B8FF\">true</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    http_request_destroy</span><span style=\"color:#E1E4E8\">(request);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_NONE;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">cleanup_request:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    http_request_destroy</span><span style=\"color:#E1E4E8\">(request);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">cleanup_connection:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    connection_manager_close_connection</span><span style=\"color:#E1E4E8\">(server->conn_manager, conn);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_UNAVAILABLE;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Cascade Failure Amplification</strong></p>\n<p>A critical mistake is designing error handling that amplifies failures rather than containing them. This occurs when error recovery logic creates additional load on already-stressed systems, causing localized failures to become system-wide outages.</p>\n<p>The specific anti-pattern involves aggressive retry logic that doesn&#39;t implement backoff or circuit breaker patterns. When a backend server starts responding slowly, naive retry logic sends more requests to the struggling server, making the problem worse. Similarly, when health checks detect a failing server, continuing to send health check requests at normal frequency can prevent the server from recovering.</p>\n<p>To prevent cascade failures, implement exponential backoff for retries, circuit breaker patterns for failing backends, and reduced health check frequency for known-unhealthy servers:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> health_check_backend</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> now </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> since_last_failure </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> now </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> backend->last_failure_time;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Exponential backoff for failed backends</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (backend->failure_count </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        time_t</span><span style=\"color:#E1E4E8\"> backoff_delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x3C;&#x3C;</span><span style=\"color:#B392F0\"> min</span><span style=\"color:#E1E4E8\">(backend->failure_count, </span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">)) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> lb->health_check_interval;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (since_last_failure </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> backoff_delay) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Skip health check during backoff period</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Proceed with health check...</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Inconsistent Error State Between Components</strong></p>\n<p>Components can get into inconsistent states where one component believes a resource is available while another component knows it has failed. This happens because error propagation between components is asynchronous and components may cache state that becomes stale during failures.</p>\n<p>The specific problem occurs when the <code>LoadBalancer</code> marks a backend as healthy based on successful connection establishment, but the <code>ConnectionManager</code> discovers that all connections to that backend are actually failing due to application-level issues. The load balancer continues selecting the failed backend because it hasn&#39;t received updated failure information.</p>\n<p>To maintain consistent error state, implement a centralized error reporting system where all components report failures to a shared state manager:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> backend;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyErrorCode error_code;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> error_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> error_details</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">256</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ErrorReport;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> proxy_handle_error</span><span style=\"color:#E1E4E8\">(ProxyServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> server</span><span style=\"color:#E1E4E8\">, Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">error</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> details</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Update component-specific state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> (error) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_TIMEOUT:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            loadbalancer_report_backend_error</span><span style=\"color:#E1E4E8\">(server</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">load_balancer</span><span style=\"color:#E1E4E8\">, conn</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">backend_server</span><span style=\"color:#E1E4E8\">, error);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            connection_manager_invalidate_backend_pool</span><span style=\"color:#E1E4E8\">(server</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">conn_manager</span><span style=\"color:#E1E4E8\">, conn</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">backend_server</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_SSL_HANDSHAKE_FAILED:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            ssl_termination_report_error</span><span style=\"color:#E1E4E8\">(server</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">ssl_termination</span><span style=\"color:#E1E4E8\">, error, details);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Update global error statistics</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    proxy_update_statistics</span><span style=\"color:#E1E4E8\">(server, error, details);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Log error for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    logger_log</span><span style=\"color:#E1E4E8\">(ERROR, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Request failed: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, details);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Blocking Operations in Error Handlers</strong></p>\n<p>Error handling code often performs blocking operations like DNS lookups, file I/O, or network requests, which can cause the entire event processing thread to stall. This is particularly dangerous because errors tend to occur in clusters, so blocking error handling can quickly exhaust all processing threads.</p>\n<p>The specific problem occurs when error handling code tries to immediately reload certificates from disk, perform DNS resolution for alternative backends, or send error notifications over the network. These blocking operations prevent the error handler from processing other events, leading to cascading failures.</p>\n<p>To avoid blocking in error handlers, implement asynchronous error processing using background threads or work queues:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyErrorCode error_code;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> error_details</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> error_time;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> failed_connection;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ErrorWorkItem;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> error_processing_thread</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorWorkItem</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> item;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">queue_dequeue</span><span style=\"color:#E1E4E8\">(error_queue, (</span><span style=\"color:#F97583\">void**</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">item)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        switch</span><span style=\"color:#E1E4E8\"> (item->error_code) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_SSL_HANDSHAKE_FAILED:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                // Non-blocking: schedule certificate reload</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                ssl_termination_schedule_reload</span><span style=\"color:#E1E4E8\">(ssl_termination);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_UNAVAILABLE:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                // Non-blocking: update backend health asynchronously</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                loadbalancer_schedule_health_check</span><span style=\"color:#E1E4E8\">(load_balancer, item</span><span style=\"color:#F97583\">-></span><span style=\"color:#E1E4E8\">failed_connection</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">backend_server</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(item);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Security Information Leakage in Error Messages</strong></p>\n<p>Error messages often inadvertently expose sensitive information about the system&#39;s internal structure, configuration, or data. This information can be valuable to attackers attempting to exploit the system.</p>\n<p>The specific problem occurs when error messages include internal IP addresses, file paths, database connection strings, or detailed stack traces that reveal implementation details. For example, returning &quot;Connection failed to backend server 192.168.1.100:3306&quot; exposes internal network topology.</p>\n<p>To prevent information leakage, implement error sanitization that provides useful feedback to legitimate users while hiding sensitive details:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> generate_client_error_response</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">error</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> internal_details</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpResponse</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> response </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> http_response_create</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> (error) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_UNAVAILABLE:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response->status </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 503</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            http_response_add_header</span><span style=\"color:#E1E4E8\">(response, </span><span style=\"color:#9ECBFF\">\"Content-Type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"text/plain\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            buffer_append</span><span style=\"color:#E1E4E8\">(response</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">body</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Service temporarily unavailable\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">28</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Internal details logged but not sent to client</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            logger_log</span><span style=\"color:#E1E4E8\">(ERROR, </span><span style=\"color:#B392F0\">__FILE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Backend failure: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, internal_details);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_TIMEOUT:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response->status </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 504</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            http_response_add_header</span><span style=\"color:#E1E4E8\">(response, </span><span style=\"color:#9ECBFF\">\"Content-Type\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"text/plain\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            buffer_append</span><span style=\"color:#E1E4E8\">(response</span><span style=\"color:#F97583\">-></span><span style=\"color:#FFAB70\">body</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Gateway timeout\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">15</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Send sanitized response to client</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    connection_send_response</span><span style=\"color:#E1E4E8\">(conn, response);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    http_response_destroy</span><span style=\"color:#E1E4E8\">(response);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Error handling implementation requires careful coordination between all proxy components to ensure consistent failure detection and recovery. The key challenge is implementing robust error handling without significantly impacting performance or code complexity.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Error Logging</td>\n<td>Standard C stdio with log levels</td>\n<td>Structured logging with syslog integration</td>\n</tr>\n<tr>\n<td>Error Propagation</td>\n<td>Return codes with errno</td>\n<td>Custom error types with context</td>\n</tr>\n<tr>\n<td>Timeout Management</td>\n<td>Simple timer threads</td>\n<td>Timer wheel with O(1) operations</td>\n</tr>\n<tr>\n<td>Resource Cleanup</td>\n<td>Manual cleanup with goto labels</td>\n<td>RAII-style cleanup macros</td>\n</tr>\n<tr>\n<td>Error Recovery</td>\n<td>Immediate fallback strategies</td>\n<td>Circuit breaker pattern with state machines</td>\n</tr>\n<tr>\n<td>Error Monitoring</td>\n<td>Basic counters and logs</td>\n<td>Metrics collection with alerting</td>\n</tr>\n</tbody></table>\n<p><strong>File Structure for Error Handling</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/\n├── error/\n│   ├── error_types.h         ← Error code definitions and structures\n│   ├── error_handler.c       ← Central error coordination\n│   ├── error_reporter.c      ← Error logging and monitoring\n│   └── recovery_manager.c    ← Recovery strategy implementation\n├── utils/\n│   ├── cleanup_macros.h      ← RAII-style cleanup helpers\n│   └── timeout_manager.c     ← Centralized timeout handling\n└── monitoring/\n    ├── metrics.c             ← Performance and error metrics\n    └── health_monitor.c      ← System health monitoring</code></pre></div>\n\n<p><strong>Core Error Handling Infrastructure</strong></p>\n<p>The error handling system requires a centralized error coordinator that receives error reports from all components and orchestrates appropriate recovery actions:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// error/error_types.h</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_NONE </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_PARSE_FAILED,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_BACKEND_UNAVAILABLE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_BACKEND_TIMEOUT,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CACHE_FAILURE,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_SSL_HANDSHAKE_FAILED,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CLIENT_DISCONNECTED,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_MEMORY_EXHAUSTED,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CONFIG_INVALID</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyErrorCode;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyErrorCode code;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> message</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> component</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> timestamp;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> request_id;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> failed_connection;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> failed_backend;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ErrorContext;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorContext</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> errors</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> error_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> error_capacity;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> error_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> recovery_thread;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ErrorHandler;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Central error handling initialization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> error_handler_create</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> error_handler_start</span><span style=\"color:#E1E4E8\">(ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> handler</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> error_handler_report</span><span style=\"color:#E1E4E8\">(ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> handler</span><span style=\"color:#E1E4E8\">, ErrorContext</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> error</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> error_handler_stop</span><span style=\"color:#E1E4E8\">(ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> handler</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> error_handler_destroy</span><span style=\"color:#E1E4E8\">(ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> handler</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<p><strong>Resource Cleanup Macros</strong></p>\n<p>To prevent resource leaks during error conditions, implement cleanup macros that ensure consistent resource management:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// utils/cleanup_macros.h</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> CLEANUP_BUFFER</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">buf</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">do</span><span style=\"color:#E1E4E8\"> { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (buf) { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        buffer_destroy</span><span style=\"color:#E1E4E8\">(buf); </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        buf </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} </span><span style=\"color:#F97583\">while</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> CLEANUP_CONNECTION</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">conn_mgr</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">do</span><span style=\"color:#E1E4E8\"> { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn) { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        connection_manager_close_connection</span><span style=\"color:#E1E4E8\">(conn_mgr, conn); </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} </span><span style=\"color:#F97583\">while</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> CLEANUP_HTTP_REQUEST</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">req</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">do</span><span style=\"color:#E1E4E8\"> { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (req) { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        http_request_destroy</span><span style=\"color:#E1E4E8\">(req); </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        req </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} </span><span style=\"color:#F97583\">while</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> CLEANUP_BACKEND_CONNECTION</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">conn_mgr</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">conn</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">keep_alive</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">do</span><span style=\"color:#E1E4E8\"> { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (conn) { </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        connection_manager_release_backend</span><span style=\"color:#E1E4E8\">(conn_mgr, conn, keep_alive); </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    } </span><span style=\"color:#79B8FF\">\\</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} </span><span style=\"color:#F97583\">while</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Error Recovery Skeleton</strong></p>\n<p>The core error recovery logic coordinates between components to implement graceful degradation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// error/recovery_manager.c</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> load_balancer;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> conn_manager;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CacheEngine</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> cache_engine;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> ssl_termination;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> recovery_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} RecoveryManager;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">RecoveryManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> recovery_manager_create</span><span style=\"color:#E1E4E8\">(LoadBalancer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> lb</span><span style=\"color:#E1E4E8\">, ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cm</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                        CacheEngine</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> cache</span><span style=\"color:#E1E4E8\">, SSLTermination</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ssl</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate RecoveryManager structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Initialize component references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Initialize recovery_mutex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set up recovery state tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Store references to all components for coordinated recovery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> recovery_manager_handle_backend_failure</span><span style=\"color:#E1E4E8\">(RecoveryManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> mgr</span><span style=\"color:#E1E4E8\">, BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                           ProxyErrorCode </span><span style=\"color:#FFAB70\">error</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Lock recovery_mutex to ensure atomic recovery actions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Mark backend as unhealthy in load balancer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Invalidate all pooled connections to failed backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Clear cache entries that originated from failed backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Schedule health check retry with exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Update failure statistics and monitoring metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Release recovery_mutex</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use loadbalancer_mark_backend_unhealthy(), connection_manager_invalidate_backend_pool()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> recovery_manager_handle_ssl_failure</span><span style=\"color:#E1E4E8\">(RecoveryManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> mgr</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">error</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                        char*</span><span style=\"color:#FFAB70\"> hostname</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Determine if failure affects specific hostname or all SSL contexts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If certificate expired, schedule immediate certificate reload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If SNI failure, add missing certificate to reload queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If cipher negotiation failure, log client compatibility issue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update SSL failure statistics for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use ssl_termination_schedule_reload() for certificate issues</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> recovery_manager_handle_cache_failure</span><span style=\"color:#E1E4E8\">(RecoveryManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> mgr</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">error</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                          char*</span><span style=\"color:#FFAB70\"> cache_key</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Determine scope of cache failure (single entry vs entire cache)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: If memory exhaustion, trigger emergency cache eviction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: If corruption detected, invalidate affected cache entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If lock contention, implement cache operation timeouts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Enable cache bypass mode if failures exceed threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Schedule cache subsystem restart if necessary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use cache_engine_invalidate() and cache_engine_clear() for cleanup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Timeout Management Implementation</strong></p>\n<p>Centralized timeout management prevents resource exhaustion and provides consistent timeout behavior:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// utils/timeout_manager.c</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> connection;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> timeout_time;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyErrorCode timeout_error;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">timeout_callback)(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">, ProxyErrorCode);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} TimeoutEntry;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TimerWheel</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> timer_wheel;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> timeout_thread;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} TimeoutManager;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">TimeoutManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> timeout_manager_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">time_t</span><span style=\"color:#FFAB70\"> granularity</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate TimeoutManager structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create timer wheel with specified granularity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Initialize timeout processing thread</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Set running flag to true</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use timer_wheel_create() with appropriate slot count and duration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> timeout_manager_add_connection</span><span style=\"color:#E1E4E8\">(TimeoutManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> mgr</span><span style=\"color:#E1E4E8\">, Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                  int</span><span style=\"color:#FFAB70\"> timeout_ms</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">error_code</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Calculate absolute timeout time from current time + timeout_ms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create TimeoutEntry with connection and error code</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Add timeout entry to timer wheel at calculated time slot</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Store timer wheel reference in connection for later removal</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use time(NULL) + (timeout_ms / 1000) for timeout calculation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void*</span><span style=\"color:#B392F0\"> timeout_processing_thread</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> arg</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TimeoutManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> mgr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (TimeoutManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)arg;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (mgr->running) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 1: Sleep for timer wheel granularity period</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 2: Process current timer wheel slot for expired timeouts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 3: For each expired timeout, call timeout callback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 4: Advance timer wheel to next slot</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // TODO 5: Handle any timer wheel errors or corruption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Hint: Use timer_wheel_process_current_slot() and timer_wheel_advance()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint: Error Handling Verification</strong></p>\n<p>After implementing error handling infrastructure, verify the system correctly detects and recovers from common failure scenarios:</p>\n<ol>\n<li><p><strong>Backend Failure Testing</strong>: Start the proxy with multiple backend servers, then shut down one backend. Verify that:</p>\n<ul>\n<li>The load balancer immediately stops selecting the failed backend</li>\n<li>In-flight requests to the failed backend return appropriate error codes</li>\n<li>New requests distribute only among healthy backends</li>\n<li>Health checks continue and detect when the backend recovers</li>\n</ul>\n</li>\n<li><p><strong>Client Disconnection Testing</strong>: Start a request but disconnect the client before completion. Verify that:</p>\n<ul>\n<li>The connection is properly cleaned up within 1 second</li>\n<li>The backend request is canceled if not yet sent</li>\n<li>No file descriptors or memory leak occurs</li>\n<li>Backend connections are returned to the pool if applicable</li>\n</ul>\n</li>\n<li><p><strong>SSL Certificate Failure Testing</strong>: Configure SSL termination with an expired certificate. Verify that:</p>\n<ul>\n<li>HTTPS connections are refused rather than served with expired certificates</li>\n<li>Certificate reload functionality works when valid certificates are provided</li>\n<li>SNI continues working for other valid certificates</li>\n<li>Error logs contain appropriate security alert information</li>\n</ul>\n</li>\n<li><p><strong>Resource Exhaustion Testing</strong>: Send requests at high rate to exhaust connection pools. Verify that:</p>\n<ul>\n<li>New requests receive HTTP 503 responses rather than hanging indefinitely</li>\n<li>Connection pool recovery occurs when load decreases</li>\n<li>No file descriptor leaks occur during exhaustion periods</li>\n<li>Error monitoring correctly reports resource exhaustion conditions</li>\n</ul>\n</li>\n</ol>\n<p><strong>Debugging Error Handling Issues</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>File descriptor leaks during errors</td>\n<td>Missing cleanup in error paths</td>\n<td>Use <code>lsof -p &lt;pid&gt;</code> to track FD growth</td>\n<td>Add CLEANUP_CONNECTION macros to all error paths</td>\n</tr>\n<tr>\n<td>Requests hang during backend failures</td>\n<td>Missing timeout on backend operations</td>\n<td>Check connection state, look for FORWARDING state persistence</td>\n<td>Implement timeout_manager_add_connection() for all backend operations</td>\n</tr>\n<tr>\n<td>Error responses contain internal details</td>\n<td>No error sanitization</td>\n<td>Review error response content in logs</td>\n<td>Implement generate_client_error_response() with message filtering</td>\n</tr>\n<tr>\n<td>Recovery actions cause more failures</td>\n<td>Cascade failure amplification</td>\n<td>Monitor error rates during recovery periods</td>\n<td>Add exponential backoff and circuit breaker patterns</td>\n</tr>\n<tr>\n<td>Components have inconsistent failure state</td>\n<td>Async error propagation issues</td>\n<td>Compare backend health state across load balancer and connection manager</td>\n<td>Implement centralized error reporting with proxy_handle_error()</td>\n</tr>\n</tbody></table>\n<p>The error handling implementation forms the foundation for a robust reverse proxy that maintains service availability during various failure conditions while protecting against security vulnerabilities and resource exhaustion.</p>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - comprehensive testing ensures correct implementation of HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).</p>\n</blockquote>\n<p>Think of testing a reverse proxy as conducting a full orchestra rehearsal. Just as a conductor must verify that each section plays correctly in isolation (violins, brass, percussion) and then ensure they harmonize together during the complete symphony, we need to test individual components independently and verify their coordinated behavior in realistic scenarios. A single missed note in one section can disrupt the entire performance, just as a bug in HTTP parsing or connection pooling can cascade through the entire request processing pipeline.</p>\n<p>The testing strategy for our reverse proxy follows a three-tiered approach that mirrors how complex distributed systems are validated in production environments. We start with <strong>unit testing</strong> to verify individual component behavior in isolation, progress to <strong>integration testing</strong> to validate component interactions and data flow, and culminate with <strong>milestone verification checkpoints</strong> that simulate real-world usage patterns. Each tier builds confidence in different aspects of system correctness while providing increasingly realistic validation scenarios.</p>\n<h3 id=\"unit-testing-approach\">Unit Testing Approach</h3>\n<p>Unit testing for a reverse proxy focuses on isolating each component&#39;s core logic while carefully mocking external dependencies like network I/O, file system operations, and time-dependent behavior. Think of unit testing as examining each instrument in our orchestra separately - we want to verify that the violin section can play their parts correctly before worrying about how they blend with the brass section.</p>\n<p>The foundation of effective unit testing lies in <strong>dependency injection</strong> and <strong>interface abstraction</strong>. Each component receives its dependencies through constructor parameters rather than creating them directly, allowing tests to substitute mock implementations that behave predictably. This approach enables us to test error scenarios that would be difficult to reproduce with real network connections, such as partial reads, connection timeouts, or SSL handshake failures.</p>\n<p><strong>HTTP Parser Unit Testing Strategy:</strong></p>\n<p>The <code>HttpParser</code> component requires particularly thorough unit testing due to its responsibility for correctly interpreting the HTTP protocol specification. Tests must verify parsing behavior across all <code>HttpParserState</code> transitions, handle malformed input gracefully, and correctly process edge cases like chunked transfer encoding and keep-alive connections.</p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Test Cases</th>\n<th>Input Data</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Line Parsing</td>\n<td>Valid methods, URIs, versions</td>\n<td><code>GET /path HTTP/1.1\\r\\n</code></td>\n<td>State transitions to <code>HTTP_PARSING_HEADERS</code></td>\n</tr>\n<tr>\n<td>Header Parsing</td>\n<td>Standard headers, custom headers</td>\n<td><code>Content-Type: application/json\\r\\n</code></td>\n<td>Headers stored in <code>HashTable</code></td>\n</tr>\n<tr>\n<td>Content-Length Body</td>\n<td>Fixed-length request body</td>\n<td><code>Content-Length: 5\\r\\n\\r\\nhello</code></td>\n<td>Body buffer contains exact bytes</td>\n</tr>\n<tr>\n<td>Chunked Encoding</td>\n<td>Variable-sized chunks</td>\n<td><code>5\\r\\nhello\\r\\n0\\r\\n\\r\\n</code></td>\n<td>Assembled body without chunk markers</td>\n</tr>\n<tr>\n<td>Malformed Input</td>\n<td>Invalid syntax, oversized headers</td>\n<td><code>INVALID REQUEST LINE</code></td>\n<td>State transitions to <code>HTTP_PARSING_ERROR</code></td>\n</tr>\n<tr>\n<td>Incremental Parsing</td>\n<td>Partial packet delivery</td>\n<td>Split input across multiple calls</td>\n<td>Maintains state across <code>http_parser_process</code> calls</td>\n</tr>\n</tbody></table>\n<p>The parser testing framework uses <strong>mock buffers</strong> that simulate network packet boundaries, ensuring the parser correctly handles scenarios where HTTP messages arrive in fragments. Tests inject specific byte sequences at precise boundaries to verify state machine robustness.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Mock buffer simulation for incremental parsing tests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#FFAB70\"> fragments</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">     // Simulated network packets</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#FFAB70\"> fragment_sizes</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> fragment_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> current_fragment;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} MockNetworkBuffer;</span></span></code></pre></div>\n\n<p><strong>Connection Manager Unit Testing Strategy:</strong></p>\n<p>Testing the <code>ConnectionManager</code> requires sophisticated mocking of the event-driven I/O subsystem. Since the connection manager coordinates between epoll events, timer wheel timeouts, and connection pool operations, tests must carefully control the timing and ordering of these interactions.</p>\n<table>\n<thead>\n<tr>\n<th>Component Under Test</th>\n<th>Mock Dependencies</th>\n<th>Test Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>connection_manager_accept_client</code></td>\n<td>Mock socket file descriptors</td>\n<td>Verify <code>Connection</code> state initialization</td>\n</tr>\n<tr>\n<td><code>connection_manager_acquire_backend</code></td>\n<td>Mock <code>ConnectionPool</code></td>\n<td>Test connection reuse vs. new connection logic</td>\n</tr>\n<tr>\n<td><code>connection_manager_handle_event</code></td>\n<td>Mock epoll events</td>\n<td>Verify state transitions for <code>ConnectionState</code></td>\n</tr>\n<tr>\n<td><code>timeout_processor</code></td>\n<td>Mock <code>TimerWheel</code></td>\n<td>Test timeout detection and connection cleanup</td>\n</tr>\n<tr>\n<td><code>connection_manager_release_backend</code></td>\n<td>Mock pool statistics</td>\n<td>Verify connection return to pool logic</td>\n</tr>\n</tbody></table>\n<p>The connection manager tests use <strong>synthetic epoll events</strong> generated by test harnesses rather than real network I/O. This approach allows tests to precisely control event ordering and timing without depending on external network conditions or introducing non-deterministic behavior.</p>\n<p><strong>Load Balancer Unit Testing Strategy:</strong></p>\n<p>Load balancer testing focuses on algorithm correctness and health check behavior under various backend availability scenarios. The key challenge is testing concurrent access patterns while maintaining deterministic test outcomes.</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Test Scenarios</th>\n<th>Expected Distribution</th>\n<th>Verification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>LB_ROUND_ROBIN</code></td>\n<td>3 healthy backends, 100 requests</td>\n<td>33/33/34 requests per backend</td>\n<td>Track <code>rr_current_index</code> progression</td>\n</tr>\n<tr>\n<td><code>LB_LEAST_CONNECTIONS</code></td>\n<td>Backends with 0, 5, 10 connections</td>\n<td>New requests to backend with 0</td>\n<td>Verify <code>connection_counts</code> array</td>\n</tr>\n<tr>\n<td><code>LB_WEIGHTED_ROUND_ROBIN</code></td>\n<td>Weights 1:2:3, 60 requests</td>\n<td>10/20/30 requests per backend</td>\n<td>Track <code>current_weights</code> calculations</td>\n</tr>\n<tr>\n<td><code>LB_IP_HASH</code></td>\n<td>Same client IP, 10 requests</td>\n<td>All requests to same backend</td>\n<td>Hash consistency verification</td>\n</tr>\n</tbody></table>\n<p>Backend health checking tests use <strong>controlled failure injection</strong> to simulate network timeouts, connection refused errors, and slow response scenarios. Tests advance mock timers to trigger health check intervals without waiting for real time to pass.</p>\n<p><strong>Cache Engine Unit Testing Strategy:</strong></p>\n<p>Cache testing requires careful attention to timing precision and memory management. Tests must verify cache-control header parsing, TTL calculations, LRU eviction behavior, and concurrent access patterns across multiple threads.</p>\n<table>\n<thead>\n<tr>\n<th>Cache Operation</th>\n<th>Test Scenarios</th>\n<th>Cache State Verification</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>cache_engine_lookup</code></td>\n<td>Hit, miss, expired entry</td>\n<td>Verify <code>CacheEntry</code> retrieval</td>\n</tr>\n<tr>\n<td><code>cache_engine_store</code></td>\n<td>Cacheable, non-cacheable responses</td>\n<td>Check <code>CacheStats</code> updates</td>\n</tr>\n<tr>\n<td><code>lru_list_move_to_head</code></td>\n<td>Access existing entry</td>\n<td>Verify LRU order maintenance</td>\n</tr>\n<tr>\n<td><code>cache_control_parse</code></td>\n<td>Various Cache-Control directives</td>\n<td>Validate <code>CacheControl</code> structure</td>\n</tr>\n<tr>\n<td>Cache eviction</td>\n<td>Fill cache beyond size limit</td>\n<td>Verify LRU entry removal</td>\n</tr>\n<tr>\n<td>TTL expiration</td>\n<td>Advance mock time</td>\n<td>Verify expired entry cleanup</td>\n</tr>\n</tbody></table>\n<p>Cache tests use <strong>deterministic time mocking</strong> to control TTL calculations and expiration behavior. Mock time functions replace system calls to <code>time()</code> and <code>clock_gettime()</code>, allowing tests to &quot;fast forward&quot; through cache lifetimes without actual delays.</p>\n<p><strong>SSL Termination Unit Testing Strategy:</strong></p>\n<p>SSL component testing requires sophisticated OpenSSL mocking since real certificate operations involve file system access and cryptographic computations. Tests focus on certificate loading, SNI callback behavior, and TLS context management.</p>\n<table>\n<thead>\n<tr>\n<th>SSL Function</th>\n<th>Mock Strategy</th>\n<th>Test Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ssl_utils_load_certificate</code></td>\n<td>Mock certificate file content</td>\n<td>Verify <code>CertificateInfo</code> parsing</td>\n</tr>\n<tr>\n<td><code>ssl_termination_sni_callback</code></td>\n<td>Mock SNI hostnames</td>\n<td>Test context selection logic</td>\n</tr>\n<tr>\n<td><code>ssl_utils_verify_key_cert_match</code></td>\n<td>Controlled key/cert pairs</td>\n<td>Verify cryptographic validation</td>\n</tr>\n<tr>\n<td>Certificate reload</td>\n<td>Mock file system notifications</td>\n<td>Test dynamic certificate updates</td>\n</tr>\n</tbody></table>\n<p>SSL tests use <strong>synthetic certificates</strong> generated at test startup rather than loading real certificate files. This approach eliminates file system dependencies while providing controlled certificate properties for testing edge cases.</p>\n<p>⚠️ <strong>Pitfall: Testing with Real Network I/O</strong>\nMany developers attempt to test connection manager logic using actual TCP sockets and network communication. This approach introduces non-deterministic timing behavior, makes tests fragile to network conditions, and requires complex test environment setup. Instead, use mock file descriptors and synthetic events that provide deterministic, controllable test conditions.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Parser State Persistence</strong>\nHTTP parser tests often focus only on complete, well-formed messages without testing incremental parsing behavior. Real network traffic arrives in arbitrary packet boundaries, so tests must verify that parser state correctly persists across multiple <code>http_parser_process</code> calls with fragmented input data.</p>\n<h3 id=\"integration-testing\">Integration Testing</h3>\n<p>Integration testing validates the <strong>orchestration</strong> between components, ensuring that data flows correctly through the complete request processing pipeline. Think of integration testing as rehearsing sections of our orchestra together - we need to verify that when the violins finish their phrase, the brass section enters at precisely the right moment with the correct dynamics.</p>\n<p>Integration tests operate at the <strong>component boundary level</strong>, using real implementations for the components under test while carefully controlling their external dependencies. Unlike unit tests that isolate individual functions, integration tests verify that components correctly implement their <strong>interface contracts</strong> and handle the asynchronous message passing that coordinates request processing.</p>\n<p><strong>Parser-Connection Manager Integration:</strong></p>\n<p>The integration between <code>HttpParser</code> and <code>ConnectionManager</code> centers on the <strong>stream-based parsing contract</strong>. The connection manager feeds incoming network data to the parser incrementally, while the parser signals completion states that drive connection state transitions.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Scenario</th>\n<th>Test Setup</th>\n<th>Validation Points</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Complete request parsing</td>\n<td>Send well-formed HTTP request</td>\n<td>Verify <code>HTTP_PARSING_COMPLETE</code> triggers backend forwarding</td>\n</tr>\n<tr>\n<td>Partial request arrival</td>\n<td>Send request in multiple fragments</td>\n<td>Verify parser maintains state across <code>connection_manager_handle_event</code> calls</td>\n</tr>\n<tr>\n<td>Parse error handling</td>\n<td>Send malformed HTTP data</td>\n<td>Verify connection transitions to <code>CONNECTION_CLOSING</code></td>\n</tr>\n<tr>\n<td>Keep-alive detection</td>\n<td>Send <code>Connection: keep-alive</code> header</td>\n<td>Verify connection remains in pool after response</td>\n</tr>\n<tr>\n<td>Pipeline request handling</td>\n<td>Send multiple pipelined requests</td>\n<td>Verify correct request boundary detection</td>\n</tr>\n</tbody></table>\n<p>The test harness uses <strong>mock TCP streams</strong> that deliver data at controlled intervals, simulating realistic network packet arrival patterns. Tests verify that connection state transitions occur at precisely the correct moments relative to parser state changes.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Integration test data structure for controlled packet delivery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> packet_data;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> packet_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> delivery_delay_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> should_trigger_event;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} MockPacket;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockPacket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> packets;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> packet_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> current_packet;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> conn_mgr;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HttpParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> parser;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ParserConnectionIntegrationTest;</span></span></code></pre></div>\n\n<p><strong>Load Balancer-Connection Manager Integration:</strong></p>\n<p>This integration validates the <strong>backend selection and connection acquisition workflow</strong>. The load balancer selects an appropriate backend server, while the connection manager either reuses an existing pooled connection or establishes a new connection to that backend.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Workflow</th>\n<th>Test Configuration</th>\n<th>Validation Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Backend selection with pool hit</td>\n<td>3 backends, existing pooled connections</td>\n<td>Verify <code>connection_manager_acquire_backend</code> reuses connection</td>\n</tr>\n<tr>\n<td>Backend selection with pool miss</td>\n<td>Backends with empty connection pools</td>\n<td>Verify new connection establishment</td>\n</tr>\n<tr>\n<td>Backend failure during acquisition</td>\n<td>Temporarily unreachable backend</td>\n<td>Verify failover to alternate backend</td>\n</tr>\n<tr>\n<td>Health check triggered pool eviction</td>\n<td>Backend marked unhealthy</td>\n<td>Verify pooled connections removed</td>\n</tr>\n<tr>\n<td>Weighted selection with pool status</td>\n<td>Different pool utilization per backend</td>\n<td>Verify selection considers both weight and availability</td>\n</tr>\n</tbody></table>\n<p>Integration tests use <strong>network namespace isolation</strong> to simulate backend server behavior without requiring actual backend processes. Test backends respond with predictable HTTP responses and can be configured to simulate various failure modes.</p>\n<p><strong>Cache Engine-HTTP Parser Integration:</strong></p>\n<p>Cache integration testing verifies <strong>conditional request generation</strong> and <strong>cache-control header interpretation</strong>. The cache engine must correctly parse HTTP headers to determine cacheability, generate appropriate cache keys, and create conditional requests for cache validation.</p>\n<table>\n<thead>\n<tr>\n<th>Cache Integration Scenario</th>\n<th>Request Properties</th>\n<th>Expected Cache Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Fresh cache hit</td>\n<td>Cached response within TTL</td>\n<td>Return cached response without backend query</td>\n</tr>\n<tr>\n<td>Stale cache validation</td>\n<td>Cached response beyond TTL with ETag</td>\n<td>Generate <code>If-None-Match</code> conditional request</td>\n</tr>\n<tr>\n<td>Cache miss</td>\n<td>No cached entry for request</td>\n<td>Forward to backend and cache response</td>\n</tr>\n<tr>\n<td>Non-cacheable response</td>\n<td>Response with <code>Cache-Control: no-store</code></td>\n<td>Forward response without caching</td>\n</tr>\n<tr>\n<td>Vary header handling</td>\n<td>Response with <code>Vary: Accept-Encoding</code></td>\n<td>Include Accept-Encoding in cache key</td>\n</tr>\n</tbody></table>\n<p>Cache integration tests use <strong>mock HTTP responses</strong> with controlled cache-control headers and known ETags. Tests verify that cache key generation produces consistent results and that conditional requests contain the correct validation headers.</p>\n<p><strong>SSL Termination-Connection Manager Integration:</strong></p>\n<p>SSL integration testing focuses on the <strong>TLS handshake coordination</strong> and the <strong>transition from encrypted client communication to plaintext backend forwarding</strong>. This integration is particularly complex due to the asynchronous nature of TLS handshake processing.</p>\n<table>\n<thead>\n<tr>\n<th>SSL Integration Case</th>\n<th>TLS Configuration</th>\n<th>Validation Points</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Successful handshake</td>\n<td>Valid certificate, strong ciphers</td>\n<td>Verify plaintext HTTP extraction</td>\n</tr>\n<tr>\n<td>SNI-based certificate selection</td>\n<td>Multiple certificates loaded</td>\n<td>Verify correct certificate chosen</td>\n</tr>\n<tr>\n<td>Client certificate validation</td>\n<td>Mutual TLS configuration</td>\n<td>Verify client certificate verification</td>\n</tr>\n<tr>\n<td>TLS handshake failure</td>\n<td>Invalid certificate configuration</td>\n<td>Verify graceful connection termination</td>\n</tr>\n<tr>\n<td>Mixed HTTP/HTTPS handling</td>\n<td>Both ports listening</td>\n<td>Verify protocol-appropriate handling</td>\n</tr>\n</tbody></table>\n<p>SSL integration tests use <strong>self-signed test certificates</strong> generated during test setup with known properties. Tests simulate various client TLS implementations to verify compatibility across different TLS library versions and cipher suite preferences.</p>\n<p><strong>End-to-End Request Flow Integration:</strong></p>\n<p>The most comprehensive integration tests trace <strong>complete request processing pipelines</strong> that exercise all major components in realistic sequences. These tests simulate actual reverse proxy usage patterns with multiple concurrent clients and backend servers.</p>\n<table>\n<thead>\n<tr>\n<th>End-to-End Scenario</th>\n<th>Test Configuration</th>\n<th>Component Interactions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cached response serving</td>\n<td>Cache hit with fresh entry</td>\n<td>SSL → Parser → Cache (hit) → Response</td>\n</tr>\n<tr>\n<td>Load-balanced backend request</td>\n<td>Cache miss, multiple backends</td>\n<td>SSL → Parser → Cache (miss) → LB → Backend → Response</td>\n</tr>\n<tr>\n<td>Backend failover with retry</td>\n<td>Primary backend failure</td>\n<td>SSL → Parser → LB → Failure → LB (retry) → Backend → Response</td>\n</tr>\n<tr>\n<td>SSL certificate reload</td>\n<td>Certificate update during traffic</td>\n<td>SSL (reload) → Continue serving with new cert</td>\n</tr>\n<tr>\n<td>Connection pooling optimization</td>\n<td>Multiple requests to same backend</td>\n<td>Verify connection reuse across requests</td>\n</tr>\n</tbody></table>\n<p>End-to-end tests use <strong>docker-compose environments</strong> with real backend HTTP servers, allowing tests to verify behavior against actual HTTP implementations rather than mocks. This approach catches integration issues that might be missed with entirely synthetic test environments.</p>\n<p>⚠️ <strong>Pitfall: Over-Mocking in Integration Tests</strong>\nIntegration tests lose their value when too many components are mocked. The goal is to test real component interactions, so only external dependencies (like actual network calls) should be mocked. Using real component implementations reveals interface mismatches and timing issues that unit tests cannot detect.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Asynchronous Timing</strong>\nMany integration test failures occur due to race conditions between components that communicate asynchronously. Tests must either use synchronization primitives to control component interaction timing or employ polling strategies that wait for expected state changes rather than assuming immediate completion.</p>\n<h3 id=\"milestone-verification-checkpoints\">Milestone Verification Checkpoints</h3>\n<p>Milestone checkpoints provide <strong>concrete validation criteria</strong> that confirm each phase of implementation meets functional requirements before proceeding to the next milestone. Think of these checkpoints as <strong>integration rehearsals</strong> where we verify that newly implemented functionality works correctly both in isolation and in combination with previously completed components.</p>\n<p>Each milestone checkpoint includes <strong>automated test suites</strong>, <strong>manual verification procedures</strong>, and <strong>performance benchmarks</strong> that validate both correctness and basic performance characteristics. The checkpoints are designed to catch integration issues early, before they compound with additional complexity from subsequent milestones.</p>\n<p><strong>Milestone 1: HTTP Proxy Core Verification</strong></p>\n<p>The HTTP proxy core checkpoint validates basic request forwarding functionality without load balancing, caching, or SSL termination. This foundational milestone must demonstrate rock-solid HTTP protocol handling and connection management before adding additional complexity.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Area</th>\n<th>Test Method</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP/1.1 request forwarding</td>\n<td>Automated test suite</td>\n<td>100% of well-formed requests forwarded correctly</td>\n</tr>\n<tr>\n<td>HTTP header preservation</td>\n<td>Header comparison tests</td>\n<td>All client headers preserved in backend requests</td>\n</tr>\n<tr>\n<td>Response body integrity</td>\n<td>Binary content verification</td>\n<td>Byte-for-byte response accuracy</td>\n</tr>\n<tr>\n<td>Connection state management</td>\n<td>Connection lifecycle tests</td>\n<td>No resource leaks after 1000 requests</td>\n</tr>\n<tr>\n<td>Error handling</td>\n<td>Malformed request tests</td>\n<td>Appropriate error responses for invalid input</td>\n</tr>\n<tr>\n<td>Keep-alive support</td>\n<td>Connection reuse verification</td>\n<td>Multiple requests over single client connection</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run core HTTP proxy tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> test-milestone-1</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/integration/http_proxy_core_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Performance baseline test</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/performance/proxy_benchmark</span><span style=\"color:#79B8FF\"> -requests=1000</span><span style=\"color:#79B8FF\"> -concurrency=10</span></span></code></pre></div>\n\n<p><strong>Manual Verification Procedures:</strong>\nThe manual verification uses <code>curl</code> commands to test realistic usage scenarios that automated tests might miss:</p>\n<ol>\n<li><p><strong>Basic Request Forwarding Test:</strong></p>\n<ul>\n<li>Start proxy server: <code>./reverse_proxy -config=test.conf -backends=localhost:8080</code></li>\n<li>Start test backend: <code>python3 -m http.server 8080</code></li>\n<li>Test GET request: <code>curl -v http://localhost:3128/test.html</code></li>\n<li>Verify response matches direct backend access</li>\n<li>Check proxy logs show request forwarding</li>\n</ul>\n</li>\n<li><p><strong>Header Manipulation Verification:</strong></p>\n<ul>\n<li>Send request with custom headers: <code>curl -H &quot;X-Test: value&quot; http://localhost:3128/</code></li>\n<li>Verify backend receives <code>X-Forwarded-For</code> and <code>Via</code> headers</li>\n<li>Confirm custom client headers preserved</li>\n</ul>\n</li>\n<li><p><strong>HTTP Method Support:</strong></p>\n<ul>\n<li>Test POST: <code>curl -X POST -d &quot;data&quot; http://localhost:3128/api/test</code></li>\n<li>Test PUT: <code>curl -X PUT -d @file.json http://localhost:3128/upload</code></li>\n<li>Test DELETE: <code>curl -X DELETE http://localhost:3128/resource/123</code></li>\n</ul>\n</li>\n<li><p><strong>Error Condition Handling:</strong></p>\n<ul>\n<li>Stop backend server, verify 502 Bad Gateway response</li>\n<li>Send oversized request, verify 413 Request Entity Too Large</li>\n<li>Send malformed HTTP, verify connection closes gracefully</li>\n</ul>\n</li>\n</ol>\n<p><strong>Expected Performance Baseline:</strong></p>\n<ul>\n<li><strong>Throughput:</strong> 1,000 requests/second with 10 concurrent connections</li>\n<li><strong>Latency:</strong> 95th percentile under 10ms for localhost backends</li>\n<li><strong>Memory Usage:</strong> Stable under 50MB resident memory after 10,000 requests</li>\n<li><strong>Connection Handling:</strong> Support at least 100 concurrent client connections</li>\n</ul>\n<p>⚠️ <strong>Milestone 1 Common Issues:</strong></p>\n<ul>\n<li><strong>Incomplete response forwarding:</strong> Verify both headers and body are completely transmitted</li>\n<li><strong>Connection hang on backend failure:</strong> Ensure timeouts are implemented for backend connections</li>\n<li><strong>Memory leaks in request processing:</strong> Use valgrind to detect buffer management issues</li>\n</ul>\n<p><strong>Milestone 2: Load Balancing Verification</strong></p>\n<p>Load balancing verification confirms correct request distribution across multiple backend servers and validates health checking behavior under various failure scenarios.</p>\n<table>\n<thead>\n<tr>\n<th>Load Balancing Feature</th>\n<th>Test Method</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Round-robin distribution</td>\n<td>Statistical analysis</td>\n<td>Even distribution within 5% variance</td>\n</tr>\n<tr>\n<td>Least-connections algorithm</td>\n<td>Connection count tracking</td>\n<td>Requests routed to least busy backend</td>\n</tr>\n<tr>\n<td>Backend health checking</td>\n<td>Controlled backend failures</td>\n<td>Unhealthy backends removed within 30 seconds</td>\n</tr>\n<tr>\n<td>Failover behavior</td>\n<td>Sequential backend shutdown</td>\n<td>Traffic redirected without client errors</td>\n</tr>\n<tr>\n<td>Dynamic backend updates</td>\n<td>Configuration reload</td>\n<td>New backends available without restart</td>\n</tr>\n<tr>\n<td>Weighted distribution</td>\n<td>Capacity-based routing</td>\n<td>Traffic distributed per weight ratios</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run load balancing test suite</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> test-milestone-2</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/integration/load_balancer_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Multi-backend stress test</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/load/multi_backend_test</span><span style=\"color:#79B8FF\"> -backends=3</span><span style=\"color:#79B8FF\"> -requests=5000</span></span></code></pre></div>\n\n<p><strong>Manual Verification Procedures:</strong></p>\n<ol>\n<li><p><strong>Round-Robin Distribution Test:</strong></p>\n<ul>\n<li>Configure 3 backend servers on ports 8080, 8081, 8082</li>\n<li>Send 30 requests: <code>for i in {1..30}; do curl http://localhost:3128/; done</code></li>\n<li>Check backend logs: each should receive ~10 requests</li>\n<li>Verify request distribution is approximately even</li>\n</ul>\n</li>\n<li><p><strong>Health Check Validation:</strong></p>\n<ul>\n<li>Start proxy with health checking enabled (30-second intervals)</li>\n<li>Stop one backend server: <code>kill $BACKEND_PID</code></li>\n<li>Send requests and verify traffic routes only to healthy backends</li>\n<li>Restart backend and verify it rejoins rotation</li>\n</ul>\n</li>\n<li><p><strong>Weighted Load Balancing:</strong></p>\n<ul>\n<li>Configure backends with weights 1:2:3</li>\n<li>Send 60 requests and verify distribution: 10/20/30</li>\n<li>Monitor <code>LoadBalancer</code> metrics for weight compliance</li>\n</ul>\n</li>\n<li><p><strong>Least-Connections Algorithm:</strong></p>\n<ul>\n<li>Configure least-connections mode</li>\n<li>Establish persistent connections to backends (different counts)</li>\n<li>Send new requests and verify routing to least busy backend</li>\n</ul>\n</li>\n</ol>\n<p><strong>Backend Health Check Configuration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">ini</span><pre class=\"arch-pre shiki-highlighted\"><code># test.conf load balancing section\n[load_balancer]\nalgorithm = round_robin\nhealth_check_interval = 30\nhealth_check_timeout = 5\nfailure_threshold = 3\nsuccess_threshold = 2\n\n[backends]\nbackend1 = host=localhost port=8080 weight=1\nbackend2 = host=localhost port=8081 weight=2  \nbackend3 = host=localhost port=8082 weight=3</code></pre></div>\n\n<p>⚠️ <strong>Milestone 2 Common Issues:</strong></p>\n<ul>\n<li><strong>Sticky connections disrupting distribution:</strong> Ensure connection pooling doesn&#39;t bias routing</li>\n<li><strong>Health check false positives:</strong> Verify health check timeout values are appropriate for network conditions</li>\n<li><strong>Race conditions in backend selection:</strong> Check thread safety of backend state updates</li>\n</ul>\n<p><strong>Milestone 3: Connection Pooling Verification</strong></p>\n<p>Connection pooling checkpoint validates backend connection reuse, proper pool size management, and connection lifecycle handling under various load patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Connection Pool Feature</th>\n<th>Test Method</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connection reuse</td>\n<td>Pool utilization metrics</td>\n<td>&gt;80% connection reuse rate</td>\n</tr>\n<tr>\n<td>Pool size limits</td>\n<td>Concurrent connection test</td>\n<td>Pool never exceeds configured maximum</td>\n</tr>\n<tr>\n<td>Idle timeout handling</td>\n<td>Connection aging test</td>\n<td>Stale connections removed within timeout</td>\n</tr>\n<tr>\n<td>Pool exhaustion handling</td>\n<td>High concurrency test</td>\n<td>Graceful handling when pool full</td>\n</tr>\n<tr>\n<td>Health integration</td>\n<td>Backend failure simulation</td>\n<td>Broken connections purged from pool</td>\n</tr>\n<tr>\n<td>Per-backend isolation</td>\n<td>Multi-backend pool test</td>\n<td>Separate pools maintained per backend</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run connection pooling test suite  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> test-milestone-3</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/integration/connection_pool_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Pool exhaustion stress test</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/stress/pool_exhaustion_test</span><span style=\"color:#79B8FF\"> -max_pools=100</span><span style=\"color:#79B8FF\"> -concurrent=500</span></span></code></pre></div>\n\n<p><strong>Manual Verification Procedures:</strong></p>\n<ol>\n<li><p><strong>Connection Reuse Validation:</strong></p>\n<ul>\n<li>Configure small pool size (max 5 connections per backend)</li>\n<li>Send 50 sequential requests to same backend</li>\n<li>Monitor pool metrics: should show high reuse percentage</li>\n<li>Check backend: should see only 5 TCP connections established</li>\n</ul>\n</li>\n<li><p><strong>Pool Limit Enforcement:</strong></p>\n<ul>\n<li>Configure pool with max_connections=3</li>\n<li>Generate 10 concurrent requests</li>\n<li>Verify only 3 backend connections established</li>\n<li>Additional requests should queue or use alternate backends</li>\n</ul>\n</li>\n<li><p><strong>Idle Timeout Testing:</strong></p>\n<ul>\n<li>Send requests to establish pooled connections</li>\n<li>Wait for idle_timeout period (configured in test.conf)</li>\n<li>Send new request and verify fresh connection establishment</li>\n<li>Check pool metrics show connection eviction occurred</li>\n</ul>\n</li>\n<li><p><strong>Pool Health Integration:</strong></p>\n<ul>\n<li>Establish connections in pool</li>\n<li>Force backend restart (simulates network partition)</li>\n<li>Verify broken connections detected and removed</li>\n<li>New requests should establish fresh connections</li>\n</ul>\n</li>\n</ol>\n<p><strong>Connection Pool Metrics to Monitor:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Expected pool statistics after testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> total_connections_created;</span><span style=\"color:#6A737D\">    // Should be minimized via reuse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> current_active_connections;</span><span style=\"color:#6A737D\">   // Should stay within limits</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> current_idle_connections;</span><span style=\"color:#6A737D\">     // Should reflect pool utilization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> connection_reuse_count;</span><span style=\"color:#6A737D\">     // Should be high relative to requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> pool_exhaustion_events;</span><span style=\"color:#6A737D\">     // Should be zero under normal load</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> last_cleanup_time;</span><span style=\"color:#6A737D\">            // Should advance with idle timeouts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} PoolMetrics;</span></span></code></pre></div>\n\n<p>⚠️ <strong>Milestone 3 Common Issues:</strong></p>\n<ul>\n<li><strong>Connection leaks:</strong> Ensure connections are properly returned to pool after request completion</li>\n<li><strong>Deadlocks in pool access:</strong> Verify thread-safe pool operations under high concurrency</li>\n<li><strong>Stale connection reuse:</strong> Implement connection validation before reuse from pool</li>\n</ul>\n<p><strong>Milestone 4: Caching Verification</strong></p>\n<p>Caching verification confirms correct HTTP caching behavior, cache-control header compliance, and cache performance characteristics under various response types and cache sizes.</p>\n<table>\n<thead>\n<tr>\n<th>Cache Feature</th>\n<th>Test Method</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache hit serving</td>\n<td>Duplicate request test</td>\n<td>Second request served from cache</td>\n</tr>\n<tr>\n<td>TTL expiration</td>\n<td>Time-based cache test</td>\n<td>Expired entries trigger backend requests</td>\n</tr>\n<tr>\n<td>Cache-Control compliance</td>\n<td>Header parsing test</td>\n<td><code>no-cache</code>, <code>no-store</code> directives respected</td>\n</tr>\n<tr>\n<td>ETag validation</td>\n<td>Conditional request test</td>\n<td><code>If-None-Match</code> requests generate 304 responses</td>\n</tr>\n<tr>\n<td>LRU eviction</td>\n<td>Cache overflow test</td>\n<td>Oldest entries evicted when cache full</td>\n</tr>\n<tr>\n<td>Vary header handling</td>\n<td>Content negotiation test</td>\n<td>Accept-Encoding included in cache keys</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run caching test suite</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> test-milestone-4</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/integration/cache_engine_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Cache performance benchmark</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/performance/cache_benchmark</span><span style=\"color:#79B8FF\"> -cache_size=100MB</span><span style=\"color:#79B8FF\"> -requests=10000</span></span></code></pre></div>\n\n<p><strong>Manual Verification Procedures:</strong></p>\n<ol>\n<li><p><strong>Basic Cache Hit Testing:</strong></p>\n<ul>\n<li>Clear cache: <code>curl -X DELETE http://localhost:3128/admin/cache</code></li>\n<li>Send request: <code>curl -v http://localhost:3128/static/image.jpg</code></li>\n<li>Note backend access in logs and response headers</li>\n<li>Repeat request: should show cache hit with <code>X-Cache-Status: HIT</code></li>\n</ul>\n</li>\n<li><p><strong>Cache-Control Compliance:</strong></p>\n<ul>\n<li>Test cacheable response: <code>curl http://localhost:3128/api/data</code> (with <code>Cache-Control: max-age=300</code>)</li>\n<li>Test non-cacheable: <code>curl http://localhost:3128/api/user</code> (with <code>Cache-Control: no-store</code>)</li>\n<li>Verify only first response gets cached</li>\n</ul>\n</li>\n<li><p><strong>TTL Expiration Validation:</strong></p>\n<ul>\n<li>Configure short TTL in test backend responses (<code>max-age=5</code>)</li>\n<li>Send request and verify cache storage</li>\n<li>Wait 10 seconds, repeat request</li>\n<li>Verify backend access occurs due to expiration</li>\n</ul>\n</li>\n<li><p><strong>Conditional Request Testing:</strong></p>\n<ul>\n<li>Send request to backend that supports ETags</li>\n<li>Verify cache stores ETag value</li>\n<li>After expiration, verify proxy sends <code>If-None-Match</code></li>\n<li>Backend should respond with 304, cache should serve original response</li>\n</ul>\n</li>\n</ol>\n<p><strong>Cache Metrics Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Expected cache statistics after testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> hit_count;</span><span style=\"color:#6A737D\">          // Should increase with duplicate requests  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> miss_count;</span><span style=\"color:#6A737D\">         // Should equal unique cacheable requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> eviction_count;</span><span style=\"color:#6A737D\">     // Should remain low until cache full</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> current_size;</span><span style=\"color:#6A737D\">         // Should not exceed configured limit</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    double</span><span style=\"color:#E1E4E8\"> hit_ratio;</span><span style=\"color:#6A737D\">            // Should be >50% with duplicate requests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} CachePerformanceMetrics;</span></span></code></pre></div>\n\n<p>⚠️ <strong>Milestone 4 Common Issues:</strong></p>\n<ul>\n<li><strong>Caching non-cacheable responses:</strong> Verify POST requests and private responses excluded</li>\n<li><strong>Incorrect cache key generation:</strong> Ensure Vary headers properly included in cache keys</li>\n<li><strong>Memory leaks in cache entries:</strong> Verify proper cleanup of evicted cache entries</li>\n</ul>\n<p><strong>Milestone 5: SSL Termination Verification</strong></p>\n<p>SSL termination checkpoint validates HTTPS request handling, certificate management, SNI support, and the transition from encrypted client connections to plaintext backend communication.</p>\n<table>\n<thead>\n<tr>\n<th>SSL Feature</th>\n<th>Test Method</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>TLS handshake completion</td>\n<td>HTTPS client test</td>\n<td>Successful connection establishment</td>\n</tr>\n<tr>\n<td>Certificate validation</td>\n<td>Certificate chain test</td>\n<td>Valid certificates accepted, invalid rejected</td>\n</tr>\n<tr>\n<td>SNI hostname selection</td>\n<td>Multi-domain test</td>\n<td>Correct certificate chosen per hostname</td>\n</tr>\n<tr>\n<td>Cipher suite negotiation</td>\n<td>TLS compatibility test</td>\n<td>Strong ciphers preferred, weak ciphers rejected</td>\n</tr>\n<tr>\n<td>HTTP to HTTPS redirect</td>\n<td>Mixed protocol test</td>\n<td>HTTP requests redirected to HTTPS</td>\n</tr>\n<tr>\n<td>Certificate reload</td>\n<td>Dynamic cert update</td>\n<td>New certificates loaded without restart</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Test Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run SSL termination test suite</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">make</span><span style=\"color:#9ECBFF\"> test-milestone-5</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/integration/ssl_termination_test</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># SSL compatibility test across TLS versions  </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./test/ssl/tls_compatibility_test</span><span style=\"color:#79B8FF\"> -min_version=TLS1.2</span></span></code></pre></div>\n\n<p><strong>Manual Verification Procedures:</strong></p>\n<ol>\n<li><p><strong>Basic HTTPS Request Processing:</strong></p>\n<ul>\n<li>Generate test certificate: <code>openssl req -x509 -newkey rsa:2048 -keyout test.key -out test.crt</code></li>\n<li>Configure SSL termination with test certificate</li>\n<li>Test HTTPS request: <code>curl -k https://localhost:3129/test.html</code></li>\n<li>Verify response received and backend accessed via HTTP</li>\n</ul>\n</li>\n<li><p><strong>SNI Multi-Domain Testing:</strong></p>\n<ul>\n<li>Configure certificates for multiple domains</li>\n<li>Test domain1: <code>curl -k --resolve domain1.test:3129:127.0.0.1 https://domain1.test:3129/</code></li>\n<li>Test domain2: <code>curl -k --resolve domain2.test:3129:127.0.0.1 https://domain2.test:3129/</code></li>\n<li>Verify correct certificates selected via OpenSSL inspection</li>\n</ul>\n</li>\n<li><p><strong>TLS Version and Cipher Validation:</strong></p>\n<ul>\n<li>Test minimum TLS version: <code>curl --tlsv1.2 -k https://localhost:3129/</code></li>\n<li>Verify weak TLS rejected: <code>curl --tlsv1.0 https://localhost:3129/</code> (should fail)</li>\n<li>Check cipher selection: <code>openssl s_client -connect localhost:3129 -cipher HIGH</code></li>\n</ul>\n</li>\n<li><p><strong>Certificate Reload Testing:</strong></p>\n<ul>\n<li>Start proxy with initial certificate</li>\n<li>Update certificate files on disk</li>\n<li>Send reload signal or API call</li>\n<li>Verify new certificate used for subsequent connections</li>\n</ul>\n</li>\n</ol>\n<p><strong>SSL Configuration Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">ini</span><pre class=\"arch-pre shiki-highlighted\"><code># test.conf SSL section\n[ssl]  \nenabled = true\ncert_path = /etc/ssl/test.crt\nkey_path = /etc/ssl/test.key\nmin_tls_version = TLS_1_2\ncipher_list = ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS</code></pre></div>\n\n<p><strong>SSL Metrics to Monitor:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// SSL termination performance statistics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> handshakes_completed;</span><span style=\"color:#6A737D\">       // Should equal HTTPS requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> handshake_failures;</span><span style=\"color:#6A737D\">         // Should remain low</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> certificate_reloads;</span><span style=\"color:#6A737D\">        // Should match reload operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    double</span><span style=\"color:#E1E4E8\"> avg_handshake_time_ms;</span><span style=\"color:#6A737D\">        // Should be &#x3C;100ms for RSA certificates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> active_ssl_connections;</span><span style=\"color:#6A737D\">     // Should not exceed connection limits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} SSLTerminationMetrics;</span></span></code></pre></div>\n\n<p>⚠️ <strong>Milestone 5 Common Issues:</strong></p>\n<ul>\n<li><strong>Certificate/key mismatch:</strong> Verify certificate and private key correspond via OpenSSL</li>\n<li><strong>Weak cipher acceptance:</strong> Ensure cipher suite configuration rejects deprecated algorithms</li>\n<li><strong>Memory leaks in SSL contexts:</strong> Properly cleanup SSL_CTX structures during certificate reload</li>\n</ul>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The testing strategy implementation requires careful coordination between test frameworks, mock systems, and build automation. The following guidance provides concrete tools and patterns for implementing the testing approach described above.</p>\n<p><strong>A. Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Testing Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Unit Test Framework</td>\n<td>Custom assert macros with C</td>\n<td>Google Test (C++) or Unity (C)</td>\n</tr>\n<tr>\n<td>Mock System</td>\n<td>Manual dependency injection</td>\n<td>CMock or FFF (Fake Function Framework)</td>\n</tr>\n<tr>\n<td>Integration Testing</td>\n<td>Custom test harnesses</td>\n<td>Testcontainers with Docker</td>\n</tr>\n<tr>\n<td>HTTP Test Clients</td>\n<td>curl + shell scripts</td>\n<td>Custom HTTP client library</td>\n</tr>\n<tr>\n<td>Performance Testing</td>\n<td>Simple timing loops</td>\n<td>wrk or Apache Bench (ab)</td>\n</tr>\n<tr>\n<td>SSL Testing</td>\n<td>OpenSSL command line tools</td>\n<td>custom SSL test client</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>reverse-proxy/\n├── src/                           # Source code\n│   ├── http_parser/\n│   ├── connection_manager/ \n│   ├── load_balancer/\n│   ├── cache_engine/\n│   └── ssl_termination/\n├── test/                          # All testing code\n│   ├── unit/                      # Unit tests\n│   │   ├── test_http_parser.c\n│   │   ├── test_connection_manager.c\n│   │   ├── test_load_balancer.c\n│   │   ├── test_cache_engine.c\n│   │   └── test_ssl_termination.c\n│   ├── integration/               # Integration tests\n│   │   ├── test_parser_connection.c\n│   │   ├── test_lb_connection.c\n│   │   ├── test_cache_integration.c\n│   │   └── test_ssl_integration.c\n│   ├── milestone/                 # Milestone checkpoints\n│   │   ├── milestone1_http_core.c\n│   │   ├── milestone2_load_balancing.c\n│   │   ├── milestone3_connection_pooling.c\n│   │   ├── milestone4_caching.c\n│   │   └── milestone5_ssl_termination.c\n│   ├── mocks/                     # Mock implementations\n│   │   ├── mock_network.c\n│   │   ├── mock_timer.c\n│   │   └── mock_ssl.c\n│   ├── fixtures/                  # Test data and configurations\n│   │   ├── test_certificates/\n│   │   ├── sample_http_requests/\n│   │   └── test_configs/\n│   └── scripts/                   # Test automation\n│       ├── run_unit_tests.sh\n│       ├── run_integration_tests.sh\n│       └── milestone_verification.sh\n├── tools/                         # Development tools\n│   ├── test_http_server.c         # Simple backend for testing\n│   └── ssl_cert_generator.sh      # Generate test certificates\n└── Makefile                       # Build and test automation</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code (COMPLETE):</strong></p>\n<p><strong>Mock Network Interface (<code>test/mocks/mock_network.c</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;errno.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"mock_network.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Mock network implementation for testing without real sockets</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> buffer_data;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> buffer_size;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> read_position;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> write_position;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> closed;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> mock_errno;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} MockSocket;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#E1E4E8\"> MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> mock_sockets</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> next_mock_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> mock_socket_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> buffer_size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> next_mock_fd</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sock </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(MockSocket));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->buffer_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(buffer_size);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->buffer_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> buffer_size;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->read_position </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->write_position </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->closed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->mock_errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sock;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> fd;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">ssize_t</span><span style=\"color:#B392F0\"> mock_read</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sock </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">sock </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> sock->closed) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EBADF;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (sock->mock_errno </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sock->mock_errno;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> available </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sock->write_position </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> sock->read_position;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> to_read </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (count </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> available) </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> count </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> available;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (to_read </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EAGAIN;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(buf, sock->buffer_data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> sock->read_position, to_read);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->read_position </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> to_read;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> to_read;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">ssize_t</span><span style=\"color:#B392F0\"> mock_write</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> void*</span><span style=\"color:#FFAB70\"> buf</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sock </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">sock </span><span style=\"color:#F97583\">||</span><span style=\"color:#E1E4E8\"> sock->closed) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EBADF;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (sock->mock_errno </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sock->mock_errno;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> available </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sock->buffer_size </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> sock->write_position;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> to_write </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (count </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> available) </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> count </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> available;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (to_write </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EAGAIN;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> -</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memcpy</span><span style=\"color:#E1E4E8\">(sock->buffer_data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> sock->write_position, buf, to_write);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sock->write_position </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> to_write;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> to_write;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> mock_socket_inject_data</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sock </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (sock </span><span style=\"color:#F97583\">&#x26;&#x26;</span><span style=\"color:#E1E4E8\"> sock->write_position </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> size </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> sock->buffer_size) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        memcpy</span><span style=\"color:#E1E4E8\">(sock->buffer_data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> sock->write_position, data, size);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sock->write_position </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> size;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> mock_socket_set_error</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> error_code</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sock </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (sock) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sock->mock_errno </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> error_code;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> mock_socket_close</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> fd</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    MockSocket</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> sock </span><span style=\"color:#F97583\">=</span><span style=\"color:#FFAB70\"> mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (sock) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        sock->closed </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(sock->buffer_data);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(sock);</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        mock_sockets</span><span style=\"color:#E1E4E8\">[fd </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Test HTTP Server (<code>tools/test_http_server.c</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdlib.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;string.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;unistd.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;sys/socket.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;netinet/in.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;signal.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Simple HTTP server for integration testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> port;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> delay_ms;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> response_body;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> custom_headers;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> should_fail;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} TestServerConfig;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> volatile</span><span style=\"color:#F97583\"> bool</span><span style=\"color:#E1E4E8\"> server_running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> signal_handler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> sig</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    server_running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Test server shutting down...</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> send_http_response</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> client_fd</span><span style=\"color:#E1E4E8\">, TestServerConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> response</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">4096</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> now </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (config->should_fail) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Simulate server error</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        close</span><span style=\"color:#E1E4E8\">(client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (config->delay_ms </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        usleep</span><span style=\"color:#E1E4E8\">(config->delay_ms </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    snprintf</span><span style=\"color:#E1E4E8\">(response, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(response),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"HTTP/1.1 200 OK</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"Content-Type: text/plain</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"Content-Length: </span><span style=\"color:#79B8FF\">%zu\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"Cache-Control: max-age=300</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"ETag: </span><span style=\"color:#79B8FF\">\\\"</span><span style=\"color:#9ECBFF\">test-etag-</span><span style=\"color:#79B8FF\">%ld\\\"\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        strlen</span><span style=\"color:#E1E4E8\">(config->response_body),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        now,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config->custom_headers </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> config->custom_headers </span><span style=\"color:#F97583\">:</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        config->response_body</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    );</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    send</span><span style=\"color:#E1E4E8\">(client_fd, response, </span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(response), </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(client_fd);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> argc</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char*</span><span style=\"color:#FFAB70\"> argv</span><span style=\"color:#F97583\">[]</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    TestServerConfig config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        .port </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 8080</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        .delay_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        .response_body </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Test server response\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        .custom_headers </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        .should_fail </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> false</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    };</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Parse command line arguments</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">int</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> argc; i</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#E1E4E8\">[i], </span><span style=\"color:#9ECBFF\">\"--port=\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            config.port </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> atoi</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 7</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#E1E4E8\">[i], </span><span style=\"color:#9ECBFF\">\"--delay=\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">8</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            config.delay_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> atoi</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#E1E4E8\">[i] </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">strncmp</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">argv</span><span style=\"color:#E1E4E8\">[i], </span><span style=\"color:#9ECBFF\">\"--fail\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            config.should_fail </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    signal</span><span style=\"color:#E1E4E8\">(SIGINT, signal_handler);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    signal</span><span style=\"color:#E1E4E8\">(SIGTERM, signal_handler);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> server_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> socket</span><span style=\"color:#E1E4E8\">(AF_INET, SOCK_STREAM, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> opt </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    setsockopt</span><span style=\"color:#E1E4E8\">(server_fd, SOL_SOCKET, SO_REUSEADDR, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">opt, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(opt));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> sockaddr_in address </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address.sin_family </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AF_INET;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address.sin_addr.s_addr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> INADDR_ANY;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    address.sin_port </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> htons</span><span style=\"color:#E1E4E8\">(config.port);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    bind</span><span style=\"color:#E1E4E8\">(server_fd, (</span><span style=\"color:#F97583\">struct</span><span style=\"color:#E1E4E8\"> sockaddr</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">address, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(address));</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    listen</span><span style=\"color:#E1E4E8\">(server_fd, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Test HTTP server listening on port </span><span style=\"color:#79B8FF\">%d\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, config.port);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    while</span><span style=\"color:#E1E4E8\"> (server_running) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        fd_set read_fds;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        FD_ZERO</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">read_fds);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        FD_SET</span><span style=\"color:#E1E4E8\">(server_fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">read_fds);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        struct</span><span style=\"color:#E1E4E8\"> timeval timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {.tv_sec </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, .tv_usec </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> activity </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> select</span><span style=\"color:#E1E4E8\">(server_fd </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">read_fds, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">timeout);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (activity </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> &#x26;&#x26;</span><span style=\"color:#B392F0\"> FD_ISSET</span><span style=\"color:#E1E4E8\">(server_fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">read_fds)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            int</span><span style=\"color:#E1E4E8\"> client_fd </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> accept</span><span style=\"color:#E1E4E8\">(server_fd, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (client_fd </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                char</span><span style=\"color:#FFAB70\"> buffer</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                recv</span><span style=\"color:#E1E4E8\">(client_fd, buffer, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(buffer), </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\"> // Read request</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">                send_http_response</span><span style=\"color:#E1E4E8\">(client_fd, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">config);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    close</span><span style=\"color:#E1E4E8\">(server_fd);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code:</strong></p>\n<p><strong>Unit Test Template (<code>test/unit/test_http_parser.c</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"http_parser.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"test_framework.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// HTTP Parser unit test template</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> test_http_parser_request_line_parsing</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create HttpParser instance using http_parser_create()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Prepare test input: \"GET /path HTTP/1.1\\r\\n\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Call http_parser_process() with test input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify parser state transitions to HTTP_PARSING_HEADERS</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Verify HttpRequest fields populated correctly (method, uri, version)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Clean up parser and request structures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use mock_socket_inject_data() for controlled input delivery</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> test_http_parser_chunked_encoding</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create parser and prepare chunked request body</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Process input incrementally: \"5\\r\\nhello\\r\\n0\\r\\n\\r\\n\"  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Verify state transitions: BODY -> CHUNKED_SIZE -> CHUNKED_DATA -> COMPLETE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify assembled body contains \"hello\" without chunk markers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Verify Content-Length calculation matches actual body</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Test partial delivery of chunk size and data separately</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> test_http_parser_malformed_input</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create parser and prepare invalid HTTP input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Test cases: invalid method, malformed headers, oversized requests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Verify parser transitions to HTTP_PARSING_ERROR state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify error handling doesn't crash or leak memory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Verify parser can be reset and reused after errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use valgrind to detect memory leaks in error paths</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    test_http_parser_request_line_parsing</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    test_http_parser_chunked_encoding</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    test_http_parser_malformed_input</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"HTTP Parser unit tests completed</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Integration Test Template (<code>test/integration/test_cache_integration.c</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"cache_engine.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"http_parser.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"test_framework.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Cache Engine integration test template</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> test_cache_conditional_request_generation</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create CacheEngine and populate with test response (with ETag)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create new HttpRequest for same resource after TTL expiry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Call cache_engine_lookup() and verify it returns stale entry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify cache_create_conditional() generates If-None-Match header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Simulate 304 Not Modified response from backend</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Verify cache_update_from_304() refreshes entry TTL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use mock time functions to control TTL calculations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> test_cache_vary_header_handling</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create responses with \"Vary: Accept-Encoding\" header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Store responses for same URL with different Accept-Encoding values</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Verify cache_generate_key() includes Accept-Encoding in key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify cache lookups return correct response for each encoding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Verify cache doesn't serve gzip response for non-gzip request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Test with \"gzip, deflate\" vs \"identity\" Accept-Encoding values</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> test_cache_size_limit_enforcement</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Create CacheEngine with small size limit (e.g., 1MB)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Store responses until cache size approaches limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Store additional response that exceeds limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Verify LRU eviction removes oldest entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Verify cache size stays within configured limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Verify evicted entries are completely cleaned up</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Monitor cache_engine_stats() for size and eviction metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">int</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    test_cache_conditional_request_generation</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    test_cache_vary_header_handling</span><span style=\"color:#E1E4E8\">(); </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    test_cache_size_limit_enforcement</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Cache Engine integration tests completed</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints:</strong></p>\n<p><strong>C Development Tips:</strong></p>\n<ul>\n<li>Use <code>valgrind --leak-check=full</code> to detect memory leaks in connection pooling</li>\n<li>Use <code>gdb</code> with breakpoints to debug state machine transitions</li>\n<li>Compile with <code>-fsanitize=address</code> to detect buffer overflows</li>\n<li>Use <code>strace</code> to monitor actual system calls during network testing</li>\n<li>Use <code>tcpdump</code> to capture real network traffic for integration verification</li>\n</ul>\n<p><strong>Mock Time Management:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Override system time functions for deterministic testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> time_t</span><span style=\"color:#E1E4E8\"> mock_current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1640995200</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // 2022-01-01 00:00:00</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">time_t</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">time_t*</span><span style=\"color:#FFAB70\"> tloc</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (tloc) </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">tloc </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mock_current_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> mock_current_time;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> advance_mock_time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">time_t</span><span style=\"color:#FFAB70\"> seconds</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mock_current_time </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> seconds;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Thread Safety Testing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Use pthread barriers to synchronize test threads</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">pthread_barrier_t</span><span style=\"color:#E1E4E8\"> test_barrier;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> setup_concurrent_test</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> thread_count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_barrier_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">test_barrier, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">, thread_count </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> wait_for_threads</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_barrier_wait</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">test_barrier);</span><span style=\"color:#6A737D\"> // All threads start simultaneously</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>F. Milestone Checkpoint Implementation:</strong></p>\n<p><strong>Milestone 1 Checkpoint Script (<code>test/scripts/milestone1_verification.sh</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">#!/bin/bash</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">set</span><span style=\"color:#79B8FF\"> -e</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"=== Milestone 1: HTTP Proxy Core Verification ===\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Start test backend</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./tools/test_http_server</span><span style=\"color:#79B8FF\"> --port=8080</span><span style=\"color:#E1E4E8\"> &#x26;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">BACKEND_PID</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">$!</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sleep</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Start proxy server</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">./reverse_proxy</span><span style=\"color:#79B8FF\"> --config=test/fixtures/milestone1.conf</span><span style=\"color:#E1E4E8\"> &#x26;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">PROXY_PID</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">$!</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sleep</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test basic request forwarding</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Testing basic request forwarding...\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">RESPONSE</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">$(</span><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -s</span><span style=\"color:#79B8FF\"> -o</span><span style=\"color:#9ECBFF\"> /dev/null</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> \"%{http_code}\"</span><span style=\"color:#9ECBFF\"> http://localhost:3128/test</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> [ </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">$RESPONSE</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#F97583\"> !=</span><span style=\"color:#9ECBFF\"> \"200\"</span><span style=\"color:#E1E4E8\"> ]; </span><span style=\"color:#F97583\">then</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    echo</span><span style=\"color:#9ECBFF\"> \"FAIL: Expected 200, got </span><span style=\"color:#E1E4E8\">$RESPONSE</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">fi</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test header preservation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Testing header preservation...\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#9ECBFF\"> \"X-Test-Header: test-value\"</span><span style=\"color:#9ECBFF\"> http://localhost:3128/headers</span><span style=\"color:#F97583\"> ></span><span style=\"color:#9ECBFF\"> /tmp/response.txt</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#F97583\"> !</span><span style=\"color:#B392F0\"> grep</span><span style=\"color:#79B8FF\"> -q</span><span style=\"color:#9ECBFF\"> \"X-Forwarded-For\"</span><span style=\"color:#9ECBFF\"> /tmp/response.txt</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#F97583\">then</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    echo</span><span style=\"color:#9ECBFF\"> \"FAIL: X-Forwarded-For header missing\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">fi</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test error handling</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"Testing error handling...\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">kill</span><span style=\"color:#E1E4E8\"> $BACKEND_PID</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">sleep</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">RESPONSE</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">$(</span><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -s</span><span style=\"color:#79B8FF\"> -o</span><span style=\"color:#9ECBFF\"> /dev/null</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> \"%{http_code}\"</span><span style=\"color:#9ECBFF\"> http://localhost:3128/test</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> [ </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">$RESPONSE</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#F97583\"> !=</span><span style=\"color:#9ECBFF\"> \"502\"</span><span style=\"color:#E1E4E8\"> ]; </span><span style=\"color:#F97583\">then</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    echo</span><span style=\"color:#9ECBFF\"> \"FAIL: Expected 502 Bad Gateway, got </span><span style=\"color:#E1E4E8\">$RESPONSE</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    exit</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">fi</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Cleanup</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">kill</span><span style=\"color:#E1E4E8\"> $PROXY_PID</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">echo</span><span style=\"color:#9ECBFF\"> \"SUCCESS: Milestone 1 verification passed\"</span></span></code></pre></div>\n\n<p><strong>G. Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Parser hangs on input</td>\n<td>Infinite loop in state machine</td>\n<td>Add debug prints in <code>http_parser_process</code></td>\n<td>Check state transition logic for missing break statements</td>\n</tr>\n<tr>\n<td>Connection pool exhaustion</td>\n<td>Connections not returned to pool</td>\n<td>Monitor pool metrics and connection lifecycle</td>\n<td>Ensure <code>connection_manager_release_backend</code> called</td>\n</tr>\n<tr>\n<td>Cache hit ratio is 0%</td>\n<td>Incorrect cache key generation</td>\n<td>Log cache keys for identical requests</td>\n<td>Verify <code>cache_generate_key</code> includes all relevant headers</td>\n</tr>\n<tr>\n<td>SSL handshake fails</td>\n<td>Certificate/key mismatch</td>\n<td>Check certificate with <code>openssl x509 -text</code></td>\n<td>Verify certificate and key correspond with <code>ssl_utils_verify_key_cert_match</code></td>\n</tr>\n<tr>\n<td>Memory usage grows continuously</td>\n<td>Resource leaks in error paths</td>\n<td>Run with valgrind during error injection</td>\n<td>Add proper cleanup in all error handling branches</td>\n</tr>\n<tr>\n<td>Backend health checks failing</td>\n<td>Network timing issues</td>\n<td>Monitor health check request/response timing</td>\n<td>Adjust health check timeout values in configuration</td>\n</tr>\n</tbody></table>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - comprehensive debugging knowledge is essential across HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).</p>\n</blockquote>\n<p>Think of debugging a reverse proxy like being a detective investigating a complex crime scene. Unlike debugging a simple application where problems typically have one cause, reverse proxy issues often involve multiple moving parts: network connections, protocol parsing, thread synchronization, and distributed systems interactions. Each component can fail in subtle ways that cascade through the system, creating symptoms that appear far from their root cause. A connection timeout might stem from DNS resolution issues, SSL handshake failures, backend overload, or even a subtle HTTP parser bug that corrupts request headers.</p>\n<p>The key insight for reverse proxy debugging is understanding the <strong>request lifecycle dependencies</strong>. Every HTTP request flows through multiple components in a specific sequence, and each component maintains state that can become corrupted. Unlike a stateless function where inputs directly map to outputs, reverse proxy debugging requires understanding how connection state, cache entries, SSL contexts, and load balancer statistics interact across multiple threads and connections.</p>\n<h3 id=\"common-bug-patterns\">Common Bug Patterns</h3>\n<p>This section catalogs the most frequently encountered issues when building reverse proxies, organized by component and symptom. Each pattern includes the observable behavior, underlying cause, diagnostic steps, and resolution strategy.</p>\n<h4 id=\"http-parser-component-issues\">HTTP Parser Component Issues</h4>\n<p><strong>⚠️ Pitfall: Partial Request Buffering</strong></p>\n<p>The HTTP parser receives data in chunks from TCP sockets, but HTTP requests don&#39;t always arrive as complete units. A common mistake is assuming <code>recv()</code> calls return complete HTTP messages, leading to parser failures when requests span multiple network packets.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Parser returns <code>HTTP_PARSING_ERROR</code> randomly</td>\n<td>Treating partial data as complete requests</td>\n<td>Log buffer contents before parsing, check if request headers end with <code>\\r\\n\\r\\n</code></td>\n<td>Implement proper buffering with <code>buffer_append()</code> until complete headers received</td>\n</tr>\n<tr>\n<td>Missing request headers</td>\n<td>Parser processes incomplete header section</td>\n<td>Monitor <code>buffer_length</code> vs expected header size</td>\n<td>Buffer data until double CRLF found before parsing</td>\n</tr>\n<tr>\n<td>Request body truncated</td>\n<td>Not handling <code>Content-Length</code> properly</td>\n<td>Compare bytes read vs <code>Content-Length</code> header value</td>\n<td>Continue reading until full body received based on <code>Content-Length</code></td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Key Insight</strong>: HTTP is a stream protocol delivered over TCP. The protocol boundaries (message start/end) don&#39;t align with TCP packet boundaries. Always buffer until you have a complete HTTP message unit.</p>\n</blockquote>\n<p><strong>⚠️ Pitfall: Chunked Transfer Encoding Bugs</strong></p>\n<p>Chunked transfer encoding allows HTTP bodies to be sent without knowing the total size upfront. Parsers must handle the chunk size parsing, data reading, and trailer processing correctly.</p>\n<table>\n<thead>\n<tr>\n<th>State Transition Error</th>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>HTTP_PARSING_CHUNKED_SIZE</code> → <code>HTTP_PARSING_ERROR</code></td>\n<td>Parser fails on chunk size line</td>\n<td>Not parsing hexadecimal chunk size correctly</td>\n<td>Use <code>strtol(chunk_line, NULL, 16)</code> for hex conversion</td>\n</tr>\n<tr>\n<td>Infinite loop in <code>HTTP_PARSING_CHUNKED_DATA</code></td>\n<td>Connection hangs reading chunk data</td>\n<td>Chunk size calculation error, reading wrong number of bytes</td>\n<td>Verify <code>bytes_remaining</code> matches parsed chunk size</td>\n</tr>\n<tr>\n<td>Missing final chunk</td>\n<td>Response appears truncated</td>\n<td>Not detecting zero-size final chunk <code>0\\r\\n\\r\\n</code></td>\n<td>Check for <code>chunk_size == 0</code> transition to <code>HTTP_PARSING_COMPLETE</code></td>\n</tr>\n</tbody></table>\n<p><strong>⚠️ Pitfall: Request Smuggling Vulnerabilities</strong></p>\n<p>Request smuggling occurs when the proxy and backend server disagree on request boundaries, typically due to inconsistent <code>Content-Length</code> and <code>Transfer-Encoding</code> header handling.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Example vulnerable request:\nPOST /api/data HTTP/1.1\nHost: example.com\nContent-Length: 44\nTransfer-Encoding: chunked\n\n5c\nPOST /admin/delete HTTP/1.1\nHost: example.com\nContent-Length: 15\n\nmalicious_data\n0</code></pre></div>\n\n<table>\n<thead>\n<tr>\n<th>Vulnerability Pattern</th>\n<th>Detection Method</th>\n<th>Prevention Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dual <code>Content-Length</code> headers</td>\n<td>Multiple <code>Content-Length</code> values in request</td>\n<td>Reject requests with multiple <code>Content-Length</code> headers</td>\n</tr>\n<tr>\n<td><code>Content-Length</code> + <code>Transfer-Encoding</code></td>\n<td>Both headers present simultaneously</td>\n<td>Prefer <code>Transfer-Encoding</code> when both present, or reject request</td>\n</tr>\n<tr>\n<td>Invalid chunk encoding</td>\n<td>Malformed chunk size or missing CRLF</td>\n<td>Strict chunk format validation before forwarding</td>\n</tr>\n</tbody></table>\n<h4 id=\"connection-manager-issues\">Connection Manager Issues</h4>\n<p><strong>⚠️ Pitfall: File Descriptor Exhaustion</strong></p>\n<p>The connection manager can exhaust system file descriptors if connections aren&#39;t properly closed or if the connection pool grows unbounded.</p>\n<table>\n<thead>\n<tr>\n<th>Resource Leak Pattern</th>\n<th>Symptom</th>\n<th>Detection Command</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Client connections not closed</td>\n<td><code>accept()</code> fails with <code>EMFILE</code></td>\n<td><code>lsof -p &lt;proxy_pid&gt; | wc -l</code></td>\n<td>Ensure <code>connection_manager_close_connection()</code> called on all error paths</td>\n</tr>\n<tr>\n<td>Backend pool connections accumulate</td>\n<td>Backend connection count grows continuously</td>\n<td>Monitor <code>ConnectionPool.idle_count</code> and <code>active_count</code></td>\n<td>Implement idle timeout cleanup in <code>timeout_processor()</code></td>\n</tr>\n<tr>\n<td>Epoll events not removed</td>\n<td><code>epoll_wait()</code> returns events for closed FDs</td>\n<td><code>strace -e epoll_ctl</code> to see unmatched additions/deletions</td>\n<td>Call <code>epoll_ctl(EPOLL_CTL_DEL)</code> before closing file descriptors</td>\n</tr>\n</tbody></table>\n<p><strong>⚠️ Pitfall: Connection State Race Conditions</strong></p>\n<p>Multiple threads can modify connection state simultaneously, leading to use-after-free bugs or double-close errors when proper synchronization is missing.</p>\n<table>\n<thead>\n<tr>\n<th>Race Condition</th>\n<th>Observable Behavior</th>\n<th>Root Cause</th>\n<th>Synchronization Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Double connection close</td>\n<td>Segmentation fault in <code>close()</code> or <code>free()</code></td>\n<td>Two threads call <code>connection_manager_close_connection()</code></td>\n<td>Use atomic compare-and-swap for connection state transitions</td>\n</tr>\n<tr>\n<td>Use-after-free on connection object</td>\n<td>Random crashes accessing connection fields</td>\n<td>Connection freed while another thread uses it</td>\n<td>Reference counting with atomic operations</td>\n</tr>\n<tr>\n<td>Backend selection vs connection close</td>\n<td>Wrong backend receives request</td>\n<td>Load balancer selects backend while connection manager closes it</td>\n<td>Hold backend reference with proper cleanup ordering</td>\n</tr>\n</tbody></table>\n<h4 id=\"load-balancer-issues\">Load Balancer Issues</h4>\n<p><strong>⚠️ Pitfall: Backend Health Check False Positives</strong></p>\n<p>Health checks might report backends as healthy when they&#39;re actually overloaded or partially failing, leading to request failures despite &quot;healthy&quot; status.</p>\n<table>\n<thead>\n<tr>\n<th>False Positive Pattern</th>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Improved Detection</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>TCP connect succeeds but HTTP fails</td>\n<td>Requests timeout despite healthy backends</td>\n<td>Health check only tests TCP connectivity</td>\n<td>Send actual HTTP request in <code>health_check_backend()</code></td>\n</tr>\n<tr>\n<td>Backend responds to health check but not requests</td>\n<td>Intermittent request failures</td>\n<td>Health check endpoint different from request handling</td>\n<td>Use same endpoint/port for health checks as real requests</td>\n</tr>\n<tr>\n<td>Health check too infrequent</td>\n<td>Failures detected after many requests fail</td>\n<td>Long intervals between health checks</td>\n<td>Reduce <code>health_check_interval</code> and implement passive failure detection</td>\n</tr>\n</tbody></table>\n<p><strong>⚠️ Pitfall: Load Balancer Algorithm Edge Cases</strong></p>\n<p>Load balancing algorithms can behave unexpectedly when backend weights change, connections finish, or servers are added/removed dynamically.</p>\n<table>\n<thead>\n<tr>\n<th>Algorithm Issue</th>\n<th>Unexpected Behavior</th>\n<th>Edge Case</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Round-robin index out of bounds</td>\n<td>Segmentation fault in backend selection</td>\n<td>Backend removed while <code>rr_current_index</code> points to it</td>\n<td>Reset index when backend array changes</td>\n</tr>\n<tr>\n<td>Weighted round-robin starvation</td>\n<td>Some backends never selected</td>\n<td>Weight calculation overflow or zero weights</td>\n<td>Normalize weights and handle zero-weight backends</td>\n</tr>\n<tr>\n<td>Least-connections stale data</td>\n<td>Requests sent to overloaded backends</td>\n<td>Connection counts not updated on failures</td>\n<td>Update counts immediately in error handlers</td>\n</tr>\n</tbody></table>\n<h4 id=\"cache-engine-issues\">Cache Engine Issues</h4>\n<p><strong>⚠️ Pitfall: Cache Coherence Problems</strong></p>\n<p>Cached responses can become stale or inconsistent when cache invalidation doesn&#39;t account for all scenarios where cached data should be purged.</p>\n<table>\n<thead>\n<tr>\n<th>Coherence Issue</th>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Invalidation Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Stale responses served after backend update</td>\n<td>Clients see old data after server changes</td>\n<td>TTL too long or no invalidation on errors</td>\n<td>Invalidate cache entries on 5xx responses from backend</td>\n</tr>\n<tr>\n<td>Cache poisoning with error responses</td>\n<td>404 or 500 responses cached and served repeatedly</td>\n<td>Caching non-cacheable responses</td>\n<td>Check <code>cache_is_cacheable()</code> includes status code validation</td>\n</tr>\n<tr>\n<td>Vary header ignored in cache key</td>\n<td>Wrong cached response for different request variants</td>\n<td>Cache key doesn&#39;t include <code>Vary</code> header fields</td>\n<td>Include <code>Vary</code> header values in <code>cache_generate_key()</code></td>\n</tr>\n</tbody></table>\n<p><strong>⚠️ Pitfall: Cache Memory Management</strong></p>\n<p>Cache engines can consume unbounded memory if eviction policies don&#39;t work correctly or if large responses are cached without size limits.</p>\n<table>\n<thead>\n<tr>\n<th>Memory Issue</th>\n<th>Observable Behavior</th>\n<th>Monitoring Metric</th>\n<th>Memory Control</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache size grows beyond limit</td>\n<td>Proxy memory usage increases continuously</td>\n<td>Monitor <code>CacheEngine.size_current</code> vs <code>size_limit</code></td>\n<td>Implement LRU eviction in <code>cache_engine_store()</code></td>\n</tr>\n<tr>\n<td>Large response caching</td>\n<td>Single large file consumes entire cache</td>\n<td>Track individual entry size in <code>CacheEntry.entry_size</code></td>\n<td>Reject responses larger than percentage of cache limit</td>\n</tr>\n<tr>\n<td>Cache fragmentation</td>\n<td>Available cache space but unable to store entries</td>\n<td>Monitor successful vs failed cache storage attempts</td>\n<td>Implement cache compaction or use memory pools</td>\n</tr>\n</tbody></table>\n<h4 id=\"ssl-termination-issues\">SSL Termination Issues</h4>\n<p><strong>⚠️ Pitfall: Certificate Validation and SNI Problems</strong></p>\n<p>SSL termination can fail silently or present wrong certificates when Server Name Indication (SNI) handling or certificate loading has bugs.</p>\n<table>\n<thead>\n<tr>\n<th>SSL Issue</th>\n<th>Client Observable Behavior</th>\n<th>Server-Side Symptom</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Wrong certificate served</td>\n<td>Browser certificate warning for different domain</td>\n<td>SNI callback not triggered or incorrect context selection</td>\n<td>Verify <code>ssl_termination_sni_callback()</code> hostname matching</td>\n</tr>\n<tr>\n<td>Certificate chain incomplete</td>\n<td>SSL handshake fails with &quot;unknown CA&quot;</td>\n<td>Missing intermediate certificates</td>\n<td>Load full certificate chain in <code>ssl_utils_load_certificate()</code></td>\n</tr>\n<tr>\n<td>Private key mismatch</td>\n<td>SSL handshake fails with &quot;bad certificate&quot;</td>\n<td>Certificate and key don&#39;t correspond</td>\n<td>Use <code>ssl_utils_verify_key_cert_match()</code> during loading</td>\n</tr>\n</tbody></table>\n<p><strong>⚠️ Pitfall: TLS Performance and Security Issues</strong></p>\n<p>SSL termination performance can degrade due to poor cipher selection, missing session resumption, or inefficient TLS context management.</p>\n<table>\n<thead>\n<tr>\n<th>Performance Issue</th>\n<th>Observable Metric</th>\n<th>Root Cause</th>\n<th>Optimization</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>High SSL handshake latency</td>\n<td>Increased connection establishment time</td>\n<td>Weak key exchange algorithms</td>\n<td>Configure ECDHE ciphers in <code>ssl_utils_set_secure_ciphers()</code></td>\n</tr>\n<tr>\n<td>Excessive CPU usage for SSL</td>\n<td>High CPU utilization on SSL threads</td>\n<td>No session resumption, repeated full handshakes</td>\n<td>Enable TLS session tickets and caching</td>\n</tr>\n<tr>\n<td>Memory usage grows with connections</td>\n<td>SSL context memory increases</td>\n<td>Creating new SSL_CTX per connection instead of reusing</td>\n<td>Share SSL contexts across connections for same domain</td>\n</tr>\n</tbody></table>\n<h3 id=\"debugging-techniques-and-tools\">Debugging Techniques and Tools</h3>\n<p>This section provides systematic approaches for diagnosing reverse proxy issues, from initial symptom observation through root cause identification to verification of fixes.</p>\n<h4 id=\"systematic-debugging-approach\">Systematic Debugging Approach</h4>\n<p><strong>Mental Model: The Debugging Funnel</strong></p>\n<p>Think of reverse proxy debugging like a medical diagnosis process. Start with observable symptoms (the patient&#39;s complaints), gather more data through systematic observation (vital signs and tests), form hypotheses about root causes (differential diagnosis), test hypotheses with targeted experiments (specific tests), and verify the cure works (follow-up monitoring). Each step narrows down the possible causes until you isolate the specific problem.</p>\n<p>The key insight is that reverse proxy bugs often manifest far from their source. A client timeout might be caused by DNS resolution delays, SSL handshake failures, backend overload, cache corruption, or thread synchronization bugs. The debugging process must systematically eliminate possibilities rather than jumping to conclusions based on surface symptoms.</p>\n<h4 id=\"diagnostic-data-collection\">Diagnostic Data Collection</h4>\n<p>Before attempting to fix any issue, establish comprehensive visibility into proxy operation. This involves capturing data at multiple layers of the system.</p>\n<p><strong>Connection-Level Diagnostics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Data Point</th>\n<th>Collection Method</th>\n<th>Information Revealed</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Active connection count</td>\n<td>Monitor <code>ConnectionManager</code> statistics</td>\n<td>Whether issue is connection exhaustion</td>\n</tr>\n<tr>\n<td>Connection state distribution</td>\n<td>Count connections in each <code>ConnectionState</code></td>\n<td>Which processing stage has bottlenecks</td>\n</tr>\n<tr>\n<td>Connection duration histogram</td>\n<td>Track time from creation to closure</td>\n<td>Whether connections are hanging</td>\n</tr>\n<tr>\n<td>Bytes transferred per connection</td>\n<td>Sum <code>bytes_read</code> and <code>bytes_written</code></td>\n<td>Whether transfers are completing</td>\n</tr>\n<tr>\n<td>Backend connection pool utilization</td>\n<td>Monitor <code>ConnectionPool.idle_count</code> vs <code>max_connections</code></td>\n<td>Whether backend pooling is effective</td>\n</tr>\n</tbody></table>\n<p><strong>Request-Level Diagnostics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Diagnostic Technique</th>\n<th>Implementation</th>\n<th>Troubleshooting Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request ID tracing</td>\n<td>Generate unique ID per request, log in all components</td>\n<td>Follow request flow across components</td>\n</tr>\n<tr>\n<td>Timing breakdown</td>\n<td>Measure time in each processing stage</td>\n<td>Identify bottleneck components</td>\n</tr>\n<tr>\n<td>Header inspection</td>\n<td>Log all request/response headers</td>\n<td>Debug protocol-level issues</td>\n</tr>\n<tr>\n<td>Cache hit/miss tracking</td>\n<td>Log cache decisions with reasons</td>\n<td>Understand cache effectiveness</td>\n</tr>\n<tr>\n<td>Backend selection logging</td>\n<td>Log load balancer decisions</td>\n<td>Debug routing issues</td>\n</tr>\n</tbody></table>\n<h4 id=\"component-specific-debugging-tools\">Component-Specific Debugging Tools</h4>\n<p><strong>HTTP Parser Debugging</strong></p>\n<p>When HTTP parser issues occur, the key is understanding exactly what data the parser received and how it interpreted the protocol boundaries.</p>\n<table>\n<thead>\n<tr>\n<th>Parser Issue</th>\n<th>Debug Data to Collect</th>\n<th>Analysis Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Parse failures</td>\n<td>Raw buffer contents before parsing</td>\n<td>Check for valid HTTP format, protocol violations</td>\n</tr>\n<tr>\n<td>Incomplete requests</td>\n<td>Buffer state at each <code>http_parser_process()</code> call</td>\n<td>Verify incremental parsing state machine</td>\n</tr>\n<tr>\n<td>Header corruption</td>\n<td>Header hash table contents after parsing</td>\n<td>Compare parsed values with raw buffer</td>\n</tr>\n<tr>\n<td>Body length errors</td>\n<td><code>Content-Length</code> vs actual body bytes received</td>\n<td>Check for chunked encoding vs fixed length</td>\n</tr>\n</tbody></table>\n<p><strong>Load Balancer Debugging</strong></p>\n<p>Load balancer issues require understanding the decision-making process and backend server state over time.</p>\n<table>\n<thead>\n<tr>\n<th>Debug Data Collection</th>\n<th>Purpose</th>\n<th>Implementation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Backend selection history</td>\n<td>Track which backend chosen for each request</td>\n<td>Log backend ID and selection algorithm result</td>\n</tr>\n<tr>\n<td>Health check timeline</td>\n<td>Record all health check attempts and results</td>\n<td>Log successful/failed checks with timestamps</td>\n</tr>\n<tr>\n<td>Connection count tracking</td>\n<td>Monitor active connections per backend</td>\n<td>Sample connection counts periodically</td>\n</tr>\n<tr>\n<td>Weight adjustment history</td>\n<td>Track dynamic weight changes</td>\n<td>Log weight updates with reasons</td>\n</tr>\n</tbody></table>\n<p><strong>Cache Engine Debugging</strong></p>\n<p>Cache-related issues often involve understanding why specific entries were or weren&#39;t cached, and how cache invalidation decisions were made.</p>\n<table>\n<thead>\n<tr>\n<th>Cache Debug Information</th>\n<th>Collection Method</th>\n<th>Analysis Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cache key generation</td>\n<td>Log keys generated for each request</td>\n<td>Debug cache miss issues</td>\n</tr>\n<tr>\n<td>Cache-Control parsing</td>\n<td>Log parsed cache directives</td>\n<td>Understand caching decisions</td>\n</tr>\n<tr>\n<td>TTL calculations</td>\n<td>Log computed expiration times</td>\n<td>Debug premature or delayed expiration</td>\n</tr>\n<tr>\n<td>Eviction decisions</td>\n<td>Log LRU operations and size-based evictions</td>\n<td>Understand cache memory management</td>\n</tr>\n<tr>\n<td>Cache hit/miss reasons</td>\n<td>Log why each lookup succeeded or failed</td>\n<td>Optimize cache effectiveness</td>\n</tr>\n</tbody></table>\n<h4 id=\"memory-and-resource-leak-detection\">Memory and Resource Leak Detection</h4>\n<p>Reverse proxies are long-running servers that must manage resources carefully to avoid gradual degradation.</p>\n<p><strong>Memory Leak Detection Strategy</strong></p>\n<table>\n<thead>\n<tr>\n<th>Detection Method</th>\n<th>Tool/Technique</th>\n<th>What It Reveals</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Process memory monitoring</td>\n<td>Track RSS/VSZ over time with <code>ps</code> or <code>/proc/pid/status</code></td>\n<td>Overall memory growth trends</td>\n</tr>\n<tr>\n<td>Allocation tracking</td>\n<td>Use Valgrind or AddressSanitizer</td>\n<td>Specific allocation sites that aren&#39;t freed</td>\n</tr>\n<tr>\n<td>Connection object counting</td>\n<td>Monitor <code>ConnectionManager</code> object counts</td>\n<td>Whether connections are accumulating</td>\n</tr>\n<tr>\n<td>Cache size monitoring</td>\n<td>Track <code>CacheEngine.size_current</code> over time</td>\n<td>Whether cache eviction is working</td>\n</tr>\n<tr>\n<td>SSL context counting</td>\n<td>Count SSL contexts in <code>SSLTermination</code></td>\n<td>Whether TLS contexts are leaking</td>\n</tr>\n</tbody></table>\n<p><strong>File Descriptor Leak Detection</strong></p>\n<table>\n<thead>\n<tr>\n<th>Resource Type</th>\n<th>Monitoring Command</th>\n<th>Normal vs Leak Pattern</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Socket file descriptors</td>\n<td><code>lsof -p &lt;pid&gt; -a -i</code></td>\n<td>Should correlate with active connections</td>\n</tr>\n<tr>\n<td>Regular file descriptors</td>\n<td><code>lsof -p &lt;pid&gt; -a -f -- /</code></td>\n<td>Should remain constant for config/log files</td>\n</tr>\n<tr>\n<td>Pipe/eventfd descriptors</td>\n<td><code>lsof -p &lt;pid&gt; -a -t REG</code></td>\n<td>Should match thread communication channels</td>\n</tr>\n<tr>\n<td>Total FD count</td>\n<td><code>ls /proc/&lt;pid&gt;/fd | wc -l</code></td>\n<td>Should stay within reasonable bounds</td>\n</tr>\n</tbody></table>\n<h4 id=\"network-level-debugging\">Network-Level Debugging</h4>\n<p>Since reverse proxies are network intermediaries, network-level debugging provides critical visibility into connection establishment, data transfer, and protocol interactions.</p>\n<p><strong>Traffic Analysis Techniques</strong></p>\n<table>\n<thead>\n<tr>\n<th>Analysis Level</th>\n<th>Tool</th>\n<th>Information Provided</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Packet capture</td>\n<td><code>tcpdump -i any -w proxy-traffic.pcap</code></td>\n<td>Raw network data for protocol analysis</td>\n</tr>\n<tr>\n<td>Connection tracking</td>\n<td><code>ss -tupln</code> and <code>netstat -an</code></td>\n<td>Current socket states and listen ports</td>\n</tr>\n<tr>\n<td>Traffic statistics</td>\n<td><code>iftop</code> or <code>nethogs</code></td>\n<td>Bandwidth utilization per connection</td>\n</tr>\n<tr>\n<td>DNS resolution</td>\n<td><code>dig</code> and <code>nslookup</code> for backend hostnames</td>\n<td>DNS resolution delays or failures</td>\n</tr>\n</tbody></table>\n<p><strong>SSL/TLS Debugging</strong></p>\n<p>TLS issues require specialized analysis tools since the traffic is encrypted and handshake failures can have many causes.</p>\n<table>\n<thead>\n<tr>\n<th>TLS Debug Technique</th>\n<th>Command/Tool</th>\n<th>Diagnostic Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Handshake analysis</td>\n<td><code>openssl s_client -connect proxy:443 -debug</code></td>\n<td>Step-by-step handshake progression</td>\n</tr>\n<tr>\n<td>Certificate validation</td>\n<td><code>openssl verify -CApath /etc/ssl/certs cert.pem</code></td>\n<td>Certificate chain validation issues</td>\n</tr>\n<tr>\n<td>Cipher negotiation</td>\n<td><code>nmap --script ssl-enum-ciphers -p 443 proxy</code></td>\n<td>Available cipher suites</td>\n</tr>\n<tr>\n<td>SNI testing</td>\n<td><code>openssl s_client -servername domain.com -connect proxy:443</code></td>\n<td>SNI hostname handling</td>\n</tr>\n</tbody></table>\n<h4 id=\"performance-profiling-and-bottleneck-analysis\">Performance Profiling and Bottleneck Analysis</h4>\n<p>Performance issues in reverse proxies often involve identifying which component or operation is the limiting factor under load.</p>\n<p><strong>CPU Profiling Strategy</strong></p>\n<table>\n<thead>\n<tr>\n<th>Profiling Target</th>\n<th>Tool/Method</th>\n<th>Analysis Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Function-level CPU usage</td>\n<td><code>perf record -g</code> + <code>perf report</code></td>\n<td>Which functions consume most CPU time</td>\n</tr>\n<tr>\n<td>Lock contention</td>\n<td><code>perf lock record</code> + <code>perf lock report</code></td>\n<td>Mutex/rwlock blocking behavior</td>\n</tr>\n<tr>\n<td>System call overhead</td>\n<td><code>strace -c -p &lt;pid&gt;</code></td>\n<td>System call frequency and timing</td>\n</tr>\n<tr>\n<td>Thread activity</td>\n<td><code>htop</code> with thread view</td>\n<td>Per-thread CPU utilization</td>\n</tr>\n</tbody></table>\n<p><strong>I/O Performance Analysis</strong></p>\n<table>\n<thead>\n<tr>\n<th>I/O Pattern</th>\n<th>Monitoring Method</th>\n<th>Performance Implications</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Socket read/write efficiency</td>\n<td>Monitor <code>EAGAIN</code> frequency in logs</td>\n<td>Whether non-blocking I/O is optimal</td>\n</tr>\n<tr>\n<td>Disk I/O for caching</td>\n<td><code>iostat</code> to monitor disk utilization</td>\n<td>Whether cache storage is bottleneck</td>\n</tr>\n<tr>\n<td>DNS resolution performance</td>\n<td>Time DNS lookups with <code>dig</code></td>\n<td>Whether backend resolution is slow</td>\n</tr>\n<tr>\n<td>Backend response times</td>\n<td>Log request duration per backend</td>\n<td>Whether specific backends are slow</td>\n</tr>\n</tbody></table>\n<h4 id=\"systematic-root-cause-analysis\">Systematic Root Cause Analysis</h4>\n<p>When debugging complex issues, use a systematic approach to avoid missing important causes or making incorrect assumptions.</p>\n<p><strong>The Five Whys Technique for Reverse Proxy Issues</strong></p>\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Question</th>\n<th>Example Analysis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1st Why</td>\n<td>Why is the symptom occurring?</td>\n<td>&quot;Clients are getting 503 errors&quot;</td>\n</tr>\n<tr>\n<td>2nd Why</td>\n<td>Why is that immediate cause happening?</td>\n<td>&quot;Load balancer returns no healthy backends&quot;</td>\n</tr>\n<tr>\n<td>3rd Why</td>\n<td>Why is that deeper cause happening?</td>\n<td>&quot;Health checks are failing for all backends&quot;</td>\n</tr>\n<tr>\n<td>4th Why</td>\n<td>Why is that root cause occurring?</td>\n<td>&quot;Health check timeout is too short&quot;</td>\n</tr>\n<tr>\n<td>5th Why</td>\n<td>Why was that configuration chosen?</td>\n<td>&quot;Default timeout not adjusted for network latency&quot;</td>\n</tr>\n</tbody></table>\n<p><strong>Hypothesis Testing Framework</strong></p>\n<p>For each suspected root cause, design specific tests that can confirm or refute the hypothesis.</p>\n<table>\n<thead>\n<tr>\n<th>Hypothesis</th>\n<th>Test Design</th>\n<th>Expected Result if Correct</th>\n<th>Expected Result if Incorrect</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&quot;Backend overload causing timeouts&quot;</td>\n<td>Send requests directly to backend, bypassing proxy</td>\n<td>Direct requests also timeout</td>\n<td>Direct requests succeed</td>\n</tr>\n<tr>\n<td>&quot;SSL handshake failures&quot;</td>\n<td>Test same domain with HTTP vs HTTPS</td>\n<td>HTTPS fails, HTTP succeeds</td>\n<td>Both fail or both succeed</td>\n</tr>\n<tr>\n<td>&quot;Cache serving stale data&quot;</td>\n<td>Send cache-busting headers (<code>Cache-Control: no-cache</code>)</td>\n<td>Fresh data returned</td>\n<td>Same stale data returned</td>\n</tr>\n<tr>\n<td>&quot;Load balancer algorithm bug&quot;</td>\n<td>Manually specify backend in request</td>\n<td>Specified backend works</td>\n<td>All backends fail</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Debugging Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logging Framework</td>\n<td><code>fprintf(stderr, ...)</code> with timestamp</td>\n<td>Structured logging with log levels and rotation</td>\n</tr>\n<tr>\n<td>Memory Debugging</td>\n<td>Valgrind memcheck</td>\n<td>AddressSanitizer with custom allocator</td>\n</tr>\n<tr>\n<td>Network Analysis</td>\n<td>tcpdump + Wireshark</td>\n<td>Custom packet capture with libpcap</td>\n</tr>\n<tr>\n<td>Performance Profiling</td>\n<td>gprof with <code>-pg</code> compilation</td>\n<td>perf with flamegraph visualization</td>\n</tr>\n<tr>\n<td>Configuration Debugging</td>\n<td>Static config file parsing</td>\n<td>Dynamic config reload with validation</td>\n</tr>\n</tbody></table>\n<h4 id=\"debugging-infrastructure-code\">Debugging Infrastructure Code</h4>\n<p><strong>Complete Logging System Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// logger.h</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdio.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;time.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdarg.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;pthread.h></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_DEBUG </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_INFO </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_WARN </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LOG_ERROR </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LogLevel;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LogLevel min_level;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    FILE</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> output_file;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> log_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> include_thread_id;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> include_component;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} Logger;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize logging system with specified minimum level and output file</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> logger_init</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">min_level</span><span style=\"color:#E1E4E8\">, FILE</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> output</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Log formatted message with component, file, and line information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_log</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> line</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> format</span><span style=\"color:#E1E4E8\">, ...);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Specialized logging macros for convenience</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_DEBUG_MSG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_DEBUG, component, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_INFO_MSG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_INFO, component, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_WARN_MSG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_WARN, component, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#define</span><span style=\"color:#B392F0\"> LOG_ERROR_MSG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">component</span><span style=\"color:#E1E4E8\">, ...) </span><span style=\"color:#B392F0\">logger_log</span><span style=\"color:#E1E4E8\">(LOG_ERROR, component, </span><span style=\"color:#B392F0\">__LINE__</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#B392F0\">__VA_ARGS__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// logger.c</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#E1E4E8\"> Logger g_logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> logger_init</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">min_level</span><span style=\"color:#E1E4E8\">, FILE</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> output</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    g_logger.min_level </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> min_level;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    g_logger.output_file </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> output </span><span style=\"color:#F97583\">?</span><span style=\"color:#E1E4E8\"> output </span><span style=\"color:#F97583\">:</span><span style=\"color:#E1E4E8\"> stderr;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    g_logger.include_thread_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    g_logger.include_component </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">pthread_mutex_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">g_logger.log_mutex, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> false</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> logger_log</span><span style=\"color:#E1E4E8\">(LogLevel </span><span style=\"color:#FFAB70\">level</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> component</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">int</span><span style=\"color:#FFAB70\"> line</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> format</span><span style=\"color:#E1E4E8\">, ...) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (level </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> g_logger.min_level) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_lock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">g_logger.log_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Generate timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> now </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> time</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    struct</span><span style=\"color:#E1E4E8\"> tm</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> local_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> localtime</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">now);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> timestamp</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    strftime</span><span style=\"color:#E1E4E8\">(timestamp, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(timestamp), </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#FDAEB7;font-style:italic\">%</span><span style=\"color:#9ECBFF\">Y-</span><span style=\"color:#FDAEB7;font-style:italic\">%</span><span style=\"color:#9ECBFF\">m-</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#FDAEB7;font-style:italic\"> %</span><span style=\"color:#9ECBFF\">H:</span><span style=\"color:#FDAEB7;font-style:italic\">%</span><span style=\"color:#9ECBFF\">M:</span><span style=\"color:#79B8FF\">%S</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, local_time);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Get thread ID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> thread_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> pthread_self</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Format level string</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#E1E4E8\"> level_strings</span><span style=\"color:#F97583\">[]</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"DEBUG\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"INFO\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"WARN\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"ERROR\"</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Print log prefix</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    fprintf</span><span style=\"color:#E1E4E8\">(g_logger.output_file, </span><span style=\"color:#9ECBFF\">\"[</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">] [</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">] [</span><span style=\"color:#79B8FF\">%lu</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">:</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">] \"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            timestamp, </span><span style=\"color:#FFAB70\">level_strings</span><span style=\"color:#E1E4E8\">[level], (</span><span style=\"color:#F97583\">unsigned</span><span style=\"color:#F97583\"> long</span><span style=\"color:#E1E4E8\">)thread_id, component, line);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Print actual message</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    va_list args;</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    va_start</span><span style=\"color:#E1E4E8\">(args, format);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    vfprintf</span><span style=\"color:#E1E4E8\">(g_logger.output_file, format, args);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    va_end</span><span style=\"color:#E1E4E8\">(args);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    fprintf</span><span style=\"color:#E1E4E8\">(g_logger.output_file, </span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    fflush</span><span style=\"color:#E1E4E8\">(g_logger.output_file);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_unlock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">g_logger.log_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Complete Error Context Tracking:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// error_handler.h</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"logger.h\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> \"proxy_types.h\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_NONE </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_PARSE_FAILED </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_BACKEND_UNAVAILABLE </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_BACKEND_TIMEOUT </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CACHE_FAILURE </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_SSL_HANDSHAKE_FAILED </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CLIENT_DISCONNECTED </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 6</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_MEMORY_ALLOCATION </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 7</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CONNECTION_LIMIT </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    PROXY_ERROR_CONFIG_INVALID </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 9</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ProxyErrorCode;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyErrorCode code;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> message</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> component</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> timestamp;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> request_id;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> failed_connection;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> failed_backend;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> thread_id;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> system_errno;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ErrorContext;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorContext </span><span style=\"color:#FFAB70\">errors</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> error_count;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> error_capacity;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_mutex_t</span><span style=\"color:#E1E4E8\"> error_mutex;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> recovery_thread;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> running;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ErrorHandler;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize centralized error handling system</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> error_handler_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Report error to central handler for recovery coordination</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> error_handler_report</span><span style=\"color:#E1E4E8\">(ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> handler</span><span style=\"color:#E1E4E8\">, ErrorContext</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> context</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Generate sanitized error responses for clients</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> generate_client_error_response</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">code</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> details</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// error_handler.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> error_handler_create</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> handler </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> malloc</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(ErrorHandler));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">handler) </span><span style=\"color:#F97583\">return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    memset</span><span style=\"color:#E1E4E8\">(handler, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(ErrorHandler));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    handler->error_capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">pthread_mutex_init</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">handler->error_mutex, </span><span style=\"color:#79B8FF\">NULL</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        free</span><span style=\"color:#E1E4E8\">(handler);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> NULL</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    handler->running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> true</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> handler;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> error_handler_report</span><span style=\"color:#E1E4E8\">(ErrorHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> handler</span><span style=\"color:#E1E4E8\">, ErrorContext</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> context</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">handler </span><span style=\"color:#F97583\">||</span><span style=\"color:#F97583\"> !</span><span style=\"color:#E1E4E8\">context) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_lock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">handler->error_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (handler->error_count </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> handler->error_capacity) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Store error context</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        memcpy</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">handler->errors[handler->error_count], context, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(ErrorContext));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        handler->error_count</span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Log error with full context</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        LOG_ERROR_MSG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"error_handler\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                      \"Error </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\"> in </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\"> (request_id=</span><span style=\"color:#79B8FF\">%lu</span><span style=\"color:#9ECBFF\">, connection=</span><span style=\"color:#79B8FF\">%p</span><span style=\"color:#9ECBFF\">, backend=</span><span style=\"color:#79B8FF\">%p</span><span style=\"color:#9ECBFF\">, errno=</span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      context->code, context->component, context->message,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      context->request_id, context->failed_connection, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      context->failed_backend, context->system_errno);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    pthread_mutex_unlock</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">handler->error_mutex);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> generate_client_error_response</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, ProxyErrorCode </span><span style=\"color:#FFAB70\">code</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> details</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">conn) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Generate appropriate HTTP error response</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#E1E4E8\"> status_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Internal Server Error\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 500</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    switch</span><span style=\"color:#E1E4E8\"> (code) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_UNAVAILABLE:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 503</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Service Unavailable\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_BACKEND_TIMEOUT:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 504</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Gateway Timeout\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_PARSE_FAILED:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 400</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Bad Request\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        case</span><span style=\"color:#E1E4E8\"> PROXY_ERROR_SSL_HANDSHAKE_FAILED:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 400</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Bad Request\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        default</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            break</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Sanitize details - never expose internal information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#E1E4E8\"> safe_details </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"The server encountered an error processing your request.\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> response</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    snprintf</span><span style=\"color:#E1E4E8\">(response, </span><span style=\"color:#F97583\">sizeof</span><span style=\"color:#E1E4E8\">(response),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">             \"HTTP/1.1 </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#79B8FF\"> %s\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">             \"Content-Type: text/plain</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">             \"Content-Length: </span><span style=\"color:#79B8FF\">%zu\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">             \"Connection: close</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">             \"</span><span style=\"color:#79B8FF\">\\r\\n</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">             \"</span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">             status_code, status_text, </span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(safe_details), safe_details);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Send error response to client</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    send</span><span style=\"color:#E1E4E8\">(conn->client_fd, response, </span><span style=\"color:#B392F0\">strlen</span><span style=\"color:#E1E4E8\">(response), </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    LOG_INFO_MSG</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"error_response\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Sent </span><span style=\"color:#79B8FF\">%d</span><span style=\"color:#79B8FF\"> %s</span><span style=\"color:#9ECBFF\"> to client (error: </span><span style=\"color:#79B8FF\">%s</span><span style=\"color:#9ECBFF\">)\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 status_code, status_text, details);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"core-logic-debugging-skeletons\">Core Logic Debugging Skeletons</h4>\n<p><strong>Request Tracing Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// request_tracer.h</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint64_t</span><span style=\"color:#E1E4E8\"> request_id;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> client_ip</span><span style=\"color:#E1E4E8\">[INET_ADDRSTRLEN];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> method</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> uri</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">512</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> start_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> parse_complete_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> backend_selected_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> cache_lookup_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> backend_request_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> response_complete_time;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> selected_backend;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> cache_hit;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ProxyErrorCode error_code;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} RequestTrace;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">RequestTrace</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> request_trace_create</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, HttpRequest</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> request</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Allocate RequestTrace structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Generate unique request ID using atomic counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Extract client IP from connection socket address</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Copy HTTP method and URI from request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Set start_time to current timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Initialize timing fields to 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 7: Initialize error_code to PROXY_ERROR_NONE</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 8: Log request start with all initial context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> request_trace_mark_milestone</span><span style=\"color:#E1E4E8\">(RequestTrace</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> trace</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> milestone</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Get current timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Set appropriate timing field based on milestone string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Log milestone reached with elapsed time since start</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If this is an error milestone, set error_code appropriately</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> request_trace_complete</span><span style=\"color:#E1E4E8\">(RequestTrace</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> trace</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Set response_complete_time to current timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Calculate total request duration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Log complete request summary with all timing breakdowns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Log backend selection, cache hit status, and any errors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Free RequestTrace structure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Connection State Debugging:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// connection_debug.h</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> connection;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionState previous_state;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ConnectionState current_state;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    time_t</span><span style=\"color:#E1E4E8\"> transition_time;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#E1E4E8\"> transition_reason;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> bytes_processed;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> system_error;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ConnectionStateTrace;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> debug_log_connection_state_change</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">, ConnectionState </span><span style=\"color:#FFAB70\">new_state</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                      const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> reason</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Check if connection state actually changed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Create ConnectionStateTrace with previous and new states</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Log state transition with timing and reason</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: If transitioning to error state, log additional context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Update connection's last_activity timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 6: Store trace in connection debugging history</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> debug_dump_connection_state</span><span style=\"color:#E1E4E8\">(Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> conn</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 1: Log current connection state and timing information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 2: Log buffer states (request_buffer and response_buffer positions)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 3: Log backend server information if connected</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 4: Log any pending timeout information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO 5: Log recent state transition history</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Debugging Verification:</strong></p>\n<p>After implementing basic HTTP proxy functionality, verify debugging capabilities:</p>\n<ol>\n<li><p><strong>Start proxy with debug logging enabled</strong>: <code>./proxy --log-level=DEBUG --log-file=debug.log</code></p>\n</li>\n<li><p><strong>Send malformed HTTP request</strong> to test parser error handling:</p>\n</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#79B8FF\">   echo</span><span style=\"color:#79B8FF\"> -e</span><span style=\"color:#9ECBFF\"> \"GET /test HTTP/1.1\\r\\nInvalid-Header-Missing-Colon\\r\\n\\r\\n\"</span><span style=\"color:#F97583\"> |</span><span style=\"color:#B392F0\"> nc</span><span style=\"color:#9ECBFF\"> localhost</span><span style=\"color:#79B8FF\"> 8080</span></span></code></pre></div>\n<p>   Expected: Parser error logged with specific buffer contents and error reason.</p>\n<ol start=\"3\">\n<li><strong>Monitor connection state transitions</strong> with legitimate request:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   curl</span><span style=\"color:#79B8FF\"> -v</span><span style=\"color:#9ECBFF\"> http://localhost:8080/test</span></span></code></pre></div>\n<p>   Expected: State transitions logged from <code>CONNECTION_IDLE</code> → <code>CONNECTION_READING_REQUEST</code> → <code>CONNECTION_FORWARDING</code> → etc.</p>\n<ol start=\"4\">\n<li><strong>Verify error response generation</strong> when backend unavailable:<ul>\n<li>Stop backend server</li>\n<li>Send request through proxy</li>\n<li>Expected: 503 Service Unavailable response with sanitized error message</li>\n</ul>\n</li>\n</ol>\n<p><strong>Milestone 2 Load Balancer Debugging:</strong></p>\n<ol>\n<li><strong>Test backend selection logging</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">   # Send multiple requests and verify round-robin distribution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">   for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#B392F0\">1..10}</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#F97583\">do</span><span style=\"color:#B392F0\"> curl</span><span style=\"color:#9ECBFF\"> http://localhost:8080/test</span><span style=\"color:#E1E4E8\">; </span><span style=\"color:#F97583\">done</span></span></code></pre></div>\n<p>   Expected: Log shows requests distributed evenly across healthy backends.</p>\n<ol start=\"2\">\n<li><p><strong>Test health check failure detection</strong>:</p>\n<ul>\n<li>Stop one backend server</li>\n<li>Wait for health check interval</li>\n<li>Send requests</li>\n<li>Expected: Failed backend marked unhealthy and excluded from selection.</li>\n</ul>\n</li>\n<li><p><strong>Test connection count tracking</strong>:</p>\n<ul>\n<li>Send concurrent requests</li>\n<li>Expected: Connection counts per backend logged and updated correctly.</li>\n</ul>\n</li>\n</ol>\n<p><strong>Milestone 3-5 Advanced Debugging:</strong></p>\n<p>Each subsequent milestone should verify debugging capabilities for new components:</p>\n<ul>\n<li>Cache hit/miss logging with reasons</li>\n<li>SSL handshake failure diagnosis</li>\n<li>Performance profiling under load</li>\n</ul>\n<h4 id=\"common-debugging-command-patterns\">Common Debugging Command Patterns</h4>\n<p><strong>Resource Monitoring Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Monitor file descriptor usage</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">watch</span><span style=\"color:#79B8FF\"> -n</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#9ECBFF\"> 'lsof -p $(pgrep proxy) | wc -l'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Monitor memory usage</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">watch</span><span style=\"color:#79B8FF\"> -n</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#9ECBFF\"> 'cat /proc/$(pgrep proxy)/status | grep VmRSS'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Monitor network connections</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">watch</span><span style=\"color:#79B8FF\"> -n</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#9ECBFF\"> 'ss -tupln | grep :8080'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Monitor thread activity</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">htop</span><span style=\"color:#79B8FF\"> -H</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> proxy</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Capture network traffic</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">tcpdump</span><span style=\"color:#79B8FF\"> -i</span><span style=\"color:#9ECBFF\"> any</span><span style=\"color:#79B8FF\"> -w</span><span style=\"color:#9ECBFF\"> proxy-debug.pcap</span><span style=\"color:#9ECBFF\"> host</span><span style=\"color:#9ECBFF\"> backend-server</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Profile CPU usage</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">perf</span><span style=\"color:#9ECBFF\"> record</span><span style=\"color:#79B8FF\"> -g</span><span style=\"color:#79B8FF\"> -p</span><span style=\"color:#E1E4E8\"> $(</span><span style=\"color:#B392F0\">pgrep</span><span style=\"color:#9ECBFF\"> proxy</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#9ECBFF\">sleep</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">perf</span><span style=\"color:#9ECBFF\"> report</span><span style=\"color:#79B8FF\"> --stdio</span></span></code></pre></div>\n\n<p>These debugging techniques and tools provide comprehensive visibility into reverse proxy operation, enabling systematic diagnosis of issues from simple configuration errors to complex race conditions and performance bottlenecks.</p>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - the extensibility architecture established during the core implementation (Milestones 1-5) enables future growth without requiring fundamental redesigns.</p>\n</blockquote>\n<p>Think of a reverse proxy like a Swiss Army knife that starts with basic tools but has slots for additional specialized implements. The base platform provides the essential mechanisms (HTTP parsing, connection management, request routing), while the extension system allows new tools to be added without redesigning the entire handle. Each extension leverages the existing infrastructure while adding specialized capabilities, just as a magnifying glass attachment uses the knife&#39;s existing frame while providing new optical functionality.</p>\n<h3 id=\"strategic-extension-framework\">Strategic Extension Framework</h3>\n<p>The reverse proxy&#39;s architecture naturally accommodates future enhancements through several key extensibility patterns. The <strong>plugin architecture</strong> allows new functionality to be added without modifying core components, while the <strong>configuration-driven approach</strong> enables features to be enabled or disabled dynamically. The <strong>event-driven design</strong> provides hooks where extensions can intercept and modify request processing, and the <strong>component isolation</strong> ensures that new features don&#39;t destabilize existing functionality.</p>\n<blockquote>\n<p><strong>Decision: Extension Architecture Pattern</strong></p>\n<ul>\n<li><strong>Context</strong>: Future features require integration points without destabilizing the core proxy functionality or requiring architectural rewrites</li>\n<li><strong>Options Considered</strong>: Monolithic expansion, Plugin system with dynamic loading, Event-driven hooks with static compilation</li>\n<li><strong>Decision</strong>: Event-driven hooks with static compilation and configuration-based activation</li>\n<li><strong>Rationale</strong>: Provides flexibility without the complexity and security risks of dynamic plugin loading, while maintaining compile-time type safety and performance</li>\n<li><strong>Consequences</strong>: Extensions require recompilation but gain full access to core data structures and zero-overhead integration</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Extension Pattern</th>\n<th>Implementation Complexity</th>\n<th>Runtime Overhead</th>\n<th>Security Risk</th>\n<th>Flexibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Monolithic Expansion</td>\n<td>Low</td>\n<td>None</td>\n<td>Low</td>\n<td>Limited</td>\n</tr>\n<tr>\n<td>Dynamic Plugin System</td>\n<td>High</td>\n<td>Moderate</td>\n<td>High</td>\n<td>Maximum</td>\n</tr>\n<tr>\n<td>Event-Driven Hooks</td>\n<td>Moderate</td>\n<td>Minimal</td>\n<td>Low</td>\n<td>High</td>\n</tr>\n</tbody></table>\n<h3 id=\"rate-limiting-and-throttling\">Rate Limiting and Throttling</h3>\n<p>Rate limiting acts like a nightclub bouncer who controls the flow of patrons to prevent overcrowding. The bouncer counts how many people have entered recently, checks against established limits, and either allows entry or asks visitors to wait. Similarly, rate limiting tracks request patterns per client and enforces configurable limits to protect backend servers from overload.</p>\n<p>The rate limiting extension integrates with the existing <code>HttpParser</code> and <code>ConnectionManager</code> components by adding request tracking before the load balancing stage. Each incoming request triggers rate limit evaluation based on client IP address, request path patterns, or custom header values. The system maintains sliding window counters that track request volumes across different time intervals, enabling both burst protection and sustained rate enforcement.</p>\n<p><strong>Rate Limiting Data Structures:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Structure</th>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>RateLimiter</code></td>\n<td>rules</td>\n<td><code>RateLimitRule**</code></td>\n<td>Array of configured rate limiting rules</td>\n</tr>\n<tr>\n<td><code>RateLimiter</code></td>\n<td>rule_count</td>\n<td><code>size_t</code></td>\n<td>Number of active rate limiting rules</td>\n</tr>\n<tr>\n<td><code>RateLimiter</code></td>\n<td>client_counters</td>\n<td><code>HashTable*</code></td>\n<td>Per-client request counters indexed by IP</td>\n</tr>\n<tr>\n<td><code>RateLimiter</code></td>\n<td>sliding_windows</td>\n<td><code>SlidingWindow**</code></td>\n<td>Time-based request counting windows</td>\n</tr>\n<tr>\n<td><code>RateLimiter</code></td>\n<td>cleanup_thread</td>\n<td><code>pthread_t</code></td>\n<td>Background thread for counter cleanup</td>\n</tr>\n<tr>\n<td><code>RateLimiter</code></td>\n<td>limiter_mutex</td>\n<td><code>pthread_rwlock_t</code></td>\n<td>Synchronization for counter updates</td>\n</tr>\n<tr>\n<td><code>RateLimitRule</code></td>\n<td>pattern</td>\n<td><code>char[512]</code></td>\n<td>URL pattern or client identifier pattern</td>\n</tr>\n<tr>\n<td><code>RateLimitRule</code></td>\n<td>requests_per_second</td>\n<td><code>uint32_t</code></td>\n<td>Maximum requests allowed per second</td>\n</tr>\n<tr>\n<td><code>RateLimitRule</code></td>\n<td>burst_size</td>\n<td><code>uint32_t</code></td>\n<td>Maximum burst requests before rate limiting</td>\n</tr>\n<tr>\n<td><code>RateLimitRule</code></td>\n<td>time_window_seconds</td>\n<td><code>uint32_t</code></td>\n<td>Time window for rate calculation</td>\n</tr>\n<tr>\n<td><code>ClientCounter</code></td>\n<td>client_id</td>\n<td><code>char[64]</code></td>\n<td>Client identifier (IP address or custom key)</td>\n</tr>\n<tr>\n<td><code>ClientCounter</code></td>\n<td>request_count</td>\n<td><code>uint32_t</code></td>\n<td>Current request count in time window</td>\n</tr>\n<tr>\n<td><code>ClientCounter</code></td>\n<td>last_request_time</td>\n<td><code>time_t</code></td>\n<td>Timestamp of most recent request</td>\n</tr>\n<tr>\n<td><code>ClientCounter</code></td>\n<td>burst_tokens</td>\n<td><code>uint32_t</code></td>\n<td>Available burst request tokens</td>\n</tr>\n</tbody></table>\n<p>The rate limiter extension hooks into the request processing pipeline at three key points: <strong>request arrival</strong> (to increment counters), <strong>backend selection</strong> (to enforce limits before load balancing), and <strong>response generation</strong> (to add rate limit headers). When a request exceeds configured limits, the system generates an HTTP 429 Too Many Requests response with appropriate Retry-After headers, preventing the request from reaching backend servers.</p>\n<blockquote>\n<p>The critical insight for rate limiting is that enforcement must occur as early as possible in the request pipeline to maximize protection effectiveness. Waiting until after parsing or load balancing wastes processing resources on requests that will ultimately be rejected.</p>\n</blockquote>\n<p><strong>Rate Limiting Integration Points:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Integration Point</th>\n<th>Component</th>\n<th>Hook Function</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Arrival</td>\n<td><code>ConnectionManager</code></td>\n<td><code>rate_limiter_check_request()</code></td>\n<td>Early request validation</td>\n</tr>\n<tr>\n<td>Backend Selection</td>\n<td><code>LoadBalancer</code></td>\n<td><code>rate_limiter_pre_balance()</code></td>\n<td>Pre-routing enforcement</td>\n</tr>\n<tr>\n<td>Response Headers</td>\n<td><code>HttpParser</code></td>\n<td><code>rate_limiter_add_headers()</code></td>\n<td>Rate limit status communication</td>\n</tr>\n<tr>\n<td>Counter Cleanup</td>\n<td>Background Thread</td>\n<td><code>rate_limiter_cleanup_expired()</code></td>\n<td>Memory management</td>\n</tr>\n</tbody></table>\n<h3 id=\"web-application-firewall-waf\">Web Application Firewall (WAF)</h3>\n<p>A Web Application Firewall functions like an expert security guard who examines every visitor&#39;s belongings and behavior patterns, looking for signs of malicious intent. The guard knows common attack signatures (like weapons or suspicious tools) and behavioral patterns (like someone trying to access restricted areas repeatedly). When threats are detected, the guard can block entry, strip dangerous items, or alert security management.</p>\n<p>The WAF extension operates on fully parsed HTTP requests, examining headers, URL patterns, request bodies, and parameter values against configurable rule sets. It integrates after the <code>HttpParser</code> component completes request parsing but before the <code>LoadBalancer</code> selects a backend server, ensuring that malicious requests never reach application servers.</p>\n<p><strong>WAF Architecture Components:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Integration Point</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Rule Engine</td>\n<td>Pattern matching and threat detection</td>\n<td>Post-parsing, pre-routing</td>\n</tr>\n<tr>\n<td>Signature Database</td>\n<td>Known attack patterns and payloads</td>\n<td>Static configuration with hot reload</td>\n</tr>\n<tr>\n<td>Anomaly Detector</td>\n<td>Statistical analysis of request patterns</td>\n<td>Background analysis thread</td>\n</tr>\n<tr>\n<td>Response Generator</td>\n<td>Security error page generation</td>\n<td>Request termination point</td>\n</tr>\n<tr>\n<td>Audit Logger</td>\n<td>Security event logging and alerting</td>\n<td>Cross-cutting concern</td>\n</tr>\n</tbody></table>\n<p>The WAF rule engine processes requests through multiple detection layers: <strong>signature matching</strong> (comparing request content against known attack patterns), <strong>statistical anomaly detection</strong> (identifying unusual request characteristics), <strong>rate-based detection</strong> (spotting suspicious request volumes), and <strong>behavioral analysis</strong> (tracking client interaction patterns over time).</p>\n<p><strong>WAF Rule Types:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Rule Type</th>\n<th>Detection Method</th>\n<th>Example Pattern</th>\n<th>Action Options</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SQL Injection</td>\n<td>Pattern matching</td>\n<td><code>UNION SELECT.*FROM</code></td>\n<td>Block, sanitize, log</td>\n</tr>\n<tr>\n<td>XSS Attack</td>\n<td>Content scanning</td>\n<td><code>&lt;script&gt;.*&lt;/script&gt;</code></td>\n<td>Block, escape, log</td>\n</tr>\n<tr>\n<td>Path Traversal</td>\n<td>URL analysis</td>\n<td><code>\\.\\.\\/</code> sequences</td>\n<td>Block, normalize, log</td>\n</tr>\n<tr>\n<td>Command Injection</td>\n<td>Parameter scanning</td>\n<td>Shell metacharacters</td>\n<td>Block, sanitize, log</td>\n</tr>\n<tr>\n<td>Rate Anomaly</td>\n<td>Statistical analysis</td>\n<td>Request volume spikes</td>\n<td>Throttle, block, log</td>\n</tr>\n</tbody></table>\n<p>When the WAF detects threats, it can take various actions: <strong>blocking</strong> (returning 403 Forbidden responses), <strong>sanitizing</strong> (cleaning request content and forwarding), <strong>logging</strong> (recording security events while allowing requests), or <strong>challenging</strong> (requiring additional authentication). The system maintains detailed audit logs that include threat classifications, rule triggers, client information, and response actions.</p>\n<h3 id=\"monitoring-and-observability\">Monitoring and Observability</h3>\n<p>Monitoring a reverse proxy resembles managing a busy restaurant kitchen where you need visibility into every station&#39;s performance. The head chef needs real-time information about order volumes, preparation times, ingredient availability, and staff performance. Similarly, proxy monitoring provides comprehensive visibility into request flows, component performance, error rates, and resource utilization across all system layers.</p>\n<p>The observability extension integrates with every core component through instrumentation hooks that collect metrics without impacting request processing performance. The system employs <strong>push-based metrics</strong> (actively sending data to monitoring systems), <strong>pull-based metrics</strong> (exposing endpoints for metric collection), and <strong>structured logging</strong> (machine-readable log formats for analysis).</p>\n<p><strong>Monitoring Data Model:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Component Source</th>\n<th>Key Metrics</th>\n<th>Collection Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Metrics</td>\n<td><code>HttpParser</code></td>\n<td>Parse time, request size, protocol version</td>\n<td>Per-request instrumentation</td>\n</tr>\n<tr>\n<td>Connection Metrics</td>\n<td><code>ConnectionManager</code></td>\n<td>Pool utilization, connection lifetime, timeouts</td>\n<td>Connection lifecycle hooks</td>\n</tr>\n<tr>\n<td>Load Balancing</td>\n<td><code>LoadBalancer</code></td>\n<td>Backend selection time, health check results</td>\n<td>Algorithm execution hooks</td>\n</tr>\n<tr>\n<td>Cache Performance</td>\n<td><code>CacheEngine</code></td>\n<td>Hit/miss ratios, eviction rates, storage usage</td>\n<td>Cache operation instrumentation</td>\n</tr>\n<tr>\n<td>SSL Performance</td>\n<td><code>SSLTermination</code></td>\n<td>Handshake duration, cipher negotiation, SNI usage</td>\n<td>TLS event callbacks</td>\n</tr>\n</tbody></table>\n<p>The monitoring system exposes metrics through multiple interfaces: <strong>Prometheus endpoints</strong> (for scraping-based collection), <strong>StatsD integration</strong> (for push-based metric delivery), <strong>structured JSON logs</strong> (for centralized log aggregation), and <strong>health check endpoints</strong> (for load balancer health monitoring). Each interface provides different metric granularities and update frequencies to support various monitoring architectures.</p>\n<p><strong>Observable Events:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Event Type</th>\n<th>Trigger Condition</th>\n<th>Included Data</th>\n<th>Monitoring Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Started</td>\n<td>Client connection accepted</td>\n<td>Timestamp, client IP, request ID</td>\n<td>Request tracing</td>\n</tr>\n<tr>\n<td>Backend Selected</td>\n<td>Load balancer chooses server</td>\n<td>Backend ID, selection algorithm, health status</td>\n<td>Load distribution analysis</td>\n</tr>\n<tr>\n<td>Cache Hit/Miss</td>\n<td>Cache lookup completed</td>\n<td>Cache key, hit status, TTL remaining</td>\n<td>Cache performance tuning</td>\n</tr>\n<tr>\n<td>Error Occurred</td>\n<td>Any component error</td>\n<td>Error code, component, stack trace</td>\n<td>Error rate monitoring</td>\n</tr>\n<tr>\n<td>Connection Pooled</td>\n<td>Backend connection returned</td>\n<td>Pool size, connection age, reuse count</td>\n<td>Pool efficiency analysis</td>\n</tr>\n</tbody></table>\n<h3 id=\"authentication-and-authorization\">Authentication and Authorization</h3>\n<p>Authentication and authorization work like a sophisticated embassy security system with multiple checkpoints. The first checkpoint verifies visitor identity through passport examination (authentication), while subsequent checkpoints determine which areas the visitor can access based on their diplomatic status and clearance level (authorization). The system maintains visitor records, tracks access patterns, and can revoke access privileges dynamically.</p>\n<p>The auth extension integrates early in the request pipeline, immediately after HTTP parsing but before cache lookup or backend selection. This positioning ensures that unauthorized requests consume minimal system resources while authorized requests benefit from full proxy optimizations including caching and connection pooling.</p>\n<p><strong>Authentication Integration Architecture:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Integration Point</th>\n<th>Purpose</th>\n<th>Component Interaction</th>\n<th>Data Flow</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Validation</td>\n<td>Identity verification</td>\n<td><code>HttpParser</code> → Auth Extension</td>\n<td>Headers → Auth decision</td>\n</tr>\n<tr>\n<td>Cache Key Modification</td>\n<td>User-aware caching</td>\n<td>Auth Extension → <code>CacheEngine</code></td>\n<td>User context → Cache key</td>\n</tr>\n<tr>\n<td>Backend Selection</td>\n<td>User-based routing</td>\n<td>Auth Extension → <code>LoadBalancer</code></td>\n<td>User role → Backend pool</td>\n</tr>\n<tr>\n<td>Response Headers</td>\n<td>Auth status communication</td>\n<td>Auth Extension → <code>HttpParser</code></td>\n<td>Auth result → Response headers</td>\n</tr>\n</tbody></table>\n<p>The authentication system supports multiple verification methods: <strong>JWT token validation</strong> (for stateless authentication), <strong>session cookie verification</strong> (for traditional web applications), <strong>API key authentication</strong> (for service-to-service communication), and <strong>OAuth2 token introspection</strong> (for delegated authorization). Each method integrates with external identity providers while maintaining local caching for performance.</p>\n<p><strong>Authorization Decision Engine:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Decision Factor</th>\n<th>Data Source</th>\n<th>Evaluation Method</th>\n<th>Caching Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>User Identity</td>\n<td>Auth token/session</td>\n<td>Token validation/lookup</td>\n<td>In-memory with TTL</td>\n</tr>\n<tr>\n<td>Request Path</td>\n<td>HTTP request URL</td>\n<td>Pattern matching</td>\n<td>Rule compilation</td>\n</tr>\n<tr>\n<td>HTTP Method</td>\n<td>Request method header</td>\n<td>Exact matching</td>\n<td>Static configuration</td>\n</tr>\n<tr>\n<td>User Roles</td>\n<td>Identity provider</td>\n<td>Role membership check</td>\n<td>User session cache</td>\n</tr>\n<tr>\n<td>Resource Permissions</td>\n<td>Permission database</td>\n<td>ACL evaluation</td>\n<td>Permission result cache</td>\n</tr>\n</tbody></table>\n<p>When authorization fails, the system can respond with different strategies: <strong>401 Unauthorized</strong> (for missing authentication), <strong>403 Forbidden</strong> (for insufficient permissions), <strong>redirect to login</strong> (for web applications), or <strong>custom error pages</strong> (for branded experiences). The auth extension maintains audit logs for security compliance, tracking authentication attempts, authorization decisions, and access pattern anomalies.</p>\n<h3 id=\"content-transformation\">Content Transformation</h3>\n<p>Content transformation functions like a universal translator and format converter at an international conference. Just as the translator converts languages and cultural references to ensure effective communication between parties, content transformation adapts response formats, protocols, and encodings to match client capabilities and requirements.</p>\n<p>The transformation extension operates on HTTP responses after they return from backend servers but before they reach the client. This positioning allows the proxy to modify content without impacting backend server logic while ensuring that transformations respect caching and connection management optimizations.</p>\n<p><strong>Transformation Pipeline Architecture:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Transformation Stage</th>\n<th>Purpose</th>\n<th>Processing Order</th>\n<th>Configuration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Content Negotiation</td>\n<td>Format selection</td>\n<td>1st - immediately after backend response</td>\n<td>Client Accept headers</td>\n</tr>\n<tr>\n<td>Protocol Translation</td>\n<td>Version conversion</td>\n<td>2nd - after format decision</td>\n<td>HTTP version capabilities</td>\n</tr>\n<tr>\n<td>Compression</td>\n<td>Bandwidth optimization</td>\n<td>3rd - after content finalization</td>\n<td>Client encoding support</td>\n</tr>\n<tr>\n<td>Security Headers</td>\n<td>Response hardening</td>\n<td>4th - final header addition</td>\n<td>Security policy configuration</td>\n</tr>\n</tbody></table>\n<p>The content transformation system supports multiple transformation types: <strong>protocol conversion</strong> (HTTP/1.1 to HTTP/2), <strong>format translation</strong> (JSON to XML or vice versa), <strong>image optimization</strong> (resizing and compression), <strong>response compression</strong> (gzip, brotli), and <strong>security header injection</strong> (HSTS, CSP, CORP headers).</p>\n<p><strong>Transformation Rules:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Rule Type</th>\n<th>Trigger Condition</th>\n<th>Input Data</th>\n<th>Output Modification</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Protocol Downgrade</td>\n<td>HTTP/2 client, HTTP/1.1 backend</td>\n<td>Response stream</td>\n<td>Header format conversion</td>\n<td>Low</td>\n</tr>\n<tr>\n<td>JSON to XML</td>\n<td>Accept: application/xml header</td>\n<td>Response body</td>\n<td>Format transformation</td>\n<td>High</td>\n</tr>\n<tr>\n<td>Image Resize</td>\n<td>Image content type + query params</td>\n<td>Binary response body</td>\n<td>Resized image data</td>\n<td>Very High</td>\n</tr>\n<tr>\n<td>Compression</td>\n<td>Client accepts gzip/brotli</td>\n<td>Response body</td>\n<td>Compressed body + headers</td>\n<td>Moderate</td>\n</tr>\n<tr>\n<td>Security Headers</td>\n<td>All responses</td>\n<td>Response headers</td>\n<td>Additional security headers</td>\n<td>Minimal</td>\n</tr>\n</tbody></table>\n<p>Content transformation integrates with the <code>CacheEngine</code> to ensure that transformed content is cached appropriately. The cache key generation includes transformation parameters so that different client capabilities receive correctly cached responses. For example, a gzipped response and an uncompressed response for the same resource are cached as separate entries.</p>\n<h3 id=\"service-mesh-integration\">Service Mesh Integration</h3>\n<p>Service mesh integration transforms the reverse proxy into a service mesh sidecar proxy, similar to how a personal assistant coordinates all communications and interactions for a busy executive. The assistant handles scheduling, protocol translation, security verification, and relationship management, allowing the executive to focus on core business decisions while ensuring all interactions follow organizational policies and procedures.</p>\n<p>The service mesh extension adds distributed tracing, service discovery, traffic policies, and inter-service security. It integrates with the existing <code>LoadBalancer</code> component for dynamic service discovery and with the <code>ConnectionManager</code> for connection security and observability.</p>\n<p><strong>Service Mesh Components:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Integration Point</th>\n<th>External Dependencies</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Service Discovery</td>\n<td>Backend server enumeration</td>\n<td><code>LoadBalancer</code> backend configuration</td>\n<td>Kubernetes API, Consul, etcd</td>\n</tr>\n<tr>\n<td>Traffic Policy Engine</td>\n<td>Request routing and shaping</td>\n<td><code>LoadBalancer</code> selection algorithm</td>\n<td>Policy configuration store</td>\n</tr>\n<tr>\n<td>Distributed Tracing</td>\n<td>Request correlation across services</td>\n<td>All component instrumentation</td>\n<td>Jaeger, Zipkin, OpenTelemetry</td>\n</tr>\n<tr>\n<td>mTLS Manager</td>\n<td>Inter-service authentication</td>\n<td><code>SSLTermination</code> certificate management</td>\n<td>Certificate authority integration</td>\n</tr>\n</tbody></table>\n<p>The service mesh extension enables <strong>progressive traffic deployment</strong> (canary releases and blue-green deployments), <strong>circuit breaker patterns</strong> (automatic failure isolation), <strong>retry and timeout policies</strong> (configurable resilience patterns), and <strong>traffic splitting</strong> (A/B testing and gradual rollouts).</p>\n<p><strong>Service Mesh Policies:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Policy Type</th>\n<th>Configuration Scope</th>\n<th>Enforcement Point</th>\n<th>Dynamic Updates</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Traffic Routing</td>\n<td>Per-service destination</td>\n<td>Backend selection</td>\n<td>Real-time via API</td>\n</tr>\n<tr>\n<td>Retry Behavior</td>\n<td>Per-service or per-endpoint</td>\n<td>Connection failure handling</td>\n<td>Configuration reload</td>\n</tr>\n<tr>\n<td>Timeout Values</td>\n<td>Per-service or per-operation</td>\n<td>Request processing</td>\n<td>Real-time via API</td>\n</tr>\n<tr>\n<td>Circuit Breaker</td>\n<td>Per-backend server</td>\n<td>Health checking integration</td>\n<td>Real-time via API</td>\n</tr>\n<tr>\n<td>Load Balancing</td>\n<td>Per-service backend pool</td>\n<td>Load balancer algorithm</td>\n<td>Configuration reload</td>\n</tr>\n</tbody></table>\n<h3 id=\"multi-tenancy-support\">Multi-Tenancy Support</h3>\n<p>Multi-tenancy resembles managing a large apartment building where different tenants share common infrastructure (elevators, utilities, security) while maintaining complete isolation of their private spaces and resources. The building management system ensures that tenant A cannot access tenant B&#39;s apartment, utilities are billed correctly, and common areas remain available to all authorized residents.</p>\n<p>The multi-tenancy extension adds <strong>tenant isolation</strong> (separate resource pools and configurations), <strong>tenant-aware routing</strong> (directing requests to appropriate backend clusters), <strong>resource quotas</strong> (preventing tenant resource exhaustion), and <strong>audit isolation</strong> (separate logging and monitoring per tenant).</p>\n<p><strong>Multi-Tenant Architecture:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Isolation Layer</th>\n<th>Implementation Method</th>\n<th>Resource Separation</th>\n<th>Configuration Management</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Network</td>\n<td>Virtual routing tables</td>\n<td>Separate backend pools per tenant</td>\n<td>Tenant-specific load balancer rules</td>\n</tr>\n<tr>\n<td>Cache</td>\n<td>Namespace prefixing</td>\n<td>Isolated cache partitions</td>\n<td>Per-tenant cache policies</td>\n</tr>\n<tr>\n<td>SSL</td>\n<td>Certificate management</td>\n<td>Tenant-specific certificates</td>\n<td>SNI-based tenant resolution</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Metric tagging</td>\n<td>Separate metric namespaces</td>\n<td>Tenant-aware dashboards</td>\n</tr>\n<tr>\n<td>Rate Limiting</td>\n<td>Client classification</td>\n<td>Per-tenant rate limits</td>\n<td>Tenant-specific policies</td>\n</tr>\n</tbody></table>\n<p>The multi-tenancy system determines tenant identity through multiple methods: <strong>subdomain analysis</strong> (tenant1.example.com), <strong>URL path prefixes</strong> (/tenant1/api/...), <strong>custom headers</strong> (X-Tenant-ID), or <strong>SSL certificate subject names</strong>. Once identified, all proxy components apply tenant-specific configurations and resource allocations.</p>\n<h3 id=\"design-extensibility-features\">Design Extensibility Features</h3>\n<p>The current reverse proxy architecture accommodates future extensions through several key design patterns that were established during the core implementation phases.</p>\n<blockquote>\n<p><strong>Decision: Extension Hook Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Future features require integration points without modifying core component logic or destabilizing existing functionality</li>\n<li><strong>Options Considered</strong>: Callback functions, Event publishing/subscription, Component inheritance</li>\n<li><strong>Decision</strong>: Event publishing with typed message interfaces and subscriber registration</li>\n<li><strong>Rationale</strong>: Provides loose coupling between extensions and core components while maintaining type safety and compile-time validation</li>\n<li><strong>Consequences</strong>: Extensions can observe and modify request processing without requiring changes to core components, but extension interactions must be carefully coordinated</li>\n</ul>\n</blockquote>\n<p><strong>Extension Integration Patterns:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Pattern</th>\n<th>Usage Scenario</th>\n<th>Implementation Method</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pre-processing Hooks</td>\n<td>Request modification before routing</td>\n<td>Event subscription at request parsing completion</td>\n<td>Low latency, limited context</td>\n</tr>\n<tr>\n<td>Post-processing Hooks</td>\n<td>Response modification before client delivery</td>\n<td>Event subscription at response generation</td>\n<td>Full context, higher latency</td>\n</tr>\n<tr>\n<td>Component Replacement</td>\n<td>Alternative algorithm implementations</td>\n<td>Interface inheritance with factory selection</td>\n<td>Maximum flexibility, complexity</td>\n</tr>\n<tr>\n<td>Configuration Extensions</td>\n<td>New configuration sections</td>\n<td>Configuration parser plugin registration</td>\n<td>Easy integration, limited runtime changes</td>\n</tr>\n</tbody></table>\n<p>The <code>EventDispatcher</code> component, introduced during the core architecture phase, provides the foundation for extension integration. Extensions register event handlers for specific processing stages, receiving typed messages with full request context and the ability to modify processing behavior.</p>\n<p><strong>Extension Event Types:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Event Type</th>\n<th>Trigger Point</th>\n<th>Message Data</th>\n<th>Extension Capabilities</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>RequestParsed</code></td>\n<td>After HTTP parsing completion</td>\n<td><code>HttpRequest*</code>, <code>Connection*</code></td>\n<td>Header modification, request blocking</td>\n</tr>\n<tr>\n<td><code>BackendSelected</code></td>\n<td>After load balancer decision</td>\n<td><code>BackendServer*</code>, <code>HttpRequest*</code></td>\n<td>Backend override, request transformation</td>\n</tr>\n<tr>\n<td><code>CacheLookup</code></td>\n<td>Before cache key generation</td>\n<td><code>HttpRequest*</code>, cache key</td>\n<td>Cache key modification, bypass decisions</td>\n</tr>\n<tr>\n<td><code>ResponseReceived</code></td>\n<td>After backend response arrival</td>\n<td><code>HttpResponse*</code>, <code>BackendServer*</code></td>\n<td>Content transformation, header injection</td>\n</tr>\n<tr>\n<td><code>ConnectionEstablished</code></td>\n<td>After client connection acceptance</td>\n<td><code>Connection*</code>, client address</td>\n<td>Connection rejection, metadata attachment</td>\n</tr>\n</tbody></table>\n<p>The configuration system supports extension-specific sections through a plugin registration mechanism. Extensions provide configuration schema definitions that integrate with the main configuration parser, enabling complex extension settings while maintaining configuration validation and hot-reload capabilities.</p>\n<h3 id=\"performance-considerations-for-extensions\">Performance Considerations for Extensions</h3>\n<p>Extensions must balance functionality with performance impact, particularly since the reverse proxy operates in the critical path of application traffic. The architecture provides several mechanisms to minimize extension overhead while maximizing functionality.</p>\n<p><strong>Performance Optimization Strategies:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Strategy</th>\n<th>Application Area</th>\n<th>Performance Gain</th>\n<th>Implementation Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Filtering</td>\n<td>Extension activation</td>\n<td>Skip unused extensions</td>\n<td>Low</td>\n</tr>\n<tr>\n<td>Asynchronous Processing</td>\n<td>Heavy computations</td>\n<td>Non-blocking request path</td>\n<td>High</td>\n</tr>\n<tr>\n<td>Result Caching</td>\n<td>Expensive operations</td>\n<td>Amortized computation cost</td>\n<td>Moderate</td>\n</tr>\n<tr>\n<td>Bulk Operations</td>\n<td>Batch processing</td>\n<td>Reduced per-request overhead</td>\n<td>Moderate</td>\n</tr>\n</tbody></table>\n<p>Extensions that perform expensive operations (content transformation, complex authentication) implement <strong>asynchronous processing patterns</strong> where the extension initiates background work and registers completion callbacks. This approach prevents extension processing from blocking the main request pipeline while ensuring that responses incorporate extension results.</p>\n<p>The extension system includes <strong>performance budgets</strong> that limit the maximum processing time extensions can consume per request. When extensions exceed their allocated time budget, the system can skip optional extensions, use cached results, or fail gracefully while maintaining core proxy functionality.</p>\n<h3 id=\"common-extension-pitfalls\">Common Extension Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Memory Leaks in Extension Data</strong>\nExtensions that allocate memory for request processing (authentication tokens, transformation buffers, cached results) must properly integrate with the connection lifecycle to ensure cleanup. Extension data attached to <code>Connection</code> structures requires cleanup callbacks registered during attachment.</p>\n<p>⚠️ <strong>Pitfall: Blocking Operations in Extension Hooks</strong>\nExtensions that perform synchronous I/O operations (database lookups, external API calls, file system access) in event handlers block the entire request processing pipeline. Extensions requiring external data must use asynchronous patterns with completion callbacks.</p>\n<p>⚠️ <strong>Pitfall: Thread Safety in Extension State</strong>\nExtensions that maintain global state (caches, configuration, metrics) must implement proper synchronization when accessed from multiple worker threads. The proxy&#39;s event-driven architecture ensures that request processing can occur concurrently across multiple connections.</p>\n<p>⚠️ <strong>Pitfall: Extension Ordering Dependencies</strong>\nMultiple extensions processing the same request can create ordering dependencies where Extension A&#39;s output becomes Extension B&#39;s input. The extension system requires explicit ordering configuration to ensure deterministic behavior.</p>\n<p>⚠️ <strong>Pitfall: Configuration Validation Gaps</strong>\nExtensions that introduce new configuration sections must implement comprehensive validation to prevent runtime failures. Invalid extension configuration should be detected during startup rather than during request processing.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The reverse proxy&#39;s extension architecture leverages the event-driven foundation established during core development. Extensions integrate through well-defined interfaces that provide access to request context while maintaining performance and stability guarantees.</p>\n<p><strong>Technology Recommendations for Extensions:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Extension Type</th>\n<th>Simple Implementation</th>\n<th>Advanced Implementation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Filtering</td>\n<td>Direct header inspection</td>\n<td>Pattern matching with compiled regex</td>\n</tr>\n<tr>\n<td>Content Transformation</td>\n<td>String replacement</td>\n<td>Streaming transformation with SAX parsing</td>\n</tr>\n<tr>\n<td>Authentication</td>\n<td>Static token validation</td>\n<td>JWT with cryptographic verification</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Simple counter increments</td>\n<td>Time-series metrics with statistical aggregation</td>\n</tr>\n<tr>\n<td>Rate Limiting</td>\n<td>Token bucket algorithm</td>\n<td>Sliding window with distributed state</td>\n</tr>\n</tbody></table>\n<p><strong>Extension Integration File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">proxy</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── core</span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\">                    ← Core proxy components</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── http_parser.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── connection_manager.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── load_balancer.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── extensions</span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\">              ← Extension implementations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── rate_limiter</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   │   ├── rate_limiter.h   ← Extension interface</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   │   ├── rate_limiter.c   ← Core rate limiting logic</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   │   └── sliding_window.c ← Helper components</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── waf</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   │   ├── waf.h</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   │   ├── rule_engine.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   │   └── signature_db.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── auth</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│       ├── auth_extension.h</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│       ├── jwt_validator.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│       └── session_manager.c</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">├── extension_framework</span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\">     ← Extension support infrastructure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── event_dispatcher.h   ← Event system interfaces</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   ├── extension_manager.c  ← Extension lifecycle management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">│   └── extension_config.c   ← Configuration integration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">└── config</span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\">                  ← Extension configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ├── rate_limits.conf</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ├── waf_rules.conf</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    └── auth_policies.conf</span></span></code></pre></div>\n\n<p><strong>Extension Registration Infrastructure:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Extension interface definition</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> Extension {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> name</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">                           // Extension identifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">init)(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> config);</span><span style=\"color:#6A737D\">      // Extension initialization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">destroy)(</span><span style=\"color:#F97583\">void</span><span style=\"color:#E1E4E8\">);</span><span style=\"color:#6A737D\">                  // Extension cleanup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EventHandler</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> handlers;</span><span style=\"color:#6A737D\">                  // Event handler array</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> handler_count;</span><span style=\"color:#6A737D\">                   // Number of handlers</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} Extension;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Event handler definition for extensions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> EventHandler {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    EventType event_type;</span><span style=\"color:#6A737D\">                   // Which event to handle</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    int</span><span style=\"color:#E1E4E8\"> priority;</span><span style=\"color:#6A737D\">                           // Handler execution order</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">handler_func)(EventData</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> data);</span><span style=\"color:#6A737D\">  // Handler implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> enabled;</span><span style=\"color:#6A737D\">                           // Runtime enable/disable</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} EventHandler;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Extension manager for lifecycle control</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> ExtensionManager {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    Extension</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> extensions</span><span style=\"color:#E1E4E8\">[MAX_EXTENSIONS];</span><span style=\"color:#6A737D\">   // Loaded extensions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> extension_count;</span><span style=\"color:#6A737D\">                 // Number of loaded extensions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    HashTable</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> event_handlers;</span><span style=\"color:#6A737D\">              // Handlers by event type</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_rwlock_t</span><span style=\"color:#E1E4E8\"> extensions_lock;</span><span style=\"color:#6A737D\">       // Thread-safe registration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> extensions_enabled;</span><span style=\"color:#6A737D\">                // Global extension toggle</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ExtensionManager;</span></span></code></pre></div>\n\n<p><strong>Core Extension Registration Functions:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Register extension with the proxy system</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> extension_manager_register</span><span style=\"color:#E1E4E8\">(ExtensionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, Extension</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> ext</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Validate extension interface completeness</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Check for name conflicts with existing extensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Initialize extension with proxy configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Register event handlers in dispatcher</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Add extension to manager's extension array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Use write lock during registration to prevent races</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Initialize all registered extensions during proxy startup</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> extension_manager_init_all</span><span style=\"color:#E1E4E8\">(ExtensionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Iterate through registered extensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Call each extension's init function with config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Disable extensions that fail initialization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Sort event handlers by priority for each event type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Log extension initialization results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Dispatch event to all registered handlers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> extension_manager_dispatch_event</span><span style=\"color:#E1E4E8\">(ExtensionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, EventType </span><span style=\"color:#FFAB70\">type</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                     EventData</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Look up handlers for the specified event type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Execute handlers in priority order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Stop processing if any handler returns false (blocks request)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Update extension performance metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Handle handler exceptions gracefully</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Rate Limiting Extension Example:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Rate limiting extension implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> RateLimitExtension {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    RateLimiter</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> limiter;</span><span style=\"color:#6A737D\">                   // Core rate limiting logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pthread_t</span><span style=\"color:#E1E4E8\"> cleanup_thread;</span><span style=\"color:#6A737D\">              // Background counter cleanup</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> thread_running;</span><span style=\"color:#6A737D\">                    // Thread lifecycle flag</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} RateLimitExtension;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Extension initialization function</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> rate_limit_extension_init</span><span style=\"color:#E1E4E8\">(ProxyConfig</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> config</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Parse rate limiting configuration from config file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Initialize rate limiter with configured rules</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Start background cleanup thread for expired counters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Register event handlers for request arrival and response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Set up performance monitoring for rate limit decisions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Request arrival event handler for rate limiting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> rate_limit_handle_request</span><span style=\"color:#E1E4E8\">(EventData</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> event_data</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Extract client identifier from request (IP, user ID, API key)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Look up rate limit rules that apply to this request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Check current request count against configured limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Update request counters for this client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Return false to block request if limits exceeded, true to allow</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Hint: Generate HTTP 429 response with Retry-After header for blocked requests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Extension Configuration Integration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Extension configuration parser registration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> struct</span><span style=\"color:#E1E4E8\"> ExtensionConfigParser {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char</span><span style=\"color:#FFAB70\"> section_name</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">64</span><span style=\"color:#E1E4E8\">];</span><span style=\"color:#6A737D\">                  // Configuration section identifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">parse_section)(cJSON</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> section, </span><span style=\"color:#F97583\">void**</span><span style=\"color:#E1E4E8\"> config);</span><span style=\"color:#6A737D\"> // Parser function</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    bool</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">validate_config)(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#E1E4E8\"> config);</span><span style=\"color:#6A737D\"> // Configuration validator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    void</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">free_config)(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#E1E4E8\"> config);</span><span style=\"color:#6A737D\">     // Configuration cleanup</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ExtensionConfigParser;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Register configuration parser for extension</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">bool</span><span style=\"color:#B392F0\"> config_register_extension_parser</span><span style=\"color:#E1E4E8\">(ConfigManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                     ExtensionConfigParser</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> parser</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Validate parser function pointers are non-null</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Check for section name conflicts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Add parser to configuration manager's parser registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // TODO: Enable hot-reload support for extension configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint - Extension Framework:</strong>\nAfter implementing the extension framework infrastructure, verify functionality by:</p>\n<ol>\n<li><strong>Extension Registration Test</strong>: Create a simple test extension that logs requests and verify it loads correctly during proxy startup</li>\n<li><strong>Event Dispatch Test</strong>: Send HTTP requests and confirm that extension event handlers receive appropriate event data</li>\n<li><strong>Configuration Integration Test</strong>: Add extension-specific configuration and verify parsing and validation work correctly</li>\n<li><strong>Performance Test</strong>: Measure request processing latency with and without extensions to ensure minimal overhead</li>\n<li><strong>Thread Safety Test</strong>: Run concurrent requests while loading/unloading extensions to verify thread safety</li>\n</ol>\n<p>Expected behavior: Extensions should integrate seamlessly without impacting core proxy functionality, and extension failures should not crash the proxy process.</p>\n<p>The extension architecture provides a robust foundation for evolving the reverse proxy to meet changing requirements while maintaining the performance, reliability, and security characteristics established during core development.</p>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones - this glossary provides definitions for technical terms, acronyms, and domain-specific vocabulary used throughout the reverse proxy implementation.</p>\n</blockquote>\n<p>A comprehensive understanding of reverse proxy terminology is essential for successfully implementing the HTTP proxy core, load balancing, connection pooling, caching, and SSL termination components. This glossary serves as your technical dictionary throughout the implementation journey.</p>\n<h3 id=\"core-reverse-proxy-concepts\">Core Reverse Proxy Concepts</h3>\n<p><strong>Reverse Proxy</strong>\nA server that sits in front of one or more backend servers, intercepting requests from clients and forwarding them to the appropriate backend. Unlike a forward proxy that acts on behalf of clients, a reverse proxy acts on behalf of the servers. Think of it as a skilled receptionist at a large company who receives all visitor requests and directs them to the right department based on availability and specialization.</p>\n<p><strong>Forward Proxy</strong>\nA proxy server that acts on behalf of clients, forwarding their requests to servers on the internet. The server sees the proxy&#39;s IP address rather than the client&#39;s original IP address. This is the traditional &quot;proxy&quot; that users configure in their browsers.</p>\n<p><strong>Backend Server</strong>\nAn upstream server that actually processes client requests and generates responses. These are the real application servers that do the work, while the reverse proxy handles the complexity of client communication, load balancing, and optimization.</p>\n<p><strong>Upstream Server</strong>\nAnother term for backend server, emphasizing that it&#39;s &quot;upstream&quot; in the request processing flow from the reverse proxy&#39;s perspective.</p>\n<p><strong>SSL Termination</strong>\nThe process of decrypting SSL/TLS connections at the reverse proxy level, then forwarding the decrypted HTTP requests to backend servers over plain HTTP. This centralizes certificate management and reduces computational load on backend servers.</p>\n<p><strong>TLS Termination</strong>\nModern terminology for SSL termination, as TLS (Transport Layer Security) has superseded SSL (Secure Sockets Layer) in practice, though the terms are often used interchangeably.</p>\n<h3 id=\"http-protocol-and-parsing\">HTTP Protocol and Parsing</h3>\n<p><strong>HTTP/1.1</strong>\nThe widely-supported HTTP protocol version that uses text-based headers and supports persistent connections through the <code>Connection: keep-alive</code> header. Requests and responses are processed sequentially on each connection.</p>\n<p><strong>HTTP/2</strong>\nA binary protocol that multiplexes multiple request-response streams over a single connection. It includes header compression and server push capabilities, requiring more complex parsing logic than HTTP/1.1.</p>\n<p><strong>Stream-Based Parsing</strong>\nAn incremental parsing approach that processes HTTP messages as data arrives over the network, rather than buffering the entire message before parsing. This is essential for handling large requests and responses without excessive memory usage.</p>\n<p><strong>State Machine</strong>\nA parsing approach where the parser maintains its current state (parsing request line, headers, body, etc.) and transitions between states based on input data. This enables robust handling of partial reads and malformed input.</p>\n<p><strong>Request Smuggling</strong>\nAn attack that exploits differences in how front-end proxies and backend servers parse HTTP messages, particularly around Content-Length and Transfer-Encoding headers. Proper parsing and validation prevent these vulnerabilities.</p>\n<p><strong>Chunked Transfer Encoding</strong>\nAn HTTP mechanism for sending message bodies in chunks when the total size is unknown at transmission start. Each chunk is prefixed with its size in hexadecimal, followed by the data and a trailing CRLF.</p>\n<p><strong>Content-Length Header</strong>\nHTTP header specifying the exact size of the message body in bytes. When present, it determines how much data to read for the complete message body.</p>\n<p><strong>Transfer-Encoding Header</strong>\nHTTP header indicating how the message body is encoded for transfer. The most common value is &quot;chunked&quot; for chunked transfer encoding.</p>\n<p><strong>Keep-Alive Connection</strong>\nHTTP/1.1 feature allowing multiple requests and responses to be sent over a single TCP connection, reducing the overhead of connection establishment and teardown.</p>\n<p><strong>Pipeline Depth</strong>\nThe number of HTTP requests sent on a connection before waiting for responses. HTTP/1.1 pipelining allows multiple requests to be sent without waiting for each response, though it&#39;s rarely used in practice due to head-of-line blocking issues.</p>\n<h3 id=\"connection-management\">Connection Management</h3>\n<p><strong>Connection Pooling</strong>\nThe practice of maintaining persistent connections to backend servers and reusing them for multiple requests. This eliminates the TCP handshake overhead for each request and improves performance.</p>\n<p><strong>Connection Lifecycle</strong>\nThe states and transitions connections go through from establishment to cleanup, including idle, reading request, forwarding, reading response, writing response, and closing states.</p>\n<p><strong>Event-Driven Architecture</strong>\nAn architecture pattern using asynchronous I/O and event loops to handle many concurrent connections efficiently. Events like data arrival, connection completion, and timeouts trigger appropriate handlers.</p>\n<p><strong>LIFO Strategy</strong>\nLast-In First-Out connection reuse strategy where the most recently used connection is selected first from the pool. This improves CPU cache locality and can reduce connection establishment overhead.</p>\n<p><strong>Connection State</strong>\nThe current operational phase of a connection, such as <code>CONNECTION_IDLE</code>, <code>CONNECTION_READING_REQUEST</code>, <code>CONNECTION_FORWARDING</code>, <code>CONNECTION_READING_RESPONSE</code>, <code>CONNECTION_WRITING_RESPONSE</code>, or <code>CONNECTION_CLOSING</code>.</p>\n<p><strong>Resource Leak</strong>\nA programming error where allocated system resources (file descriptors, memory, connections) are not properly released, eventually exhausting available resources and causing system failure.</p>\n<p><strong>Timeout Management</strong>\nThe practice of enforcing time limits on network operations to prevent connections from hanging indefinitely and consuming system resources.</p>\n<p><strong>Timer Wheel</strong>\nAn efficient data structure for managing timeouts with O(1) insertion and deletion operations. It uses a circular array of time slots, each containing operations that expire at that time.</p>\n<p><strong>Non-Blocking I/O</strong>\nI/O operations that return immediately if no data is available, allowing a single thread to handle many connections by processing only those that are ready for I/O operations.</p>\n<p><strong>Edge-Triggered Events</strong>\nEvent notification mode where events are delivered only when the state changes (e.g., from no data available to data available), requiring the application to process all available data before waiting for the next event.</p>\n<p><strong>Level-Triggered Events</strong>\nEvent notification mode where events are delivered whenever the condition is true (e.g., data is available), making it easier to program but potentially less efficient than edge-triggered mode.</p>\n<h3 id=\"load-balancing\">Load Balancing</h3>\n<p><strong>Round-Robin</strong>\nA load balancing algorithm that distributes requests by cycling through backend servers in order. Each server receives an equal number of requests over time, regardless of their current load or capacity.</p>\n<p><strong>Least-Connections</strong>\nA load balancing algorithm that routes requests to the backend server with the fewest active connections. This helps balance load more dynamically than round-robin when requests have varying processing times.</p>\n<p><strong>Weighted Distribution</strong>\nLoad balancing that accounts for different server capacities by assigning weights to each server. Servers with higher weights receive proportionally more requests than those with lower weights.</p>\n<p><strong>IP Hash</strong>\nA load balancing method that uses a hash of the client&#39;s IP address to consistently route requests from the same client to the same backend server, providing session affinity.</p>\n<p><strong>Session Affinity</strong>\nThe practice of routing requests from the same client session to the same backend server, ensuring that session state stored on the server remains accessible across requests.</p>\n<p><strong>Sticky Sessions</strong>\nAnother term for session affinity, emphasizing that client sessions &quot;stick&quot; to particular backend servers for the duration of the session.</p>\n<p><strong>Health Checking</strong>\nThe process of periodically testing backend servers to determine their availability and readiness to handle requests. Failed health checks remove servers from the active pool.</p>\n<p><strong>Failure Threshold</strong>\nThe number of consecutive health check failures required before marking a backend server as unhealthy and removing it from the load balancing rotation.</p>\n<p><strong>Success Threshold</strong>\nThe number of consecutive health check successes required before marking a previously failed backend server as healthy and returning it to the load balancing rotation.</p>\n<p><strong>Graceful Degradation</strong>\nThe ability to continue operating with reduced functionality when some backend servers fail, rather than experiencing complete system failure.</p>\n<p><strong>Connection Count</strong>\nThe number of active connections currently being handled by a backend server, used by least-connections load balancing algorithms to make routing decisions.</p>\n<p><strong>Backend Selection</strong>\nThe process of choosing which available backend server should handle an incoming request based on the configured load balancing algorithm and server health status.</p>\n<h3 id=\"caching\">Caching</h3>\n<p><strong>Cache Hit</strong>\nA request for which a valid cached response exists and can be returned to the client without contacting the backend server. This improves response time and reduces backend load.</p>\n<p><strong>Cache Miss</strong>\nA request for which no cached response exists or the cached response is stale, requiring the proxy to forward the request to a backend server.</p>\n<p><strong>TTL (Time To Live)</strong>\nThe duration for which a cached entry remains valid before it expires and must be refreshed from the backend server.</p>\n<p><strong>TTL Expiration</strong>\nThe process of cached entries becoming stale due to exceeding their time-to-live limits, requiring revalidation or refresh from the backend.</p>\n<p><strong>Cache Key</strong>\nA unique identifier generated from request attributes (method, URL, headers) used to store and retrieve cached responses. Proper key generation is crucial for cache correctness.</p>\n<p><strong>Cache-Control Header</strong>\nHTTP header containing directives that specify caching behavior, including whether responses can be cached, for how long, and under what conditions.</p>\n<p><strong>ETag (Entity Tag)</strong>\nA unique identifier assigned to a specific version of a resource, used for cache validation through conditional requests to determine if cached content is still current.</p>\n<p><strong>Last-Modified Header</strong>\nHTTP header indicating when a resource was last changed, used for cache validation through conditional requests with If-Modified-Since headers.</p>\n<p><strong>Conditional Request</strong>\nHTTP requests that include headers like If-Modified-Since or If-None-Match to allow servers to respond with 304 Not Modified if the cached version is still current.</p>\n<p><strong>304 Not Modified</strong>\nHTTP status code indicating that a cached response is still valid, sent in response to conditional requests when the resource hasn&#39;t changed since the cached version.</p>\n<p><strong>Vary Header</strong>\nHTTP response header indicating which request headers were used to generate the response, affecting cache key generation to ensure proper cache segmentation.</p>\n<p><strong>LRU (Least Recently Used)</strong>\nA cache eviction policy that removes the least recently accessed entries when the cache reaches its capacity limit, keeping frequently accessed content in cache longer.</p>\n<p><strong>Cache Invalidation</strong>\nThe process of removing or marking cached entries as invalid, either due to TTL expiration, explicit purge requests, or backend error conditions.</p>\n<p><strong>Cache Validation</strong>\nThe process of checking whether a cached response is still valid by sending conditional requests to the backend server.</p>\n<p><strong>No-Cache Directive</strong>\nCache-Control directive indicating that cached responses must be validated with the origin server before being served to clients.</p>\n<p><strong>No-Store Directive</strong>\nCache-Control directive indicating that responses must not be stored in any cache, typically used for sensitive or highly dynamic content.</p>\n<p><strong>Max-Age Directive</strong>\nCache-Control directive specifying the maximum time in seconds that a response may be cached before it becomes stale and requires revalidation.</p>\n<h3 id=\"ssltls-and-security\">SSL/TLS and Security</h3>\n<p><strong>TLS Context</strong>\nThe cryptographic configuration and state information for SSL/TLS connections, including certificates, private keys, cipher preferences, and protocol versions.</p>\n<p><strong>SSL Context</strong>\nLegacy term for TLS context, still commonly used even though TLS has replaced SSL in modern implementations.</p>\n<p><strong>SNI (Server Name Indication)</strong>\nA TLS extension that allows clients to specify which hostname they&#39;re connecting to, enabling a single IP address to serve multiple SSL certificates for different domains.</p>\n<p><strong>Certificate Chain</strong>\nThe sequence of certificates from the server&#39;s leaf certificate up to a trusted root CA certificate, required for clients to verify the server&#39;s authenticity.</p>\n<p><strong>Wildcard Certificate</strong>\nAn SSL certificate valid for multiple subdomains of a domain (e.g., *.example.com covers api.example.com, <a href=\"http://www.example.com\">www.example.com</a>, etc.).</p>\n<p><strong>Subject Alternative Name (SAN)</strong>\nX.509 certificate extension that allows a single certificate to be valid for multiple hostnames, providing an alternative to wildcard certificates.</p>\n<p><strong>Cipher Suite</strong>\nA combination of encryption algorithms used in TLS connections, including key exchange, authentication, bulk encryption, and message authentication algorithms.</p>\n<p><strong>Perfect Forward Secrecy</strong>\nA security property ensuring that session keys cannot be derived from long-term keys, so compromising long-term keys doesn&#39;t compromise past communication sessions.</p>\n<p><strong>AEAD Cipher</strong>\nAuthenticated Encryption with Associated Data cipher that provides both confidentiality and authenticity in a single operation, preferred in modern TLS implementations.</p>\n<p><strong>TLS Handshake</strong>\nThe initial negotiation process between client and server to establish encryption parameters, exchange certificates, and derive session keys for secure communication.</p>\n<p><strong>Certificate Validation</strong>\nThe process of verifying that a server&#39;s certificate is valid, properly signed by a trusted CA, not expired, and matches the requested hostname.</p>\n<p><strong>Session Resumption</strong>\nTLS optimization that allows clients and servers to reuse previously established session parameters, reducing handshake overhead for subsequent connections.</p>\n<p><strong>Cipher Preference</strong>\nThe order in which cipher suites are preferred during TLS negotiation, typically prioritizing stronger, more secure cipher suites over weaker alternatives.</p>\n<h3 id=\"error-handling-and-recovery\">Error Handling and Recovery</h3>\n<p><strong>Cascade Failure</strong>\nA failure propagation pattern where the failure of one component triggers failures in dependent components, potentially causing widespread system failure.</p>\n<p><strong>Circuit Breaker</strong>\nA design pattern that prevents operations when error rates exceed configured thresholds, allowing systems to fail fast and recover more quickly.</p>\n<p><strong>Exponential Backoff</strong>\nA retry strategy where the delay between retry attempts increases exponentially, reducing load on failing systems and improving recovery chances.</p>\n<p><strong>Error Sanitization</strong>\nThe practice of removing sensitive information (internal paths, stack traces, configuration details) from error messages shown to clients.</p>\n<p><strong>Graceful Shutdown</strong>\nThe process of cleanly stopping a server by finishing in-flight requests, closing connections properly, and releasing resources before termination.</p>\n<p><strong>Health Check Endpoint</strong>\nA specific URL path that backend servers expose to indicate their readiness to handle requests, used by load balancers for health monitoring.</p>\n<p><strong>Retry Logic</strong>\nAutomated mechanisms for retrying failed operations with appropriate delays and limits to handle transient failures without overwhelming systems.</p>\n<p><strong>Fallback Mechanism</strong>\nAlternative behavior implemented when primary systems fail, such as serving cached content when backends are unavailable.</p>\n<p><strong>Dead Letter Queue</strong>\nA storage mechanism for requests that cannot be processed successfully after multiple retry attempts, allowing for later analysis or manual intervention.</p>\n<p><strong>Bulkhead Pattern</strong>\nAn isolation strategy that prevents failures in one part of the system from affecting other parts, similar to watertight compartments in ships.</p>\n<h3 id=\"performance-and-monitoring\">Performance and Monitoring</h3>\n<p><strong>Latency</strong>\nThe time delay between sending a request and receiving a response, typically measured in milliseconds for HTTP operations.</p>\n<p><strong>Throughput</strong>\nThe number of requests processed per unit time, typically measured in requests per second (RPS) for reverse proxy performance.</p>\n<p><strong>Connection Multiplexing</strong>\nThe ability to handle multiple requests simultaneously over a single connection, particularly important in HTTP/2 implementations.</p>\n<p><strong>Keep-Alive Timeout</strong>\nThe duration a connection remains open waiting for additional requests before being closed to free up resources.</p>\n<p><strong>Request Rate Limiting</strong>\nControlling the number of requests accepted from clients over a specific time period to prevent overload and ensure fair resource usage.</p>\n<p><strong>Response Time Percentiles</strong>\nStatistical measures (P50, P95, P99) indicating the response time below which a certain percentage of requests are served, useful for understanding performance distribution.</p>\n<p><strong>Memory Footprint</strong>\nThe amount of system memory used by the reverse proxy, important for capacity planning and resource optimization.</p>\n<p><strong>File Descriptor Usage</strong>\nThe number of file descriptors (handles for files, sockets, etc.) used by the proxy, as each connection typically requires at least one file descriptor.</p>\n<p><strong>CPU Utilization</strong>\nThe percentage of available CPU resources being used by the proxy, affecting its ability to handle concurrent connections and requests.</p>\n<p><strong>Bandwidth Utilization</strong>\nThe amount of network bandwidth consumed by the proxy for client and backend communications, important for capacity planning.</p>\n<h3 id=\"testing-and-development\">Testing and Development</h3>\n<p><strong>Unit Testing</strong>\nTesting individual components in isolation using mock implementations of dependencies to verify correct behavior under various conditions.</p>\n<p><strong>Integration Testing</strong>\nTesting interactions between multiple components to ensure they work correctly together and handle data flow properly.</p>\n<p><strong>Milestone Verification</strong>\nPredefined checkpoints that validate implementation progress, ensuring each milestone&#39;s acceptance criteria are met before proceeding.</p>\n<p><strong>Synthetic Testing</strong>\nUsing artificially generated test data and scenarios to validate system behavior under controlled conditions.</p>\n<p><strong>Load Testing</strong>\nTesting system performance under high request volumes to identify bottlenecks and capacity limits.</p>\n<p><strong>Stress Testing</strong>\nTesting system behavior under extreme conditions beyond normal operating parameters to identify failure modes and recovery behavior.</p>\n<p><strong>Mock Implementation</strong>\nFake components that simulate real behavior for testing purposes, allowing isolation of the component under test.</p>\n<p><strong>Test Harness</strong>\nA framework that automates test execution, result collection, and validation across multiple test scenarios.</p>\n<p><strong>Deterministic Testing</strong>\nTests designed to produce predictable, repeatable outcomes regardless of execution timing or environment variations.</p>\n<p><strong>Regression Testing</strong>\nRe-running existing tests after code changes to ensure new modifications don&#39;t break previously working functionality.</p>\n<h3 id=\"architecture-and-design-patterns\">Architecture and Design Patterns</h3>\n<p><strong>Component Architecture</strong>\nA design approach that breaks the system into discrete, loosely-coupled components with well-defined responsibilities and interfaces.</p>\n<p><strong>Dependency Injection</strong>\nA design pattern where components receive their dependencies through constructor parameters or setters rather than creating them directly.</p>\n<p><strong>Observer Pattern</strong>\nA design pattern where components register to receive notifications about events or state changes in other components.</p>\n<p><strong>Factory Pattern</strong>\nA creational pattern that provides an interface for creating objects without specifying their concrete classes.</p>\n<p><strong>Singleton Pattern</strong>\nA design pattern ensuring only one instance of a class exists, commonly used for global configuration and resource managers.</p>\n<p><strong>State Pattern</strong>\nA behavioral pattern that allows objects to change their behavior based on internal state changes, useful for connection and parser state management.</p>\n<p><strong>Strategy Pattern</strong>\nA behavioral pattern that defines a family of algorithms (like load balancing strategies) and makes them interchangeable at runtime.</p>\n<p><strong>Facade Pattern</strong>\nA structural pattern that provides a simplified interface to a complex subsystem, hiding implementation details from clients.</p>\n<h3 id=\"network-and-system-programming\">Network and System Programming</h3>\n<p><strong>Epoll</strong>\nA Linux system call for efficient I/O event notification that can monitor many file descriptors for events without the overhead of polling each one individually.</p>\n<p><strong>Kqueue</strong>\nA BSD system call similar to epoll, providing scalable event notification for file descriptors and other system events.</p>\n<p><strong>File Descriptor</strong>\nAn operating system handle representing an open file, socket, or other I/O resource, with each process having a limited number available.</p>\n<p><strong>Socket Programming</strong>\nNetwork programming using BSD socket APIs to create, bind, listen, accept, connect, send, and receive data over TCP/UDP connections.</p>\n<p><strong>TCP Nodelay</strong>\nA socket option that disables Nagle&#39;s algorithm, reducing latency by immediately sending small packets rather than waiting to accumulate more data.</p>\n<p><strong>SO_REUSEADDR</strong>\nA socket option allowing immediate reuse of local addresses, particularly useful for server sockets that need to restart quickly.</p>\n<p><strong>Buffer Management</strong>\nTechniques for efficiently handling data buffers during network I/O operations, including allocation, reuse, and memory management strategies.</p>\n<p><strong>Memory Pool</strong>\nA memory management technique that pre-allocates large blocks of memory and suballocates from them to reduce allocation overhead and fragmentation.</p>\n<h3 id=\"extension-and-plugin-architecture\">Extension and Plugin Architecture</h3>\n<p><strong>Extension Architecture</strong>\nA framework for adding new functionality to the reverse proxy without modifying core components, enabling modularity and customization.</p>\n<p><strong>Plugin System</strong>\nA modular architecture allowing runtime loading of additional features through dynamically loaded libraries or modules.</p>\n<p><strong>Event-Driven Hooks</strong>\nCallback mechanisms that allow extensions to intercept and modify request processing at specific points in the pipeline.</p>\n<p><strong>Rate Limiting</strong>\nControlling request frequency from clients to prevent overload and ensure fair resource usage across multiple clients.</p>\n<p><strong>Web Application Firewall (WAF)</strong>\nSecurity extension that examines HTTP requests for malicious patterns and blocks potentially harmful traffic.</p>\n<p><strong>Authentication Extension</strong>\nModule responsible for verifying client identity and authorization before allowing access to backend services.</p>\n<p><strong>Monitoring Extension</strong>\nModule that collects metrics, logs, and observability data about proxy operations and performance.</p>\n<p><strong>Multi-Tenancy</strong>\nArchitecture pattern for serving multiple isolated customers or applications from a single proxy instance with proper resource isolation.</p>\n<p><strong>Service Mesh Integration</strong>\nFeatures for integrating with distributed system coordination platforms that provide service discovery, load balancing, and observability.</p>\n<p><strong>Content Transformation</strong>\nExtensions that modify response content, headers, or format before delivering to clients, such as compression or format conversion.</p>\n<h3 id=\"acronyms-and-abbreviations\">Acronyms and Abbreviations</h3>\n<p><strong>HTTP</strong>: HyperText Transfer Protocol\n<strong>HTTPS</strong>: HyperText Transfer Protocol Secure<br><strong>SSL</strong>: Secure Sockets Layer\n<strong>TLS</strong>: Transport Layer Security\n<strong>TCP</strong>: Transmission Control Protocol\n<strong>UDP</strong>: User Datagram Protocol\n<strong>DNS</strong>: Domain Name System\n<strong>IP</strong>: Internet Protocol\n<strong>URL</strong>: Uniform Resource Locator\n<strong>URI</strong>: Uniform Resource Identifier\n<strong>API</strong>: Application Programming Interface\n<strong>JSON</strong>: JavaScript Object Notation\n<strong>XML</strong>: eXtensible Markup Language\n<strong>MIME</strong>: Multipurpose Internet Mail Extensions\n<strong>CORS</strong>: Cross-Origin Resource Sharing\n<strong>CDN</strong>: Content Delivery Network\n<strong>DDoS</strong>: Distributed Denial of Service\n<strong>CA</strong>: Certificate Authority\n<strong>CRL</strong>: Certificate Revocation List\n<strong>OCSP</strong>: Online Certificate Status Protocol\n<strong>RSA</strong>: Rivest-Shamir-Adleman (encryption algorithm)\n<strong>AES</strong>: Advanced Encryption Standard\n<strong>SHA</strong>: Secure Hash Algorithm\n<strong>HMAC</strong>: Hash-based Message Authentication Code\n<strong>CSRF</strong>: Cross-Site Request Forgery\n<strong>XSS</strong>: Cross-Site Scripting\n<strong>SQL</strong>: Structured Query Language\n<strong>REST</strong>: Representational State Transfer\n<strong>SOAP</strong>: Simple Object Access Protocol\n<strong>gRPC</strong>: Google Remote Procedure Call\n<strong>WebSocket</strong>: Web Socket Protocol\n<strong>SPDY</strong>: SPeeDY (HTTP/2 predecessor)\n<strong>QUIC</strong>: Quick UDP Internet Connections\n<strong>MTU</strong>: Maximum Transmission Unit\n<strong>MSS</strong>: Maximum Segment Size\n<strong>TTL</strong>: Time To Live\n<strong>QoS</strong>: Quality of Service\n<strong>SLA</strong>: Service Level Agreement\n<strong>RTO</strong>: Request Time Out\n<strong>RTT</strong>: Round Trip Time\n<strong>ACK</strong>: Acknowledgment\n<strong>SYN</strong>: Synchronize\n<strong>FIN</strong>: Finish\n<strong>PSH</strong>: Push\n<strong>RST</strong>: Reset\n<strong>URG</strong>: Urgent</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides practical guidance for implementing reverse proxy components with proper terminology usage throughout the codebase.</p>\n<h4 id=\"a-technology-recommendations\">A. Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Parser</td>\n<td>Manual state machine with <code>HttpParser</code></td>\n<td>ANTLR/Yacc generated parser</td>\n</tr>\n<tr>\n<td>Event Loop</td>\n<td>Basic epoll with <code>EventDispatcher</code></td>\n<td>libevent/libuv wrapper</td>\n</tr>\n<tr>\n<td>SSL/TLS</td>\n<td>OpenSSL with <code>SSLTermination</code></td>\n<td>BoringSSL or wolfSSL</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Simple file logging with <code>LogLevel</code></td>\n<td>Structured logging with syslog</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>INI file parsing with <code>ProxyConfig</code></td>\n<td>YAML/JSON with schema validation</td>\n</tr>\n<tr>\n<td>Testing</td>\n<td>Custom test framework</td>\n<td>CUnit/Unity testing framework</td>\n</tr>\n</tbody></table>\n<h4 id=\"b-recommended-file-structure\">B. Recommended File Structure</h4>\n<p>The codebase should be organized to reflect the component architecture and terminology used throughout this glossary:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>reverse-proxy/\n├── src/\n│   ├── core/\n│   │   ├── proxy_server.c           ← Main ProxyServer implementation\n│   │   ├── proxy_server.h           ← Public ProxyServer interface\n│   │   └── proxy_config.c           ← ProxyConfig loading and validation\n│   ├── http/\n│   │   ├── http_parser.c            ← HttpParser state machine\n│   │   ├── http_request.c           ← HttpRequest manipulation\n│   │   └── http_response.c          ← HttpResponse handling\n│   ├── connection/\n│   │   ├── connection_manager.c     ← ConnectionManager with event-driven I/O\n│   │   ├── connection_pool.c        ← ConnectionPool per backend\n│   │   └── timer_wheel.c            ← TimerWheel timeout management\n│   ├── load_balancer/\n│   │   ├── load_balancer.c          ← LoadBalancer algorithms\n│   │   ├── backend_server.c         ← BackendServer health checking\n│   │   └── health_checker.c         ← Health checking implementation\n│   ├── cache/\n│   │   ├── cache_engine.c           ← CacheEngine with LRU eviction\n│   │   ├── cache_control.c          ← CacheControl header parsing\n│   │   └── lru_list.c              ← LRUList implementation\n│   ├── ssl/\n│   │   ├── ssl_termination.c        ← SSLTermination with SNI support\n│   │   └── ssl_utils.c              ← Certificate loading utilities\n│   ├── error/\n│   │   ├── error_handler.c          ← ErrorHandler for recovery coordination\n│   │   └── recovery_manager.c       ← RecoveryManager for failure handling\n│   └── utils/\n│       ├── buffer.c                 ← Buffer management utilities\n│       ├── hashtable.c              ← HashTable implementation\n│       └── logger.c                 ← Logging with LogLevel support\n├── include/\n│   └── reverse_proxy/               ← Public header files\n├── tests/\n│   ├── unit/                        ← Unit tests for individual components\n│   ├── integration/                 ← Integration tests for component interactions\n│   └── mocks/                       ← MockSocket and test utilities\n├── config/\n│   └── proxy.conf                   ← Example ProxyConfig file\n└── docs/\n    └── terminology.md               ← This glossary for reference</code></pre></div>\n\n<h4 id=\"c-terminology-usage-in-code\">C. Terminology Usage in Code</h4>\n<p>When implementing components, use the exact terminology from this glossary in comments, variable names, and function names. This creates consistency between the design documentation and implementation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">// Example: Connection state management using proper terminology</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CONNECTION_IDLE,</span><span style=\"color:#6A737D\">              // Connection waiting for new request</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CONNECTION_READING_REQUEST,</span><span style=\"color:#6A737D\">   // Receiving HTTP request from client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CONNECTION_FORWARDING,</span><span style=\"color:#6A737D\">        // Forwarding request to backend server</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CONNECTION_READING_RESPONSE,</span><span style=\"color:#6A737D\">  // Receiving response from backend</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CONNECTION_WRITING_RESPONSE,</span><span style=\"color:#6A737D\">  // Sending response back to client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CONNECTION_CLOSING</span><span style=\"color:#6A737D\">           // Graceful connection shutdown</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} ConnectionState;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// Example: Load balancing algorithm enumeration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> enum</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_ROUND_ROBIN,</span><span style=\"color:#6A737D\">              // Round-robin backend selection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_LEAST_CONNECTIONS,</span><span style=\"color:#6A737D\">        // Least-connections algorithm</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_WEIGHTED_ROUND_ROBIN,</span><span style=\"color:#6A737D\">     // Weighted distribution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    LB_IP_HASH</span><span style=\"color:#6A737D\">                   // IP hash for session affinity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">} LoadBalancingAlgorithm;</span></span></code></pre></div>\n\n<h4 id=\"d-common-implementation-terminology-mistakes\">D. Common Implementation Terminology Mistakes</h4>\n<table>\n<thead>\n<tr>\n<th>Incorrect Term</th>\n<th>Correct Term</th>\n<th>Explanation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&quot;Upstream proxy&quot;</td>\n<td>&quot;Reverse proxy&quot;</td>\n<td>Avoids confusion with forward proxies</td>\n</tr>\n<tr>\n<td>&quot;SSL connection&quot;</td>\n<td>&quot;TLS connection&quot;</td>\n<td>Uses modern terminology</td>\n</tr>\n<tr>\n<td>&quot;Connection reuse&quot;</td>\n<td>&quot;Connection pooling&quot;</td>\n<td>More specific technical term</td>\n</tr>\n<tr>\n<td>&quot;Request caching&quot;</td>\n<td>&quot;Response caching&quot;</td>\n<td>Clarifies what is actually cached</td>\n</tr>\n<tr>\n<td>&quot;Server selection&quot;</td>\n<td>&quot;Backend selection&quot;</td>\n<td>Distinguishes from client/proxy server</td>\n</tr>\n<tr>\n<td>&quot;Health monitoring&quot;</td>\n<td>&quot;Health checking&quot;</td>\n<td>Standard industry terminology</td>\n</tr>\n<tr>\n<td>&quot;Certificate reload&quot;</td>\n<td>&quot;Certificate rotation&quot;</td>\n<td>Different concepts</td>\n</tr>\n<tr>\n<td>&quot;Error recovery&quot;</td>\n<td>&quot;Failure recovery&quot;</td>\n<td>More precise terminology</td>\n</tr>\n</tbody></table>\n<h4 id=\"e-documentation-and-comment-guidelines\">E. Documentation and Comment Guidelines</h4>\n<p>Use consistent terminology in all code comments and documentation:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">c</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * connection_manager_acquire_backend - Acquire backend connection from pool</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * </span><span style=\"color:#F97583\">@manager:</span><span style=\"color:#6A737D\"> ConnectionManager instance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * </span><span style=\"color:#F97583\">@backend:</span><span style=\"color:#6A737D\"> Target BackendServer for connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * </span><span style=\"color:#F97583\">@timeout_ms:</span><span style=\"color:#6A737D\"> Connection timeout in milliseconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Attempts to acquire a connection from the connection pool for the specified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * backend server. If no idle connections are available, creates a new connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * up to the pool's maximum limit. Uses LIFO strategy for cache locality.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> *</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns: Connection pointer on success, NULL on failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Connection</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> connection_manager_acquire_backend</span><span style=\"color:#E1E4E8\">(ConnectionManager</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> manager</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                               BackendServer</span><span style=\"color:#F97583\">*</span><span style=\"color:#FFAB70\"> backend</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                                               int</span><span style=\"color:#FFAB70\"> timeout_ms</span><span style=\"color:#E1E4E8\">);</span></span></code></pre></div>\n\n<h4 id=\"f-debugging-terminology-reference\">F. Debugging Terminology Reference</h4>\n<p>When debugging reverse proxy issues, use precise terminology to communicate problems effectively:</p>\n<table>\n<thead>\n<tr>\n<th>Problem Area</th>\n<th>Correct Terminology</th>\n<th>Avoid</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connection issues</td>\n<td>&quot;Connection pool exhausted&quot;</td>\n<td>&quot;Out of connections&quot;</td>\n</tr>\n<tr>\n<td>SSL problems</td>\n<td>&quot;TLS handshake failure&quot;</td>\n<td>&quot;SSL error&quot;</td>\n</tr>\n<tr>\n<td>Parsing errors</td>\n<td>&quot;HTTP parser state machine error&quot;</td>\n<td>&quot;Bad request&quot;</td>\n</tr>\n<tr>\n<td>Load balancing</td>\n<td>&quot;Backend server health check failure&quot;</td>\n<td>&quot;Server down&quot;</td>\n</tr>\n<tr>\n<td>Caching</td>\n<td>&quot;Cache miss due to TTL expiration&quot;</td>\n<td>&quot;Cache not working&quot;</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>&quot;High connection establishment latency&quot;</td>\n<td>&quot;Slow connections&quot;</td>\n</tr>\n</tbody></table>\n<p>This terminology consistency ensures clear communication between team members and accurate problem diagnosis throughout the development process.</p>\n","toc":[{"level":1,"text":"Reverse Proxy: Design Document","id":"reverse-proxy-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"The Reverse Proxy Problem","id":"the-reverse-proxy-problem"},{"level":3,"text":"Existing Solutions Analysis","id":"existing-solutions-analysis"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Core Functional Goals","id":"core-functional-goals"},{"level":3,"text":"Performance and Quality Goals","id":"performance-and-quality-goals"},{"level":3,"text":"Explicit Non-Goals","id":"explicit-non-goals"},{"level":3,"text":"Architecture Decision Records","id":"architecture-decision-records"},{"level":3,"text":"Success Criteria and Validation","id":"success-criteria-and-validation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Core Configuration Structure","id":"core-configuration-structure"},{"level":4,"text":"Configuration Loading Implementation","id":"configuration-loading-implementation"},{"level":4,"text":"Goal Validation Checklist","id":"goal-validation-checklist"},{"level":4,"text":"Common Implementation Pitfalls","id":"common-implementation-pitfalls"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Component Overview","id":"component-overview"},{"level":3,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Core Data Types","id":"core-data-types"},{"level":4,"text":"Buffer Management","id":"buffer-management"},{"level":4,"text":"HTTP Message Structures","id":"http-message-structures"},{"level":4,"text":"Connection State Management","id":"connection-state-management"},{"level":4,"text":"Performance Metrics and Monitoring","id":"performance-metrics-and-monitoring"},{"level":3,"text":"Configuration Model","id":"configuration-model"},{"level":4,"text":"Primary Configuration Structure","id":"primary-configuration-structure"},{"level":4,"text":"Backend Server Configuration","id":"backend-server-configuration"},{"level":4,"text":"Load Balancing Algorithm Configuration","id":"load-balancing-algorithm-configuration"},{"level":4,"text":"Cache Configuration Model","id":"cache-configuration-model"},{"level":4,"text":"Logging and Monitoring Configuration","id":"logging-and-monitoring-configuration"},{"level":3,"text":"Common Data Model Pitfalls","id":"common-data-model-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Buffer Implementation","id":"buffer-implementation"},{"level":4,"text":"Hash Table Infrastructure","id":"hash-table-infrastructure"},{"level":4,"text":"HTTP Message Structures","id":"http-message-structures"},{"level":4,"text":"Configuration Management","id":"configuration-management"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"HTTP Parser Component","id":"http-parser-component"},{"level":3,"text":"Parser Architecture","id":"parser-architecture"},{"level":3,"text":"Parser Design Decisions","id":"parser-design-decisions"},{"level":3,"text":"Common Parser Pitfalls","id":"common-parser-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Connection Manager Component","id":"connection-manager-component"},{"level":3,"text":"Connection Lifecycle Management","id":"connection-lifecycle-management"},{"level":4,"text":"Connection State Tracking","id":"connection-state-tracking"},{"level":4,"text":"Connection Timeout Management","id":"connection-timeout-management"},{"level":3,"text":"Connection Pooling Strategy","id":"connection-pooling-strategy"},{"level":4,"text":"Pool Architecture and Management","id":"pool-architecture-and-management"},{"level":4,"text":"Connection Pool Operations","id":"connection-pool-operations"},{"level":4,"text":"Pool Health Management","id":"pool-health-management"},{"level":4,"text":"Pool Sizing and Auto-scaling","id":"pool-sizing-and-auto-scaling"},{"level":3,"text":"Connection Management Decisions","id":"connection-management-decisions"},{"level":4,"text":"Connection State Management Decision","id":"connection-state-management-decision"},{"level":4,"text":"Connection Pooling Algorithm Decision","id":"connection-pooling-algorithm-decision"},{"level":4,"text":"Timeout Management Decision","id":"timeout-management-decision"},{"level":4,"text":"Connection Validation Decision","id":"connection-validation-decision"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Connection Manager Infrastructure","id":"connection-manager-infrastructure"},{"level":4,"text":"Core Connection Management Logic","id":"core-connection-management-logic"},{"level":4,"text":"Connection Pool Management Implementation","id":"connection-pool-management-implementation"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Connection Management Issues","id":"debugging-connection-management-issues"},{"level":2,"text":"Load Balancer Component","id":"load-balancer-component"},{"level":3,"text":"Load Balancing Algorithms","id":"load-balancing-algorithms"},{"level":3,"text":"Health Checking System","id":"health-checking-system"},{"level":3,"text":"Load Balancing Decisions","id":"load-balancing-decisions"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Cache Engine Component","id":"cache-engine-component"},{"level":3,"text":"Caching Strategy","id":"caching-strategy"},{"level":3,"text":"HTTP Cache-Control Handling","id":"http-cache-control-handling"},{"level":3,"text":"Caching Design Decisions","id":"caching-design-decisions"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"SSL Termination Component","id":"ssl-termination-component"},{"level":3,"text":"TLS Context Management","id":"tls-context-management"},{"level":3,"text":"Server Name Indication","id":"server-name-indication"},{"level":3,"text":"SSL Termination Decisions","id":"ssl-termination-decisions"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Interactions and Data Flow","id":"interactions-and-data-flow"},{"level":3,"text":"Request Processing Flow","id":"request-processing-flow"},{"level":4,"text":"Phase 1: Connection Establishment and Initial Processing","id":"phase-1-connection-establishment-and-initial-processing"},{"level":4,"text":"Phase 2: Cache Lookup and Backend Selection","id":"phase-2-cache-lookup-and-backend-selection"},{"level":4,"text":"Phase 3: Backend Communication and Connection Management","id":"phase-3-backend-communication-and-connection-management"},{"level":4,"text":"Phase 4: Response Caching and Client Delivery","id":"phase-4-response-caching-and-client-delivery"},{"level":3,"text":"Inter-Component Communication","id":"inter-component-communication"},{"level":4,"text":"Communication Architecture and Patterns","id":"communication-architecture-and-patterns"},{"level":4,"text":"Component Interface Specifications","id":"component-interface-specifications"},{"level":4,"text":"Data Flow Coordination","id":"data-flow-coordination"},{"level":4,"text":"Synchronization and Thread Safety","id":"synchronization-and-thread-safety"},{"level":4,"text":"Component Startup and Shutdown Coordination","id":"component-startup-and-shutdown-coordination"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Failure Modes and Detection","id":"failure-modes-and-detection"},{"level":3,"text":"Recovery and Fallback Strategies","id":"recovery-and-fallback-strategies"},{"level":3,"text":"Common Pitfalls in Error Handling","id":"common-pitfalls-in-error-handling"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Unit Testing Approach","id":"unit-testing-approach"},{"level":3,"text":"Integration Testing","id":"integration-testing"},{"level":3,"text":"Milestone Verification Checkpoints","id":"milestone-verification-checkpoints"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Common Bug Patterns","id":"common-bug-patterns"},{"level":4,"text":"HTTP Parser Component Issues","id":"http-parser-component-issues"},{"level":4,"text":"Connection Manager Issues","id":"connection-manager-issues"},{"level":4,"text":"Load Balancer Issues","id":"load-balancer-issues"},{"level":4,"text":"Cache Engine Issues","id":"cache-engine-issues"},{"level":4,"text":"SSL Termination Issues","id":"ssl-termination-issues"},{"level":3,"text":"Debugging Techniques and Tools","id":"debugging-techniques-and-tools"},{"level":4,"text":"Systematic Debugging Approach","id":"systematic-debugging-approach"},{"level":4,"text":"Diagnostic Data Collection","id":"diagnostic-data-collection"},{"level":4,"text":"Component-Specific Debugging Tools","id":"component-specific-debugging-tools"},{"level":4,"text":"Memory and Resource Leak Detection","id":"memory-and-resource-leak-detection"},{"level":4,"text":"Network-Level Debugging","id":"network-level-debugging"},{"level":4,"text":"Performance Profiling and Bottleneck Analysis","id":"performance-profiling-and-bottleneck-analysis"},{"level":4,"text":"Systematic Root Cause Analysis","id":"systematic-root-cause-analysis"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Debugging Infrastructure Code","id":"debugging-infrastructure-code"},{"level":4,"text":"Core Logic Debugging Skeletons","id":"core-logic-debugging-skeletons"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Common Debugging Command Patterns","id":"common-debugging-command-patterns"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Strategic Extension Framework","id":"strategic-extension-framework"},{"level":3,"text":"Rate Limiting and Throttling","id":"rate-limiting-and-throttling"},{"level":3,"text":"Web Application Firewall (WAF)","id":"web-application-firewall-waf"},{"level":3,"text":"Monitoring and Observability","id":"monitoring-and-observability"},{"level":3,"text":"Authentication and Authorization","id":"authentication-and-authorization"},{"level":3,"text":"Content Transformation","id":"content-transformation"},{"level":3,"text":"Service Mesh Integration","id":"service-mesh-integration"},{"level":3,"text":"Multi-Tenancy Support","id":"multi-tenancy-support"},{"level":3,"text":"Design Extensibility Features","id":"design-extensibility-features"},{"level":3,"text":"Performance Considerations for Extensions","id":"performance-considerations-for-extensions"},{"level":3,"text":"Common Extension Pitfalls","id":"common-extension-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Core Reverse Proxy Concepts","id":"core-reverse-proxy-concepts"},{"level":3,"text":"HTTP Protocol and Parsing","id":"http-protocol-and-parsing"},{"level":3,"text":"Connection Management","id":"connection-management"},{"level":3,"text":"Load Balancing","id":"load-balancing"},{"level":3,"text":"Caching","id":"caching"},{"level":3,"text":"SSL/TLS and Security","id":"ssltls-and-security"},{"level":3,"text":"Error Handling and Recovery","id":"error-handling-and-recovery"},{"level":3,"text":"Performance and Monitoring","id":"performance-and-monitoring"},{"level":3,"text":"Testing and Development","id":"testing-and-development"},{"level":3,"text":"Architecture and Design Patterns","id":"architecture-and-design-patterns"},{"level":3,"text":"Network and System Programming","id":"network-and-system-programming"},{"level":3,"text":"Extension and Plugin Architecture","id":"extension-and-plugin-architecture"},{"level":3,"text":"Acronyms and Abbreviations","id":"acronyms-and-abbreviations"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"A. Technology Recommendations","id":"a-technology-recommendations"},{"level":4,"text":"B. Recommended File Structure","id":"b-recommended-file-structure"},{"level":4,"text":"C. Terminology Usage in Code","id":"c-terminology-usage-in-code"},{"level":4,"text":"D. Common Implementation Terminology Mistakes","id":"d-common-implementation-terminology-mistakes"},{"level":4,"text":"E. Documentation and Comment Guidelines","id":"e-documentation-and-comment-guidelines"},{"level":4,"text":"F. Debugging Terminology Reference","id":"f-debugging-terminology-reference"}],"title":"Reverse Proxy: Design Document","markdown":"# Reverse Proxy: Design Document\n\n\n## Overview\n\nA high-performance reverse proxy that accepts client connections, forwards requests to backend servers, and returns responses, solving the key challenge of efficiently managing concurrent connections while providing load balancing, caching, and SSL termination. The system handles the complexities of HTTP protocol parsing, connection pooling, and asynchronous I/O to maximize throughput and minimize latency.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** All milestones - this foundational understanding applies throughout the entire reverse proxy implementation journey.\n\nBuilding a reverse proxy might seem straightforward at first glance - accept requests, forward them to backend servers, and return responses. However, beneath this simple description lies a complex system that must handle thousands of concurrent connections, parse intricate HTTP protocols, manage connection lifecycles, and maintain high performance under varying load conditions. Understanding why reverse proxies are essential and what makes them architecturally challenging provides the foundation for making informed design decisions throughout the implementation process.\n\n### The Reverse Proxy Problem\n\nThink of a reverse proxy as a sophisticated receptionist in a large corporate building. When visitors arrive, the receptionist doesn't just blindly direct them to any available employee. Instead, she maintains detailed knowledge about which departments are currently busy, which employees are out sick, and which meeting rooms have the best equipment for specific types of meetings. She makes intelligent decisions about where to route each visitor based on their needs, current building capacity, and the availability of resources. Additionally, she remembers frequent visitors and can quickly access their preferred meeting locations from her files, avoiding the need to walk through the entire building directory each time.\n\nThis analogy captures the essence of what a **reverse proxy** accomplishes in network architecture. Unlike a forward proxy that sits between clients and the internet (acting on behalf of clients), a reverse proxy sits between clients and backend servers, acting on behalf of the servers. The proxy becomes the single point of contact for clients, while intelligently distributing their requests across multiple backend servers based on various criteria such as server health, current load, and request characteristics.\n\nThe fundamental challenge that reverse proxies solve is the **many-to-many connection problem**. Consider a web service that needs to handle 10,000 concurrent users, but each backend server can only handle 1,000 connections effectively. Without a reverse proxy, you would need to either over-provision individual servers (wasteful and expensive) or implement complex client-side load balancing logic (brittle and difficult to update). The reverse proxy elegantly solves this by maintaining a smaller number of persistent connections to backend servers while handling the full volume of client connections on the frontend.\n\nHowever, implementing this solution introduces several architectural challenges that make reverse proxy development particularly complex:\n\n**Connection State Management Challenge**: A reverse proxy must simultaneously manage two distinct connection contexts - the client-facing connection and the backend-facing connection. Each connection exists in its own lifecycle with different states (connecting, reading request, forwarding, reading response, writing response, closing), and these states must be carefully synchronized. The proxy cannot simply pass bytes between connections because it needs to understand the HTTP protocol structure to make intelligent routing decisions and handle error scenarios gracefully.\n\n**Protocol Parsing and Transformation Challenge**: HTTP appears simple on the surface, but the protocol contains numerous edge cases and variations that must be handled correctly. The proxy must parse incoming requests completely enough to extract routing information (Host headers, URL paths), while simultaneously preserving the original request structure for forwarding. Additionally, the proxy must handle protocol version differences - a client might connect via HTTP/2 while the backend server only supports HTTP/1.1, requiring protocol translation.\n\n**Asynchronous I/O Complexity**: To achieve high performance, a reverse proxy cannot afford to block threads waiting for I/O operations. This necessitates an event-driven architecture using asynchronous I/O primitives like `epoll` on Linux or `kqueue` on BSD systems. However, asynchronous programming introduces complexity in error handling, connection lifecycle management, and state tracking. The proxy must handle partial reads and writes gracefully, manage timeouts across multiple concurrent operations, and ensure that connection state remains consistent even when I/O operations complete in unpredictable orders.\n\n**Memory Management and Resource Limits**: Each active connection requires memory for buffers, connection state, and potentially cached data. A reverse proxy handling thousands of connections must carefully manage memory usage to avoid exhaustion. This includes implementing efficient buffer reuse strategies, setting appropriate limits on request sizes and connection counts, and ensuring that slow or malicious clients cannot consume unbounded resources through techniques like slowloris attacks.\n\n**Backend Health and Failure Handling**: Unlike simple load balancers that can assume backend servers are always available, a production reverse proxy must handle backend failures gracefully. This includes detecting when backend servers become unavailable, removing them from the active pool, and implementing retry logic with appropriate backoff strategies. The proxy must also handle partial failures - situations where a backend server accepts a connection but fails during request processing.\n\nThe interplay between these challenges creates emergent complexity. For example, when a backend server fails during request processing, the proxy must simultaneously clean up the backend connection, maintain the client connection, generate an appropriate error response, update its load balancing state, and ensure that any cached data related to the failed request is invalidated. Managing these interdependent concerns requires careful architectural planning and robust error handling throughout the system.\n\n![System Component Architecture](./diagrams/system-components.svg)\n\n### Existing Solutions Analysis\n\nUnderstanding how existing reverse proxy implementations approach these challenges provides valuable context for design decisions. Each solution makes different trade-offs between performance, complexity, and feature richness, reflecting the diverse requirements of their target environments.\n\n**NGINX** represents the dominant approach in production environments, built around an event-driven architecture using a master-worker process model. The master process handles configuration loading and worker process management, while worker processes handle actual request processing using asynchronous I/O. NGINX achieves exceptional performance by avoiding thread-per-connection models and instead using a small number of worker processes (typically one per CPU core) that handle thousands of connections each through event loops.\n\n| Aspect | NGINX Approach | Strengths | Weaknesses |\n|--------|----------------|-----------|------------|\n| Architecture | Master-worker with event loops | Excellent performance, proven scalability | Complex configuration, C codebase hard to modify |\n| Memory Model | Shared memory pools | Low memory overhead per connection | Memory pool tuning requires expertise |\n| Configuration | Declarative config files | Powerful and flexible | Complex syntax, requires restarts for changes |\n| Extensibility | C modules | High performance modules | High barrier to entry for custom logic |\n\nNGINX's design philosophy prioritizes performance and memory efficiency above ease of development. Its configuration system, while powerful, requires deep understanding of HTTP semantics and NGINX-specific concepts. The C-based module system enables high-performance extensions but creates a significant barrier for developers who need custom business logic in their reverse proxy.\n\n**HAProxy** takes a different approach, focusing specifically on load balancing with extensive health checking and traffic management features. Built around a single-threaded event loop model, HAProxy excels at connection management and provides sophisticated algorithms for backend server selection.\n\n| Aspect | HAProxy Approach | Strengths | Weaknesses |\n|--------|------------------|-----------|------------|\n| Architecture | Single-threaded event loop | Predictable performance, simpler debugging | Limited CPU scalability on multi-core systems |\n| Load Balancing | Advanced algorithms | Comprehensive health checks, detailed statistics | Less general-purpose than NGINX |\n| Configuration | Specialized DSL | Optimized for load balancing use cases | Learning curve for complex routing rules |\n| Observability | Built-in statistics | Excellent monitoring capabilities | Limited extensibility for custom metrics |\n\nHAProxy's single-threaded model provides predictable performance characteristics and simplifies reasoning about connection state, but limits its ability to fully utilize multi-core systems for CPU-intensive operations like SSL termination.\n\n**Envoy** represents a modern approach designed for cloud-native environments, built with observability, dynamic configuration, and service mesh integration as core requirements. Written in C++, Envoy uses a multi-threaded architecture with careful attention to lock-free data structures and thread-local storage.\n\n| Aspect | Envoy Approach | Strengths | Weaknesses |\n|--------|----------------|-----------|------------|\n| Architecture | Multi-threaded with thread-local workers | Good multi-core utilization | More complex than single-threaded designs |\n| Configuration | gRPC-based dynamic config | Can update configuration without restarts | Requires additional infrastructure (control plane) |\n| Extensibility | C++ filters and WASM | Flexible extension model | C++ expertise required for native extensions |\n| Observability | Built-in metrics and tracing | Excellent for microservices environments | Higher resource overhead than simpler proxies |\n\nEnvoy's dynamic configuration capabilities enable sophisticated deployment patterns but require additional infrastructure to manage the configuration distribution, making it more complex for simple use cases.\n\n**Cloud Load Balancers** (like AWS ALB, Google Cloud Load Balancing) represent fully managed solutions that abstract away the implementation complexity entirely. These services handle scaling, health checking, and SSL certificate management automatically, but provide limited customization options.\n\n| Aspect | Cloud Load Balancers | Strengths | Weaknesses |\n|--------|---------------------|-----------|------------|\n| Architecture | Fully managed | No operational overhead | Vendor lock-in, limited customization |\n| Scalability | Automatic scaling | Handles traffic spikes transparently | Cost can be unpredictable |\n| Features | Integrated with cloud services | SSL management, DDoS protection | Less control over routing logic |\n| Configuration | Web UI or APIs | Easy to get started | Advanced configurations may hit limitations |\n\nThe managed approach eliminates operational complexity but sacrifices the ability to implement custom business logic or optimize for specific use cases.\n\n> **Key Insight**: The choice between these approaches depends heavily on the specific requirements and constraints of your environment. NGINX excels in high-performance scenarios with relatively static configurations. HAProxy provides superior load balancing algorithms and health checking for traditional server environments. Envoy offers the most flexibility for dynamic, cloud-native environments. Managed solutions work well when standardized features meet your requirements and operational simplicity is prioritized over customization.\n\nFor our educational implementation, we need to balance learning value with implementation complexity. Our design will draw inspiration from NGINX's event-driven architecture for its proven performance characteristics, while incorporating some of Envoy's modularity concepts to make the codebase more approachable for learning purposes.\n\n> **Decision: Event-Driven Architecture with Modular Components**\n> - **Context**: We need an architecture that demonstrates production-quality concepts while remaining understandable for educational purposes\n> - **Options Considered**: \n>   1. Thread-per-connection model (simple but poor performance)\n>   2. Single-threaded event loop (simple but limited scalability)\n>   3. Multi-threaded event-driven with worker pools (complex but realistic)\n> - **Decision**: Multi-threaded event-driven architecture with clearly separated components\n> - **Rationale**: This approach teaches modern high-performance patterns while keeping each component focused and testable. The modular design allows learners to understand each piece independently before seeing how they interact.\n> - **Consequences**: Higher initial complexity but better representation of production systems. Each component can be developed and tested independently, making the learning process more manageable.\n\nThe architecture decision above shapes our entire implementation approach. Rather than building a monolithic proxy, we'll create distinct components (HTTP Parser, Connection Manager, Load Balancer, Cache Engine, SSL Termination) that communicate through well-defined interfaces. This mirrors how production systems achieve maintainability and testability while handling the inherent complexity of high-performance network programming.\n\nUnderstanding these existing solutions and their trade-offs provides essential context for the design decisions we'll make throughout our implementation. Each component we build will face similar challenges to those solved by NGINX, HAProxy, and Envoy, but our solutions will prioritize learning clarity and implementation understandability while still demonstrating the fundamental concepts that make production reverse proxies successful.\n\n### Implementation Guidance\n\nThis implementation guidance bridges the gap between understanding reverse proxy concepts and building a working system. The recommendations here focus on practical technology choices and project organization that will support learning while building toward a production-quality architecture.\n\n**A. Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| HTTP Parsing | Manual state machine with character-by-character parsing | HTTP parser library (http-parser, picohttpparser) |\n| Async I/O | Basic `select()` or `poll()` with non-blocking sockets | Platform-specific `epoll`/`kqueue` with event libraries |\n| SSL/TLS | OpenSSL with basic certificate loading | mbedTLS or BoringSSL with advanced features |\n| Configuration | Simple key-value file parsing | JSON/YAML with schema validation |\n| Logging | Printf-style logging to stdout/files | Structured logging with log levels and rotation |\n| Memory Management | Standard malloc/free with careful tracking | Custom memory pools and arena allocators |\n\nFor learning purposes, start with the simple options to understand the underlying concepts, then migrate to advanced options as your understanding deepens. The simple options expose more of the fundamental mechanisms, while advanced options provide production-ready performance and features.\n\n**B. Recommended Project Structure:**\n\n```\nreverse-proxy/\n├── src/\n│   ├── main.c                    ← Entry point and main event loop\n│   ├── config/\n│   │   ├── config.h              ← Configuration data structures\n│   │   ├── config.c              ← Configuration file parsing\n│   │   └── config_test.c         ← Configuration parsing tests\n│   ├── http/\n│   │   ├── parser.h              ← HTTP parsing interface\n│   │   ├── parser.c              ← HTTP request/response parsing\n│   │   ├── message.h             ← HTTP message data structures\n│   │   └── parser_test.c         ← HTTP parsing unit tests\n│   ├── connection/\n│   │   ├── manager.h             ← Connection management interface\n│   │   ├── manager.c             ← Connection lifecycle and pooling\n│   │   ├── pool.h                ← Connection pool data structures\n│   │   └── connection_test.c     ← Connection management tests\n│   ├── loadbalancer/\n│   │   ├── balancer.h            ← Load balancing algorithms interface\n│   │   ├── roundrobin.c          ← Round-robin implementation\n│   │   ├── healthcheck.h         ← Health checking interface\n│   │   └── balancer_test.c       ← Load balancing tests\n│   ├── cache/\n│   │   ├── cache.h               ← Cache engine interface\n│   │   ├── lru.c                 ← LRU cache implementation\n│   │   ├── cache_control.h       ← HTTP cache control parsing\n│   │   └── cache_test.c          ← Cache functionality tests\n│   ├── ssl/\n│   │   ├── termination.h         ← SSL termination interface\n│   │   ├── termination.c         ← TLS context and SNI handling\n│   │   └── ssl_test.c            ← SSL termination tests\n│   └── util/\n│       ├── buffer.h              ← Dynamic buffer management\n│       ├── buffer.c              ← Buffer implementation\n│       ├── logger.h              ← Logging utilities\n│       ├── logger.c              ← Logging implementation\n│       └── hashtable.h           ← Hash table for caching\n├── config/\n│   ├── proxy.conf                ← Example configuration file\n│   └── ssl/\n│       ├── server.crt            ← Example SSL certificate\n│       └── server.key            ← Example private key\n├── tests/\n│   ├── integration/              ← End-to-end tests\n│   └── fixtures/                 ← Test data and mock servers\n├── docs/\n│   └── api.md                    ← Component interfaces documentation\n├── Makefile                      ← Build configuration\n└── README.md                     ← Setup and usage instructions\n```\n\nThis structure separates concerns clearly, making it easier to understand and test individual components. Each component directory contains its interface header, implementation, and tests, following the principle that related code should live together.\n\n**C. Infrastructure Starter Code:**\n\nThe following utilities handle cross-cutting concerns that every component needs, allowing you to focus on the core reverse proxy logic rather than reimplementing basic infrastructure.\n\n**Dynamic Buffer Management** (`src/util/buffer.h` and `src/util/buffer.c`):\n```c\n#include <stddef.h>\n#include <stdbool.h>\n\n// Dynamic buffer for handling variable-length HTTP messages\ntypedef struct {\n    char *data;          // Buffer memory\n    size_t capacity;     // Total allocated size\n    size_t length;       // Current data length\n    size_t position;     // Current read/write position\n} Buffer;\n\n// Initialize a new buffer with initial capacity\nBuffer* buffer_create(size_t initial_capacity);\n\n// Ensure buffer has at least required_capacity bytes available\nbool buffer_ensure_capacity(Buffer *buf, size_t required_capacity);\n\n// Append data to buffer, growing if necessary\nbool buffer_append(Buffer *buf, const char *data, size_t length);\n\n// Read data from buffer starting at current position\nsize_t buffer_read(Buffer *buf, char *dest, size_t max_length);\n\n// Reset buffer position to beginning for reading\nvoid buffer_rewind(Buffer *buf);\n\n// Clear buffer contents but preserve allocated memory\nvoid buffer_clear(Buffer *buf);\n\n// Free buffer and all associated memory\nvoid buffer_destroy(Buffer *buf);\n```\n\n**Logging Infrastructure** (`src/util/logger.h` and `src/util/logger.c`):\n```c\n#include <stdio.h>\n\ntypedef enum {\n    LOG_DEBUG = 0,\n    LOG_INFO = 1,\n    LOG_WARN = 2,\n    LOG_ERROR = 3\n} LogLevel;\n\n// Initialize logging system with minimum level and output file\nbool logger_init(LogLevel min_level, FILE *output);\n\n// Log formatted message with specified level\nvoid logger_log(LogLevel level, const char *component, const char *format, ...);\n\n// Convenience macros for common logging patterns\n#define LOG_DEBUG(component, ...) logger_log(LOG_DEBUG, component, __VA_ARGS__)\n#define LOG_INFO(component, ...)  logger_log(LOG_INFO, component, __VA_ARGS__)\n#define LOG_WARN(component, ...)  logger_log(LOG_WARN, component, __VA_ARGS__)\n#define LOG_ERROR(component, ...) logger_log(LOG_ERROR, component, __VA_ARGS__)\n\n// Shutdown logging system and close files\nvoid logger_shutdown(void);\n```\n\n**Hash Table for Caching** (`src/util/hashtable.h`):\n```c\n#include <stddef.h>\n#include <stdbool.h>\n\ntypedef struct HashTable HashTable;\n\n// Create hash table with specified initial capacity\nHashTable* hashtable_create(size_t initial_capacity);\n\n// Insert key-value pair, returns false if out of memory\nbool hashtable_put(HashTable *ht, const char *key, void *value);\n\n// Retrieve value for key, returns NULL if not found\nvoid* hashtable_get(HashTable *ht, const char *key);\n\n// Remove entry for key, returns true if key existed\nbool hashtable_remove(HashTable *ht, const char *key);\n\n// Get current number of entries\nsize_t hashtable_size(HashTable *ht);\n\n// Free hash table and all keys (values must be freed by caller)\nvoid hashtable_destroy(HashTable *ht);\n```\n\nThese utilities provide the foundational infrastructure that every reverse proxy component requires. The buffer management handles dynamic memory allocation for HTTP messages, the logging system enables debugging and operational monitoring, and the hash table supports caching and configuration lookups.\n\n**D. Core Logic Skeleton Code:**\n\nFor the main event loop and component coordination, provide structure without implementation:\n\n**Main Event Loop** (`src/main.c`):\n```c\n#include \"config/config.h\"\n#include \"connection/manager.h\"\n#include \"util/logger.h\"\n\nint main(int argc, char *argv[]) {\n    // TODO 1: Parse command line arguments for config file path\n    // TODO 2: Load configuration from file using config_load()\n    // TODO 3: Initialize logger with configured log level and output\n    // TODO 4: Create connection manager with configured listen address\n    // TODO 5: Initialize SSL contexts if SSL termination is enabled\n    // TODO 6: Enter main event loop calling connection_manager_run()\n    // TODO 7: Handle shutdown signals gracefully (SIGTERM, SIGINT)\n    // TODO 8: Clean up resources and close all connections before exit\n    // Hint: Use signal handlers to set a global shutdown flag\n    return 0;\n}\n```\n\n**Configuration Loading** (`src/config/config.c`):\n```c\n#include \"config.h\"\n\nProxyConfig* config_load(const char *config_file_path) {\n    // TODO 1: Open configuration file and handle file not found errors\n    // TODO 2: Parse listen address and port from config\n    // TODO 3: Parse backend server list with weights and health check URLs\n    // TODO 4: Parse SSL settings including certificate paths and cipher suites\n    // TODO 5: Parse cache settings including max size and default TTL\n    // TODO 6: Validate all configuration values for sanity\n    // TODO 7: Return populated ProxyConfig struct or NULL on error\n    // Hint: Start with simple key=value format, expand to JSON later\n    return NULL;\n}\n```\n\n**E. Language-Specific Hints for C:**\n\n- **Socket Programming**: Use `socket(AF_INET, SOCK_STREAM, 0)` for TCP sockets, set `SO_REUSEADDR` to avoid \"Address already in use\" errors during development\n- **Non-blocking I/O**: Set sockets to non-blocking mode with `fcntl(sockfd, F_SETFL, O_NONBLOCK)` and handle `EAGAIN`/`EWOULDBLOCK` return codes\n- **Memory Management**: Always pair `malloc()` with `free()`, consider using `valgrind` to detect memory leaks during development\n- **String Handling**: Use `strncpy()` instead of `strcpy()` and always null-terminate strings manually, HTTP headers are case-insensitive so implement case-insensitive comparison\n- **Error Handling**: Check return values from all system calls, use `errno` and `strerror()` to provide meaningful error messages\n- **Event-Driven I/O**: Start with `select()` for portability, then optimize with `epoll()` on Linux or `kqueue()` on BSD systems for better performance\n\n**F. Milestone Checkpoint:**\n\nAfter implementing the basic project structure and infrastructure components:\n\n**What to Run:**\n```bash\nmake clean && make\n./reverse-proxy config/proxy.conf\n```\n\n**Expected Output:**\n```\n[INFO] Starting reverse proxy on 0.0.0.0:8080\n[INFO] Loaded 3 backend servers from configuration\n[INFO] SSL termination enabled with certificate: config/ssl/server.crt\n[INFO] Cache enabled with 100MB maximum size\n[INFO] Ready to accept connections\n```\n\n**What to Verify Manually:**\n1. Start a simple HTTP server on port 8081 (can use Python's `python -m http.server 8081`)\n2. Configure your proxy to forward to localhost:8081\n3. Send a request to your proxy: `curl -v http://localhost:8080/`\n4. Verify the proxy forwards the request and returns the backend's response\n5. Check logs to see request processing information\n\n**Signs Something is Wrong:**\n- **\"Address already in use\" error**: Another process is using the port, or you forgot to set `SO_REUSEADDR`\n- **Connection refused**: Check that backend servers are actually running and accessible\n- **Segmentation fault**: Likely a memory management issue, run with `valgrind` to identify the problem\n- **Hanging requests**: Probably an issue with non-blocking I/O handling or event loop logic\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Proxy accepts connections but never responds | Event loop not processing read events | Add debug logging to event handlers | Check `select()`/`epoll()` event masks |\n| High CPU usage with no traffic | Busy loop in event handling | Profile with `top` or `htop` | Add proper blocking on empty event queues |\n| Memory usage grows continuously | Memory leaks in connection handling | Run with `valgrind --leak-check=full` | Review buffer allocation and cleanup |\n| Requests timeout randomly | Backend connection pool exhaustion | Log connection pool statistics | Implement connection limits and queuing |\n| SSL handshake failures | Certificate or cipher suite issues | Check OpenSSL error messages | Verify certificate validity and supported ciphers |\n\nThis implementation guidance provides a solid foundation for beginning the reverse proxy implementation. The modular structure and infrastructure components allow you to focus on learning the core concepts of each component without getting bogged down in repetitive utility code. As you implement each milestone, you'll build upon this foundation while gaining deep understanding of how production reverse proxies handle the complexities of high-performance network programming.\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** All milestones - this section establishes the scope boundaries that guide implementation decisions throughout the entire project lifecycle.\n\nBuilding a reverse proxy is like constructing a high-performance traffic control system for a busy metropolitan area. Just as a traffic control center must decide which roads to build, which intersections to prioritize, and which advanced features to include versus which to defer, our reverse proxy implementation requires clear boundaries about what functionality to include in our initial design versus what to leave for future iterations.\n\nThe challenge with reverse proxy development lies in the vast scope of potential features. Modern production reverse proxies like NGINX and HAProxy include hundreds of configuration directives, dozens of load balancing algorithms, sophisticated rate limiting, WebSocket proxying, HTTP/3 support, Lua scripting capabilities, and complex SSL certificate management. Attempting to implement everything would result in an overly complex system that never reaches completion. Instead, we must carefully choose a focused subset of functionality that provides a solid foundation while remaining achievable within reasonable development timeframes.\n\nThink of this goals definition as drawing the blueprint boundaries for our traffic control system. We're deciding whether to build a basic intersection with traffic lights (core HTTP forwarding), add highway on-ramps (load balancing), include parking structures (caching), and install toll booths (SSL termination), while consciously deciding not to build subway systems (complex routing rules) or airport terminals (advanced features) in our initial version.\n\n### Core Functional Goals\n\nOur reverse proxy implementation focuses on five fundamental capabilities that represent the essential building blocks of any production reverse proxy system. These goals directly align with our milestone structure and provide measurable success criteria for each development phase.\n\n**HTTP Request Forwarding and Response Relay**\n\nThe primary goal involves implementing a robust HTTP proxy core that can accept incoming client connections, parse HTTP requests completely, forward those requests to configured backend servers, and relay the backend responses back to clients. This functionality forms the foundation upon which all other features build.\n\nThe system must handle both HTTP/1.1 and HTTP/2 protocol versions, supporting the complete request-response cycle including method extraction, header parsing, body handling, and proper connection management. This includes correctly implementing HTTP semantics for chunked transfer encoding, content-length validation, and connection keep-alive behavior.\n\nSuccess criteria include the ability to proxy any valid HTTP request without modification to the request semantics, maintain request fidelity during forwarding, and properly handle various HTTP methods including GET, POST, PUT, DELETE, and HEAD requests. The proxy must preserve all client headers while adding appropriate forwarding headers like `X-Forwarded-For` and `Via`.\n\n**Load Balancing and Backend Distribution**\n\nThe second core goal implements intelligent request distribution across multiple backend servers using proven load balancing algorithms. This capability transforms our simple proxy into a scalable traffic distribution system capable of handling high-volume applications.\n\nThe implementation must support multiple distribution strategies including round-robin for even distribution, least-connections for optimal resource utilization, weighted distribution for heterogeneous backend capacity, and IP hash for session affinity requirements. Each algorithm addresses different operational needs and scaling patterns.\n\nHealth checking integration ensures that only healthy backends receive traffic by implementing periodic health checks against configured endpoints, automatically removing failed backends from the active pool, and restoring them when health checks succeed. This provides automatic failover capabilities without manual intervention.\n\n**Connection Pooling and Resource Management**\n\nThe third goal focuses on efficient resource utilization through persistent connection management. Rather than establishing new TCP connections for each request, the system maintains pools of reusable connections to backend servers, dramatically reducing connection establishment overhead and improving overall throughput.\n\nConnection pooling involves maintaining separate pools for each backend server, implementing configurable pool size limits to prevent resource exhaustion, handling connection timeouts through idle connection eviction, and validating connection health before reuse. The pooling strategy must balance resource efficiency with connection freshness.\n\nThe system must gracefully handle pool exhaustion scenarios by either creating temporary connections or queuing requests, depending on configuration policies. Connection lifecycle management includes proper cleanup of idle connections and handling of backend connection failures.\n\n**HTTP Response Caching**\n\nThe fourth goal implements intelligent response caching to reduce backend load and improve client response times. The caching system must respect HTTP caching semantics while providing significant performance improvements for cacheable content.\n\nCache implementation includes generating unique cache keys from request attributes, storing responses with appropriate TTL values based on `Cache-Control` headers, supporting cache invalidation through both time-based expiry and explicit purge operations, and properly handling conditional requests using ETags and `If-Modified-Since` headers.\n\nThe system must distinguish between cacheable and non-cacheable responses, respecting directives like `no-cache`, `no-store`, and `private`. Cache storage utilizes memory-based storage with LRU eviction policies when size limits are reached.\n\n**SSL Termination and Certificate Management**\n\nThe fifth goal provides secure HTTPS connection handling through SSL/TLS termination at the proxy layer. This allows backend servers to operate with plain HTTP while presenting encrypted endpoints to clients, simplifying backend infrastructure while maintaining security.\n\nSSL termination includes loading X.509 certificates and private keys from PEM files, supporting Server Name Indication (SNI) for multi-domain hosting, implementing strong cipher suite selection, enforcing minimum TLS version requirements, and providing automatic HTTP-to-HTTPS redirects for security.\n\nCertificate management supports runtime certificate reloading without process restarts, proper certificate chain validation, and secure private key handling. The system must support multiple certificates for different domains while selecting the appropriate certificate based on SNI during TLS handshake.\n\n### Performance and Quality Goals\n\nBeyond functional capabilities, our reverse proxy must meet specific performance and reliability standards that enable production deployment scenarios. These quality goals ensure the system can handle real-world traffic patterns and operational requirements.\n\n**Throughput and Latency Targets**\n\nThe system must handle at least 10,000 concurrent connections with sub-millisecond proxy overhead added to backend response times. This performance target ensures the proxy doesn't become a bottleneck in high-traffic applications while maintaining responsive user experiences.\n\nLatency measurements exclude backend processing time and network transit delays, focusing specifically on proxy overhead including request parsing, routing decisions, connection management, and response forwarding. The target assumes properly tuned operating system settings and adequate hardware resources.\n\nMemory usage must remain bounded and predictable under load, with configurable limits for connection pools, cache storage, and request buffering. The system should avoid memory leaks and implement proper resource cleanup to support long-running operation.\n\n**Reliability and Error Handling**\n\nThe proxy must provide robust error handling and graceful degradation capabilities, ensuring that individual backend failures don't affect overall system availability. Error handling includes proper timeout management, circuit breaker patterns for failing backends, and appropriate error responses to clients.\n\nLogging and monitoring integration provides operational visibility through structured log output, metrics collection for key performance indicators, and debugging information for troubleshooting. The system must support configurable log levels and external monitoring system integration.\n\nRecovery mechanisms handle various failure scenarios including backend connection failures, SSL certificate errors, configuration reload failures, and resource exhaustion conditions. Each failure mode requires specific detection and recovery strategies.\n\n### Explicit Non-Goals\n\nClearly defining what our reverse proxy will NOT implement is equally important as defining its goals. These non-goals establish scope boundaries that prevent feature creep and maintain implementation focus on core capabilities.\n\n**Advanced Routing and Traffic Management**\n\nOur implementation explicitly excludes complex routing features found in advanced reverse proxies and API gateways. We will not implement URL rewriting capabilities, complex path-based routing rules, regular expression matching for request routing, or header-based routing decisions beyond basic host header handling.\n\nRate limiting and traffic shaping features are excluded from the initial implementation. While these capabilities are valuable in production environments, they add significant complexity to the core proxy logic and can be implemented as future extensions without affecting the fundamental architecture.\n\nAuthentication and authorization features including OAuth integration, JWT validation, API key management, and access control lists are outside our scope. These features typically require integration with external identity systems and add substantial complexity to the request processing pipeline.\n\n**Protocol Extensions and Advanced Features**\n\nWebSocket proxying support is explicitly excluded due to the different connection semantics and state management requirements. WebSocket connections require long-lived, bidirectional communication that differs significantly from standard HTTP request-response patterns.\n\nHTTP/3 and QUIC protocol support are not included in the initial implementation. While these protocols represent the future of web communication, they require specialized libraries and significantly more complex implementation than HTTP/1.1 and HTTP/2.\n\nCompression and content modification features including gzip compression, content transcoding, and response body modification are excluded. These features require streaming content processing and add complexity to the response handling pipeline.\n\n**Operational and Management Features**\n\nAdministrative interfaces including REST APIs for configuration management, web-based dashboards, and runtime configuration modification are not included. The system will use file-based configuration with restart-required configuration changes.\n\nAdvanced monitoring features including Prometheus metrics export, distributed tracing integration, and detailed performance profiling are excluded from the core implementation. Basic logging provides operational visibility without requiring complex monitoring infrastructure.\n\nClustering and high availability features including configuration synchronization across multiple proxy instances, shared state management, and automatic failover are outside our scope. The system focuses on single-instance operation with external load balancing for high availability.\n\n**Security and Compliance Features**\n\nAdvanced security features including request filtering, SQL injection detection, cross-site scripting protection, and other web application firewall capabilities are excluded. These features require deep content inspection and complex rule engines.\n\nCertificate authority integration, automatic certificate provisioning through ACME protocol, and certificate rotation automation are not included. The system supports manual certificate management through file-based configuration.\n\nCompliance features including detailed audit logging, request/response recording, and regulatory compliance reporting are outside our implementation scope.\n\n### Architecture Decision Records\n\nThe following decisions establish fundamental design principles that guide implementation choices throughout the development process.\n\n> **Decision: Event-Driven Architecture with Asynchronous I/O**\n> - **Context**: Reverse proxies must handle thousands of concurrent connections efficiently without blocking on slow operations like backend requests or SSL handshakes.\n> - **Options Considered**: Thread-per-connection model, process-per-connection model, event-driven model with epoll/kqueue\n> - **Decision**: Event-driven architecture using non-blocking I/O and event loops\n> - **Rationale**: Thread-per-connection models consume excessive memory (8KB+ per thread stack) and suffer context switching overhead with thousands of connections. Event-driven models achieve higher concurrency with lower resource usage.\n> - **Consequences**: Requires careful state management and non-blocking operation implementation, but enables handling 10,000+ concurrent connections efficiently.\n\n| Architecture Model | Memory per Connection | Context Switch Overhead | Max Connections | Chosen |\n|-------------------|----------------------|-------------------------|-----------------|--------|\n| Thread-per-connection | ~8KB+ stack | High with many threads | ~1,000 | No |\n| Process-per-connection | ~1MB+ per process | Very high | ~100 | No |\n| Event-driven | ~1KB connection state | Minimal | 10,000+ | **Yes** |\n\n> **Decision: In-Memory Caching with LRU Eviction**\n> - **Context**: Response caching requires balancing cache hit rates with memory usage and implementation complexity.\n> - **Options Considered**: In-memory hash table, Redis external cache, disk-based cache with memory index\n> - **Decision**: In-memory hash table with LRU eviction policy\n> - **Rationale**: In-memory storage provides microsecond access times without network round trips. LRU eviction provides good hit rates for web traffic patterns. External caches add network latency and operational complexity.\n> - **Consequences**: Cache size limited by available memory, but provides excellent performance and simple implementation.\n\n| Caching Strategy | Access Latency | Scalability | Operational Complexity | Chosen |\n|------------------|----------------|-------------|----------------------|--------|\n| In-memory hash table | Microseconds | Limited by RAM | Low | **Yes** |\n| External Redis | Milliseconds | High | Medium | No |\n| Disk with memory index | Milliseconds | Very high | High | No |\n\n> **Decision: File-Based Configuration with Restart-Required Reload**\n> - **Context**: Configuration management requires balancing operational flexibility with implementation complexity.\n> - **Options Considered**: File-based with restart, file-based with hot reload, API-based runtime configuration\n> - **Decision**: File-based configuration requiring process restart for changes\n> - **Rationale**: File-based configuration integrates well with configuration management tools and version control. Hot reload requires complex state synchronization and error handling. API-based configuration requires additional security and persistence mechanisms.\n> - **Consequences**: Configuration changes require brief service interruption, but implementation remains simple and reliable.\n\n| Configuration Method | Change Latency | Implementation Complexity | Version Control | Chosen |\n|---------------------|---------------|---------------------------|-----------------|--------|\n| File + restart | ~1 second downtime | Low | Excellent | **Yes** |\n| File + hot reload | Immediate | High | Good | No |\n| API-based runtime | Immediate | Very high | Poor | No |\n\n### Success Criteria and Validation\n\nEach goal requires specific, measurable criteria that validate successful implementation and provide clear checkpoints for development progress.\n\n**Functional Validation Criteria**\n\nHTTP proxy functionality validation involves testing complete request-response cycles with various HTTP methods, header combinations, and body types. Success requires bit-for-bit response fidelity compared to direct backend communication, proper forwarding header addition, and correct error handling for invalid requests.\n\nLoad balancing validation tests distribution algorithms with multiple backend servers, verifying even distribution for round-robin, connection-aware routing for least-connections, and proper weight respect for weighted algorithms. Health checking validation requires automatic backend removal during simulated failures and restoration when health checks succeed.\n\nConnection pooling validation measures connection reuse rates, pool size management under load, and proper connection cleanup during idle periods. Cache validation tests hit rates for repeated requests, proper TTL expiration, and correct cache-control header respect.\n\nSSL termination validation requires successful TLS handshake completion, proper certificate selection based on SNI, and secure cipher suite negotiation. Backend communication validation ensures plain HTTP forwarding works correctly after SSL termination.\n\n**Performance Validation Benchmarks**\n\nThroughput testing uses tools like `ab` (Apache Bench) or `wrk` to generate sustained load and measure requests per second under various connection counts. Target performance includes maintaining 95th percentile response times under 1ms proxy overhead with 1,000 concurrent connections.\n\nMemory usage testing validates bounded memory growth under sustained load, proper cleanup of idle resources, and absence of memory leaks during extended operation. Connection pool efficiency testing measures connection reuse rates and pool hit ratios.\n\nCache effectiveness testing measures hit rates for typical web traffic patterns and validates proper memory usage under various cache sizes. SSL performance testing ensures TLS handshake overhead remains acceptable under load.\n\n### Implementation Guidance\n\nThe goals and non-goals established in this section guide every architectural and implementation decision throughout the reverse proxy development process. Understanding these boundaries helps maintain focus on core capabilities while avoiding scope creep that could derail the project.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| HTTP Parsing | Custom parser with state machine | libhttp-parser library |\n| TLS Implementation | OpenSSL with basic configuration | mbedTLS with advanced features |\n| Event Loop | select() system call | epoll (Linux) / kqueue (BSD) |\n| Configuration Format | INI-style key-value pairs | YAML with validation schema |\n| Logging Framework | fprintf to stderr/file | Structured JSON logging |\n\n#### Core Configuration Structure\n\nThe configuration system forms the foundation that enables all proxy functionality. A well-designed configuration structure supports the goals while maintaining simplicity and clarity.\n\n```c\n// Complete configuration structure supporting all goals\ntypedef struct {\n    // Server configuration\n    char listen_address[256];\n    int listen_port;\n    int max_connections;\n    int worker_threads;\n    \n    // SSL configuration\n    bool ssl_enabled;\n    char ssl_cert_path[512];\n    char ssl_key_path[512];\n    char ssl_ca_path[512];\n    int ssl_min_version;  // Minimum TLS version\n    \n    // Backend server configuration\n    int backend_count;\n    struct {\n        char address[256];\n        int port;\n        int weight;\n        int max_connections;\n        int health_check_interval;\n        char health_check_path[256];\n    } backends[32];\n    \n    // Load balancing configuration\n    enum {\n        LB_ROUND_ROBIN,\n        LB_LEAST_CONNECTIONS,\n        LB_WEIGHTED_ROUND_ROBIN,\n        LB_IP_HASH\n    } lb_algorithm;\n    \n    // Cache configuration\n    bool cache_enabled;\n    size_t cache_max_size;\n    int cache_default_ttl;\n    char cache_exclude_patterns[1024];\n    \n    // Connection pooling configuration\n    int pool_max_connections;\n    int pool_idle_timeout;\n    int pool_connect_timeout;\n    \n    // Logging configuration\n    LogLevel log_level;\n    char log_file_path[512];\n    bool log_requests;\n    \n} ProxyConfig;\n```\n\n#### Configuration Loading Implementation\n\n```c\n// Configuration loader that validates goals compliance\nProxyConfig* config_load(char* config_file_path) {\n    // TODO 1: Open configuration file with error handling\n    // TODO 2: Parse each configuration section (server, ssl, backends, etc.)\n    // TODO 3: Validate backend configuration has at least one server\n    // TODO 4: Validate SSL configuration if SSL is enabled\n    // TODO 5: Set default values for optional parameters\n    // TODO 6: Validate port numbers are in valid ranges\n    // TODO 7: Validate file paths exist and are readable\n    // TODO 8: Allocate and populate ProxyConfig structure\n    // TODO 9: Close configuration file and return config\n    // Hint: Use fopen(), fgets(), and sscanf() for simple parsing\n    return NULL;  // Placeholder for implementation\n}\n```\n\n#### Goal Validation Checklist\n\nThe following validation steps ensure implementation stays within defined goals and meets all success criteria:\n\n**Milestone 1 Validation - HTTP Proxy Core**\n- Start proxy server on configured port\n- Send HTTP GET request using curl or similar tool\n- Verify response matches direct backend response exactly\n- Check proxy logs show request processing\n- Test with various HTTP methods (GET, POST, PUT, DELETE)\n- Verify `X-Forwarded-For` header is added to forwarded requests\n\n**Milestone 2 Validation - Load Balancing**\n- Configure multiple backend servers in different states\n- Send multiple requests and verify round-robin distribution\n- Stop one backend server and verify traffic redirects automatically\n- Check health check logs show backend status changes\n- Test weighted distribution with different backend weights\n\n**Milestone 3 Validation - Connection Pooling**\n- Enable connection pooling in configuration\n- Send multiple requests to same backend\n- Monitor connection counts to verify reuse\n- Test pool size limits by exceeding max connections\n- Verify idle connections get cleaned up after timeout\n\n**Milestone 4 Validation - Caching**\n- Enable caching with reasonable size limit\n- Send same GET request multiple times\n- Verify subsequent requests return faster (cache hits)\n- Check cache hit/miss statistics in logs\n- Test cache expiration with short TTL values\n\n**Milestone 5 Validation - SSL Termination**\n- Configure SSL certificate and enable HTTPS\n- Connect using https:// URL and verify certificate\n- Check backend receives plain HTTP requests\n- Test SNI with multiple domain certificates\n- Verify HTTP requests redirect to HTTPS\n\n#### Common Implementation Pitfalls\n\n⚠️ **Pitfall: Scope Creep Beyond Defined Goals**\nMany developers attempt to add features not included in the goals, such as complex routing rules or authentication mechanisms. This leads to incomplete core functionality and extended development timelines. Stay focused on the five core goals and implement them completely before considering extensions.\n\n⚠️ **Pitfall: Ignoring Performance Goals During Development**\nImplementing features without considering performance implications can result in a functionally correct but unusable proxy. Test performance early and often, ensuring each milestone meets latency and throughput targets before proceeding to the next.\n\n⚠️ **Pitfall: Over-Engineering Configuration System**\nAttempting to build a sophisticated configuration system with hot reloading, validation schemas, and complex nesting violates the non-goals and adds unnecessary complexity. Use simple file-based configuration that covers the required functionality without extra features.\n\n⚠️ **Pitfall: Inadequate Error Handling Strategy**\nFocusing only on happy path scenarios without implementing comprehensive error handling for network failures, backend timeouts, and resource exhaustion. Define specific error handling strategies for each goal and implement them consistently.\n\nThe goals and non-goals established here serve as the north star for all implementation decisions. When facing design choices or feature requests, refer back to these boundaries to maintain project focus and ensure successful delivery of core reverse proxy functionality.\n\n\n## High-Level Architecture\n\n> **Milestone(s):** All milestones - the architectural foundation established here guides implementation decisions across HTTP proxy core, load balancing, connection pooling, caching, and SSL termination components.\n\nBuilding a reverse proxy is like designing the traffic control system for a busy metropolitan area. Just as traffic lights, road signs, and interchange ramps must work together seamlessly to move thousands of vehicles efficiently from origin to destination, our reverse proxy must coordinate multiple specialized components to route HTTP requests from clients to backend servers and return responses reliably. The architectural challenge lies not just in handling individual requests, but in managing thousands of concurrent connections, making intelligent routing decisions, maintaining performance under load, and gracefully handling failures - all while appearing as a single, responsive service to clients.\n\nThe reverse proxy sits at a critical network chokepoint, making architectural decisions that directly impact system scalability, reliability, and performance. Unlike a simple forwarding service, our proxy must simultaneously act as an HTTP server accepting client connections, an HTTP client making backend requests, a load balancer distributing traffic intelligently, a cache providing fast response delivery, and an SSL termination point handling cryptographic operations. Each of these roles requires specialized logic, yet they must integrate seamlessly to process requests with minimal latency and maximum throughput.\n\n![System Component Architecture](./diagrams/system-components.svg)\n\nThe event-driven architecture we employ mirrors how modern operating systems handle I/O operations. Rather than dedicating one thread per connection (which would exhaust system resources with thousands of concurrent clients), our proxy uses asynchronous, non-blocking I/O with event loops - similar to how a single air traffic controller can manage multiple aircraft simultaneously by responding to events (radio calls, radar updates, weather changes) as they occur rather than giving each plane dedicated attention.\n\n### Component Overview\n\nThe reverse proxy architecture consists of five primary components working in concert, each with distinct responsibilities that collectively enable high-performance request processing. Think of these components as specialized departments in a logistics company: the mail sorting facility (HTTP Parser) processes incoming packages, the route planning department (Load Balancer) decides which delivery truck to use, the dispatcher (Connection Manager) manages the vehicle fleet, the warehouse (Cache Engine) stores frequently requested items for quick access, and the security checkpoint (SSL Termination) handles package verification and unwrapping.\n\nThe **HTTP Parser Component** serves as the protocol translation layer, responsible for interpreting the stream of bytes received from client connections and constructing well-formed HTTP requests that can be processed by other components. This component must handle the complexities of HTTP/1.1 and HTTP/2 protocols, including chunked transfer encoding, connection keep-alive semantics, and header field parsing. The parser maintains state machines for each connection to track parsing progress and handle partial reads that commonly occur with TCP streams. Beyond basic parsing, this component validates request syntax, extracts routing information, and prepares request objects that downstream components can process efficiently.\n\n| Responsibility | Description | Input | Output |\n|---------------|-------------|-------|---------|\n| Request Parsing | Convert raw TCP data streams into structured HTTP request objects | Raw bytes from client connections | `HttpRequest` structures with parsed headers, method, path, and body |\n| Response Construction | Build HTTP response messages from backend responses and proxy metadata | Backend responses, cache entries, error conditions | Formatted HTTP response bytes for client transmission |\n| Protocol Handling | Support HTTP/1.1 and HTTP/2 protocol variations | Various HTTP protocol versions and features | Consistent internal request/response representation |\n| Header Manipulation | Add proxy-specific headers like X-Forwarded-For and Via | Original client requests | Enriched requests with proxy headers for backend forwarding |\n| Connection State Tracking | Maintain parsing state for each active connection | Connection events and data arrivals | Updated connection parsing states and completion notifications |\n\nThe **Connection Manager Component** orchestrates the lifecycle of network connections, acting as both a client connection acceptor and a backend connection pool manager. This component implements the challenging task of maintaining persistent connections to backend servers while efficiently serving thousands of concurrent clients. The connection manager must balance resource utilization against performance, deciding when to create new backend connections, when to reuse existing ones, and when to close idle connections to free system resources. It also handles connection health monitoring, ensuring that stale or broken connections are detected and removed before they can impact request processing.\n\n| Responsibility | Description | Managed Resources | Key Algorithms |\n|---------------|-------------|-------------------|----------------|\n| Client Connection Acceptance | Accept and manage incoming client connections on listen socket | Client socket file descriptors, connection state objects | Accept loop with non-blocking I/O and connection queuing |\n| Backend Connection Pooling | Maintain reusable connections to backend servers | Connection pools per backend, idle connection timers | Pool size management, connection validation, timeout handling |\n| Connection Lifecycle Management | Track connection states from establishment to closure | Connection state machines, resource cleanup timers | State transition handling, graceful connection termination |\n| Resource Limit Enforcement | Prevent resource exhaustion through connection limits | File descriptor limits, memory usage tracking | Connection counting, admission control, backpressure mechanisms |\n| Health Monitoring | Detect and handle connection failures | Connection health status, failure detection timers | Heartbeat checking, failure pattern recognition, automatic cleanup |\n\nThe **Load Balancer Component** implements intelligent request distribution across available backend servers, making real-time routing decisions based on server health, current load, and configured algorithms. This component must maintain up-to-date knowledge of backend server status while making routing decisions quickly enough to avoid introducing significant latency. The load balancer coordinates with the connection manager to ensure selected backends have available connections and can handle additional requests without becoming overwhelmed.\n\n| Algorithm | Selection Criteria | State Maintained | Use Case |\n|-----------|-------------------|------------------|----------|\n| Round Robin | Sequential server selection with wraparound | Current position index, server list | Equal capacity servers, simple distribution |\n| Least Connections | Server with fewest active connections | Active connection count per server | Variable request processing times |\n| Weighted Round Robin | Server selection based on assigned capacity weights | Weight values, weighted position tracking | Servers with different capacity levels |\n| IP Hash | Consistent server selection based on client IP | Hash ring or consistent hashing state | Session affinity requirements |\n| Health Check Integration | Exclude unhealthy servers from selection | Server health status, last check timestamps | Automatic failure detection and recovery |\n\nThe **Cache Engine Component** provides intelligent HTTP response caching to reduce backend load and improve client response times. This component must respect HTTP caching semantics while implementing efficient cache storage and retrieval mechanisms. The cache engine works closely with the HTTP parser to extract cache-control directives and with the load balancer to determine when cache misses require backend requests. Cache management involves complex decisions around what to cache, how long to retain cached responses, and when to invalidate or refresh cached content.\n\n| Cache Operation | Decision Factors | Storage Requirements | Performance Impact |\n|----------------|------------------|---------------------|-------------------|\n| Cache Key Generation | Request method, URL, relevant headers (Vary) | Unique key per cacheable request variant | Fast key computation and collision avoidance |\n| Cacheability Assessment | Cache-Control headers, request method, response status | Header parsing state, policy configuration | Quick cache policy evaluation |\n| Storage and Retrieval | TTL management, LRU eviction, size limits | In-memory hash tables, expiration queues | Sub-millisecond lookup and storage operations |\n| Cache Invalidation | TTL expiration, explicit purge commands | Expiration timestamps, invalidation triggers | Automatic cleanup without blocking request processing |\n| Conditional Request Support | ETag and Last-Modified header handling | Cached response metadata, validation tokens | Bandwidth savings through 304 Not Modified responses |\n\nThe **SSL Termination Component** handles the complexities of TLS connection establishment, certificate management, and cryptographic operations required for HTTPS support. This component must efficiently perform TLS handshakes, validate certificates, support Server Name Indication (SNI) for multi-domain hosting, and decrypt incoming requests for processing by other components. SSL termination involves significant computational overhead, requiring careful resource management and optimization to maintain high throughput.\n\n| SSL Operation | Technical Requirements | Security Considerations | Performance Factors |\n|---------------|----------------------|------------------------|-------------------|\n| TLS Handshake Processing | Cipher suite negotiation, certificate presentation | Strong cipher selection, protocol version enforcement | Handshake latency, connection establishment time |\n| Certificate Management | Multiple certificate loading, SNI support | Private key security, certificate chain validation | Certificate lookup speed, memory usage |\n| Session Management | TLS session resumption, session ticket handling | Session key security, replay attack prevention | Session cache efficiency, resumption success rate |\n| Cryptographic Operations | Bulk encryption/decryption, MAC verification | Constant-time operations, side-channel resistance | Cipher performance, hardware acceleration utilization |\n| Protocol Security | TLS version enforcement, vulnerability mitigation | Known attack prevention, security patch integration | Security overhead vs. performance trade-offs |\n\n> **Decision: Event-Driven vs. Thread-Per-Connection Architecture**\n> - **Context**: Reverse proxies must handle thousands of concurrent connections efficiently, requiring a choice between traditional threading models and event-driven architectures\n> - **Options Considered**: Thread-per-connection, thread pool with blocking I/O, event-driven with non-blocking I/O\n> - **Decision**: Event-driven architecture with non-blocking I/O and event loops\n> - **Rationale**: Thread-per-connection models consume excessive memory (8KB+ stack per thread) and CPU context switching overhead with thousands of connections. Event-driven architectures can handle 10,000+ concurrent connections in a single process with minimal resource overhead\n> - **Consequences**: Requires more complex state management and asynchronous programming patterns, but enables horizontal scalability and efficient resource utilization\n\n| Architecture Option | Memory Usage | Scalability Limit | Context Switching Overhead | Chosen |\n|---------------------|--------------|-------------------|---------------------------|---------|\n| Thread-per-connection | 8KB+ per connection | ~1,000 connections | High (kernel thread scheduling) | No |\n| Thread pool + blocking I/O | Fixed pool memory | Limited by pool size | Medium (thread pool contention) | No |\n| Event-driven + non-blocking I/O | ~1KB per connection | 10,000+ connections | Minimal (user-space event loop) | **Yes** |\n\nThe components communicate through well-defined interfaces using message passing and shared data structures. The HTTP Parser produces `HttpRequest` objects consumed by the Load Balancer for routing decisions. The Connection Manager provides connection handles that other components use for I/O operations. The Cache Engine intercepts requests and responses, potentially short-circuiting the normal backend forwarding path. The SSL Termination component acts as a preprocessor, decrypting requests before they reach the HTTP Parser and encrypting responses before client transmission.\n\n### Recommended File Structure\n\nOrganizing the reverse proxy codebase requires careful consideration of component boundaries, shared dependencies, and testing requirements. The file structure should reflect the architectural components while providing clear separation of concerns and enabling independent development and testing of each component. Think of the file organization as creating dedicated workshop areas for different craftspeople - each component gets its own space with the tools it needs, while shared utilities remain accessible to all.\n\nThe recommended structure follows the principle of **component-based organization** where each major architectural component gets its own directory containing implementation files, tests, and component-specific utilities. This approach enables parallel development, simplifies testing by isolating component dependencies, and makes the codebase easier to navigate for developers working on specific features.\n\n```\nreverse-proxy/\n├── cmd/\n│   └── proxy/\n│       └── main.c                    ← Application entry point, server initialization\n├── src/\n│   ├── core/\n│   │   ├── proxy.h                   ← Main proxy server structure and lifecycle\n│   │   ├── proxy.c\n│   │   ├── config.h                  ← ProxyConfig definition and loading\n│   │   ├── config.c\n│   │   ├── logger.h                  ← Logging system with LogLevel enum\n│   │   └── logger.c\n│   ├── http/\n│   │   ├── parser.h                  ← HTTP request/response parsing\n│   │   ├── parser.c\n│   │   ├── request.h                 ← HttpRequest and HttpResponse structures\n│   │   ├── request.c\n│   │   ├── response.h\n│   │   └── response.c\n│   ├── connection/\n│   │   ├── manager.h                 ← Connection lifecycle management\n│   │   ├── manager.c\n│   │   ├── pool.h                    ← Backend connection pooling\n│   │   ├── pool.c\n│   │   ├── client.h                  ← Client connection handling\n│   │   └── client.c\n│   ├── loadbalancer/\n│   │   ├── balancer.h                ← Load balancing algorithms\n│   │   ├── balancer.c\n│   │   ├── health.h                  ← Health checking system\n│   │   ├── health.c\n│   │   ├── algorithms.h              ← Round-robin, least-connections, weighted\n│   │   └── algorithms.c\n│   ├── cache/\n│   │   ├── engine.h                  ← Cache storage and retrieval\n│   │   ├── engine.c\n│   │   ├── policies.h                ← Cache-control header handling\n│   │   ├── policies.c\n│   │   ├── storage.h                 ← LRU eviction and memory management\n│   │   └── storage.c\n│   ├── ssl/\n│   │   ├── termination.h             ← SSL/TLS context management\n│   │   ├── termination.c\n│   │   ├── certificates.h            ← Certificate loading and SNI support\n│   │   ├── certificates.c\n│   │   ├── handshake.h               ← TLS handshake processing\n│   │   └── handshake.c\n│   ├── utils/\n│   │   ├── buffer.h                  ← Buffer structure and operations\n│   │   ├── buffer.c\n│   │   ├── hashtable.h               ← HashTable implementation\n│   │   ├── hashtable.c\n│   │   ├── string.h                  ← String manipulation utilities\n│   │   ├── string.c\n│   │   ├── network.h                 ← Socket utilities and address handling\n│   │   └── network.c\n│   └── common/\n│       ├── types.h                   ← Common type definitions and constants\n│       ├── errors.h                  ← Error codes and error handling macros\n│       └── constants.h               ← System constants like SO_REUSEADDR, O_NONBLOCK\n├── tests/\n│   ├── unit/\n│   │   ├── test_http_parser.c        ← Unit tests for HTTP parsing components\n│   │   ├── test_connection_manager.c\n│   │   ├── test_load_balancer.c\n│   │   ├── test_cache_engine.c\n│   │   └── test_ssl_termination.c\n│   ├── integration/\n│   │   ├── test_request_flow.c       ← End-to-end request processing tests\n│   │   ├── test_backend_integration.c\n│   │   └── test_ssl_integration.c\n│   └── fixtures/\n│       ├── test_configs/             ← Test configuration files\n│       ├── certificates/             ← Test SSL certificates\n│       └── responses/                ← Sample HTTP responses for testing\n├── config/\n│   ├── proxy.conf                    ← Main configuration file template\n│   ├── ssl/\n│   │   ├── server.crt               ← SSL certificate files\n│   │   ├── server.key\n│   │   └── ca.crt\n│   └── backends.conf                 ← Backend server definitions\n├── scripts/\n│   ├── build.sh                      ← Build automation scripts\n│   ├── test.sh                       ← Test execution scripts\n│   └── generate_certs.sh             ← SSL certificate generation for testing\n├── docs/\n│   ├── api.md                        ← Component API documentation\n│   ├── configuration.md              ← Configuration file format and options\n│   └── deployment.md                 ← Deployment and operations guide\n├── Makefile                          ← Build system configuration\n└── README.md                         ← Project overview and quick start guide\n```\n\nThe **core** directory contains the fundamental proxy server infrastructure, including the main `ProxyConfig` structure that holds all configuration parameters, the logging system with `LogLevel` enumeration, and the primary server lifecycle management. These components provide the foundation that all other components depend on, similar to how a building's foundation supports all upper floors.\n\nThe **http** directory encapsulates all HTTP protocol handling, including request and response parsing, header manipulation, and protocol version negotiation. The separation between parsing logic and data structures allows for easier testing and potential future support for additional protocols. The `HttpRequest` and `HttpResponse` structures defined here become the standard data interchange format between all proxy components.\n\nThe **connection** directory manages the complex lifecycle of network connections, separating client connection handling from backend connection pooling. This separation allows independent optimization of client-facing and backend-facing connection strategies. The connection manager coordinates between these subsystems to ensure efficient resource utilization and proper connection cleanup.\n\nThe **loadbalancer** directory implements request distribution logic, health checking, and backend server management. The separation between general balancing logic and specific algorithms allows easy addition of new load balancing strategies without modifying core balancing infrastructure. Health checking gets its own module because it requires independent timing and state management.\n\nThe **cache** directory contains HTTP caching implementation, separated into cache storage mechanisms and HTTP cache policy enforcement. This separation allows the storage engine to be optimized independently of cache policy logic, and enables potential future backends like Redis or memcached without changing cache policy handling.\n\nThe **ssl** directory handles all aspects of TLS termination, from certificate management to cryptographic operations. The modular structure allows different SSL implementations or hardware acceleration to be integrated by replacing specific modules while maintaining the same interface to other components.\n\n> **Decision: Component Directory Structure vs. Feature-Based Structure**\n> - **Context**: Large codebases can be organized by architectural components or by user-facing features, each with different navigation and development implications\n> - **Options Considered**: Component-based directories (http/, ssl/, cache/), feature-based directories (proxying/, load-balancing/, caching/), flat structure\n> - **Decision**: Component-based directory structure with clear architectural boundaries\n> - **Rationale**: Component-based organization maps directly to system architecture, enabling parallel development by different team members, clear testing boundaries, and easier code navigation when debugging specific component issues\n> - **Consequences**: Requires well-defined interfaces between components and may require some code duplication, but provides better separation of concerns and development scalability\n\n| Organization Option | Developer Navigation | Testing Isolation | Parallel Development | Chosen |\n|--------------------|---------------------|-------------------|---------------------|---------|\n| Component-based (http/, ssl/, cache/) | Easy to find component-specific code | Clear test boundaries per component | Multiple developers per component | **Yes** |\n| Feature-based (proxying/, load-balancing/) | Code scattered across components | Complex cross-component test setup | Feature conflicts across components | No |\n| Flat structure (all files in src/) | Simple but becomes unwieldy | Difficult to isolate component tests | High merge conflict probability | No |\n\nThe **utils** directory provides shared infrastructure components like `Buffer` management, `HashTable` implementation, and network utilities that multiple components require. These utilities are designed to be reusable and thoroughly tested since they form the building blocks for higher-level functionality.\n\nThe **tests** directory structure mirrors the main source organization, providing unit tests for individual components and integration tests that verify cross-component interactions. The **fixtures** subdirectory contains test data, configuration files, and certificates needed for comprehensive testing scenarios.\n\n⚠️ **Pitfall: Circular Dependencies Between Components**\nA common architectural mistake is creating circular dependencies where Component A includes Component B's headers, and Component B includes Component A's headers. This often happens when the connection manager needs to call load balancer functions, and the load balancer needs to access connection manager state. The compiler cannot resolve these circular includes, leading to compilation errors and unclear component boundaries. To fix this, define clear interface boundaries using forward declarations in headers and only include necessary headers in implementation files. Use dependency inversion by having both components depend on abstract interfaces rather than concrete implementations.\n\n⚠️ **Pitfall: Overly Complex Include Hierarchies**\nWithout careful header organization, you might end up with headers that transitively include dozens of other headers, leading to long compilation times and unclear dependencies. For example, if `connection/manager.h` includes `loadbalancer/balancer.h`, which includes `cache/engine.h`, then every file using the connection manager gets all cache engine dependencies. Keep header files minimal by using forward declarations for pointer types and only including what's directly needed. Move complex includes to implementation (.c) files where they don't propagate to other compilation units.\n\n⚠️ **Pitfall: Inconsistent Error Handling Across Components**\nDifferent components might use different error reporting mechanisms - some returning error codes, others using errno, others logging errors directly. This inconsistency makes error handling unpredictable and debugging difficult. Establish consistent error handling patterns in the `common/errors.h` file and ensure all components use the same error reporting mechanisms. Define standard error codes and ensure every component function has clearly documented error conditions and return value semantics.\n\n### Implementation Guidance\n\nThe reverse proxy implementation requires careful selection of technologies and development practices that support high-performance, concurrent network programming. The C programming language provides the fine-grained control over memory management and system resources necessary for building efficient network services, while requiring disciplined development practices to avoid common pitfalls.\n\n**A. Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Event Loop | `select()` or `poll()` system calls | `epoll` (Linux) or `kqueue` (BSD/macOS) for scalability |\n| TLS Implementation | OpenSSL 1.1.1+ with basic configuration | OpenSSL 3.0+ with advanced features and hardware acceleration |\n| HTTP/2 Support | HTTP/1.1 only for initial implementation | nghttp2 library for full HTTP/2 support |\n| Memory Management | Standard `malloc()`/`free()` with careful tracking | Memory pools or custom allocators for performance |\n| Configuration Format | Simple key-value pairs in text files | JSON or YAML with validation and schema support |\n| Logging System | `fprintf()` to log files with manual formatting | Structured logging with log rotation and remote targets |\n\n**B. Development Environment Setup**\n\nFor building the reverse proxy, establish a development environment that supports concurrent programming and network testing:\n\n```bash\n# Required development tools and libraries\nsudo apt-get install build-essential gcc libc6-dev\nsudo apt-get install libssl-dev         # OpenSSL for TLS support\nsudo apt-get install libev-dev          # libev for efficient event loops\nsudo apt-get install valgrind          # Memory leak detection\nsudo apt-get install wireshark-dev     # Network traffic analysis tools\nsudo apt-get install nginx             # Reference implementation for testing\n```\n\n**C. Core Infrastructure Starter Code**\n\nThe following infrastructure components provide tested foundations that support the main reverse proxy logic without requiring implementation from scratch:\n\n**Buffer Management System** (`src/utils/buffer.h` and `src/utils/buffer.c`):\n```c\n#include <stddef.h>\n#include <stdbool.h>\n\ntypedef struct {\n    char* data;\n    size_t capacity;\n    size_t length;\n    size_t position;\n} Buffer;\n\n// Create new buffer with specified initial capacity\nBuffer* buffer_create(size_t initial_capacity);\n\n// Append data to buffer, expanding capacity if needed\nbool buffer_append(Buffer* buf, const char* data, size_t data_len);\n\n// Read data from buffer starting at current position\nsize_t buffer_read(Buffer* buf, char* dest, size_t max_len);\n\n// Reset buffer position to beginning for reading\nvoid buffer_rewind(Buffer* buf);\n\n// Ensure buffer has at least min_capacity space available\nbool buffer_ensure_capacity(Buffer* buf, size_t min_capacity);\n\n// Free buffer and associated memory\nvoid buffer_destroy(Buffer* buf);\n\n// Check if buffer has data available for reading\nstatic inline bool buffer_has_data(Buffer* buf) {\n    return buf->position < buf->length;\n}\n\n// Get number of bytes available for reading\nstatic inline size_t buffer_available(Buffer* buf) {\n    return buf->length - buf->position;\n}\n```\n\n**Hash Table Implementation** (`src/utils/hashtable.h` and `src/utils/hashtable.c`):\n```c\n#include <stddef.h>\n#include <stdbool.h>\n\ntypedef struct HashTable HashTable;\n\n// Create hash table with specified number of buckets\nHashTable* hashtable_create(size_t bucket_count);\n\n// Insert key-value pair (takes ownership of key string)\nbool hashtable_put(HashTable* table, const char* key, void* value);\n\n// Retrieve value by key, returns NULL if not found\nvoid* hashtable_get(HashTable* table, const char* key);\n\n// Remove entry by key, returns old value or NULL\nvoid* hashtable_remove(HashTable* table, const char* key);\n\n// Check if key exists in table\nbool hashtable_contains(HashTable* table, const char* key);\n\n// Get current number of entries\nsize_t hashtable_size(HashTable* table);\n\n// Free hash table and all keys (values are caller's responsibility)\nvoid hashtable_destroy(HashTable* table);\n\n// Iterator for walking all entries\ntypedef struct {\n    HashTable* table;\n    size_t bucket_index;\n    void* current_entry;\n} HashTableIterator;\n\nHashTableIterator hashtable_iterator_create(HashTable* table);\nbool hashtable_iterator_next(HashTableIterator* iter, const char** key, void** value);\n```\n\n**Logging System** (`src/core/logger.h` and `src/core/logger.c`):\n```c\n#include <stdio.h>\n#include <stdarg.h>\n#include <stdbool.h>\n\ntypedef enum {\n    LOG_DEBUG = 0,\n    LOG_INFO = 1,\n    LOG_WARN = 2,\n    LOG_ERROR = 3\n} LogLevel;\n\n// Initialize logging system with minimum level and output file\nbool logger_init(LogLevel min_level, FILE* output_file);\n\n// Log formatted message with specified level, source file, and line\nvoid logger_log(LogLevel level, const char* source_file, int line, const char* format, ...);\n\n// Convenience macros that automatically include file and line information\n#define LOG_DEBUG(fmt, ...) logger_log(LOG_DEBUG, __FILE__, __LINE__, fmt, ##__VA_ARGS__)\n#define LOG_INFO(fmt, ...)  logger_log(LOG_INFO, __FILE__, __LINE__, fmt, ##__VA_ARGS__)\n#define LOG_WARN(fmt, ...)  logger_log(LOG_WARN, __FILE__, __LINE__, fmt, ##__VA_ARGS__)\n#define LOG_ERROR(fmt, ...) logger_log(LOG_ERROR, __FILE__, __LINE__, fmt, ##__VA_ARGS__)\n\n// Clean up logging system resources\nvoid logger_shutdown(void);\n\n// Change log level at runtime\nvoid logger_set_level(LogLevel new_level);\n```\n\n**D. Core Proxy Structure Skeleton**\n\nThe main proxy server structure provides the foundation for component integration:\n\n**Main Proxy Server** (`src/core/proxy.h`):\n```c\n#include \"config.h\"\n#include \"../http/parser.h\"\n#include \"../connection/manager.h\"\n#include \"../loadbalancer/balancer.h\"\n#include \"../cache/engine.h\"\n#include \"../ssl/termination.h\"\n\ntypedef struct {\n    ProxyConfig* config;\n    ConnectionManager* conn_manager;\n    LoadBalancer* load_balancer;\n    CacheEngine* cache_engine;\n    SSLTermination* ssl_context;\n    \n    int listen_fd;\n    bool running;\n    int worker_thread_count;\n    pthread_t* worker_threads;\n} ProxyServer;\n\n// Initialize proxy server with configuration\nProxyServer* proxy_server_create(ProxyConfig* config);\n\n// Start proxy server and begin accepting connections\nbool proxy_server_start(ProxyServer* server);\n\n// Main event loop processing connections and requests  \nvoid proxy_server_run(ProxyServer* server);\n// TODO 1: Create epoll/kqueue event loop for handling I/O events\n// TODO 2: Accept new client connections and add to connection manager\n// TODO 3: Process readable connections by parsing HTTP requests\n// TODO 4: Route requests through load balancer to select backend\n// TODO 5: Check cache for existing responses before forwarding\n// TODO 6: Forward cache misses to selected backend servers\n// TODO 7: Process backend responses and update cache if appropriate\n// TODO 8: Send responses back to clients and manage connection state\n// TODO 9: Handle connection timeouts and cleanup closed connections\n// TODO 10: Gracefully handle shutdown signals and resource cleanup\n\n// Stop proxy server and clean up resources\nvoid proxy_server_stop(ProxyServer* server);\n\n// Free proxy server and all associated resources\nvoid proxy_server_destroy(ProxyServer* server);\n```\n\n**Configuration Management** (`src/core/config.h`):\n```c\n#include <stdbool.h>\n#include <stddef.h>\n#include \"logger.h\"\n\ntypedef enum {\n    LB_ROUND_ROBIN,\n    LB_LEAST_CONNECTIONS, \n    LB_WEIGHTED_ROUND_ROBIN,\n    LB_IP_HASH\n} LoadBalancingAlgorithm;\n\ntypedef struct {\n    char address[256];\n    int port;\n    int weight;\n    bool enabled;\n} BackendServer;\n\ntypedef struct {\n    char listen_address[256];\n    int listen_port;\n    int max_connections;\n    int worker_threads;\n    \n    bool ssl_enabled;\n    char ssl_cert_path[512];\n    char ssl_key_path[512];\n    char ssl_ca_path[512];\n    int ssl_min_version;\n    \n    int backend_count;\n    BackendServer backends[64];\n    LoadBalancingAlgorithm lb_algorithm;\n    \n    bool cache_enabled;\n    size_t cache_max_size;\n    int cache_default_ttl;\n    char cache_exclude_patterns[1024];\n    \n    int pool_max_connections;\n    int pool_idle_timeout;\n    int pool_connect_timeout;\n    \n    LogLevel log_level;\n    char log_file_path[512];\n    bool log_requests;\n} ProxyConfig;\n\n// Load configuration from file\nProxyConfig* config_load(const char* config_file_path);\n// TODO 1: Open and parse configuration file line by line\n// TODO 2: Parse listen address and port settings\n// TODO 3: Parse SSL certificate paths and TLS configuration\n// TODO 4: Parse backend server list with addresses, ports, and weights\n// TODO 5: Parse load balancing algorithm selection\n// TODO 6: Parse cache settings and exclusion patterns\n// TODO 7: Parse connection pool configuration parameters\n// TODO 8: Parse logging configuration and validate log file paths\n// TODO 9: Validate all configuration values for consistency\n// TODO 10: Return populated ProxyConfig structure or NULL on error\n\n// Validate configuration for consistency and required values\nbool config_validate(ProxyConfig* config);\n\n// Free configuration structure\nvoid config_destroy(ProxyConfig* config);\n```\n\n**E. Language-Specific Implementation Hints**\n\n**Socket Programming Best Practices:**\n- Use `SO_REUSEADDR` socket option to allow rapid server restarts: `setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt))`\n- Set sockets to non-blocking mode with `fcntl(fd, F_SETFL, O_NONBLOCK)` for event-driven I/O\n- Handle `EAGAIN` and `EWOULDBLOCK` errors gracefully in non-blocking operations\n- Use `TCP_NODELAY` to disable Nagle's algorithm for low-latency forwarding\n\n**Memory Management Strategies:**\n- Always pair `malloc()` calls with corresponding `free()` calls to prevent memory leaks\n- Set pointers to `NULL` after freeing to avoid double-free errors\n- Use `valgrind` during development to detect memory leaks and buffer overflows\n- Consider object pools for frequently allocated/deallocated structures like HTTP requests\n\n**Error Handling Patterns:**\n- Check return values of all system calls and library functions\n- Use consistent error codes throughout the application\n- Log error conditions with sufficient context for debugging\n- Implement graceful degradation when non-critical operations fail\n\n**F. Milestone Checkpoints**\n\n**Milestone 1 Checkpoint - HTTP Proxy Core:**\n```bash\n# Compile and test basic proxy functionality\nmake clean && make\n./proxy --config=config/test.conf\n\n# Test basic request forwarding with curl\ncurl -v -H \"X-Test: milestone1\" http://localhost:8080/test\n# Expected: Response from backend server with X-Forwarded-For header added\n# Expected: Proxy logs showing request parsing and forwarding\n\n# Verify error handling\ncurl -v http://localhost:8080/nonexistent\n# Expected: Appropriate HTTP error response when backend is unavailable\n```\n\n**Architecture Validation Checkpoint:**\n- Verify each component can be compiled independently without circular dependencies\n- Test component interfaces by creating mock implementations\n- Run static analysis tools to detect potential issues early\n- Validate configuration loading and parsing with various input files\n\n**G. Performance Monitoring Setup**\n\nEstablish performance monitoring from the beginning of development to track system behavior under load:\n\n```c\n// Performance metrics structure for monitoring\ntypedef struct {\n    uint64_t requests_processed;\n    uint64_t requests_cached;\n    uint64_t backend_failures;\n    uint64_t ssl_handshakes;\n    double avg_response_time_ms;\n    uint32_t active_connections;\n    uint32_t backend_connections;\n} ProxyMetrics;\n\n// Expose metrics through HTTP endpoint for monitoring tools\nvoid metrics_update_request_processed(ProxyMetrics* metrics);\nvoid metrics_update_response_time(ProxyMetrics* metrics, double response_time_ms);\nvoid metrics_export_json(ProxyMetrics* metrics, char* buffer, size_t buffer_size);\n```\n\nThe architectural foundation established here provides a robust platform for implementing each milestone component. The clear separation of concerns, well-defined interfaces, and comprehensive infrastructure support rapid development while maintaining code quality and system reliability. As you progress through each milestone, this architectural framework will guide implementation decisions and ensure component integration proceeds smoothly.\n\n\n## Data Model\n\n> **Milestone(s):** All milestones - the data structures defined here form the foundation for HTTP proxy core, load balancing, connection pooling, caching, and SSL termination components.\n\nThink of the data model as the blueprint of a complex building - it defines all the rooms, their purposes, and how they connect to each other. In a reverse proxy, these \"rooms\" are the data structures that represent HTTP messages, network connections, configuration settings, and runtime state. Just as a building's blueprint must account for electrical wiring, plumbing, and structural supports, our data model must carefully design structures that support concurrent access, memory efficiency, and protocol compliance.\n\nThe data model serves as the contract between all components in the reverse proxy. When the HTTP parser creates an `HttpRequest` structure, it must contain all the information the load balancer needs to make routing decisions. When the cache engine stores responses, it must preserve all the metadata the connection manager needs to send data back to clients. This careful orchestration of data structures enables loose coupling between components while maintaining system coherence.\n\n### Core Data Types\n\nThe core data types form the foundation of HTTP message processing and connection management. These structures must handle the complexities of the HTTP protocol while providing efficient access patterns for high-performance request processing.\n\n#### Buffer Management\n\nThink of a `Buffer` as a smart container that grows and shrinks as needed, like a shopping bag that expands when you add items but keeps track of how much space is left. In network programming, data arrives in chunks of unpredictable sizes, and the buffer must efficiently accumulate these pieces while providing fast access to the complete message.\n\nThe `Buffer` structure provides the foundation for all data handling in the reverse proxy:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| data | char* | Pointer to the allocated memory region storing actual data bytes |\n| capacity | size_t | Total allocated memory size in bytes, representing maximum storage before reallocation |\n| length | size_t | Current number of valid data bytes stored in the buffer |\n| position | size_t | Current read/write position within the buffer for streaming operations |\n\n> **Decision: Dynamic Buffer Growth Strategy**\n> - **Context**: Network data arrives in variable-sized chunks, and HTTP messages can range from tiny (200 bytes) to massive (multi-gigabyte uploads)\n> - **Options Considered**: Fixed-size buffers, exponential growth, linear growth\n> - **Decision**: Exponential growth with configurable initial size and maximum capacity\n> - **Rationale**: Exponential growth minimizes reallocation overhead for typical HTTP message sizes while preventing unbounded memory consumption through maximum limits\n> - **Consequences**: Reduces memory copy operations for growing messages but may over-allocate for small messages; requires careful tuning of growth parameters\n\nThe buffer implements a position-based streaming interface that enables efficient parsing without copying data. When the HTTP parser reads a request line, it advances the position pointer rather than extracting substrings. This zero-copy approach significantly improves performance for large messages.\n\n#### HTTP Message Structures\n\nHTTP messages in a reverse proxy must preserve all protocol semantics while providing efficient access to routing-relevant information. The `HttpRequest` structure captures the complete client request state:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| method | char[16] | HTTP method (GET, POST, PUT, DELETE, etc.) as null-terminated string |\n| uri | char[2048] | Complete request URI including path and query string |\n| version | char[16] | HTTP version string (HTTP/1.1, HTTP/2.0) for protocol compliance |\n| headers | HashTable* | Hash table mapping header names to values for O(1) lookup |\n| body | Buffer* | Request body data for POST/PUT requests, may be NULL for GET |\n| content_length | size_t | Size of request body in bytes, -1 if chunked transfer encoding |\n| keep_alive | bool | Whether connection should remain open after response |\n| host | char[256] | Host header value extracted for routing decisions |\n| connection_id | uint64_t | Unique identifier linking request to client connection |\n| timestamp | time_t | Request arrival time for timeout calculations |\n| client_ip | char[46] | Client IP address for logging and forwarding headers |\n\nThe `HttpResponse` structure mirrors the request format while adding caching metadata:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| status_code | int | HTTP status code (200, 404, 500, etc.) |\n| status_text | char[128] | Human-readable status description |\n| headers | HashTable* | Response headers including Content-Type, Cache-Control |\n| body | Buffer* | Response body data to send to client |\n| content_length | size_t | Response body size, may differ from buffer length if compressed |\n| cache_control | char[256] | Cache-Control header value for cache engine decisions |\n| etag | char[128] | ETag header for conditional request validation |\n| last_modified | time_t | Last-Modified timestamp for cache validation |\n| expires | time_t | Response expiration time calculated from cache headers |\n\n> **Decision: Embedded vs. Referenced Header Storage**\n> - **Context**: HTTP headers can be numerous (10-50 per message) and variable in size, accessed frequently during processing\n> - **Options Considered**: Embedded fixed arrays, hash table references, linked lists\n> - **Decision**: Hash table references with case-insensitive string keys\n> - **Rationale**: Hash tables provide O(1) header lookup which is critical for processing performance, case-insensitive keys handle HTTP's case-insensitive header semantics\n> - **Consequences**: Additional memory allocation overhead but significantly faster header access; enables efficient header manipulation and forwarding\n\n#### Connection State Management\n\nNetwork connections in a reverse proxy exist in multiple states as they process requests and maintain persistent connections. The connection state machine drives the event loop and determines valid state transitions:\n\n| Current State | Event | Next State | Actions Taken |\n|---------------|-------|------------|---------------|\n| IDLE | Data Available | READING_REQUEST | Begin HTTP parsing, start request timeout |\n| READING_REQUEST | Complete Request | FORWARDING | Select backend, establish upstream connection |\n| FORWARDING | Upstream Connected | READING_RESPONSE | Send request to backend, start response timeout |\n| READING_RESPONSE | Response Complete | WRITING_RESPONSE | Begin sending response to client |\n| WRITING_RESPONSE | Write Complete | IDLE or CLOSING | Return to IDLE if keep-alive, otherwise CLOSING |\n| Any State | Error or Timeout | CLOSING | Clean up resources, close connections |\n\nThe `Connection` structure maintains all state required for connection lifecycle management:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| client_fd | int | File descriptor for client socket connection |\n| backend_fd | int | File descriptor for upstream backend connection, -1 if not connected |\n| state | ConnectionState | Current connection state for event loop processing |\n| request_buffer | Buffer* | Accumulates incoming request data during parsing |\n| response_buffer | Buffer* | Buffers outgoing response data for client transmission |\n| backend_id | int | Index of selected backend server for this request |\n| created_time | time_t | Connection establishment timestamp |\n| last_activity | time_t | Most recent I/O activity for idle timeout detection |\n| bytes_sent | uint64_t | Total bytes transmitted to client for metrics |\n| bytes_received | uint64_t | Total bytes received from client for metrics |\n| ssl_context | void* | OpenSSL context pointer for HTTPS connections, NULL for HTTP |\n\n#### Performance Metrics and Monitoring\n\nThe `ProxyMetrics` structure aggregates runtime performance data for monitoring and capacity planning:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| requests_processed | uint64_t | Total number of requests handled since startup |\n| requests_cached | uint64_t | Number of requests served from cache |\n| bytes_transferred | uint64_t | Total data transferred in both directions |\n| active_connections | uint32_t | Current number of client connections |\n| backend_failures | uint64_t | Count of backend server error responses |\n| average_response_time | double | Rolling average response time in milliseconds |\n| peak_connections | uint32_t | Maximum concurrent connections observed |\n| uptime_seconds | uint64_t | Server uptime for availability calculations |\n\n### Configuration Model\n\nConfiguration management in a reverse proxy requires balancing flexibility with performance. The configuration model must support runtime updates for operational requirements while maintaining type safety and validation.\n\n#### Primary Configuration Structure\n\nThink of `ProxyConfig` as the master control panel for the entire reverse proxy - every knob, switch, and setting that operators need to tune the system's behavior. Like a car's dashboard that groups related controls (engine, climate, entertainment), the configuration structure organizes settings by functional area while maintaining a single authoritative source.\n\nThe `ProxyConfig` structure serves as the single source of truth for all proxy behavior:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| listen_address | char[256] | IP address to bind for incoming connections, \"0.0.0.0\" for all interfaces |\n| listen_port | int | TCP port number for client connections, typically 80 or 443 |\n| max_connections | int | Maximum concurrent client connections before rejecting new requests |\n| worker_threads | int | Number of event loop threads for connection processing |\n| ssl_enabled | bool | Whether to enable HTTPS/TLS termination |\n| ssl_cert_path | char[512] | File system path to SSL certificate in PEM format |\n| ssl_key_path | char[512] | File system path to SSL private key file |\n| ssl_ca_path | char[512] | Path to certificate authority bundle for client certificate validation |\n| ssl_min_version | int | Minimum TLS version (1.2, 1.3) for security compliance |\n| backend_count | int | Number of configured backend servers in the cluster |\n| backends | BackendServer[32] | Array of backend server configurations |\n| lb_algorithm | LoadBalancingAlgorithm | Algorithm for distributing requests across backends |\n| cache_enabled | bool | Whether to enable HTTP response caching |\n| cache_max_size | size_t | Maximum cache memory usage in bytes |\n| cache_default_ttl | int | Default cache entry lifetime in seconds |\n| cache_exclude_patterns | char[1024] | Regex patterns for URLs to exclude from caching |\n| pool_max_connections | int | Maximum connections per backend server pool |\n| pool_idle_timeout | int | Seconds to keep idle backend connections alive |\n| pool_connect_timeout | int | Timeout for establishing new backend connections |\n| log_level | LogLevel | Minimum severity level for log message output |\n| log_file_path | char[512] | File system path for log output, stdout if empty |\n| log_requests | bool | Whether to log every HTTP request for auditing |\n\n> **Decision: Static vs. Dynamic Backend Configuration**\n> - **Context**: Backend servers may be added, removed, or reconfigured during proxy operation for scaling and maintenance\n> - **Options Considered**: Static array requiring restart, dynamic linked list, configuration file reload\n> - **Decision**: Static array with configuration file reload mechanism\n> - **Rationale**: Static arrays provide predictable memory usage and cache-friendly access patterns; reload mechanism enables updates without losing connection state\n> - **Consequences**: Limits maximum backend count but provides better performance; requires reload coordination to avoid inconsistent state\n\n#### Backend Server Configuration\n\nEach backend server requires comprehensive configuration to support health checking, load balancing, and connection management. The `BackendServer` structure encapsulates all backend-specific settings:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| hostname | char[256] | Backend server hostname or IP address for connection establishment |\n| port | int | TCP port number for backend service, typically 80 or 8080 |\n| weight | int | Relative weight for weighted load balancing algorithms (1-100) |\n| max_connections | int | Maximum concurrent connections to this specific backend |\n| health_check_url | char[512] | HTTP endpoint for health check requests (e.g., \"/health\") |\n| health_check_interval | int | Seconds between health check probes |\n| health_check_timeout | int | Timeout for health check request completion |\n| failure_threshold | int | Consecutive failures before marking backend unhealthy |\n| recovery_threshold | int | Consecutive successes required to mark backend healthy again |\n| is_healthy | bool | Current health status for load balancing decisions |\n| last_health_check | time_t | Timestamp of most recent health check attempt |\n| total_requests | uint64_t | Lifetime request count for load balancing statistics |\n| failed_requests | uint64_t | Count of requests that resulted in errors |\n| average_response_time | double | Rolling average response time for performance-based routing |\n| ssl_required | bool | Whether backend connections must use HTTPS |\n| ssl_verify | bool | Whether to validate backend SSL certificates |\n\nThe backend configuration enables sophisticated load balancing algorithms that consider server capacity, health status, and historical performance. Weight-based distribution allows operators to account for heterogeneous backend hardware, while health checking ensures requests avoid failed servers.\n\n#### Load Balancing Algorithm Configuration\n\nThe `LoadBalancingAlgorithm` enumeration defines the available request distribution strategies:\n\n| Algorithm | Description | Use Case | Considerations |\n|-----------|-------------|----------|----------------|\n| ROUND_ROBIN | Distributes requests sequentially across healthy backends | Equal backend capacity | Simple but ignores server load |\n| LEAST_CONNECTIONS | Routes to backend with fewest active connections | Variable request processing time | Requires connection count tracking |\n| WEIGHTED_ROUND_ROBIN | Distributes based on configured backend weights | Mixed backend capacity | Weights must reflect actual performance |\n| IP_HASH | Consistent routing based on client IP hash | Session affinity requirements | May cause uneven distribution |\n| RANDOM | Random selection among healthy backends | Simple load distribution | No performance optimization |\n\n> **Decision: Algorithm Selection Criteria**\n> - **Context**: Different applications have varying requirements for load distribution and session handling\n> - **Options Considered**: Single algorithm, runtime selection, automatic algorithm selection\n> - **Decision**: Runtime selection with configuration override capability\n> - **Rationale**: Different traffic patterns benefit from different algorithms; operators need flexibility to optimize for their specific workload characteristics\n> - **Consequences**: Increases configuration complexity but enables performance tuning; requires implementation of multiple algorithm variants\n\n#### Cache Configuration Model\n\nResponse caching requires careful configuration to balance performance gains with memory usage and cache coherence. The cache configuration integrates with HTTP semantics to provide correct caching behavior:\n\n| Configuration Aspect | Implementation | Rationale |\n|---------------------|----------------|-----------|\n| Cache Key Generation | URL + Host + Vary headers | Ensures correct cache isolation per content variant |\n| Size Management | LRU eviction with memory limits | Provides predictable memory usage with automatic cleanup |\n| TTL Calculation | Min(Cache-Control max-age, configured default) | Respects HTTP semantics while providing fallback values |\n| Invalidation Strategy | Time-based expiry + manual purge | Supports both automatic and operational cache management |\n\n⚠️ **Pitfall: Cache Key Collisions**\nMany implementations generate cache keys using only the request URL, which causes incorrect cache hits when the same URL serves different content based on request headers like Accept-Encoding or Accept-Language. The cache key must include all headers listed in the response's Vary header to ensure cache correctness.\n\n#### Logging and Monitoring Configuration\n\nThe logging subsystem provides operational visibility into proxy behavior and performance. The `LogLevel` enumeration controls message verbosity:\n\n| Log Level | Purpose | Example Messages |\n|-----------|---------|------------------|\n| DEBUG | Detailed internal state | Connection state transitions, header parsing details |\n| INFO | Normal operational events | Request processing, backend selection, cache hits |\n| WARN | Concerning but recoverable conditions | Backend failures, retry attempts, cache evictions |\n| ERROR | Serious problems requiring attention | Configuration errors, resource exhaustion, SSL failures |\n\nRequest logging captures complete HTTP transaction details for security auditing and traffic analysis. The log format includes client IP, timestamp, request line, response status, processing time, and backend server selection.\n\n### Common Data Model Pitfalls\n\n⚠️ **Pitfall: Insufficient Buffer Bounds Checking**\nMany implementations allocate fixed-size buffers for HTTP headers and URIs but fail to validate input lengths, leading to buffer overflows. Every buffer operation must check available capacity and handle overflow conditions gracefully, either by rejecting oversized requests or dynamically resizing buffers.\n\n⚠️ **Pitfall: Memory Leaks in Error Paths**\nComplex data structures like `HttpRequest` and `HttpResponse` contain multiple heap-allocated components (buffers, hash tables). Error handling during parsing or processing often forgets to deallocate partially constructed objects, causing memory leaks under failure conditions. Every allocation must have a corresponding cleanup path.\n\n⚠️ **Pitfall: Race Conditions in Shared State**\nConfiguration updates and metrics collection occur concurrently with request processing, but many implementations access shared data structures without proper synchronization. The configuration reload process must use atomic updates or reader-writer locks to prevent corruption of active request processing.\n\n⚠️ **Pitfall: Inconsistent String Handling**\nHTTP protocols require case-insensitive header name comparisons but case-sensitive value handling. Implementations often apply inconsistent string comparison functions, causing header lookup failures or incorrect cache key generation. All header name operations must use case-insensitive comparison while preserving original case for forwarding.\n\n### Implementation Guidance\n\nThe data model implementation requires careful attention to memory management, thread safety, and performance optimization. The following guidance provides concrete implementation strategies for the core data structures.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Hash Tables | Linear probing with string keys | Robin Hood hashing with SipHash |\n| Memory Management | malloc/free with explicit cleanup | Memory pools with arena allocation |\n| String Handling | strdup/strcasecmp with manual bounds | Interned strings with length prefixes |\n| Configuration Parsing | Simple key-value parser | Full YAML/JSON parser with validation |\n| Buffer Management | Exponential growth with realloc | Ring buffers with memory mapping |\n\n#### Recommended File Structure\n\n```\nsrc/\n  data/\n    buffer.h              ← Buffer structure and operations\n    buffer.c\n    http_message.h        ← HTTP request/response structures  \n    http_message.c\n    connection.h          ← Connection state management\n    connection.c\n    config.h              ← Configuration structures and loading\n    config.c\n    metrics.h             ← Performance monitoring structures\n    metrics.c\n  utils/\n    hashtable.h           ← Hash table implementation\n    hashtable.c\n    logger.h              ← Logging infrastructure\n    logger.c\n  tests/\n    test_buffer.c         ← Unit tests for data structures\n    test_http_message.c\n    test_config.c\n```\n\n#### Buffer Implementation\n\nThe buffer provides the foundation for all data handling operations. This implementation handles dynamic growth and streaming operations:\n\n```c\n#include <stdlib.h>\n#include <string.h>\n#include <stdbool.h>\n\ntypedef struct {\n    char* data;\n    size_t capacity;\n    size_t length;\n    size_t position;\n} Buffer;\n\n// Buffer management functions - complete implementation\nBuffer* buffer_create(size_t initial_capacity) {\n    // TODO 1: Allocate Buffer structure\n    // TODO 2: Allocate initial data array with initial_capacity\n    // TODO 3: Initialize capacity, set length and position to 0\n    // TODO 4: Return NULL if any allocation fails\n}\n\nbool buffer_append(Buffer* buffer, const char* data, size_t data_len) {\n    // TODO 1: Check if current capacity can hold additional data\n    // TODO 2: If insufficient, calculate new capacity (double until fits)\n    // TODO 3: Reallocate data array with new capacity using realloc\n    // TODO 4: Copy new data to end of existing content\n    // TODO 5: Update length to reflect new data\n    // Hint: Always null-terminate for string operations\n}\n\nsize_t buffer_read(Buffer* buffer, char* dest, size_t max_len) {\n    // TODO 1: Calculate available data from position to length\n    // TODO 2: Determine actual read size (min of available and max_len)\n    // TODO 3: Copy data from buffer starting at position\n    // TODO 4: Advance position by amount read\n    // TODO 5: Return actual bytes read\n}\n\nvoid buffer_reset(Buffer* buffer) {\n    // TODO: Reset length and position to 0, keep allocated memory\n}\n\nvoid buffer_destroy(Buffer* buffer) {\n    // TODO 1: Free data array if not NULL\n    // TODO 2: Free Buffer structure\n    // TODO 3: Handle NULL buffer parameter gracefully\n}\n```\n\n#### Hash Table Infrastructure\n\nHTTP header management requires efficient string-based lookups with case-insensitive keys:\n\n```c\n#include <stdint.h>\n\n#define HASHTABLE_INITIAL_SIZE 16\n#define HASHTABLE_LOAD_FACTOR 0.75\n\ntypedef struct HashEntry {\n    char* key;\n    void* value;\n    struct HashEntry* next;  // Chain for collision resolution\n} HashEntry;\n\ntypedef struct {\n    HashEntry** buckets;\n    size_t size;\n    size_t count;\n} HashTable;\n\nHashTable* hashtable_create(size_t initial_size) {\n    // TODO 1: Allocate HashTable structure\n    // TODO 2: Allocate array of bucket pointers, initialize to NULL\n    // TODO 3: Set size and count fields\n    // TODO 4: Return hashtable or NULL on failure\n}\n\nuint32_t hash_string_case_insensitive(const char* str) {\n    // TODO 1: Implement djb2 hash algorithm\n    // TODO 2: Convert each character to lowercase before hashing\n    // TODO 3: Return hash value for bucket selection\n    // Hint: Use tolower() for consistent case handling\n}\n\nbool hashtable_put(HashTable* table, const char* key, void* value) {\n    // TODO 1: Check if resize needed (count/size > LOAD_FACTOR)\n    // TODO 2: Calculate bucket index using hash_string_case_insensitive\n    // TODO 3: Search existing chain for key (case-insensitive comparison)\n    // TODO 4: Update existing entry or create new entry in chain\n    // TODO 5: Increment count if new entry added\n    // Hint: Use strcasecmp for case-insensitive key comparison\n}\n\nvoid* hashtable_get(HashTable* table, const char* key) {\n    // TODO 1: Calculate bucket index using hash function\n    // TODO 2: Walk chain comparing keys with strcasecmp\n    // TODO 3: Return value if found, NULL otherwise\n}\n```\n\n#### HTTP Message Structures\n\nComplete HTTP request and response handling with proper resource management:\n\n```c\n#include \"buffer.h\"\n#include \"hashtable.h\"\n#include <time.h>\n\ntypedef struct {\n    char method[16];\n    char uri[2048];\n    char version[16];\n    HashTable* headers;\n    Buffer* body;\n    size_t content_length;\n    bool keep_alive;\n    char host[256];\n    uint64_t connection_id;\n    time_t timestamp;\n    char client_ip[46];  // IPv6-compatible\n} HttpRequest;\n\ntypedef struct {\n    int status_code;\n    char status_text[128];\n    HashTable* headers;\n    Buffer* body;\n    size_t content_length;\n    char cache_control[256];\n    char etag[128];\n    time_t last_modified;\n    time_t expires;\n} HttpResponse;\n\nHttpRequest* http_request_create() {\n    // TODO 1: Allocate HttpRequest structure\n    // TODO 2: Initialize all string fields to empty\n    // TODO 3: Create headers hash table\n    // TODO 4: Set timestamp to current time\n    // TODO 5: Initialize numeric fields to sensible defaults\n}\n\nvoid http_request_destroy(HttpRequest* request) {\n    // TODO 1: Destroy headers hash table\n    // TODO 2: Destroy body buffer if not NULL\n    // TODO 3: Free request structure\n    // TODO 4: Handle NULL parameter gracefully\n}\n\nbool http_request_add_header(HttpRequest* request, const char* name, const char* value) {\n    // TODO 1: Validate name and value parameters\n    // TODO 2: Create copies of name and value strings\n    // TODO 3: Add to headers hash table\n    // TODO 4: Handle special headers (Host, Content-Length, Connection)\n    // Hint: Extract host for routing, parse content-length, detect keep-alive\n}\n\nconst char* http_request_get_header(HttpRequest* request, const char* name) {\n    // TODO: Use hashtable_get with case-insensitive lookup\n}\n```\n\n#### Configuration Management\n\nConfiguration loading and validation with comprehensive error handling:\n\n```c\n#include <stdio.h>\n\ntypedef enum {\n    ROUND_ROBIN,\n    LEAST_CONNECTIONS,  \n    WEIGHTED_ROUND_ROBIN,\n    IP_HASH,\n    RANDOM\n} LoadBalancingAlgorithm;\n\ntypedef enum {\n    DEBUG,\n    INFO,\n    WARN,\n    ERROR\n} LogLevel;\n\ntypedef struct {\n    char hostname[256];\n    int port;\n    int weight;\n    int max_connections;\n    char health_check_url[512];\n    int health_check_interval;\n    int health_check_timeout;\n    int failure_threshold;\n    int recovery_threshold;\n    bool is_healthy;\n    time_t last_health_check;\n    uint64_t total_requests;\n    uint64_t failed_requests;\n    double average_response_time;\n    bool ssl_required;\n    bool ssl_verify;\n} BackendServer;\n\nProxyConfig* config_load(const char* config_file) {\n    // TODO 1: Open configuration file for reading\n    // TODO 2: Parse key-value pairs line by line\n    // TODO 3: Populate ProxyConfig structure fields\n    // TODO 4: Parse backend server sections\n    // TODO 5: Validate all configuration values\n    // TODO 6: Return NULL if any validation fails\n    // Hint: Use simple \"key=value\" format for easier parsing\n}\n\nbool config_validate(ProxyConfig* config) {\n    // TODO 1: Check required fields are not empty\n    // TODO 2: Validate port numbers are in valid range (1-65535)\n    // TODO 3: Verify SSL certificate files exist if SSL enabled\n    // TODO 4: Check at least one backend server is configured\n    // TODO 5: Validate backend server configurations\n    // TODO 6: Ensure resource limits are reasonable\n    // Hint: Use access() to check file existence\n}\n```\n\n#### Milestone Checkpoints\n\n**After Data Structures Implementation:**\n1. Run `gcc -Wall -Wextra -std=c99 -o test_data tests/test_buffer.c src/data/buffer.c`\n2. Execute `./test_data` - should show all buffer operations working correctly\n3. Test hash table operations: put/get with case-insensitive keys\n4. Verify HTTP message creation and header manipulation\n5. Load sample configuration file and verify all fields populated\n\n**Expected Output:**\n```\nBuffer tests: PASSED\nHash table tests: PASSED  \nHTTP message tests: PASSED\nConfiguration loading: PASSED\nAll data structure tests completed successfully\n```\n\n**Signs of Problems:**\n- Segmentation faults indicate memory management errors\n- Hash table get returns NULL for keys that were put\n- Configuration validation fails on valid config files\n- Memory leaks detected by valgrind during testing\n\n![Data Model Relationships](./diagrams/data-model-relationships.svg)\n\n\n## HTTP Parser Component\n\n> **Milestone(s):** Milestone 1 (HTTP Proxy Core), Milestone 4 (Caching), Milestone 5 (SSL Termination) - the HTTP parser forms the foundation for request processing, cache-control header parsing, and protocol handling across encrypted and unencrypted connections.\n\nThe HTTP parser component serves as the linguistic translator of our reverse proxy system. Think of it as a skilled interpreter at the United Nations who must fluently understand multiple dialects of the same language - HTTP/1.1 and HTTP/2 - and accurately convert the spoken words (raw bytes from network sockets) into structured meaning (parsed request and response objects) that other components can work with. Just as an interpreter must handle incomplete sentences, interruptions, and speaking errors gracefully, our parser must handle partial data reads, malformed headers, and protocol violations without crashing the entire system.\n\nThe parser operates as a **stream-based state machine** rather than a simple string processor. This architectural choice stems from the fundamental nature of network communication: data arrives in chunks of unpredictable size, and we cannot assume that a complete HTTP message will arrive in a single network read operation. The parser must maintain state across multiple read operations, gradually building up a complete picture of the incoming request while handling the uncertainty of when the next piece of data will arrive.\n\n### Parser Architecture\n\nThe HTTP parser architecture centers around a **finite state machine** that processes incoming byte streams incrementally. Think of this state machine as a factory assembly line where each station (state) performs a specific parsing operation on the data before passing it to the next station. Unlike a traditional assembly line that processes discrete physical objects, our parsing assembly line processes a continuous stream of bytes, gradually building up the final product (a complete `HttpRequest` structure) as data flows through each processing stage.\n\nThe parser maintains four critical pieces of state information: the current parsing position within the input stream, the current parsing state (which determines what type of data we expect next), a working buffer for accumulating partial data, and the partially constructed request object that gets populated as parsing progresses. This stateful approach allows the parser to handle the fundamental challenge of network programming: data arrives in arbitrary chunk sizes that rarely align with message boundaries.\n\n![Request Processing Sequence](./diagrams/request-flow-sequence.svg)\n\nThe state machine progresses through a well-defined sequence of parsing phases, each responsible for extracting specific components of the HTTP message format. The **request line parsing state** extracts the HTTP method, request URI, and protocol version from the first line of the request. The **header parsing state** iterates through name-value pairs until it encounters the empty line that signals the end of headers. The **body length determination state** examines `Content-Length` and `Transfer-Encoding` headers to understand how much request body data to expect. Finally, the **body parsing state** accumulates the request payload according to the length or chunking rules determined in the previous state.\n\nEach state transition occurs when the parser encounters specific delimiter sequences in the input stream. The transition from request line parsing to header parsing triggers when the parser encounters the `\\r\\n` sequence that terminates the request line. Similarly, the transition from header parsing to body parsing occurs when the parser encounters the `\\r\\n\\r\\n` sequence that indicates the end of headers. The parser must handle cases where these delimiter sequences span multiple read operations - for example, when a network read returns data ending with `\\r` and the next read begins with `\\n`.\n\n![Connection State Machine](./diagrams/connection-state-machine.svg)\n\nThe parser integrates closely with the connection state machine shown in the diagram above. When a connection enters the `READING_REQUEST` state, it activates the HTTP parser to process incoming bytes. The parser operates incrementally, consuming available data and updating its internal state without blocking the event loop. When the parser completes request parsing, it signals the connection manager to transition the connection to the `FORWARDING` state, where the load balancer takes over to select an appropriate backend server.\n\nThe following table details each parsing state, its responsibilities, and transition conditions:\n\n| State | Purpose | Input Expected | Transition Trigger | Next State | Error Conditions |\n|-------|---------|---------------|-------------------|------------|-----------------|\n| PARSING_REQUEST_LINE | Extract HTTP method, URI, version | \"GET /path HTTP/1.1\\r\\n\" | Found \\r\\n sequence | PARSING_HEADERS | Invalid method, malformed URI, unsupported version |\n| PARSING_HEADERS | Extract header name-value pairs | \"Host: example.com\\r\\n\" | Found \\r\\n\\r\\n sequence | DETERMINING_BODY_LENGTH | Invalid header format, header too long |\n| DETERMINING_BODY_LENGTH | Calculate expected body size | Content-Length or Transfer-Encoding headers | Length calculated | PARSING_BODY or PARSING_COMPLETE | Conflicting length headers, invalid encoding |\n| PARSING_BODY | Read request body content | Raw body bytes or chunked data | Read expected bytes | PARSING_COMPLETE | Body exceeds limits, chunking format error |\n| PARSING_COMPLETE | Request ready for forwarding | No more input expected | External trigger | Reset to PARSING_REQUEST_LINE | N/A |\n\nThe parser's buffer management strategy plays a crucial role in memory efficiency and performance. The parser maintains a single `Buffer` structure that grows as needed to accommodate the incoming request data. The buffer uses a **sliding window approach** where parsed data gets discarded from the beginning of the buffer while new data gets appended to the end. This approach prevents memory usage from growing unboundedly during long-lived connections that process many sequential requests.\n\nThe buffer management algorithm operates as follows: when the parser completes parsing a particular component (such as the request line), it advances the buffer's position marker to skip over the consumed data. When the buffer becomes more than half empty due to position advancement, the parser triggers a **buffer compaction** operation that shifts the remaining unparsed data to the beginning of the buffer and resets the position marker to zero. This compaction prevents fragmentation while ensuring that the buffer can continue accepting new data without constant reallocation.\n\nThe parser handles **protocol version detection** by examining the request line's version field and configuring subsequent parsing behavior accordingly. HTTP/1.1 requests use text-based header parsing with specific rules for handling connection persistence, chunked encoding, and trailer headers. HTTP/2 requests require binary frame parsing with different state transitions and data structures. The parser maintains separate state machines for each protocol version, switching between them based on the detected protocol during request line parsing.\n\nFor HTTP/1.1 parsing, the parser must handle several complex scenarios including **chunked transfer encoding**, where the request body arrives in variable-sized chunks each prefixed with a hexadecimal length indicator. The parser transitions into a sub-state machine for chunked parsing that alternates between reading chunk size lines and chunk data blocks. Each chunk ends with a `\\r\\n` sequence, and the final chunk has size zero followed by optional trailer headers.\n\n### Parser Design Decisions\n\nThe architecture of the HTTP parser component required several critical design decisions that fundamentally impact performance, memory usage, and maintainability. Each decision represents a carefully considered trade-off between competing concerns, and understanding the rationale behind these choices provides insight into the engineering principles that guide robust system design.\n\n> **Decision: Stream-Based vs. Buffer-All Parsing Strategy**\n> - **Context**: HTTP messages can be arbitrarily large, and network data arrives in unpredictable chunk sizes. We must choose between accumulating complete messages before parsing or parsing incrementally as data arrives.\n> - **Options Considered**: Complete message buffering, incremental stream parsing, hybrid buffering with size limits\n> - **Decision**: Incremental stream-based parsing with sliding buffer windows\n> - **Rationale**: Stream parsing enables constant memory usage regardless of request size, reduces latency by starting processing before complete message arrival, and prevents denial-of-service attacks through memory exhaustion. The complexity of state management is justified by these significant benefits.\n> - **Consequences**: Enables handling of large file uploads and streaming requests, requires sophisticated state machine implementation, complicates error handling and recovery, but provides predictable memory usage patterns.\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Buffer Complete Message | Simple parsing logic, easy error handling, straightforward testing | Unbounded memory usage, high latency for large requests, DoS vulnerability | No |\n| Incremental Stream Parsing | Constant memory usage, low latency, DoS protection | Complex state machine, difficult error recovery, testing complexity | **Yes** |\n| Hybrid Size-Limited Buffer | Balanced approach, predictable memory limits | Arbitrary size limits, still vulnerable to smaller DoS attacks | No |\n\n> **Decision: Single State Machine vs. Protocol-Specific Parsers**\n> - **Context**: The reverse proxy must support both HTTP/1.1 and HTTP/2 protocols, which have fundamentally different message formats (text vs. binary). We need to decide how to structure the parsing logic.\n> - **Options Considered**: Unified state machine handling both protocols, separate parsers per protocol, protocol detection with delegation\n> - **Decision**: Protocol detection with delegation to specialized parsers\n> - **Rationale**: HTTP/1.1 and HTTP/2 have incompatible parsing requirements that would create excessive complexity in a unified parser. Separate parsers allow optimization for each protocol's characteristics while maintaining clean interfaces.\n> - **Consequences**: Clean separation of concerns, protocol-specific optimizations possible, requires protocol detection logic, slightly higher code complexity, but improved maintainability and performance.\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| Unified State Machine | Single codebase to maintain, shared parsing infrastructure | Complex conditional logic, poor performance optimization, difficult testing | No |\n| Protocol-Specific Parsers | Clean separation, optimized for each protocol, maintainable | Code duplication, requires detection logic, larger codebase | **Yes** |\n| Shared Components | Some code reuse, moderate complexity | Forced abstractions, unclear boundaries | No |\n\n> **Decision: Copy vs. Zero-Copy Header Processing**\n> - **Context**: HTTP headers must be extracted from the input stream and made available to other components. We can either copy header data into separate strings or maintain references into the original buffer.\n> - **Options Considered**: Copy all headers to separate strings, zero-copy with buffer references, hybrid approach with selective copying\n> - **Decision**: Selective copying based on header usage patterns\n> - **Rationale**: Critical headers needed by multiple components (Host, Content-Length) benefit from copying to avoid buffer lifetime dependencies. Less frequently accessed headers can use zero-copy references to reduce allocation overhead.\n> - **Consequences**: Optimizes for common case performance, requires careful buffer lifetime management, complicates memory management, but achieves good balance of performance and safety.\n\n> **Decision: Error Recovery vs. Connection Termination Strategy**\n> - **Context**: Malformed HTTP requests can occur due to client bugs, network corruption, or malicious attacks. We must decide how aggressively to attempt recovery versus terminating problematic connections.\n> - **Options Considered**: Strict RFC compliance with connection termination, lenient parsing with error recovery, configurable strictness levels\n> - **Decision**: Lenient parsing with graceful degradation and connection termination for severe violations\n> - **Rationale**: Internet traffic contains many minor protocol violations from legitimate clients. Overly strict parsing would reject valid traffic, while overly lenient parsing could enable security vulnerabilities. A balanced approach maximizes compatibility while maintaining security.\n> - **Consequences**: Improved client compatibility, requires extensive testing of edge cases, potential security considerations, but achieves good balance of robustness and standards compliance.\n\nThe parser's **buffer management strategy** represents another crucial architectural decision. The sliding window approach chosen here optimizes for long-lived connections that process many requests sequentially. Alternative approaches such as fixed-size circular buffers or linked buffer chains each offer different trade-offs between memory usage, allocation overhead, and implementation complexity.\n\nThe sliding window buffer provides **optimal memory locality** for parsing operations since related data remains contiguous in memory. This locality improves CPU cache performance during header parsing, where the parser frequently scans backward and forward through recently processed data. The compaction mechanism ensures that buffer memory doesn't grow unboundedly while maintaining the locality benefits.\n\nBuffer compaction triggers based on a **fractional occupancy threshold** rather than absolute sizes. When the buffer's unprocessed data occupies less than 25% of the total buffer capacity, the compaction algorithm shifts the remaining data to the beginning of the buffer. This threshold balances compaction overhead against memory efficiency - too frequent compaction wastes CPU cycles, while infrequent compaction wastes memory.\n\nThe parser implements **header validation** according to RFC 9110 specifications while allowing common deviations found in real-world HTTP traffic. Header names must consist only of token characters (alphanumeric plus specific punctuation), while header values allow a broader range of characters including spaces and international characters encoded in UTF-8. The parser rejects headers with null bytes or control characters that could enable request smuggling attacks.\n\n### Common Parser Pitfalls\n\nHTTP parser implementation contains numerous subtle pitfalls that can lead to security vulnerabilities, compatibility issues, or performance problems. Understanding these common mistakes helps developers avoid well-known traps and build robust, secure parsers that handle the complexities of real-world HTTP traffic.\n\n⚠️ **Pitfall: Incomplete Read Handling**\nThe most fundamental mistake in HTTP parser implementation involves assuming that network reads will return complete, well-formed data. Beginning developers often write parsing code that expects to receive complete request lines or headers in a single read operation. In reality, TCP provides a byte stream abstraction where data arrives in arbitrary chunk sizes determined by network conditions, buffer sizes, and timing.\n\nConsider a scenario where a client sends the request line \"GET /api/users HTTP/1.1\\r\\n\" but the first network read returns only \"GET /api/us\" and the remainder arrives in subsequent reads. A naive parser that searches for the \"\\r\\n\" delimiter in the first read will fail to find it and may incorrectly conclude that the request line is malformed. The correct approach involves accumulating data across multiple reads until the complete delimiter sequence is found.\n\nThis pitfall manifests in several ways: prematurely rejecting valid requests due to incomplete data, buffer overruns when assuming data length, and state machine corruption when partial delimiters span read boundaries. The solution requires implementing proper buffering with incremental delimiter detection that can handle delimiter sequences split across read operations.\n\n⚠️ **Pitfall: HTTP Request Smuggling via Header Parsing**\nHTTP request smuggling represents one of the most serious security vulnerabilities in parser implementation. This attack exploits discrepancies in how different systems parse HTTP messages with ambiguous length information. The vulnerability typically arises from incorrect handling of `Content-Length` and `Transfer-Encoding` headers when both are present in the same request.\n\nRFC 9110 specifies that requests containing both `Content-Length` and `Transfer-Encoding: chunked` headers must ignore the `Content-Length` header and process the request as chunked. However, parsers that prioritize `Content-Length` over `Transfer-Encoding` create opportunities for request smuggling. An attacker can craft requests where the reverse proxy and backend server disagree on message boundaries, allowing injection of additional requests into the connection stream.\n\nThe correct implementation must strictly follow the RFC precedence rules: check for `Transfer-Encoding: chunked` first, and if present, ignore any `Content-Length` headers. Additionally, the parser must reject requests with multiple `Content-Length` headers containing different values, as this represents a clear protocol violation that could indicate an attack attempt.\n\n⚠️ **Pitfall: Memory Exhaustion via Unbounded Buffering**\nParsers that continuously accumulate incoming data without size limits create denial-of-service vulnerabilities where attackers can exhaust server memory by sending extremely large requests. This pitfall commonly occurs in implementations that buffer entire requests before beginning processing, or that fail to implement maximum size limits on headers and request bodies.\n\nThe vulnerability manifests when an attacker sends requests with enormous header sections (for example, a single header with megabytes of data) or claims extremely large content lengths without sending corresponding body data. The parser allocates memory to accommodate the claimed data size but never receives enough data to complete parsing, leaving large buffers allocated indefinitely.\n\nMitigation requires implementing strict limits at multiple levels: maximum total header size (typically 8KB-16KB), maximum individual header length, maximum request line length, and maximum request body size. The parser should reject requests that exceed these limits immediately rather than attempting to buffer them. Additionally, implementing timeouts prevents slow-send attacks where attackers send valid data extremely slowly to maintain connections indefinitely.\n\n⚠️ **Pitfall: Case Sensitivity in Header Names**\nHTTP header names are case-insensitive according to the specification, but many parser implementations perform case-sensitive comparisons when processing headers. This creates compatibility issues where requests with headers like \"Content-length\" (lowercase 'l') or \"HOST\" (uppercase) fail to match expected header names.\n\nThe issue becomes particularly problematic when integrating with other HTTP libraries or when forwarding requests to backend servers that may have different case sensitivity behaviors. Some backend servers or frameworks expect specific header name capitalization patterns, leading to subtle failures when the parser normalizes header names differently than expected.\n\nThe correct approach involves normalizing header names to a consistent case (typically lowercase) during parsing while preserving the original case when forwarding requests. Hash table implementations used for header storage must use case-insensitive comparison functions. When extracting headers for processing (such as checking `Content-Length` for body parsing), use normalized lookups that handle any case variation.\n\n⚠️ **Pitfall: Improper URI Decoding and Validation**\nRequest URI parsing involves multiple layers of encoding and validation that create numerous opportunities for security vulnerabilities. Common mistakes include performing URL decoding multiple times (double-decoding), failing to validate decoded paths for directory traversal attempts, and incorrectly handling international characters in URIs.\n\nDouble-decoding occurs when the parser URL-decodes the request URI and then passes it to another component that performs additional URL decoding. An attacker can exploit this by encoding malicious sequences multiple times - for example, encoding \"../\" as \"%252e%252e%252f\" where the \"%25\" sequences decode to \"%\" characters that form new percent-encoded sequences in the second decoding pass.\n\nDirectory traversal attacks exploit insufficient path validation after URL decoding. Attackers encode sequences like \"../\" to bypass naive string-based filtering, then use the decoded paths to access files outside the intended directory structure. The parser must validate decoded paths to ensure they don't contain directory traversal sequences or resolve to unauthorized locations.\n\nInternational character handling requires careful attention to UTF-8 encoding and normalization. Different UTF-8 sequences can represent the same logical character, creating opportunities for filter bypassing if validation occurs before normalization. The parser must handle UTF-8 decoding errors gracefully and apply consistent normalization rules.\n\n⚠️ **Pitfall: Chunked Encoding Implementation Errors**\nChunked transfer encoding parsing contains several subtle complexities that frequently trip up implementers. The most common errors involve incorrect hex parsing of chunk sizes, improper handling of chunk extensions, and failure to process trailer headers that may follow the final chunk.\n\nChunk size parsing must handle hexadecimal numbers with optional leading zeros and case-insensitive hex digits. However, parsers must also handle chunk extensions - optional parameters that follow the chunk size on the same line separated by semicolons. For example: \"1a;charset=utf-8\\r\\n\" indicates a chunk of 26 bytes with an extension parameter. Parsers that don't expect extensions may fail when encountering them.\n\nThe final chunk in a chunked message has size zero and may be followed by trailer headers that use the same syntax as regular headers. These trailers must be parsed and potentially merged with the main header set. Many implementations incorrectly assume that the zero-size chunk marks the absolute end of the message and fail to process trailers.\n\nProper chunked encoding implementation requires a sub-state machine that alternates between reading chunk size lines and chunk data blocks. The parser must validate that exactly the specified number of bytes are received for each chunk and that each chunk ends with the correct \"\\r\\n\" sequence.\n\n### Implementation Guidance\n\nThe HTTP parser implementation requires careful attention to performance, security, and correctness. This guidance provides concrete recommendations for building a robust parser that handles real-world HTTP traffic while maintaining security and efficiency.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| HTTP/1.1 Parser | Custom state machine with string operations | Optimized state machine with SIMD string scanning |\n| HTTP/2 Parser | HTTP/2 frame parsing library (nghttp2) | Custom binary frame parser with zero-copy |\n| Buffer Management | Dynamic reallocation with memmove compaction | Ring buffer with scatter-gather I/O |\n| Header Storage | Hash table with string keys | Trie structure with interned strings |\n| URI Parsing | Standard library URL parsing | Custom parser with validation |\n\n**Recommended File Structure:**\n\n```\nsrc/\n  http/\n    parser.c              ← Main parser state machine\n    parser.h              ← Parser interface and structures\n    http1_parser.c        ← HTTP/1.1 specific parsing logic\n    http2_parser.c        ← HTTP/2 frame parsing logic\n    buffer.c              ← Buffer management utilities\n    buffer.h              ← Buffer structure and operations\n    headers.c             ← Header parsing and storage\n    headers.h             ← Header manipulation interface\n    uri_parser.c          ← URI parsing and validation\n    test/\n      test_parser.c       ← Parser unit tests\n      test_buffer.c       ← Buffer management tests\n      test_headers.c      ← Header parsing tests\n```\n\n**HTTP Parser Core Structures:**\n\n```c\n#include <stddef.h>\n#include <stdbool.h>\n#include <sys/types.h>\n\n// Buffer management structure for incremental parsing\ntypedef struct {\n    char* data;           // Buffer memory allocation\n    size_t capacity;      // Total allocated buffer size\n    size_t length;        // Current data length in buffer\n    size_t position;      // Current parsing position\n} Buffer;\n\n// HTTP parser state enumeration\ntypedef enum {\n    HTTP_PARSING_REQUEST_LINE,\n    HTTP_PARSING_HEADERS,\n    HTTP_DETERMINING_BODY_LENGTH,\n    HTTP_PARSING_BODY,\n    HTTP_PARSING_CHUNKED_SIZE,\n    HTTP_PARSING_CHUNKED_DATA,\n    HTTP_PARSING_COMPLETE,\n    HTTP_PARSING_ERROR\n} HttpParserState;\n\n// HTTP request structure populated by parser\ntypedef struct {\n    char method[16];          // HTTP method (GET, POST, etc.)\n    char uri[2048];          // Request URI path and query\n    char version[16];        // HTTP version (1.1, 2.0)\n    HashTable* headers;      // Header name-value pairs\n    Buffer* body;            // Request body content\n    size_t content_length;   // Content-Length header value\n    bool chunked;            // Transfer-Encoding: chunked flag\n    bool keep_alive;         // Connection persistence flag\n} HttpRequest;\n\n// HTTP parser context maintaining state across reads\ntypedef struct {\n    HttpParserState state;       // Current parsing state\n    Buffer* input_buffer;        // Accumulated input data\n    HttpRequest* current_request; // Request being parsed\n    size_t bytes_remaining;      // Body bytes still expected\n    size_t chunk_size;          // Current chunk size (chunked mode)\n    bool chunk_size_parsed;     // Chunk size line completion flag\n} HttpParser;\n```\n\n**Core Parser Infrastructure (Complete Implementation):**\n\n```c\n// Buffer management functions - complete implementation ready to use\nBuffer* buffer_create(size_t initial_capacity) {\n    Buffer* buf = malloc(sizeof(Buffer));\n    if (!buf) return NULL;\n    \n    buf->data = malloc(initial_capacity);\n    if (!buf->data) {\n        free(buf);\n        return NULL;\n    }\n    \n    buf->capacity = initial_capacity;\n    buf->length = 0;\n    buf->position = 0;\n    return buf;\n}\n\nbool buffer_append(Buffer* buf, char* data, size_t size) {\n    // Compact buffer if more than 75% consumed\n    if (buf->position > buf->capacity * 3 / 4) {\n        size_t remaining = buf->length - buf->position;\n        memmove(buf->data, buf->data + buf->position, remaining);\n        buf->length = remaining;\n        buf->position = 0;\n    }\n    \n    // Expand buffer if needed\n    while (buf->length + size > buf->capacity) {\n        size_t new_capacity = buf->capacity * 2;\n        char* new_data = realloc(buf->data, new_capacity);\n        if (!new_data) return false;\n        buf->data = new_data;\n        buf->capacity = new_capacity;\n    }\n    \n    memcpy(buf->data + buf->length, data, size);\n    buf->length += size;\n    return true;\n}\n\nsize_t buffer_read(Buffer* buf, char* dest, size_t max_size) {\n    size_t available = buf->length - buf->position;\n    size_t to_read = (available < max_size) ? available : max_size;\n    memcpy(dest, buf->data + buf->position, to_read);\n    buf->position += to_read;\n    return to_read;\n}\n\n// Header management functions - complete implementation\nHashTable* headers_create() {\n    return hashtable_create(32); // Start with 32 header slots\n}\n\nbool headers_add(HashTable* headers, const char* name, const char* value) {\n    // Normalize header name to lowercase for case-insensitive lookup\n    char* normalized_name = malloc(strlen(name) + 1);\n    for (int i = 0; name[i]; i++) {\n        normalized_name[i] = tolower(name[i]);\n    }\n    normalized_name[strlen(name)] = '\\0';\n    \n    char* value_copy = malloc(strlen(value) + 1);\n    strcpy(value_copy, value);\n    \n    bool result = hashtable_put(headers, normalized_name, value_copy);\n    if (!result) {\n        free(normalized_name);\n        free(value_copy);\n    }\n    return result;\n}\n\nchar* headers_get(HashTable* headers, const char* name) {\n    char* normalized_name = malloc(strlen(name) + 1);\n    for (int i = 0; name[i]; i++) {\n        normalized_name[i] = tolower(name[i]);\n    }\n    normalized_name[strlen(name)] = '\\0';\n    \n    char* value = (char*)hashtable_get(headers, normalized_name);\n    free(normalized_name);\n    return value;\n}\n```\n\n**Parser Core Logic Skeleton (for learner implementation):**\n\n```c\n// Initialize HTTP parser with clean state\n// Sets up parser context and allocates required buffers\nHttpParser* http_parser_create() {\n    // TODO 1: Allocate HttpParser structure\n    // TODO 2: Initialize parser state to HTTP_PARSING_REQUEST_LINE\n    // TODO 3: Create input buffer with initial capacity (8KB recommended)\n    // TODO 4: Set current_request to NULL (will be allocated per request)\n    // TODO 5: Initialize all numeric fields to 0\n    // TODO 6: Return NULL on any allocation failure\n    // Hint: Use buffer_create(8192) for input buffer\n}\n\n// Process incoming data through the parser state machine\n// Returns number of bytes consumed, 0 if need more data, -1 on error\nint http_parser_process(HttpParser* parser, char* data, size_t size) {\n    // TODO 1: Append incoming data to input buffer using buffer_append()\n    // TODO 2: Enter main parsing loop while data available\n    // TODO 3: Switch on parser->state to handle current parsing phase\n    // TODO 4: For each state, try to parse expected data format\n    // TODO 5: Advance parser state when delimiter found or length satisfied\n    // TODO 6: Return consumed byte count or error code\n    // Hint: Use find_delimiter() helper to locate \\r\\n sequences\n    // Hint: Handle case where delimiter spans multiple process() calls\n}\n\n// Parse HTTP request line: \"METHOD /path HTTP/version\\r\\n\"\n// Updates parser->current_request with method, URI, and version\nstatic bool parse_request_line(HttpParser* parser) {\n    // TODO 1: Find \\r\\n delimiter in input buffer from current position\n    // TODO 2: If delimiter not found, return false (need more data)\n    // TODO 3: Extract line content between position and delimiter\n    // TODO 4: Split line on spaces to get method, URI, version\n    // TODO 5: Validate method against allowed HTTP methods\n    // TODO 6: Validate URI format and length limits\n    // TODO 7: Validate HTTP version (1.0, 1.1, 2.0)\n    // TODO 8: Copy parsed values to current_request structure\n    // TODO 9: Advance buffer position past \\r\\n delimiter\n    // TODO 10: Return true on successful parsing\n    // Hint: Use strncmp() for method validation\n    // Hint: Reject URIs longer than 2048 characters\n}\n\n// Parse header lines until empty line encountered\n// Populates parser->current_request->headers hash table\nstatic bool parse_headers(HttpParser* parser) {\n    // TODO 1: Loop looking for header lines terminated by \\r\\n\n    // TODO 2: When find \\r\\n\\r\\n sequence, headers complete\n    // TODO 3: For each header line, split on first ':' character\n    // TODO 4: Trim whitespace from header name and value\n    // TODO 5: Validate header name contains only valid characters\n    // TODO 6: Add header to hash table using headers_add()\n    // TODO 7: Check for special headers: Content-Length, Transfer-Encoding, Connection\n    // TODO 8: Set parser flags based on special header values\n    // TODO 9: Advance buffer position past processed headers\n    // TODO 10: Return true when all headers parsed\n    // Hint: Use strchr() to find ':' separator in header line\n    // Hint: Watch for folded headers (lines starting with space/tab)\n}\n\n// Determine request body length from headers\n// Sets parser->content_length and parser->chunked flags\nstatic bool determine_body_length(HttpParser* parser) {\n    // TODO 1: Check for Transfer-Encoding: chunked header\n    // TODO 2: If chunked, set parser->chunked = true and return\n    // TODO 3: Check for Content-Length header\n    // TODO 4: If Content-Length present, parse numeric value\n    // TODO 5: Validate Content-Length is non-negative integer\n    // TODO 6: Set parser->content_length and parser->bytes_remaining\n    // TODO 7: If no body length indicators, assume no body\n    // TODO 8: Transition parser state to appropriate body parsing state\n    // Hint: Use strtoul() to parse Content-Length value\n    // Hint: Reject requests with both chunked and Content-Length\n}\n\n// Parse fixed-length request body based on Content-Length\n// Accumulates body data into parser->current_request->body buffer\nstatic bool parse_fixed_body(HttpParser* parser) {\n    // TODO 1: Calculate bytes available in input buffer\n    // TODO 2: Determine how many bytes to consume (min of available and remaining)\n    // TODO 3: Append consumed bytes to request body buffer\n    // TODO 4: Subtract consumed bytes from parser->bytes_remaining\n    // TODO 5: Advance input buffer position past consumed data\n    // TODO 6: If bytes_remaining reaches 0, parsing complete\n    // TODO 7: Return false if more body data needed\n    // Hint: Use buffer_append() to add body data to request\n}\n\n// Parse chunked request body with size prefixes\n// Handles chunk size parsing and data accumulation\nstatic bool parse_chunked_body(HttpParser* parser) {\n    // TODO 1: If in PARSING_CHUNKED_SIZE state, look for size line\n    // TODO 2: Parse hexadecimal chunk size from line\n    // TODO 3: Handle chunk extensions after semicolon (ignore them)\n    // TODO 4: If chunk size is 0, look for trailer headers\n    // TODO 5: If chunk size > 0, transition to PARSING_CHUNKED_DATA\n    // TODO 6: In data state, read exactly chunk_size bytes\n    // TODO 7: After chunk data, expect \\r\\n delimiter\n    // TODO 8: Repeat size/data cycle until zero-size chunk\n    // Hint: Use strtoul() with base 16 for hex chunk size parsing\n    // Hint: Each chunk ends with \\r\\n after the data\n}\n```\n\n**Language-Specific Implementation Hints:**\n\n- Use `memmem()` function for efficient delimiter searching in binary data rather than `strstr()` which stops at null bytes\n- Implement `find_crlf()` helper that can find `\\r\\n` sequences spanning buffer boundaries by checking the last character of previous searches\n- Use `realloc()` for buffer expansion but always check return value and handle failure by keeping original buffer\n- For header storage, consider using a trie data structure instead of hash table for better memory efficiency with common header prefixes\n- Use `tolower()` for case-insensitive header comparisons but be aware of locale-specific behavior\n- Implement connection timeout handling using `alarm()` or `select()` with timeout to prevent slow-read attacks\n- Use `TCP_NODELAY` socket option to reduce latency for small HTTP messages\n- Consider using `MSG_PEEK` flag with `recv()` to examine data without consuming it during delimiter searches\n\n**Milestone Checkpoint:**\n\nAfter implementing the HTTP parser core, verify functionality with these tests:\n\n1. **Basic Request Parsing**: Send \"GET /test HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\" and verify the parser extracts method=\"GET\", uri=\"/test\", version=\"HTTP/1.1\", and headers contain Host entry.\n\n2. **Chunked Encoding**: Send a chunked request with body \"5\\r\\nhello\\r\\n0\\r\\n\\r\\n\" and verify the parser correctly assembles \"hello\" in the body buffer.\n\n3. **Partial Read Handling**: Send request data in small chunks (1-2 bytes per write) and verify the parser accumulates data correctly across multiple `http_parser_process()` calls.\n\n4. **Large Header Handling**: Send request with 100+ headers and verify parser doesn't crash or leak memory.\n\n5. **Error Case Handling**: Send malformed requests (invalid methods, missing headers, bad chunk encoding) and verify parser returns appropriate error codes.\n\nExpected output when running `make test`:\n```\nRunning HTTP parser tests...\n✓ Basic request parsing\n✓ Chunked transfer encoding  \n✓ Partial data handling\n✓ Large header processing\n✓ Error case validation\n✓ Memory leak detection\nAll parser tests passed!\n```\n\nSigns of implementation issues:\n- **Segmentation faults**: Usually indicate buffer overruns or null pointer dereferences in parsing logic\n- **Memory leaks**: Check that all allocated buffers and hash table entries are properly freed\n- **Hanging on partial data**: Parser not handling incomplete reads correctly - verify state machine transitions\n- **Header corruption**: Case sensitivity issues or incorrect string termination in header processing\n\n\n## Connection Manager Component\n\n> **Milestone(s):** Milestone 1 (HTTP Proxy Core), Milestone 3 (Connection Pooling) - the connection manager handles client connections for basic request forwarding and implements connection pooling for efficient backend communication.\n\nThink of the Connection Manager as the **backstage coordinator at a busy restaurant**. When customers arrive, it seats them at tables (establishing client connections), takes their orders (receiving requests), coordinates with the kitchen (backend servers), and ensures the waitstaff (connection pools) efficiently deliver food without constantly running back and forth. Just as a restaurant maintains a staff of waiters who can serve multiple tables without hiring new staff for each customer, the Connection Manager maintains pools of reusable connections to backend servers, avoiding the expensive overhead of establishing new network connections for every request.\n\nThe Connection Manager represents one of the most complex components in our reverse proxy architecture because it must juggle multiple concerns simultaneously: accepting new client connections, maintaining the lifecycle of active connections, pooling backend connections for reuse, and gracefully handling failures at every stage. Unlike simpler HTTP servers that handle one connection at a time, a production reverse proxy must efficiently manage thousands of concurrent connections while maintaining low latency and high throughput.\n\n### Connection Lifecycle Management\n\nThe **connection lifecycle** in our reverse proxy follows a sophisticated state machine that tracks each connection from initial establishment through final cleanup. Understanding this lifecycle is crucial because connections represent expensive system resources (file descriptors, memory buffers, kernel state) that must be carefully managed to prevent resource exhaustion and ensure optimal performance.\n\n![Connection State Machine](./diagrams/connection-state-machine.svg)\n\nEach connection in our system progresses through well-defined states that determine what operations are valid and what data is expected. The connection lifecycle begins when a client establishes a TCP connection to our proxy's listening socket. At this moment, the connection enters the `IDLE` state, where it waits for the first HTTP request to arrive. The Connection Manager must track not only the current state but also timing information, buffer contents, and associated metadata for each connection.\n\nThe state transitions are triggered by specific events that occur during request processing. When data arrives on an idle connection, it transitions to `READING_REQUEST` state, where the HTTP Parser Component begins processing the incoming bytes. Once a complete request is parsed, the connection moves to `FORWARDING` state while the Load Balancer Component selects a backend server. After successful backend selection, the connection enters `READING_RESPONSE` state as it waits for the backend's reply. Finally, it transitions to `WRITING_RESPONSE` state while sending data back to the client.\n\n#### Connection State Tracking\n\nThe Connection Manager maintains detailed state information for every active connection through the `Connection` structure. This structure serves as the single source of truth for connection status, timing information, and associated resources.\n\n| Field Name | Type | Description |\n|------------|------|-------------|\n| connection_id | int | Unique identifier for this connection instance |\n| client_fd | int | File descriptor for client socket |\n| backend_fd | int | File descriptor for backend socket (if assigned) |\n| state | ConnectionState | Current state in the connection lifecycle |\n| client_addr | struct sockaddr_in | Client IP address and port information |\n| backend_server | BackendServer* | Pointer to selected backend server |\n| request_buffer | Buffer* | Buffer containing incoming request data |\n| response_buffer | Buffer* | Buffer containing outgoing response data |\n| created_time | time_t | Timestamp when connection was established |\n| last_activity | time_t | Timestamp of most recent I/O activity |\n| bytes_read | size_t | Total bytes read from client |\n| bytes_written | size_t | Total bytes written to client |\n| keep_alive | bool | Whether connection supports HTTP keep-alive |\n| pipeline_depth | int | Number of pipelined requests in queue |\n| timeout_ms | int | Connection timeout in milliseconds |\n\nThe `ConnectionState` enum defines all possible states a connection can occupy during its lifetime:\n\n| State | Description | Valid Next States |\n|-------|-------------|-------------------|\n| CONNECTION_IDLE | Waiting for incoming request | READING_REQUEST, CLOSING |\n| CONNECTION_READING_REQUEST | Parsing incoming HTTP request | FORWARDING, CLOSING |\n| CONNECTION_FORWARDING | Selecting backend and sending request | READING_RESPONSE, CLOSING |\n| CONNECTION_READING_RESPONSE | Waiting for backend response | WRITING_RESPONSE, CLOSING |\n| CONNECTION_WRITING_RESPONSE | Sending response to client | IDLE (keep-alive), CLOSING |\n| CONNECTION_CLOSING | Cleaning up and terminating | None (terminal state) |\n\n#### Connection Timeout Management\n\nTimeout management prevents connections from consuming resources indefinitely when clients disappear or become unresponsive. The Connection Manager implements multiple timeout mechanisms that operate at different stages of the connection lifecycle. **Read timeouts** protect against slow or malicious clients that send partial requests, **write timeouts** handle cases where clients stop reading response data, and **idle timeouts** clean up keep-alive connections that remain unused.\n\nThe timeout implementation uses a **timer wheel** data structure that efficiently tracks thousands of connections with minimal overhead. Rather than setting individual timers for each connection (which would be expensive in terms of system calls), the timer wheel groups connections by their expiration time and processes entire groups together. This approach scales well as connection counts increase and provides precise timeout handling with minimal CPU overhead.\n\nWhen a timeout occurs, the Connection Manager follows a specific cleanup procedure. First, it logs the timeout event with relevant connection details for debugging purposes. Next, it gracefully closes any associated backend connection to prevent resource leaks. Then it sends an appropriate HTTP error response to the client if possible (408 Request Timeout for read timeouts, 502 Bad Gateway for backend timeouts). Finally, it removes the connection from all tracking structures and releases its allocated memory.\n\n> **Design Insight**: The timer wheel timeout mechanism is crucial for handling the \"slow loris\" attack pattern, where malicious clients open many connections and send requests extremely slowly to exhaust server resources. Without proper timeouts, a single attacker could consume all available connection slots.\n\n### Connection Pooling Strategy\n\nConnection pooling represents the **heart of our performance optimization strategy**. Establishing a new TCP connection to a backend server requires a three-way handshake, DNS resolution (if needed), and potential SSL/TLS negotiation. This overhead can add 50-200ms of latency per request, making it the dominant performance bottleneck in many scenarios. Connection pooling eliminates this overhead by maintaining a pool of pre-established connections that can be immediately reused for new requests.\n\nThink of connection pooling like a **taxi dispatch system at a busy airport**. Instead of calling a new taxi for each passenger (expensive and slow), the airport maintains a queue of waiting taxis that can immediately pick up the next passenger. When a taxi drops off a passenger at their destination, it returns to the airport queue to serve the next customer. This system maximizes efficiency by reusing expensive resources (taxis/connections) and minimizing wait times (network handshake overhead).\n\n#### Pool Architecture and Management\n\nOur connection pooling system maintains a separate pool for each configured backend server, allowing fine-grained control over connection limits and load distribution. Each pool operates as an independent resource manager with its own allocation policies, health checking, and cleanup procedures.\n\nThe pool management algorithm balances several competing concerns. It must maintain enough idle connections to handle traffic spikes without establishing new connections (which would increase latency). However, it cannot maintain too many idle connections, as they consume memory and file descriptors unnecessarily. The pool must also detect and remove stale connections that have been closed by the backend server or network infrastructure.\n\n| Pool Configuration | Default Value | Description |\n|-------------------|---------------|-------------|\n| max_connections | 32 | Maximum connections per backend server |\n| min_idle_connections | 4 | Minimum idle connections to maintain |\n| max_idle_connections | 16 | Maximum idle connections before cleanup |\n| idle_timeout_seconds | 300 | Timeout for unused idle connections |\n| connect_timeout_ms | 5000 | Timeout for establishing new connections |\n| health_check_interval | 30 | Seconds between connection health checks |\n| retry_backoff_ms | 1000 | Delay before retrying failed connections |\n\nThe connection pool implements a **LIFO (Last-In, First-Out) strategy** for connection reuse. When a connection finishes serving a request, it goes to the front of the idle queue. When a new request needs a connection, it takes from the front of the queue. This strategy improves cache locality and connection warmth, as recently used connections are more likely to have warm CPU caches and network buffers.\n\n#### Connection Pool Operations\n\nThe pool provides several key operations that abstract the complexity of connection management from the rest of the proxy system. These operations handle all aspects of connection lifecycle, from initial allocation through final cleanup.\n\n| Operation | Parameters | Returns | Description |\n|-----------|------------|---------|-------------|\n| pool_acquire | backend_server, timeout_ms | Connection* | Get available connection from pool |\n| pool_release | connection, reusable | void | Return connection to pool or close |\n| pool_create_connection | backend_server | Connection* | Establish new connection to backend |\n| pool_validate_connection | connection | bool | Check if connection is still healthy |\n| pool_cleanup_idle | pool, max_age_seconds | int | Remove old idle connections |\n| pool_get_stats | pool | PoolStats* | Retrieve pool utilization metrics |\n| pool_set_limits | pool, max_conn, max_idle | bool | Update pool configuration limits |\n\nThe `pool_acquire` operation implements the core connection allocation logic. When a request needs a backend connection, this function first attempts to reuse an idle connection from the pool. If no idle connections are available and the pool hasn't reached its maximum size, it establishes a new connection. If the pool is at capacity, the operation can either block until a connection becomes available or return an error, depending on the configured behavior.\n\nConnection validation is critical for pool reliability. The `pool_validate_connection` function checks whether a pooled connection is still usable before assigning it to a new request. This validation includes checking if the socket is still open, verifying there's no pending data that would indicate a protocol error, and optionally sending a lightweight health check request to the backend server.\n\nThe `pool_release` operation handles returning connections to the pool after request completion. If the connection is still healthy and the request completed successfully, it's marked as available for reuse. However, if an error occurred during request processing, or if the connection shows signs of corruption, it's immediately closed and removed from the pool.\n\n> **Critical Insight**: Connection validation must be extremely lightweight since it occurs on every connection reuse. Expensive validation (like sending HTTP requests) would negate the performance benefits of pooling. Instead, we rely on socket-level checks and occasional background health monitoring.\n\n#### Pool Health Management\n\nConnection pools require continuous health monitoring because network conditions and backend server states change dynamically. A connection that was healthy when returned to the pool might become stale due to firewall timeouts, server restarts, or network partitions. The health management system proactively identifies and removes unhealthy connections before they can cause request failures.\n\nThe health checking strategy operates on multiple levels. **Passive health checking** monitors connection behavior during normal request processing. If a connection fails during use, it's immediately removed from the pool and the failure is recorded. **Active health checking** periodically validates idle connections by sending lightweight probe requests or checking socket status. This proactive approach catches problems before they affect user requests.\n\nBackground health checking runs on a separate thread to avoid blocking request processing. The health checker iterates through idle connections in each pool, validating them according to configured criteria. Connections that fail validation are removed from the pool and properly closed. The health checker also implements **backoff strategies** for pools with repeated failures, temporarily reducing health check frequency to avoid overwhelming struggling backend servers.\n\n#### Pool Sizing and Auto-scaling\n\nDetermining optimal pool sizes requires balancing resource utilization with performance requirements. Small pools may not provide sufficient connection reuse, leading to frequent connection establishment overhead. Large pools waste memory and file descriptors while providing minimal additional benefit. Our pool sizing algorithm adapts dynamically based on observed traffic patterns and backend performance characteristics.\n\nThe auto-scaling mechanism monitors several key metrics to guide sizing decisions. **Connection utilization rates** indicate whether the current pool size adequately serves the request load. **Connection establishment latency** shows whether new connections are expensive enough to justify maintaining larger pools. **Backend response times** help identify when backend servers are becoming overloaded and may benefit from reduced connection counts.\n\nPool scaling operates conservatively to avoid oscillation. When scaling up, the system gradually increases pool sizes while monitoring the impact on overall performance. When scaling down, it waits for extended periods of low utilization before reducing pool sizes. This hysteresis prevents the system from constantly adjusting pool sizes in response to normal traffic fluctuations.\n\n### Connection Management Decisions\n\nThe connection management system involves numerous architectural decisions that significantly impact performance, scalability, and reliability. These decisions represent trade-offs between competing concerns, and understanding the rationale behind each choice is essential for maintaining and extending the system.\n\n#### Connection State Management Decision\n\n> **Decision: Centralized Connection State Tracking**\n> - **Context**: The system needs to track connection state, timeouts, and metadata for thousands of concurrent connections while supporting efficient lookup and update operations.\n> - **Options Considered**:\n>   1. Distributed state stored in connection structures\n>   2. Centralized state manager with hash table lookup\n>   3. Hybrid approach with local caching\n> - **Decision**: Centralized state manager with hash table-based connection tracking\n> - **Rationale**: Centralized management enables efficient timeout processing, resource cleanup, and system-wide connection limits. Hash table lookup provides O(1) access time regardless of connection count. Centralized design simplifies debugging and monitoring.\n> - **Consequences**: Enables efficient batch processing of timeouts and cleanup operations. Requires careful synchronization for multi-threaded access. Single point of truth for connection state improves debugging capabilities.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Distributed State | Simple per-connection logic, no synchronization overhead | Difficult timeout management, hard to enforce global limits |\n| Centralized Manager | Efficient batch operations, unified resource management | Potential synchronization bottleneck, more complex implementation |\n| Hybrid Caching | Balance of performance and manageability | Complex cache coherency, increased memory overhead |\n\nThe centralized approach proves superior for production reverse proxy implementations because timeout processing and resource cleanup operations become much more efficient when connection state is co-located. The ability to iterate through all connections for batch timeout processing provides significant performance benefits compared to per-connection timer management.\n\n#### Connection Pooling Algorithm Decision\n\n> **Decision: Per-Backend LIFO Connection Pools**\n> - **Context**: Backend connections must be efficiently reused to minimize connection establishment overhead while maintaining good cache locality and resource utilization.\n> - **Options Considered**:\n>   1. Global connection pool shared across all backends\n>   2. Per-backend FIFO pools for fairness\n>   3. Per-backend LIFO pools for cache locality\n> - **Decision**: Separate LIFO pools for each backend server with configurable limits\n> - **Rationale**: Per-backend pools prevent connection starvation and allow fine-grained configuration. LIFO ordering improves CPU and network cache locality by reusing recently active connections. Separate pools enable backend-specific tuning.\n> - **Consequences**: Improved cache locality and connection warmth. Requires more memory for pool management structures. Enables sophisticated per-backend configuration and monitoring.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Global Pool | Simple implementation, automatic load balancing | Connection starvation, no backend-specific tuning |\n| Per-Backend FIFO | Fair connection aging, predictable behavior | Poor cache locality, potentially stale connections |\n| Per-Backend LIFO | Optimal cache locality, warm connection reuse | May not age connections evenly, complex pool management |\n\nThe LIFO strategy proves most effective in practice because recently used connections maintain warm CPU caches, established TCP windows, and active network paths. This warmth translates to measurably better performance for subsequent requests compared to connections that have been idle in the pool for extended periods.\n\n#### Timeout Management Decision\n\n> **Decision: Timer Wheel with Hierarchical Timeouts**\n> - **Context**: The system must efficiently handle timeouts for thousands of concurrent connections without excessive CPU overhead or system call frequency.\n> - **Options Considered**:\n>   1. Per-connection timer threads\n>   2. Single timeout thread with sorted timeout list\n>   3. Timer wheel with batched timeout processing\n> - **Decision**: Timer wheel implementation with hierarchical timeout granularity\n> - **Rationale**: Timer wheels provide O(1) timeout insertion and deletion with efficient batch processing. Hierarchical granularity allows precise short-term timeouts and efficient long-term timeouts. Single timeout thread minimizes synchronization overhead.\n> - **Consequences**: Excellent scalability with connection count. Requires more complex timeout data structures. Enables precise timeout handling with minimal CPU overhead.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| Per-Connection Timers | Simple per-connection logic, precise timing | Excessive system calls, poor scalability |\n| Sorted Timeout List | Simple implementation, good precision | O(log n) insertion cost, potential lock contention |\n| Timer Wheel | O(1) operations, excellent scalability | Complex implementation, less precise for very short timeouts |\n\nThe timer wheel approach scales linearly with connection count and provides batch processing opportunities that significantly reduce CPU overhead. The hierarchical design allows the system to handle both short-term request timeouts (measured in seconds) and long-term keep-alive timeouts (measured in minutes) efficiently within the same data structure.\n\n#### Connection Validation Decision\n\n> **Decision: Lightweight Socket Validation with Background Health Checking**\n> - **Context**: Pooled connections must be validated before reuse to prevent request failures, but validation overhead must not negate the performance benefits of connection pooling.\n> - **Options Considered**:\n>   1. No validation (rely on error handling during use)\n>   2. Full HTTP health check before each reuse\n>   3. Lightweight socket validation with periodic background checks\n> - **Decision**: Socket-level validation on reuse combined with background HTTP health checking\n> - **Rationale**: Socket validation is extremely fast (single system call) and catches most connection failures. Background health checking proactively identifies problems without adding request latency. Combination provides reliability without performance penalty.\n> - **Consequences**: Minimal validation overhead during request processing. Requires background health checking infrastructure. Provides good balance of reliability and performance.\n\n| Option | Pros | Cons |\n|--------|------|------|\n| No Validation | Zero validation overhead, maximum performance | High failure rate on reuse, poor user experience |\n| Full HTTP Validation | Comprehensive connection testing, high reliability | Significant overhead negates pooling benefits |\n| Lightweight + Background | Fast validation, proactive problem detection | Complex implementation, requires background threads |\n\nThe lightweight validation approach acknowledges that perfect connection validation would be too expensive to perform on every reuse. Instead, it catches the most common failure modes (closed sockets, network errors) quickly and relies on background processes to handle more subtle problems.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Connection Resource Leaks**\nMany implementations fail to properly clean up connections during error conditions, leading to file descriptor exhaustion and memory leaks. This typically occurs when error handling paths don't properly close both client and backend file descriptors, or when connection tracking structures aren't properly removed from hash tables during cleanup. The fix involves implementing comprehensive resource cleanup in a single function that handles all cleanup aspects, and ensuring this function is called from every error path. Use a cleanup checklist: close client socket, close backend socket, free buffers, remove from connection manager, log cleanup completion.\n\n⚠️ **Pitfall: Race Conditions in Pool Management**\nMulti-threaded access to connection pools often introduces race conditions where the same connection is returned to multiple requests, or connections are returned to pools multiple times. This occurs because pool acquire/release operations aren't properly synchronized, or because connection state checks and modifications aren't atomic. The solution requires protecting all pool operations with appropriate locking mechanisms and ensuring connection state transitions are atomic. Use connection-level state flags to prevent double-release scenarios.\n\n⚠️ **Pitfall: Ignoring Connection Validation Failures**\nSome implementations acquire connections from pools but don't properly handle validation failures, leading to requests being sent over broken connections. This happens when developers assume pooled connections are always valid, or when validation functions return false but the calling code doesn't check the return value. The fix requires checking validation results and implementing fallback logic that either retries with a new connection or returns an appropriate error to the client.\n\n⚠️ **Pitfall: Improper Timeout Configuration**\nSetting timeouts too aggressively causes premature connection termination under normal load, while setting them too generously allows resource exhaustion during attack scenarios. This typically occurs when timeout values are chosen arbitrarily without considering actual network conditions and backend response characteristics. The solution involves implementing adaptive timeout strategies that adjust based on observed latency patterns, and providing different timeout values for different types of operations (connect, read, write, idle).\n\n⚠️ **Pitfall: Pool Size Misconfiguration**\nMany implementations set static pool sizes that work well under normal conditions but fail during traffic spikes or backend failures. This happens when pool sizes are based on average traffic rather than peak traffic, or when all backend pools use the same configuration regardless of backend capacity differences. The fix requires implementing dynamic pool sizing based on traffic patterns and backend health, with different pool configurations for different backend servers based on their capacity and performance characteristics.\n\n### Implementation Guidance\n\nThe Connection Manager represents one of the most performance-critical components in the reverse proxy architecture. Efficient implementation requires careful attention to memory management, system call optimization, and concurrent data structure access patterns.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Event Loop | select() system call with blocking I/O | epoll/kqueue with event-driven architecture |\n| Connection Storage | Linear array with O(n) lookup | Hash table with O(1) connection lookup |\n| Timeout Management | Per-connection timer threads | Timer wheel with batch processing |\n| Thread Safety | Global mutex protecting all operations | Fine-grained locking with per-pool mutexes |\n| Memory Management | malloc/free for each connection | Memory pools with pre-allocated connection objects |\n| Backend Health Checking | Simple socket validation | Active HTTP probes with exponential backoff |\n\n#### Recommended File Structure\n\n```\ninternal/\n  connection/\n    manager.c              ← Main connection manager implementation\n    manager.h              ← Connection manager public interface\n    pool.c                 ← Connection pool implementation\n    pool.h                 ← Connection pool interface\n    timeout.c              ← Timer wheel timeout implementation\n    timeout.h              ← Timeout management interface\n    connection_test.c      ← Unit tests for connection management\n    pool_test.c            ← Unit tests for connection pooling\n  utils/\n    hashtable.c            ← Hash table implementation for connection lookup\n    timer_wheel.c          ← Timer wheel data structure\n    memory_pool.c          ← Memory pool for connection objects\n```\n\n#### Connection Manager Infrastructure\n\nThe core Connection Manager infrastructure provides the foundation for connection lifecycle management and pool coordination. This infrastructure handles the complex details of event-driven I/O and resource management, allowing the main proxy logic to focus on request processing.\n\n```c\n#include <sys/epoll.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <fcntl.h>\n#include <unistd.h>\n#include <errno.h>\n#include <time.h>\n#include <pthread.h>\n\n// Timer wheel implementation for efficient timeout management\ntypedef struct TimerWheel {\n    struct TimerSlot** slots;\n    size_t slot_count;\n    size_t current_slot;\n    time_t slot_duration;\n    pthread_mutex_t wheel_mutex;\n} TimerWheel;\n\ntypedef struct TimerSlot {\n    Connection** connections;\n    size_t connection_count;\n    size_t capacity;\n} TimerSlot;\n\n// Initialize timer wheel with specified granularity\nTimerWheel* timer_wheel_create(size_t slots, time_t slot_duration) {\n    TimerWheel* wheel = malloc(sizeof(TimerWheel));\n    if (!wheel) return NULL;\n    \n    wheel->slots = calloc(slots, sizeof(TimerSlot*));\n    wheel->slot_count = slots;\n    wheel->current_slot = 0;\n    wheel->slot_duration = slot_duration;\n    pthread_mutex_init(&wheel->wheel_mutex, NULL);\n    \n    for (size_t i = 0; i < slots; i++) {\n        wheel->slots[i] = malloc(sizeof(TimerSlot));\n        wheel->slots[i]->connections = NULL;\n        wheel->slots[i]->connection_count = 0;\n        wheel->slots[i]->capacity = 0;\n    }\n    \n    return wheel;\n}\n\n// Connection pool implementation with per-backend management\ntypedef struct ConnectionPool {\n    BackendServer* backend;\n    Connection** idle_connections;\n    size_t idle_count;\n    size_t max_connections;\n    size_t active_count;\n    pthread_mutex_t pool_mutex;\n    pthread_cond_t pool_condition;\n    time_t last_health_check;\n} ConnectionPool;\n\n// Initialize connection pool for specific backend server\nConnectionPool* connection_pool_create(BackendServer* backend, size_t max_connections) {\n    ConnectionPool* pool = malloc(sizeof(ConnectionPool));\n    if (!pool) return NULL;\n    \n    pool->backend = backend;\n    pool->idle_connections = calloc(max_connections, sizeof(Connection*));\n    pool->idle_count = 0;\n    pool->max_connections = max_connections;\n    pool->active_count = 0;\n    pool->last_health_check = time(NULL);\n    \n    pthread_mutex_init(&pool->pool_mutex, NULL);\n    pthread_cond_init(&pool->pool_condition, NULL);\n    \n    return pool;\n}\n\n// Connection manager main structure\ntypedef struct ConnectionManager {\n    int epoll_fd;\n    HashTable* connections;\n    ConnectionPool** backend_pools;\n    size_t pool_count;\n    TimerWheel* timeout_wheel;\n    pthread_t timeout_thread;\n    pthread_mutex_t manager_mutex;\n    volatile bool running;\n} ConnectionManager;\n\n// Initialize connection manager with event-driven I/O\nConnectionManager* connection_manager_create(ProxyConfig* config) {\n    ConnectionManager* manager = malloc(sizeof(ConnectionManager));\n    if (!manager) return NULL;\n    \n    // Create epoll instance for event-driven I/O\n    manager->epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n    if (manager->epoll_fd == -1) {\n        free(manager);\n        return NULL;\n    }\n    \n    // Initialize connection tracking hash table\n    manager->connections = hashtable_create(config->max_connections * 2);\n    \n    // Create connection pools for each backend server\n    manager->pool_count = config->backend_count;\n    manager->backend_pools = calloc(config->backend_count, sizeof(ConnectionPool*));\n    \n    for (size_t i = 0; i < config->backend_count; i++) {\n        manager->backend_pools[i] = connection_pool_create(\n            &config->backends[i], \n            config->pool_max_connections\n        );\n    }\n    \n    // Initialize timeout management\n    manager->timeout_wheel = timer_wheel_create(3600, 1); // 1-hour wheel with 1-second slots\n    manager->running = true;\n    \n    pthread_mutex_init(&manager->manager_mutex, NULL);\n    \n    // Start background timeout processing thread\n    pthread_create(&manager->timeout_thread, NULL, timeout_processor, manager);\n    \n    return manager;\n}\n```\n\n#### Core Connection Management Logic\n\nThe core connection management functions implement the sophisticated state machine and resource tracking required for high-performance connection handling.\n\n```c\n// Accept new client connection and initialize state\nConnection* connection_manager_accept_client(ConnectionManager* manager, int listen_fd) {\n    // TODO 1: Accept incoming connection using accept4() with SOCK_NONBLOCK flag\n    // TODO 2: Set TCP_NODELAY socket option to disable Nagle algorithm\n    // TODO 3: Create new Connection structure and initialize all fields\n    // TODO 4: Generate unique connection_id and set initial state to CONNECTION_IDLE\n    // TODO 5: Add connection to epoll interest list for EPOLLIN events\n    // TODO 6: Insert connection into manager's connection hash table\n    // TODO 7: Schedule initial timeout using timer wheel\n    // TODO 8: Log connection acceptance with client address information\n    // Hint: Use setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &flag, sizeof(flag))\n    // Hint: Connection ID can be generated using atomic increment counter\n}\n\n// Acquire backend connection from pool or create new one\nConnection* connection_manager_acquire_backend(ConnectionManager* manager, \n                                             BackendServer* backend,\n                                             int timeout_ms) {\n    // TODO 1: Find connection pool for specified backend server\n    // TODO 2: Lock pool mutex to ensure thread-safe access\n    // TODO 3: Check if idle connection is available in pool\n    // TODO 4: If idle connection available, validate it's still healthy\n    // TODO 5: If no idle connection and under max limit, create new connection\n    // TODO 6: If at max limit, wait on condition variable or return NULL\n    // TODO 7: Mark selected connection as active and remove from idle list\n    // TODO 8: Update pool statistics and unlock mutex\n    // Hint: Use pthread_mutex_lock() and pthread_cond_timedwait() for waiting\n    // Hint: Connection validation can use MSG_PEEK to check socket status\n}\n\n// Return backend connection to pool for reuse\nvoid connection_manager_release_backend(ConnectionManager* manager, \n                                      Connection* connection, \n                                      bool reusable) {\n    // TODO 1: Find connection pool based on connection's backend server\n    // TODO 2: Lock pool mutex for thread-safe modification\n    // TODO 3: If connection is reusable and pool not full, add to idle list\n    // TODO 4: If not reusable or pool full, close connection immediately\n    // TODO 5: Update pool statistics (decrement active count)\n    // TODO 6: Signal waiting threads using condition variable\n    // TODO 7: Schedule connection for timeout tracking if pooled\n    // TODO 8: Unlock pool mutex and log pool operation\n    // Hint: Use LIFO ordering when adding to idle list for cache locality\n    // Hint: Check connection->keep_alive flag to determine reusability\n}\n\n// Process connection state transitions\nvoid connection_manager_handle_event(ConnectionManager* manager, \n                                   Connection* connection, \n                                   uint32_t events) {\n    // TODO 1: Check event type (EPOLLIN, EPOLLOUT, EPOLLERR, EPOLLHUP)\n    // TODO 2: Based on current connection state, determine appropriate action\n    // TODO 3: For EPOLLIN in IDLE state, transition to READING_REQUEST\n    // TODO 4: For EPOLLIN in READING_RESPONSE, continue response processing\n    // TODO 5: For EPOLLOUT in WRITING_RESPONSE, continue response transmission\n    // TODO 6: For error events, transition to CLOSING state\n    // TODO 7: Update connection's last_activity timestamp\n    // TODO 8: If state transition complete, update epoll interest list\n    // Hint: Use switch statement based on connection->state\n    // Hint: Error events (EPOLLERR, EPOLLHUP) always require connection cleanup\n}\n\n// Clean up connection and release all resources\nvoid connection_manager_close_connection(ConnectionManager* manager, Connection* connection) {\n    // TODO 1: Remove connection from epoll interest list\n    // TODO 2: Remove connection from timeout tracking (timer wheel)\n    // TODO 3: Close client file descriptor if open\n    // TODO 4: Close backend file descriptor if open (return to pool if applicable)\n    // TODO 5: Free request and response buffers\n    // TODO 6: Remove connection from manager's hash table\n    // TODO 7: Free connection structure memory\n    // TODO 8: Log connection closure with lifetime statistics\n    // Hint: Always check if file descriptors are valid (>= 0) before closing\n    // Hint: Use hashtable_remove() to clean up connection tracking\n}\n```\n\n#### Connection Pool Management Implementation\n\n```c\n// Background health checking for pooled connections\nvoid* pool_health_checker(void* arg) {\n    ConnectionManager* manager = (ConnectionManager*)arg;\n    \n    while (manager->running) {\n        // TODO 1: Sleep for configured health check interval\n        // TODO 2: Iterate through all backend connection pools\n        // TODO 3: For each pool, lock mutex and check idle connections\n        // TODO 4: Validate each idle connection using lightweight socket check\n        // TODO 5: Remove any unhealthy connections from pool\n        // TODO 6: Log health check results and pool statistics\n        // TODO 7: Unlock pool mutex before moving to next pool\n        // TODO 8: Implement exponential backoff for pools with repeated failures\n        // Hint: Use recv(fd, buffer, 0, MSG_PEEK) for non-destructive socket validation\n        // Hint: Track consecutive health check failures per pool\n    }\n    \n    return NULL;\n}\n\n// Timeout processing using timer wheel\nvoid* timeout_processor(void* arg) {\n    ConnectionManager* manager = (ConnectionManager*)arg;\n    TimerWheel* wheel = manager->timeout_wheel;\n    \n    while (manager->running) {\n        // TODO 1: Sleep for timer wheel slot duration (typically 1 second)\n        // TODO 2: Lock timer wheel mutex for thread-safe access\n        // TODO 3: Get current time and calculate which slot to process\n        // TODO 4: Process all connections in the current timeout slot\n        // TODO 5: Check each connection's last_activity against timeout limit\n        // TODO 6: Close connections that have exceeded their timeout\n        // TODO 7: Move wheel to next slot and unlock mutex\n        // TODO 8: Log timeout processing statistics periodically\n        // Hint: Use time(NULL) - connection->last_activity for age calculation\n        // Hint: Different connection states may have different timeout values\n    }\n    \n    return NULL;\n}\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Checkpoint: Basic Connection Handling**\nAfter implementing basic connection acceptance and client communication:\n- Start the proxy server: `./proxy -c proxy.conf`\n- Use netcat to connect: `nc localhost 8080`\n- Send HTTP request: `GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n`\n- Expected behavior: Connection accepted, request forwarded to backend, response returned\n- Verify: Check logs for connection lifecycle events (accept, forward, close)\n- Debug signs: If connections hang, check epoll event handling; if responses are incomplete, verify buffer management\n\n**Milestone 3 Checkpoint: Connection Pooling**\nAfter implementing connection pool management:\n- Configure multiple backend servers in proxy configuration\n- Send burst of requests: `for i in {1..100}; do curl -s http://localhost:8080/ & done`\n- Expected behavior: Connections reused across requests, pool statistics showing reuse\n- Verify: Monitor pool metrics showing idle/active connection counts\n- Debug signs: If performance doesn't improve, check pool acquisition logic; if connections leak, verify release operations\n\n#### Debugging Connection Management Issues\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Connection count grows indefinitely | Resource leak in cleanup path | Monitor `/proc/PID/fd/` count and compare with active connections | Add cleanup validation in error paths, use resource tracking |\n| High latency despite pooling | Pool validation too expensive | Profile connection acquisition time | Implement lightweight socket validation, reduce health check frequency |\n| Intermittent connection failures | Stale connections in pool | Check backend server connection logs | Improve connection validation, reduce pool idle timeout |\n| Memory usage grows over time | Connection structures not freed | Use memory profiler to track allocations | Ensure connection_destroy() called in all cleanup paths |\n| Deadlock under high load | Lock ordering issues in pools | Use thread debugger to identify lock contention | Implement consistent lock ordering, reduce lock scope |\n| Backend overload | Too many concurrent connections | Monitor backend connection counts | Implement connection limiting per backend, add backpressure |\n\nThis comprehensive Connection Manager implementation provides the foundation for efficient request processing while maintaining the sophisticated resource management required for production reverse proxy deployments.\n\n\n## Load Balancer Component\n\n> **Milestone(s):** Milestone 2 (Load Balancing) - implements request distribution across backend servers with health checking and dynamic backend management.\n\nThink of a load balancer as the dispatcher at a busy restaurant during peak hours. When customers arrive, the dispatcher doesn't just randomly assign them to tables - they consider which servers have the lightest workload, which tables are currently available, and which servers might be on break due to illness. The dispatcher keeps track of each server's current capacity and health status, ensuring that no single server gets overwhelmed while others sit idle. Similarly, our load balancer component acts as this intelligent dispatcher, examining each incoming request and making smart decisions about which backend server should handle it based on current load, server health, and configured distribution policies.\n\nThe **load balancer component** sits at the heart of our reverse proxy's request distribution logic, responsible for selecting the most appropriate backend server for each incoming client request. This component must balance multiple competing objectives: distributing load evenly across available servers, respecting server capacity differences, avoiding unhealthy servers, and maintaining session affinity where required. Unlike a simple random selection, the load balancer maintains sophisticated state about each backend server, continuously monitoring their health and performance characteristics to make informed routing decisions.\n\nThe challenge lies in implementing this intelligence efficiently - the load balancer operates in the critical path of every request, so any slowdown here directly impacts client response times. The component must make routing decisions in microseconds while maintaining accurate load statistics, performing health checks, and handling dynamic backend changes without dropping requests. This requires careful algorithm selection, efficient data structures, and robust error handling to ensure that backend failures don't cascade into client-visible outages.\n\n![Load Balancing Decision Flow](./diagrams/load-balancing-flowchart.svg)\n\n### Load Balancing Algorithms\n\nThe foundation of effective load balancing lies in choosing the right algorithm for your specific traffic patterns and backend characteristics. Each algorithm makes different assumptions about server capabilities, request costs, and client behavior, leading to vastly different performance outcomes under varying conditions.\n\n**Round-robin algorithm** represents the simplest approach to load distribution, cycling through available backend servers in a fixed order regardless of their current load or capacity. Think of it like dealing cards from a deck - each backend gets the next request in sequence, wrapping back to the first server after reaching the last one. While this approach ensures perfectly even distribution over time, it assumes all servers have identical capacity and all requests require similar processing resources.\n\nThe round-robin implementation maintains a simple counter that tracks the index of the last selected server within the available backend list. For each new request, the algorithm increments this counter modulo the number of healthy backends, ensuring automatic wraparound when reaching the end of the list. This stateless approach makes round-robin extremely fast and memory-efficient, requiring only a single integer of state per upstream group.\n\nHowever, round-robin's simplicity becomes a liability when servers have different capabilities or when request processing times vary significantly. A powerful server with twice the CPU cores of its peers will receive the same number of requests as the weaker machines, leading to suboptimal resource utilization. Similarly, if some requests trigger expensive database queries while others serve cached content, the server unlucky enough to receive multiple expensive requests in sequence may become overloaded while others remain idle.\n\n**Least-connections algorithm** addresses round-robin's load blindness by tracking the number of active connections to each backend server and preferentially routing new requests to the server with the fewest current connections. This approach assumes that connection count serves as a reasonable proxy for server load - servers handling more concurrent requests are likely under higher load than those with fewer active connections.\n\nThe algorithm maintains a connection counter for each backend server, incrementing the counter when establishing a new connection and decrementing it when connections close or requests complete. For each incoming request, the load balancer scans all healthy backends to find the server with the minimum connection count. In case of ties, the algorithm can break them using secondary criteria such as server ID for deterministic behavior or random selection for additional load spreading.\n\nLeast-connections works particularly well for applications with long-lived connections or requests with highly variable processing times. Web applications that mix quick static file requests with expensive API calls benefit significantly from this approach, as servers can naturally shed load by completing requests quickly rather than being forced to accept new work regardless of their current burden.\n\nThe algorithm does introduce additional complexity and state management overhead compared to round-robin. Each connection establishment and termination requires updating the connection counters in a thread-safe manner, and the backend selection process requires examining all available servers rather than simple arithmetic. However, this overhead is typically insignificant compared to the performance benefits of better load distribution.\n\n**Weighted round-robin algorithm** extends basic round-robin by allowing administrators to assign different weights to backend servers based on their relative capacity or performance characteristics. A server with weight 3 will receive three times as many requests as a server with weight 1, allowing the load balancer to account for hardware differences, geographic proximity, or other capacity factors.\n\nThe implementation uses a more sophisticated counter system that tracks both the current server index and the number of requests sent to that server within its weight allocation. When a server receives its full allocation of requests (equal to its weight), the algorithm advances to the next server and resets the request counter. This ensures that over any complete cycle, each server receives requests proportional to its configured weight.\n\nConsider a backend pool with three servers having weights 3, 2, and 1 respectively. The distribution pattern over six requests would be: Server A (weight 3) receives requests 1, 2, 3; Server B (weight 2) receives requests 4, 5; Server C (weight 1) receives request 6. This pattern repeats for subsequent request batches, maintaining the 3:2:1 ratio over time while preserving the round-robin property of cycling through all servers.\n\nWeighted round-robin proves invaluable in heterogeneous environments where backend servers have significantly different capabilities. Cloud deployments often mix instance types with different CPU, memory, and network characteristics, making it critical to account for these differences in load distribution. The algorithm also supports gradual traffic shifting scenarios, such as blue-green deployments where new server versions initially receive low weights that gradually increase as confidence grows.\n\nThe following table compares the characteristics of each load balancing algorithm:\n\n| Algorithm | Complexity | Memory Usage | Load Awareness | Hardware Heterogeneity | Session Affinity |\n|-----------|------------|--------------|----------------|----------------------|------------------|\n| Round-Robin | O(1) | Minimal | None | Poor | Difficult |\n| Least-Connections | O(n) | Moderate | Good | Good | Natural |\n| Weighted Round-Robin | O(1) | Minimal | None | Excellent | Moderate |\n\n> **Decision: Primary Load Balancing Algorithm Selection**\n> - **Context**: The reverse proxy must efficiently distribute requests across backend servers while supporting different server capacities and providing good performance under various traffic patterns.\n> - **Options Considered**: \n>   1. Round-robin only (simplest implementation)\n>   2. Least-connections only (best load awareness)\n>   3. Multiple algorithms with runtime selection (maximum flexibility)\n> - **Decision**: Implement all three algorithms with runtime configuration selection\n> - **Rationale**: Different applications have vastly different characteristics - some benefit from round-robin's simplicity and predictability, others need least-connections' load awareness, and heterogeneous environments require weighted distribution. Supporting multiple algorithms allows the reverse proxy to adapt to diverse deployment scenarios.\n> - **Consequences**: Increases implementation complexity and testing surface area, but provides maximum deployment flexibility and better performance across diverse workloads.\n\n### Health Checking System\n\nHealth checking forms the critical foundation that prevents the load balancer from routing requests to failed or degraded backend servers. Without robust health checking, even the most sophisticated load balancing algorithm becomes counterproductive, as it may consistently route requests to servers that cannot fulfill them, leading to cascading failures and poor user experience.\n\nThink of health checking as the reverse proxy's immune system - it continuously monitors the health of each backend server, detecting problems before they impact client requests, and automatically removing unhealthy servers from the active pool while attempting to rehabilitate them. This system must balance responsiveness (detecting failures quickly) with stability (avoiding false positives that unnecessarily remove healthy servers).\n\n**Active health checking** proactively monitors backend server health by periodically sending synthetic health check requests and evaluating the responses. This approach provides the most reliable health assessment because it exercises the same code paths that real client requests would use, detecting application-level failures that might not be visible through simple network connectivity tests.\n\nThe health checker maintains a separate connection pool for health check requests, isolated from the main request processing to ensure that health checks continue even when the backend server is under heavy load or experiencing connection pool exhaustion. Each backend server receives health check requests at configurable intervals, typically ranging from 5 to 30 seconds depending on the desired failure detection speed and the overhead tolerance.\n\nHealth check requests should target a lightweight endpoint specifically designed for health monitoring rather than expensive application routes. Many applications provide dedicated health check endpoints (such as `/health` or `/ping`) that perform essential system checks without the overhead of full request processing. These endpoints typically verify database connectivity, cache availability, and other critical dependencies while returning simple success indicators.\n\nThe health checker evaluates multiple criteria when determining server health status. HTTP response status codes provide the primary indicator - responses in the 200-299 range typically indicate healthy servers, while 5xx errors suggest server problems. However, the system also monitors response times, as servers that respond correctly but very slowly may indicate resource exhaustion or performance degradation that warrants load reduction.\n\n**Failure threshold logic** prevents transient network issues or temporary server hiccups from unnecessarily removing healthy servers from the active pool. Rather than marking servers unhealthy after a single failed health check, the system implements configurable failure thresholds that require multiple consecutive failures before changing server status.\n\nA typical failure threshold configuration might require three consecutive health check failures before marking a server unhealthy, and five consecutive successes before returning it to service. This asymmetric threshold design reflects the principle that removing servers from service should be conservative (to avoid unnecessary capacity reduction) while returning servers to service should be even more conservative (to avoid repeatedly adding and removing flapping servers).\n\nThe health checking system maintains detailed state for each backend server, tracking not only the current health status but also the history of recent health check results, failure counts, and timing information. This rich state enables sophisticated health assessment logic that can detect patterns such as intermittent failures, gradual performance degradation, or partial service degradation.\n\n| Health Check Parameter | Typical Range | Purpose | Impact of Too Low | Impact of Too High |\n|------------------------|---------------|---------|-------------------|-------------------|\n| Check Interval | 5-30 seconds | Detection speed vs overhead | Higher server load | Slower failure detection |\n| Timeout | 1-10 seconds | Unresponsive server detection | False positives | Slow detection of hanging servers |\n| Failure Threshold | 2-5 failures | Stability vs responsiveness | Flapping servers | Slow unhealthy server removal |\n| Success Threshold | 3-7 successes | Recovery confidence | Premature server return | Slow healthy server recovery |\n\n**Graceful degradation** ensures that health check failures don't immediately impact in-flight requests to the affected backend server. When a server transitions from healthy to unhealthy status, the load balancer stops routing new requests to that server but allows existing connections and requests to complete naturally. This approach prevents abrupt connection termination that could cause client errors while still protecting against sending additional load to problematic servers.\n\nThe system implements a grace period during which unhealthy servers remain in a \"draining\" state, continuing to handle existing connections while being excluded from new request routing. The duration of this grace period balances client experience (allowing time for requests to complete) with failure isolation (limiting exposure to a potentially failing server).\n\nFor servers that fail health checks but maintain existing connections, the connection manager monitors these connections more aggressively, applying shorter timeouts and more aggressive error detection to prevent hanging connections from consuming resources indefinitely.\n\n> **Decision: Health Check Strategy**\n> - **Context**: Backend servers can fail in various ways (network issues, application crashes, performance degradation), and the load balancer must detect these failures quickly while avoiding false positives that unnecessarily reduce capacity.\n> - **Options Considered**: \n>   1. Active HTTP health checks only\n>   2. Passive failure detection based on request failures\n>   3. Combined active and passive health checking\n> - **Decision**: Implement active HTTP health checks with passive failure detection as a backup\n> - **Rationale**: Active health checks provide proactive failure detection and can catch issues before they impact client requests. Passive detection serves as a safety net for failures that might not be caught by periodic health checks, such as servers that pass health checks but fail real requests due to race conditions or resource exhaustion.\n> - **Consequences**: Requires additional implementation complexity and generates constant background traffic to backend servers, but provides the most reliable failure detection and fastest recovery times.\n\n### Load Balancing Decisions\n\nThe architecture of the load balancing component requires several critical design decisions that fundamentally impact performance, reliability, and operational characteristics. These decisions interact with each other in complex ways, making it essential to understand the trade-offs and select options that align with the overall system goals.\n\n**Backend selection synchronization** addresses the challenge of making load balancing decisions safely in a multi-threaded environment where multiple worker threads may simultaneously attempt to select backend servers for different client requests. The naive approach of protecting the entire backend selection process with a single mutex would create a severe bottleneck, as every request would need to acquire the same lock before proceeding.\n\nThe selected approach uses fine-grained locking with separate mutexes for different aspects of the backend selection process. The backend server list itself is protected by a read-write lock that allows multiple threads to read the list simultaneously while ensuring exclusive access for updates when servers are added, removed, or change health status. Load balancing algorithm state (such as connection counters for least-connections or round-robin positions) uses separate synchronization primitives appropriate to each algorithm's needs.\n\nRound-robin algorithm state uses atomic integer operations for the server index counter, eliminating lock contention entirely for the common case of backend selection. Least-connections algorithm requires more complex synchronization because it needs to both read connection counts across all servers and update the selected server's count, which is handled through a combination of atomic operations for individual counters and brief critical sections for the selection logic.\n\n> **Decision: Backend Selection Synchronization Strategy**\n> - **Context**: Multiple worker threads need to select backend servers simultaneously, and the backend selection process is in the critical path for request processing performance.\n> - **Options Considered**: \n>   1. Single global mutex protecting all backend selection\n>   2. Per-algorithm synchronization strategies with minimal locking\n>   3. Lock-free algorithms using atomic operations and hazard pointers\n> - **Decision**: Implement per-algorithm synchronization with atomic operations where possible and fine-grained locking where necessary\n> - **Rationale**: Single global mutex would create unacceptable performance bottlenecks under high concurrency. Lock-free algorithms provide the best performance but significantly increase implementation complexity and debugging difficulty. Per-algorithm synchronization strikes the right balance of performance and maintainability.\n> - **Consequences**: Requires careful implementation of each algorithm's synchronization needs and thorough testing for race conditions, but provides good performance scaling with multiple worker threads.\n\n**Health check integration** determines how health status changes propagate to the load balancing algorithm and how quickly the system responds to backend server state transitions. The health checking system operates on a different timeline than request processing - health checks occur every few seconds while request routing happens thousands of times per second.\n\nThe integration design uses event-driven health status updates where health check results trigger immediate updates to the load balancing algorithm's view of available servers. When a server transitions from healthy to unhealthy, the health checker immediately removes it from all load balancing algorithms' active server lists. Conversely, when an unhealthy server recovers, it gets added back to the active lists with appropriate state initialization (such as resetting connection counters for least-connections).\n\nThis event-driven approach ensures that load balancing decisions always reflect the most current health information without requiring the request processing path to perform health status checks. The alternative of having each request check server health status would introduce unacceptable latency and complexity to the critical path.\n\n**Server weight management** for weighted round-robin algorithm requires careful consideration of how weight changes propagate and when they take effect. Changing server weights while the algorithm is actively processing requests could disrupt the distribution pattern or create inconsistent behavior.\n\nThe implementation uses a two-phase weight update process where new weights are staged in a separate configuration structure and then atomically activated during the next algorithm cycle completion. This approach ensures that weight changes take effect cleanly without disrupting ongoing request distribution patterns or creating race conditions between configuration updates and request processing.\n\nThe system also supports dynamic weight adjustment based on server performance metrics, allowing weights to automatically decrease for servers showing signs of stress (such as increasing response times) and increase for servers with excess capacity. This adaptive weighting provides a bridge between the simplicity of weighted round-robin and the load awareness of least-connections.\n\n| Synchronization Approach | Pros | Cons | Best Use Case |\n|-------------------------|------|------|---------------|\n| Global Mutex | Simple implementation, Easy reasoning | Severe performance bottleneck | Low-concurrency deployments |\n| Per-Algorithm Locks | Balanced complexity/performance | Still some lock contention | Most production deployments |\n| Lock-Free Atomic | Maximum performance | High implementation complexity | Ultra-high performance requirements |\n\n**Error handling and fallback logic** defines how the load balancer behaves when all backend servers are unhealthy or when the selected backend server fails after being chosen but before the request is forwarded. These edge cases require careful handling to provide graceful degradation rather than complete service failure.\n\nWhen all backend servers in a pool are marked unhealthy, the load balancer implements a \"best effort\" fallback mode where it continues routing requests to the least-recently-failed servers while continuing aggressive health checking. This approach recognizes that health check failures might represent false positives due to network issues or temporary overload, and that attempting to serve requests is better than refusing all traffic.\n\nThe system maintains a \"failure recency\" ranking for unhealthy servers, preferring servers that failed more recently (and thus might have a higher chance of recovery) over servers that have been failing for extended periods. This heuristic helps identify servers that might be experiencing transient issues versus those with more serious problems.\n\nFor requests that fail after backend selection (such as connection establishment failures or immediate HTTP errors), the load balancer implements limited retry logic with different backend selection. A request that fails to connect to the initially selected backend server will be retried against up to two additional servers before returning an error to the client. This retry logic uses an exponential backoff delay to avoid overwhelming failing servers while still providing reasonable client response times.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Ignoring Connection State During Server Health Transitions**\n\nMany implementations make the mistake of immediately updating load balancing algorithm state when servers transition between healthy and unhealthy status, without considering the impact on existing connections to those servers. When a server becomes unhealthy, naive implementations might immediately mark all its connections as bad and close them, causing unnecessary client errors for requests that could have completed successfully.\n\nThe correct approach requires coordinating between the health checking system and the connection manager to handle server state transitions gracefully. When a server becomes unhealthy, new requests should stop being routed to it, but existing connections should be allowed to complete normally unless they individually show signs of failure. This requires the load balancer to distinguish between \"don't send new requests here\" and \"this server is completely unusable.\"\n\n⚠️ **Pitfall: Race Conditions in Connection Count Updates**\n\nThe least-connections algorithm requires careful synchronization when updating connection counts, particularly during rapid connection establishment and termination. A common mistake is updating connection counts at the wrong time in the connection lifecycle, leading to inaccurate counts that cause poor load distribution or even integer underflow when decrementing counts for connections that weren't properly registered.\n\nConnection counts must be updated atomically and at precisely defined points in the connection lifecycle: increment when a connection is successfully established and assigned to a backend server, decrement when the connection is closed or returned to the connection pool. The count update must be paired with the actual connection state change to prevent race conditions where the count and reality diverge.\n\n⚠️ **Pitfall: Not Handling Backend List Changes During Request Processing**\n\nBackend server lists can change dynamically as servers are added, removed, or change health status. Implementations often fail to properly handle these changes when they occur during active request processing, leading to array bounds errors, null pointer dereferences, or routing requests to servers that no longer exist.\n\nThe solution requires implementing proper read-copy-update semantics for the backend server list, where request processing threads work with stable snapshots of the server list while background threads can safely update the master list. This prevents request processing from being impacted by concurrent backend list modifications while ensuring that changes eventually become visible to new requests.\n\n### Implementation Guidance\n\nThe load balancer component builds upon the connection manager and HTTP parser to provide intelligent request distribution across backend servers. This component operates entirely within the request processing critical path, so implementation choices directly impact overall proxy performance.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Algorithm Selection | Single round-robin implementation | Pluggable algorithm interface with runtime selection |\n| Health Checking | Synchronous health checks in main loop | Dedicated health check thread with async updates |\n| Backend Configuration | Static configuration file | Dynamic backend management with configuration reload |\n| Metrics Collection | Simple counters | Detailed per-backend performance metrics |\n\n**Recommended File Structure:**\n\n```\ninternal/loadbalancer/\n  loadbalancer.go          ← main LoadBalancer struct and public interface\n  algorithms.go            ← load balancing algorithm implementations\n  healthcheck.go           ← health checking system and backend monitoring\n  backend.go               ← BackendServer management and configuration\n  metrics.go               ← load balancing metrics and statistics\n  loadbalancer_test.go     ← unit tests for load balancing logic\n  algorithms_test.go       ← algorithm-specific test cases\n  healthcheck_test.go      ← health checking test scenarios\n```\n\n**Load Balancer Infrastructure Code:**\n\n```c\n// LoadBalancer manages request distribution across backend servers\ntypedef struct {\n    BackendServer** backends;\n    size_t backend_count;\n    LoadBalancingAlgorithm algorithm;\n    \n    // Algorithm-specific state\n    size_t rr_current_index;\n    uint32_t* connection_counts;\n    uint32_t* weights;\n    uint32_t* current_weights;\n    \n    // Health checking\n    pthread_t health_check_thread;\n    bool* backend_healthy;\n    time_t* last_health_check;\n    time_t* last_failure_time;\n    uint32_t* failure_count;\n    \n    // Synchronization\n    pthread_rwlock_t backends_lock;\n    pthread_mutex_t state_mutex;\n    \n    // Configuration\n    int health_check_interval;\n    int health_check_timeout;\n    int failure_threshold;\n    int success_threshold;\n    \n    bool running;\n} LoadBalancer;\n\n// Backend server configuration and runtime state\ntypedef struct {\n    char host[256];\n    int port;\n    int weight;\n    bool enabled;\n    \n    // Health check configuration\n    char health_check_path[512];\n    int health_check_port;\n    \n    // Runtime metrics\n    uint32_t active_connections;\n    uint64_t total_requests;\n    uint64_t failed_requests;\n    double avg_response_time;\n    time_t last_success_time;\n    time_t last_failure_time;\n} BackendServer;\n\n// Load balancing algorithm enumeration\ntypedef enum {\n    LB_ROUND_ROBIN,\n    LB_LEAST_CONNECTIONS,\n    LB_WEIGHTED_ROUND_ROBIN,\n    LB_IP_HASH\n} LoadBalancingAlgorithm;\n\nLoadBalancer* loadbalancer_create(BackendServer** backends, size_t count, LoadBalancingAlgorithm algorithm);\nvoid loadbalancer_destroy(LoadBalancer* lb);\nbool loadbalancer_start(LoadBalancer* lb);\nvoid loadbalancer_stop(LoadBalancer* lb);\nBackendServer* loadbalancer_select_backend(LoadBalancer* lb, HttpRequest* request);\nvoid loadbalancer_update_connection_count(LoadBalancer* lb, BackendServer* backend, int delta);\nbool loadbalancer_is_backend_healthy(LoadBalancer* lb, BackendServer* backend);\n```\n\n**Core Load Balancing Algorithm Skeletons:**\n\n```c\n// SelectBackendRoundRobin selects the next backend using round-robin algorithm.\n// This algorithm cycles through healthy backends in order, providing even distribution.\nBackendServer* select_backend_round_robin(LoadBalancer* lb) {\n    // TODO 1: Acquire read lock on backends list to ensure stable access\n    // TODO 2: Count number of healthy backends in current list\n    // TODO 3: If no healthy backends available, return NULL\n    // TODO 4: Use atomic increment on rr_current_index to get next position\n    // TODO 5: Modulo operation to wrap around when reaching end of healthy backends\n    // TODO 6: Scan from current position to find next healthy backend\n    // TODO 7: Handle wraparound case if no healthy backends found after current position\n    // TODO 8: Release read lock and return selected backend\n    // Hint: Use __atomic_fetch_add for thread-safe index increment\n}\n\n// SelectBackendLeastConnections selects backend with minimum active connections.\n// This algorithm examines all healthy backends to find the least loaded server.\nBackendServer* select_backend_least_connections(LoadBalancer* lb) {\n    // TODO 1: Acquire read lock on backends list for stable access\n    // TODO 2: Initialize min_connections to UINT32_MAX and selected_backend to NULL\n    // TODO 3: Iterate through all backends in the list\n    // TODO 4: Skip backends that are marked unhealthy\n    // TODO 5: Read current connection count using atomic operation\n    // TODO 6: Compare with current minimum, update if lower\n    // TODO 7: Handle tie-breaking by preferring backends with lower index\n    // TODO 8: Increment selected backend's connection count atomically\n    // TODO 9: Release read lock and return selected backend\n    // Hint: Use __atomic_load for reading connection counts safely\n}\n\n// SelectBackendWeightedRoundRobin selects backend based on configured weights.\n// This algorithm ensures backends receive requests proportional to their weights.\nBackendServer* select_backend_weighted_round_robin(LoadBalancer* lb) {\n    // TODO 1: Acquire read lock on backends list\n    // TODO 2: Find backend with highest current_weight among healthy backends\n    // TODO 3: Select backend with maximum current_weight value\n    // TODO 4: Decrease selected backend's current_weight by sum of all backend weights\n    // TODO 5: Increase all healthy backends' current_weight by their configured weight\n    // TODO 6: Handle edge case where all backends have zero weight\n    // TODO 7: Release read lock and return selected backend\n    // Hint: This implements the \"smooth weighted round-robin\" algorithm\n}\n```\n\n**Health Checking System Implementation:**\n\n```c\n// HealthCheckBackend performs a single health check against specified backend.\n// Returns true if backend responds successfully, false otherwise.\nbool health_check_backend(LoadBalancer* lb, BackendServer* backend) {\n    // TODO 1: Create TCP socket with non-blocking flag\n    // TODO 2: Set socket timeout using SO_RCVTIMEO and SO_SNDTIMEO\n    // TODO 3: Connect to backend's health check port (or main port if not specified)\n    // TODO 4: Send HTTP GET request to health check path\n    // TODO 5: Read HTTP response with timeout handling\n    // TODO 6: Parse response status code from response line\n    // TODO 7: Consider 200-299 status codes as healthy, others as unhealthy\n    // TODO 8: Close socket and return health status\n    // Hint: Use poll() or select() for timeout handling during connect and read\n}\n\n// HealthCheckLoop runs continuously in background thread checking all backends.\n// This function implements the main health checking logic with configurable intervals.\nvoid* health_check_loop(void* arg) {\n    LoadBalancer* lb = (LoadBalancer*)arg;\n    \n    // TODO 1: Loop while lb->running flag is true\n    // TODO 2: Sleep for health_check_interval seconds (use nanosleep for precision)\n    // TODO 3: Iterate through all configured backends\n    // TODO 4: Skip disabled backends in configuration\n    // TODO 5: Perform health check using health_check_backend function\n    // TODO 6: Update failure/success counts based on health check result\n    // TODO 7: Apply failure_threshold and success_threshold logic\n    // TODO 8: Update backend_healthy array when status changes\n    // TODO 9: Log health status changes for operational visibility\n    // TODO 10: Update last_health_check timestamp\n    // Hint: Use compare-and-swap for atomic backend status updates\n}\n\n// UpdateBackendHealth changes backend health status with proper synchronization.\n// This function handles the transition between healthy and unhealthy states.\nvoid update_backend_health(LoadBalancer* lb, size_t backend_index, bool healthy) {\n    // TODO 1: Acquire write lock on backends to ensure exclusive access\n    // TODO 2: Check if health status is actually changing\n    // TODO 3: Update backend_healthy array with new status\n    // TODO 4: Reset failure/success counters when status changes\n    // TODO 5: Update last_failure_time or last_success_time as appropriate\n    // TODO 6: Log status change with backend details for monitoring\n    // TODO 7: Release write lock\n    // Hint: Only log when status actually changes to avoid log spam\n}\n```\n\n**Milestone Checkpoint:**\n\nAfter implementing the load balancer component, verify correct operation by:\n\n1. **Algorithm Testing**: Start the proxy with different load balancing algorithms and send multiple requests. Observe backend selection patterns:\n   - Round-robin should cycle through backends evenly\n   - Least-connections should prefer backends with fewer active connections\n   - Weighted round-robin should respect configured backend weights\n\n2. **Health Check Verification**: Stop one backend server and observe health check behavior:\n   - Requests should stop routing to the failed backend within one health check interval\n   - Backend should return to service after restarting and passing success threshold\n   - Check logs for health status change notifications\n\n3. **Concurrent Access Testing**: Use load testing tools to send many concurrent requests:\n   - No race condition errors or crashes should occur\n   - Backend selection should remain fair under high load\n   - Health checking should continue operating during heavy traffic\n\n4. **Configuration Changes**: Test dynamic backend configuration updates:\n   - Adding new backends should start receiving requests immediately\n   - Removing backends should drain existing connections gracefully\n   - Weight changes should affect distribution in next algorithm cycle\n\nExpected behavior: The load balancer should distribute requests according to the configured algorithm, automatically remove failed backends from service, and handle high concurrency without race conditions or performance degradation.\n\n\n## Cache Engine Component\n\n> **Milestone(s):** Milestone 4 (Caching) - implements HTTP response caching with proper cache-control header handling, TTL management, and cache invalidation strategies.\n\nThink of the cache engine as a smart librarian for your reverse proxy. Just as a librarian maintains an organized collection of books, knows which books are popular and should stay on the easy-access shelves, and periodically removes outdated materials, the cache engine stores frequently requested responses, understands HTTP caching rules, and automatically removes stale content. The librarian doesn't store every book ever requested (space is limited), doesn't lend out damaged books (respects cache-control directives), and knows when a book's information is too old to be useful (TTL expiration). This analogy captures the three core responsibilities: intelligent storage decisions, rule-based access control, and proactive cleanup.\n\nThe cache engine sits between the load balancer and backend servers, intercepting requests before they reach the backend and serving cached responses when possible. This positioning allows the cache to dramatically reduce backend load by serving repeated requests from memory, while respecting HTTP semantics ensures clients receive correct, up-to-date responses. The cache engine must balance performance gains against memory usage and cache coherence requirements.\n\n![Cache Lookup and Storage Flow](./diagrams/cache-lookup-flowchart.svg)\n\n### Caching Strategy\n\nThe caching strategy encompasses three fundamental decisions: what to cache, how to organize cached content, and when to remove it. These decisions directly impact both performance gains and memory efficiency.\n\n**Cache Key Generation**\n\nCache keys uniquely identify cacheable responses and determine whether two requests can share the same cached response. Think of cache keys as precise addresses in a massive warehouse - they must be specific enough to avoid delivering the wrong item, but consistent enough that identical requests always generate the same address.\n\nThe cache key generation process follows a deterministic algorithm that combines multiple request attributes:\n\n1. **Base Key Construction**: Start with the HTTP method and normalized URI (lowercased, sorted query parameters)\n2. **Header Variation Handling**: Examine the response `Vary` header to determine which request headers affect the response\n3. **Header Value Incorporation**: For each header listed in `Vary`, append its value to the cache key\n4. **Authorization Consideration**: Never cache responses for requests containing authorization headers unless explicitly allowed\n5. **Normalization**: Apply consistent encoding and ordering to ensure identical requests produce identical keys\n\n| Key Component | Source | Example | Purpose |\n|---------------|---------|---------|---------|\n| HTTP Method | Request line | `GET` | Distinguish method semantics |\n| Normalized URI | Request line | `/api/users?sort=name&limit=10` | Core resource identifier |\n| Vary Headers | Response Vary + Request | `accept-encoding:gzip` | Content negotiation |\n| Host Header | Request headers | `api.example.com` | Multi-tenant support |\n| Query Parameters | URI query string | `limit=10&sort=name` | Parameterized requests |\n\n**Storage Architecture**\n\nThe cache engine uses a two-level storage architecture combining hash table lookup with LRU eviction tracking. This design provides O(1) average-case lookup performance while maintaining efficient memory management.\n\nThe primary storage structure is a hash table mapping cache keys to cache entries. Each cache entry contains the complete HTTP response (status, headers, body) plus metadata for cache management. A separate doubly-linked list tracks access recency for LRU eviction decisions.\n\n| Storage Component | Purpose | Data Structure | Access Pattern |\n|-------------------|---------|----------------|----------------|\n| Primary Index | Fast key lookup | Hash table | O(1) average lookup |\n| Eviction Tracker | LRU ordering | Doubly-linked list | O(1) move-to-head |\n| Size Monitor | Memory limits | Running total | O(1) size tracking |\n| TTL Index | Expiration cleanup | Min-heap by expiry | O(log n) expiration |\n\n> **Design Insight**: The two-level architecture separates concerns between access speed (hash table) and replacement policy (LRU list). This separation allows independent optimization of each concern and supports future replacement policy changes without affecting the lookup mechanism.\n\n**Eviction Policies**\n\nThe cache engine implements multiple eviction triggers to maintain memory limits and data freshness. Eviction operates as a background process triggered by memory pressure or expiration events.\n\n**LRU (Least Recently Used) Eviction** removes the oldest accessed entries when memory limits are reached. Each cache access moves the corresponding entry to the head of the LRU list, maintaining precise access ordering. When eviction is needed, entries are removed from the tail until sufficient space is available.\n\n**TTL (Time-To-Live) Expiration** removes entries that exceed their maximum age, regardless of access patterns. Each cache entry stores an absolute expiration time calculated from the response `Cache-Control` directives. A background thread periodically scans for expired entries and removes them proactively.\n\n**Size-Based Eviction** prevents individual large responses from consuming excessive memory. Responses exceeding a configurable size threshold are never cached, and existing entries may be evicted if they prevent caching newer, smaller responses.\n\n> **Decision: Hybrid Eviction Strategy**\n> - **Context**: Different response patterns require different eviction strategies - some content becomes stale (TTL), others are rarely accessed (LRU), and some consume too much memory (size-based)\n> - **Options Considered**:\n>   1. TTL-only eviction with fixed expiration times\n>   2. Pure LRU eviction based solely on access patterns\n>   3. Hybrid approach combining TTL, LRU, and size constraints\n> - **Decision**: Implement hybrid eviction with TTL, LRU, and size-based triggers\n> - **Rationale**: HTTP caching semantics require TTL respect for correctness, LRU provides performance optimization, and size limits prevent memory exhaustion from large responses\n> - **Consequences**: More complex implementation but correctly handles diverse caching scenarios while providing memory safety guarantees\n\n| Eviction Type | Trigger Condition | Selection Criteria | Performance Impact |\n|---------------|-------------------|-------------------|-------------------|\n| TTL Expiration | Entry exceeds max-age | Absolute expiry time | O(1) per entry |\n| LRU Pressure | Memory limit exceeded | Least recently accessed | O(1) per eviction |\n| Size Rejection | Response too large | Individual response size | O(1) size check |\n| Proactive Cleanup | Periodic background | Batch expired entries | O(n) scan overhead |\n\n### HTTP Cache-Control Handling\n\nHTTP cache-control handling ensures the cache engine respects standard HTTP semantics while maximizing caching opportunities. Think of cache-control directives as traffic signals for cached content - they provide clear rules about when it's safe to serve cached responses, when fresh validation is required, and when caching is prohibited entirely.\n\n**Cache-Control Directive Processing**\n\nThe cache engine parses and evaluates cache-control directives from both request and response headers. Response directives control cachability and expiration, while request directives influence cache lookups and validation requirements.\n\n**Response Cache-Control Evaluation**:\n\n1. **Parse Response Headers**: Extract and parse the `Cache-Control` header into individual directives\n2. **Evaluate Cachability**: Check for `no-store` (never cache), `no-cache` (cache but validate), and `private` (cache only in private caches)\n3. **Calculate Expiration**: Use `max-age` directive or fall back to `Expires` header for TTL calculation\n4. **Store Validation Info**: Preserve `ETag` and `Last-Modified` headers for conditional requests\n5. **Apply Storage Decision**: Cache the response only if cachable according to evaluated directives\n\n| Directive | Effect on Caching | TTL Calculation | Validation Required |\n|-----------|-------------------|-----------------|-------------------|\n| `no-store` | Never cache | N/A | N/A |\n| `no-cache` | Cache with validation | From max-age/expires | Always |\n| `private` | Skip (reverse proxy) | N/A | N/A |\n| `public` | Cache allowed | From max-age/expires | When stale |\n| `max-age=N` | Cache for N seconds | N seconds | When stale |\n| `must-revalidate` | Cache with strict validation | From max-age/expires | When stale |\n\n**Conditional Request Handling**\n\nConditional requests allow the cache engine to validate stale entries with backend servers, potentially avoiding full response transfers. The cache engine generates conditional requests using stored validation information and processes 304 Not Modified responses appropriately.\n\n**Conditional Request Generation Process**:\n\n1. **Check Stale Entry**: Identify cached entries that exceed their max-age but have validation headers\n2. **Generate If-None-Match**: Use stored `ETag` value to create `If-None-Match` header\n3. **Generate If-Modified-Since**: Use stored `Last-Modified` value to create `If-Modified-Since` header\n4. **Forward Conditional Request**: Send conditional request to backend server with original URI and validation headers\n5. **Process Validation Response**: Handle 304 Not Modified (refresh cache entry) or 200 OK (replace cache entry)\n\n> **Design Insight**: Conditional requests transform cache misses into cache refreshes, significantly reducing bandwidth usage and backend load. A 304 Not Modified response allows the cache to serve the existing response body while updating expiration information, providing the performance benefits of caching with the correctness guarantees of validation.\n\n**Vary Header Processing**\n\nThe `Vary` response header indicates which request headers affect the response content, requiring the cache engine to incorporate these headers into cache key generation. Proper `Vary` handling prevents serving inappropriate cached responses to clients with different capabilities or preferences.\n\n**Vary Processing Algorithm**:\n\n1. **Parse Vary Header**: Extract list of header names from the response `Vary` header\n2. **Extract Request Values**: For each header name in `Vary`, extract the corresponding value from the original request\n3. **Normalize Values**: Apply consistent case normalization and whitespace handling to header values\n4. **Incorporate into Key**: Append normalized header values to the cache key in deterministic order\n5. **Store Vary Information**: Preserve the complete `Vary` list with the cached response for future key generation\n\n| Vary Header | Request Impact | Key Component | Example |\n|-------------|----------------|---------------|---------|\n| `Accept-Encoding` | Content compression | `accept-encoding:gzip` | Different compressions cached separately |\n| `Accept-Language` | Content localization | `accept-language:en-US` | Different languages cached separately |\n| `User-Agent` | Browser-specific content | `user-agent:Mozilla/...` | Browser-specific responses |\n| `Accept` | Content type negotiation | `accept:application/json` | JSON vs XML responses |\n\n> **Decision: Full Vary Support with Key Segmentation**\n> - **Context**: The `Vary` header allows responses to depend on arbitrary request headers, creating complex cache key requirements\n> - **Options Considered**:\n>   1. Ignore `Vary` headers and cache only the first response variant\n>   2. Support limited `Vary` headers (only common ones like `Accept-Encoding`)\n>   3. Full `Vary` support with dynamic key generation\n> - **Decision**: Implement full `Vary` support with request header incorporation into cache keys\n> - **Rationale**: Correct HTTP semantics require full `Vary` support to avoid serving incorrect cached responses to clients with different capabilities\n> - **Consequences**: More complex cache key generation and potentially reduced cache hit rates, but guaranteed correctness for content negotiation scenarios\n\n### Caching Design Decisions\n\nThe cache engine architecture reflects several critical design decisions that balance performance, correctness, and operational complexity. Each decision involves trade-offs between competing requirements.\n\n> **Decision: In-Memory Cache with LRU Eviction**\n> - **Context**: The cache engine needs fast access to cached responses while managing memory limits and avoiding storage complexity\n> - **Options Considered**:\n>   1. Pure in-memory hash table with no eviction\n>   2. Disk-backed cache with persistent storage\n>   3. In-memory cache with LRU eviction\n>   4. Tiered cache with memory and disk levels\n> - **Decision**: In-memory cache with LRU eviction and configurable size limits\n> - **Rationale**: In-memory storage provides microsecond access times essential for reverse proxy performance, LRU eviction prevents memory exhaustion, and avoiding disk eliminates I/O bottlenecks\n> - **Consequences**: Cache is lost on restart and limited by available memory, but provides maximum performance for actively cached content\n\n| Option | Performance | Persistence | Complexity | Memory Usage |\n|--------|------------|-------------|------------|--------------|\n| Pure Memory | Excellent | None | Low | Unbounded |\n| Disk-Backed | Poor | Full | High | Bounded |\n| Memory + LRU | Excellent | None | Medium | Bounded |\n| Tiered | Good | Partial | Very High | Tiered |\n\n> **Decision: Thread-Safe Cache with Read-Write Locks**\n> - **Context**: Multiple worker threads need concurrent access to cache data structures for both reads (cache lookups) and writes (cache updates and evictions)\n> - **Options Considered**:\n>   1. Single-threaded cache with message passing\n>   2. Coarse-grained mutex protecting entire cache\n>   3. Fine-grained locking with per-entry locks\n>   4. Read-write locks with optimistic concurrency\n> - **Decision**: Read-write locks with separate locks for cache operations and LRU management\n> - **Rationale**: Cache lookups vastly outnumber updates, making read-write locks optimal for this read-heavy workload with occasional writes\n> - **Consequences**: Excellent read concurrency but potential write contention during eviction storms; requires careful lock ordering to prevent deadlocks\n\n> **Decision: Proactive TTL Cleanup with Background Thread**\n> - **Context**: Expired cache entries consume memory and may be served incorrectly if not removed promptly\n> - **Options Considered**:\n>   1. Lazy expiration checking only on access\n>   2. Periodic full cache scanning for expired entries\n>   3. Priority queue with next-expiry tracking\n>   4. Background thread with batched cleanup\n> - **Decision**: Background thread that periodically scans and removes expired entries in batches\n> - **Rationale**: Proactive cleanup prevents memory leaks from expired content, batched processing amortizes scanning costs, and background execution avoids blocking request processing\n> - **Consequences**: Constant low-level CPU overhead for cleanup scanning, but guaranteed memory reclamation and elimination of stale content serving\n\n**Cache Engine Data Structures**\n\nThe cache engine maintains several interconnected data structures to support fast lookup, efficient eviction, and proper HTTP semantics compliance.\n\n| Structure | Type | Purpose | Key Operations |\n|-----------|------|---------|----------------|\n| `cache_table` | `HashTable*` | Primary cache lookup | get, put, remove |\n| `lru_list` | `LRUList*` | Access ordering | move_to_head, remove_tail |\n| `ttl_heap` | `TTLHeap*` | Expiration tracking | peek_expired, remove_expired |\n| `cache_mutex` | `pthread_rwlock_t` | Concurrency control | read_lock, write_lock |\n| `size_current` | `size_t` | Memory usage tracking | atomic_add, atomic_sub |\n| `size_limit` | `size_t` | Memory limit | configuration value |\n\n**CacheEngine Structure Definition**:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `cache_table` | `HashTable*` | Primary storage mapping cache keys to entries |\n| `lru_head` | `CacheEntry*` | Head of doubly-linked LRU list |\n| `lru_tail` | `CacheEntry*` | Tail of doubly-linked LRU list |\n| `ttl_heap` | `TTLHeap*` | Min-heap ordered by expiration time |\n| `cache_rwlock` | `pthread_rwlock_t` | Reader-writer lock for cache operations |\n| `lru_mutex` | `pthread_mutex_t` | Mutex protecting LRU list manipulation |\n| `size_current` | `size_t` | Current total cache size in bytes |\n| `size_limit` | `size_t` | Maximum allowed cache size |\n| `default_ttl` | `time_t` | Default TTL for responses without cache headers |\n| `cleanup_thread` | `pthread_t` | Background thread for TTL cleanup |\n| `cleanup_interval` | `int` | Seconds between cleanup cycles |\n| `hit_count` | `uint64_t` | Cache hit counter for metrics |\n| `miss_count` | `uint64_t` | Cache miss counter for metrics |\n| `eviction_count` | `uint64_t` | Eviction counter for metrics |\n| `running` | `bool` | Flag controlling background thread execution |\n\n**CacheEntry Structure Definition**:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `cache_key` | `char[512]` | Unique identifier for cached response |\n| `response_status` | `int` | HTTP status code of cached response |\n| `response_headers` | `HashTable*` | Complete response header collection |\n| `response_body` | `Buffer*` | Response body content |\n| `content_length` | `size_t` | Size of response body in bytes |\n| `created_time` | `time_t` | When entry was first cached |\n| `last_access` | `time_t` | Most recent access timestamp |\n| `expires_time` | `time_t` | Absolute expiration time |\n| `etag` | `char[256]` | ETag header value for validation |\n| `last_modified` | `char[128]` | Last-Modified header for validation |\n| `vary_headers` | `char[512]` | Comma-separated list of Vary header names |\n| `cache_control` | `CacheControl*` | Parsed cache-control directives |\n| `lru_prev` | `CacheEntry*` | Previous entry in LRU list |\n| `lru_next` | `CacheEntry*` | Next entry in LRU list |\n| `ttl_heap_index` | `size_t` | Position in TTL expiration heap |\n| `entry_size` | `size_t` | Total memory consumed by this entry |\n| `hit_count` | `uint32_t` | Number of times entry was served |\n\n**Cache Engine Interface Methods**:\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `cache_engine_create` | `size_t max_size, int default_ttl` | `CacheEngine*` | Initialize cache with size and TTL limits |\n| `cache_engine_lookup` | `CacheEngine*, HttpRequest*` | `CacheEntry*` | Find cached response for request |\n| `cache_engine_store` | `CacheEngine*, char*, HttpResponse*` | `bool` | Store response in cache if cacheable |\n| `cache_engine_invalidate` | `CacheEngine*, char*` | `bool` | Remove specific entry from cache |\n| `cache_engine_clear` | `CacheEngine*` | `void` | Remove all cached entries |\n| `cache_engine_stats` | `CacheEngine*` | `CacheStats*` | Retrieve hit/miss/eviction statistics |\n| `cache_generate_key` | `HttpRequest*` | `char*` | Generate cache key for request |\n| `cache_is_cacheable` | `HttpResponse*` | `bool` | Determine if response can be cached |\n| `cache_is_fresh` | `CacheEntry*, time_t` | `bool` | Check if cached entry is still fresh |\n| `cache_create_conditional` | `HttpRequest*, CacheEntry*` | `HttpRequest*` | Create conditional request for validation |\n| `cache_update_from_304` | `CacheEntry*, HttpResponse*` | `void` | Update entry from 304 Not Modified |\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Caching Non-Cacheable Responses**\n\nBeginning developers often cache every response to maximize hit rates, ignoring HTTP semantics that prohibit caching certain responses. Caching responses with `Cache-Control: no-store`, responses to authenticated requests, or responses with `Set-Cookie` headers can cause security vulnerabilities and incorrect behavior.\n\nThis occurs because the caching logic focuses on performance rather than correctness. The cache engine must evaluate cache-control directives, authentication headers, and response characteristics before making storage decisions.\n\nTo avoid this pitfall, implement a comprehensive `cache_is_cacheable` function that checks all HTTP caching restrictions: verify no `no-store` directive, ensure no authorization headers in the request unless `public` is specified, check that the response status code is cacheable (200, 203, 300, 301, 410, etc.), and confirm no `Set-Cookie` headers unless specifically allowed.\n\n⚠️ **Pitfall: Ignoring Vary Headers in Cache Keys**\n\nMany implementations generate cache keys using only the request URI, ignoring the response `Vary` header that indicates which request headers affect the response. This causes the cache to serve incorrect responses to clients with different capabilities or preferences.\n\nFor example, a server might return gzipped content for clients supporting compression and uncompressed content for others, using `Vary: Accept-Encoding`. Without incorporating the `Accept-Encoding` header into the cache key, a client that doesn't support compression might receive a cached gzipped response, causing display errors.\n\nThe solution requires parsing the `Vary` header from cached responses and incorporating the corresponding request header values into cache key generation. Store the complete `Vary` header list with each cache entry and use it to generate keys for subsequent requests.\n\n⚠️ **Pitfall: Serving Stale Content Beyond max-age**\n\nCache implementations sometimes serve expired content when backend servers are unavailable, violating HTTP semantics unless the response included `Cache-Control: stale-while-revalidate` or similar directives.\n\nThis happens when error handling logic prioritizes availability over correctness, serving any cached content during backend failures. While this might seem helpful, it can serve dangerously stale content (hours or days old) that no longer represents accurate information.\n\nImplement proper TTL checking that never serves content beyond its `max-age` unless the response explicitly allows stale serving. Use conditional requests to validate stale content when possible, and return appropriate 502/503 errors when fresh content cannot be obtained.\n\n⚠️ **Pitfall: Memory Leaks from Unbounded Cache Growth**\n\nWithout proper eviction mechanisms, cache implementations can consume unlimited memory, eventually causing out-of-memory crashes in high-traffic scenarios.\n\nThis occurs when developers implement cache storage without size limits or eviction policies, assuming that cache hit rates will naturally limit memory usage. In reality, diverse request patterns can create large numbers of unique cache entries that collectively exceed available memory.\n\nImplement comprehensive size tracking that includes both response body size and metadata overhead. Use LRU eviction triggered by configurable memory limits, and consider implementing maximum entry size limits to prevent individual large responses from dominating cache space.\n\n⚠️ **Pitfall: Race Conditions in Concurrent Cache Access**\n\nMulti-threaded environments require careful synchronization of cache data structures, but many implementations use insufficient locking that leads to corruption, crashes, or incorrect behavior.\n\nThe most common issue is using a single mutex for all cache operations, creating unnecessary contention between read operations (cache lookups) that could proceed concurrently. Another issue is inconsistent locking between cache lookup and LRU list updates, potentially corrupting the access ordering.\n\nUse read-write locks that allow concurrent reads while serializing writes. Implement separate locks for cache table operations and LRU list manipulation, but ensure consistent lock ordering to prevent deadlocks. Consider atomic operations for simple counter updates like hit/miss statistics.\n\n### Implementation Guidance\n\nThe cache engine implementation requires careful attention to memory management, concurrency control, and HTTP semantics compliance. This guidance provides working infrastructure code and detailed implementation skeletons for the core caching logic.\n\n**Technology Recommendations**:\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Hash Table | Simple chaining with linked lists | Robin Hood hashing with open addressing |\n| Memory Management | malloc/free with manual tracking | Memory pools with fixed-size allocations |\n| Threading | pthread with read-write locks | Lock-free data structures with hazard pointers |\n| Time Handling | time() system calls | High-resolution timers with cached current time |\n| HTTP Parsing | String manipulation with strstr | Dedicated HTTP header parsing library |\n\n**Recommended File Structure**:\n```\nsrc/\n  cache/\n    cache_engine.h          ← Main cache engine interface\n    cache_engine.c          ← Core cache logic implementation  \n    cache_entry.h           ← Cache entry data structures\n    cache_entry.c           ← Entry lifecycle management\n    cache_key.h             ← Cache key generation\n    cache_key.c             ← Key generation algorithms\n    cache_control.h         ← HTTP cache-control parsing\n    cache_control.c         ← Cache directive evaluation\n    lru_list.h              ← LRU eviction list\n    lru_list.c              ← LRU list operations\n    ttl_heap.h              ← TTL expiration heap\n    ttl_heap.c              ← Heap-based expiration tracking\n    cache_stats.h           ← Cache metrics and statistics\n    cache_stats.c           ← Statistics collection\n  tests/\n    test_cache_engine.c     ← Cache engine unit tests\n    test_cache_key.c        ← Key generation tests\n    test_cache_control.c    ← HTTP directive tests\n```\n\n**Infrastructure Starter Code**:\n\n```c\n// cache_control.h - Complete HTTP Cache-Control parsing\n#ifndef CACHE_CONTROL_H\n#define CACHE_CONTROL_H\n\n#include <stdbool.h>\n#include <time.h>\n\ntypedef struct {\n    bool no_store;\n    bool no_cache;\n    bool must_revalidate;\n    bool private;\n    bool public;\n    int max_age;           // -1 if not specified\n    int s_maxage;          // -1 if not specified\n    bool has_etag;\n    bool has_last_modified;\n} CacheControl;\n\n// Parse Cache-Control header into structured directives\nCacheControl* cache_control_parse(const char* header_value);\n\n// Check if response is cacheable based on cache-control directives\nbool cache_control_is_cacheable(const CacheControl* cc, bool has_authorization);\n\n// Calculate expiration time from cache-control and response headers\ntime_t cache_control_calculate_expiry(const CacheControl* cc, \n                                     const char* expires_header,\n                                     time_t response_time);\n\n// Check if cached entry is fresh at given time\nbool cache_control_is_fresh(const CacheControl* cc, time_t cached_time, \n                           time_t current_time);\n\nvoid cache_control_destroy(CacheControl* cc);\n\n#endif\n\n// cache_control.c - Implementation\n#include \"cache_control.h\"\n#include <stdlib.h>\n#include <string.h>\n#include <ctype.h>\n\nCacheControl* cache_control_parse(const char* header_value) {\n    if (!header_value) return NULL;\n    \n    CacheControl* cc = calloc(1, sizeof(CacheControl));\n    cc->max_age = -1;\n    cc->s_maxage = -1;\n    \n    char* header_copy = strdup(header_value);\n    char* token = strtok(header_copy, \",\");\n    \n    while (token) {\n        // Skip whitespace\n        while (isspace(*token)) token++;\n        \n        if (strncmp(token, \"no-store\", 8) == 0) {\n            cc->no_store = true;\n        } else if (strncmp(token, \"no-cache\", 8) == 0) {\n            cc->no_cache = true;\n        } else if (strncmp(token, \"must-revalidate\", 15) == 0) {\n            cc->must_revalidate = true;\n        } else if (strncmp(token, \"private\", 7) == 0) {\n            cc->private = true;\n        } else if (strncmp(token, \"public\", 6) == 0) {\n            cc->public = true;\n        } else if (strncmp(token, \"max-age=\", 8) == 0) {\n            cc->max_age = atoi(token + 8);\n        } else if (strncmp(token, \"s-maxage=\", 9) == 0) {\n            cc->s_maxage = atoi(token + 9);\n        }\n        \n        token = strtok(NULL, \",\");\n    }\n    \n    free(header_copy);\n    return cc;\n}\n\nbool cache_control_is_cacheable(const CacheControl* cc, bool has_authorization) {\n    // Never cache if no-store directive present\n    if (cc->no_store) return false;\n    \n    // Don't cache authorized requests unless explicitly public\n    if (has_authorization && !cc->public) return false;\n    \n    // Don't cache private responses in shared cache (reverse proxy)\n    if (cc->private) return false;\n    \n    return true;\n}\n\ntime_t cache_control_calculate_expiry(const CacheControl* cc, \n                                     const char* expires_header,\n                                     time_t response_time) {\n    // Use s-maxage for shared caches if present\n    if (cc->s_maxage >= 0) {\n        return response_time + cc->s_maxage;\n    }\n    \n    // Use max-age if present\n    if (cc->max_age >= 0) {\n        return response_time + cc->max_age;\n    }\n    \n    // Fall back to Expires header parsing\n    if (expires_header) {\n        // Parse HTTP date format - simplified for example\n        struct tm tm = {0};\n        if (strptime(expires_header, \"%a, %d %b %Y %H:%M:%S GMT\", &tm)) {\n            return mktime(&tm);\n        }\n    }\n    \n    // No expiration information\n    return 0;\n}\n\nbool cache_control_is_fresh(const CacheControl* cc, time_t cached_time, \n                           time_t current_time) {\n    int max_age = cc->s_maxage >= 0 ? cc->s_maxage : cc->max_age;\n    if (max_age < 0) return false; // No expiration specified\n    \n    return (current_time - cached_time) <= max_age;\n}\n\nvoid cache_control_destroy(CacheControl* cc) {\n    if (cc) free(cc);\n}\n```\n\n```c\n// lru_list.h - Complete LRU list implementation\n#ifndef LRU_LIST_H\n#define LRU_LIST_H\n\n#include \"cache_entry.h\"\n#include <pthread.h>\n\ntypedef struct LRUList {\n    CacheEntry* head;\n    CacheEntry* tail;\n    size_t count;\n    pthread_mutex_t lru_mutex;\n} LRUList;\n\nLRUList* lru_list_create(void);\nvoid lru_list_move_to_head(LRUList* list, CacheEntry* entry);\nvoid lru_list_add_to_head(LRUList* list, CacheEntry* entry);\nCacheEntry* lru_list_remove_tail(LRUList* list);\nvoid lru_list_remove_entry(LRUList* list, CacheEntry* entry);\nvoid lru_list_destroy(LRUList* list);\n\n#endif\n\n// lru_list.c\n#include \"lru_list.h\"\n#include <stdlib.h>\n\nLRUList* lru_list_create(void) {\n    LRUList* list = calloc(1, sizeof(LRUList));\n    pthread_mutex_init(&list->lru_mutex, NULL);\n    return list;\n}\n\nvoid lru_list_move_to_head(LRUList* list, CacheEntry* entry) {\n    pthread_mutex_lock(&list->lru_mutex);\n    \n    // Remove from current position\n    if (entry->lru_prev) entry->lru_prev->lru_next = entry->lru_next;\n    if (entry->lru_next) entry->lru_next->lru_prev = entry->lru_prev;\n    if (list->tail == entry) list->tail = entry->lru_prev;\n    \n    // Add to head\n    entry->lru_prev = NULL;\n    entry->lru_next = list->head;\n    if (list->head) list->head->lru_prev = entry;\n    list->head = entry;\n    if (!list->tail) list->tail = entry;\n    \n    pthread_mutex_unlock(&list->lru_mutex);\n}\n\nvoid lru_list_add_to_head(LRUList* list, CacheEntry* entry) {\n    pthread_mutex_lock(&list->lru_mutex);\n    \n    entry->lru_prev = NULL;\n    entry->lru_next = list->head;\n    if (list->head) list->head->lru_prev = entry;\n    list->head = entry;\n    if (!list->tail) list->tail = entry;\n    list->count++;\n    \n    pthread_mutex_unlock(&list->lru_mutex);\n}\n\nCacheEntry* lru_list_remove_tail(LRUList* list) {\n    pthread_mutex_lock(&list->lru_mutex);\n    \n    CacheEntry* entry = list->tail;\n    if (entry) {\n        list->tail = entry->lru_prev;\n        if (list->tail) list->tail->lru_next = NULL;\n        else list->head = NULL;\n        \n        entry->lru_prev = entry->lru_next = NULL;\n        list->count--;\n    }\n    \n    pthread_mutex_unlock(&list->lru_mutex);\n    return entry;\n}\n\nvoid lru_list_remove_entry(LRUList* list, CacheEntry* entry) {\n    pthread_mutex_lock(&list->lru_mutex);\n    \n    if (entry->lru_prev) entry->lru_prev->lru_next = entry->lru_next;\n    if (entry->lru_next) entry->lru_next->lru_prev = entry->lru_prev;\n    if (list->head == entry) list->head = entry->lru_next;\n    if (list->tail == entry) list->tail = entry->lru_prev;\n    \n    entry->lru_prev = entry->lru_next = NULL;\n    list->count--;\n    \n    pthread_mutex_unlock(&list->lru_mutex);\n}\n\nvoid lru_list_destroy(LRUList* list) {\n    if (list) {\n        pthread_mutex_destroy(&list->lru_mutex);\n        free(list);\n    }\n}\n```\n\n**Core Cache Engine Implementation Skeleton**:\n\n```c\n// cache_engine.c - Core cache logic with detailed TODOs\n#include \"cache_engine.h\"\n#include \"cache_control.h\"\n#include \"lru_list.h\"\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n\nCacheEngine* cache_engine_create(size_t max_size, int default_ttl) {\n    // TODO 1: Allocate and initialize CacheEngine structure\n    // TODO 2: Create hash table with reasonable initial size (e.g., 1024 buckets)\n    // TODO 3: Initialize LRU list for eviction tracking\n    // TODO 4: Initialize read-write lock for concurrent access\n    // TODO 5: Set size limits and TTL defaults from parameters\n    // TODO 6: Initialize statistics counters (hit_count, miss_count, etc.)\n    // TODO 7: Start background cleanup thread for TTL expiration\n    // Hint: Use hashtable_create(1024) for initial table size\n    // Hint: pthread_rwlock_init for read-write lock initialization\n}\n\nCacheEntry* cache_engine_lookup(CacheEngine* engine, HttpRequest* request) {\n    // TODO 1: Generate cache key from request (method, URI, headers)\n    // TODO 2: Acquire read lock on cache for thread-safe lookup\n    // TODO 3: Search hash table using generated cache key\n    // TODO 4: If entry found, check if it's still fresh (TTL validation)\n    // TODO 5: If fresh, update access time and move to LRU head\n    // TODO 6: If stale, consider conditional request creation\n    // TODO 7: Increment hit or miss counters appropriately\n    // TODO 8: Release read lock and return entry (or NULL for miss)\n    // Hint: Use cache_generate_key(request) for key generation\n    // Hint: Use cache_control_is_fresh() for TTL checking\n}\n\nbool cache_engine_store(CacheEngine* engine, char* key, HttpResponse* response) {\n    // TODO 1: Parse response Cache-Control headers for cachability\n    // TODO 2: Check if response is cacheable (no no-store, appropriate status)\n    // TODO 3: Calculate response size including headers and body\n    // TODO 4: Check if response size exceeds individual entry limit\n    // TODO 5: Acquire write lock for cache modification\n    // TODO 6: Check if storing would exceed total cache size limit\n    // TODO 7: Evict LRU entries until sufficient space available\n    // TODO 8: Create new CacheEntry with response data and metadata\n    // TODO 9: Insert entry into hash table and add to LRU head\n    // TODO 10: Update current cache size and storage statistics\n    // TODO 11: Release write lock and return success status\n    // Hint: Use cache_control_parse() for Cache-Control evaluation\n    // Hint: Use lru_list_remove_tail() for eviction when space needed\n}\n\nchar* cache_generate_key(HttpRequest* request) {\n    // TODO 1: Start with HTTP method and normalized URI\n    // TODO 2: Check for cached response Vary header (if doing validation)\n    // TODO 3: For each header in Vary, append header name and value\n    // TODO 4: Include Host header for virtual hosting support\n    // TODO 5: Ensure consistent ordering and normalization\n    // TODO 6: Allocate and return null-terminated key string\n    // Hint: Use fixed-size buffer (512 bytes) for key construction\n    // Hint: Normalize header names to lowercase for consistency\n}\n\nbool cache_is_cacheable(HttpResponse* response) {\n    // TODO 1: Parse Cache-Control header from response\n    // TODO 2: Check for no-store directive (never cache)\n    // TODO 3: Check for private directive (not for shared caches)\n    // TODO 4: Verify response status code is cacheable (200, 301, etc.)\n    // TODO 5: Check for Set-Cookie headers (usually not cacheable)\n    // TODO 6: Return true only if all caching requirements met\n    // Hint: Use cache_control_parse() for header evaluation\n    // Hint: Status codes 200, 203, 300, 301, 410 are typically cacheable\n}\n\nvoid* cache_cleanup_thread(void* arg) {\n    // TODO 1: Cast argument to CacheEngine pointer\n    // TODO 2: Loop while engine->running flag is true\n    // TODO 3: Sleep for cleanup_interval seconds\n    // TODO 4: Acquire write lock for cache modification\n    // TODO 5: Scan cache entries for expired TTL values\n    // TODO 6: Remove expired entries from hash table and LRU list\n    // TODO 7: Update cache size and eviction statistics\n    // TODO 8: Release write lock and continue loop\n    // Hint: Use time(NULL) for current time comparison\n    // Hint: Batch multiple removals in single lock acquisition\n}\n```\n\n**Milestone Checkpoints**:\n\nAfter implementing the cache engine core, verify functionality with these checkpoints:\n\n1. **Cache Key Generation**: Create requests with different URIs, methods, and headers. Verify that identical requests generate identical keys and different requests generate different keys.\n\n2. **Basic Caching**: Send identical GET requests through the proxy. First request should be forwarded to backend, subsequent requests should be served from cache (verify with backend access logs).\n\n3. **Cache-Control Respect**: Send requests for resources with different cache-control headers (`no-store`, `max-age=60`, etc.). Verify that uncacheable responses are not cached and cached responses respect TTL limits.\n\n4. **Vary Header Handling**: Configure backend to return `Vary: Accept-Encoding` and send requests with different Accept-Encoding headers. Verify that different encodings are cached separately.\n\n5. **LRU Eviction**: Configure small cache size and send requests for more content than cache can hold. Verify that least recently used entries are evicted first.\n\n**Debugging Tips**:\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Cache never hits | Key generation inconsistency | Log generated keys for identical requests | Ensure header normalization and consistent ordering |\n| Memory usage grows unbounded | Missing eviction or TTL cleanup | Check LRU list size and cleanup thread | Verify size limit enforcement and cleanup thread operation |\n| Stale content served | TTL calculation error | Log expiry times vs current time | Fix cache_control_calculate_expiry implementation |\n| Wrong content for client | Missing Vary support | Check if response has Vary header | Include Vary headers in key generation |\n| Cache corruption/crashes | Race condition in concurrent access | Run with thread sanitizer | Fix lock ordering and ensure consistent locking |\n\n\n## SSL Termination Component\n\n> **Milestone(s):** Milestone 5 (SSL Termination) - handles HTTPS connections by terminating TLS at the proxy and forwarding decrypted HTTP to backends\n\nThink of SSL termination like a high-security checkpoint at a government building. Visitors arrive with various forms of encrypted identification (SSL certificates), guards at the checkpoint verify their credentials and decrypt their intentions (TLS handshake), then escort them inside using simple internal protocols (plain HTTP to backends). The guards must handle multiple types of credentials (SNI for different domains) and maintain strict security protocols while ensuring smooth traffic flow.\n\nThe `SSLTermination` component sits at the network edge, accepting encrypted TLS connections from clients and converting them into plain HTTP connections to backend servers. This design choice centralizes certificate management, reduces computational load on backend servers, and enables the proxy to inspect and route HTTP traffic effectively. However, it also creates a critical security boundary that must be implemented with extreme care to prevent vulnerabilities.\n\n### TLS Context Management\n\nThe foundation of SSL termination lies in proper TLS context management, which involves setting up cryptographic contexts, loading certificates and private keys, and configuring security parameters. Think of a TLS context as a cryptographic blueprint that defines how the proxy will handle encrypted connections - it specifies which certificates to present, which cipher suites to accept, and how to validate client connections.\n\nThe `SSLTermination` component maintains multiple TLS contexts to support different domains and security requirements. Each context represents a complete cryptographic configuration for a specific domain or set of domains. The component must handle context creation during startup, dynamic certificate reloading for renewals, and context selection based on incoming connection characteristics.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| contexts | `HashTable*` | Maps domain names to SSL_CTX structures |\n| default_context | `SSL_CTX*` | Fallback context for unmatched SNI requests |\n| cert_store | `X509_STORE*` | Certificate authority store for validation |\n| cipher_list | `char[1024]` | Configured cipher suite preference string |\n| min_tls_version | `int` | Minimum TLS version (TLS_1_2 or TLS_1_3) |\n| max_tls_version | `int` | Maximum TLS version for compatibility |\n| session_cache | `SSL_SESSION_CACHE*` | Session resumption cache for performance |\n| context_mutex | `pthread_rwlock_t` | Synchronizes context access and updates |\n| cert_reload_thread | `pthread_t` | Background thread monitoring certificate changes |\n| reload_interval | `int` | Certificate file monitoring interval in seconds |\n| running | `bool` | Controls background certificate monitoring |\n\nThe certificate loading process involves several critical security validations. The component must verify that certificate files are readable, private keys match their corresponding certificates, certificate chains are complete and valid, and file permissions restrict access appropriately. Certificate validation extends beyond basic file parsing to include expiration date checking, key usage validation, and certificate chain verification against trusted authorities.\n\n> **Decision: OpenSSL vs BoringSSL vs Custom TLS Implementation**\n> - **Context**: Need TLS implementation for production reverse proxy handling potentially thousands of concurrent connections\n> - **Options Considered**: OpenSSL (mature, feature-complete), BoringSSL (Google's fork focused on security), Custom implementation (full control)\n> - **Decision**: OpenSSL with careful version management and security patches\n> - **Rationale**: OpenSSL provides comprehensive TLS support, extensive documentation, and broad platform compatibility. While BoringSSL offers enhanced security, OpenSSL's maturity and ecosystem support outweigh the benefits for this implementation\n> - **Consequences**: Enables full TLS feature support and easy certificate management but requires staying current with security patches and careful API usage to avoid common pitfalls\n\n| Option | Pros | Cons | Chosen? |\n|--------|------|------|---------|\n| OpenSSL | Comprehensive features, extensive docs, broad compatibility | Large attack surface, complex API, frequent security updates | ✓ Yes |\n| BoringSSL | Enhanced security focus, simplified API, Google backing | Limited documentation, fewer features, potential compatibility issues | No |\n| Custom TLS | Complete control, minimal dependencies, tailored security | Enormous development effort, high risk of security bugs, maintenance burden | No |\n\nThe context initialization process follows a carefully orchestrated sequence to ensure security and reliability:\n\n1. **Library Initialization**: Initialize OpenSSL library components including random number generators, error strings, and algorithm tables\n2. **Context Creation**: Create SSL_CTX structures for each configured domain using appropriate TLS methods (TLS_server_method for modern compatibility)\n3. **Certificate Loading**: Load X.509 certificates from PEM files, validating format and extracting subject information\n4. **Private Key Loading**: Load corresponding private keys, ensuring they match their certificates through cryptographic validation\n5. **Certificate Chain Verification**: Validate complete certificate chains from leaf certificates to trusted root authorities\n6. **Cipher Suite Configuration**: Configure allowed cipher suites prioritizing modern, secure algorithms like AES-GCM and ChaCha20-Poly1305\n7. **Protocol Version Limits**: Set minimum and maximum TLS versions, typically requiring TLS 1.2 or higher for security\n8. **Session Cache Setup**: Configure session resumption cache to improve performance for returning clients\n9. **SNI Callback Registration**: Register Server Name Indication callback for dynamic certificate selection\n10. **Security Parameter Validation**: Verify all security parameters meet organizational security policies\n\nCertificate reloading presents unique challenges in a production environment where the proxy cannot afford downtime. The component implements a sophisticated certificate monitoring system that detects file system changes and performs atomic context updates.\n\n⚠️ **Pitfall: Certificate and Private Key Mismatch**\nLoading certificates and private keys from separate files can result in cryptographic mismatches that only surface during TLS handshakes. The component must verify that each private key corresponds to its certificate by performing a cryptographic validation immediately after loading. Failing to validate this relationship results in TLS handshake failures that are difficult to diagnose in production environments.\n\nThe certificate monitoring system operates through a dedicated background thread that periodically checks certificate file modification times and validates new certificates before performing atomic swaps. This approach ensures that certificate renewals (common with automated systems like Let's Encrypt) don't require proxy restarts or service interruptions.\n\nCertificate storage security requires careful attention to file system permissions and memory management. Private keys must be stored in files readable only by the proxy process user, and private key material in memory should be cleared when contexts are destroyed. The component implements secure memory allocation for key material and ensures that sensitive data doesn't persist in process memory dumps or swap files.\n\n### Server Name Indication\n\nServer Name Indication (SNI) enables a single proxy instance to serve multiple domains with different SSL certificates, much like how a multilingual receptionist can greet visitors in their preferred language. When clients initiate TLS connections, they include the hostname they're trying to reach in the SNI extension, allowing the proxy to select the appropriate certificate for that specific domain.\n\nThe SNI implementation centers around a callback mechanism that executes during the TLS handshake process. When a client sends a TLS ClientHello message containing an SNI extension, OpenSSL invokes the proxy's SNI callback function, providing the requested hostname. The proxy must then locate the appropriate TLS context for that hostname and switch the connection to use the correct certificate and configuration.\n\n![SSL Termination and SNI Processing](./diagrams/ssl-handshake-sequence.svg)\n\nThe SNI selection algorithm handles several complex scenarios including exact hostname matches, wildcard certificate matching, and fallback behavior for unrecognized domains. Wildcard certificates (e.g., *.example.com) require careful pattern matching logic that understands DNS wildcard semantics while maintaining security boundaries.\n\n| Current State | Client Action | Proxy Response | Next State |\n|---------------|---------------|----------------|------------|\n| `TLS_HANDSHAKE_INIT` | ClientHello with SNI | Select appropriate certificate context | `TLS_CONTEXT_SELECTED` |\n| `TLS_CONTEXT_SELECTED` | Continue handshake | Send ServerHello with selected certificate | `TLS_CERTIFICATE_SENT` |\n| `TLS_CERTIFICATE_SENT` | Certificate validation | Process client certificate if required | `TLS_KEY_EXCHANGE` |\n| `TLS_KEY_EXCHANGE` | Key exchange completion | Generate session keys | `TLS_HANDSHAKE_COMPLETE` |\n| `TLS_HANDSHAKE_COMPLETE` | Application data | Decrypt and forward to backend | `TLS_APPLICATION_DATA` |\n\nThe hostname matching logic must handle various edge cases that occur in real-world deployments. International domain names require proper Unicode normalization and IDNA encoding. Case sensitivity variations in hostnames need consistent handling. Port numbers included in Host headers must be stripped when matching against certificate subject names.\n\n> **Decision: Wildcard Certificate Matching Strategy**\n> - **Context**: Need to support wildcard certificates (*.example.com) while maintaining security boundaries and preventing certificate misuse\n> - **Options Considered**: Simple string matching, regex-based matching, DNS-compliant wildcard matching\n> - **Decision**: DNS-compliant wildcard matching following RFC 6125 guidelines\n> - **Rationale**: DNS wildcards have specific semantic rules that must be followed for security. Simple string matching can create security vulnerabilities, while regex matching is overkill and potentially slower\n> - **Consequences**: Enables proper wildcard certificate support with strong security guarantees but requires implementing RFC-compliant matching logic\n\nThe SNI callback implementation requires thread-safe access to the certificate context map since multiple TLS handshakes may occur simultaneously. The component uses read-write locks to allow concurrent access to the context map while serializing updates during certificate reloads.\n\nCertificate selection follows a priority order designed to provide the most specific match for each request:\n\n1. **Exact Hostname Match**: Direct lookup in the context map for the exact requested hostname\n2. **Wildcard Certificate Match**: Check for wildcard certificates that cover the requested domain following DNS wildcard rules\n3. **Subject Alternative Name Match**: Examine SAN extensions in certificates for additional hostname matches\n4. **Default Context Fallback**: Use the default certificate context if no specific match is found\n5. **Connection Termination**: Optionally terminate connections that don't match any configured certificate\n\nThe wildcard matching algorithm implements RFC 6125 semantics, which specify that wildcards only match a single DNS label and cannot span multiple levels. For example, *.example.com matches api.example.com but not sub.api.example.com. This restriction prevents overly broad certificate matching that could create security vulnerabilities.\n\nSNI-based certificate selection enables advanced deployment scenarios such as hosting multiple customer domains on a single proxy instance, gradual certificate migrations, and A/B testing of different TLS configurations. However, it also introduces complexity in certificate management and monitoring since each domain requires separate certificate lifecycle management.\n\n⚠️ **Pitfall: SNI Extension Missing from Client**\nOlder clients or certain automated tools may not include SNI extensions in their TLS handshakes, causing certificate selection to fail or fall back to default certificates. The proxy must handle these cases gracefully by providing a sensible default certificate that can serve the most common domain or by terminating connections with clear error messages that guide clients toward proper SNI support.\n\nCertificate caching and context pooling optimize performance for high-throughput scenarios where thousands of TLS handshakes occur simultaneously. The component maintains a cache of recently used certificate contexts and pre-computes expensive cryptographic operations where possible.\n\n### SSL Termination Decisions\n\nThe SSL termination component faces numerous architectural decisions that significantly impact security, performance, and operational complexity. These decisions involve trade-offs between security posture, computational efficiency, memory usage, and implementation complexity.\n\n> **Decision: TLS Version Support Policy**\n> - **Context**: Need to balance security with client compatibility, considering that older TLS versions have known vulnerabilities while newer versions aren't universally supported\n> - **Options Considered**: TLS 1.0+ (maximum compatibility), TLS 1.2+ (security focused), TLS 1.3 only (cutting edge)\n> - **Decision**: TLS 1.2 minimum with TLS 1.3 preferred\n> - **Rationale**: TLS 1.2 provides strong security while maintaining broad client compatibility. TLS 1.3 offers performance and security improvements where supported. TLS 1.0/1.1 have known vulnerabilities and should be deprecated\n> - **Consequences**: Provides strong security posture while maintaining compatibility with 99%+ of modern clients but may reject very old clients that only support deprecated TLS versions\n\n| TLS Version | Security Level | Client Support | Performance | Chosen? |\n|-------------|----------------|----------------|-------------|---------|\n| TLS 1.0/1.1 | Weak (deprecated) | Universal | Poor | No |\n| TLS 1.2+ | Strong | 99%+ modern clients | Good | ✓ Yes |\n| TLS 1.3 Only | Excellent | 80%+ clients | Excellent | No |\n\nCipher suite selection represents another critical security decision that affects both protection strength and computational performance. Modern cipher suites like AES-GCM and ChaCha20-Poly1305 provide authenticated encryption with excellent performance characteristics, while older suites like RC4 and DES have known vulnerabilities.\n\n> **Decision: Cipher Suite Priority and Selection**\n> - **Context**: Must choose which encryption algorithms to support, considering security strength, performance characteristics, and client compatibility\n> - **Options Considered**: Server preference ordering, client preference ordering, security-only suites\n> - **Decision**: Server preference with modern AEAD cipher priority\n> - **Rationale**: Server preference allows the proxy to enforce security policy while modern AEAD ciphers provide both security and performance. ChaCha20-Poly1305 offers excellent performance on systems without AES-NI hardware acceleration\n> - **Consequences**: Ensures strong encryption with optimal performance but may need periodic updates as cryptographic recommendations evolve\n\nThe preferred cipher suite ordering prioritizes authenticated encryption with associated data (AEAD) ciphers that provide both confidentiality and integrity protection:\n\n1. **TLS_AES_256_GCM_SHA384**: TLS 1.3 with AES-256 in Galois/Counter Mode\n2. **TLS_CHACHA20_POLY1305_SHA256**: TLS 1.3 with ChaCha20-Poly1305 for ARM/mobile optimization\n3. **TLS_AES_128_GCM_SHA256**: TLS 1.3 with AES-128 for performance-sensitive scenarios\n4. **ECDHE-RSA-AES256-GCM-SHA384**: TLS 1.2 with perfect forward secrecy\n5. **ECDHE-RSA-CHACHA20-POLY1305**: TLS 1.2 ChaCha20 variant for non-AES hardware\n\nSession resumption configuration balances security and performance by allowing clients to reuse cryptographic session state across multiple connections. This optimization significantly reduces CPU usage and connection establishment latency, particularly important for mobile clients and high-frequency API access patterns.\n\n> **Decision: Session Resumption and Ticket Rotation**\n> - **Context**: Session resumption improves performance by reusing TLS session state, but session tickets must be rotated regularly for security\n> - **Options Considered**: No session resumption (security focused), session IDs only, session tickets with rotation\n> - **Decision**: Session tickets with automatic rotation every 24 hours\n> - **Rationale**: Session tickets provide better scalability than session IDs while rotation prevents long-term session compromise. 24-hour rotation balances security with operational simplicity\n> - **Consequences**: Achieves optimal TLS performance with good security properties but requires implementing ticket key rotation and handling rotation edge cases\n\nCertificate validation and chain building require sophisticated logic to handle the complexities of real-world PKI deployments. Certificate chains may include intermediate certificates, cross-signed roots, and alternative validation paths. The component must build complete validation chains while respecting certificate policies and constraints.\n\nThe certificate chain validation process involves several security-critical steps:\n\n1. **Certificate Chain Construction**: Build complete chains from leaf certificates to trusted root authorities\n2. **Signature Verification**: Validate cryptographic signatures throughout the certificate chain\n3. **Validity Period Check**: Ensure all certificates are within their valid time ranges\n4. **Revocation Checking**: Optionally check certificate revocation status via CRL or OCSP\n5. **Policy Validation**: Verify certificate policies and key usage constraints\n6. **Hostname Validation**: Confirm certificate subject names match the requested hostname\n\nMemory management for SSL contexts and session data requires careful attention to prevent both memory leaks and security vulnerabilities. TLS session data contains sensitive cryptographic material that must be cleared when sessions end. Context switching during SNI selection must preserve memory isolation between different domains.\n\n⚠️ **Pitfall: Inadequate Certificate Chain Validation**\nMany SSL implementations perform minimal certificate validation, checking only basic cryptographic signatures while ignoring critical security constraints like key usage, certificate policies, and validity periods. Production reverse proxies must implement comprehensive validation that matches browser security standards to prevent accepting compromised or misused certificates.\n\nPerformance optimization in SSL termination focuses on reducing per-connection computational overhead while maintaining security properties. Hardware acceleration through AES-NI instructions, optimized cipher suite selection, and connection pooling all contribute to scalable TLS performance.\n\nThe SSL termination component integrates with the broader proxy architecture through well-defined interfaces that isolate TLS complexity from other components. Once TLS connections are established and decrypted, they appear as standard HTTP connections to the HTTP parser and connection manager components.\n\nError handling in SSL termination must distinguish between client errors (invalid certificates, unsupported protocols), server configuration errors (missing certificates, expired keys), and network errors (connection timeouts, malformed packets). Each error category requires different logging levels and recovery strategies.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Private Key Exposure in Memory Dumps**\nPrivate key material loaded into process memory can be exposed through core dumps, swap files, or memory debugging tools. The SSL termination component must use secure memory allocation functions (like `mlock()`) to prevent key material from being written to disk and explicitly clear memory regions containing sensitive data when contexts are destroyed.\n\n⚠️ **Pitfall: Certificate Expiration Without Monitoring**\nProduction deployments frequently experience outages due to expired certificates that weren't renewed in time. The component should implement certificate expiration monitoring that logs warnings well before certificates expire and optionally exposes metrics for external monitoring systems to alert on approaching expiration dates.\n\n⚠️ **Pitfall: Weak Cipher Suite Configuration**\nDefault OpenSSL cipher configurations may include weak or deprecated algorithms for compatibility reasons. Production deployments must explicitly configure cipher suite preferences to exclude vulnerable algorithms like RC4, DES, and export-grade ciphers while prioritizing modern AEAD ciphers.\n\n⚠️ **Pitfall: Improper SNI Fallback Handling**\nWhen clients don't provide SNI extensions or request unrecognized hostnames, the proxy must handle these cases gracefully. Falling back to a default certificate that doesn't match the requested hostname can cause certificate validation errors in clients, while terminating connections may impact legitimate traffic.\n\n⚠️ **Pitfall: Certificate Reload Race Conditions**\nDynamic certificate reloading during production traffic can create race conditions where some connections use old certificates while others use new ones. The component must implement atomic context switching that ensures all new connections use updated certificates while allowing existing connections to complete with their original contexts.\n\n### Implementation Guidance\n\nThe SSL termination component requires careful integration with OpenSSL and precise handling of cryptographic material. The implementation balances security requirements with performance needs while maintaining operational simplicity.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| TLS Library | OpenSSL 1.1.1+ with basic configuration | OpenSSL 3.0+ with provider architecture |\n| Certificate Storage | File-based PEM certificates | Hardware Security Module (HSM) integration |\n| Session Management | In-memory session cache | Distributed session store with Redis |\n| Certificate Monitoring | Filesystem polling with inotify | Certificate transparency log monitoring |\n| Performance Optimization | Basic cipher suite selection | Hardware acceleration with AES-NI and AVX |\n\n#### Recommended File Structure\n\n```\nproxy/\n  src/\n    ssl/\n      ssl_termination.h        ← SSL component interface\n      ssl_termination.c        ← Core SSL termination logic\n      ssl_context.h           ← TLS context management\n      ssl_context.c           ← Context creation and certificate loading\n      ssl_sni.h              ← SNI handling interface\n      ssl_sni.c              ← SNI callback and hostname matching\n      ssl_session.h          ← Session resumption management\n      ssl_session.c          ← Session cache and ticket rotation\n      ssl_utils.h            ← SSL utility functions\n      ssl_utils.c            ← Certificate validation and crypto helpers\n      ssl_config.h           ← SSL configuration structures\n      ssl_config.c           ← Configuration parsing and validation\n    tests/\n      test_ssl_termination.c  ← SSL termination tests\n      test_ssl_context.c      ← Context management tests\n      test_ssl_sni.c         ← SNI handling tests\n      ssl_test_certs/        ← Test certificates and keys\n        test_server.crt\n        test_server.key\n        test_ca.crt\n        wildcard_test.crt\n        wildcard_test.key\n```\n\n#### Infrastructure Starter Code\n\n```c\n// ssl_utils.h - SSL utility functions\n#ifndef SSL_UTILS_H\n#define SSL_UTILS_H\n\n#include <openssl/ssl.h>\n#include <openssl/x509.h>\n#include <openssl/x509v3.h>\n#include <openssl/err.h>\n#include <openssl/pem.h>\n#include <time.h>\n#include <stdbool.h>\n\n// Certificate validation result structure\ntypedef struct {\n    bool valid;\n    char error_message[256];\n    time_t expires_at;\n    char subject_name[256];\n    char issuer_name[256];\n    char **san_entries;\n    size_t san_count;\n} CertificateInfo;\n\n// Initialize OpenSSL library\nbool ssl_utils_init(void);\n\n// Clean up OpenSSL library\nvoid ssl_utils_cleanup(void);\n\n// Load certificate from PEM file with validation\nX509* ssl_utils_load_certificate(const char* cert_path, CertificateInfo* info);\n\n// Load private key from PEM file\nEVP_PKEY* ssl_utils_load_private_key(const char* key_path);\n\n// Verify that private key matches certificate\nbool ssl_utils_verify_key_cert_match(EVP_PKEY* key, X509* cert);\n\n// Extract hostname from certificate (CN or SAN)\nbool ssl_utils_extract_hostnames(X509* cert, char*** hostnames, size_t* count);\n\n// Check if hostname matches certificate (with wildcard support)\nbool ssl_utils_hostname_matches_cert(const char* hostname, X509* cert);\n\n// Get certificate expiration time\ntime_t ssl_utils_get_cert_expiration(X509* cert);\n\n// Check if certificate is expired or expiring soon\nbool ssl_utils_cert_expires_soon(X509* cert, int days_threshold);\n\n// Build complete certificate chain\nSTACK_OF(X509)* ssl_utils_build_cert_chain(X509* cert, const char* chain_path);\n\n// Configure secure cipher suites\nbool ssl_utils_set_secure_ciphers(SSL_CTX* ctx);\n\n// Set up TLS version restrictions\nbool ssl_utils_set_tls_versions(SSL_CTX* ctx, int min_version, int max_version);\n\n// Free certificate info structure\nvoid ssl_utils_free_cert_info(CertificateInfo* info);\n\n#endif // SSL_UTILS_H\n```\n\n```c\n// ssl_utils.c - Complete SSL utility implementation\n#include \"ssl_utils.h\"\n#include <string.h>\n#include <stdlib.h>\n#include <stdio.h>\n\nstatic bool ssl_initialized = false;\n\nbool ssl_utils_init(void) {\n    if (ssl_initialized) {\n        return true;\n    }\n    \n    SSL_load_error_strings();\n    SSL_library_init();\n    OpenSSL_add_all_algorithms();\n    \n    ssl_initialized = true;\n    return true;\n}\n\nvoid ssl_utils_cleanup(void) {\n    if (!ssl_initialized) {\n        return;\n    }\n    \n    EVP_cleanup();\n    ERR_free_strings();\n    ssl_initialized = false;\n}\n\nX509* ssl_utils_load_certificate(const char* cert_path, CertificateInfo* info) {\n    FILE* cert_file = fopen(cert_path, \"r\");\n    if (!cert_file) {\n        if (info) {\n            snprintf(info->error_message, sizeof(info->error_message), \n                    \"Cannot open certificate file: %s\", cert_path);\n            info->valid = false;\n        }\n        return NULL;\n    }\n    \n    X509* cert = PEM_read_X509(cert_file, NULL, NULL, NULL);\n    fclose(cert_file);\n    \n    if (!cert) {\n        if (info) {\n            snprintf(info->error_message, sizeof(info->error_message), \n                    \"Cannot parse certificate file: %s\", cert_path);\n            info->valid = false;\n        }\n        return NULL;\n    }\n    \n    if (info) {\n        info->valid = true;\n        info->expires_at = ssl_utils_get_cert_expiration(cert);\n        \n        // Extract subject name\n        X509_NAME* subject = X509_get_subject_name(cert);\n        X509_NAME_oneline(subject, info->subject_name, sizeof(info->subject_name));\n        \n        // Extract issuer name\n        X509_NAME* issuer = X509_get_issuer_name(cert);\n        X509_NAME_oneline(issuer, info->issuer_name, sizeof(info->issuer_name));\n        \n        // Extract SAN entries\n        ssl_utils_extract_hostnames(cert, &info->san_entries, &info->san_count);\n    }\n    \n    return cert;\n}\n\nEVP_PKEY* ssl_utils_load_private_key(const char* key_path) {\n    FILE* key_file = fopen(key_path, \"r\");\n    if (!key_file) {\n        return NULL;\n    }\n    \n    EVP_PKEY* key = PEM_read_PrivateKey(key_file, NULL, NULL, NULL);\n    fclose(key_file);\n    \n    return key;\n}\n\nbool ssl_utils_verify_key_cert_match(EVP_PKEY* key, X509* cert) {\n    if (!key || !cert) {\n        return false;\n    }\n    \n    EVP_PKEY* cert_key = X509_get_pubkey(cert);\n    if (!cert_key) {\n        return false;\n    }\n    \n    int result = EVP_PKEY_cmp(key, cert_key);\n    EVP_PKEY_free(cert_key);\n    \n    return result == 1;\n}\n\nbool ssl_utils_extract_hostnames(X509* cert, char*** hostnames, size_t* count) {\n    STACK_OF(GENERAL_NAME)* san_names = NULL;\n    san_names = X509_get_ext_d2i(cert, NID_subject_alt_name, NULL, NULL);\n    \n    if (!san_names) {\n        *hostnames = NULL;\n        *count = 0;\n        return true; // Not an error, just no SAN extension\n    }\n    \n    int san_count = sk_GENERAL_NAME_num(san_names);\n    *hostnames = malloc(san_count * sizeof(char*));\n    *count = 0;\n    \n    for (int i = 0; i < san_count; i++) {\n        GENERAL_NAME* name = sk_GENERAL_NAME_value(san_names, i);\n        if (name->type == GEN_DNS) {\n            char* hostname = (char*)ASN1_STRING_get0_data(name->d.dNSName);\n            (*hostnames)[*count] = strdup(hostname);\n            (*count)++;\n        }\n    }\n    \n    sk_GENERAL_NAME_pop_free(san_names, GENERAL_NAME_free);\n    return true;\n}\n\ntime_t ssl_utils_get_cert_expiration(X509* cert) {\n    ASN1_TIME* not_after = X509_get_notAfter(cert);\n    struct tm tm;\n    \n    if (!ASN1_TIME_to_tm(not_after, &tm)) {\n        return 0;\n    }\n    \n    return mktime(&tm);\n}\n\nbool ssl_utils_set_secure_ciphers(SSL_CTX* ctx) {\n    const char* cipher_list = \n        \"ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS\";\n    \n    return SSL_CTX_set_cipher_list(ctx, cipher_list) == 1;\n}\n\nbool ssl_utils_set_tls_versions(SSL_CTX* ctx, int min_version, int max_version) {\n    if (SSL_CTX_set_min_proto_version(ctx, min_version) != 1) {\n        return false;\n    }\n    \n    if (SSL_CTX_set_max_proto_version(ctx, max_version) != 1) {\n        return false;\n    }\n    \n    return true;\n}\n```\n\n#### Core Logic Skeleton Code\n\n```c\n// ssl_termination.h - SSL Termination component interface\n#ifndef SSL_TERMINATION_H\n#define SSL_TERMINATION_H\n\n#include \"ssl_utils.h\"\n#include \"../config.h\"\n#include \"../hashtable.h\"\n#include <pthread.h>\n\ntypedef struct {\n    HashTable* contexts;           // Maps domain names to SSL_CTX*\n    SSL_CTX* default_context;     // Fallback context\n    char cipher_list[1024];       // Configured cipher suites\n    int min_tls_version;          // Minimum TLS version\n    int max_tls_version;          // Maximum TLS version\n    pthread_rwlock_t context_mutex; // Protects context map\n    pthread_t cert_reload_thread; // Certificate monitoring thread\n    int reload_interval;          // Reload check interval\n    bool running;                 // Component running state\n} SSLTermination;\n\n// Create and initialize SSL termination component\nSSLTermination* ssl_termination_create(ProxyConfig* config);\n\n// Start SSL termination component (starts background threads)\nbool ssl_termination_start(SSLTermination* ssl_term);\n\n// Stop SSL termination component and cleanup resources\nvoid ssl_termination_stop(SSLTermination* ssl_term);\n\n// Destroy SSL termination component\nvoid ssl_termination_destroy(SSLTermination* ssl_term);\n\n// Create SSL connection wrapper for client socket\nSSL* ssl_termination_accept_connection(SSLTermination* ssl_term, int client_fd);\n\n// SNI callback for certificate selection\nint ssl_termination_sni_callback(SSL* ssl, int* ad, void* arg);\n\n// Reload certificates from disk (for certificate renewal)\nbool ssl_termination_reload_certificates(SSLTermination* ssl_term);\n\n#endif // SSL_TERMINATION_H\n```\n\n```c\n// ssl_termination.c - Core SSL termination logic\n#include \"ssl_termination.h\"\n#include \"../logger.h\"\n#include <unistd.h>\n#include <sys/stat.h>\n\nSSLTermination* ssl_termination_create(ProxyConfig* config) {\n    // TODO 1: Allocate SSLTermination structure and initialize fields\n    // TODO 2: Initialize OpenSSL library using ssl_utils_init()\n    // TODO 3: Create hash table for certificate contexts\n    // TODO 4: Initialize read-write lock for thread-safe context access\n    // TODO 5: Load and validate all configured certificates and private keys\n    // TODO 6: Create SSL_CTX for each certificate domain\n    // TODO 7: Configure cipher suites and TLS versions for each context\n    // TODO 8: Set up default context for unmatched SNI requests\n    // TODO 9: Register SNI callback for dynamic certificate selection\n    // TODO 10: Validate that all contexts are properly configured\n    // Hint: Use config->ssl_cert_path and config->ssl_key_path for certificate loading\n    // Hint: Call ssl_utils_verify_key_cert_match() to ensure key/cert pairs match\n}\n\nbool ssl_termination_start(SSLTermination* ssl_term) {\n    // TODO 1: Set running flag to true\n    // TODO 2: Create certificate reload monitoring thread\n    // TODO 3: Start background thread with cert_reload_monitor function\n    // TODO 4: Return true if all threads started successfully\n    // Hint: Use pthread_create() to start the certificate monitoring thread\n}\n\nSSL* ssl_termination_accept_connection(SSLTermination* ssl_term, int client_fd) {\n    // TODO 1: Create new SSL connection using default context\n    // TODO 2: Set file descriptor for SSL connection\n    // TODO 3: Configure SSL connection for server mode\n    // TODO 4: Set SNI callback data to point to ssl_term\n    // TODO 5: Perform SSL handshake with client\n    // TODO 6: Handle handshake errors gracefully\n    // TODO 7: Return established SSL connection or NULL on failure\n    // Hint: Use SSL_new(), SSL_set_fd(), SSL_set_accept_state(), SSL_accept()\n    // Hint: Check SSL_get_error() for detailed error information on failure\n}\n\nint ssl_termination_sni_callback(SSL* ssl, int* ad, void* arg) {\n    // TODO 1: Cast arg back to SSLTermination pointer\n    // TODO 2: Get requested hostname from SSL connection using SSL_get_servername()\n    // TODO 3: Acquire read lock on context mutex for thread safety\n    // TODO 4: Look up SSL_CTX for requested hostname in contexts hash table\n    // TODO 5: If exact match found, set SSL context using SSL_set_SSL_CTX()\n    // TODO 6: If no exact match, try wildcard certificate matching\n    // TODO 7: If still no match, use default context (already set)\n    // TODO 8: Release read lock on context mutex\n    // TODO 9: Return SSL_TLSEXT_ERR_OK on success or SSL_TLSEXT_ERR_ALERT_FATAL on error\n    // Hint: Use hashtable_get() to look up contexts by hostname\n    // Hint: Implement wildcard matching following DNS wildcard rules (*.domain.com)\n}\n\nbool ssl_termination_reload_certificates(SSLTermination* ssl_term) {\n    // TODO 1: Acquire write lock on context mutex to prevent concurrent access\n    // TODO 2: Iterate through all certificate files checking modification times\n    // TODO 3: For each modified certificate, load and validate new certificate\n    // TODO 4: Create new SSL_CTX with updated certificate and key\n    // TODO 5: Replace old context in hash table with new context atomically\n    // TODO 6: Free old SSL_CTX after replacement to prevent memory leaks\n    // TODO 7: Log certificate reload events for operational visibility\n    // TODO 8: Release write lock on context mutex\n    // TODO 9: Return true if all reloads successful, false if any failed\n    // Hint: Use stat() to check file modification times\n    // Hint: Keep track of last reload time to avoid unnecessary work\n}\n```\n\n#### Milestone Checkpoint\n\nAfter implementing SSL termination, verify functionality with these steps:\n\n**Basic SSL Connection Test:**\n```bash\n# Test HTTPS connection with self-signed certificate\nopenssl s_client -connect localhost:8443 -servername test.example.com\n# Should show certificate details and establish connection\n```\n\n**SNI Functionality Test:**\n```bash\n# Test different hostnames resolve to different certificates\nopenssl s_client -connect localhost:8443 -servername api.example.com\nopenssl s_client -connect localhost:8443 -servername web.example.com\n# Should show different certificate subjects for different hostnames\n```\n\n**Expected Behavior:**\n- HTTPS connections establish successfully with proper certificate presentation\n- SNI selects appropriate certificates based on requested hostname\n- Proxy decrypts HTTPS traffic and forwards plain HTTP to backends\n- Certificate reload works without restarting the proxy process\n- Logs show SSL handshake success/failure events with clear error messages\n\n**Signs of Problems:**\n- \"SSL handshake failed\" errors indicate certificate or configuration issues\n- \"Certificate verification failed\" suggests certificate chain problems\n- \"SNI callback failed\" indicates hostname matching logic errors\n- Memory leaks during certificate reloading suggest cleanup issues\n\n\n## Interactions and Data Flow\n\n> **Milestone(s):** All milestones - understanding component interactions is essential for HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).\n\nThink of a reverse proxy as a sophisticated air traffic control system. Just as air traffic controllers coordinate multiple aircraft, runways, and weather services to safely guide planes from departure to destination, a reverse proxy orchestrates multiple components - HTTP parsers, connection managers, load balancers, cache engines, and SSL terminators - to guide client requests through a complex journey to backend servers and back. Each component has specialized responsibilities, but they must communicate seamlessly to deliver a cohesive service. The air traffic analogy helps us understand that timing, coordination, and clear communication protocols between components are absolutely critical for system reliability and performance.\n\nThe interaction patterns between reverse proxy components follow well-defined protocols, much like how air traffic control uses standardized communication procedures. Each component exposes specific interfaces, maintains its own internal state, and participates in the larger request processing workflow. Understanding these interactions is crucial because the reverse proxy's performance, reliability, and correctness depend entirely on how effectively these components collaborate.\n\n![System Component Architecture](./diagrams/system-components.svg)\n\n### Request Processing Flow\n\nThe request processing flow represents the complete journey of an HTTP request from client arrival to response delivery, traversing through multiple components in a carefully orchestrated sequence. Think of this flow as a factory assembly line where each station (component) performs specialized operations on the product (HTTP request) before passing it to the next station. However, unlike a simple linear assembly line, the reverse proxy flow includes decision points, parallel processing paths, and feedback loops that make it more sophisticated.\n\n![Request Processing Sequence](./diagrams/request-flow-sequence.svg)\n\nThe request processing begins when a client establishes a connection to the reverse proxy's listening socket. This initial connection may be either a plain HTTP connection or an HTTPS connection requiring SSL termination. The distinction is crucial because it determines which component handles the initial connection establishment and how the request data flows through the system.\n\n#### Phase 1: Connection Establishment and Initial Processing\n\n**Step 1: Client Connection Arrival**\n\nWhen a client attempts to connect, the reverse proxy's main event loop detects the incoming connection on the listening socket. The proxy examines the destination port to determine whether this is an HTTP connection (typically port 80) or an HTTPS connection (typically port 443). This determination affects the entire subsequent processing pipeline because HTTPS connections require SSL termination before HTTP parsing can begin.\n\nFor HTTP connections, the `ConnectionManager` directly accepts the client socket using `connection_manager_accept_client()`, creating a new `Connection` structure initialized in the `CONNECTION_IDLE` state. The connection includes buffers for request and response data, timing information, and state tracking fields that guide subsequent processing decisions.\n\nFor HTTPS connections, the `SSLTermination` component first accepts the connection using `ssl_termination_accept_connection()`, which performs the TLS handshake. During this handshake, the SSL termination component examines the Server Name Indication (SNI) extension to select the appropriate SSL certificate for the requested hostname. The `ssl_termination_sni_callback()` function handles this certificate selection by looking up the hostname in the SSL context hash table and returning the corresponding SSL context.\n\n**Step 2: SSL Termination Processing (HTTPS only)**\n\nFor HTTPS connections, the SSL termination process involves several critical steps that must complete successfully before HTTP parsing can begin. The TLS handshake includes cipher suite negotiation, where the client and server agree on encryption algorithms. The `SSLTermination` component enforces minimum TLS versions and secure cipher suites to maintain security standards.\n\nOnce the TLS handshake completes successfully, the SSL termination component creates an encrypted channel with the client. All subsequent data from the client arrives encrypted and must be decrypted using the established SSL context before passing to other components. The SSL termination component maintains the mapping between client file descriptors and their corresponding SSL contexts, enabling efficient decryption of incoming data.\n\nThe decrypted HTTP data is then passed to the `ConnectionManager` for further processing, effectively converting the HTTPS connection into an internal HTTP data stream that the rest of the proxy can handle uniformly.\n\n**Step 3: HTTP Request Parsing**\n\nOnce the connection is established (and decrypted if necessary), the `ConnectionManager` transitions the connection to the `CONNECTION_READING_REQUEST` state and begins accumulating HTTP request data. As data arrives on the client socket, the connection manager appends it to the connection's request buffer using `buffer_append()`.\n\nThe HTTP parsing process is stream-based, meaning it processes data incrementally as it arrives rather than waiting for the complete request. The `HttpParser` component uses a state machine approach with states defined in the `HttpParserState` enumeration. The parser begins in the `HTTP_PARSING_REQUEST_LINE` state and processes the incoming data byte by byte.\n\nThe `http_parser_process()` function examines each byte and makes state transitions based on the current parser state and the incoming character. For example, when parsing the request line, the parser accumulates characters until it encounters a space character, indicating the end of the HTTP method. It then transitions to parsing the URI, accumulates characters until the next space, and continues until it completes the request line with a CRLF sequence.\n\nHeader parsing follows a similar pattern, where the parser accumulates header name and value pairs until it encounters the empty line that separates headers from the message body. The parser handles various HTTP complexities including case-insensitive header names, multi-line header values, and proper handling of the `Content-Length` and `Transfer-Encoding` headers that determine body parsing strategy.\n\n**Step 4: Request Validation and Preprocessing**\n\nAfter successful HTTP parsing, the `ConnectionManager` performs request validation to ensure the parsed request meets basic correctness requirements. This validation includes verifying that required headers are present, checking URI format validity, and ensuring HTTP version compatibility.\n\nThe connection manager also performs request preprocessing by adding standard reverse proxy headers. The `X-Forwarded-For` header is added with the client's IP address, allowing backend servers to identify the original client. The `Via` header is added to indicate that the request passed through the reverse proxy, following HTTP specification requirements for proxy identification.\n\nDuring preprocessing, the connection manager examines the `Connection` header to determine if the client requested keep-alive behavior. This information is stored in the connection's `keep_alive` field and influences connection lifecycle management decisions later in the processing flow.\n\n#### Phase 2: Cache Lookup and Backend Selection\n\n**Step 5: Cache Engine Consultation**\n\nBefore forwarding the request to backend servers, the reverse proxy consults the `CacheEngine` to determine if a cached response can satisfy the request. The cache engine performs this lookup using `cache_engine_lookup()`, which generates a cache key based on the request characteristics.\n\nThe cache key generation process considers multiple request attributes including the HTTP method, complete URI (including query parameters), and specific headers that affect response content. The `Vary` header from previously cached responses influences which request headers are included in the cache key calculation, ensuring that responses cached for different client capabilities are served appropriately.\n\nIf a cache entry is found, the cache engine validates its freshness using `cache_is_fresh()`. This validation examines the entry's expiration time, calculated from `Cache-Control` directives like `max-age` and response headers like `Expires`. Fresh cache entries can be served immediately, bypassing backend server communication entirely.\n\nFor stale cache entries, the cache engine can generate conditional requests using `cache_create_conditional()`. These conditional requests include `If-None-Match` headers with the cached response's ETag or `If-Modified-Since` headers with the cached response's last modification time. Conditional requests allow backend servers to respond with `304 Not Modified` if the content hasn't changed, saving bandwidth and processing time.\n\n**Step 6: Load Balancer Backend Selection**\n\nWhen a cache miss occurs or the request cannot be satisfied from cache, the `LoadBalancer` component selects an appropriate backend server using `loadbalancer_select_backend()`. The selection process depends on the configured load balancing algorithm and the current health status of backend servers.\n\nThe load balancer first filters the backend server list to exclude servers marked as unhealthy by the health checking system. Unhealthy servers are identified by failed health check attempts or recent request failures that exceed the configured failure threshold.\n\nFor healthy servers, the selection algorithm depends on the configured `LoadBalancingAlgorithm`. Round-robin selection uses the `rr_current_index` field to track the next server in rotation, incrementing atomically after each selection to ensure thread-safe operation across concurrent requests. Least-connections selection examines the `connection_counts` array to identify the backend server with the minimum number of active connections.\n\nWeighted round-robin selection is more complex, using the `current_weights` array to implement the weighted round-robin algorithm. Each server's current weight is incremented by its static weight on each selection, and the server with the highest current weight is chosen. The selected server's current weight is then decremented by the sum of all server weights, ensuring that servers with higher weights are selected proportionally more often over time.\n\nThe IP hash algorithm provides session affinity by computing a hash of the client's IP address and using this hash to consistently select the same backend server for requests from the same client. This approach ensures that clients with session state requirements are always directed to the same backend server.\n\n#### Phase 3: Backend Communication and Connection Management\n\n**Step 7: Backend Connection Acquisition**\n\nAfter backend server selection, the `ConnectionManager` acquires a connection to the selected backend using `connection_manager_acquire_backend()`. This function implements connection pooling by first checking if any idle connections to the target backend server exist in the connection pool.\n\nConnection pools are maintained per backend server in the `backend_pools` array, with each `ConnectionPool` structure tracking idle and active connections. The pool uses a LIFO (Last-In, First-Out) strategy for connection reuse, which provides better cache locality because recently used connections are more likely to have warm CPU caches and established network paths.\n\nWhen reusing a pooled connection, the connection manager validates the connection's health by checking if the socket is still readable without data available (indicating a connection reset) and verifying that the connection hasn't exceeded its maximum idle time. Invalid connections are discarded and replaced with new connections.\n\nIf no suitable pooled connections exist, the connection manager creates a new connection to the backend server. This involves establishing a TCP socket, setting appropriate socket options like `TCP_NODELAY` to minimize latency, and configuring non-blocking I/O mode for integration with the event-driven architecture.\n\n**Step 8: Request Forwarding**\n\nWith a backend connection acquired, the connection manager forwards the HTTP request to the backend server. The forwarding process involves serializing the parsed HTTP request back into the standard HTTP wire format, but with modifications appropriate for backend communication.\n\nThe forwarded request includes the modified headers added during preprocessing, ensuring that backend servers receive client identification information. The connection manager may modify or remove certain headers that are only relevant for client-proxy communication, such as `Proxy-Authorization` headers.\n\nRequest forwarding handles various HTTP complexities including chunked transfer encoding and request bodies. For requests with `Content-Length` headers, the connection manager ensures that the specified number of bytes are forwarded to the backend. For chunked requests, the proxy forwards the chunk headers and data while tracking the chunking state to detect the end of the request body.\n\nDuring forwarding, the connection transitions to the `CONNECTION_FORWARDING` state, and the connection manager configures epoll events to monitor both the client connection for additional request data and the backend connection for response data.\n\n**Step 9: Response Processing and Parsing**\n\nWhen the backend server begins sending response data, the connection manager transitions to the `CONNECTION_READING_RESPONSE` state and begins accumulating response data in the connection's response buffer. Response parsing follows a similar pattern to request parsing, using the HTTP parser component to incrementally process the response data.\n\nThe HTTP response parser extracts the status line, response headers, and message body. Special attention is paid to caching-related headers including `Cache-Control`, `Expires`, `ETag`, `Last-Modified`, and `Vary`. These headers determine whether the response can be cached and how long it remains valid.\n\nResponse parsing also handles various HTTP response formats including chunked transfer encoding and keep-alive connection management. The parser tracks the response completeness to determine when the entire response has been received from the backend server.\n\n#### Phase 4: Response Caching and Client Delivery\n\n**Step 10: Cache Storage Decision**\n\nAfter receiving the complete response from the backend server, the `CacheEngine` evaluates whether the response should be cached using `cache_is_cacheable()`. This evaluation examines the response status code, HTTP method, and cache-control directives to determine cacheability.\n\nCacheable responses are typically successful GET requests (status 200) with explicit caching directives or responses without explicit no-cache directives. The cache engine respects `Cache-Control: no-store` directives by never storing such responses, and handles `Cache-Control: private` directives by considering the proxy's role as a shared cache.\n\nFor cacheable responses, the cache engine calculates the expiration time using `cache_control_calculate_expiry()`, which considers `max-age` directives, `Expires` headers, and heuristic expiration calculations for responses without explicit expiration information.\n\nThe cache storage process using `cache_engine_store()` involves generating the same cache key used during lookup, creating a `CacheEntry` structure with the response data and metadata, and inserting the entry into both the hash table for fast lookup and the LRU list for eviction management.\n\n**Step 11: Response Delivery to Client**\n\nThe final phase involves delivering the response to the client through the appropriate channel. For HTTP connections, the connection manager writes the response data directly to the client socket. For HTTPS connections, the response data must first pass through SSL encryption using the established SSL context.\n\nResponse delivery handles various client capabilities including HTTP version differences and connection management preferences. The proxy respects the client's `Connection` header preferences, maintaining keep-alive connections when requested and possible, or closing connections when appropriate.\n\nDuring response delivery, the connection transitions to the `CONNECTION_WRITING_RESPONSE` state and configures epoll events to monitor the client socket for write readiness. The delivery process handles partial writes and flow control, ensuring that response data is delivered reliably even when client connections have limited receive buffers.\n\n**Step 12: Connection Cleanup and Recycling**\n\nAfter completing response delivery, the connection manager performs cleanup and recycling operations. Backend connections are returned to the connection pool using `connection_manager_release_backend()` if they remain healthy and the pool has capacity. This recycling process updates connection statistics and resets connection state for future reuse.\n\nClient connections are either maintained for additional requests (HTTP keep-alive) or closed based on the HTTP version, client preferences, and error conditions. Keep-alive connections transition back to the `CONNECTION_IDLE` state and remain registered for read events to detect additional incoming requests.\n\nThe connection manager also updates various statistics including request counts, response times, and error rates. These statistics support monitoring, debugging, and performance optimization activities.\n\n### Inter-Component Communication\n\nThe inter-component communication patterns define how the reverse proxy's components exchange information, coordinate activities, and maintain consistency across the distributed system architecture. Think of inter-component communication as the nervous system of the reverse proxy, carrying control signals, data messages, and status updates between specialized organs (components) that must work together to maintain the system's health and functionality.\n\nUnderstanding these communication patterns is essential because they determine system performance characteristics, reliability behaviors, and debugging approaches. The communication patterns also define the system's scalability limits and guide optimization strategies for high-performance deployments.\n\n#### Communication Architecture and Patterns\n\nThe reverse proxy uses an event-driven communication architecture where components interact through well-defined interfaces rather than direct memory sharing or global variables. This architecture provides isolation between components, enabling independent testing, debugging, and optimization of each component while maintaining clear contracts for inter-component collaboration.\n\n**Message-Based Communication**\n\nComponents communicate primarily through structured messages passed via function calls rather than shared memory regions. This approach provides type safety, clear ownership semantics, and explicit error handling paths that improve system reliability and maintainability.\n\n| Message Type | Source Component | Target Component | Purpose | Data Included |\n|--------------|------------------|------------------|---------|---------------|\n| HTTP Request | Connection Manager | HTTP Parser | Request parsing initiation | Raw HTTP data buffer |\n| Parsed Request | HTTP Parser | Connection Manager | Parsing completion notification | HttpRequest structure |\n| Backend Selection | Connection Manager | Load Balancer | Backend server selection | HttpRequest, client info |\n| Selected Backend | Load Balancer | Connection Manager | Backend selection result | BackendServer pointer |\n| Cache Lookup | Connection Manager | Cache Engine | Cache hit evaluation | HttpRequest, cache key |\n| Cache Entry | Cache Engine | Connection Manager | Cache lookup result | CacheEntry or null |\n| SSL Handshake | Connection Manager | SSL Termination | TLS connection establishment | Client socket, SNI hostname |\n| Decrypted Data | SSL Termination | Connection Manager | Decrypted HTTP data | Buffer with plain HTTP |\n\n**Event-Driven Coordination**\n\nThe communication architecture uses event-driven coordination where components register for specific events and respond asynchronously when those events occur. The `ConnectionManager` serves as the central event coordinator, using epoll-based event monitoring to detect socket events and coordinating responses across multiple components.\n\nEvent-driven coordination enables high concurrency because components don't block waiting for responses from other components. Instead, components initiate operations and continue processing other tasks while waiting for asynchronous completion notifications.\n\n#### Component Interface Specifications\n\nEach component exposes well-defined interfaces that specify exactly how other components can interact with it. These interfaces include function signatures, parameter requirements, return value semantics, and error handling behaviors.\n\n**Connection Manager Interfaces**\n\nThe `ConnectionManager` provides the primary coordination interfaces used by other components to participate in request processing workflows.\n\n| Interface Method | Parameters | Return Value | Description | Error Conditions |\n|------------------|------------|--------------|-------------|------------------|\n| `connection_manager_accept_client` | `ConnectionManager*`, `int client_fd` | `Connection*` | Accept new client connection and initialize state | Returns NULL on memory allocation failure |\n| `connection_manager_acquire_backend` | `ConnectionManager*`, `BackendServer*`, `int timeout_ms` | `Connection*` | Acquire backend connection from pool or create new | Returns NULL on connection failure or timeout |\n| `connection_manager_release_backend` | `ConnectionManager*`, `Connection*`, `bool keep_alive` | `void` | Return backend connection to pool or close | No error return - best effort cleanup |\n| `connection_manager_handle_event` | `ConnectionManager*`, `Connection*`, `uint32_t events` | `void` | Process connection state transition events | Logs errors but continues processing |\n| `connection_manager_close_connection` | `ConnectionManager*`, `Connection*` | `void` | Clean up connection and release resources | No error return - best effort cleanup |\n\n**HTTP Parser Interfaces**\n\nThe `HttpParser` component provides stream-based parsing interfaces that support incremental processing of HTTP data as it arrives from network connections.\n\n| Interface Method | Parameters | Return Value | Description | Error Conditions |\n|------------------|------------|--------------|-------------|------------------|\n| `http_parser_create` | `void` | `HttpParser*` | Initialize new parser instance | Returns NULL on memory allocation failure |\n| `http_parser_process` | `HttpParser*`, `char* data`, `size_t length` | `int` | Process incoming HTTP data incrementally | Returns negative on parsing errors |\n| `http_request_create` | `void` | `HttpRequest*` | Create empty HTTP request structure | Returns NULL on memory allocation failure |\n| `http_request_add_header` | `HttpRequest*`, `char* name`, `char* value` | `bool` | Add header to request structure | Returns false on memory allocation failure |\n| `http_request_get_header` | `HttpRequest*`, `char* name` | `char*` | Retrieve header value by name | Returns NULL if header not found |\n\n**Load Balancer Interfaces**\n\nThe `LoadBalancer` component provides backend selection interfaces that implement various distribution algorithms and health checking logic.\n\n| Interface Method | Parameters | Return Value | Description | Error Conditions |\n|------------------|------------|--------------|-------------|------------------|\n| `loadbalancer_select_backend` | `LoadBalancer*`, `HttpRequest*` | `BackendServer*` | Select backend using configured algorithm | Returns NULL if no healthy backends available |\n| `loadbalancer_update_connection_count` | `LoadBalancer*`, `BackendServer*`, `int delta` | `void` | Update active connection count for backend | No error return - uses atomic operations |\n| `select_backend_round_robin` | `LoadBalancer*` | `BackendServer*` | Round-robin backend selection implementation | Returns NULL if no healthy backends |\n| `select_backend_least_connections` | `LoadBalancer*` | `BackendServer*` | Least-connections selection implementation | Returns NULL if no healthy backends |\n| `health_check_backend` | `LoadBalancer*`, `BackendServer*` | `bool` | Perform health check against backend | Returns false on health check failure |\n\n**Cache Engine Interfaces**\n\nThe `CacheEngine` component provides caching interfaces that implement HTTP semantics for cache storage, retrieval, and invalidation operations.\n\n| Interface Method | Parameters | Return Value | Description | Error Conditions |\n|------------------|------------|--------------|-------------|------------------|\n| `cache_engine_lookup` | `CacheEngine*`, `HttpRequest*` | `CacheEntry*` | Find cached response for request | Returns NULL on cache miss |\n| `cache_engine_store` | `CacheEngine*`, `char* key`, `HttpResponse*` | `bool` | Store response in cache if cacheable | Returns false if not cacheable or storage failure |\n| `cache_engine_invalidate` | `CacheEngine*`, `char* key` | `bool` | Remove specific entry from cache | Returns false if key not found |\n| `cache_generate_key` | `HttpRequest*` | `char*` | Generate cache key for request | Returns NULL on memory allocation failure |\n| `cache_is_fresh` | `CacheEntry*`, `time_t current_time` | `bool` | Check if cached entry is still fresh | No error conditions |\n\n**SSL Termination Interfaces**\n\nThe `SSLTermination` component provides TLS-related interfaces for connection establishment, certificate management, and data encryption/decryption operations.\n\n| Interface Method | Parameters | Return Value | Description | Error Conditions |\n|------------------|------------|--------------|-------------|------------------|\n| `ssl_termination_accept_connection` | `SSLTermination*`, `int client_fd` | `SSL*` | Perform TLS handshake for client | Returns NULL on handshake failure |\n| `ssl_termination_sni_callback` | `SSL*`, `int* alert`, `void* context` | `int` | SNI hostname callback for certificate selection | Returns error codes for certificate selection failures |\n| `ssl_termination_reload_certificates` | `SSLTermination*` | `bool` | Reload certificates from disk without restart | Returns false on certificate loading errors |\n| `ssl_utils_load_certificate` | `char* cert_path`, `CertificateInfo*` | `X509*` | Load certificate from PEM file | Returns NULL on file or parsing errors |\n| `ssl_utils_verify_key_cert_match` | `EVP_PKEY*`, `X509*` | `bool` | Verify private key matches certificate | Returns false on key/certificate mismatch |\n\n#### Data Flow Coordination\n\nThe data flow coordination mechanisms ensure that HTTP request and response data moves efficiently between components while maintaining data integrity and proper error handling. The coordination patterns handle various complexities including partial data availability, flow control, and cleanup after errors.\n\n**Request Data Flow**\n\nRequest data flows from client connections through multiple processing stages, with each component transforming or enriching the data before passing it to the next stage.\n\n| Flow Stage | Input Data | Component | Output Data | Transformation Applied |\n|------------|------------|-----------|-------------|----------------------|\n| Raw Network Data | TCP byte stream | Connection Manager | Buffered HTTP data | Socket reading, buffering |\n| HTTP Parsing | Buffered HTTP data | HTTP Parser | HttpRequest structure | Protocol parsing, header extraction |\n| Request Preprocessing | HttpRequest structure | Connection Manager | Enhanced HttpRequest | Header addition, validation |\n| Backend Selection | Enhanced HttpRequest | Load Balancer | BackendServer assignment | Algorithm-based selection |\n| Cache Consultation | Enhanced HttpRequest | Cache Engine | CacheEntry or cache miss | Key generation, lookup |\n| Backend Forwarding | Enhanced HttpRequest | Connection Manager | Serialized HTTP | Request serialization, transmission |\n\n**Response Data Flow**\n\nResponse data flows from backend servers back to clients, with caching and SSL encryption stages modifying the data path based on configuration and client capabilities.\n\n| Flow Stage | Input Data | Component | Output Data | Transformation Applied |\n|------------|------------|-----------|-------------|----------------------|\n| Backend Response | TCP byte stream | Connection Manager | Buffered response data | Socket reading, buffering |\n| Response Parsing | Buffered response data | HTTP Parser | HttpResponse structure | Protocol parsing, header extraction |\n| Cache Storage | HttpResponse structure | Cache Engine | Stored CacheEntry | Cacheability evaluation, storage |\n| Client Delivery | HttpResponse structure | Connection Manager | Serialized HTTP | Response serialization |\n| SSL Encryption | Serialized HTTP | SSL Termination | Encrypted byte stream | TLS encryption (HTTPS only) |\n| Client Transmission | Encrypted/plain data | Connection Manager | Network transmission | Socket writing, flow control |\n\n**Error Propagation Patterns**\n\nError conditions must be properly propagated between components to ensure that failures are handled gracefully and don't corrupt system state or cause resource leaks.\n\n| Error Source | Detection Point | Propagation Path | Recovery Action |\n|--------------|-----------------|------------------|------------------|\n| Client connection failure | Connection Manager | Direct error return | Connection cleanup, client notification |\n| HTTP parsing error | HTTP Parser | Error return code | Bad request response, connection close |\n| Backend selection failure | Load Balancer | NULL return value | Service unavailable response |\n| Backend connection failure | Connection Manager | Connection timeout | Backend retry or error response |\n| Cache storage failure | Cache Engine | Boolean failure return | Continue without caching |\n| SSL handshake failure | SSL Termination | NULL SSL context | Connection close, SSL error logging |\n\n#### Synchronization and Thread Safety\n\nThe inter-component communication must handle concurrent access patterns safely because the reverse proxy processes multiple requests simultaneously across different threads. Each component implements appropriate synchronization mechanisms to protect shared data structures and coordinate access to system resources.\n\n**Component-Level Synchronization**\n\nEach component implements internal synchronization to protect its data structures from concurrent access corruption while minimizing lock contention that could impact performance.\n\n| Component | Synchronization Mechanism | Protected Resources | Lock Granularity |\n|-----------|---------------------------|---------------------|------------------|\n| Connection Manager | Per-connection state locks | Connection structures, socket operations | Individual connections |\n| Load Balancer | Reader-writer locks | Backend server list, health status | Backend array and individual servers |\n| Cache Engine | Hash table locks, LRU locks | Cache entries, eviction lists | Hash buckets and LRU operations |\n| SSL Termination | Context map locks | SSL contexts, certificate reloading | SSL context hash table |\n| HTTP Parser | No synchronization needed | Parser state is per-request | Not applicable - stateless |\n\n**Cross-Component Coordination**\n\nCross-component interactions require careful coordination to avoid deadlocks and ensure consistent system behavior when multiple components must collaborate to complete operations.\n\nThe primary coordination mechanism uses the event-driven architecture where components don't hold locks while calling other components. Instead, components complete their internal operations, release any held locks, and then invoke other component methods without holding internal locks.\n\n> **Critical Design Insight**: The event-driven architecture eliminates most cross-component deadlock risks because components don't hold internal locks while making external calls. This design choice trades some potential performance for significantly improved reliability and debuggability.\n\n#### Component Startup and Shutdown Coordination\n\nThe system startup and shutdown sequences require careful coordination to ensure that components initialize in the correct order and that shutdown occurs gracefully without losing in-flight requests or corrupting persistent state.\n\n**Startup Sequence**\n\n| Order | Component | Initialization Actions | Dependencies |\n|-------|-----------|----------------------|--------------|\n| 1 | Configuration Loading | Parse config file, validate settings | File system access |\n| 2 | SSL Termination | Load certificates, initialize OpenSSL | Certificate files, OpenSSL library |\n| 3 | Cache Engine | Initialize hash tables, start cleanup threads | Memory allocation |\n| 4 | Load Balancer | Initialize backend list, start health checking | Backend server network access |\n| 5 | Connection Manager | Initialize epoll, create listening sockets | Network socket permissions |\n| 6 | Main Event Loop | Start request processing | All other components ready |\n\n**Shutdown Sequence**\n\n| Order | Component | Shutdown Actions | Cleanup Requirements |\n|-------|-----------|------------------|---------------------|\n| 1 | Main Event Loop | Stop accepting new connections | Complete current request processing |\n| 2 | Connection Manager | Drain existing connections, close sockets | Wait for request completion timeouts |\n| 3 | Load Balancer | Stop health checking, update backend status | Join health check threads |\n| 4 | Cache Engine | Stop cleanup threads, sync cached data | Join cleanup threads |\n| 5 | SSL Termination | Stop certificate reloading, cleanup SSL contexts | Join certificate threads |\n| 6 | Resource Cleanup | Free memory, close files, release system resources | Final system resource release |\n\n### Implementation Guidance\n\nThe inter-component communication implementation requires careful attention to interface design, error handling, and performance optimization. The following guidance provides concrete implementation strategies for building robust component interactions.\n\n**Technology Recommendations**\n\n| Communication Aspect | Simple Approach | Advanced Approach |\n|----------------------|-----------------|-------------------|\n| Function Interfaces | Direct function calls with error returns | Function pointers with callback interfaces |\n| Data Serialization | Direct structure passing | Protocol buffers or JSON serialization |\n| Event Coordination | Epoll-based event loops | Custom event dispatch framework |\n| Error Handling | Return codes and errno | Structured error objects with context |\n| Inter-thread Communication | Mutex and condition variables | Lock-free queues and atomic operations |\n\n**Recommended File Structure**\n\n```\nproxy/\n├── src/\n│   ├── main.c                     ← Main event loop and component coordination\n│   ├── interfaces/                ← Component interface definitions\n│   │   ├── connection_manager.h   ← Connection manager interface\n│   │   ├── http_parser.h          ← HTTP parser interface\n│   │   ├── load_balancer.h        ← Load balancer interface\n│   │   ├── cache_engine.h         ← Cache engine interface\n│   │   └── ssl_termination.h      ← SSL termination interface\n│   ├── core/                      ← Core coordination logic\n│   │   ├── proxy_server.c         ← Main server coordination\n│   │   ├── event_dispatcher.c     ← Event routing between components\n│   │   └── error_handling.c       ← Cross-component error handling\n│   └── utils/                     ← Shared utilities\n│       ├── buffer.c               ← Buffer management\n│       ├── hashtable.c            ← Hash table implementation\n│       └── logger.c               ← Logging system\n```\n\n**Core Event Dispatcher Implementation**\n\n```c\n#include <sys/epoll.h>\n#include <errno.h>\n#include <unistd.h>\n#include \"interfaces/connection_manager.h\"\n#include \"interfaces/ssl_termination.h\"\n\n// Event dispatcher coordinates between components\ntypedef struct {\n    int epoll_fd;\n    ConnectionManager* conn_mgr;\n    SSLTermination* ssl_term;\n    bool running;\n} EventDispatcher;\n\n// Initialize event dispatcher with component references\nEventDispatcher* event_dispatcher_create(ConnectionManager* conn_mgr, \n                                        SSLTermination* ssl_term) {\n    EventDispatcher* dispatcher = malloc(sizeof(EventDispatcher));\n    if (!dispatcher) return NULL;\n    \n    dispatcher->epoll_fd = epoll_create1(EPOLL_CLOEXEC);\n    if (dispatcher->epoll_fd == -1) {\n        free(dispatcher);\n        return NULL;\n    }\n    \n    dispatcher->conn_mgr = conn_mgr;\n    dispatcher->ssl_term = ssl_term;\n    dispatcher->running = true;\n    \n    return dispatcher;\n}\n\n// Main event processing loop - coordinates all component interactions\nvoid event_dispatcher_run(EventDispatcher* dispatcher) {\n    struct epoll_event events[1024];\n    \n    while (dispatcher->running) {\n        int event_count = epoll_wait(dispatcher->epoll_fd, events, 1024, 1000);\n        \n        if (event_count == -1) {\n            if (errno == EINTR) continue;\n            logger_log(ERROR, __FILE__, __LINE__, \"epoll_wait failed: %s\", strerror(errno));\n            break;\n        }\n        \n        // TODO 1: Process each epoll event\n        // TODO 2: Determine if event is for client connection, backend connection, or listening socket\n        // TODO 3: Route event to appropriate component (ConnectionManager or SSLTermination)\n        // TODO 4: Handle component coordination for complex operations (cache + backend)\n        // TODO 5: Update event monitoring based on connection state changes\n        // Hint: Use epoll event data to store Connection* pointers for fast lookup\n    }\n}\n```\n\n**Inter-Component Message Structures**\n\n```c\n// Standard message header for all inter-component communication\ntypedef struct {\n    uint32_t message_type;\n    uint32_t message_length;\n    uint64_t transaction_id;  // For request tracing\n    time_t timestamp;\n} MessageHeader;\n\n// Cache lookup request message\ntypedef struct {\n    MessageHeader header;\n    char cache_key[512];\n    HttpRequest* request;\n    bool conditional_request;\n} CacheLookupMessage;\n\n// Backend selection request message\ntypedef struct {\n    MessageHeader header;\n    HttpRequest* request;\n    struct sockaddr_in client_addr;\n    LoadBalancingAlgorithm preferred_algorithm;\n} BackendSelectionMessage;\n\n// Generic component response message\ntypedef struct {\n    MessageHeader header;\n    int result_code;\n    char error_message[256];\n    void* result_data;\n} ComponentResponse;\n```\n\n**Request Processing Coordination**\n\n```c\n// Coordinate complete request processing across all components\nint proxy_process_request(ProxyServer* server, Connection* client_conn) {\n    HttpRequest* request = NULL;\n    BackendServer* backend = NULL;\n    Connection* backend_conn = NULL;\n    CacheEntry* cached_response = NULL;\n    int result = -1;\n    \n    // TODO 1: Parse HTTP request using HttpParser component\n    // TODO 2: Check cache using CacheEngine component - return cached response if fresh\n    // TODO 3: Select backend using LoadBalancer component\n    // TODO 4: Acquire backend connection using ConnectionManager\n    // TODO 5: Forward request to backend server\n    // TODO 6: Process backend response and update cache\n    // TODO 7: Send response to client (with SSL encryption if needed)\n    // TODO 8: Clean up all resources and update connection pools\n    // Hint: Use goto cleanup pattern to ensure proper resource cleanup on any error\n    \ncleanup:\n    // Always clean up resources regardless of success/failure\n    if (backend_conn) {\n        connection_manager_release_backend(server->conn_mgr, backend_conn, \n                                         result == 0 && client_conn->keep_alive);\n    }\n    if (request) http_request_destroy(request);\n    return result;\n}\n```\n\n**Component Error Handling Coordination**\n\n```c\n// Centralized error handling for cross-component operations\ntypedef enum {\n    PROXY_ERROR_NONE = 0,\n    PROXY_ERROR_PARSE_FAILED,\n    PROXY_ERROR_BACKEND_UNAVAILABLE,\n    PROXY_ERROR_BACKEND_TIMEOUT,\n    PROXY_ERROR_CACHE_FAILURE,\n    PROXY_ERROR_SSL_HANDSHAKE_FAILED,\n    PROXY_ERROR_CLIENT_DISCONNECTED\n} ProxyErrorCode;\n\n// Handle errors that span multiple components\nvoid proxy_handle_error(ProxyServer* server, Connection* client_conn, \n                       ProxyErrorCode error_code, const char* error_details) {\n    HttpResponse* error_response = NULL;\n    \n    // TODO 1: Log error with appropriate severity level\n    // TODO 2: Create appropriate HTTP error response based on error code\n    // TODO 3: Update component statistics (failed requests, error counts)\n    // TODO 4: Send error response to client (with SSL if needed)\n    // TODO 5: Clean up any partial state in components\n    // TODO 6: Close client connection if error is unrecoverable\n    // Hint: Different error codes require different HTTP status codes and cleanup actions\n}\n```\n\n**Component Health Monitoring**\n\n```c\n// Monitor component health and coordination effectiveness\ntypedef struct {\n    uint64_t requests_processed;\n    uint64_t cache_hits;\n    uint64_t cache_misses;\n    uint64_t backend_failures;\n    uint64_t ssl_handshake_failures;\n    double avg_request_time;\n    time_t last_update;\n} ProxyStats;\n\n// Collect statistics from all components\nvoid proxy_update_statistics(ProxyServer* server, ProxyStats* stats) {\n    // TODO 1: Collect statistics from ConnectionManager (request counts, timing)\n    // TODO 2: Collect statistics from CacheEngine (hit rates, evictions)\n    // TODO 3: Collect statistics from LoadBalancer (backend health, distribution)\n    // TODO 4: Collect statistics from SSLTermination (handshake success rates)\n    // TODO 5: Calculate derived metrics (success rates, latency percentiles)\n    // TODO 6: Update monitoring endpoints for external systems\n    // Hint: Use atomic operations for statistics updates to avoid locks\n}\n```\n\n**Milestone Checkpoints**\n\nAfter implementing the inter-component communication system, verify correct operation using these checkpoints:\n\n1. **Component Isolation Testing**: Each component should be testable independently by providing mock implementations of other component interfaces. Create mock implementations that return predictable results and verify that each component handles the mock responses correctly.\n\n2. **Request Flow Tracing**: Implement transaction ID tracking that follows a single request through all components. Add logging at each component boundary and verify that the transaction ID appears in all log entries for a single request.\n\n3. **Error Propagation Verification**: Inject errors at each component interface and verify that errors propagate correctly to the client without corrupting system state or causing resource leaks.\n\n4. **Concurrent Request Testing**: Process multiple concurrent requests and verify that component interactions don't cause race conditions, deadlocks, or data corruption. Monitor for proper connection pool usage and cache consistency.\n\n**Common Implementation Pitfalls**\n\n⚠️ **Pitfall: Holding Internal Locks During External Calls**\nComponents should never hold their internal locks while calling methods on other components. This creates deadlock risks when components need to interact bidirectionally. Always complete internal operations and release locks before making external component calls.\n\n⚠️ **Pitfall: Inconsistent Error Handling Across Components**\nEach component must handle errors consistently and provide meaningful error information to callers. Don't ignore error return values or fail to propagate errors up the call stack. Implement structured error handling that provides context about which component failed and why.\n\n⚠️ **Pitfall: Resource Ownership Confusion**\nClearly define which component owns each resource and is responsible for cleanup. Use consistent patterns like \"creator owns\" or \"last user owns\" throughout the system. Document ownership rules in interface specifications.\n\n⚠️ **Pitfall: Race Conditions in Component Statistics**\nStatistics updates across components can create race conditions if not properly synchronized. Use atomic operations for simple counters and appropriate locking for complex statistics calculations. Consider using per-thread statistics with periodic aggregation to reduce contention.\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** All milestones - comprehensive error handling is essential across HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).\n\nThink of error handling in a reverse proxy like an air traffic control system managing multiple failure scenarios simultaneously. Just as air traffic controllers must handle plane mechanical failures, weather emergencies, runway closures, and communication blackouts while keeping other flights operating safely, a reverse proxy must gracefully handle client disconnections, backend server failures, network partitions, and SSL certificate problems while continuing to serve other requests. The key insight is that failures are not exceptional cases—they are normal operating conditions that require systematic detection, classification, and recovery strategies.\n\nBuilding robust error handling requires understanding that failures cascade through components in predictable patterns. When a backend server fails, it affects the load balancer's backend selection, the connection manager's pooled connections, and potentially cached responses that originated from that server. Each failure mode requires specific detection mechanisms, recovery strategies, and graceful degradation approaches to maintain service availability.\n\nThe challenge lies in designing error handling that provides strong guarantees while maintaining performance. Error detection must be fast enough not to impact request latency, recovery mechanisms must activate quickly to minimize service disruption, and fallback strategies must preserve as much functionality as possible during partial system failures.\n\n![Error Handling and Recovery Flow](./diagrams/error-handling-flowchart.svg)\n\n### Failure Modes and Detection\n\nUnderstanding failure modes requires systematically analyzing each point where the reverse proxy interacts with external systems or manages internal state. Think of failure detection like a comprehensive medical diagnostic system—each component must monitor its own vital signs while also coordinating with other components to detect system-wide health issues. The goal is early detection before failures cascade into service outages.\n\n**Client Connection Failures** represent the most common failure category, occurring when clients disconnect unexpectedly, send malformed requests, or violate protocol specifications. These failures require immediate detection to prevent resource leaks and unnecessary backend processing.\n\n| Failure Mode | Detection Method | Symptoms | Root Cause |\n|--------------|------------------|----------|------------|\n| Client Disconnect During Request | `EPOLLHUP` or `EPOLLERR` events | Connection state shows `CONNECTION_READING_REQUEST` but socket closed | Client closed browser, network timeout, mobile device sleep |\n| Malformed HTTP Request | HTTP parser returns `HTTP_PARSING_ERROR` | Parser unable to extract method, URI, or headers | Client bug, protocol violation, manual crafting |\n| Request Size Exceeding Limits | Buffer allocation failure or size checks | Request buffer exceeds configured maximum | Large file upload, DoS attempt, misconfigured client |\n| Slow Client Attack | Timer wheel timeout on request reading | Connection remains in `CONNECTION_READING_REQUEST` beyond timeout | Intentional slowloris attack or very slow network |\n| SSL Handshake Failure | SSL_accept returns error codes | TLS negotiation fails during connection establishment | Wrong certificate, cipher mismatch, protocol version incompatibility |\n\nThe detection strategy for client failures centers on the connection state machine monitoring and timeout management. The `ConnectionManager` tracks each connection's state and uses the `TimerWheel` to detect connections that remain in transitional states beyond configured thresholds.\n\n**Backend Server Failures** require more sophisticated detection because they affect multiple concurrent requests and the overall service capacity. Backend failures can be immediate (connection refused) or gradual (increasing response times, partial responses).\n\n| Failure Mode | Detection Method | Symptoms | Impact |\n|--------------|------------------|----------|---------|\n| Backend Server Down | Connection establishment failure, `ECONNREFUSED` | `connect()` system call fails immediately | All requests to this backend fail |\n| Backend Network Partition | Connection timeout during establishment | `connect()` hangs then times out after `SO_SNDTIMEO` | Backend appears down but may be healthy |\n| Backend Slow Response | Response timeout using timer wheel | Connection stuck in `CONNECTION_READING_RESPONSE` | Requests queue up, response times increase |\n| Backend Partial Response | Incomplete response parsing, unexpected connection close | `HttpParser` detects incomplete response or connection closes mid-response | Data corruption, partial service failure |\n| Backend Health Check Failure | Active health check request failure | HTTP request to health check endpoint returns non-200 status | Backend overloaded or failing internally |\n\nThe `LoadBalancer` component implements comprehensive backend failure detection through both passive monitoring (observing request failures) and active health checking (periodic probe requests). The health checking system maintains failure counters and implements exponential backoff to avoid overwhelming failing backends.\n\n> **Key Insight**: Backend failure detection must balance responsiveness with stability. Too aggressive failure detection leads to healthy backends being marked down due to temporary network hiccups. Too conservative detection allows failing backends to impact user requests.\n\n**Connection Pool Failures** occur when the connection pooling mechanism itself experiences problems, such as resource exhaustion, connection leaks, or pool corruption.\n\n| Failure Mode | Detection Method | Symptoms | Prevention |\n|--------------|------------------|----------|------------|\n| Connection Pool Exhaustion | Pool creation fails when `active_count + idle_count >= max_connections` | New requests wait indefinitely for connections | Monitor pool utilization, implement connection limits |\n| Stale Connection Reuse | Backend connection fails immediately after retrieval from pool | First request on reused connection gets `EPIPE` or `ECONNRESET` | Validate connections before reuse, implement keep-alive timeouts |\n| Connection Leak | Pool size grows continuously, connections never returned | `active_count` increases without corresponding decreases | Audit connection lifecycle, ensure all code paths release connections |\n| Pool Lock Contention | High latency on connection acquisition | Threads block on `pool_mutex` for extended periods | Implement pool sharding, reduce critical section duration |\n\nThe `ConnectionPool` implements connection validation by sending a minimal probe (like TCP `MSG_PEEK`) before returning connections from the idle pool. Stale connections are discarded and new connections established as needed.\n\n**Caching System Failures** impact performance rather than correctness, but require careful handling to avoid serving stale or corrupted cached responses.\n\n| Failure Mode | Detection Method | Symptoms | Recovery Strategy |\n|--------------|------------------|----------|------------------|\n| Cache Memory Exhaustion | Memory allocation failures during cache storage | `cache_engine_store()` returns false, new entries not cached | Emergency cache eviction, memory pressure relief |\n| Cache Corruption | Checksum validation failure, invalid cache entry structure | Cache lookup returns malformed response | Invalidate corrupted entries, fall back to backend |\n| TTL Heap Corruption | Heap invariant violations during TTL processing | Expired entries not evicted, fresh entries evicted prematurely | Rebuild TTL heap, restart cache cleanup thread |\n| Cache Lock Deadlock | Cache operations hang indefinitely | Threads block on `cache_rwlock` or `lru_mutex` | Detect deadlock using timeouts, restart cache subsystem |\n\nThe `CacheEngine` implements defensive programming by validating cache entry integrity before returning cached responses. Corrupted entries are immediately purged and requests fall back to backend servers.\n\n**SSL/TLS Failures** require special handling because they involve cryptographic operations and certificate management with specific security implications.\n\n| Failure Mode | Detection Method | Symptoms | Security Impact |\n|--------------|------------------|----------|-----------------|\n| Certificate Expiration | Certificate validity period check during context creation | SSL context creation fails, `ssl_utils_load_certificate()` reports expiration | Clients receive certificate errors, connections fail |\n| Private Key Mismatch | Key-certificate validation during SSL context setup | `ssl_utils_verify_key_cert_match()` returns false | SSL handshake failures, authentication problems |\n| SNI Certificate Missing | SNI callback unable to find matching certificate | `ssl_termination_sni_callback()` returns `SSL_TLSEXT_ERR_ALERT_FATAL` | Wrong certificate served, client warnings |\n| Cipher Suite Negotiation Failure | SSL handshake fails during cipher selection | TLS handshake aborts with cipher-related errors | Connection establishment fails, compatibility issues |\n| Certificate Chain Validation Failure | Chain verification fails during certificate loading | `ssl_utils_load_certificate()` unable to build trust chain | Browser security warnings, connection failures |\n\nThe `SSLTermination` component implements certificate monitoring through background validation threads that check certificate expiration dates and reload certificates when files change on disk.\n\n> **Architecture Decision: Failure Detection Strategy**\n> - **Context**: Need to balance early failure detection with system stability and performance\n> - **Options Considered**: \n>   1. Reactive detection (detect failures only when they impact requests)\n>   2. Proactive detection (active monitoring and health checking)\n>   3. Hybrid approach (combine passive observation with active probing)\n> - **Decision**: Hybrid approach with component-specific strategies\n> - **Rationale**: Reactive detection alone misses gradual degradation and allows cascade failures. Pure proactive detection creates excessive monitoring overhead. Hybrid approach provides early warning while minimizing false positives.\n> - **Consequences**: Requires coordination between components for failure state sharing, but provides robust early detection with acceptable overhead.\n\n### Recovery and Fallback Strategies\n\nRecovery strategies must address the fundamental challenge of maintaining service availability while dealing with component failures. Think of this like a hospital emergency response system—when one department fails, other departments must absorb the load while the failed department recovers, all without compromising patient care. The key principle is graceful degradation: the system should lose functionality gradually rather than failing catastrophically.\n\n**Client Connection Recovery** focuses on clean resource management and appropriate error responses that help clients understand and respond to failure conditions.\n\nWhen client disconnections are detected during request processing, the recovery strategy prioritizes preventing resource leaks and canceling unnecessary backend processing. The `ConnectionManager` implements a comprehensive cleanup sequence that releases all resources associated with the failed client connection.\n\n| Recovery Scenario | Detection Point | Recovery Actions | Client Response |\n|-------------------|----------------|------------------|-----------------|\n| Client Disconnect During Request Reading | `EPOLLHUP` event on client socket | 1. Cancel request parsing 2. Release client connection 3. Clean up request buffers 4. Log disconnect for monitoring | None (client already disconnected) |\n| Client Disconnect During Backend Processing | `EPOLLHUP` during `CONNECTION_FORWARDING` | 1. Cancel backend request 2. Return backend connection to pool 3. Release client connection 4. Update backend statistics | None (client already disconnected) |\n| Malformed Request Parsing | Parser enters `HTTP_PARSING_ERROR` state | 1. Generate HTTP 400 Bad Request response 2. Include specific error details 3. Close connection (HTTP/1.0) or reset stream (HTTP/2) | HTTP 400 with error description |\n| Request Size Limit Exceeded | Buffer allocation fails or size check triggers | 1. Generate HTTP 413 Payload Too Large 2. Close connection immediately 3. Log oversized request attempt | HTTP 413 with size limit information |\n| Client Timeout During Request | Timer wheel timeout fires | 1. Generate HTTP 408 Request Timeout 2. Close connection 3. Release all associated resources | HTTP 408 with timeout duration |\n\nThe client error response generation follows HTTP specification guidelines to provide actionable feedback. Error responses include specific details about the failure condition and suggested client actions when appropriate.\n\n**Backend Server Recovery** requires sophisticated strategies because backend failures affect multiple concurrent client requests and the overall system capacity. The recovery approach must minimize impact on active requests while restoring service capacity.\n\nWhen backend servers fail, the `LoadBalancer` immediately removes them from the active pool and redistributes their load across remaining healthy backends. This requires careful coordination between the load balancer and connection manager to handle in-flight requests appropriately.\n\n| Recovery Scenario | Detection Trigger | Immediate Actions | Long-term Recovery |\n|-------------------|-------------------|-------------------|-------------------|\n| Backend Connection Refused | `connect()` fails with `ECONNREFUSED` | 1. Mark backend unhealthy 2. Select alternative backend 3. Retry request on new backend | 1. Continue health checking 2. Restore to pool when healthy 3. Adjust health check frequency |\n| Backend Response Timeout | Timer wheel timeout on response reading | 1. Close backend connection 2. Return connection failure to load balancer 3. Generate HTTP 504 Gateway Timeout for client | 1. Increase backend timeout threshold 2. Monitor for systematic slowness 3. Consider backend capacity issues |\n| Backend Partial Response | Parser detects incomplete response | 1. Close corrupted connection 2. Remove from connection pool 3. Retry request if safe (GET, HEAD) 4. Generate HTTP 502 Bad Gateway if not retriable | 1. Monitor for data corruption patterns 2. Investigate backend health 3. Consider network issues |\n| All Backends Down | No healthy backends available | 1. Return HTTP 503 Service Unavailable 2. Include Retry-After header 3. Continue health checking all backends | 1. Implement emergency backend discovery 2. Alert operations team 3. Consider maintenance mode |\n\nThe backend recovery system implements intelligent retry logic that distinguishes between retriable requests (idempotent operations like GET and HEAD) and non-retriable requests (potentially state-changing operations like POST and PUT). Retriable requests automatically retry on alternative backends, while non-retriable requests return errors to avoid duplicate processing.\n\n> **Critical Design Principle**: Backend recovery must never amplify failures. When backends are struggling, the recovery system should reduce load rather than increase it through aggressive retries.\n\n**Connection Pool Recovery** ensures that connection pooling continues to provide performance benefits even when individual connections fail or pools become corrupted.\n\nThe `ConnectionPool` implements a self-healing design that automatically adapts to changing backend conditions. When stale connections are detected, the pool discards them and establishes fresh connections. When pool exhaustion occurs, the system gracefully degrades to creating direct connections while working to restore pool capacity.\n\n| Recovery Scenario | Trigger Condition | Immediate Response | Pool Restoration |\n|-------------------|-------------------|-------------------|------------------|\n| Stale Connection Detection | Connection validation fails before reuse | 1. Discard stale connection 2. Attempt to create new connection 3. Update pool statistics | 1. Reduce idle timeout to prevent staleness 2. Increase validation frequency 3. Monitor backend keep-alive settings |\n| Pool Exhaustion | `active_count >= max_connections` and no idle connections | 1. Block new requests with timeout 2. Create direct connection if possible 3. Monitor for connection returns | 1. Increase pool size if backend can handle it 2. Investigate connection leaks 3. Optimize connection lifecycle |\n| Pool Lock Contention | High latency on mutex acquisition | 1. Implement connection request queuing 2. Use timeout on lock acquisition 3. Fall back to direct connections | 1. Implement pool sharding 2. Reduce critical section size 3. Consider lock-free data structures |\n| Connection Leak Detection | Pool size grows without bound | 1. Force connection cleanup 2. Log connection allocation traces 3. Implement emergency pool reset | 1. Audit all connection acquisition sites 2. Add connection lifecycle tracking 3. Implement automatic leak detection |\n\nThe pool recovery system maintains detailed statistics about connection usage patterns to identify systemic issues. When connection leaks are detected, the system implements emergency pool draining that forcibly closes all connections and rebuilds the pool from scratch.\n\n**Cache System Recovery** focuses on maintaining performance benefits while ensuring data integrity during cache failures.\n\nWhen cache system failures occur, the primary strategy is immediate fallback to backend servers while attempting to restore cache functionality in the background. This ensures that service remains available even if caching performance benefits are temporarily lost.\n\n| Recovery Scenario | Failure Detection | Immediate Fallback | Cache Restoration |\n|-------------------|-------------------|-------------------|-------------------|\n| Cache Memory Exhaustion | Memory allocation failures during storage | 1. Disable new cache entries 2. Trigger emergency eviction 3. Fall back to backend for all requests | 1. Implement aggressive LRU eviction 2. Reduce cache size limits 3. Monitor memory usage patterns |\n| Cache Entry Corruption | Checksum validation failure | 1. Purge corrupted entry immediately 2. Serve request from backend 3. Log corruption details | 1. Investigate corruption patterns 2. Implement cache entry versioning 3. Add redundant storage |\n| Cache Lock Deadlock | Timeout on cache operations | 1. Bypass cache for affected requests 2. Restart cache subsystem 3. Serve from backend | 1. Implement deadlock detection 2. Redesign locking hierarchy 3. Add lock timeout mechanisms |\n| TTL Processing Failure | Heap corruption or processing errors | 1. Disable TTL-based eviction 2. Implement manual cache clearing 3. Continue serving cached entries | 1. Rebuild TTL heap from scratch 2. Implement heap invariant checking 3. Add TTL processing monitoring |\n\nThe cache recovery system implements a \"circuit breaker\" pattern that automatically disables caching when error rates exceed configurable thresholds. This prevents cache failures from impacting request processing while allowing time for automatic recovery.\n\n**SSL/TLS Recovery** requires special handling due to security implications and the need to maintain encrypted communications.\n\nWhen SSL termination failures occur, the system must balance security requirements with service availability. The recovery strategy prioritizes security over availability—it's better to refuse connections than to serve them with compromised encryption.\n\n| Recovery Scenario | Security Impact | Immediate Response | Certificate Recovery |\n|-------------------|----------------|-------------------|---------------------|\n| Certificate Expiration | High - clients receive security warnings | 1. Disable affected SSL contexts 2. Return HTTP 503 for HTTPS requests 3. Alert operations immediately | 1. Install renewed certificates 2. Reload SSL contexts 3. Resume HTTPS service |\n| Private Key Compromise | Critical - potential man-in-the-middle attacks | 1. Immediately disable all SSL contexts 2. Refuse all HTTPS connections 3. Generate new key pairs | 1. Generate new private keys 2. Request new certificates 3. Update all SSL contexts |\n| SNI Certificate Missing | Medium - wrong certificate served | 1. Fall back to default certificate 2. Log SNI hostname mismatches 3. Continue service with warnings | 1. Install missing certificates 2. Update SNI configuration 3. Validate certificate coverage |\n| Cipher Suite Negotiation Failure | Medium - reduced security or connection failures | 1. Expand cipher suite support 2. Log negotiation failures 3. Maintain secure defaults | 1. Update cipher configuration 2. Test client compatibility 3. Balance security with compatibility |\n\nThe SSL recovery system implements automatic certificate monitoring that checks for expiration dates and triggers renewal processes before certificates expire. Certificate reloading happens atomically to avoid service interruption during updates.\n\n> **Architecture Decision: Error Recovery Philosophy**\n> - **Context**: Need to balance service availability with operational safety during failures\n> - **Options Considered**:\n>   1. Fail-fast: Stop processing immediately when errors are detected\n>   2. Best-effort: Continue processing with degraded functionality\n>   3. Graceful degradation: Systematically reduce functionality while maintaining core service\n> - **Decision**: Graceful degradation with fail-fast for security-critical failures\n> - **Rationale**: Web services must maintain availability during partial failures, but security violations require immediate protection. Graceful degradation preserves user experience while systematic recovery restores full functionality.\n> - **Consequences**: Requires sophisticated error classification and recovery coordination, but provides optimal balance of availability and safety.\n\n### Common Pitfalls in Error Handling\n\n⚠️ **Pitfall: Resource Leaks During Error Conditions**\n\nThe most common error handling mistake is failing to properly clean up resources when errors occur. This happens because error handling code paths are tested less frequently than success paths, leading to subtle resource leaks that only manifest under stress.\n\nThe specific problem occurs when error handling code returns early without calling cleanup functions, or when cleanup functions themselves can fail and propagate errors. For example, if `connection_manager_acquire_backend()` fails after allocating a `Connection` structure but before adding it to the pool, the connection memory and file descriptor leak unless the error path explicitly releases them.\n\nTo avoid this pitfall, implement the \"RAII pattern\" even in C by using consistent cleanup functions and ensuring every resource acquisition has a corresponding release in all code paths. Structure error handling with goto labels that consolidate cleanup operations:\n\n```c\nProxyErrorCode proxy_process_request(ProxyServer* server, Connection* conn) {\n    HttpRequest* request = NULL;\n    BackendServer* backend = NULL;\n    Connection* backend_conn = NULL;\n    \n    request = http_request_create();\n    if (!request) {\n        goto cleanup_connection;\n    }\n    \n    backend = loadbalancer_select_backend(server->load_balancer, request);\n    if (!backend) {\n        goto cleanup_request;\n    }\n    \n    backend_conn = connection_manager_acquire_backend(server->conn_manager, backend, 5000);\n    if (!backend_conn) {\n        goto cleanup_request;\n    }\n    \n    // Process request...\n    \n    connection_manager_release_backend(server->conn_manager, backend_conn, true);\n    http_request_destroy(request);\n    return PROXY_ERROR_NONE;\n\ncleanup_request:\n    http_request_destroy(request);\ncleanup_connection:\n    connection_manager_close_connection(server->conn_manager, conn);\n    return PROXY_ERROR_BACKEND_UNAVAILABLE;\n}\n```\n\n⚠️ **Pitfall: Cascade Failure Amplification**\n\nA critical mistake is designing error handling that amplifies failures rather than containing them. This occurs when error recovery logic creates additional load on already-stressed systems, causing localized failures to become system-wide outages.\n\nThe specific anti-pattern involves aggressive retry logic that doesn't implement backoff or circuit breaker patterns. When a backend server starts responding slowly, naive retry logic sends more requests to the struggling server, making the problem worse. Similarly, when health checks detect a failing server, continuing to send health check requests at normal frequency can prevent the server from recovering.\n\nTo prevent cascade failures, implement exponential backoff for retries, circuit breaker patterns for failing backends, and reduced health check frequency for known-unhealthy servers:\n\n```c\nbool health_check_backend(LoadBalancer* lb, BackendServer* backend) {\n    time_t now = time(NULL);\n    time_t since_last_failure = now - backend->last_failure_time;\n    \n    // Exponential backoff for failed backends\n    if (backend->failure_count > 0) {\n        time_t backoff_delay = (1 << min(backend->failure_count, 6)) * lb->health_check_interval;\n        if (since_last_failure < backoff_delay) {\n            return false; // Skip health check during backoff period\n        }\n    }\n    \n    // Proceed with health check...\n}\n```\n\n⚠️ **Pitfall: Inconsistent Error State Between Components**\n\nComponents can get into inconsistent states where one component believes a resource is available while another component knows it has failed. This happens because error propagation between components is asynchronous and components may cache state that becomes stale during failures.\n\nThe specific problem occurs when the `LoadBalancer` marks a backend as healthy based on successful connection establishment, but the `ConnectionManager` discovers that all connections to that backend are actually failing due to application-level issues. The load balancer continues selecting the failed backend because it hasn't received updated failure information.\n\nTo maintain consistent error state, implement a centralized error reporting system where all components report failures to a shared state manager:\n\n```c\ntypedef struct {\n    BackendServer* backend;\n    ProxyErrorCode error_code;\n    time_t error_time;\n    char error_details[256];\n} ErrorReport;\n\nvoid proxy_handle_error(ProxyServer* server, Connection* conn, ProxyErrorCode error, char* details) {\n    // Update component-specific state\n    switch (error) {\n        case PROXY_ERROR_BACKEND_TIMEOUT:\n            loadbalancer_report_backend_error(server->load_balancer, conn->backend_server, error);\n            connection_manager_invalidate_backend_pool(server->conn_manager, conn->backend_server);\n            break;\n        case PROXY_ERROR_SSL_HANDSHAKE_FAILED:\n            ssl_termination_report_error(server->ssl_termination, error, details);\n            break;\n    }\n    \n    // Update global error statistics\n    proxy_update_statistics(server, error, details);\n    \n    // Log error for monitoring\n    logger_log(ERROR, __FILE__, __LINE__, \"Request failed: %s\", details);\n}\n```\n\n⚠️ **Pitfall: Blocking Operations in Error Handlers**\n\nError handling code often performs blocking operations like DNS lookups, file I/O, or network requests, which can cause the entire event processing thread to stall. This is particularly dangerous because errors tend to occur in clusters, so blocking error handling can quickly exhaust all processing threads.\n\nThe specific problem occurs when error handling code tries to immediately reload certificates from disk, perform DNS resolution for alternative backends, or send error notifications over the network. These blocking operations prevent the error handler from processing other events, leading to cascading failures.\n\nTo avoid blocking in error handlers, implement asynchronous error processing using background threads or work queues:\n\n```c\ntypedef struct {\n    ProxyErrorCode error_code;\n    char error_details[512];\n    time_t error_time;\n    Connection* failed_connection;\n} ErrorWorkItem;\n\nvoid* error_processing_thread(void* arg) {\n    ErrorWorkItem* item;\n    while (queue_dequeue(error_queue, (void**)&item)) {\n        switch (item->error_code) {\n            case PROXY_ERROR_SSL_HANDSHAKE_FAILED:\n                // Non-blocking: schedule certificate reload\n                ssl_termination_schedule_reload(ssl_termination);\n                break;\n            case PROXY_ERROR_BACKEND_UNAVAILABLE:\n                // Non-blocking: update backend health asynchronously\n                loadbalancer_schedule_health_check(load_balancer, item->failed_connection->backend_server);\n                break;\n        }\n        free(item);\n    }\n    return NULL;\n}\n```\n\n⚠️ **Pitfall: Security Information Leakage in Error Messages**\n\nError messages often inadvertently expose sensitive information about the system's internal structure, configuration, or data. This information can be valuable to attackers attempting to exploit the system.\n\nThe specific problem occurs when error messages include internal IP addresses, file paths, database connection strings, or detailed stack traces that reveal implementation details. For example, returning \"Connection failed to backend server 192.168.1.100:3306\" exposes internal network topology.\n\nTo prevent information leakage, implement error sanitization that provides useful feedback to legitimate users while hiding sensitive details:\n\n```c\nvoid generate_client_error_response(Connection* conn, ProxyErrorCode error, char* internal_details) {\n    HttpResponse* response = http_response_create();\n    \n    switch (error) {\n        case PROXY_ERROR_BACKEND_UNAVAILABLE:\n            response->status = 503;\n            http_response_add_header(response, \"Content-Type\", \"text/plain\");\n            buffer_append(response->body, \"Service temporarily unavailable\", 28);\n            // Internal details logged but not sent to client\n            logger_log(ERROR, __FILE__, __LINE__, \"Backend failure: %s\", internal_details);\n            break;\n        case PROXY_ERROR_BACKEND_TIMEOUT:\n            response->status = 504;\n            http_response_add_header(response, \"Content-Type\", \"text/plain\");\n            buffer_append(response->body, \"Gateway timeout\", 15);\n            break;\n    }\n    \n    // Send sanitized response to client\n    connection_send_response(conn, response);\n    http_response_destroy(response);\n}\n```\n\n### Implementation Guidance\n\nError handling implementation requires careful coordination between all proxy components to ensure consistent failure detection and recovery. The key challenge is implementing robust error handling without significantly impacting performance or code complexity.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Error Logging | Standard C stdio with log levels | Structured logging with syslog integration |\n| Error Propagation | Return codes with errno | Custom error types with context |\n| Timeout Management | Simple timer threads | Timer wheel with O(1) operations |\n| Resource Cleanup | Manual cleanup with goto labels | RAII-style cleanup macros |\n| Error Recovery | Immediate fallback strategies | Circuit breaker pattern with state machines |\n| Error Monitoring | Basic counters and logs | Metrics collection with alerting |\n\n**File Structure for Error Handling**\n\n```\nsrc/\n├── error/\n│   ├── error_types.h         ← Error code definitions and structures\n│   ├── error_handler.c       ← Central error coordination\n│   ├── error_reporter.c      ← Error logging and monitoring\n│   └── recovery_manager.c    ← Recovery strategy implementation\n├── utils/\n│   ├── cleanup_macros.h      ← RAII-style cleanup helpers\n│   └── timeout_manager.c     ← Centralized timeout handling\n└── monitoring/\n    ├── metrics.c             ← Performance and error metrics\n    └── health_monitor.c      ← System health monitoring\n```\n\n**Core Error Handling Infrastructure**\n\nThe error handling system requires a centralized error coordinator that receives error reports from all components and orchestrates appropriate recovery actions:\n\n```c\n// error/error_types.h\ntypedef enum {\n    PROXY_ERROR_NONE = 0,\n    PROXY_ERROR_PARSE_FAILED,\n    PROXY_ERROR_BACKEND_UNAVAILABLE,\n    PROXY_ERROR_BACKEND_TIMEOUT,\n    PROXY_ERROR_CACHE_FAILURE,\n    PROXY_ERROR_SSL_HANDSHAKE_FAILED,\n    PROXY_ERROR_CLIENT_DISCONNECTED,\n    PROXY_ERROR_MEMORY_EXHAUSTED,\n    PROXY_ERROR_CONFIG_INVALID\n} ProxyErrorCode;\n\ntypedef struct {\n    ProxyErrorCode code;\n    char message[512];\n    char component[64];\n    time_t timestamp;\n    uint64_t request_id;\n    Connection* failed_connection;\n    BackendServer* failed_backend;\n} ErrorContext;\n\ntypedef struct {\n    ErrorContext* errors[1024];\n    size_t error_count;\n    size_t error_capacity;\n    pthread_mutex_t error_mutex;\n    pthread_t recovery_thread;\n    bool running;\n} ErrorHandler;\n\n// Central error handling initialization\nErrorHandler* error_handler_create();\nvoid error_handler_start(ErrorHandler* handler);\nvoid error_handler_report(ErrorHandler* handler, ErrorContext* error);\nvoid error_handler_stop(ErrorHandler* handler);\nvoid error_handler_destroy(ErrorHandler* handler);\n```\n\n**Resource Cleanup Macros**\n\nTo prevent resource leaks during error conditions, implement cleanup macros that ensure consistent resource management:\n\n```c\n// utils/cleanup_macros.h\n#define CLEANUP_BUFFER(buf) do { \\\n    if (buf) { \\\n        buffer_destroy(buf); \\\n        buf = NULL; \\\n    } \\\n} while(0)\n\n#define CLEANUP_CONNECTION(conn_mgr, conn) do { \\\n    if (conn) { \\\n        connection_manager_close_connection(conn_mgr, conn); \\\n        conn = NULL; \\\n    } \\\n} while(0)\n\n#define CLEANUP_HTTP_REQUEST(req) do { \\\n    if (req) { \\\n        http_request_destroy(req); \\\n        req = NULL; \\\n    } \\\n} while(0)\n\n#define CLEANUP_BACKEND_CONNECTION(conn_mgr, conn, keep_alive) do { \\\n    if (conn) { \\\n        connection_manager_release_backend(conn_mgr, conn, keep_alive); \\\n        conn = NULL; \\\n    } \\\n} while(0)\n```\n\n**Error Recovery Skeleton**\n\nThe core error recovery logic coordinates between components to implement graceful degradation:\n\n```c\n// error/recovery_manager.c\ntypedef struct {\n    LoadBalancer* load_balancer;\n    ConnectionManager* conn_manager;\n    CacheEngine* cache_engine;\n    SSLTermination* ssl_termination;\n    pthread_mutex_t recovery_mutex;\n} RecoveryManager;\n\nRecoveryManager* recovery_manager_create(LoadBalancer* lb, ConnectionManager* cm, \n                                        CacheEngine* cache, SSLTermination* ssl) {\n    // TODO 1: Allocate RecoveryManager structure\n    // TODO 2: Initialize component references\n    // TODO 3: Initialize recovery_mutex\n    // TODO 4: Set up recovery state tracking\n    // Hint: Store references to all components for coordinated recovery\n}\n\nvoid recovery_manager_handle_backend_failure(RecoveryManager* mgr, BackendServer* backend, \n                                           ProxyErrorCode error) {\n    // TODO 1: Lock recovery_mutex to ensure atomic recovery actions\n    // TODO 2: Mark backend as unhealthy in load balancer\n    // TODO 3: Invalidate all pooled connections to failed backend\n    // TODO 4: Clear cache entries that originated from failed backend\n    // TODO 5: Schedule health check retry with exponential backoff\n    // TODO 6: Update failure statistics and monitoring metrics\n    // TODO 7: Release recovery_mutex\n    // Hint: Use loadbalancer_mark_backend_unhealthy(), connection_manager_invalidate_backend_pool()\n}\n\nvoid recovery_manager_handle_ssl_failure(RecoveryManager* mgr, ProxyErrorCode error, \n                                        char* hostname) {\n    // TODO 1: Determine if failure affects specific hostname or all SSL contexts\n    // TODO 2: If certificate expired, schedule immediate certificate reload\n    // TODO 3: If SNI failure, add missing certificate to reload queue\n    // TODO 4: If cipher negotiation failure, log client compatibility issue\n    // TODO 5: Update SSL failure statistics for monitoring\n    // Hint: Use ssl_termination_schedule_reload() for certificate issues\n}\n\nvoid recovery_manager_handle_cache_failure(RecoveryManager* mgr, ProxyErrorCode error, \n                                          char* cache_key) {\n    // TODO 1: Determine scope of cache failure (single entry vs entire cache)\n    // TODO 2: If memory exhaustion, trigger emergency cache eviction\n    // TODO 3: If corruption detected, invalidate affected cache entries\n    // TODO 4: If lock contention, implement cache operation timeouts\n    // TODO 5: Enable cache bypass mode if failures exceed threshold\n    // TODO 6: Schedule cache subsystem restart if necessary\n    // Hint: Use cache_engine_invalidate() and cache_engine_clear() for cleanup\n}\n```\n\n**Timeout Management Implementation**\n\nCentralized timeout management prevents resource exhaustion and provides consistent timeout behavior:\n\n```c\n// utils/timeout_manager.c\ntypedef struct {\n    Connection* connection;\n    time_t timeout_time;\n    ProxyErrorCode timeout_error;\n    void (*timeout_callback)(Connection*, ProxyErrorCode);\n} TimeoutEntry;\n\ntypedef struct {\n    TimerWheel* timer_wheel;\n    pthread_t timeout_thread;\n    bool running;\n} TimeoutManager;\n\nTimeoutManager* timeout_manager_create(time_t granularity) {\n    // TODO 1: Allocate TimeoutManager structure\n    // TODO 2: Create timer wheel with specified granularity\n    // TODO 3: Initialize timeout processing thread\n    // TODO 4: Set running flag to true\n    // Hint: Use timer_wheel_create() with appropriate slot count and duration\n}\n\nvoid timeout_manager_add_connection(TimeoutManager* mgr, Connection* conn, \n                                  int timeout_ms, ProxyErrorCode error_code) {\n    // TODO 1: Calculate absolute timeout time from current time + timeout_ms\n    // TODO 2: Create TimeoutEntry with connection and error code\n    // TODO 3: Add timeout entry to timer wheel at calculated time slot\n    // TODO 4: Store timer wheel reference in connection for later removal\n    // Hint: Use time(NULL) + (timeout_ms / 1000) for timeout calculation\n}\n\nvoid* timeout_processing_thread(void* arg) {\n    TimeoutManager* mgr = (TimeoutManager*)arg;\n    \n    while (mgr->running) {\n        // TODO 1: Sleep for timer wheel granularity period\n        // TODO 2: Process current timer wheel slot for expired timeouts\n        // TODO 3: For each expired timeout, call timeout callback\n        // TODO 4: Advance timer wheel to next slot\n        // TODO 5: Handle any timer wheel errors or corruption\n        // Hint: Use timer_wheel_process_current_slot() and timer_wheel_advance()\n    }\n    return NULL;\n}\n```\n\n**Milestone Checkpoint: Error Handling Verification**\n\nAfter implementing error handling infrastructure, verify the system correctly detects and recovers from common failure scenarios:\n\n1. **Backend Failure Testing**: Start the proxy with multiple backend servers, then shut down one backend. Verify that:\n   - The load balancer immediately stops selecting the failed backend\n   - In-flight requests to the failed backend return appropriate error codes\n   - New requests distribute only among healthy backends\n   - Health checks continue and detect when the backend recovers\n\n2. **Client Disconnection Testing**: Start a request but disconnect the client before completion. Verify that:\n   - The connection is properly cleaned up within 1 second\n   - The backend request is canceled if not yet sent\n   - No file descriptors or memory leak occurs\n   - Backend connections are returned to the pool if applicable\n\n3. **SSL Certificate Failure Testing**: Configure SSL termination with an expired certificate. Verify that:\n   - HTTPS connections are refused rather than served with expired certificates\n   - Certificate reload functionality works when valid certificates are provided\n   - SNI continues working for other valid certificates\n   - Error logs contain appropriate security alert information\n\n4. **Resource Exhaustion Testing**: Send requests at high rate to exhaust connection pools. Verify that:\n   - New requests receive HTTP 503 responses rather than hanging indefinitely\n   - Connection pool recovery occurs when load decreases\n   - No file descriptor leaks occur during exhaustion periods\n   - Error monitoring correctly reports resource exhaustion conditions\n\n**Debugging Error Handling Issues**\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| File descriptor leaks during errors | Missing cleanup in error paths | Use `lsof -p <pid>` to track FD growth | Add CLEANUP_CONNECTION macros to all error paths |\n| Requests hang during backend failures | Missing timeout on backend operations | Check connection state, look for FORWARDING state persistence | Implement timeout_manager_add_connection() for all backend operations |\n| Error responses contain internal details | No error sanitization | Review error response content in logs | Implement generate_client_error_response() with message filtering |\n| Recovery actions cause more failures | Cascade failure amplification | Monitor error rates during recovery periods | Add exponential backoff and circuit breaker patterns |\n| Components have inconsistent failure state | Async error propagation issues | Compare backend health state across load balancer and connection manager | Implement centralized error reporting with proxy_handle_error() |\n\nThe error handling implementation forms the foundation for a robust reverse proxy that maintains service availability during various failure conditions while protecting against security vulnerabilities and resource exhaustion.\n\n\n## Testing Strategy\n\n> **Milestone(s):** All milestones - comprehensive testing ensures correct implementation of HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).\n\nThink of testing a reverse proxy as conducting a full orchestra rehearsal. Just as a conductor must verify that each section plays correctly in isolation (violins, brass, percussion) and then ensure they harmonize together during the complete symphony, we need to test individual components independently and verify their coordinated behavior in realistic scenarios. A single missed note in one section can disrupt the entire performance, just as a bug in HTTP parsing or connection pooling can cascade through the entire request processing pipeline.\n\nThe testing strategy for our reverse proxy follows a three-tiered approach that mirrors how complex distributed systems are validated in production environments. We start with **unit testing** to verify individual component behavior in isolation, progress to **integration testing** to validate component interactions and data flow, and culminate with **milestone verification checkpoints** that simulate real-world usage patterns. Each tier builds confidence in different aspects of system correctness while providing increasingly realistic validation scenarios.\n\n### Unit Testing Approach\n\nUnit testing for a reverse proxy focuses on isolating each component's core logic while carefully mocking external dependencies like network I/O, file system operations, and time-dependent behavior. Think of unit testing as examining each instrument in our orchestra separately - we want to verify that the violin section can play their parts correctly before worrying about how they blend with the brass section.\n\nThe foundation of effective unit testing lies in **dependency injection** and **interface abstraction**. Each component receives its dependencies through constructor parameters rather than creating them directly, allowing tests to substitute mock implementations that behave predictably. This approach enables us to test error scenarios that would be difficult to reproduce with real network connections, such as partial reads, connection timeouts, or SSL handshake failures.\n\n**HTTP Parser Unit Testing Strategy:**\n\nThe `HttpParser` component requires particularly thorough unit testing due to its responsibility for correctly interpreting the HTTP protocol specification. Tests must verify parsing behavior across all `HttpParserState` transitions, handle malformed input gracefully, and correctly process edge cases like chunked transfer encoding and keep-alive connections.\n\n| Test Category | Test Cases | Input Data | Expected Behavior |\n|--------------|------------|------------|------------------|\n| Request Line Parsing | Valid methods, URIs, versions | `GET /path HTTP/1.1\\r\\n` | State transitions to `HTTP_PARSING_HEADERS` |\n| Header Parsing | Standard headers, custom headers | `Content-Type: application/json\\r\\n` | Headers stored in `HashTable` |\n| Content-Length Body | Fixed-length request body | `Content-Length: 5\\r\\n\\r\\nhello` | Body buffer contains exact bytes |\n| Chunked Encoding | Variable-sized chunks | `5\\r\\nhello\\r\\n0\\r\\n\\r\\n` | Assembled body without chunk markers |\n| Malformed Input | Invalid syntax, oversized headers | `INVALID REQUEST LINE` | State transitions to `HTTP_PARSING_ERROR` |\n| Incremental Parsing | Partial packet delivery | Split input across multiple calls | Maintains state across `http_parser_process` calls |\n\nThe parser testing framework uses **mock buffers** that simulate network packet boundaries, ensuring the parser correctly handles scenarios where HTTP messages arrive in fragments. Tests inject specific byte sequences at precise boundaries to verify state machine robustness.\n\n```c\n// Mock buffer simulation for incremental parsing tests\ntypedef struct {\n    char* fragments[16];     // Simulated network packets\n    size_t fragment_sizes[16];\n    size_t fragment_count;\n    size_t current_fragment;\n} MockNetworkBuffer;\n```\n\n**Connection Manager Unit Testing Strategy:**\n\nTesting the `ConnectionManager` requires sophisticated mocking of the event-driven I/O subsystem. Since the connection manager coordinates between epoll events, timer wheel timeouts, and connection pool operations, tests must carefully control the timing and ordering of these interactions.\n\n| Component Under Test | Mock Dependencies | Test Focus |\n|---------------------|------------------|------------|\n| `connection_manager_accept_client` | Mock socket file descriptors | Verify `Connection` state initialization |\n| `connection_manager_acquire_backend` | Mock `ConnectionPool` | Test connection reuse vs. new connection logic |\n| `connection_manager_handle_event` | Mock epoll events | Verify state transitions for `ConnectionState` |\n| `timeout_processor` | Mock `TimerWheel` | Test timeout detection and connection cleanup |\n| `connection_manager_release_backend` | Mock pool statistics | Verify connection return to pool logic |\n\nThe connection manager tests use **synthetic epoll events** generated by test harnesses rather than real network I/O. This approach allows tests to precisely control event ordering and timing without depending on external network conditions or introducing non-deterministic behavior.\n\n**Load Balancer Unit Testing Strategy:**\n\nLoad balancer testing focuses on algorithm correctness and health check behavior under various backend availability scenarios. The key challenge is testing concurrent access patterns while maintaining deterministic test outcomes.\n\n| Algorithm | Test Scenarios | Expected Distribution | Verification Method |\n|-----------|---------------|---------------------|-------------------|\n| `LB_ROUND_ROBIN` | 3 healthy backends, 100 requests | 33/33/34 requests per backend | Track `rr_current_index` progression |\n| `LB_LEAST_CONNECTIONS` | Backends with 0, 5, 10 connections | New requests to backend with 0 | Verify `connection_counts` array |\n| `LB_WEIGHTED_ROUND_ROBIN` | Weights 1:2:3, 60 requests | 10/20/30 requests per backend | Track `current_weights` calculations |\n| `LB_IP_HASH` | Same client IP, 10 requests | All requests to same backend | Hash consistency verification |\n\nBackend health checking tests use **controlled failure injection** to simulate network timeouts, connection refused errors, and slow response scenarios. Tests advance mock timers to trigger health check intervals without waiting for real time to pass.\n\n**Cache Engine Unit Testing Strategy:**\n\nCache testing requires careful attention to timing precision and memory management. Tests must verify cache-control header parsing, TTL calculations, LRU eviction behavior, and concurrent access patterns across multiple threads.\n\n| Cache Operation | Test Scenarios | Cache State Verification |\n|----------------|---------------|-------------------------|\n| `cache_engine_lookup` | Hit, miss, expired entry | Verify `CacheEntry` retrieval |\n| `cache_engine_store` | Cacheable, non-cacheable responses | Check `CacheStats` updates |\n| `lru_list_move_to_head` | Access existing entry | Verify LRU order maintenance |\n| `cache_control_parse` | Various Cache-Control directives | Validate `CacheControl` structure |\n| Cache eviction | Fill cache beyond size limit | Verify LRU entry removal |\n| TTL expiration | Advance mock time | Verify expired entry cleanup |\n\nCache tests use **deterministic time mocking** to control TTL calculations and expiration behavior. Mock time functions replace system calls to `time()` and `clock_gettime()`, allowing tests to \"fast forward\" through cache lifetimes without actual delays.\n\n**SSL Termination Unit Testing Strategy:**\n\nSSL component testing requires sophisticated OpenSSL mocking since real certificate operations involve file system access and cryptographic computations. Tests focus on certificate loading, SNI callback behavior, and TLS context management.\n\n| SSL Function | Mock Strategy | Test Focus |\n|-------------|---------------|------------|\n| `ssl_utils_load_certificate` | Mock certificate file content | Verify `CertificateInfo` parsing |\n| `ssl_termination_sni_callback` | Mock SNI hostnames | Test context selection logic |\n| `ssl_utils_verify_key_cert_match` | Controlled key/cert pairs | Verify cryptographic validation |\n| Certificate reload | Mock file system notifications | Test dynamic certificate updates |\n\nSSL tests use **synthetic certificates** generated at test startup rather than loading real certificate files. This approach eliminates file system dependencies while providing controlled certificate properties for testing edge cases.\n\n⚠️ **Pitfall: Testing with Real Network I/O**\nMany developers attempt to test connection manager logic using actual TCP sockets and network communication. This approach introduces non-deterministic timing behavior, makes tests fragile to network conditions, and requires complex test environment setup. Instead, use mock file descriptors and synthetic events that provide deterministic, controllable test conditions.\n\n⚠️ **Pitfall: Ignoring Parser State Persistence**\nHTTP parser tests often focus only on complete, well-formed messages without testing incremental parsing behavior. Real network traffic arrives in arbitrary packet boundaries, so tests must verify that parser state correctly persists across multiple `http_parser_process` calls with fragmented input data.\n\n### Integration Testing\n\nIntegration testing validates the **orchestration** between components, ensuring that data flows correctly through the complete request processing pipeline. Think of integration testing as rehearsing sections of our orchestra together - we need to verify that when the violins finish their phrase, the brass section enters at precisely the right moment with the correct dynamics.\n\nIntegration tests operate at the **component boundary level**, using real implementations for the components under test while carefully controlling their external dependencies. Unlike unit tests that isolate individual functions, integration tests verify that components correctly implement their **interface contracts** and handle the asynchronous message passing that coordinates request processing.\n\n**Parser-Connection Manager Integration:**\n\nThe integration between `HttpParser` and `ConnectionManager` centers on the **stream-based parsing contract**. The connection manager feeds incoming network data to the parser incrementally, while the parser signals completion states that drive connection state transitions.\n\n| Integration Scenario | Test Setup | Validation Points |\n|---------------------|------------|------------------|\n| Complete request parsing | Send well-formed HTTP request | Verify `HTTP_PARSING_COMPLETE` triggers backend forwarding |\n| Partial request arrival | Send request in multiple fragments | Verify parser maintains state across `connection_manager_handle_event` calls |\n| Parse error handling | Send malformed HTTP data | Verify connection transitions to `CONNECTION_CLOSING` |\n| Keep-alive detection | Send `Connection: keep-alive` header | Verify connection remains in pool after response |\n| Pipeline request handling | Send multiple pipelined requests | Verify correct request boundary detection |\n\nThe test harness uses **mock TCP streams** that deliver data at controlled intervals, simulating realistic network packet arrival patterns. Tests verify that connection state transitions occur at precisely the correct moments relative to parser state changes.\n\n```c\n// Integration test data structure for controlled packet delivery\ntypedef struct {\n    char* packet_data;\n    size_t packet_size;\n    int delivery_delay_ms;\n    bool should_trigger_event;\n} MockPacket;\n\ntypedef struct {\n    MockPacket* packets;\n    size_t packet_count;\n    size_t current_packet;\n    ConnectionManager* conn_mgr;\n    HttpParser* parser;\n} ParserConnectionIntegrationTest;\n```\n\n**Load Balancer-Connection Manager Integration:**\n\nThis integration validates the **backend selection and connection acquisition workflow**. The load balancer selects an appropriate backend server, while the connection manager either reuses an existing pooled connection or establishes a new connection to that backend.\n\n| Integration Workflow | Test Configuration | Validation Criteria |\n|---------------------|------------------|-------------------|\n| Backend selection with pool hit | 3 backends, existing pooled connections | Verify `connection_manager_acquire_backend` reuses connection |\n| Backend selection with pool miss | Backends with empty connection pools | Verify new connection establishment |\n| Backend failure during acquisition | Temporarily unreachable backend | Verify failover to alternate backend |\n| Health check triggered pool eviction | Backend marked unhealthy | Verify pooled connections removed |\n| Weighted selection with pool status | Different pool utilization per backend | Verify selection considers both weight and availability |\n\nIntegration tests use **network namespace isolation** to simulate backend server behavior without requiring actual backend processes. Test backends respond with predictable HTTP responses and can be configured to simulate various failure modes.\n\n**Cache Engine-HTTP Parser Integration:**\n\nCache integration testing verifies **conditional request generation** and **cache-control header interpretation**. The cache engine must correctly parse HTTP headers to determine cacheability, generate appropriate cache keys, and create conditional requests for cache validation.\n\n| Cache Integration Scenario | Request Properties | Expected Cache Behavior |\n|----------------------------|------------------|------------------------|\n| Fresh cache hit | Cached response within TTL | Return cached response without backend query |\n| Stale cache validation | Cached response beyond TTL with ETag | Generate `If-None-Match` conditional request |\n| Cache miss | No cached entry for request | Forward to backend and cache response |\n| Non-cacheable response | Response with `Cache-Control: no-store` | Forward response without caching |\n| Vary header handling | Response with `Vary: Accept-Encoding` | Include Accept-Encoding in cache key |\n\nCache integration tests use **mock HTTP responses** with controlled cache-control headers and known ETags. Tests verify that cache key generation produces consistent results and that conditional requests contain the correct validation headers.\n\n**SSL Termination-Connection Manager Integration:**\n\nSSL integration testing focuses on the **TLS handshake coordination** and the **transition from encrypted client communication to plaintext backend forwarding**. This integration is particularly complex due to the asynchronous nature of TLS handshake processing.\n\n| SSL Integration Case | TLS Configuration | Validation Points |\n|---------------------|------------------|------------------|\n| Successful handshake | Valid certificate, strong ciphers | Verify plaintext HTTP extraction |\n| SNI-based certificate selection | Multiple certificates loaded | Verify correct certificate chosen |\n| Client certificate validation | Mutual TLS configuration | Verify client certificate verification |\n| TLS handshake failure | Invalid certificate configuration | Verify graceful connection termination |\n| Mixed HTTP/HTTPS handling | Both ports listening | Verify protocol-appropriate handling |\n\nSSL integration tests use **self-signed test certificates** generated during test setup with known properties. Tests simulate various client TLS implementations to verify compatibility across different TLS library versions and cipher suite preferences.\n\n**End-to-End Request Flow Integration:**\n\nThe most comprehensive integration tests trace **complete request processing pipelines** that exercise all major components in realistic sequences. These tests simulate actual reverse proxy usage patterns with multiple concurrent clients and backend servers.\n\n| End-to-End Scenario | Test Configuration | Component Interactions |\n|---------------------|------------------|----------------------|\n| Cached response serving | Cache hit with fresh entry | SSL → Parser → Cache (hit) → Response |\n| Load-balanced backend request | Cache miss, multiple backends | SSL → Parser → Cache (miss) → LB → Backend → Response |\n| Backend failover with retry | Primary backend failure | SSL → Parser → LB → Failure → LB (retry) → Backend → Response |\n| SSL certificate reload | Certificate update during traffic | SSL (reload) → Continue serving with new cert |\n| Connection pooling optimization | Multiple requests to same backend | Verify connection reuse across requests |\n\nEnd-to-end tests use **docker-compose environments** with real backend HTTP servers, allowing tests to verify behavior against actual HTTP implementations rather than mocks. This approach catches integration issues that might be missed with entirely synthetic test environments.\n\n⚠️ **Pitfall: Over-Mocking in Integration Tests**\nIntegration tests lose their value when too many components are mocked. The goal is to test real component interactions, so only external dependencies (like actual network calls) should be mocked. Using real component implementations reveals interface mismatches and timing issues that unit tests cannot detect.\n\n⚠️ **Pitfall: Ignoring Asynchronous Timing**\nMany integration test failures occur due to race conditions between components that communicate asynchronously. Tests must either use synchronization primitives to control component interaction timing or employ polling strategies that wait for expected state changes rather than assuming immediate completion.\n\n### Milestone Verification Checkpoints\n\nMilestone checkpoints provide **concrete validation criteria** that confirm each phase of implementation meets functional requirements before proceeding to the next milestone. Think of these checkpoints as **integration rehearsals** where we verify that newly implemented functionality works correctly both in isolation and in combination with previously completed components.\n\nEach milestone checkpoint includes **automated test suites**, **manual verification procedures**, and **performance benchmarks** that validate both correctness and basic performance characteristics. The checkpoints are designed to catch integration issues early, before they compound with additional complexity from subsequent milestones.\n\n**Milestone 1: HTTP Proxy Core Verification**\n\nThe HTTP proxy core checkpoint validates basic request forwarding functionality without load balancing, caching, or SSL termination. This foundational milestone must demonstrate rock-solid HTTP protocol handling and connection management before adding additional complexity.\n\n| Verification Area | Test Method | Success Criteria |\n|------------------|-------------|------------------|\n| HTTP/1.1 request forwarding | Automated test suite | 100% of well-formed requests forwarded correctly |\n| HTTP header preservation | Header comparison tests | All client headers preserved in backend requests |\n| Response body integrity | Binary content verification | Byte-for-byte response accuracy |\n| Connection state management | Connection lifecycle tests | No resource leaks after 1000 requests |\n| Error handling | Malformed request tests | Appropriate error responses for invalid input |\n| Keep-alive support | Connection reuse verification | Multiple requests over single client connection |\n\n**Automated Test Commands:**\n```bash\n# Run core HTTP proxy tests\nmake test-milestone-1\n./test/integration/http_proxy_core_test\n\n# Performance baseline test\n./test/performance/proxy_benchmark -requests=1000 -concurrency=10\n```\n\n**Manual Verification Procedures:**\nThe manual verification uses `curl` commands to test realistic usage scenarios that automated tests might miss:\n\n1. **Basic Request Forwarding Test:**\n   - Start proxy server: `./reverse_proxy -config=test.conf -backends=localhost:8080`\n   - Start test backend: `python3 -m http.server 8080`\n   - Test GET request: `curl -v http://localhost:3128/test.html`\n   - Verify response matches direct backend access\n   - Check proxy logs show request forwarding\n\n2. **Header Manipulation Verification:**\n   - Send request with custom headers: `curl -H \"X-Test: value\" http://localhost:3128/`\n   - Verify backend receives `X-Forwarded-For` and `Via` headers\n   - Confirm custom client headers preserved\n\n3. **HTTP Method Support:**\n   - Test POST: `curl -X POST -d \"data\" http://localhost:3128/api/test`\n   - Test PUT: `curl -X PUT -d @file.json http://localhost:3128/upload`\n   - Test DELETE: `curl -X DELETE http://localhost:3128/resource/123`\n\n4. **Error Condition Handling:**\n   - Stop backend server, verify 502 Bad Gateway response\n   - Send oversized request, verify 413 Request Entity Too Large\n   - Send malformed HTTP, verify connection closes gracefully\n\n**Expected Performance Baseline:**\n- **Throughput:** 1,000 requests/second with 10 concurrent connections\n- **Latency:** 95th percentile under 10ms for localhost backends\n- **Memory Usage:** Stable under 50MB resident memory after 10,000 requests\n- **Connection Handling:** Support at least 100 concurrent client connections\n\n⚠️ **Milestone 1 Common Issues:**\n- **Incomplete response forwarding:** Verify both headers and body are completely transmitted\n- **Connection hang on backend failure:** Ensure timeouts are implemented for backend connections\n- **Memory leaks in request processing:** Use valgrind to detect buffer management issues\n\n**Milestone 2: Load Balancing Verification**\n\nLoad balancing verification confirms correct request distribution across multiple backend servers and validates health checking behavior under various failure scenarios.\n\n| Load Balancing Feature | Test Method | Success Criteria |\n|----------------------|-------------|------------------|\n| Round-robin distribution | Statistical analysis | Even distribution within 5% variance |\n| Least-connections algorithm | Connection count tracking | Requests routed to least busy backend |\n| Backend health checking | Controlled backend failures | Unhealthy backends removed within 30 seconds |\n| Failover behavior | Sequential backend shutdown | Traffic redirected without client errors |\n| Dynamic backend updates | Configuration reload | New backends available without restart |\n| Weighted distribution | Capacity-based routing | Traffic distributed per weight ratios |\n\n**Automated Test Commands:**\n```bash\n# Run load balancing test suite\nmake test-milestone-2\n./test/integration/load_balancer_test\n\n# Multi-backend stress test\n./test/load/multi_backend_test -backends=3 -requests=5000\n```\n\n**Manual Verification Procedures:**\n\n1. **Round-Robin Distribution Test:**\n   - Configure 3 backend servers on ports 8080, 8081, 8082\n   - Send 30 requests: `for i in {1..30}; do curl http://localhost:3128/; done`\n   - Check backend logs: each should receive ~10 requests\n   - Verify request distribution is approximately even\n\n2. **Health Check Validation:**\n   - Start proxy with health checking enabled (30-second intervals)\n   - Stop one backend server: `kill $BACKEND_PID`\n   - Send requests and verify traffic routes only to healthy backends\n   - Restart backend and verify it rejoins rotation\n\n3. **Weighted Load Balancing:**\n   - Configure backends with weights 1:2:3\n   - Send 60 requests and verify distribution: 10/20/30\n   - Monitor `LoadBalancer` metrics for weight compliance\n\n4. **Least-Connections Algorithm:**\n   - Configure least-connections mode\n   - Establish persistent connections to backends (different counts)\n   - Send new requests and verify routing to least busy backend\n\n**Backend Health Check Configuration:**\n```ini\n# test.conf load balancing section\n[load_balancer]\nalgorithm = round_robin\nhealth_check_interval = 30\nhealth_check_timeout = 5\nfailure_threshold = 3\nsuccess_threshold = 2\n\n[backends]\nbackend1 = host=localhost port=8080 weight=1\nbackend2 = host=localhost port=8081 weight=2  \nbackend3 = host=localhost port=8082 weight=3\n```\n\n⚠️ **Milestone 2 Common Issues:**\n- **Sticky connections disrupting distribution:** Ensure connection pooling doesn't bias routing\n- **Health check false positives:** Verify health check timeout values are appropriate for network conditions\n- **Race conditions in backend selection:** Check thread safety of backend state updates\n\n**Milestone 3: Connection Pooling Verification**\n\nConnection pooling checkpoint validates backend connection reuse, proper pool size management, and connection lifecycle handling under various load patterns.\n\n| Connection Pool Feature | Test Method | Success Criteria |\n|------------------------|-------------|------------------|\n| Connection reuse | Pool utilization metrics | >80% connection reuse rate |\n| Pool size limits | Concurrent connection test | Pool never exceeds configured maximum |\n| Idle timeout handling | Connection aging test | Stale connections removed within timeout |\n| Pool exhaustion handling | High concurrency test | Graceful handling when pool full |\n| Health integration | Backend failure simulation | Broken connections purged from pool |\n| Per-backend isolation | Multi-backend pool test | Separate pools maintained per backend |\n\n**Automated Test Commands:**\n```bash\n# Run connection pooling test suite  \nmake test-milestone-3\n./test/integration/connection_pool_test\n\n# Pool exhaustion stress test\n./test/stress/pool_exhaustion_test -max_pools=100 -concurrent=500\n```\n\n**Manual Verification Procedures:**\n\n1. **Connection Reuse Validation:**\n   - Configure small pool size (max 5 connections per backend)\n   - Send 50 sequential requests to same backend\n   - Monitor pool metrics: should show high reuse percentage\n   - Check backend: should see only 5 TCP connections established\n\n2. **Pool Limit Enforcement:**\n   - Configure pool with max_connections=3\n   - Generate 10 concurrent requests\n   - Verify only 3 backend connections established\n   - Additional requests should queue or use alternate backends\n\n3. **Idle Timeout Testing:**\n   - Send requests to establish pooled connections\n   - Wait for idle_timeout period (configured in test.conf)\n   - Send new request and verify fresh connection establishment\n   - Check pool metrics show connection eviction occurred\n\n4. **Pool Health Integration:**\n   - Establish connections in pool\n   - Force backend restart (simulates network partition)\n   - Verify broken connections detected and removed\n   - New requests should establish fresh connections\n\n**Connection Pool Metrics to Monitor:**\n```c\n// Expected pool statistics after testing\ntypedef struct {\n    size_t total_connections_created;    // Should be minimized via reuse\n    size_t current_active_connections;   // Should stay within limits\n    size_t current_idle_connections;     // Should reflect pool utilization\n    uint64_t connection_reuse_count;     // Should be high relative to requests\n    uint64_t pool_exhaustion_events;     // Should be zero under normal load\n    time_t last_cleanup_time;            // Should advance with idle timeouts\n} PoolMetrics;\n```\n\n⚠️ **Milestone 3 Common Issues:**\n- **Connection leaks:** Ensure connections are properly returned to pool after request completion\n- **Deadlocks in pool access:** Verify thread-safe pool operations under high concurrency\n- **Stale connection reuse:** Implement connection validation before reuse from pool\n\n**Milestone 4: Caching Verification**\n\nCaching verification confirms correct HTTP caching behavior, cache-control header compliance, and cache performance characteristics under various response types and cache sizes.\n\n| Cache Feature | Test Method | Success Criteria |\n|--------------|-------------|------------------|\n| Cache hit serving | Duplicate request test | Second request served from cache |\n| TTL expiration | Time-based cache test | Expired entries trigger backend requests |\n| Cache-Control compliance | Header parsing test | `no-cache`, `no-store` directives respected |\n| ETag validation | Conditional request test | `If-None-Match` requests generate 304 responses |\n| LRU eviction | Cache overflow test | Oldest entries evicted when cache full |\n| Vary header handling | Content negotiation test | Accept-Encoding included in cache keys |\n\n**Automated Test Commands:**\n```bash\n# Run caching test suite\nmake test-milestone-4  \n./test/integration/cache_engine_test\n\n# Cache performance benchmark\n./test/performance/cache_benchmark -cache_size=100MB -requests=10000\n```\n\n**Manual Verification Procedures:**\n\n1. **Basic Cache Hit Testing:**\n   - Clear cache: `curl -X DELETE http://localhost:3128/admin/cache`\n   - Send request: `curl -v http://localhost:3128/static/image.jpg`\n   - Note backend access in logs and response headers\n   - Repeat request: should show cache hit with `X-Cache-Status: HIT`\n\n2. **Cache-Control Compliance:**\n   - Test cacheable response: `curl http://localhost:3128/api/data` (with `Cache-Control: max-age=300`)\n   - Test non-cacheable: `curl http://localhost:3128/api/user` (with `Cache-Control: no-store`)\n   - Verify only first response gets cached\n\n3. **TTL Expiration Validation:**\n   - Configure short TTL in test backend responses (`max-age=5`)\n   - Send request and verify cache storage\n   - Wait 10 seconds, repeat request\n   - Verify backend access occurs due to expiration\n\n4. **Conditional Request Testing:**\n   - Send request to backend that supports ETags\n   - Verify cache stores ETag value\n   - After expiration, verify proxy sends `If-None-Match`\n   - Backend should respond with 304, cache should serve original response\n\n**Cache Metrics Validation:**\n```c\n// Expected cache statistics after testing\ntypedef struct {\n    uint64_t hit_count;          // Should increase with duplicate requests  \n    uint64_t miss_count;         // Should equal unique cacheable requests\n    uint64_t eviction_count;     // Should remain low until cache full\n    size_t current_size;         // Should not exceed configured limit\n    double hit_ratio;            // Should be >50% with duplicate requests\n} CachePerformanceMetrics;\n```\n\n⚠️ **Milestone 4 Common Issues:**\n- **Caching non-cacheable responses:** Verify POST requests and private responses excluded\n- **Incorrect cache key generation:** Ensure Vary headers properly included in cache keys\n- **Memory leaks in cache entries:** Verify proper cleanup of evicted cache entries\n\n**Milestone 5: SSL Termination Verification**\n\nSSL termination checkpoint validates HTTPS request handling, certificate management, SNI support, and the transition from encrypted client connections to plaintext backend communication.\n\n| SSL Feature | Test Method | Success Criteria |\n|------------|-------------|------------------|\n| TLS handshake completion | HTTPS client test | Successful connection establishment |\n| Certificate validation | Certificate chain test | Valid certificates accepted, invalid rejected |\n| SNI hostname selection | Multi-domain test | Correct certificate chosen per hostname |\n| Cipher suite negotiation | TLS compatibility test | Strong ciphers preferred, weak ciphers rejected |\n| HTTP to HTTPS redirect | Mixed protocol test | HTTP requests redirected to HTTPS |\n| Certificate reload | Dynamic cert update | New certificates loaded without restart |\n\n**Automated Test Commands:**\n```bash\n# Run SSL termination test suite\nmake test-milestone-5\n./test/integration/ssl_termination_test\n\n# SSL compatibility test across TLS versions  \n./test/ssl/tls_compatibility_test -min_version=TLS1.2\n```\n\n**Manual Verification Procedures:**\n\n1. **Basic HTTPS Request Processing:**\n   - Generate test certificate: `openssl req -x509 -newkey rsa:2048 -keyout test.key -out test.crt`\n   - Configure SSL termination with test certificate\n   - Test HTTPS request: `curl -k https://localhost:3129/test.html`\n   - Verify response received and backend accessed via HTTP\n\n2. **SNI Multi-Domain Testing:**\n   - Configure certificates for multiple domains\n   - Test domain1: `curl -k --resolve domain1.test:3129:127.0.0.1 https://domain1.test:3129/`\n   - Test domain2: `curl -k --resolve domain2.test:3129:127.0.0.1 https://domain2.test:3129/`\n   - Verify correct certificates selected via OpenSSL inspection\n\n3. **TLS Version and Cipher Validation:**\n   - Test minimum TLS version: `curl --tlsv1.2 -k https://localhost:3129/`\n   - Verify weak TLS rejected: `curl --tlsv1.0 https://localhost:3129/` (should fail)\n   - Check cipher selection: `openssl s_client -connect localhost:3129 -cipher HIGH`\n\n4. **Certificate Reload Testing:**\n   - Start proxy with initial certificate\n   - Update certificate files on disk\n   - Send reload signal or API call\n   - Verify new certificate used for subsequent connections\n\n**SSL Configuration Validation:**\n```ini\n# test.conf SSL section\n[ssl]  \nenabled = true\ncert_path = /etc/ssl/test.crt\nkey_path = /etc/ssl/test.key\nmin_tls_version = TLS_1_2\ncipher_list = ECDHE+AESGCM:ECDHE+CHACHA20:DHE+AESGCM:DHE+CHACHA20:!aNULL:!MD5:!DSS\n```\n\n**SSL Metrics to Monitor:**\n```c\n// SSL termination performance statistics\ntypedef struct {\n    uint64_t handshakes_completed;       // Should equal HTTPS requests\n    uint64_t handshake_failures;         // Should remain low\n    uint64_t certificate_reloads;        // Should match reload operations\n    double avg_handshake_time_ms;        // Should be <100ms for RSA certificates\n    uint32_t active_ssl_connections;     // Should not exceed connection limits\n} SSLTerminationMetrics;\n```\n\n⚠️ **Milestone 5 Common Issues:**\n- **Certificate/key mismatch:** Verify certificate and private key correspond via OpenSSL\n- **Weak cipher acceptance:** Ensure cipher suite configuration rejects deprecated algorithms\n- **Memory leaks in SSL contexts:** Properly cleanup SSL_CTX structures during certificate reload\n\n### Implementation Guidance\n\nThe testing strategy implementation requires careful coordination between test frameworks, mock systems, and build automation. The following guidance provides concrete tools and patterns for implementing the testing approach described above.\n\n**A. Technology Recommendations:**\n\n| Testing Component | Simple Option | Advanced Option |\n|------------------|---------------|-----------------|\n| Unit Test Framework | Custom assert macros with C | Google Test (C++) or Unity (C) |\n| Mock System | Manual dependency injection | CMock or FFF (Fake Function Framework) |\n| Integration Testing | Custom test harnesses | Testcontainers with Docker |\n| HTTP Test Clients | curl + shell scripts | Custom HTTP client library |\n| Performance Testing | Simple timing loops | wrk or Apache Bench (ab) |\n| SSL Testing | OpenSSL command line tools | custom SSL test client |\n\n**B. Recommended File Structure:**\n\n```\nreverse-proxy/\n├── src/                           # Source code\n│   ├── http_parser/\n│   ├── connection_manager/ \n│   ├── load_balancer/\n│   ├── cache_engine/\n│   └── ssl_termination/\n├── test/                          # All testing code\n│   ├── unit/                      # Unit tests\n│   │   ├── test_http_parser.c\n│   │   ├── test_connection_manager.c\n│   │   ├── test_load_balancer.c\n│   │   ├── test_cache_engine.c\n│   │   └── test_ssl_termination.c\n│   ├── integration/               # Integration tests\n│   │   ├── test_parser_connection.c\n│   │   ├── test_lb_connection.c\n│   │   ├── test_cache_integration.c\n│   │   └── test_ssl_integration.c\n│   ├── milestone/                 # Milestone checkpoints\n│   │   ├── milestone1_http_core.c\n│   │   ├── milestone2_load_balancing.c\n│   │   ├── milestone3_connection_pooling.c\n│   │   ├── milestone4_caching.c\n│   │   └── milestone5_ssl_termination.c\n│   ├── mocks/                     # Mock implementations\n│   │   ├── mock_network.c\n│   │   ├── mock_timer.c\n│   │   └── mock_ssl.c\n│   ├── fixtures/                  # Test data and configurations\n│   │   ├── test_certificates/\n│   │   ├── sample_http_requests/\n│   │   └── test_configs/\n│   └── scripts/                   # Test automation\n│       ├── run_unit_tests.sh\n│       ├── run_integration_tests.sh\n│       └── milestone_verification.sh\n├── tools/                         # Development tools\n│   ├── test_http_server.c         # Simple backend for testing\n│   └── ssl_cert_generator.sh      # Generate test certificates\n└── Makefile                       # Build and test automation\n```\n\n**C. Infrastructure Starter Code (COMPLETE):**\n\n**Mock Network Interface (`test/mocks/mock_network.c`):**\n```c\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include \"mock_network.h\"\n\n// Mock network implementation for testing without real sockets\ntypedef struct {\n    char* buffer_data;\n    size_t buffer_size;\n    size_t read_position;\n    size_t write_position;\n    bool closed;\n    int mock_errno;\n} MockSocket;\n\nstatic MockSocket* mock_sockets[1024] = {0};\nstatic int next_mock_fd = 1000;\n\nint mock_socket_create(size_t buffer_size) {\n    int fd = next_mock_fd++;\n    MockSocket* sock = malloc(sizeof(MockSocket));\n    sock->buffer_data = malloc(buffer_size);\n    sock->buffer_size = buffer_size;\n    sock->read_position = 0;\n    sock->write_position = 0;\n    sock->closed = false;\n    sock->mock_errno = 0;\n    mock_sockets[fd - 1000] = sock;\n    return fd;\n}\n\nssize_t mock_read(int fd, void* buf, size_t count) {\n    MockSocket* sock = mock_sockets[fd - 1000];\n    if (!sock || sock->closed) {\n        errno = EBADF;\n        return -1;\n    }\n    \n    if (sock->mock_errno != 0) {\n        errno = sock->mock_errno;\n        return -1;\n    }\n    \n    size_t available = sock->write_position - sock->read_position;\n    size_t to_read = (count < available) ? count : available;\n    \n    if (to_read == 0) {\n        errno = EAGAIN;\n        return -1;\n    }\n    \n    memcpy(buf, sock->buffer_data + sock->read_position, to_read);\n    sock->read_position += to_read;\n    return to_read;\n}\n\nssize_t mock_write(int fd, const void* buf, size_t count) {\n    MockSocket* sock = mock_sockets[fd - 1000];\n    if (!sock || sock->closed) {\n        errno = EBADF;\n        return -1;\n    }\n    \n    if (sock->mock_errno != 0) {\n        errno = sock->mock_errno;\n        return -1;\n    }\n    \n    size_t available = sock->buffer_size - sock->write_position;\n    size_t to_write = (count < available) ? count : available;\n    \n    if (to_write == 0) {\n        errno = EAGAIN;\n        return -1;\n    }\n    \n    memcpy(sock->buffer_data + sock->write_position, buf, to_write);\n    sock->write_position += to_write;\n    return to_write;\n}\n\nvoid mock_socket_inject_data(int fd, const char* data, size_t size) {\n    MockSocket* sock = mock_sockets[fd - 1000];\n    if (sock && sock->write_position + size <= sock->buffer_size) {\n        memcpy(sock->buffer_data + sock->write_position, data, size);\n        sock->write_position += size;\n    }\n}\n\nvoid mock_socket_set_error(int fd, int error_code) {\n    MockSocket* sock = mock_sockets[fd - 1000];\n    if (sock) {\n        sock->mock_errno = error_code;\n    }\n}\n\nvoid mock_socket_close(int fd) {\n    MockSocket* sock = mock_sockets[fd - 1000];\n    if (sock) {\n        sock->closed = true;\n        free(sock->buffer_data);\n        free(sock);\n        mock_sockets[fd - 1000] = NULL;\n    }\n}\n```\n\n**Test HTTP Server (`tools/test_http_server.c`):**\n```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n#include <signal.h>\n#include <time.h>\n\n// Simple HTTP server for integration testing\ntypedef struct {\n    int port;\n    int delay_ms;\n    char* response_body;\n    char* custom_headers;\n    bool should_fail;\n} TestServerConfig;\n\nstatic volatile bool server_running = true;\n\nvoid signal_handler(int sig) {\n    server_running = false;\n    printf(\"Test server shutting down...\\n\");\n}\n\nvoid send_http_response(int client_fd, TestServerConfig* config) {\n    char response[4096];\n    time_t now = time(NULL);\n    \n    if (config->should_fail) {\n        // Simulate server error\n        close(client_fd);\n        return;\n    }\n    \n    if (config->delay_ms > 0) {\n        usleep(config->delay_ms * 1000);\n    }\n    \n    snprintf(response, sizeof(response),\n        \"HTTP/1.1 200 OK\\r\\n\"\n        \"Content-Type: text/plain\\r\\n\"\n        \"Content-Length: %zu\\r\\n\"\n        \"Cache-Control: max-age=300\\r\\n\"\n        \"ETag: \\\"test-etag-%ld\\\"\\r\\n\"\n        \"%s\"\n        \"\\r\\n\"\n        \"%s\",\n        strlen(config->response_body),\n        now,\n        config->custom_headers ? config->custom_headers : \"\",\n        config->response_body\n    );\n    \n    send(client_fd, response, strlen(response), 0);\n    close(client_fd);\n}\n\nint main(int argc, char* argv[]) {\n    TestServerConfig config = {\n        .port = 8080,\n        .delay_ms = 0,\n        .response_body = \"Test server response\",\n        .custom_headers = NULL,\n        .should_fail = false\n    };\n    \n    // Parse command line arguments\n    for (int i = 1; i < argc; i++) {\n        if (strncmp(argv[i], \"--port=\", 7) == 0) {\n            config.port = atoi(argv[i] + 7);\n        } else if (strncmp(argv[i], \"--delay=\", 8) == 0) {\n            config.delay_ms = atoi(argv[i] + 8);\n        } else if (strncmp(argv[i], \"--fail\", 6) == 0) {\n            config.should_fail = true;\n        }\n    }\n    \n    signal(SIGINT, signal_handler);\n    signal(SIGTERM, signal_handler);\n    \n    int server_fd = socket(AF_INET, SOCK_STREAM, 0);\n    int opt = 1;\n    setsockopt(server_fd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));\n    \n    struct sockaddr_in address = {0};\n    address.sin_family = AF_INET;\n    address.sin_addr.s_addr = INADDR_ANY;\n    address.sin_port = htons(config.port);\n    \n    bind(server_fd, (struct sockaddr*)&address, sizeof(address));\n    listen(server_fd, 10);\n    \n    printf(\"Test HTTP server listening on port %d\\n\", config.port);\n    \n    while (server_running) {\n        fd_set read_fds;\n        FD_ZERO(&read_fds);\n        FD_SET(server_fd, &read_fds);\n        \n        struct timeval timeout = {.tv_sec = 1, .tv_usec = 0};\n        int activity = select(server_fd + 1, &read_fds, NULL, NULL, &timeout);\n        \n        if (activity > 0 && FD_ISSET(server_fd, &read_fds)) {\n            int client_fd = accept(server_fd, NULL, NULL);\n            if (client_fd >= 0) {\n                char buffer[1024];\n                recv(client_fd, buffer, sizeof(buffer), 0); // Read request\n                send_http_response(client_fd, &config);\n            }\n        }\n    }\n    \n    close(server_fd);\n    return 0;\n}\n```\n\n**D. Core Logic Skeleton Code:**\n\n**Unit Test Template (`test/unit/test_http_parser.c`):**\n```c\n#include \"http_parser.h\"\n#include \"test_framework.h\"\n\n// HTTP Parser unit test template\nvoid test_http_parser_request_line_parsing() {\n    // TODO 1: Create HttpParser instance using http_parser_create()\n    // TODO 2: Prepare test input: \"GET /path HTTP/1.1\\r\\n\"\n    // TODO 3: Call http_parser_process() with test input\n    // TODO 4: Verify parser state transitions to HTTP_PARSING_HEADERS\n    // TODO 5: Verify HttpRequest fields populated correctly (method, uri, version)\n    // TODO 6: Clean up parser and request structures\n    // Hint: Use mock_socket_inject_data() for controlled input delivery\n}\n\nvoid test_http_parser_chunked_encoding() {\n    // TODO 1: Create parser and prepare chunked request body\n    // TODO 2: Process input incrementally: \"5\\r\\nhello\\r\\n0\\r\\n\\r\\n\"  \n    // TODO 3: Verify state transitions: BODY -> CHUNKED_SIZE -> CHUNKED_DATA -> COMPLETE\n    // TODO 4: Verify assembled body contains \"hello\" without chunk markers\n    // TODO 5: Verify Content-Length calculation matches actual body\n    // Hint: Test partial delivery of chunk size and data separately\n}\n\nvoid test_http_parser_malformed_input() {\n    // TODO 1: Create parser and prepare invalid HTTP input\n    // TODO 2: Test cases: invalid method, malformed headers, oversized requests\n    // TODO 3: Verify parser transitions to HTTP_PARSING_ERROR state\n    // TODO 4: Verify error handling doesn't crash or leak memory\n    // TODO 5: Verify parser can be reset and reused after errors\n    // Hint: Use valgrind to detect memory leaks in error paths\n}\n\nint main() {\n    test_http_parser_request_line_parsing();\n    test_http_parser_chunked_encoding();\n    test_http_parser_malformed_input();\n    \n    printf(\"HTTP Parser unit tests completed\\n\");\n    return 0;\n}\n```\n\n**Integration Test Template (`test/integration/test_cache_integration.c`):**\n```c\n#include \"cache_engine.h\"\n#include \"http_parser.h\"\n#include \"test_framework.h\"\n\n// Cache Engine integration test template\nvoid test_cache_conditional_request_generation() {\n    // TODO 1: Create CacheEngine and populate with test response (with ETag)\n    // TODO 2: Create new HttpRequest for same resource after TTL expiry\n    // TODO 3: Call cache_engine_lookup() and verify it returns stale entry\n    // TODO 4: Verify cache_create_conditional() generates If-None-Match header\n    // TODO 5: Simulate 304 Not Modified response from backend\n    // TODO 6: Verify cache_update_from_304() refreshes entry TTL\n    // Hint: Use mock time functions to control TTL calculations\n}\n\nvoid test_cache_vary_header_handling() {\n    // TODO 1: Create responses with \"Vary: Accept-Encoding\" header\n    // TODO 2: Store responses for same URL with different Accept-Encoding values\n    // TODO 3: Verify cache_generate_key() includes Accept-Encoding in key\n    // TODO 4: Verify cache lookups return correct response for each encoding\n    // TODO 5: Verify cache doesn't serve gzip response for non-gzip request\n    // Hint: Test with \"gzip, deflate\" vs \"identity\" Accept-Encoding values\n}\n\nvoid test_cache_size_limit_enforcement() {\n    // TODO 1: Create CacheEngine with small size limit (e.g., 1MB)\n    // TODO 2: Store responses until cache size approaches limit\n    // TODO 3: Store additional response that exceeds limit\n    // TODO 4: Verify LRU eviction removes oldest entries\n    // TODO 5: Verify cache size stays within configured limit\n    // TODO 6: Verify evicted entries are completely cleaned up\n    // Hint: Monitor cache_engine_stats() for size and eviction metrics\n}\n\nint main() {\n    test_cache_conditional_request_generation();\n    test_cache_vary_header_handling(); \n    test_cache_size_limit_enforcement();\n    \n    printf(\"Cache Engine integration tests completed\\n\");\n    return 0;\n}\n```\n\n**E. Language-Specific Hints:**\n\n**C Development Tips:**\n- Use `valgrind --leak-check=full` to detect memory leaks in connection pooling\n- Use `gdb` with breakpoints to debug state machine transitions\n- Compile with `-fsanitize=address` to detect buffer overflows\n- Use `strace` to monitor actual system calls during network testing\n- Use `tcpdump` to capture real network traffic for integration verification\n\n**Mock Time Management:**\n```c\n// Override system time functions for deterministic testing\nstatic time_t mock_current_time = 1640995200; // 2022-01-01 00:00:00\n\ntime_t time(time_t* tloc) {\n    if (tloc) *tloc = mock_current_time;\n    return mock_current_time;\n}\n\nvoid advance_mock_time(time_t seconds) {\n    mock_current_time += seconds;\n}\n```\n\n**Thread Safety Testing:**\n```c\n// Use pthread barriers to synchronize test threads\npthread_barrier_t test_barrier;\n\nvoid setup_concurrent_test(int thread_count) {\n    pthread_barrier_init(&test_barrier, NULL, thread_count + 1);\n}\n\nvoid wait_for_threads() {\n    pthread_barrier_wait(&test_barrier); // All threads start simultaneously\n}\n```\n\n**F. Milestone Checkpoint Implementation:**\n\n**Milestone 1 Checkpoint Script (`test/scripts/milestone1_verification.sh`):**\n```bash\n#!/bin/bash\nset -e\n\necho \"=== Milestone 1: HTTP Proxy Core Verification ===\"\n\n# Start test backend\n./tools/test_http_server --port=8080 &\nBACKEND_PID=$!\nsleep 2\n\n# Start proxy server\n./reverse_proxy --config=test/fixtures/milestone1.conf &\nPROXY_PID=$!\nsleep 3\n\n# Test basic request forwarding\necho \"Testing basic request forwarding...\"\nRESPONSE=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:3128/test)\nif [ \"$RESPONSE\" != \"200\" ]; then\n    echo \"FAIL: Expected 200, got $RESPONSE\"\n    exit 1\nfi\n\n# Test header preservation\necho \"Testing header preservation...\"\ncurl -H \"X-Test-Header: test-value\" http://localhost:3128/headers > /tmp/response.txt\nif ! grep -q \"X-Forwarded-For\" /tmp/response.txt; then\n    echo \"FAIL: X-Forwarded-For header missing\"\n    exit 1\nfi\n\n# Test error handling\necho \"Testing error handling...\"\nkill $BACKEND_PID\nsleep 1\nRESPONSE=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:3128/test)\nif [ \"$RESPONSE\" != \"502\" ]; then\n    echo \"FAIL: Expected 502 Bad Gateway, got $RESPONSE\"\n    exit 1\nfi\n\n# Cleanup\nkill $PROXY_PID\necho \"SUCCESS: Milestone 1 verification passed\"\n```\n\n**G. Debugging Tips:**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Parser hangs on input | Infinite loop in state machine | Add debug prints in `http_parser_process` | Check state transition logic for missing break statements |\n| Connection pool exhaustion | Connections not returned to pool | Monitor pool metrics and connection lifecycle | Ensure `connection_manager_release_backend` called |\n| Cache hit ratio is 0% | Incorrect cache key generation | Log cache keys for identical requests | Verify `cache_generate_key` includes all relevant headers |\n| SSL handshake fails | Certificate/key mismatch | Check certificate with `openssl x509 -text` | Verify certificate and key correspond with `ssl_utils_verify_key_cert_match` |\n| Memory usage grows continuously | Resource leaks in error paths | Run with valgrind during error injection | Add proper cleanup in all error handling branches |\n| Backend health checks failing | Network timing issues | Monitor health check request/response timing | Adjust health check timeout values in configuration |\n\n\n## Debugging Guide\n\n> **Milestone(s):** All milestones - comprehensive debugging knowledge is essential across HTTP proxy core (Milestone 1), load balancing (Milestone 2), connection pooling (Milestone 3), caching (Milestone 4), and SSL termination (Milestone 5).\n\nThink of debugging a reverse proxy like being a detective investigating a complex crime scene. Unlike debugging a simple application where problems typically have one cause, reverse proxy issues often involve multiple moving parts: network connections, protocol parsing, thread synchronization, and distributed systems interactions. Each component can fail in subtle ways that cascade through the system, creating symptoms that appear far from their root cause. A connection timeout might stem from DNS resolution issues, SSL handshake failures, backend overload, or even a subtle HTTP parser bug that corrupts request headers.\n\nThe key insight for reverse proxy debugging is understanding the **request lifecycle dependencies**. Every HTTP request flows through multiple components in a specific sequence, and each component maintains state that can become corrupted. Unlike a stateless function where inputs directly map to outputs, reverse proxy debugging requires understanding how connection state, cache entries, SSL contexts, and load balancer statistics interact across multiple threads and connections.\n\n### Common Bug Patterns\n\nThis section catalogs the most frequently encountered issues when building reverse proxies, organized by component and symptom. Each pattern includes the observable behavior, underlying cause, diagnostic steps, and resolution strategy.\n\n#### HTTP Parser Component Issues\n\n**⚠️ Pitfall: Partial Request Buffering**\n\nThe HTTP parser receives data in chunks from TCP sockets, but HTTP requests don't always arrive as complete units. A common mistake is assuming `recv()` calls return complete HTTP messages, leading to parser failures when requests span multiple network packets.\n\n| Symptom | Likely Cause | Diagnostic Steps | Resolution |\n|---------|--------------|------------------|------------|\n| Parser returns `HTTP_PARSING_ERROR` randomly | Treating partial data as complete requests | Log buffer contents before parsing, check if request headers end with `\\r\\n\\r\\n` | Implement proper buffering with `buffer_append()` until complete headers received |\n| Missing request headers | Parser processes incomplete header section | Monitor `buffer_length` vs expected header size | Buffer data until double CRLF found before parsing |\n| Request body truncated | Not handling `Content-Length` properly | Compare bytes read vs `Content-Length` header value | Continue reading until full body received based on `Content-Length` |\n\n> **Key Insight**: HTTP is a stream protocol delivered over TCP. The protocol boundaries (message start/end) don't align with TCP packet boundaries. Always buffer until you have a complete HTTP message unit.\n\n**⚠️ Pitfall: Chunked Transfer Encoding Bugs**\n\nChunked transfer encoding allows HTTP bodies to be sent without knowing the total size upfront. Parsers must handle the chunk size parsing, data reading, and trailer processing correctly.\n\n| State Transition Error | Symptom | Root Cause | Fix |\n|----------------------|---------|------------|-----|\n| `HTTP_PARSING_CHUNKED_SIZE` → `HTTP_PARSING_ERROR` | Parser fails on chunk size line | Not parsing hexadecimal chunk size correctly | Use `strtol(chunk_line, NULL, 16)` for hex conversion |\n| Infinite loop in `HTTP_PARSING_CHUNKED_DATA` | Connection hangs reading chunk data | Chunk size calculation error, reading wrong number of bytes | Verify `bytes_remaining` matches parsed chunk size |\n| Missing final chunk | Response appears truncated | Not detecting zero-size final chunk `0\\r\\n\\r\\n` | Check for `chunk_size == 0` transition to `HTTP_PARSING_COMPLETE` |\n\n**⚠️ Pitfall: Request Smuggling Vulnerabilities**\n\nRequest smuggling occurs when the proxy and backend server disagree on request boundaries, typically due to inconsistent `Content-Length` and `Transfer-Encoding` header handling.\n\n```\nExample vulnerable request:\nPOST /api/data HTTP/1.1\nHost: example.com\nContent-Length: 44\nTransfer-Encoding: chunked\n\n5c\nPOST /admin/delete HTTP/1.1\nHost: example.com\nContent-Length: 15\n\nmalicious_data\n0\n```\n\n| Vulnerability Pattern | Detection Method | Prevention Strategy |\n|---------------------|------------------|-------------------|\n| Dual `Content-Length` headers | Multiple `Content-Length` values in request | Reject requests with multiple `Content-Length` headers |\n| `Content-Length` + `Transfer-Encoding` | Both headers present simultaneously | Prefer `Transfer-Encoding` when both present, or reject request |\n| Invalid chunk encoding | Malformed chunk size or missing CRLF | Strict chunk format validation before forwarding |\n\n#### Connection Manager Issues\n\n**⚠️ Pitfall: File Descriptor Exhaustion**\n\nThe connection manager can exhaust system file descriptors if connections aren't properly closed or if the connection pool grows unbounded.\n\n| Resource Leak Pattern | Symptom | Detection Command | Resolution |\n|----------------------|---------|------------------|------------|\n| Client connections not closed | `accept()` fails with `EMFILE` | `lsof -p <proxy_pid> \\| wc -l` | Ensure `connection_manager_close_connection()` called on all error paths |\n| Backend pool connections accumulate | Backend connection count grows continuously | Monitor `ConnectionPool.idle_count` and `active_count` | Implement idle timeout cleanup in `timeout_processor()` |\n| Epoll events not removed | `epoll_wait()` returns events for closed FDs | `strace -e epoll_ctl` to see unmatched additions/deletions | Call `epoll_ctl(EPOLL_CTL_DEL)` before closing file descriptors |\n\n**⚠️ Pitfall: Connection State Race Conditions**\n\nMultiple threads can modify connection state simultaneously, leading to use-after-free bugs or double-close errors when proper synchronization is missing.\n\n| Race Condition | Observable Behavior | Root Cause | Synchronization Fix |\n|----------------|-------------------|------------|-------------------|\n| Double connection close | Segmentation fault in `close()` or `free()` | Two threads call `connection_manager_close_connection()` | Use atomic compare-and-swap for connection state transitions |\n| Use-after-free on connection object | Random crashes accessing connection fields | Connection freed while another thread uses it | Reference counting with atomic operations |\n| Backend selection vs connection close | Wrong backend receives request | Load balancer selects backend while connection manager closes it | Hold backend reference with proper cleanup ordering |\n\n#### Load Balancer Issues\n\n**⚠️ Pitfall: Backend Health Check False Positives**\n\nHealth checks might report backends as healthy when they're actually overloaded or partially failing, leading to request failures despite \"healthy\" status.\n\n| False Positive Pattern | Symptom | Root Cause | Improved Detection |\n|-----------------------|---------|------------|-------------------|\n| TCP connect succeeds but HTTP fails | Requests timeout despite healthy backends | Health check only tests TCP connectivity | Send actual HTTP request in `health_check_backend()` |\n| Backend responds to health check but not requests | Intermittent request failures | Health check endpoint different from request handling | Use same endpoint/port for health checks as real requests |\n| Health check too infrequent | Failures detected after many requests fail | Long intervals between health checks | Reduce `health_check_interval` and implement passive failure detection |\n\n**⚠️ Pitfall: Load Balancer Algorithm Edge Cases**\n\nLoad balancing algorithms can behave unexpectedly when backend weights change, connections finish, or servers are added/removed dynamically.\n\n| Algorithm Issue | Unexpected Behavior | Edge Case | Solution |\n|----------------|-------------------|-----------|---------|\n| Round-robin index out of bounds | Segmentation fault in backend selection | Backend removed while `rr_current_index` points to it | Reset index when backend array changes |\n| Weighted round-robin starvation | Some backends never selected | Weight calculation overflow or zero weights | Normalize weights and handle zero-weight backends |\n| Least-connections stale data | Requests sent to overloaded backends | Connection counts not updated on failures | Update counts immediately in error handlers |\n\n#### Cache Engine Issues\n\n**⚠️ Pitfall: Cache Coherence Problems**\n\nCached responses can become stale or inconsistent when cache invalidation doesn't account for all scenarios where cached data should be purged.\n\n| Coherence Issue | Symptom | Root Cause | Invalidation Strategy |\n|----------------|---------|------------|----------------------|\n| Stale responses served after backend update | Clients see old data after server changes | TTL too long or no invalidation on errors | Invalidate cache entries on 5xx responses from backend |\n| Cache poisoning with error responses | 404 or 500 responses cached and served repeatedly | Caching non-cacheable responses | Check `cache_is_cacheable()` includes status code validation |\n| Vary header ignored in cache key | Wrong cached response for different request variants | Cache key doesn't include `Vary` header fields | Include `Vary` header values in `cache_generate_key()` |\n\n**⚠️ Pitfall: Cache Memory Management**\n\nCache engines can consume unbounded memory if eviction policies don't work correctly or if large responses are cached without size limits.\n\n| Memory Issue | Observable Behavior | Monitoring Metric | Memory Control |\n|-------------|-------------------|------------------|----------------|\n| Cache size grows beyond limit | Proxy memory usage increases continuously | Monitor `CacheEngine.size_current` vs `size_limit` | Implement LRU eviction in `cache_engine_store()` |\n| Large response caching | Single large file consumes entire cache | Track individual entry size in `CacheEntry.entry_size` | Reject responses larger than percentage of cache limit |\n| Cache fragmentation | Available cache space but unable to store entries | Monitor successful vs failed cache storage attempts | Implement cache compaction or use memory pools |\n\n#### SSL Termination Issues\n\n**⚠️ Pitfall: Certificate Validation and SNI Problems**\n\nSSL termination can fail silently or present wrong certificates when Server Name Indication (SNI) handling or certificate loading has bugs.\n\n| SSL Issue | Client Observable Behavior | Server-Side Symptom | Resolution |\n|-----------|---------------------------|-------------------|------------|\n| Wrong certificate served | Browser certificate warning for different domain | SNI callback not triggered or incorrect context selection | Verify `ssl_termination_sni_callback()` hostname matching |\n| Certificate chain incomplete | SSL handshake fails with \"unknown CA\" | Missing intermediate certificates | Load full certificate chain in `ssl_utils_load_certificate()` |\n| Private key mismatch | SSL handshake fails with \"bad certificate\" | Certificate and key don't correspond | Use `ssl_utils_verify_key_cert_match()` during loading |\n\n**⚠️ Pitfall: TLS Performance and Security Issues**\n\nSSL termination performance can degrade due to poor cipher selection, missing session resumption, or inefficient TLS context management.\n\n| Performance Issue | Observable Metric | Root Cause | Optimization |\n|------------------|------------------|------------|--------------|\n| High SSL handshake latency | Increased connection establishment time | Weak key exchange algorithms | Configure ECDHE ciphers in `ssl_utils_set_secure_ciphers()` |\n| Excessive CPU usage for SSL | High CPU utilization on SSL threads | No session resumption, repeated full handshakes | Enable TLS session tickets and caching |\n| Memory usage grows with connections | SSL context memory increases | Creating new SSL_CTX per connection instead of reusing | Share SSL contexts across connections for same domain |\n\n### Debugging Techniques and Tools\n\nThis section provides systematic approaches for diagnosing reverse proxy issues, from initial symptom observation through root cause identification to verification of fixes.\n\n#### Systematic Debugging Approach\n\n**Mental Model: The Debugging Funnel**\n\nThink of reverse proxy debugging like a medical diagnosis process. Start with observable symptoms (the patient's complaints), gather more data through systematic observation (vital signs and tests), form hypotheses about root causes (differential diagnosis), test hypotheses with targeted experiments (specific tests), and verify the cure works (follow-up monitoring). Each step narrows down the possible causes until you isolate the specific problem.\n\nThe key insight is that reverse proxy bugs often manifest far from their source. A client timeout might be caused by DNS resolution delays, SSL handshake failures, backend overload, cache corruption, or thread synchronization bugs. The debugging process must systematically eliminate possibilities rather than jumping to conclusions based on surface symptoms.\n\n#### Diagnostic Data Collection\n\nBefore attempting to fix any issue, establish comprehensive visibility into proxy operation. This involves capturing data at multiple layers of the system.\n\n**Connection-Level Diagnostics**\n\n| Data Point | Collection Method | Information Revealed |\n|------------|------------------|-------------------|\n| Active connection count | Monitor `ConnectionManager` statistics | Whether issue is connection exhaustion |\n| Connection state distribution | Count connections in each `ConnectionState` | Which processing stage has bottlenecks |\n| Connection duration histogram | Track time from creation to closure | Whether connections are hanging |\n| Bytes transferred per connection | Sum `bytes_read` and `bytes_written` | Whether transfers are completing |\n| Backend connection pool utilization | Monitor `ConnectionPool.idle_count` vs `max_connections` | Whether backend pooling is effective |\n\n**Request-Level Diagnostics**\n\n| Diagnostic Technique | Implementation | Troubleshooting Value |\n|---------------------|----------------|---------------------|\n| Request ID tracing | Generate unique ID per request, log in all components | Follow request flow across components |\n| Timing breakdown | Measure time in each processing stage | Identify bottleneck components |\n| Header inspection | Log all request/response headers | Debug protocol-level issues |\n| Cache hit/miss tracking | Log cache decisions with reasons | Understand cache effectiveness |\n| Backend selection logging | Log load balancer decisions | Debug routing issues |\n\n#### Component-Specific Debugging Tools\n\n**HTTP Parser Debugging**\n\nWhen HTTP parser issues occur, the key is understanding exactly what data the parser received and how it interpreted the protocol boundaries.\n\n| Parser Issue | Debug Data to Collect | Analysis Method |\n|-------------|---------------------|-----------------|\n| Parse failures | Raw buffer contents before parsing | Check for valid HTTP format, protocol violations |\n| Incomplete requests | Buffer state at each `http_parser_process()` call | Verify incremental parsing state machine |\n| Header corruption | Header hash table contents after parsing | Compare parsed values with raw buffer |\n| Body length errors | `Content-Length` vs actual body bytes received | Check for chunked encoding vs fixed length |\n\n**Load Balancer Debugging**\n\nLoad balancer issues require understanding the decision-making process and backend server state over time.\n\n| Debug Data Collection | Purpose | Implementation |\n|-----------------------|---------|----------------|\n| Backend selection history | Track which backend chosen for each request | Log backend ID and selection algorithm result |\n| Health check timeline | Record all health check attempts and results | Log successful/failed checks with timestamps |\n| Connection count tracking | Monitor active connections per backend | Sample connection counts periodically |\n| Weight adjustment history | Track dynamic weight changes | Log weight updates with reasons |\n\n**Cache Engine Debugging**\n\nCache-related issues often involve understanding why specific entries were or weren't cached, and how cache invalidation decisions were made.\n\n| Cache Debug Information | Collection Method | Analysis Purpose |\n|------------------------|------------------|------------------|\n| Cache key generation | Log keys generated for each request | Debug cache miss issues |\n| Cache-Control parsing | Log parsed cache directives | Understand caching decisions |\n| TTL calculations | Log computed expiration times | Debug premature or delayed expiration |\n| Eviction decisions | Log LRU operations and size-based evictions | Understand cache memory management |\n| Cache hit/miss reasons | Log why each lookup succeeded or failed | Optimize cache effectiveness |\n\n#### Memory and Resource Leak Detection\n\nReverse proxies are long-running servers that must manage resources carefully to avoid gradual degradation.\n\n**Memory Leak Detection Strategy**\n\n| Detection Method | Tool/Technique | What It Reveals |\n|-----------------|---------------|-----------------|\n| Process memory monitoring | Track RSS/VSZ over time with `ps` or `/proc/pid/status` | Overall memory growth trends |\n| Allocation tracking | Use Valgrind or AddressSanitizer | Specific allocation sites that aren't freed |\n| Connection object counting | Monitor `ConnectionManager` object counts | Whether connections are accumulating |\n| Cache size monitoring | Track `CacheEngine.size_current` over time | Whether cache eviction is working |\n| SSL context counting | Count SSL contexts in `SSLTermination` | Whether TLS contexts are leaking |\n\n**File Descriptor Leak Detection**\n\n| Resource Type | Monitoring Command | Normal vs Leak Pattern |\n|--------------|-------------------|------------------------|\n| Socket file descriptors | `lsof -p <pid> -a -i` | Should correlate with active connections |\n| Regular file descriptors | `lsof -p <pid> -a -f -- /` | Should remain constant for config/log files |\n| Pipe/eventfd descriptors | `lsof -p <pid> -a -t REG` | Should match thread communication channels |\n| Total FD count | `ls /proc/<pid>/fd \\| wc -l` | Should stay within reasonable bounds |\n\n#### Network-Level Debugging\n\nSince reverse proxies are network intermediaries, network-level debugging provides critical visibility into connection establishment, data transfer, and protocol interactions.\n\n**Traffic Analysis Techniques**\n\n| Analysis Level | Tool | Information Provided |\n|---------------|------|---------------------|\n| Packet capture | `tcpdump -i any -w proxy-traffic.pcap` | Raw network data for protocol analysis |\n| Connection tracking | `ss -tupln` and `netstat -an` | Current socket states and listen ports |\n| Traffic statistics | `iftop` or `nethogs` | Bandwidth utilization per connection |\n| DNS resolution | `dig` and `nslookup` for backend hostnames | DNS resolution delays or failures |\n\n**SSL/TLS Debugging**\n\nTLS issues require specialized analysis tools since the traffic is encrypted and handshake failures can have many causes.\n\n| TLS Debug Technique | Command/Tool | Diagnostic Value |\n|--------------------|--------------|------------------|\n| Handshake analysis | `openssl s_client -connect proxy:443 -debug` | Step-by-step handshake progression |\n| Certificate validation | `openssl verify -CApath /etc/ssl/certs cert.pem` | Certificate chain validation issues |\n| Cipher negotiation | `nmap --script ssl-enum-ciphers -p 443 proxy` | Available cipher suites |\n| SNI testing | `openssl s_client -servername domain.com -connect proxy:443` | SNI hostname handling |\n\n#### Performance Profiling and Bottleneck Analysis\n\nPerformance issues in reverse proxies often involve identifying which component or operation is the limiting factor under load.\n\n**CPU Profiling Strategy**\n\n| Profiling Target | Tool/Method | Analysis Focus |\n|-----------------|-------------|----------------|\n| Function-level CPU usage | `perf record -g` + `perf report` | Which functions consume most CPU time |\n| Lock contention | `perf lock record` + `perf lock report` | Mutex/rwlock blocking behavior |\n| System call overhead | `strace -c -p <pid>` | System call frequency and timing |\n| Thread activity | `htop` with thread view | Per-thread CPU utilization |\n\n**I/O Performance Analysis**\n\n| I/O Pattern | Monitoring Method | Performance Implications |\n|-------------|------------------|-------------------------|\n| Socket read/write efficiency | Monitor `EAGAIN` frequency in logs | Whether non-blocking I/O is optimal |\n| Disk I/O for caching | `iostat` to monitor disk utilization | Whether cache storage is bottleneck |\n| DNS resolution performance | Time DNS lookups with `dig` | Whether backend resolution is slow |\n| Backend response times | Log request duration per backend | Whether specific backends are slow |\n\n#### Systematic Root Cause Analysis\n\nWhen debugging complex issues, use a systematic approach to avoid missing important causes or making incorrect assumptions.\n\n**The Five Whys Technique for Reverse Proxy Issues**\n\n| Level | Question | Example Analysis |\n|-------|----------|------------------|\n| 1st Why | Why is the symptom occurring? | \"Clients are getting 503 errors\" |\n| 2nd Why | Why is that immediate cause happening? | \"Load balancer returns no healthy backends\" |\n| 3rd Why | Why is that deeper cause happening? | \"Health checks are failing for all backends\" |\n| 4th Why | Why is that root cause occurring? | \"Health check timeout is too short\" |\n| 5th Why | Why was that configuration chosen? | \"Default timeout not adjusted for network latency\" |\n\n**Hypothesis Testing Framework**\n\nFor each suspected root cause, design specific tests that can confirm or refute the hypothesis.\n\n| Hypothesis | Test Design | Expected Result if Correct | Expected Result if Incorrect |\n|------------|-------------|---------------------------|----------------------------|\n| \"Backend overload causing timeouts\" | Send requests directly to backend, bypassing proxy | Direct requests also timeout | Direct requests succeed |\n| \"SSL handshake failures\" | Test same domain with HTTP vs HTTPS | HTTPS fails, HTTP succeeds | Both fail or both succeed |\n| \"Cache serving stale data\" | Send cache-busting headers (`Cache-Control: no-cache`) | Fresh data returned | Same stale data returned |\n| \"Load balancer algorithm bug\" | Manually specify backend in request | Specified backend works | All backends fail |\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Debugging Component | Simple Option | Advanced Option |\n|-------------------|---------------|------------------|\n| Logging Framework | `fprintf(stderr, ...)` with timestamp | Structured logging with log levels and rotation |\n| Memory Debugging | Valgrind memcheck | AddressSanitizer with custom allocator |\n| Network Analysis | tcpdump + Wireshark | Custom packet capture with libpcap |\n| Performance Profiling | gprof with `-pg` compilation | perf with flamegraph visualization |\n| Configuration Debugging | Static config file parsing | Dynamic config reload with validation |\n\n#### Debugging Infrastructure Code\n\n**Complete Logging System Implementation:**\n\n```c\n// logger.h\n#include <stdio.h>\n#include <time.h>\n#include <stdarg.h>\n#include <pthread.h>\n\ntypedef enum {\n    LOG_DEBUG = 0,\n    LOG_INFO = 1,\n    LOG_WARN = 2,\n    LOG_ERROR = 3\n} LogLevel;\n\ntypedef struct {\n    LogLevel min_level;\n    FILE* output_file;\n    pthread_mutex_t log_mutex;\n    bool include_thread_id;\n    bool include_component;\n} Logger;\n\n// Initialize logging system with specified minimum level and output file\nbool logger_init(LogLevel min_level, FILE* output);\n\n// Log formatted message with component, file, and line information\nvoid logger_log(LogLevel level, const char* component, int line, const char* format, ...);\n\n// Specialized logging macros for convenience\n#define LOG_DEBUG_MSG(component, ...) logger_log(LOG_DEBUG, component, __LINE__, __VA_ARGS__)\n#define LOG_INFO_MSG(component, ...) logger_log(LOG_INFO, component, __LINE__, __VA_ARGS__)\n#define LOG_WARN_MSG(component, ...) logger_log(LOG_WARN, component, __LINE__, __VA_ARGS__)\n#define LOG_ERROR_MSG(component, ...) logger_log(LOG_ERROR, component, __LINE__, __VA_ARGS__)\n\n// logger.c\nstatic Logger g_logger = {0};\n\nbool logger_init(LogLevel min_level, FILE* output) {\n    g_logger.min_level = min_level;\n    g_logger.output_file = output ? output : stderr;\n    g_logger.include_thread_id = true;\n    g_logger.include_component = true;\n    \n    if (pthread_mutex_init(&g_logger.log_mutex, NULL) != 0) {\n        return false;\n    }\n    \n    return true;\n}\n\nvoid logger_log(LogLevel level, const char* component, int line, const char* format, ...) {\n    if (level < g_logger.min_level) {\n        return;\n    }\n    \n    pthread_mutex_lock(&g_logger.log_mutex);\n    \n    // Generate timestamp\n    time_t now = time(NULL);\n    struct tm* local_time = localtime(&now);\n    char timestamp[32];\n    strftime(timestamp, sizeof(timestamp), \"%Y-%m-%d %H:%M:%S\", local_time);\n    \n    // Get thread ID\n    pthread_t thread_id = pthread_self();\n    \n    // Format level string\n    const char* level_strings[] = {\"DEBUG\", \"INFO\", \"WARN\", \"ERROR\"};\n    \n    // Print log prefix\n    fprintf(g_logger.output_file, \"[%s] [%s] [%lu:%s:%d] \", \n            timestamp, level_strings[level], (unsigned long)thread_id, component, line);\n    \n    // Print actual message\n    va_list args;\n    va_start(args, format);\n    vfprintf(g_logger.output_file, format, args);\n    va_end(args);\n    \n    fprintf(g_logger.output_file, \"\\n\");\n    fflush(g_logger.output_file);\n    \n    pthread_mutex_unlock(&g_logger.log_mutex);\n}\n```\n\n**Complete Error Context Tracking:**\n\n```c\n// error_handler.h\n#include \"logger.h\"\n#include \"proxy_types.h\"\n\ntypedef enum {\n    PROXY_ERROR_NONE = 0,\n    PROXY_ERROR_PARSE_FAILED = 1,\n    PROXY_ERROR_BACKEND_UNAVAILABLE = 2,\n    PROXY_ERROR_BACKEND_TIMEOUT = 3,\n    PROXY_ERROR_CACHE_FAILURE = 4,\n    PROXY_ERROR_SSL_HANDSHAKE_FAILED = 5,\n    PROXY_ERROR_CLIENT_DISCONNECTED = 6,\n    PROXY_ERROR_MEMORY_ALLOCATION = 7,\n    PROXY_ERROR_CONNECTION_LIMIT = 8,\n    PROXY_ERROR_CONFIG_INVALID = 9\n} ProxyErrorCode;\n\ntypedef struct {\n    ProxyErrorCode code;\n    char message[512];\n    char component[64];\n    time_t timestamp;\n    uint64_t request_id;\n    Connection* failed_connection;\n    BackendServer* failed_backend;\n    pthread_t thread_id;\n    int system_errno;\n} ErrorContext;\n\ntypedef struct {\n    ErrorContext errors[1024];\n    size_t error_count;\n    size_t error_capacity;\n    pthread_mutex_t error_mutex;\n    pthread_t recovery_thread;\n    bool running;\n} ErrorHandler;\n\n// Initialize centralized error handling system\nErrorHandler* error_handler_create(void);\n\n// Report error to central handler for recovery coordination\nvoid error_handler_report(ErrorHandler* handler, ErrorContext* context);\n\n// Generate sanitized error responses for clients\nvoid generate_client_error_response(Connection* conn, ProxyErrorCode code, const char* details);\n\n// error_handler.c\nErrorHandler* error_handler_create(void) {\n    ErrorHandler* handler = malloc(sizeof(ErrorHandler));\n    if (!handler) return NULL;\n    \n    memset(handler, 0, sizeof(ErrorHandler));\n    handler->error_capacity = 1024;\n    \n    if (pthread_mutex_init(&handler->error_mutex, NULL) != 0) {\n        free(handler);\n        return NULL;\n    }\n    \n    handler->running = true;\n    return handler;\n}\n\nvoid error_handler_report(ErrorHandler* handler, ErrorContext* context) {\n    if (!handler || !context) return;\n    \n    pthread_mutex_lock(&handler->error_mutex);\n    \n    if (handler->error_count < handler->error_capacity) {\n        // Store error context\n        memcpy(&handler->errors[handler->error_count], context, sizeof(ErrorContext));\n        handler->error_count++;\n        \n        // Log error with full context\n        LOG_ERROR_MSG(\"error_handler\", \n                      \"Error %d in %s: %s (request_id=%lu, connection=%p, backend=%p, errno=%d)\",\n                      context->code, context->component, context->message,\n                      context->request_id, context->failed_connection, \n                      context->failed_backend, context->system_errno);\n    }\n    \n    pthread_mutex_unlock(&handler->error_mutex);\n}\n\nvoid generate_client_error_response(Connection* conn, ProxyErrorCode code, const char* details) {\n    if (!conn) return;\n    \n    // Generate appropriate HTTP error response\n    const char* status_text = \"Internal Server Error\";\n    int status_code = 500;\n    \n    switch (code) {\n        case PROXY_ERROR_BACKEND_UNAVAILABLE:\n            status_code = 503;\n            status_text = \"Service Unavailable\";\n            break;\n        case PROXY_ERROR_BACKEND_TIMEOUT:\n            status_code = 504;\n            status_text = \"Gateway Timeout\";\n            break;\n        case PROXY_ERROR_PARSE_FAILED:\n            status_code = 400;\n            status_text = \"Bad Request\";\n            break;\n        case PROXY_ERROR_SSL_HANDSHAKE_FAILED:\n            status_code = 400;\n            status_text = \"Bad Request\";\n            break;\n        default:\n            break;\n    }\n    \n    // Sanitize details - never expose internal information\n    const char* safe_details = \"The server encountered an error processing your request.\";\n    \n    char response[1024];\n    snprintf(response, sizeof(response),\n             \"HTTP/1.1 %d %s\\r\\n\"\n             \"Content-Type: text/plain\\r\\n\"\n             \"Content-Length: %zu\\r\\n\"\n             \"Connection: close\\r\\n\"\n             \"\\r\\n\"\n             \"%s\",\n             status_code, status_text, strlen(safe_details), safe_details);\n    \n    // Send error response to client\n    send(conn->client_fd, response, strlen(response), 0);\n    LOG_INFO_MSG(\"error_response\", \"Sent %d %s to client (error: %s)\", \n                 status_code, status_text, details);\n}\n```\n\n#### Core Logic Debugging Skeletons\n\n**Request Tracing Implementation:**\n\n```c\n// request_tracer.h\ntypedef struct {\n    uint64_t request_id;\n    char client_ip[INET_ADDRSTRLEN];\n    char method[16];\n    char uri[512];\n    time_t start_time;\n    time_t parse_complete_time;\n    time_t backend_selected_time;\n    time_t cache_lookup_time;\n    time_t backend_request_time;\n    time_t response_complete_time;\n    BackendServer* selected_backend;\n    bool cache_hit;\n    ProxyErrorCode error_code;\n} RequestTrace;\n\nRequestTrace* request_trace_create(Connection* conn, HttpRequest* request) {\n    // TODO 1: Allocate RequestTrace structure\n    // TODO 2: Generate unique request ID using atomic counter\n    // TODO 3: Extract client IP from connection socket address\n    // TODO 4: Copy HTTP method and URI from request\n    // TODO 5: Set start_time to current timestamp\n    // TODO 6: Initialize timing fields to 0\n    // TODO 7: Initialize error_code to PROXY_ERROR_NONE\n    // TODO 8: Log request start with all initial context\n}\n\nvoid request_trace_mark_milestone(RequestTrace* trace, const char* milestone) {\n    // TODO 1: Get current timestamp\n    // TODO 2: Set appropriate timing field based on milestone string\n    // TODO 3: Log milestone reached with elapsed time since start\n    // TODO 4: If this is an error milestone, set error_code appropriately\n}\n\nvoid request_trace_complete(RequestTrace* trace) {\n    // TODO 1: Set response_complete_time to current timestamp\n    // TODO 2: Calculate total request duration\n    // TODO 3: Log complete request summary with all timing breakdowns\n    // TODO 4: Log backend selection, cache hit status, and any errors\n    // TODO 5: Free RequestTrace structure\n}\n```\n\n**Connection State Debugging:**\n\n```c\n// connection_debug.h\ntypedef struct {\n    Connection* connection;\n    ConnectionState previous_state;\n    ConnectionState current_state;\n    time_t transition_time;\n    const char* transition_reason;\n    size_t bytes_processed;\n    int system_error;\n} ConnectionStateTrace;\n\nvoid debug_log_connection_state_change(Connection* conn, ConnectionState new_state, \n                                      const char* reason) {\n    // TODO 1: Check if connection state actually changed\n    // TODO 2: Create ConnectionStateTrace with previous and new states\n    // TODO 3: Log state transition with timing and reason\n    // TODO 4: If transitioning to error state, log additional context\n    // TODO 5: Update connection's last_activity timestamp\n    // TODO 6: Store trace in connection debugging history\n}\n\nvoid debug_dump_connection_state(Connection* conn) {\n    // TODO 1: Log current connection state and timing information\n    // TODO 2: Log buffer states (request_buffer and response_buffer positions)\n    // TODO 3: Log backend server information if connected\n    // TODO 4: Log any pending timeout information\n    // TODO 5: Log recent state transition history\n}\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Debugging Verification:**\n\nAfter implementing basic HTTP proxy functionality, verify debugging capabilities:\n\n1. **Start proxy with debug logging enabled**: `./proxy --log-level=DEBUG --log-file=debug.log`\n\n2. **Send malformed HTTP request** to test parser error handling:\n   ```bash\n   echo -e \"GET /test HTTP/1.1\\r\\nInvalid-Header-Missing-Colon\\r\\n\\r\\n\" | nc localhost 8080\n   ```\n   Expected: Parser error logged with specific buffer contents and error reason.\n\n3. **Monitor connection state transitions** with legitimate request:\n   ```bash\n   curl -v http://localhost:8080/test\n   ```\n   Expected: State transitions logged from `CONNECTION_IDLE` → `CONNECTION_READING_REQUEST` → `CONNECTION_FORWARDING` → etc.\n\n4. **Verify error response generation** when backend unavailable:\n   - Stop backend server\n   - Send request through proxy\n   - Expected: 503 Service Unavailable response with sanitized error message\n\n**Milestone 2 Load Balancer Debugging:**\n\n1. **Test backend selection logging**:\n   ```bash\n   # Send multiple requests and verify round-robin distribution\n   for i in {1..10}; do curl http://localhost:8080/test; done\n   ```\n   Expected: Log shows requests distributed evenly across healthy backends.\n\n2. **Test health check failure detection**:\n   - Stop one backend server\n   - Wait for health check interval\n   - Send requests\n   - Expected: Failed backend marked unhealthy and excluded from selection.\n\n3. **Test connection count tracking**:\n   - Send concurrent requests\n   - Expected: Connection counts per backend logged and updated correctly.\n\n**Milestone 3-5 Advanced Debugging:**\n\nEach subsequent milestone should verify debugging capabilities for new components:\n- Cache hit/miss logging with reasons\n- SSL handshake failure diagnosis\n- Performance profiling under load\n\n#### Common Debugging Command Patterns\n\n**Resource Monitoring Commands:**\n\n```bash\n# Monitor file descriptor usage\nwatch -n 1 'lsof -p $(pgrep proxy) | wc -l'\n\n# Monitor memory usage\nwatch -n 1 'cat /proc/$(pgrep proxy)/status | grep VmRSS'\n\n# Monitor network connections\nwatch -n 1 'ss -tupln | grep :8080'\n\n# Monitor thread activity\nhtop -H -p $(pgrep proxy)\n\n# Capture network traffic\ntcpdump -i any -w proxy-debug.pcap host backend-server\n\n# Profile CPU usage\nperf record -g -p $(pgrep proxy) sleep 10\nperf report --stdio\n```\n\nThese debugging techniques and tools provide comprehensive visibility into reverse proxy operation, enabling systematic diagnosis of issues from simple configuration errors to complex race conditions and performance bottlenecks.\n\n\n## Future Extensions\n\n> **Milestone(s):** All milestones - the extensibility architecture established during the core implementation (Milestones 1-5) enables future growth without requiring fundamental redesigns.\n\nThink of a reverse proxy like a Swiss Army knife that starts with basic tools but has slots for additional specialized implements. The base platform provides the essential mechanisms (HTTP parsing, connection management, request routing), while the extension system allows new tools to be added without redesigning the entire handle. Each extension leverages the existing infrastructure while adding specialized capabilities, just as a magnifying glass attachment uses the knife's existing frame while providing new optical functionality.\n\n### Strategic Extension Framework\n\nThe reverse proxy's architecture naturally accommodates future enhancements through several key extensibility patterns. The **plugin architecture** allows new functionality to be added without modifying core components, while the **configuration-driven approach** enables features to be enabled or disabled dynamically. The **event-driven design** provides hooks where extensions can intercept and modify request processing, and the **component isolation** ensures that new features don't destabilize existing functionality.\n\n> **Decision: Extension Architecture Pattern**\n> - **Context**: Future features require integration points without destabilizing the core proxy functionality or requiring architectural rewrites\n> - **Options Considered**: Monolithic expansion, Plugin system with dynamic loading, Event-driven hooks with static compilation\n> - **Decision**: Event-driven hooks with static compilation and configuration-based activation\n> - **Rationale**: Provides flexibility without the complexity and security risks of dynamic plugin loading, while maintaining compile-time type safety and performance\n> - **Consequences**: Extensions require recompilation but gain full access to core data structures and zero-overhead integration\n\n| Extension Pattern | Implementation Complexity | Runtime Overhead | Security Risk | Flexibility |\n|------------------|---------------------------|------------------|---------------|-------------|\n| Monolithic Expansion | Low | None | Low | Limited |\n| Dynamic Plugin System | High | Moderate | High | Maximum |\n| Event-Driven Hooks | Moderate | Minimal | Low | High |\n\n### Rate Limiting and Throttling\n\nRate limiting acts like a nightclub bouncer who controls the flow of patrons to prevent overcrowding. The bouncer counts how many people have entered recently, checks against established limits, and either allows entry or asks visitors to wait. Similarly, rate limiting tracks request patterns per client and enforces configurable limits to protect backend servers from overload.\n\nThe rate limiting extension integrates with the existing `HttpParser` and `ConnectionManager` components by adding request tracking before the load balancing stage. Each incoming request triggers rate limit evaluation based on client IP address, request path patterns, or custom header values. The system maintains sliding window counters that track request volumes across different time intervals, enabling both burst protection and sustained rate enforcement.\n\n**Rate Limiting Data Structures:**\n\n| Structure | Field | Type | Description |\n|-----------|-------|------|-------------|\n| `RateLimiter` | rules | `RateLimitRule**` | Array of configured rate limiting rules |\n| `RateLimiter` | rule_count | `size_t` | Number of active rate limiting rules |\n| `RateLimiter` | client_counters | `HashTable*` | Per-client request counters indexed by IP |\n| `RateLimiter` | sliding_windows | `SlidingWindow**` | Time-based request counting windows |\n| `RateLimiter` | cleanup_thread | `pthread_t` | Background thread for counter cleanup |\n| `RateLimiter` | limiter_mutex | `pthread_rwlock_t` | Synchronization for counter updates |\n| `RateLimitRule` | pattern | `char[512]` | URL pattern or client identifier pattern |\n| `RateLimitRule` | requests_per_second | `uint32_t` | Maximum requests allowed per second |\n| `RateLimitRule` | burst_size | `uint32_t` | Maximum burst requests before rate limiting |\n| `RateLimitRule` | time_window_seconds | `uint32_t` | Time window for rate calculation |\n| `ClientCounter` | client_id | `char[64]` | Client identifier (IP address or custom key) |\n| `ClientCounter` | request_count | `uint32_t` | Current request count in time window |\n| `ClientCounter` | last_request_time | `time_t` | Timestamp of most recent request |\n| `ClientCounter` | burst_tokens | `uint32_t` | Available burst request tokens |\n\nThe rate limiter extension hooks into the request processing pipeline at three key points: **request arrival** (to increment counters), **backend selection** (to enforce limits before load balancing), and **response generation** (to add rate limit headers). When a request exceeds configured limits, the system generates an HTTP 429 Too Many Requests response with appropriate Retry-After headers, preventing the request from reaching backend servers.\n\n> The critical insight for rate limiting is that enforcement must occur as early as possible in the request pipeline to maximize protection effectiveness. Waiting until after parsing or load balancing wastes processing resources on requests that will ultimately be rejected.\n\n**Rate Limiting Integration Points:**\n\n| Integration Point | Component | Hook Function | Purpose |\n|------------------|-----------|---------------|---------|\n| Request Arrival | `ConnectionManager` | `rate_limiter_check_request()` | Early request validation |\n| Backend Selection | `LoadBalancer` | `rate_limiter_pre_balance()` | Pre-routing enforcement |\n| Response Headers | `HttpParser` | `rate_limiter_add_headers()` | Rate limit status communication |\n| Counter Cleanup | Background Thread | `rate_limiter_cleanup_expired()` | Memory management |\n\n### Web Application Firewall (WAF)\n\nA Web Application Firewall functions like an expert security guard who examines every visitor's belongings and behavior patterns, looking for signs of malicious intent. The guard knows common attack signatures (like weapons or suspicious tools) and behavioral patterns (like someone trying to access restricted areas repeatedly). When threats are detected, the guard can block entry, strip dangerous items, or alert security management.\n\nThe WAF extension operates on fully parsed HTTP requests, examining headers, URL patterns, request bodies, and parameter values against configurable rule sets. It integrates after the `HttpParser` component completes request parsing but before the `LoadBalancer` selects a backend server, ensuring that malicious requests never reach application servers.\n\n**WAF Architecture Components:**\n\n| Component | Responsibility | Integration Point |\n|-----------|---------------|------------------|\n| Rule Engine | Pattern matching and threat detection | Post-parsing, pre-routing |\n| Signature Database | Known attack patterns and payloads | Static configuration with hot reload |\n| Anomaly Detector | Statistical analysis of request patterns | Background analysis thread |\n| Response Generator | Security error page generation | Request termination point |\n| Audit Logger | Security event logging and alerting | Cross-cutting concern |\n\nThe WAF rule engine processes requests through multiple detection layers: **signature matching** (comparing request content against known attack patterns), **statistical anomaly detection** (identifying unusual request characteristics), **rate-based detection** (spotting suspicious request volumes), and **behavioral analysis** (tracking client interaction patterns over time).\n\n**WAF Rule Types:**\n\n| Rule Type | Detection Method | Example Pattern | Action Options |\n|-----------|-----------------|----------------|----------------|\n| SQL Injection | Pattern matching | `UNION SELECT.*FROM` | Block, sanitize, log |\n| XSS Attack | Content scanning | `<script>.*</script>` | Block, escape, log |\n| Path Traversal | URL analysis | `\\.\\.\\/` sequences | Block, normalize, log |\n| Command Injection | Parameter scanning | Shell metacharacters | Block, sanitize, log |\n| Rate Anomaly | Statistical analysis | Request volume spikes | Throttle, block, log |\n\nWhen the WAF detects threats, it can take various actions: **blocking** (returning 403 Forbidden responses), **sanitizing** (cleaning request content and forwarding), **logging** (recording security events while allowing requests), or **challenging** (requiring additional authentication). The system maintains detailed audit logs that include threat classifications, rule triggers, client information, and response actions.\n\n### Monitoring and Observability\n\nMonitoring a reverse proxy resembles managing a busy restaurant kitchen where you need visibility into every station's performance. The head chef needs real-time information about order volumes, preparation times, ingredient availability, and staff performance. Similarly, proxy monitoring provides comprehensive visibility into request flows, component performance, error rates, and resource utilization across all system layers.\n\nThe observability extension integrates with every core component through instrumentation hooks that collect metrics without impacting request processing performance. The system employs **push-based metrics** (actively sending data to monitoring systems), **pull-based metrics** (exposing endpoints for metric collection), and **structured logging** (machine-readable log formats for analysis).\n\n**Monitoring Data Model:**\n\n| Metric Category | Component Source | Key Metrics | Collection Method |\n|----------------|------------------|-------------|------------------|\n| Request Metrics | `HttpParser` | Parse time, request size, protocol version | Per-request instrumentation |\n| Connection Metrics | `ConnectionManager` | Pool utilization, connection lifetime, timeouts | Connection lifecycle hooks |\n| Load Balancing | `LoadBalancer` | Backend selection time, health check results | Algorithm execution hooks |\n| Cache Performance | `CacheEngine` | Hit/miss ratios, eviction rates, storage usage | Cache operation instrumentation |\n| SSL Performance | `SSLTermination` | Handshake duration, cipher negotiation, SNI usage | TLS event callbacks |\n\nThe monitoring system exposes metrics through multiple interfaces: **Prometheus endpoints** (for scraping-based collection), **StatsD integration** (for push-based metric delivery), **structured JSON logs** (for centralized log aggregation), and **health check endpoints** (for load balancer health monitoring). Each interface provides different metric granularities and update frequencies to support various monitoring architectures.\n\n**Observable Events:**\n\n| Event Type | Trigger Condition | Included Data | Monitoring Use Case |\n|------------|------------------|---------------|-------------------|\n| Request Started | Client connection accepted | Timestamp, client IP, request ID | Request tracing |\n| Backend Selected | Load balancer chooses server | Backend ID, selection algorithm, health status | Load distribution analysis |\n| Cache Hit/Miss | Cache lookup completed | Cache key, hit status, TTL remaining | Cache performance tuning |\n| Error Occurred | Any component error | Error code, component, stack trace | Error rate monitoring |\n| Connection Pooled | Backend connection returned | Pool size, connection age, reuse count | Pool efficiency analysis |\n\n### Authentication and Authorization\n\nAuthentication and authorization work like a sophisticated embassy security system with multiple checkpoints. The first checkpoint verifies visitor identity through passport examination (authentication), while subsequent checkpoints determine which areas the visitor can access based on their diplomatic status and clearance level (authorization). The system maintains visitor records, tracks access patterns, and can revoke access privileges dynamically.\n\nThe auth extension integrates early in the request pipeline, immediately after HTTP parsing but before cache lookup or backend selection. This positioning ensures that unauthorized requests consume minimal system resources while authorized requests benefit from full proxy optimizations including caching and connection pooling.\n\n**Authentication Integration Architecture:**\n\n| Integration Point | Purpose | Component Interaction | Data Flow |\n|------------------|---------|----------------------|-----------|\n| Request Validation | Identity verification | `HttpParser` → Auth Extension | Headers → Auth decision |\n| Cache Key Modification | User-aware caching | Auth Extension → `CacheEngine` | User context → Cache key |\n| Backend Selection | User-based routing | Auth Extension → `LoadBalancer` | User role → Backend pool |\n| Response Headers | Auth status communication | Auth Extension → `HttpParser` | Auth result → Response headers |\n\nThe authentication system supports multiple verification methods: **JWT token validation** (for stateless authentication), **session cookie verification** (for traditional web applications), **API key authentication** (for service-to-service communication), and **OAuth2 token introspection** (for delegated authorization). Each method integrates with external identity providers while maintaining local caching for performance.\n\n**Authorization Decision Engine:**\n\n| Decision Factor | Data Source | Evaluation Method | Caching Strategy |\n|----------------|-------------|------------------|------------------|\n| User Identity | Auth token/session | Token validation/lookup | In-memory with TTL |\n| Request Path | HTTP request URL | Pattern matching | Rule compilation |\n| HTTP Method | Request method header | Exact matching | Static configuration |\n| User Roles | Identity provider | Role membership check | User session cache |\n| Resource Permissions | Permission database | ACL evaluation | Permission result cache |\n\nWhen authorization fails, the system can respond with different strategies: **401 Unauthorized** (for missing authentication), **403 Forbidden** (for insufficient permissions), **redirect to login** (for web applications), or **custom error pages** (for branded experiences). The auth extension maintains audit logs for security compliance, tracking authentication attempts, authorization decisions, and access pattern anomalies.\n\n### Content Transformation\n\nContent transformation functions like a universal translator and format converter at an international conference. Just as the translator converts languages and cultural references to ensure effective communication between parties, content transformation adapts response formats, protocols, and encodings to match client capabilities and requirements.\n\nThe transformation extension operates on HTTP responses after they return from backend servers but before they reach the client. This positioning allows the proxy to modify content without impacting backend server logic while ensuring that transformations respect caching and connection management optimizations.\n\n**Transformation Pipeline Architecture:**\n\n| Transformation Stage | Purpose | Processing Order | Configuration |\n|---------------------|---------|-----------------|---------------|\n| Content Negotiation | Format selection | 1st - immediately after backend response | Client Accept headers |\n| Protocol Translation | Version conversion | 2nd - after format decision | HTTP version capabilities |\n| Compression | Bandwidth optimization | 3rd - after content finalization | Client encoding support |\n| Security Headers | Response hardening | 4th - final header addition | Security policy configuration |\n\nThe content transformation system supports multiple transformation types: **protocol conversion** (HTTP/1.1 to HTTP/2), **format translation** (JSON to XML or vice versa), **image optimization** (resizing and compression), **response compression** (gzip, brotli), and **security header injection** (HSTS, CSP, CORP headers).\n\n**Transformation Rules:**\n\n| Rule Type | Trigger Condition | Input Data | Output Modification | Performance Impact |\n|-----------|------------------|------------|-------------------|------------------|\n| Protocol Downgrade | HTTP/2 client, HTTP/1.1 backend | Response stream | Header format conversion | Low |\n| JSON to XML | Accept: application/xml header | Response body | Format transformation | High |\n| Image Resize | Image content type + query params | Binary response body | Resized image data | Very High |\n| Compression | Client accepts gzip/brotli | Response body | Compressed body + headers | Moderate |\n| Security Headers | All responses | Response headers | Additional security headers | Minimal |\n\nContent transformation integrates with the `CacheEngine` to ensure that transformed content is cached appropriately. The cache key generation includes transformation parameters so that different client capabilities receive correctly cached responses. For example, a gzipped response and an uncompressed response for the same resource are cached as separate entries.\n\n### Service Mesh Integration\n\nService mesh integration transforms the reverse proxy into a service mesh sidecar proxy, similar to how a personal assistant coordinates all communications and interactions for a busy executive. The assistant handles scheduling, protocol translation, security verification, and relationship management, allowing the executive to focus on core business decisions while ensuring all interactions follow organizational policies and procedures.\n\nThe service mesh extension adds distributed tracing, service discovery, traffic policies, and inter-service security. It integrates with the existing `LoadBalancer` component for dynamic service discovery and with the `ConnectionManager` for connection security and observability.\n\n**Service Mesh Components:**\n\n| Component | Responsibility | Integration Point | External Dependencies |\n|-----------|---------------|------------------|----------------------|\n| Service Discovery | Backend server enumeration | `LoadBalancer` backend configuration | Kubernetes API, Consul, etcd |\n| Traffic Policy Engine | Request routing and shaping | `LoadBalancer` selection algorithm | Policy configuration store |\n| Distributed Tracing | Request correlation across services | All component instrumentation | Jaeger, Zipkin, OpenTelemetry |\n| mTLS Manager | Inter-service authentication | `SSLTermination` certificate management | Certificate authority integration |\n\nThe service mesh extension enables **progressive traffic deployment** (canary releases and blue-green deployments), **circuit breaker patterns** (automatic failure isolation), **retry and timeout policies** (configurable resilience patterns), and **traffic splitting** (A/B testing and gradual rollouts).\n\n**Service Mesh Policies:**\n\n| Policy Type | Configuration Scope | Enforcement Point | Dynamic Updates |\n|-------------|-------------------|------------------|-----------------|\n| Traffic Routing | Per-service destination | Backend selection | Real-time via API |\n| Retry Behavior | Per-service or per-endpoint | Connection failure handling | Configuration reload |\n| Timeout Values | Per-service or per-operation | Request processing | Real-time via API |\n| Circuit Breaker | Per-backend server | Health checking integration | Real-time via API |\n| Load Balancing | Per-service backend pool | Load balancer algorithm | Configuration reload |\n\n### Multi-Tenancy Support\n\nMulti-tenancy resembles managing a large apartment building where different tenants share common infrastructure (elevators, utilities, security) while maintaining complete isolation of their private spaces and resources. The building management system ensures that tenant A cannot access tenant B's apartment, utilities are billed correctly, and common areas remain available to all authorized residents.\n\nThe multi-tenancy extension adds **tenant isolation** (separate resource pools and configurations), **tenant-aware routing** (directing requests to appropriate backend clusters), **resource quotas** (preventing tenant resource exhaustion), and **audit isolation** (separate logging and monitoring per tenant).\n\n**Multi-Tenant Architecture:**\n\n| Isolation Layer | Implementation Method | Resource Separation | Configuration Management |\n|----------------|----------------------|-------------------|-------------------------|\n| Network | Virtual routing tables | Separate backend pools per tenant | Tenant-specific load balancer rules |\n| Cache | Namespace prefixing | Isolated cache partitions | Per-tenant cache policies |\n| SSL | Certificate management | Tenant-specific certificates | SNI-based tenant resolution |\n| Monitoring | Metric tagging | Separate metric namespaces | Tenant-aware dashboards |\n| Rate Limiting | Client classification | Per-tenant rate limits | Tenant-specific policies |\n\nThe multi-tenancy system determines tenant identity through multiple methods: **subdomain analysis** (tenant1.example.com), **URL path prefixes** (/tenant1/api/...), **custom headers** (X-Tenant-ID), or **SSL certificate subject names**. Once identified, all proxy components apply tenant-specific configurations and resource allocations.\n\n### Design Extensibility Features\n\nThe current reverse proxy architecture accommodates future extensions through several key design patterns that were established during the core implementation phases.\n\n> **Decision: Extension Hook Architecture**\n> - **Context**: Future features require integration points without modifying core component logic or destabilizing existing functionality\n> - **Options Considered**: Callback functions, Event publishing/subscription, Component inheritance\n> - **Decision**: Event publishing with typed message interfaces and subscriber registration\n> - **Rationale**: Provides loose coupling between extensions and core components while maintaining type safety and compile-time validation\n> - **Consequences**: Extensions can observe and modify request processing without requiring changes to core components, but extension interactions must be carefully coordinated\n\n**Extension Integration Patterns:**\n\n| Pattern | Usage Scenario | Implementation Method | Trade-offs |\n|---------|---------------|----------------------|------------|\n| Pre-processing Hooks | Request modification before routing | Event subscription at request parsing completion | Low latency, limited context |\n| Post-processing Hooks | Response modification before client delivery | Event subscription at response generation | Full context, higher latency |\n| Component Replacement | Alternative algorithm implementations | Interface inheritance with factory selection | Maximum flexibility, complexity |\n| Configuration Extensions | New configuration sections | Configuration parser plugin registration | Easy integration, limited runtime changes |\n\nThe `EventDispatcher` component, introduced during the core architecture phase, provides the foundation for extension integration. Extensions register event handlers for specific processing stages, receiving typed messages with full request context and the ability to modify processing behavior.\n\n**Extension Event Types:**\n\n| Event Type | Trigger Point | Message Data | Extension Capabilities |\n|------------|--------------|--------------|----------------------|\n| `RequestParsed` | After HTTP parsing completion | `HttpRequest*`, `Connection*` | Header modification, request blocking |\n| `BackendSelected` | After load balancer decision | `BackendServer*`, `HttpRequest*` | Backend override, request transformation |\n| `CacheLookup` | Before cache key generation | `HttpRequest*`, cache key | Cache key modification, bypass decisions |\n| `ResponseReceived` | After backend response arrival | `HttpResponse*`, `BackendServer*` | Content transformation, header injection |\n| `ConnectionEstablished` | After client connection acceptance | `Connection*`, client address | Connection rejection, metadata attachment |\n\nThe configuration system supports extension-specific sections through a plugin registration mechanism. Extensions provide configuration schema definitions that integrate with the main configuration parser, enabling complex extension settings while maintaining configuration validation and hot-reload capabilities.\n\n### Performance Considerations for Extensions\n\nExtensions must balance functionality with performance impact, particularly since the reverse proxy operates in the critical path of application traffic. The architecture provides several mechanisms to minimize extension overhead while maximizing functionality.\n\n**Performance Optimization Strategies:**\n\n| Strategy | Application Area | Performance Gain | Implementation Complexity |\n|----------|-----------------|------------------|--------------------------|\n| Event Filtering | Extension activation | Skip unused extensions | Low |\n| Asynchronous Processing | Heavy computations | Non-blocking request path | High |\n| Result Caching | Expensive operations | Amortized computation cost | Moderate |\n| Bulk Operations | Batch processing | Reduced per-request overhead | Moderate |\n\nExtensions that perform expensive operations (content transformation, complex authentication) implement **asynchronous processing patterns** where the extension initiates background work and registers completion callbacks. This approach prevents extension processing from blocking the main request pipeline while ensuring that responses incorporate extension results.\n\nThe extension system includes **performance budgets** that limit the maximum processing time extensions can consume per request. When extensions exceed their allocated time budget, the system can skip optional extensions, use cached results, or fail gracefully while maintaining core proxy functionality.\n\n### Common Extension Pitfalls\n\n⚠️ **Pitfall: Memory Leaks in Extension Data**\nExtensions that allocate memory for request processing (authentication tokens, transformation buffers, cached results) must properly integrate with the connection lifecycle to ensure cleanup. Extension data attached to `Connection` structures requires cleanup callbacks registered during attachment.\n\n⚠️ **Pitfall: Blocking Operations in Extension Hooks**\nExtensions that perform synchronous I/O operations (database lookups, external API calls, file system access) in event handlers block the entire request processing pipeline. Extensions requiring external data must use asynchronous patterns with completion callbacks.\n\n⚠️ **Pitfall: Thread Safety in Extension State**\nExtensions that maintain global state (caches, configuration, metrics) must implement proper synchronization when accessed from multiple worker threads. The proxy's event-driven architecture ensures that request processing can occur concurrently across multiple connections.\n\n⚠️ **Pitfall: Extension Ordering Dependencies**\nMultiple extensions processing the same request can create ordering dependencies where Extension A's output becomes Extension B's input. The extension system requires explicit ordering configuration to ensure deterministic behavior.\n\n⚠️ **Pitfall: Configuration Validation Gaps**\nExtensions that introduce new configuration sections must implement comprehensive validation to prevent runtime failures. Invalid extension configuration should be detected during startup rather than during request processing.\n\n### Implementation Guidance\n\nThe reverse proxy's extension architecture leverages the event-driven foundation established during core development. Extensions integrate through well-defined interfaces that provide access to request context while maintaining performance and stability guarantees.\n\n**Technology Recommendations for Extensions:**\n\n| Extension Type | Simple Implementation | Advanced Implementation |\n|---------------|----------------------|------------------------|\n| Request Filtering | Direct header inspection | Pattern matching with compiled regex |\n| Content Transformation | String replacement | Streaming transformation with SAX parsing |\n| Authentication | Static token validation | JWT with cryptographic verification |\n| Monitoring | Simple counter increments | Time-series metrics with statistical aggregation |\n| Rate Limiting | Token bucket algorithm | Sliding window with distributed state |\n\n**Extension Integration File Structure:**\n```c\nproxy/\n├── core/                    ← Core proxy components\n│   ├── http_parser.c\n│   ├── connection_manager.c\n│   └── load_balancer.c\n├── extensions/              ← Extension implementations\n│   ├── rate_limiter/\n│   │   ├── rate_limiter.h   ← Extension interface\n│   │   ├── rate_limiter.c   ← Core rate limiting logic\n│   │   └── sliding_window.c ← Helper components\n│   ├── waf/\n│   │   ├── waf.h\n│   │   ├── rule_engine.c\n│   │   └── signature_db.c\n│   └── auth/\n│       ├── auth_extension.h\n│       ├── jwt_validator.c\n│       └── session_manager.c\n├── extension_framework/     ← Extension support infrastructure\n│   ├── event_dispatcher.h   ← Event system interfaces\n│   ├── extension_manager.c  ← Extension lifecycle management\n│   └── extension_config.c   ← Configuration integration\n└── config/                  ← Extension configuration\n    ├── rate_limits.conf\n    ├── waf_rules.conf\n    └── auth_policies.conf\n```\n\n**Extension Registration Infrastructure:**\n```c\n// Extension interface definition\ntypedef struct Extension {\n    char name[64];                           // Extension identifier\n    bool (*init)(ProxyConfig* config);      // Extension initialization\n    void (*destroy)(void);                  // Extension cleanup\n    EventHandler* handlers;                  // Event handler array\n    size_t handler_count;                   // Number of handlers\n} Extension;\n\n// Event handler definition for extensions\ntypedef struct EventHandler {\n    EventType event_type;                   // Which event to handle\n    int priority;                           // Handler execution order\n    bool (*handler_func)(EventData* data);  // Handler implementation\n    bool enabled;                           // Runtime enable/disable\n} EventHandler;\n\n// Extension manager for lifecycle control\ntypedef struct ExtensionManager {\n    Extension* extensions[MAX_EXTENSIONS];   // Loaded extensions\n    size_t extension_count;                 // Number of loaded extensions\n    HashTable* event_handlers;              // Handlers by event type\n    pthread_rwlock_t extensions_lock;       // Thread-safe registration\n    bool extensions_enabled;                // Global extension toggle\n} ExtensionManager;\n```\n\n**Core Extension Registration Functions:**\n```c\n// Register extension with the proxy system\nbool extension_manager_register(ExtensionManager* manager, Extension* ext) {\n    // TODO: Validate extension interface completeness\n    // TODO: Check for name conflicts with existing extensions\n    // TODO: Initialize extension with proxy configuration\n    // TODO: Register event handlers in dispatcher\n    // TODO: Add extension to manager's extension array\n    // Hint: Use write lock during registration to prevent races\n}\n\n// Initialize all registered extensions during proxy startup\nbool extension_manager_init_all(ExtensionManager* manager, ProxyConfig* config) {\n    // TODO: Iterate through registered extensions\n    // TODO: Call each extension's init function with config\n    // TODO: Disable extensions that fail initialization\n    // TODO: Sort event handlers by priority for each event type\n    // TODO: Log extension initialization results\n}\n\n// Dispatch event to all registered handlers\nbool extension_manager_dispatch_event(ExtensionManager* manager, EventType type, \n                                     EventData* data) {\n    // TODO: Look up handlers for the specified event type\n    // TODO: Execute handlers in priority order\n    // TODO: Stop processing if any handler returns false (blocks request)\n    // TODO: Update extension performance metrics\n    // TODO: Handle handler exceptions gracefully\n}\n```\n\n**Rate Limiting Extension Example:**\n```c\n// Rate limiting extension implementation\ntypedef struct RateLimitExtension {\n    RateLimiter* limiter;                   // Core rate limiting logic\n    pthread_t cleanup_thread;              // Background counter cleanup\n    bool thread_running;                    // Thread lifecycle flag\n} RateLimitExtension;\n\n// Extension initialization function\nbool rate_limit_extension_init(ProxyConfig* config) {\n    // TODO: Parse rate limiting configuration from config file\n    // TODO: Initialize rate limiter with configured rules\n    // TODO: Start background cleanup thread for expired counters\n    // TODO: Register event handlers for request arrival and response\n    // TODO: Set up performance monitoring for rate limit decisions\n}\n\n// Request arrival event handler for rate limiting\nbool rate_limit_handle_request(EventData* event_data) {\n    // TODO: Extract client identifier from request (IP, user ID, API key)\n    // TODO: Look up rate limit rules that apply to this request\n    // TODO: Check current request count against configured limits\n    // TODO: Update request counters for this client\n    // TODO: Return false to block request if limits exceeded, true to allow\n    // Hint: Generate HTTP 429 response with Retry-After header for blocked requests\n}\n```\n\n**Extension Configuration Integration:**\n```c\n// Extension configuration parser registration\ntypedef struct ExtensionConfigParser {\n    char section_name[64];                  // Configuration section identifier\n    bool (*parse_section)(cJSON* section, void** config); // Parser function\n    bool (*validate_config)(void* config); // Configuration validator\n    void (*free_config)(void* config);     // Configuration cleanup\n} ExtensionConfigParser;\n\n// Register configuration parser for extension\nbool config_register_extension_parser(ConfigManager* manager, \n                                     ExtensionConfigParser* parser) {\n    // TODO: Validate parser function pointers are non-null\n    // TODO: Check for section name conflicts\n    // TODO: Add parser to configuration manager's parser registry\n    // TODO: Enable hot-reload support for extension configuration\n}\n```\n\n**Milestone Checkpoint - Extension Framework:**\nAfter implementing the extension framework infrastructure, verify functionality by:\n\n1. **Extension Registration Test**: Create a simple test extension that logs requests and verify it loads correctly during proxy startup\n2. **Event Dispatch Test**: Send HTTP requests and confirm that extension event handlers receive appropriate event data\n3. **Configuration Integration Test**: Add extension-specific configuration and verify parsing and validation work correctly\n4. **Performance Test**: Measure request processing latency with and without extensions to ensure minimal overhead\n5. **Thread Safety Test**: Run concurrent requests while loading/unloading extensions to verify thread safety\n\nExpected behavior: Extensions should integrate seamlessly without impacting core proxy functionality, and extension failures should not crash the proxy process.\n\nThe extension architecture provides a robust foundation for evolving the reverse proxy to meet changing requirements while maintaining the performance, reliability, and security characteristics established during core development.\n\n\n## Glossary\n\n> **Milestone(s):** All milestones - this glossary provides definitions for technical terms, acronyms, and domain-specific vocabulary used throughout the reverse proxy implementation.\n\nA comprehensive understanding of reverse proxy terminology is essential for successfully implementing the HTTP proxy core, load balancing, connection pooling, caching, and SSL termination components. This glossary serves as your technical dictionary throughout the implementation journey.\n\n### Core Reverse Proxy Concepts\n\n**Reverse Proxy**\nA server that sits in front of one or more backend servers, intercepting requests from clients and forwarding them to the appropriate backend. Unlike a forward proxy that acts on behalf of clients, a reverse proxy acts on behalf of the servers. Think of it as a skilled receptionist at a large company who receives all visitor requests and directs them to the right department based on availability and specialization.\n\n**Forward Proxy**\nA proxy server that acts on behalf of clients, forwarding their requests to servers on the internet. The server sees the proxy's IP address rather than the client's original IP address. This is the traditional \"proxy\" that users configure in their browsers.\n\n**Backend Server**\nAn upstream server that actually processes client requests and generates responses. These are the real application servers that do the work, while the reverse proxy handles the complexity of client communication, load balancing, and optimization.\n\n**Upstream Server**\nAnother term for backend server, emphasizing that it's \"upstream\" in the request processing flow from the reverse proxy's perspective.\n\n**SSL Termination**\nThe process of decrypting SSL/TLS connections at the reverse proxy level, then forwarding the decrypted HTTP requests to backend servers over plain HTTP. This centralizes certificate management and reduces computational load on backend servers.\n\n**TLS Termination**\nModern terminology for SSL termination, as TLS (Transport Layer Security) has superseded SSL (Secure Sockets Layer) in practice, though the terms are often used interchangeably.\n\n### HTTP Protocol and Parsing\n\n**HTTP/1.1**\nThe widely-supported HTTP protocol version that uses text-based headers and supports persistent connections through the `Connection: keep-alive` header. Requests and responses are processed sequentially on each connection.\n\n**HTTP/2**\nA binary protocol that multiplexes multiple request-response streams over a single connection. It includes header compression and server push capabilities, requiring more complex parsing logic than HTTP/1.1.\n\n**Stream-Based Parsing**\nAn incremental parsing approach that processes HTTP messages as data arrives over the network, rather than buffering the entire message before parsing. This is essential for handling large requests and responses without excessive memory usage.\n\n**State Machine**\nA parsing approach where the parser maintains its current state (parsing request line, headers, body, etc.) and transitions between states based on input data. This enables robust handling of partial reads and malformed input.\n\n**Request Smuggling**\nAn attack that exploits differences in how front-end proxies and backend servers parse HTTP messages, particularly around Content-Length and Transfer-Encoding headers. Proper parsing and validation prevent these vulnerabilities.\n\n**Chunked Transfer Encoding**\nAn HTTP mechanism for sending message bodies in chunks when the total size is unknown at transmission start. Each chunk is prefixed with its size in hexadecimal, followed by the data and a trailing CRLF.\n\n**Content-Length Header**\nHTTP header specifying the exact size of the message body in bytes. When present, it determines how much data to read for the complete message body.\n\n**Transfer-Encoding Header**\nHTTP header indicating how the message body is encoded for transfer. The most common value is \"chunked\" for chunked transfer encoding.\n\n**Keep-Alive Connection**\nHTTP/1.1 feature allowing multiple requests and responses to be sent over a single TCP connection, reducing the overhead of connection establishment and teardown.\n\n**Pipeline Depth**\nThe number of HTTP requests sent on a connection before waiting for responses. HTTP/1.1 pipelining allows multiple requests to be sent without waiting for each response, though it's rarely used in practice due to head-of-line blocking issues.\n\n### Connection Management\n\n**Connection Pooling**\nThe practice of maintaining persistent connections to backend servers and reusing them for multiple requests. This eliminates the TCP handshake overhead for each request and improves performance.\n\n**Connection Lifecycle**\nThe states and transitions connections go through from establishment to cleanup, including idle, reading request, forwarding, reading response, writing response, and closing states.\n\n**Event-Driven Architecture**\nAn architecture pattern using asynchronous I/O and event loops to handle many concurrent connections efficiently. Events like data arrival, connection completion, and timeouts trigger appropriate handlers.\n\n**LIFO Strategy**\nLast-In First-Out connection reuse strategy where the most recently used connection is selected first from the pool. This improves CPU cache locality and can reduce connection establishment overhead.\n\n**Connection State**\nThe current operational phase of a connection, such as `CONNECTION_IDLE`, `CONNECTION_READING_REQUEST`, `CONNECTION_FORWARDING`, `CONNECTION_READING_RESPONSE`, `CONNECTION_WRITING_RESPONSE`, or `CONNECTION_CLOSING`.\n\n**Resource Leak**\nA programming error where allocated system resources (file descriptors, memory, connections) are not properly released, eventually exhausting available resources and causing system failure.\n\n**Timeout Management**\nThe practice of enforcing time limits on network operations to prevent connections from hanging indefinitely and consuming system resources.\n\n**Timer Wheel**\nAn efficient data structure for managing timeouts with O(1) insertion and deletion operations. It uses a circular array of time slots, each containing operations that expire at that time.\n\n**Non-Blocking I/O**\nI/O operations that return immediately if no data is available, allowing a single thread to handle many connections by processing only those that are ready for I/O operations.\n\n**Edge-Triggered Events**\nEvent notification mode where events are delivered only when the state changes (e.g., from no data available to data available), requiring the application to process all available data before waiting for the next event.\n\n**Level-Triggered Events**\nEvent notification mode where events are delivered whenever the condition is true (e.g., data is available), making it easier to program but potentially less efficient than edge-triggered mode.\n\n### Load Balancing\n\n**Round-Robin**\nA load balancing algorithm that distributes requests by cycling through backend servers in order. Each server receives an equal number of requests over time, regardless of their current load or capacity.\n\n**Least-Connections**\nA load balancing algorithm that routes requests to the backend server with the fewest active connections. This helps balance load more dynamically than round-robin when requests have varying processing times.\n\n**Weighted Distribution**\nLoad balancing that accounts for different server capacities by assigning weights to each server. Servers with higher weights receive proportionally more requests than those with lower weights.\n\n**IP Hash**\nA load balancing method that uses a hash of the client's IP address to consistently route requests from the same client to the same backend server, providing session affinity.\n\n**Session Affinity**\nThe practice of routing requests from the same client session to the same backend server, ensuring that session state stored on the server remains accessible across requests.\n\n**Sticky Sessions**\nAnother term for session affinity, emphasizing that client sessions \"stick\" to particular backend servers for the duration of the session.\n\n**Health Checking**\nThe process of periodically testing backend servers to determine their availability and readiness to handle requests. Failed health checks remove servers from the active pool.\n\n**Failure Threshold**\nThe number of consecutive health check failures required before marking a backend server as unhealthy and removing it from the load balancing rotation.\n\n**Success Threshold**\nThe number of consecutive health check successes required before marking a previously failed backend server as healthy and returning it to the load balancing rotation.\n\n**Graceful Degradation**\nThe ability to continue operating with reduced functionality when some backend servers fail, rather than experiencing complete system failure.\n\n**Connection Count**\nThe number of active connections currently being handled by a backend server, used by least-connections load balancing algorithms to make routing decisions.\n\n**Backend Selection**\nThe process of choosing which available backend server should handle an incoming request based on the configured load balancing algorithm and server health status.\n\n### Caching\n\n**Cache Hit**\nA request for which a valid cached response exists and can be returned to the client without contacting the backend server. This improves response time and reduces backend load.\n\n**Cache Miss**\nA request for which no cached response exists or the cached response is stale, requiring the proxy to forward the request to a backend server.\n\n**TTL (Time To Live)**\nThe duration for which a cached entry remains valid before it expires and must be refreshed from the backend server.\n\n**TTL Expiration**\nThe process of cached entries becoming stale due to exceeding their time-to-live limits, requiring revalidation or refresh from the backend.\n\n**Cache Key**\nA unique identifier generated from request attributes (method, URL, headers) used to store and retrieve cached responses. Proper key generation is crucial for cache correctness.\n\n**Cache-Control Header**\nHTTP header containing directives that specify caching behavior, including whether responses can be cached, for how long, and under what conditions.\n\n**ETag (Entity Tag)**\nA unique identifier assigned to a specific version of a resource, used for cache validation through conditional requests to determine if cached content is still current.\n\n**Last-Modified Header**\nHTTP header indicating when a resource was last changed, used for cache validation through conditional requests with If-Modified-Since headers.\n\n**Conditional Request**\nHTTP requests that include headers like If-Modified-Since or If-None-Match to allow servers to respond with 304 Not Modified if the cached version is still current.\n\n**304 Not Modified**\nHTTP status code indicating that a cached response is still valid, sent in response to conditional requests when the resource hasn't changed since the cached version.\n\n**Vary Header**\nHTTP response header indicating which request headers were used to generate the response, affecting cache key generation to ensure proper cache segmentation.\n\n**LRU (Least Recently Used)**\nA cache eviction policy that removes the least recently accessed entries when the cache reaches its capacity limit, keeping frequently accessed content in cache longer.\n\n**Cache Invalidation**\nThe process of removing or marking cached entries as invalid, either due to TTL expiration, explicit purge requests, or backend error conditions.\n\n**Cache Validation**\nThe process of checking whether a cached response is still valid by sending conditional requests to the backend server.\n\n**No-Cache Directive**\nCache-Control directive indicating that cached responses must be validated with the origin server before being served to clients.\n\n**No-Store Directive**\nCache-Control directive indicating that responses must not be stored in any cache, typically used for sensitive or highly dynamic content.\n\n**Max-Age Directive**\nCache-Control directive specifying the maximum time in seconds that a response may be cached before it becomes stale and requires revalidation.\n\n### SSL/TLS and Security\n\n**TLS Context**\nThe cryptographic configuration and state information for SSL/TLS connections, including certificates, private keys, cipher preferences, and protocol versions.\n\n**SSL Context**\nLegacy term for TLS context, still commonly used even though TLS has replaced SSL in modern implementations.\n\n**SNI (Server Name Indication)**\nA TLS extension that allows clients to specify which hostname they're connecting to, enabling a single IP address to serve multiple SSL certificates for different domains.\n\n**Certificate Chain**\nThe sequence of certificates from the server's leaf certificate up to a trusted root CA certificate, required for clients to verify the server's authenticity.\n\n**Wildcard Certificate**\nAn SSL certificate valid for multiple subdomains of a domain (e.g., *.example.com covers api.example.com, www.example.com, etc.).\n\n**Subject Alternative Name (SAN)**\nX.509 certificate extension that allows a single certificate to be valid for multiple hostnames, providing an alternative to wildcard certificates.\n\n**Cipher Suite**\nA combination of encryption algorithms used in TLS connections, including key exchange, authentication, bulk encryption, and message authentication algorithms.\n\n**Perfect Forward Secrecy**\nA security property ensuring that session keys cannot be derived from long-term keys, so compromising long-term keys doesn't compromise past communication sessions.\n\n**AEAD Cipher**\nAuthenticated Encryption with Associated Data cipher that provides both confidentiality and authenticity in a single operation, preferred in modern TLS implementations.\n\n**TLS Handshake**\nThe initial negotiation process between client and server to establish encryption parameters, exchange certificates, and derive session keys for secure communication.\n\n**Certificate Validation**\nThe process of verifying that a server's certificate is valid, properly signed by a trusted CA, not expired, and matches the requested hostname.\n\n**Session Resumption**\nTLS optimization that allows clients and servers to reuse previously established session parameters, reducing handshake overhead for subsequent connections.\n\n**Cipher Preference**\nThe order in which cipher suites are preferred during TLS negotiation, typically prioritizing stronger, more secure cipher suites over weaker alternatives.\n\n### Error Handling and Recovery\n\n**Cascade Failure**\nA failure propagation pattern where the failure of one component triggers failures in dependent components, potentially causing widespread system failure.\n\n**Circuit Breaker**\nA design pattern that prevents operations when error rates exceed configured thresholds, allowing systems to fail fast and recover more quickly.\n\n**Exponential Backoff**\nA retry strategy where the delay between retry attempts increases exponentially, reducing load on failing systems and improving recovery chances.\n\n**Error Sanitization**\nThe practice of removing sensitive information (internal paths, stack traces, configuration details) from error messages shown to clients.\n\n**Graceful Shutdown**\nThe process of cleanly stopping a server by finishing in-flight requests, closing connections properly, and releasing resources before termination.\n\n**Health Check Endpoint**\nA specific URL path that backend servers expose to indicate their readiness to handle requests, used by load balancers for health monitoring.\n\n**Retry Logic**\nAutomated mechanisms for retrying failed operations with appropriate delays and limits to handle transient failures without overwhelming systems.\n\n**Fallback Mechanism**\nAlternative behavior implemented when primary systems fail, such as serving cached content when backends are unavailable.\n\n**Dead Letter Queue**\nA storage mechanism for requests that cannot be processed successfully after multiple retry attempts, allowing for later analysis or manual intervention.\n\n**Bulkhead Pattern**\nAn isolation strategy that prevents failures in one part of the system from affecting other parts, similar to watertight compartments in ships.\n\n### Performance and Monitoring\n\n**Latency**\nThe time delay between sending a request and receiving a response, typically measured in milliseconds for HTTP operations.\n\n**Throughput**\nThe number of requests processed per unit time, typically measured in requests per second (RPS) for reverse proxy performance.\n\n**Connection Multiplexing**\nThe ability to handle multiple requests simultaneously over a single connection, particularly important in HTTP/2 implementations.\n\n**Keep-Alive Timeout**\nThe duration a connection remains open waiting for additional requests before being closed to free up resources.\n\n**Request Rate Limiting**\nControlling the number of requests accepted from clients over a specific time period to prevent overload and ensure fair resource usage.\n\n**Response Time Percentiles**\nStatistical measures (P50, P95, P99) indicating the response time below which a certain percentage of requests are served, useful for understanding performance distribution.\n\n**Memory Footprint**\nThe amount of system memory used by the reverse proxy, important for capacity planning and resource optimization.\n\n**File Descriptor Usage**\nThe number of file descriptors (handles for files, sockets, etc.) used by the proxy, as each connection typically requires at least one file descriptor.\n\n**CPU Utilization**\nThe percentage of available CPU resources being used by the proxy, affecting its ability to handle concurrent connections and requests.\n\n**Bandwidth Utilization**\nThe amount of network bandwidth consumed by the proxy for client and backend communications, important for capacity planning.\n\n### Testing and Development\n\n**Unit Testing**\nTesting individual components in isolation using mock implementations of dependencies to verify correct behavior under various conditions.\n\n**Integration Testing**\nTesting interactions between multiple components to ensure they work correctly together and handle data flow properly.\n\n**Milestone Verification**\nPredefined checkpoints that validate implementation progress, ensuring each milestone's acceptance criteria are met before proceeding.\n\n**Synthetic Testing**\nUsing artificially generated test data and scenarios to validate system behavior under controlled conditions.\n\n**Load Testing**\nTesting system performance under high request volumes to identify bottlenecks and capacity limits.\n\n**Stress Testing**\nTesting system behavior under extreme conditions beyond normal operating parameters to identify failure modes and recovery behavior.\n\n**Mock Implementation**\nFake components that simulate real behavior for testing purposes, allowing isolation of the component under test.\n\n**Test Harness**\nA framework that automates test execution, result collection, and validation across multiple test scenarios.\n\n**Deterministic Testing**\nTests designed to produce predictable, repeatable outcomes regardless of execution timing or environment variations.\n\n**Regression Testing**\nRe-running existing tests after code changes to ensure new modifications don't break previously working functionality.\n\n### Architecture and Design Patterns\n\n**Component Architecture**\nA design approach that breaks the system into discrete, loosely-coupled components with well-defined responsibilities and interfaces.\n\n**Dependency Injection**\nA design pattern where components receive their dependencies through constructor parameters or setters rather than creating them directly.\n\n**Observer Pattern**\nA design pattern where components register to receive notifications about events or state changes in other components.\n\n**Factory Pattern**\nA creational pattern that provides an interface for creating objects without specifying their concrete classes.\n\n**Singleton Pattern**\nA design pattern ensuring only one instance of a class exists, commonly used for global configuration and resource managers.\n\n**State Pattern**\nA behavioral pattern that allows objects to change their behavior based on internal state changes, useful for connection and parser state management.\n\n**Strategy Pattern**\nA behavioral pattern that defines a family of algorithms (like load balancing strategies) and makes them interchangeable at runtime.\n\n**Facade Pattern**\nA structural pattern that provides a simplified interface to a complex subsystem, hiding implementation details from clients.\n\n### Network and System Programming\n\n**Epoll**\nA Linux system call for efficient I/O event notification that can monitor many file descriptors for events without the overhead of polling each one individually.\n\n**Kqueue**\nA BSD system call similar to epoll, providing scalable event notification for file descriptors and other system events.\n\n**File Descriptor**\nAn operating system handle representing an open file, socket, or other I/O resource, with each process having a limited number available.\n\n**Socket Programming**\nNetwork programming using BSD socket APIs to create, bind, listen, accept, connect, send, and receive data over TCP/UDP connections.\n\n**TCP Nodelay**\nA socket option that disables Nagle's algorithm, reducing latency by immediately sending small packets rather than waiting to accumulate more data.\n\n**SO_REUSEADDR**\nA socket option allowing immediate reuse of local addresses, particularly useful for server sockets that need to restart quickly.\n\n**Buffer Management**\nTechniques for efficiently handling data buffers during network I/O operations, including allocation, reuse, and memory management strategies.\n\n**Memory Pool**\nA memory management technique that pre-allocates large blocks of memory and suballocates from them to reduce allocation overhead and fragmentation.\n\n### Extension and Plugin Architecture\n\n**Extension Architecture**\nA framework for adding new functionality to the reverse proxy without modifying core components, enabling modularity and customization.\n\n**Plugin System**\nA modular architecture allowing runtime loading of additional features through dynamically loaded libraries or modules.\n\n**Event-Driven Hooks**\nCallback mechanisms that allow extensions to intercept and modify request processing at specific points in the pipeline.\n\n**Rate Limiting**\nControlling request frequency from clients to prevent overload and ensure fair resource usage across multiple clients.\n\n**Web Application Firewall (WAF)**\nSecurity extension that examines HTTP requests for malicious patterns and blocks potentially harmful traffic.\n\n**Authentication Extension**\nModule responsible for verifying client identity and authorization before allowing access to backend services.\n\n**Monitoring Extension**\nModule that collects metrics, logs, and observability data about proxy operations and performance.\n\n**Multi-Tenancy**\nArchitecture pattern for serving multiple isolated customers or applications from a single proxy instance with proper resource isolation.\n\n**Service Mesh Integration**\nFeatures for integrating with distributed system coordination platforms that provide service discovery, load balancing, and observability.\n\n**Content Transformation**\nExtensions that modify response content, headers, or format before delivering to clients, such as compression or format conversion.\n\n### Acronyms and Abbreviations\n\n**HTTP**: HyperText Transfer Protocol\n**HTTPS**: HyperText Transfer Protocol Secure  \n**SSL**: Secure Sockets Layer\n**TLS**: Transport Layer Security\n**TCP**: Transmission Control Protocol\n**UDP**: User Datagram Protocol\n**DNS**: Domain Name System\n**IP**: Internet Protocol\n**URL**: Uniform Resource Locator\n**URI**: Uniform Resource Identifier\n**API**: Application Programming Interface\n**JSON**: JavaScript Object Notation\n**XML**: eXtensible Markup Language\n**MIME**: Multipurpose Internet Mail Extensions\n**CORS**: Cross-Origin Resource Sharing\n**CDN**: Content Delivery Network\n**DDoS**: Distributed Denial of Service\n**CA**: Certificate Authority\n**CRL**: Certificate Revocation List\n**OCSP**: Online Certificate Status Protocol\n**RSA**: Rivest-Shamir-Adleman (encryption algorithm)\n**AES**: Advanced Encryption Standard\n**SHA**: Secure Hash Algorithm\n**HMAC**: Hash-based Message Authentication Code\n**CSRF**: Cross-Site Request Forgery\n**XSS**: Cross-Site Scripting\n**SQL**: Structured Query Language\n**REST**: Representational State Transfer\n**SOAP**: Simple Object Access Protocol\n**gRPC**: Google Remote Procedure Call\n**WebSocket**: Web Socket Protocol\n**SPDY**: SPeeDY (HTTP/2 predecessor)\n**QUIC**: Quick UDP Internet Connections\n**MTU**: Maximum Transmission Unit\n**MSS**: Maximum Segment Size\n**TTL**: Time To Live\n**QoS**: Quality of Service\n**SLA**: Service Level Agreement\n**RTO**: Request Time Out\n**RTT**: Round Trip Time\n**ACK**: Acknowledgment\n**SYN**: Synchronize\n**FIN**: Finish\n**PSH**: Push\n**RST**: Reset\n**URG**: Urgent\n\n### Implementation Guidance\n\nThis section provides practical guidance for implementing reverse proxy components with proper terminology usage throughout the codebase.\n\n#### A. Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| HTTP Parser | Manual state machine with `HttpParser` | ANTLR/Yacc generated parser |\n| Event Loop | Basic epoll with `EventDispatcher` | libevent/libuv wrapper |\n| SSL/TLS | OpenSSL with `SSLTermination` | BoringSSL or wolfSSL |\n| Logging | Simple file logging with `LogLevel` | Structured logging with syslog |\n| Configuration | INI file parsing with `ProxyConfig` | YAML/JSON with schema validation |\n| Testing | Custom test framework | CUnit/Unity testing framework |\n\n#### B. Recommended File Structure\n\nThe codebase should be organized to reflect the component architecture and terminology used throughout this glossary:\n\n```\nreverse-proxy/\n├── src/\n│   ├── core/\n│   │   ├── proxy_server.c           ← Main ProxyServer implementation\n│   │   ├── proxy_server.h           ← Public ProxyServer interface\n│   │   └── proxy_config.c           ← ProxyConfig loading and validation\n│   ├── http/\n│   │   ├── http_parser.c            ← HttpParser state machine\n│   │   ├── http_request.c           ← HttpRequest manipulation\n│   │   └── http_response.c          ← HttpResponse handling\n│   ├── connection/\n│   │   ├── connection_manager.c     ← ConnectionManager with event-driven I/O\n│   │   ├── connection_pool.c        ← ConnectionPool per backend\n│   │   └── timer_wheel.c            ← TimerWheel timeout management\n│   ├── load_balancer/\n│   │   ├── load_balancer.c          ← LoadBalancer algorithms\n│   │   ├── backend_server.c         ← BackendServer health checking\n│   │   └── health_checker.c         ← Health checking implementation\n│   ├── cache/\n│   │   ├── cache_engine.c           ← CacheEngine with LRU eviction\n│   │   ├── cache_control.c          ← CacheControl header parsing\n│   │   └── lru_list.c              ← LRUList implementation\n│   ├── ssl/\n│   │   ├── ssl_termination.c        ← SSLTermination with SNI support\n│   │   └── ssl_utils.c              ← Certificate loading utilities\n│   ├── error/\n│   │   ├── error_handler.c          ← ErrorHandler for recovery coordination\n│   │   └── recovery_manager.c       ← RecoveryManager for failure handling\n│   └── utils/\n│       ├── buffer.c                 ← Buffer management utilities\n│       ├── hashtable.c              ← HashTable implementation\n│       └── logger.c                 ← Logging with LogLevel support\n├── include/\n│   └── reverse_proxy/               ← Public header files\n├── tests/\n│   ├── unit/                        ← Unit tests for individual components\n│   ├── integration/                 ← Integration tests for component interactions\n│   └── mocks/                       ← MockSocket and test utilities\n├── config/\n│   └── proxy.conf                   ← Example ProxyConfig file\n└── docs/\n    └── terminology.md               ← This glossary for reference\n```\n\n#### C. Terminology Usage in Code\n\nWhen implementing components, use the exact terminology from this glossary in comments, variable names, and function names. This creates consistency between the design documentation and implementation:\n\n```c\n// Example: Connection state management using proper terminology\ntypedef enum {\n    CONNECTION_IDLE,              // Connection waiting for new request\n    CONNECTION_READING_REQUEST,   // Receiving HTTP request from client\n    CONNECTION_FORWARDING,        // Forwarding request to backend server\n    CONNECTION_READING_RESPONSE,  // Receiving response from backend\n    CONNECTION_WRITING_RESPONSE,  // Sending response back to client\n    CONNECTION_CLOSING           // Graceful connection shutdown\n} ConnectionState;\n\n// Example: Load balancing algorithm enumeration\ntypedef enum {\n    LB_ROUND_ROBIN,              // Round-robin backend selection\n    LB_LEAST_CONNECTIONS,        // Least-connections algorithm\n    LB_WEIGHTED_ROUND_ROBIN,     // Weighted distribution\n    LB_IP_HASH                   // IP hash for session affinity\n} LoadBalancingAlgorithm;\n```\n\n#### D. Common Implementation Terminology Mistakes\n\n| Incorrect Term | Correct Term | Explanation |\n|----------------|--------------|-------------|\n| \"Upstream proxy\" | \"Reverse proxy\" | Avoids confusion with forward proxies |\n| \"SSL connection\" | \"TLS connection\" | Uses modern terminology |\n| \"Connection reuse\" | \"Connection pooling\" | More specific technical term |\n| \"Request caching\" | \"Response caching\" | Clarifies what is actually cached |\n| \"Server selection\" | \"Backend selection\" | Distinguishes from client/proxy server |\n| \"Health monitoring\" | \"Health checking\" | Standard industry terminology |\n| \"Certificate reload\" | \"Certificate rotation\" | Different concepts |\n| \"Error recovery\" | \"Failure recovery\" | More precise terminology |\n\n#### E. Documentation and Comment Guidelines\n\nUse consistent terminology in all code comments and documentation:\n\n```c\n/**\n * connection_manager_acquire_backend - Acquire backend connection from pool\n * @manager: ConnectionManager instance\n * @backend: Target BackendServer for connection\n * @timeout_ms: Connection timeout in milliseconds\n *\n * Attempts to acquire a connection from the connection pool for the specified\n * backend server. If no idle connections are available, creates a new connection\n * up to the pool's maximum limit. Uses LIFO strategy for cache locality.\n *\n * Returns: Connection pointer on success, NULL on failure\n */\nConnection* connection_manager_acquire_backend(ConnectionManager* manager,\n                                               BackendServer* backend,\n                                               int timeout_ms);\n```\n\n#### F. Debugging Terminology Reference\n\nWhen debugging reverse proxy issues, use precise terminology to communicate problems effectively:\n\n| Problem Area | Correct Terminology | Avoid |\n|-------------|-------------------|-------|\n| Connection issues | \"Connection pool exhausted\" | \"Out of connections\" |\n| SSL problems | \"TLS handshake failure\" | \"SSL error\" |\n| Parsing errors | \"HTTP parser state machine error\" | \"Bad request\" |\n| Load balancing | \"Backend server health check failure\" | \"Server down\" |\n| Caching | \"Cache miss due to TTL expiration\" | \"Cache not working\" |\n| Performance | \"High connection establishment latency\" | \"Slow connections\" |\n\nThis terminology consistency ensures clear communication between team members and accurate problem diagnosis throughout the development process.\n"}