{"html":"<h1 id=\"semantic-search-engine-design-document\">Semantic Search Engine: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A semantic search engine that understands meaning rather than just matching keywords, using neural embeddings to find conceptually similar documents. The key architectural challenge is efficiently indexing and searching high-dimensional vector spaces while combining multiple ranking signals for optimal relevance.</p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing why semantic search is necessary and how it improves upon traditional approaches.</p>\n</blockquote>\n<h3 id=\"from-keywords-to-meaning-mental-model\">From Keywords to Meaning: Mental Model</h3>\n<p>Think of traditional keyword search like a <strong>librarian who can only match exact words</strong>. When you ask for &quot;books about canines,&quot; this librarian can only find books with the exact word &quot;canines&quot; in their title or description. They completely miss excellent books about &quot;dogs,&quot; &quot;puppies,&quot; &quot;wolves,&quot; or &quot;German Shepherds&quot; — even though these are exactly what you&#39;re looking for. The librarian understands the letters and words perfectly, but has no concept that &quot;canine&quot; and &quot;dog&quot; refer to the same thing.</p>\n<p>In contrast, semantic search works like a <strong>knowledgeable librarian who understands concepts and meaning</strong>. When you ask about &quot;canines,&quot; they immediately know you&#39;re interested in the broader concept of dog-family animals. They can recommend books about &quot;loyal companions,&quot; &quot;man&#39;s best friend,&quot; or even &quot;veterinary care for pets&quot; — because they understand the semantic relationships between concepts, not just the surface-level words.</p>\n<p>This fundamental difference transforms how information retrieval works. Traditional <strong>lexical search</strong> operates in the space of exact character sequences — it&#39;s fast and precise for literal matches, but brittle when users express the same concept using different vocabulary. <strong>Semantic search</strong> operates in the space of meaning representations — it can bridge vocabulary gaps, understand synonyms, and even grasp conceptual relationships that don&#39;t share any common words.</p>\n<p>The core challenge that semantic search solves is the <strong>vocabulary mismatch problem</strong>. Users naturally express their information needs using their own vocabulary, which often differs from how document authors chose to phrase the same concepts. A user searching for &quot;heart attack symptoms&quot; should find documents about &quot;myocardial infarction signs&quot; or &quot;cardiac event indicators.&quot; Traditional keyword search fails here because there are zero overlapping terms, despite the documents being highly relevant.</p>\n<p>Modern semantic search engines solve this by learning <strong>dense vector representations</strong> (embeddings) that capture the meaning of text in high-dimensional space. Words, phrases, and documents that are conceptually similar end up close together in this vector space, even if they share no common vocabulary. The search engine can then find relevant documents by measuring distances in this semantic space rather than counting keyword overlaps.</p>\n<blockquote>\n<p>The key insight is that semantic similarity in vector space often correlates much better with human judgments of relevance than lexical similarity based on word matching. This is why semantic search can feel almost magical — it finds what you meant, not just what you said.</p>\n</blockquote>\n<p>However, this conceptual power comes with significant engineering challenges. Vector representations are typically 300-1000 dimensions, making exact similarity search computationally expensive. Indexing millions of high-dimensional vectors requires sophisticated approximate algorithms like <strong>Hierarchical Navigable Small World (HNSW)</strong> or <strong>Inverted File (IVF)</strong> structures. Query processing becomes more complex because we need to balance semantic understanding with other relevance signals like freshness, popularity, and personalization.</p>\n<p>The mental model for building a semantic search engine is like constructing a <strong>multidimensional library</strong> where books are organized not just by subject categories, but by their position in a vast space of meaning. Finding relevant books requires navigating this high-dimensional space efficiently while combining multiple signals to determine which books best match the user&#39;s intent.</p>\n<h3 id=\"existing-search-technologies\">Existing Search Technologies</h3>\n<p>Understanding how semantic search fits into the broader landscape of information retrieval requires examining three primary approaches: lexical search, vector search, and hybrid systems. Each has distinct strengths and limitations that influence when and how they should be deployed.</p>\n<p><strong>Lexical Search Technologies</strong></p>\n<p>Traditional lexical search, exemplified by systems like <strong>Elasticsearch</strong> and <strong>Apache Solr</strong>, operates on the principle of term frequency analysis. These systems build <strong>inverted indexes</strong> that map each unique term to the list of documents containing it. Search queries are processed by finding documents that contain query terms, typically ranked using algorithms like <strong>BM25 (Best Matching 25)</strong>.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Description</th>\n<th>Strengths</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Inverted Index</td>\n<td>Maps terms → document lists with frequency statistics</td>\n<td>Fast exact matches, low storage overhead, well-understood scaling</td>\n<td>No semantic understanding, vocabulary mismatch, requires exact or stem matches</td>\n</tr>\n<tr>\n<td>BM25 Ranking</td>\n<td>Scores documents based on term frequency, document length, collection statistics</td>\n<td>Excellent for precise queries, handles document length normalization, proven effectiveness</td>\n<td>Cannot bridge vocabulary gaps, over-emphasizes rare terms, ignores concept relationships</td>\n</tr>\n<tr>\n<td>Query Processing</td>\n<td>Term extraction, stemming, boolean operators, phrase matching</td>\n<td>Predictable behavior, supports complex boolean logic, fast execution</td>\n<td>Users must know exact terminology, no query intent understanding, brittle to paraphrasing</td>\n</tr>\n<tr>\n<td>Index Updates</td>\n<td>Real-time document addition/removal with incremental index updates</td>\n<td>Low-latency updates, consistent availability, simple rollback procedures</td>\n<td>Full-text reindexing expensive, schema changes require rebuild, limited semantic enrichment</td>\n</tr>\n</tbody></table>\n<p>The fundamental strength of lexical search is <strong>predictable precision</strong> — when users know the exact terminology used in documents, lexical search provides fast, accurate results. It excels in domains with standardized vocabulary, such as legal document search, product catalogs with controlled taxonomies, or technical documentation where precise terminology matters.</p>\n<p>However, lexical search fails catastrophically in scenarios with high vocabulary diversity. Customer support queries like &quot;my internet is slow&quot; won&#39;t match knowledge base articles titled &quot;troubleshooting bandwidth limitations&quot; or &quot;resolving connectivity performance issues,&quot; despite being directly relevant. This brittleness drives the need for semantic approaches.</p>\n<p><strong>Vector Search Technologies</strong></p>\n<p>Pure vector search systems, such as <strong>Pinecone</strong>, <strong>Weaviate</strong>, or <strong>FAISS-based</strong> solutions, represent documents and queries as high-dimensional embeddings in continuous vector space. Similarity is measured using metrics like cosine similarity or Euclidean distance, with search performed using approximate nearest neighbor (ANN) algorithms.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Description</th>\n<th>Strengths</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dense Embeddings</td>\n<td>Documents/queries encoded as 384-1024 dimensional vectors</td>\n<td>Captures semantic relationships, bridges vocabulary gaps, language-agnostic similarity</td>\n<td>Opaque representations, computationally expensive, requires ML model inference</td>\n</tr>\n<tr>\n<td>ANN Indexing</td>\n<td>HNSW, IVF, or LSH structures for efficient similarity search</td>\n<td>Handles high-dimensional data, sub-linear search complexity, memory-efficient options</td>\n<td>Approximate results only, complex parameter tuning, index construction overhead</td>\n</tr>\n<tr>\n<td>Embedding Models</td>\n<td>Transformer-based encoders (BERT, Sentence-BERT, etc.)</td>\n<td>Strong semantic understanding, transfer learning from large corpora, multilingual support</td>\n<td>Model size and inference cost, domain adaptation challenges, potential bias</td>\n</tr>\n<tr>\n<td>Similarity Metrics</td>\n<td>Cosine similarity, dot product, Euclidean distance calculations</td>\n<td>Mathematically principled, differentiable for ML optimization, interpretable geometry</td>\n<td>Distance doesn&#39;t directly correlate with relevance, sensitive to vector normalization, curse of dimensionality</td>\n</tr>\n</tbody></table>\n<p>Vector search excels at <strong>conceptual matching</strong> and <strong>cross-lingual retrieval</strong>. It can successfully match &quot;heart attack symptoms&quot; with &quot;myocardial infarction signs&quot; because both phrases produce similar embedding vectors. It also handles paraphrasing naturally — multiple ways of expressing the same concept cluster together in vector space.</p>\n<p>The primary limitation is <strong>lack of exact match precision</strong>. Vector search might miss documents containing the exact query terms if the overall semantic context differs. A query for &quot;Python programming&quot; might return results about &quot;machine learning&quot; or &quot;data science&quot; — conceptually related but potentially not what the user intended if they specifically need Python language documentation.</p>\n<p><strong>Hybrid Search Approaches</strong></p>\n<p>Modern production search systems increasingly adopt <strong>hybrid architectures</strong> that combine lexical and semantic approaches to capture the benefits of both. These systems typically implement multi-stage retrieval pipelines that leverage different search modalities at different phases.</p>\n<blockquote>\n<p><strong>Decision: Hybrid Architecture for Production Systems</strong></p>\n<ul>\n<li><strong>Context</strong>: Pure lexical search misses semantic matches; pure vector search loses exact match precision; users expect both conceptual understanding and precise matching</li>\n<li><strong>Options Considered</strong>: Lexical-only, vector-only, parallel hybrid (merge results), sequential hybrid (multi-stage pipeline)</li>\n<li><strong>Decision</strong>: Sequential hybrid with lexical + vector retrieval followed by cross-encoder reranking</li>\n<li><strong>Rationale</strong>: Sequential approach allows optimization at each stage; avoids expensive operations on full corpus; combines complementary strengths while mitigating individual weaknesses</li>\n<li><strong>Consequences</strong>: Increased system complexity and latency, but significantly improved relevance across diverse query types</li>\n</ul>\n</blockquote>\n<p>The most effective hybrid approaches implement <strong>multi-stage pipelines</strong>:</p>\n<ol>\n<li><strong>Fast Retrieval Stage</strong>: Both BM25 lexical search and ANN vector search retrieve candidate documents (typically 100-1000 results each)</li>\n<li><strong>Result Fusion</strong>: Combine and deduplicate candidates using techniques like Reciprocal Rank Fusion (RRF) or weighted score combination</li>\n<li><strong>Precision Reranking</strong>: Apply computationally expensive but highly accurate cross-encoder models to rerank the top candidates</li>\n<li><strong>Signal Integration</strong>: Incorporate additional relevance signals like freshness, popularity, personalization, and click-through data</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Fusion Strategy</th>\n<th>Mechanism</th>\n<th>Advantages</th>\n<th>Trade-offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Score Interpolation</td>\n<td><code>final_score = α × bm25_score + β × vector_score</code></td>\n<td>Simple implementation, tunable weights, interpretable scores</td>\n<td>Requires score calibration, weights are dataset-dependent, linear combination limits expressiveness</td>\n</tr>\n<tr>\n<td>Reciprocal Rank Fusion</td>\n<td><code>rrf_score = Σ(1/(k + rank_i))</code> for each result list</td>\n<td>Rank-based (avoids score calibration), proven effectiveness, robust to score distribution differences</td>\n<td>Loses absolute score information, requires tuning k parameter, equal weighting of systems</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranking</td>\n<td>Train transformer model on query-document pairs</td>\n<td>Highest accuracy, can model complex relevance patterns, joint query-document understanding</td>\n<td>Expensive inference cost, requires training data, limited to small candidate sets</td>\n</tr>\n<tr>\n<td>Learning to Rank</td>\n<td>ML model trained on multiple features</td>\n<td>Can optimize end-to-end relevance, incorporates diverse signals, data-driven weight selection</td>\n<td>Requires substantial training data, complex feature engineering, model drift over time</td>\n</tr>\n</tbody></table>\n<p><strong>Comparison of Search Technology Approaches</strong></p>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Query Understanding</th>\n<th>Vocabulary Flexibility</th>\n<th>Exact Match Precision</th>\n<th>Computational Cost</th>\n<th>Implementation Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Lexical Only</td>\n<td>Poor (keyword matching)</td>\n<td>Low (requires exact/stem matches)</td>\n<td>Excellent</td>\n<td>Low</td>\n<td>Low</td>\n</tr>\n<tr>\n<td>Vector Only</td>\n<td>Excellent (semantic similarity)</td>\n<td>High (concept-based matching)</td>\n<td>Poor (approximate only)</td>\n<td>High</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td>Hybrid Sequential</td>\n<td>Very Good (combines both)</td>\n<td>High (semantic + lexical coverage)</td>\n<td>Good (lexical stage provides precision)</td>\n<td>Medium (optimized pipeline)</td>\n<td>High</td>\n</tr>\n<tr>\n<td>Hybrid Parallel</td>\n<td>Good (separate then merge)</td>\n<td>High (dual coverage)</td>\n<td>Good (lexical results included)</td>\n<td>High (dual computation)</td>\n<td>Medium</td>\n</tr>\n</tbody></table>\n<p>The emerging consensus in the industry is that <strong>hybrid approaches are essential for production semantic search systems</strong>. Companies like Google, Microsoft, and Amazon all use sophisticated multi-stage pipelines that combine lexical matching, vector similarity, machine learning reranking, and numerous other relevance signals.</p>\n<p>However, this complexity must be managed carefully. The key architectural challenge is building a system that can efficiently execute this multi-stage pipeline while maintaining sub-second response times and supporting incremental updates as new documents are added to the corpus.</p>\n<blockquote>\n<p>The fundamental trade-off in semantic search system design is between relevance quality and system complexity. Pure approaches are simpler to build and debug, but hybrid systems provide significantly better user experiences across diverse query types and domains.</p>\n</blockquote>\n<p>This context establishes why we&#39;re building a semantic search engine with hybrid capabilities, and sets up the architectural decisions we&#39;ll explore in subsequent sections. The goal is to capture the semantic understanding benefits of vector search while maintaining the precision and performance characteristics that users expect from modern search systems.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>A. Technology Recommendations Table:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Embedding Model</td>\n<td><code>sentence-transformers</code> with <code>all-MiniLM-L6-v2</code> (384 dim, fast)</td>\n<td><code>sentence-transformers</code> with <code>all-mpnet-base-v2</code> (768 dim, higher quality)</td>\n</tr>\n<tr>\n<td>Vector Index</td>\n<td><code>faiss.IndexFlatIP</code> (exact search, good for &lt;100K docs)</td>\n<td><code>faiss.IndexHNSWFlat</code> (approximate, scales to millions)</td>\n</tr>\n<tr>\n<td>Text Processing</td>\n<td><code>nltk</code> for basic tokenization and stemming</td>\n<td><code>spacy</code> with full NLP pipeline for advanced processing</td>\n</tr>\n<tr>\n<td>Lexical Search</td>\n<td>In-memory inverted index with Python dict</td>\n<td><code>elasticsearch</code> or <code>whoosh</code> for production-scale lexical search</td>\n</tr>\n<tr>\n<td>Web Framework</td>\n<td><code>flask</code> with simple JSON endpoints</td>\n<td><code>fastapi</code> with async support and automatic OpenAPI docs</td>\n</tr>\n<tr>\n<td>Vector Storage</td>\n<td><code>numpy</code> arrays with <code>pickle</code> serialization</td>\n<td><code>numpy</code> with <code>memmap</code> for memory-efficient large datasets</td>\n</tr>\n</tbody></table>\n<p><strong>B. Recommended File/Module Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>semantic-search/\n├── requirements.txt                    ← Python dependencies\n├── config/\n│   ├── __init__.py\n│   └── settings.py                     ← Configuration management\n├── src/\n│   ├── __init__.py\n│   ├── models/                         ← Data structures and schemas\n│   │   ├── __init__.py\n│   │   ├── document.py                 ← Document and embedding models\n│   │   ├── query.py                    ← Query and result models\n│   │   └── index.py                    ← Index metadata structures\n│   ├── embeddings/                     ← Embedding pipeline (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── encoder.py                  ← Text-to-vector encoding\n│   │   ├── indexer.py                  ← Vector index management\n│   │   └── persistence.py              ← Save/load index state\n│   ├── query/                          ← Query processing (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── processor.py                ← Query understanding and expansion\n│   │   ├── searcher.py                 ← Similarity search execution\n│   │   └── cache.py                    ← Query embedding cache\n│   ├── ranking/                        ← Ranking and relevance (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── scorer.py                   ← Multi-signal scoring\n│   │   ├── reranker.py                 ← Cross-encoder reranking\n│   │   └── fusion.py                   ← Result fusion strategies\n│   ├── api/                           ← Search API (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── endpoints.py               ← REST API routes\n│   │   ├── formatting.py              ← Result formatting and highlighting\n│   │   └── analytics.py               ← Search analytics and logging\n│   └── utils/                         ← Shared utilities\n│       ├── __init__.py\n│       ├── text_processing.py         ← Text cleaning and preprocessing\n│       └── metrics.py                 ← Distance calculations and evaluation\n├── tests/                             ← Test suites for each component\n│   ├── test_embeddings/\n│   ├── test_query/\n│   ├── test_ranking/\n│   └── test_api/\n├── data/                              ← Sample datasets and trained models\n│   ├── documents/                     ← Document corpus for indexing\n│   ├── models/                        ← Downloaded embedding models\n│   └── indices/                       ← Serialized vector indices\n└── scripts/                           ← Utility scripts\n    ├── build_index.py                 ← Offline index construction\n    ├── evaluate_search.py             ← Search quality evaluation\n    └── benchmark_performance.py       ← Performance testing</code></pre></div>\n\n<p><strong>C. Infrastructure Starter Code (Complete, Ready to Use)</strong></p>\n<p><strong>File: <code>src/models/document.py</code></strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Document and embedding data models.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Any, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Document</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a searchable document with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    doc_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    url: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_searchable_text</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Combine title and content for embedding generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.title</span><span style=\"color:#79B8FF\">}\\n{self</span><span style=\"color:#E1E4E8\">.content</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_dict</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert document to dictionary for JSON serialization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'doc_id'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.doc_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'title'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.title,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'content'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.content,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'url'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.url,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'metadata'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.metadata </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> {},</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'created_at'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.created_at</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEmbedding</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Pairs a document with its vector embedding.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding: np.ndarray</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    model_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding_dim: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate embedding dimensions match expected size.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.embedding.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.embedding_dim:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Embedding dimension mismatch: expected </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.embedding_dim</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, got </span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.embedding.shape[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>File: <code>src/utils/text_processing.py</code></strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Text preprocessing utilities for consistent document processing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> unicodedata</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TextProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles text cleaning and normalization for search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Common patterns for cleaning</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.url_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#DBEDFF\">http</span><span style=\"color:#79B8FF\">[s]</span><span style=\"color:#F97583\">?</span><span style=\"color:#DBEDFF\">://</span><span style=\"color:#79B8FF\">(?:[a-zA-Z]</span><span style=\"color:#F97583\">|</span><span style=\"color:#79B8FF\">[0-9]</span><span style=\"color:#F97583\">|</span><span style=\"color:#79B8FF\">[$-_@.&#x26;+]</span><span style=\"color:#F97583\">|</span><span style=\"color:#79B8FF\">[!*</span><span style=\"color:#85E89D;font-weight:bold\">\\\\</span><span style=\"color:#79B8FF\">(</span><span style=\"color:#85E89D;font-weight:bold\">\\\\</span><span style=\"color:#79B8FF\">),]</span><span style=\"color:#F97583\">|</span><span style=\"color:#79B8FF\">(?:</span><span style=\"color:#DBEDFF\">%</span><span style=\"color:#79B8FF\">[0-9a-fA-F][0-9a-fA-F]))</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.email_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\b[A-Za-z0-9._%+-]</span><span style=\"color:#F97583\">+</span><span style=\"color:#DBEDFF\">@</span><span style=\"color:#79B8FF\">[A-Za-z0-9.-]</span><span style=\"color:#F97583\">+</span><span style=\"color:#85E89D;font-weight:bold\">\\.</span><span style=\"color:#79B8FF\">[A-Z|a-z]</span><span style=\"color:#F97583\">{2,}</span><span style=\"color:#79B8FF\">\\b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.whitespace_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\s</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clean_text</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Clean and normalize text for embedding generation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Removes URLs, excess whitespace, normalizes unicode.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Normalize unicode characters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> unicodedata.normalize(</span><span style=\"color:#9ECBFF\">'NFKD'</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Remove URLs and email addresses (often not semantically useful)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.url_pattern.sub(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.email_pattern.sub(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Normalize whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.whitespace_pattern.sub(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Strip and return</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> text.strip()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> extract_keywords</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Simple keyword extraction for lexical search.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Splits on whitespace and removes short terms.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Clean text first</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cleaned </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.clean_text(text.lower())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Split into terms and filter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        terms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [term.strip(</span><span style=\"color:#9ECBFF\">'.,!?;:\"()[]</span><span style=\"color:#79B8FF\">{}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> term </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> cleaned.split()]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        keywords </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [term </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> term </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> terms </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(term) </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> term.isalpha()]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> keywords</span></span></code></pre></div>\n\n<p><strong>File: <code>src/utils/metrics.py</code></strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Distance and similarity calculations for vector search.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cosine_similarity</span><span style=\"color:#E1E4E8\">(vec1: np.ndarray, vec2: np.ndarray) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Compute cosine similarity between two vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns value between -1 and 1, where 1 = identical direction.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Ensure vectors are 1-dimensional</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    vec1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vec1.flatten()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    vec2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vec2.flatten()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Compute dot product and magnitudes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dot_product </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.dot(vec1, vec2)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    magnitude1 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vec1)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    magnitude2 </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vec2)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Handle zero vectors</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> magnitude1 </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> magnitude2 </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> dot_product </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (magnitude1 </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> magnitude2)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> normalize_vector</span><span style=\"color:#E1E4E8\">(vec: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    L2 normalize vector to unit length for cosine similarity.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Critical for efficient similarity search in FAISS.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    vec_flat </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vec.flatten()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vec_flat)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> norm </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> vec_flat</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> vec_flat </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> norm</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> euclidean_distance</span><span style=\"color:#E1E4E8\">(vec1: np.ndarray, vec2: np.ndarray) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute Euclidean distance between two vectors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(np.linalg.norm(vec1.flatten() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> vec2.flatten()))</span></span></code></pre></div>\n\n<p><strong>D. Core Logic Skeleton Code</strong></p>\n<p><strong>File: <code>src/embeddings/encoder.py</code></strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Document embedding generation using sentence transformers.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sentence_transformers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SentenceTransformer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Union</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models.document </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Document, DocumentEmbedding</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.text_processing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> TextProcessor</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEncoder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Generates semantic embeddings for documents and queries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'all-MiniLM-L6-v2'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize the sentence transformer model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Store model name and embedding dimension </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Initialize text processor for cleaning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use SentenceTransformer(model_name) and model.get_sentence_embedding_dimension()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_document</span><span style=\"color:#E1E4E8\">(self, document: Document) -> DocumentEmbedding:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Convert document to vector embedding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Combines title and content, cleans text, generates embedding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract searchable text from document (title + content)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clean the text using text processor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate embedding using sentence transformer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Normalize the embedding vector for cosine similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create and return DocumentEmbedding object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use document.get_searchable_text() and normalize_vector()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_texts</span><span style=\"color:#E1E4E8\">(self, texts: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Batch encode multiple texts for efficiency.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns 2D array where each row is an embedding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clean all input texts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Use model.encode() with show_progress_bar=True for batch processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize all embeddings for consistent similarity calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return as numpy array with shape (n_texts, embedding_dim)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Encode search query to embedding vector.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clean query text</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate embedding (single text, not batch)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize embedding vector</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return as 1D numpy array</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>E. Language-Specific Hints</strong></p>\n<p><strong>Python-Specific Implementation Tips:</strong></p>\n<ul>\n<li>Use <code>sentence-transformers</code> library for embeddings: <code>pip install sentence-transformers</code></li>\n<li>FAISS installation: <code>pip install faiss-cpu</code> (or <code>faiss-gpu</code> if you have CUDA)</li>\n<li>For large datasets, use <code>numpy.memmap</code> to handle arrays larger than RAM</li>\n<li>Use <code>@functools.lru_cache</code> decorator for caching expensive operations like model loading</li>\n<li>Handle memory efficiently: <code>del large_arrays</code> and <code>gc.collect()</code> after processing batches</li>\n<li>Use <code>logging</code> module instead of print statements for production code</li>\n<li>Type hints are crucial for maintainability: <code>from typing import List, Dict, Optional, Union</code></li>\n</ul>\n<p><strong>Performance Optimization:</strong></p>\n<ul>\n<li>Batch embedding generation: <code>model.encode(texts, batch_size=32)</code> is much faster than individual calls</li>\n<li>Use <code>numpy.float32</code> instead of <code>float64</code> for embeddings to halve memory usage</li>\n<li>Pre-allocate numpy arrays when possible: <code>np.zeros((n_docs, embedding_dim), dtype=np.float32)</code></li>\n<li>Consider using <code>multiprocessing.Pool</code> for CPU-intensive text preprocessing</li>\n</ul>\n<p><strong>Common Python Gotchas:</strong></p>\n<ul>\n<li>FAISS expects <code>np.float32</code> arrays, not <code>float64</code> (default numpy type)</li>\n<li>Sentence transformers return tensors by default — convert with <code>.numpy()</code> if needed</li>\n<li>When loading large models, they&#39;re cached in <code>~/.cache/huggingface/</code> by default</li>\n<li>Dictionary iteration order is guaranteed in Python 3.7+ but be explicit with <code>collections.OrderedDict</code> if order matters</li>\n</ul>\n<p><strong>F. Milestone Checkpoint</strong></p>\n<p>After implementing the foundational components, verify your understanding:</p>\n<p><strong>What to Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Install dependencies</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">pip</span><span style=\"color:#9ECBFF\"> install</span><span style=\"color:#9ECBFF\"> sentence-transformers</span><span style=\"color:#9ECBFF\"> faiss-cpu</span><span style=\"color:#9ECBFF\"> nltk</span><span style=\"color:#9ECBFF\"> numpy</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test document encoding</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.models.document import Document</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.embeddings.encoder import DocumentEncoder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">doc = Document('1', 'Test Title', 'This is test content about machine learning.')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">encoder = DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">embedding = encoder.encode_document(doc)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Document encoded to {embedding.embedding.shape} vector')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Embedding dimension: {embedding.embedding_dim}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Expected Output:</strong></p>\n<ul>\n<li>Document successfully encoded to shape <code>(384,)</code> for MiniLM model</li>\n<li>Embedding dimension matches model specification (384 for MiniLM-L6-v2)</li>\n<li>No errors during text processing or embedding generation</li>\n</ul>\n<p><strong>What Behavior to Verify:</strong></p>\n<ol>\n<li>Load a sentence transformer model without errors</li>\n<li>Process document text (title + content combination)</li>\n<li>Generate consistent embedding vectors for same input</li>\n<li>Handle edge cases like empty content or very long documents</li>\n<li>Text cleaning removes URLs and normalizes whitespace</li>\n</ol>\n<p><strong>Signs Something is Wrong:</strong></p>\n<ul>\n<li><code>RuntimeError: CUDA out of memory</code> → Use CPU model or reduce batch size</li>\n<li><code>ValueError: embedding dimension mismatch</code> → Check model loading and vector normalization</li>\n<li>Very slow encoding (&gt;1 second per document) → Verify you&#39;re not loading model repeatedly</li>\n<li>Embeddings are all zeros → Check text preprocessing isn&#39;t removing all content</li>\n</ul>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing what the semantic search engine must accomplish and what we deliberately exclude to maintain focus.</p>\n</blockquote>\n<p>Before diving into specific technical requirements, let&#39;s establish a clear mental model for what we&#39;re building. <strong>Think of our semantic search engine as an intelligent research assistant</strong> rather than a simple filing cabinet. Traditional keyword search is like asking someone to find all documents containing the exact words &quot;car&quot; and &quot;maintenance&quot; — they&#39;ll dutifully return every document with those precise terms but miss documents about &quot;automobile servicing&quot; or &quot;vehicle upkeep.&quot; Our semantic search engine, by contrast, understands that these concepts are related and can find relevant documents even when they use different vocabulary. This understanding comes from <strong>vector embeddings</strong> that capture semantic meaning in high-dimensional space, allowing us to find documents by conceptual similarity rather than just word matching.</p>\n<p>However, building such a system requires careful scoping. The space of possible search features is vast — from real-time collaborative filtering to multi-modal image search to conversational query interfaces. Without clear boundaries, we risk building a system that does many things poorly rather than core semantic search exceptionally well. This section establishes both what we commit to building and what we deliberately exclude to maintain focus and achievability.</p>\n<h3 id=\"core-functional-requirements\">Core Functional Requirements</h3>\n<p>The heart of our semantic search engine lies in its ability to understand meaning rather than just match keywords. This semantic understanding manifests through several essential capabilities that work together to provide a fundamentally superior search experience.</p>\n<p><strong>Semantic Query Understanding</strong> forms the foundation of our system. When a user searches for &quot;python web framework performance,&quot; our engine must understand that this query relates to concepts like Django, Flask, FastAPI, benchmarking, scalability, and response times — even if those exact terms don&#39;t appear in the query. This understanding comes through <strong>query expansion</strong> that enriches the original query with related terms while preserving the user&#39;s intent. Unlike simple synonym expansion that might add &quot;snake&quot; as a synonym for &quot;python,&quot; our semantic expansion understands context and adds relevant programming-related terms.</p>\n<table>\n<thead>\n<tr>\n<th>Requirement</th>\n<th>Description</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Semantic Query Processing</td>\n<td>Convert natural language queries to meaningful vector representations</td>\n<td>Query &quot;fast web server&quot; matches documents about &quot;high-performance HTTP services&quot;</td>\n</tr>\n<tr>\n<td>Concept-Based Matching</td>\n<td>Find documents by conceptual similarity, not just keyword overlap</td>\n<td>Query about &quot;machine learning&quot; finds documents mentioning &quot;neural networks&quot; and &quot;AI&quot;</td>\n</tr>\n<tr>\n<td>Multi-Intent Query Support</td>\n<td>Handle queries with multiple semantic aspects</td>\n<td>&quot;Python web scraping tutorial&quot; finds docs covering both Python AND web scraping AND tutorials</td>\n</tr>\n<tr>\n<td>Negation Handling</td>\n<td>Support excluding concepts from search results</td>\n<td>&quot;machine learning -deep learning&quot; excludes deep learning content</td>\n</tr>\n<tr>\n<td>Query Context Preservation</td>\n<td>Maintain original user intent throughout processing</td>\n<td>Expansion doesn&#39;t dilute or shift the core meaning of user queries</td>\n</tr>\n</tbody></table>\n<p><strong>Vector Similarity Search</strong> represents our core technical capability — the ability to find documents that are conceptually similar to a query, even when they share few common words. This addresses the fundamental <strong>vocabulary mismatch problem</strong> where users and document authors use different terms for the same concepts. Our system must convert both queries and documents into <strong>vector embeddings</strong> in the same semantic space, then use <strong>cosine similarity</strong> or other distance metrics to identify the most relevant matches.</p>\n<p>The embedding process itself must be robust and consistent. We&#39;ll use transformer-based models like <code>all-MiniLM-L6-v2</code> that have been trained on large text corpora to understand semantic relationships. The resulting embeddings live in a high-dimensional space (typically 384 or 768 dimensions) where semantically similar concepts cluster together. The challenge lies in efficiently searching this high-dimensional space — with millions of documents, a naive linear search would be far too slow for production use.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: The quality of our embeddings directly determines search quality. A poor embedding model will create a semantic space where conceptually similar documents are far apart, making even perfect similarity search useless. This is why we invest heavily in embedding quality and consistency rather than just search speed.</p>\n</blockquote>\n<p><strong>Efficient Approximate Nearest Neighbor Search</strong> enables us to find the most similar documents without examining every vector in our index. We&#39;ll implement this using algorithms like <strong>HNSW</strong> (Hierarchical Navigable Small World) or <strong>IVF</strong> (Inverted File) that can search millions of vectors in sub-second time. The &quot;approximate&quot; nature means we might occasionally miss the true nearest neighbor, but the trade-off between speed and perfect recall is essential for real-time search.</p>\n<p><strong>Hybrid Search Capabilities</strong> combine the strengths of both lexical and semantic search. While semantic search excels at handling vocabulary mismatch and conceptual queries, traditional <strong>lexical search</strong> using <strong>BM25</strong> scoring still performs better for exact term matching, proper nouns, and technical terminology. Our system must intelligently blend these approaches, using semantic similarity to cast a wide net for relevant documents, then applying lexical signals to boost documents with exact term matches.</p>\n<table>\n<thead>\n<tr>\n<th>Search Type</th>\n<th>Strengths</th>\n<th>Example Query</th>\n<th>When Most Effective</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Semantic</td>\n<td>Handles vocabulary mismatch, conceptual queries</td>\n<td>&quot;improve code quality&quot;</td>\n<td>Broad, conceptual searches</td>\n</tr>\n<tr>\n<td>Lexical</td>\n<td>Exact term matching, proper nouns, technical terms</td>\n<td>&quot;FastAPI dependency injection&quot;</td>\n<td>Specific technical queries</td>\n</tr>\n<tr>\n<td>Hybrid</td>\n<td>Combines both approaches for comprehensive results</td>\n<td>&quot;REST API best practices&quot;</td>\n<td>Most production queries</td>\n</tr>\n</tbody></table>\n<p><strong>Sub-Second Response Times</strong> represent a non-negotiable performance requirement. Search latency directly impacts user experience — studies show that users abandon searches when response times exceed 1-2 seconds. Our architecture must support response times under 500 milliseconds for typical queries, including the time for query processing, vector search, result ranking, and response formatting.</p>\n<p>This latency requirement drives several architectural decisions. We need <strong>query embedding caching</strong> for frequent searches, <strong>approximate algorithms</strong> rather than exact search, <strong>multi-stage ranking</strong> that applies expensive operations only to top candidates, and <strong>efficient data structures</strong> that minimize memory access patterns. The <code>encode_query()</code> function must complete embedding generation in under 100 milliseconds, while our vector index must support similarity search across millions of documents in under 200 milliseconds.</p>\n<h3 id=\"performance-and-scale-requirements\">Performance and Scale Requirements</h3>\n<p>Our semantic search engine must handle production workloads with predictable performance characteristics. These requirements shape our architectural decisions and technology choices throughout the system.</p>\n<p><strong>Query Throughput and Concurrency</strong> define our system&#39;s ability to serve multiple users simultaneously. We target supporting at least <strong>1,000 concurrent users</strong> with <strong>500 queries per second</strong> sustained throughput. This requires careful attention to resource management — embedding models are computationally expensive, vector indices consume significant memory, and ranking operations can create CPU bottlenecks.</p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Target</th>\n<th>Measurement Method</th>\n<th>Impact of Missing Target</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Concurrent Users</td>\n<td>1,000+</td>\n<td>Load testing with realistic query patterns</td>\n<td>Users experience timeouts and failed requests</td>\n</tr>\n<tr>\n<td>Query Throughput</td>\n<td>500 QPS sustained</td>\n<td>Monitor queries/second under load</td>\n<td>Service becomes unavailable during peak usage</td>\n</tr>\n<tr>\n<td>Response Latency</td>\n<td>&lt;500ms p95, &lt;200ms p50</td>\n<td>Histogram of end-to-end response times</td>\n<td>Users abandon searches, poor user experience</td>\n</tr>\n<tr>\n<td>Memory Usage</td>\n<td>&lt;8GB per index</td>\n<td>Monitor RSS memory consumption</td>\n<td>Out of memory crashes, expensive hosting</td>\n</tr>\n<tr>\n<td>CPU Utilization</td>\n<td>&lt;80% sustained</td>\n<td>Monitor CPU during peak load</td>\n<td>Resource starvation, increased latency</td>\n</tr>\n</tbody></table>\n<p><strong>Index Size and Document Capacity</strong> determine how much content our system can handle. We target indexing <strong>10 million documents</strong> with the ability to scale to 100 million through partitioning strategies. Each document embedding requires <code>EMBEDDING_DIM * 4</code> bytes (assuming 32-bit floats), so 10 million documents with 384-dimensional embeddings consume approximately 15GB of raw vector data. Our indexing structures add overhead, so we plan for 25-30GB total memory for the vector index.</p>\n<p>The document ingestion pipeline must handle <strong>10,000 documents per hour</strong> for batch updates and <strong>100 documents per minute</strong> for real-time updates. This throughput requirement influences our choice of embedding models — while larger models might provide better semantic understanding, they may be too slow for our ingestion rate requirements.</p>\n<p><strong>Memory and Storage Constraints</strong> reflect realistic deployment environments. Our system must operate effectively within <strong>16GB RAM</strong> for the complete search service, including the vector index, embedding models, query cache, and application overhead. This constraint drives our selection of compact embedding models like <code>all-MiniLM-L6-v2</code> (384 dimensions) rather than larger alternatives that might require 1GB+ just for model weights.</p>\n<p>For persistent storage, we target <strong>100GB maximum</strong> for the complete system, including the vector index, document metadata, and operational data. This requires efficient index serialization formats and careful management of auxiliary data structures.</p>\n<blockquote>\n<p><strong>Scalability Philosophy</strong>: We design for vertical scaling first (larger machines) before horizontal scaling (more machines). This simplifies our initial implementation while still supporting production workloads. Horizontal scaling becomes an optimization once the core system proves effective.</p>\n</blockquote>\n<p><strong>Cache Hit Rates and Memory Efficiency</strong> directly impact both performance and cost. Our query embedding cache should achieve <strong>80% hit rate</strong> for repeated queries, dramatically reducing the computational cost of re-encoding common searches. The cache must be <strong>size-bounded</strong> to prevent memory exhaustion and use <strong>LRU eviction</strong> to maintain relevance.</p>\n<p>Document-level caching for frequently accessed results should achieve <strong>60% hit rate</strong>, reducing the need to reconstruct result snippets and metadata. However, we must balance cache benefits against memory consumption — a cache that uses too much memory can degrade index performance by forcing virtual memory paging.</p>\n<h3 id=\"what-we-won39t-build\">What We Won&#39;t Build</h3>\n<p>Defining what we exclude is as important as defining what we include. These deliberate limitations keep our project focused on core semantic search capabilities rather than attempting to build a complete enterprise search platform.</p>\n<p><strong>Advanced Multi-Modal Search</strong> capabilities like image similarity, video content analysis, or audio search are explicitly out of scope. While semantic search principles extend to other modalities, each requires specialized embedding models, preprocessing pipelines, and similarity metrics. Adding multi-modal support would triple our complexity without strengthening our core text search competency.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Rationale for Exclusion</th>\n<th>Complexity Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Image Search</td>\n<td>Requires computer vision models, image preprocessing</td>\n<td>3x increase in model complexity</td>\n</tr>\n<tr>\n<td>Video Content Analysis</td>\n<td>Needs video frame extraction, temporal modeling</td>\n<td>5x increase in processing pipeline</td>\n</tr>\n<tr>\n<td>Audio/Speech Search</td>\n<td>Requires speech-to-text, audio feature extraction</td>\n<td>4x increase in preprocessing complexity</td>\n</tr>\n<tr>\n<td>PDF/Document Parsing</td>\n<td>Complex format handling, OCR for scanned content</td>\n<td>2x increase in ingestion pipeline</td>\n</tr>\n</tbody></table>\n<p><strong>Real-Time Collaborative Features</strong> such as shared search sessions, real-time query suggestions from other users, or collaborative result curation would require complex state synchronization and user management systems. These features, while valuable, represent a different product category focused on collaboration rather than search quality.</p>\n<p><strong>Advanced Personalization and User Modeling</strong> beyond basic preference signals are excluded. Building comprehensive user profiles, learning individual query patterns, or providing personalized result ranking would require extensive user data collection, privacy controls, and machine learning pipelines. Our system will support basic personalization hooks but won&#39;t implement sophisticated user modeling.</p>\n<p><strong>Enterprise Security and Access Control</strong> features like role-based permissions, document-level security, audit logging, and integration with identity providers are outside our scope. These are essential for enterprise deployment but represent operational concerns rather than search technology advancement.</p>\n<blockquote>\n<p><strong>Focus Principle</strong>: We&#39;re building a semantic search engine, not a complete search platform. Each excluded feature represents a separate product area that could absorb months of development effort without improving our core semantic understanding capabilities.</p>\n</blockquote>\n<p><strong>Distributed Search Federation</strong> across multiple data sources or external search engines is excluded. While production systems often need to search across databases, file systems, cloud storage, and third-party APIs, implementing federation would require building connectors, handling different data formats, and managing distributed query coordination. Our system will excel at searching a unified document corpus rather than attempting to federate diverse sources.</p>\n<p><strong>Advanced Analytics and Search Intelligence</strong> beyond basic query volume and zero-result tracking are out of scope. Features like query intent classification, search funnel analysis, content gap identification, or automated search quality scoring would require significant analytics infrastructure and data science expertise. We&#39;ll provide basic metrics for operational monitoring but won&#39;t build comprehensive search analytics.</p>\n<p><strong>Natural Language Query Interfaces</strong> that attempt to understand complex conversational queries or provide natural language responses are excluded. While our semantic understanding enables better query interpretation, we won&#39;t implement chatbot-style interfaces or attempt to generate natural language explanations of search results. Our interface remains a traditional search box with structured results.</p>\n<p>The key insight behind these exclusions is that <strong>semantic search technology</strong> represents a foundational capability that can power many different user experiences. By focusing intensively on the quality of semantic understanding, efficient vector search, and intelligent result ranking, we create a strong foundation that could later support any of these excluded features if desired.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete technology recommendations and project structure guidance to bridge the gap between our requirements and actual implementation.</p>\n<p><strong>Technology Stack Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Embedding Model</td>\n<td>sentence-transformers with <code>all-MiniLM-L6-v2</code></td>\n<td>Custom fine-tuned transformer</td>\n<td>Pre-trained model provides good quality with minimal complexity</td>\n</tr>\n<tr>\n<td>Vector Index</td>\n<td>FAISS FlatIP for small datasets</td>\n<td>FAISS HNSW for production scale</td>\n<td>HNSW provides best latency/recall trade-off at scale</td>\n</tr>\n<tr>\n<td>Web Framework</td>\n<td>FastAPI with async support</td>\n<td>Custom async HTTP server</td>\n<td>FastAPI provides good performance with minimal boilerplate</td>\n</tr>\n<tr>\n<td>Database</td>\n<td>SQLite for metadata, files for vectors</td>\n<td>PostgreSQL with pgvector extension</td>\n<td>File-based approach simpler for initial implementation</td>\n</tr>\n<tr>\n<td>Caching</td>\n<td>Python dict with manual LRU</td>\n<td>Redis for distributed caching</td>\n<td>In-memory caching sufficient for single-node deployment</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended Project Structure:</strong></p>\n<p>Our project organization reflects the clear separation between document processing, search infrastructure, and user-facing APIs:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>semantic-search/\n├── src/\n│   ├── embedding/\n│   │   ├── __init__.py\n│   │   ├── encoder.py           # DocumentEncoder class\n│   │   ├── processor.py         # TextProcessor for cleaning\n│   │   └── models.py           # Document and DocumentEmbedding classes\n│   ├── index/\n│   │   ├── __init__.py\n│   │   ├── vector_index.py     # FAISS index wrapper\n│   │   ├── builder.py          # Index construction pipeline\n│   │   └── updater.py          # Incremental updates\n│   ├── search/\n│   │   ├── __init__.py\n│   │   ├── query_processor.py  # Query expansion and encoding\n│   │   ├── retriever.py        # Vector similarity search\n│   │   └── ranker.py           # Multi-signal ranking\n│   ├── api/\n│   │   ├── __init__.py\n│   │   ├── server.py           # FastAPI application\n│   │   ├── models.py           # API request/response models\n│   │   └── handlers.py         # Search endpoint handlers\n│   └── utils/\n│       ├── __init__.py\n│       ├── config.py           # Configuration management\n│       └── metrics.py          # Performance monitoring\n├── tests/\n│   ├── test_embedding/\n│   ├── test_index/\n│   ├── test_search/\n│   └── test_api/\n├── data/\n│   ├── documents/              # Input document corpus\n│   ├── indexes/                # Serialized vector indexes\n│   └── cache/                  # Query embedding cache\n├── scripts/\n│   ├── build_index.py          # Offline index construction\n│   ├── evaluate_search.py      # Search quality evaluation\n│   └── load_test.py            # Performance testing\n├── requirements.txt\n├── README.md\n└── docker-compose.yml          # Development environment</code></pre></div>\n\n<p><strong>Core Infrastructure Setup:</strong></p>\n<p>The following code provides complete, working infrastructure that supports our semantic search requirements without implementing the core learning algorithms:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/utils/config.py - Complete configuration management</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Model configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"all-MiniLM-L6-v2\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding_dim: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 384</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_sequence_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 512</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Index configuration  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"hnsw\"</span><span style=\"color:#6A737D\">  # or \"flat\" for small datasets</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hnsw_m: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 16</span><span style=\"color:#6A737D\">  # HNSW connectivity parameter</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hnsw_ef_construction: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 200</span><span style=\"color:#6A737D\">  # Build-time search depth</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hnsw_ef_search: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#6A737D\">  # Query-time search depth</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Search configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_results: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_score_threshold: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_cache_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Performance limits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_concurrent_queries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_timeout_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding_batch_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 32</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_env</span><span style=\"color:#E1E4E8\">(cls) -> </span><span style=\"color:#9ECBFF\">'SearchConfig'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load configuration from environment variables with defaults.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            model_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">os.getenv(</span><span style=\"color:#9ECBFF\">'MODEL_NAME'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.model_name),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            embedding_dim</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'EMBEDDING_DIM'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.embedding_dim)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_sequence_length</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'MAX_SEQ_LEN'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.max_sequence_length)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            index_type</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">os.getenv(</span><span style=\"color:#9ECBFF\">'INDEX_TYPE'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.index_type),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            hnsw_m</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'HNSW_M'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.hnsw_m)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_results</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'MAX_RESULTS'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.max_results)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            query_cache_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'CACHE_SIZE'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">cls</span><span style=\"color:#E1E4E8\">.query_cache_size))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global configuration instance</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">CONFIG</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> SearchConfig.from_env()</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/utils/metrics.py - Complete performance monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict, deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MetricsCollector</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_latencies: deque </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_counts: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_counts: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_hits: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    cache_misses: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> time_operation</span><span style=\"color:#E1E4E8\">(self, operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager to time operations and collect metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.query_counts[operation_name] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.error_counts[</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_error\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Operation </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.query_latencies.append(elapsed)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_cache_hit</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cache_hits </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_cache_miss</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cache_misses </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_stats</span><span style=\"color:#E1E4E8\">(self) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return current performance statistics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        latencies </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> list</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.query_latencies)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'total_queries'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.query_counts.values()),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'avg_latency_ms'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">sum</span><span style=\"color:#E1E4E8\">(latencies) </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(latencies) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> latencies </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'p95_latency_ms'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">sorted</span><span style=\"color:#E1E4E8\">(latencies)[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0.95</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(latencies))] </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> latencies </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'cache_hit_rate'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.cache_hits </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.cache_hits </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.cache_misses) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.cache_hits </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.cache_misses) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'error_rate'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.error_counts.values()) </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.query_counts.values()) </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.query_counts.values()) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'operations'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.query_counts),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'errors'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.error_counts)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global metrics instance</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">METRICS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> MetricsCollector()</span></span></code></pre></div>\n\n<p><strong>Core Algorithm Skeletons:</strong></p>\n<p>The following skeletons provide the structure for implementing our core semantic search algorithms. Each function maps directly to the requirements established above:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/embedding/encoder.py - Core embedding logic (SKELETON)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sentence_transformers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SentenceTransformer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .processor </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> TextProcessor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Document, DocumentEmbedding</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEncoder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"all-MiniLM-L6-v2\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.model_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> model_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.embedding_dim </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 384</span><span style=\"color:#6A737D\">  # all-MiniLM-L6-v2 dimension</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.text_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TextProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize SentenceTransformer model with model_name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify model.get_sentence_embedding_dimension() matches embedding_dim</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Store model as self.model for use in encoding methods</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_document</span><span style=\"color:#E1E4E8\">(self, document: Document) -> DocumentEmbedding:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert a document to its vector embedding representation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Call document.get_searchable_text() to get text for embedding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clean the text using self.text_processor.clean_text()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate embedding using self.model.encode() - returns numpy array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Normalize the embedding vector using normalize_vector()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create and return DocumentEmbedding with document, embedding, model info</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Handle empty text by returning zero vector of correct dimension</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_texts</span><span style=\"color:#E1E4E8\">(self, texts: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Batch encode multiple texts for efficiency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Filter out empty/None texts, keep track of original indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clean all valid texts using text_processor.clean_text()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Use self.model.encode() with batch processing for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Normalize all embedding vectors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle empty texts by inserting zero vectors at correct positions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: model.encode() accepts List[str] and returns np.ndarray of shape (n, dim)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Encode a search query to embedding vector.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clean query text using text_processor.clean_text()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle empty query case - return zero vector or raise ValueError</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate embedding using self.model.encode() for single text</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Normalize the query embedding vector</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return normalized embedding ready for similarity search</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Single text encoding returns shape (384,) array, not (1, 384)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/search/retriever.py - Vector similarity search (SKELETON)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> faiss</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.metrics </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> METRICS</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VectorRetriever</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, index_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.document_ids </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []  </span><span style=\"color:#6A737D\"># Maps index positions to document IDs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize FAISS index (either load from index_path or create new)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load document ID mapping from companion file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use faiss.read_index() for loading, check if file exists first</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> search_similar</span><span style=\"color:#E1E4E8\">(self, query_embedding: np.ndarray, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find k most similar documents to query embedding.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> METRICS</span><span style=\"color:#E1E4E8\">.time_operation(</span><span style=\"color:#9ECBFF\">\"vector_search\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate query_embedding shape matches index dimension</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Reshape query to (1, dim) format required by FAISS</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Call self.index.search(query, k) to get distances and indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Convert distances to cosine similarity scores (if using IP index)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Map internal indices to document IDs using self.document_ids</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Filter results by minimum score threshold from config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return List[(doc_id, similarity_score)] sorted by score descending</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: FAISS returns (distances, indices) arrays of shape (1, k)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_documents</span><span style=\"color:#E1E4E8\">(self, embeddings: np.ndarray, doc_ids: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add new document embeddings to the search index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate embeddings shape (n_docs, embedding_dim)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Normalize embeddings if not already normalized</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add embeddings to FAISS index using index.add()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Append doc_ids to self.document_ids to maintain mapping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle index training if using IVF-style index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Some index types require training before adding vectors</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints:</strong></p>\n<p>After implementing each milestone, verify your system meets these concrete behavioral expectations:</p>\n<p><strong>Milestone 1 Checkpoint (Embedding Index):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test basic embedding functionality</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.embedding.encoder import DocumentEncoder</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.embedding.models import Document</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">encoder = DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">doc = Document(doc_id='test1', title='Python Tutorial', content='Learn Python programming')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">embedding = encoder.encode_document(doc)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Embedding shape: {embedding.embedding.shape}')  # Should be (384,)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Embedding norm: {np.linalg.norm(embedding.embedding):.3f}')  # Should be ~1.0</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected output: Embedding shape (384,) with norm close to 1.0, indicating proper normalization.</p>\n<p><strong>Milestone 2 Checkpoint (Query Processing):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test query encoding and basic search</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.search.retriever import VectorRetriever  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from src.embedding.encoder import DocumentEncoder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">encoder = DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">query_vec = encoder.encode_query('machine learning tutorial')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Query vector shape: {query_vec.shape}')  # Should be (384,)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print('Query encoding successful')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected behavior: Query successfully converts to normalized 384-dimensional vector without errors.</p>\n<p><strong>Performance Verification:</strong>\nAfter each milestone, run this performance check to ensure you&#39;re meeting latency requirements:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># scripts/performance_check.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.embedding.encoder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DocumentEncoder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">embedding </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> encoder.encode_query(</span><span style=\"color:#9ECBFF\">\"test query performance\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">elapsed_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Query encoding latency: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">elapsed_ms</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">assert</span><span style=\"color:#E1E4E8\"> elapsed_ms </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Query encoding too slow: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">elapsed_ms</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms > 100ms\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"✓ Performance check passed\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p>This systematic approach ensures each component meets our established requirements before moving to the next milestone.</p>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing how the major system components work together to deliver semantic search capabilities.</p>\n</blockquote>\n<p>Think of a semantic search engine as a <strong>digital librarian with superhuman understanding</strong>. Unlike a traditional librarian who relies on card catalogs with exact keyword matches, our digital librarian has read every book in the library and understands the meaning and relationships between concepts. When you ask about &quot;car maintenance,&quot; they instantly know you might also be interested in documents about &quot;automotive repair,&quot; &quot;vehicle servicing,&quot; or &quot;engine troubleshooting&quot; – even if those exact words weren&#39;t in your query.</p>\n<p>This mental model guides our architecture: we need components that can &quot;read&quot; and &quot;understand&quot; documents (embedding generation), organize this understanding efficiently (vector indexing), interpret what users really want (query processing), and combine multiple signals to deliver the best results (ranking and relevance).</p>\n<p>The semantic search engine architecture consists of four core components working in concert to transform the way users discover information. Each component has distinct responsibilities but must integrate seamlessly to deliver sub-second search experiences across millions of documents.</p>\n<h3 id=\"core-components\">Core Components</h3>\n<p>The semantic search engine is built around five primary components, each handling a specific aspect of the search pipeline from document ingestion to result delivery.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<p><strong>Document Processor</strong> serves as the entry point for all content entering the search engine. This component handles the ingestion of raw documents, extracting searchable text from various formats, and preparing content for embedding generation. The processor normalizes document metadata, validates content quality, and manages the document lifecycle from creation to updates.</p>\n<table>\n<thead>\n<tr>\n<th>Component Responsibility</th>\n<th>Description</th>\n<th>Key Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Content Ingestion</td>\n<td>Accept documents from various sources (files, APIs, databases)</td>\n<td>Parse formats, validate structure, extract metadata</td>\n</tr>\n<tr>\n<td>Text Extraction</td>\n<td>Extract clean, searchable text from document content</td>\n<td>Remove markup, normalize whitespace, handle encoding</td>\n</tr>\n<tr>\n<td>Document Validation</td>\n<td>Ensure content quality and completeness</td>\n<td>Check required fields, validate content length, detect duplicates</td>\n</tr>\n<tr>\n<td>Lifecycle Management</td>\n<td>Track document states and handle updates</td>\n<td>Version tracking, deletion handling, update notifications</td>\n</tr>\n</tbody></table>\n<p><strong>Embedding Index</strong> forms the heart of semantic search capabilities. This component converts textual content into high-dimensional vector representations using transformer models, then organizes these vectors into efficient searchable indices. The index must support both batch processing during initial construction and incremental updates as new documents arrive.</p>\n<table>\n<thead>\n<tr>\n<th>Component Responsibility</th>\n<th>Description</th>\n<th>Key Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Vector Generation</td>\n<td>Convert text to dense numerical representations</td>\n<td>Batch encoding, model management, dimension consistency</td>\n</tr>\n<tr>\n<td>Index Construction</td>\n<td>Build efficient approximate nearest neighbor indices</td>\n<td>HNSW/IVF algorithm implementation, memory management, persistence</td>\n</tr>\n<tr>\n<td>Similarity Search</td>\n<td>Find most similar vectors for query embeddings</td>\n<td>Top-K retrieval, distance calculation, result ranking</td>\n</tr>\n<tr>\n<td>Incremental Updates</td>\n<td>Add new vectors without full index reconstruction</td>\n<td>Dynamic insertion, ID mapping, index optimization</td>\n</tr>\n</tbody></table>\n<p><strong>Query Processor</strong> interprets user search intent and transforms natural language queries into optimized vector representations. This component handles query expansion, semantic analysis, and the generation of multiple query variants to improve recall while maintaining precision.</p>\n<table>\n<thead>\n<tr>\n<th>Component Responsibility</th>\n<th>Description</th>\n<th>Key Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Understanding</td>\n<td>Parse and analyze user search intent</td>\n<td>Entity extraction, intent classification, query normalization</td>\n</tr>\n<tr>\n<td>Query Expansion</td>\n<td>Generate related terms and synonyms</td>\n<td>Synonym lookup, related term generation, context expansion</td>\n</tr>\n<tr>\n<td>Multi-Vector Queries</td>\n<td>Support complex queries with multiple aspects</td>\n<td>Query decomposition, vector arithmetic, negative term handling</td>\n</tr>\n<tr>\n<td>Embedding Generation</td>\n<td>Convert processed queries to vector format</td>\n<td>Query encoding, vector normalization, cache management</td>\n</tr>\n</tbody></table>\n<p><strong>Ranking Engine</strong> combines multiple relevance signals to produce optimal result ordering. This component implements a multi-stage ranking pipeline that balances semantic similarity with lexical matching, freshness, personalization, and learned relevance signals from user interactions.</p>\n<table>\n<thead>\n<tr>\n<th>Component Responsibility</th>\n<th>Description</th>\n<th>Key Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Multi-Signal Scoring</td>\n<td>Combine semantic, lexical, and contextual signals</td>\n<td>Score normalization, weight tuning, signal combination</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranking</td>\n<td>Apply precise but expensive ranking to top candidates</td>\n<td>Transformer reranking, pairwise comparison, score calibration</td>\n</tr>\n<tr>\n<td>Personalization</td>\n<td>Adjust results based on user preferences and history</td>\n<td>User profiling, preference matching, privacy preservation</td>\n</tr>\n<tr>\n<td>Learning Integration</td>\n<td>Incorporate click-through data for ranking improvement</td>\n<td>Feature extraction, model updates, A/B testing support</td>\n</tr>\n</tbody></table>\n<p><strong>Search API</strong> provides the external interface for all search operations, handling request routing, response formatting, and advanced features like autocomplete and faceted navigation. This component ensures consistent API contracts while optimizing for different client needs and usage patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Component Responsibility</th>\n<th>Description</th>\n<th>Key Operations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Handling</td>\n<td>Process and validate search requests</td>\n<td>Parameter parsing, input validation, rate limiting</td>\n</tr>\n<tr>\n<td>Response Formatting</td>\n<td>Structure results for client consumption</td>\n<td>Result serialization, snippet generation, metadata inclusion</td>\n</tr>\n<tr>\n<td>Advanced Features</td>\n<td>Support autocomplete, faceting, and analytics</td>\n<td>Typeahead suggestions, filter navigation, usage tracking</td>\n</tr>\n<tr>\n<td>Performance Optimization</td>\n<td>Ensure fast response times and efficient resource usage</td>\n<td>Request caching, connection pooling, response compression</td>\n</tr>\n</tbody></table>\n<h3 id=\"end-to-end-data-flow\">End-to-End Data Flow</h3>\n<p>The semantic search engine processes information through two primary workflows: document indexing (preparing content for search) and query processing (serving search requests). Understanding these flows is crucial for implementing components that work together seamlessly.</p>\n<p><strong>Document Indexing Workflow</strong> transforms raw documents into searchable vector representations. This process begins when new content enters the system and culminates with updated search indices ready to serve queries.</p>\n<p>The indexing flow starts when the Document Processor receives new content through various ingestion channels. Raw documents arrive in different formats – text files, web pages, database records, or API payloads. The processor extracts clean, searchable text using the <code>get_searchable_text()</code> method, which combines document title and content while removing formatting artifacts and normalizing encoding.</p>\n<p>Once text extraction completes, the system creates a <code>Document</code> instance containing the cleaned content along with metadata like creation timestamps, source URLs, and custom attributes. This structured representation ensures consistent handling throughout the pipeline regardless of the original document format.</p>\n<p>The Document Encoder receives validated <code>Document</code> instances and generates vector embeddings using the <code>encode_document()</code> method. This process loads the configured transformer model (typically <code>DEFAULT_MODEL</code> all-MiniLM-L6-v2 with <code>EMBEDDING_DIM</code> 384 dimensions) and converts the searchable text into a <code>DocumentEmbedding</code> containing both the original document reference and its vector representation.</p>\n<p>Vector embeddings flow into the Embedding Index component for storage and indexing. The index applies vector normalization using <code>normalize_vector()</code> to ensure consistent cosine similarity calculations, then adds the embedding to the approximate nearest neighbor index structure. For HNSW indices, this involves finding optimal insertion points in the navigable graph. For IVF indices, the system assigns vectors to appropriate clusters based on the trained quantizer.</p>\n<p>The indexing workflow concludes with persistence operations that save the updated index to disk along with document metadata and ID mappings. This ensures that search capabilities remain available after system restarts and provides a foundation for incremental updates when new documents arrive.</p>\n<p><strong>Query Processing Workflow</strong> handles real-time search requests from users, combining the indexed content with ranking signals to deliver relevant results within sub-second latency requirements.</p>\n<p>Query processing begins when the Search API receives a search request containing the user&#39;s query text along with optional parameters like filters, result limits, and personalization context. The API validates input parameters and routes the request to the Query Processor for semantic analysis.</p>\n<p>The Query Processor analyzes the incoming query using multiple techniques. Query expansion generates related terms and synonyms that might appear in relevant documents, helping address vocabulary mismatch between user language and document content. Entity extraction identifies specific concepts, locations, or topics within the query. Intent classification determines whether the user seeks factual information, product recommendations, or specific document types.</p>\n<p>Enhanced query understanding produces multiple query representations that flow into the embedding generation phase. The system applies the same transformer model used during indexing to convert query text into vector form using <code>encode_query()</code>. This ensures embedding compatibility and meaningful similarity calculations between queries and documents.</p>\n<p>Query embeddings enter the Embedding Index for similarity search operations. The index performs approximate nearest neighbor search to identify the most semantically similar documents, typically retrieving a larger candidate set (e.g., top-1000) for subsequent ranking refinement. Vector similarity calculations use <code>cosine_similarity()</code> between normalized query and document embeddings.</p>\n<p>Retrieved candidates flow into the Ranking Engine for multi-signal scoring. The ranking pipeline combines semantic similarity scores with lexical BM25 matching, document freshness signals, personalization factors, and learned relevance weights. For the highest-quality results, cross-encoder reranking applies transformer models that directly compare query-document pairs, though this expensive operation typically processes only the top-100 candidates.</p>\n<p>Final ranked results return to the Search API for formatting and delivery. The API generates result snippets with query term highlighting, includes relevance scores and metadata, and structures the response according to the client&#39;s requirements. Response caching optimizes performance for repeated queries while analytics collection enables continuous system improvement.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: The separation between indexing and search workflows enables independent scaling and optimization. Heavy indexing operations can run during off-peak hours or on dedicated hardware, while the search path optimizes for low-latency response to user queries.</p>\n</blockquote>\n<h3 id=\"recommended-project-structure\">Recommended Project Structure</h3>\n<p>A well-organized project structure helps developers understand component boundaries and facilitates maintainable code as the system grows. The recommended structure separates core search logic from infrastructure concerns while providing clear interfaces between components.</p>\n<p>The project organization follows domain-driven design principles, grouping related functionality while maintaining clear separation of concerns. Each major component resides in its own module with dedicated interfaces, implementation files, and test coverage.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>semantic_search/\n├── main.py                          # Application entry point and server setup\n├── config/\n│   ├── __init__.py\n│   ├── settings.py                  # Configuration management and environment variables\n│   └── models.py                    # Transformer model configuration and loading\n├── core/\n│   ├── __init__.py\n│   ├── document.py                  # Document and DocumentEmbedding data models\n│   ├── query.py                     # Query processing data structures\n│   └── result.py                    # Search result formatting and response models\n├── components/\n│   ├── __init__.py\n│   ├── document_processor/\n│   │   ├── __init__.py\n│   │   ├── processor.py             # Document ingestion and text extraction\n│   │   ├── text_cleaner.py          # TextProcessor for content normalization\n│   │   └── validator.py             # Content validation and quality checks\n│   ├── embedding_index/\n│   │   ├── __init__.py\n│   │   ├── encoder.py               # DocumentEncoder with embedding generation\n│   │   ├── vector_index.py          # HNSW/IVF index implementation\n│   │   ├── similarity.py            # Cosine similarity and vector operations\n│   │   └── persistence.py           # Index saving and loading operations\n│   ├── query_processor/\n│   │   ├── __init__.py\n│   │   ├── understanding.py         # Query analysis and intent extraction\n│   │   ├── expansion.py             # Synonym and related term generation\n│   │   ├── embedding.py             # Query embedding generation and caching\n│   │   └── multi_vector.py          # Multi-aspect query handling\n│   ├── ranking/\n│   │   ├── __init__.py\n│   │   ├── multi_stage.py           # Multi-stage ranking pipeline coordination\n│   │   ├── hybrid_scorer.py         # Semantic and lexical score combination\n│   │   ├── cross_encoder.py         # Transformer-based reranking\n│   │   └── personalization.py       # User preference and freshness signals\n│   └── search_api/\n│       ├── __init__.py\n│       ├── endpoints.py             # RESTful API route handlers\n│       ├── autocomplete.py          # Typeahead and query suggestions\n│       ├── faceting.py              # Faceted navigation and filtering\n│       └── analytics.py             # Search metrics and usage tracking\n├── utils/\n│   ├── __init__.py\n│   ├── vector_utils.py              # Vector normalization and distance functions\n│   ├── text_utils.py                # Text processing utilities\n│   └── performance.py               # Timing and profiling helpers\n├── tests/\n│   ├── __init__.py\n│   ├── integration/                 # End-to-end workflow tests\n│   ├── unit/                        # Component-specific unit tests\n│   └── fixtures/                    # Test data and mock documents\n└── requirements.txt                 # Python dependencies</code></pre></div>\n\n<p><strong>Core Module Organization</strong> provides shared data structures and interfaces used across all components. The <code>core</code> directory contains the fundamental types like <code>Document</code>, <code>DocumentEmbedding</code>, and result formatting classes that establish contracts between components. This centralized definition prevents circular dependencies and ensures consistent data handling.</p>\n<p><strong>Component Module Structure</strong> organizes each major system component into its own directory with clear internal organization. Each component directory includes an <code>__init__.py</code> file that exports the main classes and functions, making it easy for other components to import required functionality. Implementation files focus on specific responsibilities within each component.</p>\n<p><strong>Utility Module Support</strong> provides common functionality needed across multiple components without creating tight coupling. Vector operations, text processing utilities, and performance monitoring tools live in the <code>utils</code> directory where they can be imported as needed without forcing architectural dependencies.</p>\n<p><strong>Testing Organization</strong> mirrors the main code structure while providing dedicated spaces for different testing approaches. Integration tests verify end-to-end workflows across component boundaries, while unit tests focus on individual component behavior. Fixture management centralizes test data creation and management.</p>\n<blockquote>\n<p><strong>Architecture Decision: Module Boundaries</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to organize code for maintainability while avoiding circular dependencies</li>\n<li><strong>Options Considered</strong>: Monolithic single module, feature-based modules, layer-based modules</li>\n<li><strong>Decision</strong>: Domain-driven component modules with shared core types</li>\n<li><strong>Rationale</strong>: Component boundaries match system architecture, core types prevent circular imports, each module can be developed and tested independently</li>\n<li><strong>Consequences</strong>: Clear ownership of functionality, easier testing, potential for future service extraction, requires discipline to maintain boundaries</li>\n</ul>\n</blockquote>\n<p>The project structure supports both development efficiency and production deployment. During development, the modular organization enables parallel work on different components while the shared core ensures integration compatibility. For deployment, the structure facilitates packaging decisions – the entire application can deploy as a single service, or components can be extracted into separate microservices as scaling needs evolve.</p>\n<p><strong>Import Strategy</strong> follows a clear hierarchy to prevent circular dependencies. Core types are imported by all components but import nothing from components. Components may import from utils and other components as needed, but the dependency graph must remain acyclic. The main application module ties everything together for server initialization and request routing.</p>\n<p><strong>Configuration Management</strong> centralizes all system configuration in the <code>config</code> module, including transformer model selection, index parameters, API settings, and environment-specific values. This approach enables easy configuration changes without code modification and supports different deployment environments with appropriate parameter tuning.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The architecture implementation requires careful attention to component interfaces and data flow patterns. The following guidance provides concrete starting points for each major component while establishing the integration patterns that enable seamless operation.</p>\n<p><strong>A. Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Web Framework</td>\n<td>Flask with JSON responses</td>\n<td>FastAPI with automatic OpenAPI docs</td>\n</tr>\n<tr>\n<td>Vector Library</td>\n<td>FAISS with CPU-only indices</td>\n<td>FAISS with GPU acceleration</td>\n</tr>\n<tr>\n<td>Embedding Model</td>\n<td>Sentence-Transformers all-MiniLM-L6-v2</td>\n<td>Custom fine-tuned domain-specific model</td>\n</tr>\n<tr>\n<td>Text Processing</td>\n<td>Built-in string methods with regex</td>\n<td>spaCy with advanced NLP pipelines</td>\n</tr>\n<tr>\n<td>Caching</td>\n<td>Python dict with TTL cleanup</td>\n<td>Redis with automatic expiration</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>JSON config files</td>\n<td>YAML with environment variable substitution</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Python logging module</td>\n<td>Structured logging with JSON output</td>\n</tr>\n</tbody></table>\n<p><strong>B. Core Data Models</strong></p>\n<p>The following data models establish the foundation for all component interactions. These should be implemented first as they define the contracts between system components.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Document</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Core document representation used throughout the system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    doc_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    url: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_searchable_text</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Combine title and content for embedding generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement text combination with proper spacing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle cases where title or content might be empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Consider metadata fields that should be searchable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEmbedding</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Document with its vector embedding representation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding: np.ndarray</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    model_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding_dim: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate embedding dimensions match expected size.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check embedding.shape[0] == embedding_dim</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify embedding is normalized for cosine similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate model_name matches current configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryRequest</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Search request from client with all parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_text: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_results: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filters: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    personalization_context: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    include_facets: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Individual search result with ranking information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    relevance_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    snippet: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    highlighted_terms: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ranking_signals: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryResponse</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete search response with results and metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    results: List[SearchResult]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_found: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_time_ms: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    facets: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span></code></pre></div>\n\n<p><strong>C. Component Integration Patterns</strong></p>\n<p>The system uses dependency injection and interface-based design to enable component composition while maintaining testability. Each component exposes a clear interface and accepts dependencies through constructor injection.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentProcessorInterface</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Interface for document ingestion and processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_document</span><span style=\"color:#E1E4E8\">(self, raw_content: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, metadata: Dict) -> Document:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process raw content into structured Document.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_document</span><span style=\"color:#E1E4E8\">(self, document: Document) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate document meets quality requirements.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EmbeddingIndexInterface</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">ABC</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Interface for vector indexing and similarity search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_document_embedding</span><span style=\"color:#E1E4E8\">(self, embedding: DocumentEmbedding) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add new document embedding to searchable index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> search_similar</span><span style=\"color:#E1E4E8\">(self, query_embedding: np.ndarray, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find k most similar documents returning (doc_id, similarity_score).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> save_index</span><span style=\"color:#E1E4E8\">(self, filepath: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Persist index to disk for reload after restart.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SemanticSearchEngine</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Main orchestrator that coordinates all components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 document_processor: DocumentProcessorInterface,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 embedding_index: EmbeddingIndexInterface,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 query_processor: QueryProcessorInterface,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 ranking_engine: RankingEngineInterface):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.document_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> document_processor</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.embedding_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> embedding_index</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.query_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> query_processor</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.ranking_engine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ranking_engine</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_documents</span><span style=\"color:#E1E4E8\">(self, raw_documents: List[Dict]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"End-to-end document indexing workflow.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Process each raw document through document_processor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate embeddings for processed documents</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add embeddings to the searchable index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle errors gracefully and provide progress feedback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> search</span><span style=\"color:#E1E4E8\">(self, query_request: QueryRequest) -> QueryResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"End-to-end search request processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Process query through query_processor for understanding and expansion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate query embedding for similarity search</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Retrieve candidate documents from embedding_index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Apply ranking_engine to combine multiple relevance signals</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Format results and return complete response</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>D. Configuration Management</strong></p>\n<p>Centralized configuration enables easy deployment across different environments while providing sensible defaults for development.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Central configuration for all search engine components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Embedding configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    default_model: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"all-MiniLM-L6-v2\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding_dim: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 384</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    batch_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 32</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Index configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"hnsw\"</span><span style=\"color:#6A737D\">  # or \"ivf\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hnsw_m: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 16</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hnsw_ef_construction: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 200</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    hnsw_ef_search: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Query processing configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_expansion_enabled: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_query_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 512</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_keyword_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Ranking configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    semantic_weight: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.7</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    lexical_weight: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    freshness_decay_days: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # API configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_results: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    default_results: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    autocomplete_timeout_ms: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_environment</span><span style=\"color:#E1E4E8\">(cls) -> </span><span style=\"color:#9ECBFF\">'SearchConfig'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load configuration from environment variables.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Read environment variables with fallback to defaults</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate configuration values are within acceptable ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log configuration values for debugging (excluding secrets)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_config</span><span style=\"color:#E1E4E8\">() -> SearchConfig:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load configuration based on environment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    env </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> os.getenv(</span><span style=\"color:#9ECBFF\">'SEARCH_ENV'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'development'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> env </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'production'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> SearchConfig.from_environment()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> SearchConfig()  </span><span style=\"color:#6A737D\"># Use defaults for development</span></span></code></pre></div>\n\n<p><strong>E. Application Entry Point</strong></p>\n<p>The main application file ties all components together and provides the server entry point.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uvicorn</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> fastapi </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FastAPI</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.config.settings </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> load_config</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.components.document_processor.processor </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DocumentProcessor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.components.embedding_index.encoder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DocumentEncoder</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.components.embedding_index.vector_index </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> VectorIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.components.query_processor.understanding </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryProcessor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.components.ranking.multi_stage </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> RankingEngine</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> semantic_search.components.search_api.endpoints </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SearchAPI</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_application</span><span style=\"color:#E1E4E8\">() -> FastAPI:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create and configure the FastAPI application.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_config()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    app </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FastAPI(</span><span style=\"color:#FFAB70\">title</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Semantic Search Engine\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">version</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"1.0.0\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize all components with proper dependency injection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Set up API routes with the SearchAPI component</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Configure middleware for logging, CORS, and request timing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add health check endpoints for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> app</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> main</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Application entry point.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_config()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    app </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> create_application()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Load any existing indices from disk</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Start the web server with appropriate configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Handle graceful shutdown to save indices</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    uvicorn.run(app, </span><span style=\"color:#FFAB70\">host</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"0.0.0.0\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">port</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">8000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> __name__</span><span style=\"color:#F97583\"> ==</span><span style=\"color:#9ECBFF\"> \"__main__\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    main()</span></span></code></pre></div>\n\n<p><strong>F. Development Workflow</strong></p>\n<p>The recommended development approach builds components incrementally, with each milestone providing a working system that can be tested and validated.</p>\n<p><strong>Milestone 1 Development Flow:</strong></p>\n<ol>\n<li>Implement core data models (<code>Document</code>, <code>DocumentEmbedding</code>) with proper validation</li>\n<li>Create the <code>DocumentEncoder</code> with embedding generation using sentence-transformers</li>\n<li>Build the vector index with FAISS HNSW implementation</li>\n<li>Add index persistence for saving and loading trained indices</li>\n<li>Test with a small document collection to verify embedding generation and similarity search</li>\n</ol>\n<p><strong>Milestone 2 Development Flow:</strong></p>\n<ol>\n<li>Implement query text processing with normalization and validation</li>\n<li>Add query expansion using synonym lookups or word embeddings</li>\n<li>Build query embedding generation using the same model as document encoding</li>\n<li>Implement basic similarity search returning top-K results</li>\n<li>Test query processing with various query types and verify result relevance</li>\n</ol>\n<p><strong>Milestone 3 Development Flow:</strong></p>\n<ol>\n<li>Implement BM25 lexical scoring for keyword matching</li>\n<li>Build hybrid search combining semantic and lexical scores</li>\n<li>Add cross-encoder reranking for top candidate refinement</li>\n<li>Implement freshness and personalization signal integration</li>\n<li>Test ranking quality with evaluation queries and manually assess result ordering</li>\n</ol>\n<p><strong>Milestone 4 Development Flow:</strong></p>\n<ol>\n<li>Create RESTful API endpoints using FastAPI with proper request/response models</li>\n<li>Implement autocomplete functionality with cached query suggestions</li>\n<li>Build faceted navigation with efficient facet count computation</li>\n<li>Add query term highlighting in result snippets</li>\n<li>Create analytics dashboard for monitoring search performance and quality</li>\n</ol>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing the core data structures that flow through the embedding index (Milestone 1), query processing (Milestone 2), ranking and relevance (Milestone 3), and search API (Milestone 4).</p>\n</blockquote>\n<p>The data model defines the fundamental structures that represent documents, embeddings, queries, and results throughout the semantic search engine. Think of the data model as the <strong>vocabulary</strong> that all system components use to communicate—just as a library needs consistent cataloging standards so librarians can find books regardless of which department they work in, our search engine needs consistent data representations so the embedding index, query processor, and ranking engine can seamlessly exchange information.</p>\n<p>Understanding these data structures is crucial because they directly influence system performance, scalability, and maintainability. A well-designed data model reduces memory usage, enables efficient serialization, and provides clear interfaces between components. Conversely, poor data modeling decisions create bottlenecks that are expensive to fix later in the system&#39;s lifecycle.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fdata-model.svg\" alt=\"Data Model Relationships\"></p>\n<h3 id=\"document-and-embedding-model\">Document and Embedding Model</h3>\n<p>The document and embedding model captures how textual content is represented both in its original form and as vector embeddings for semantic search. This dual representation is essential because we need the original text for result display and highlighting, while the vector embeddings enable semantic similarity matching.</p>\n<h4 id=\"document-representation\">Document Representation</h4>\n<p>The <code>Document</code> structure serves as the foundational unit of searchable content. Think of it as a <strong>digital index card</strong> in a library catalog system—it contains all the essential metadata needed to identify, retrieve, and display a piece of content to users.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>doc_id</code></td>\n<td><code>str</code></td>\n<td>Unique identifier for the document, must be stable across updates and consistent with external systems</td>\n</tr>\n<tr>\n<td><code>title</code></td>\n<td><code>str</code></td>\n<td>Document title or headline, used for display and as primary text for embedding generation</td>\n</tr>\n<tr>\n<td><code>content</code></td>\n<td><code>str</code></td>\n<td>Full document body text, preprocessed to remove HTML tags and formatting artifacts</td>\n</tr>\n<tr>\n<td><code>url</code></td>\n<td><code>Optional[str]</code></td>\n<td>Source URL for web documents, enables click-through tracking and external link generation</td>\n</tr>\n<tr>\n<td><code>metadata</code></td>\n<td><code>Optional[Dict]</code></td>\n<td>Flexible key-value storage for domain-specific fields like author, publication date, categories</td>\n</tr>\n<tr>\n<td><code>created_at</code></td>\n<td><code>Optional[str]</code></td>\n<td>Document creation timestamp in ISO 8601 format, used for freshness scoring in ranking</td>\n</tr>\n</tbody></table>\n<p>The <code>Document</code> structure balances simplicity with extensibility. The core fields (<code>doc_id</code>, <code>title</code>, <code>content</code>) are mandatory because they&#39;re required for basic search functionality, while optional fields support advanced features without complicating the basic use case.</p>\n<blockquote>\n<p><strong>Design Insight:</strong> The <code>metadata</code> field uses a dictionary rather than predefined fields because document schemas vary dramatically across domains. A news article needs author and publication date, while a product page needs price and category. The flexible metadata approach allows the same core system to handle diverse content types.</p>\n</blockquote>\n<h4 id=\"document-text-processing\">Document Text Processing</h4>\n<p>Documents require preprocessing before embedding generation to ensure consistent, high-quality vector representations. The <code>get_searchable_text()</code> method combines title and content into a single string optimized for semantic understanding:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>get_searchable_text</code></td>\n<td>None</td>\n<td><code>str</code></td>\n<td>Combines document title and content with appropriate weighting for embedding generation</td>\n</tr>\n<tr>\n<td><code>clean_text</code></td>\n<td><code>text: str</code></td>\n<td><code>str</code></td>\n<td>Normalizes whitespace, removes special characters, and handles encoding issues</td>\n</tr>\n</tbody></table>\n<p>The text processing pipeline addresses common issues that degrade embedding quality. HTML entities, excessive whitespace, and encoding artifacts create noise in vector representations. By standardizing text format before embedding generation, we ensure that similar content produces similar vectors regardless of original formatting.</p>\n<blockquote>\n<p><strong>Critical Design Decision:</strong> We concatenate title and content rather than embedding them separately because transformer models excel at understanding document-level context. The title provides crucial semantic context that helps disambiguate content meaning—the word &quot;python&quot; means different things in a programming tutorial versus a nature documentary.</p>\n</blockquote>\n<h4 id=\"vector-embedding-representation\">Vector Embedding Representation</h4>\n<p>The <code>DocumentEmbedding</code> structure bridges the gap between text documents and numerical vector representations that enable semantic search. Think of embeddings as <strong>semantic fingerprints</strong>—dense numerical signatures that capture the meaning and context of the original text.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>document</code></td>\n<td><code>Document</code></td>\n<td>Reference to the original document, maintains connection between text and vector</td>\n</tr>\n<tr>\n<td><code>embedding</code></td>\n<td><code>np.ndarray</code></td>\n<td>Dense vector representation with shape <code>(embedding_dim,)</code> and dtype <code>float32</code></td>\n</tr>\n<tr>\n<td><code>model_name</code></td>\n<td><code>str</code></td>\n<td>Identifier for the embedding model used, enables compatibility checks and model versioning</td>\n</tr>\n<tr>\n<td><code>embedding_dim</code></td>\n<td><code>int</code></td>\n<td>Dimensionality of the embedding vector, must match the model&#39;s output dimension</td>\n</tr>\n</tbody></table>\n<p>The embedding vector is the heart of semantic search—it encodes the document&#39;s meaning in a high-dimensional space where similar concepts cluster together. The <code>model_name</code> field is crucial for production systems because embedding models evolve over time, and mixing embeddings from different models destroys similarity relationships.</p>\n<blockquote>\n<p><strong>Architecture Decision Record:</strong></p>\n<p><strong>Decision: Store Document Reference in DocumentEmbedding</strong></p>\n<ul>\n<li><strong>Context</strong>: We need to connect embeddings back to original documents for result display</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Store only <code>doc_id</code> string reference</li>\n<li>Store full <code>Document</code> object reference  </li>\n<li>Store embeddings and documents in separate collections with ID-based lookup</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Store full <code>Document</code> object reference</li>\n<li><strong>Rationale</strong>: Reduces lookup overhead during search result generation, simplifies serialization, and ensures embedding-document consistency</li>\n<li><strong>Consequences</strong>: Slightly higher memory usage per embedding, but eliminates expensive joins during result formatting</li>\n</ul>\n</blockquote>\n<h4 id=\"document-encoding-pipeline\">Document Encoding Pipeline</h4>\n<p>The document encoding process transforms raw text into vector embeddings through several stages. The <code>DocumentEncoder</code> encapsulates the embedding model and text processing logic:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>model</code></td>\n<td><code>SentenceTransformer</code></td>\n<td>Pre-trained transformer model for generating embeddings</td>\n</tr>\n<tr>\n<td><code>model_name</code></td>\n<td><code>str</code></td>\n<td>Model identifier matching the <code>DEFAULT_MODEL</code> constant</td>\n</tr>\n<tr>\n<td><code>embedding_dim</code></td>\n<td><code>int</code></td>\n<td>Output dimension of the model, typically <code>EMBEDDING_DIM</code> (384)</td>\n</tr>\n<tr>\n<td><code>text_processor</code></td>\n<td><code>TextProcessor</code></td>\n<td>Text cleaning and normalization utilities</td>\n</tr>\n</tbody></table>\n<p>The encoding pipeline follows a consistent sequence:</p>\n<ol>\n<li>Extract searchable text using <code>get_searchable_text()</code> to combine title and content</li>\n<li>Clean and normalize the text using <code>clean_text()</code> to remove formatting artifacts  </li>\n<li>Generate embedding vector using the transformer model&#39;s encode method</li>\n<li>Normalize the embedding to unit length using <code>normalize_vector()</code> for cosine similarity</li>\n<li>Create <code>DocumentEmbedding</code> object linking the vector to its source document</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>encode_document</code></td>\n<td><code>document: Document</code></td>\n<td><code>DocumentEmbedding</code></td>\n<td>Complete pipeline from document to normalized embedding</td>\n</tr>\n<tr>\n<td><code>encode_texts</code></td>\n<td><code>texts: List[str]</code></td>\n<td><code>np.ndarray</code></td>\n<td>Batch encoding for efficiency, returns shape <code>(n_texts, embedding_dim)</code></td>\n</tr>\n</tbody></table>\n<p>Batch encoding is essential for performance because transformer models have high fixed overhead per forward pass. Processing documents in batches of 32-128 can improve throughput by 5-10x compared to individual encoding.</p>\n<h3 id=\"index-data-structures\">Index Data Structures</h3>\n<p>The index data structures define how vector embeddings are organized for efficient similarity search. Think of vector indices as <strong>specialized filing systems</strong> optimized for finding similar items rather than exact matches—like organizing books by topic and theme rather than alphabetically.</p>\n<h4 id=\"vector-index-organization\">Vector Index Organization</h4>\n<p>Vector indices face the fundamental challenge of the <strong>curse of dimensionality</strong>—naive similarity search requires comparing the query vector against every indexed vector, which becomes prohibitively expensive with millions of documents. Approximate nearest neighbor algorithms solve this by building data structures that quickly identify candidate similar vectors.</p>\n<p>The index must support several key operations:</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Time Complexity</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Build Index</td>\n<td>O(n log n)</td>\n<td>Construct search structure from embeddings</td>\n</tr>\n<tr>\n<td>Add Vectors</td>\n<td>O(log n)</td>\n<td>Incrementally add new embeddings</td>\n</tr>\n<tr>\n<td>Search</td>\n<td>O(log n)</td>\n<td>Find k most similar vectors to query</td>\n</tr>\n<tr>\n<td>Persist</td>\n<td>O(n)</td>\n<td>Save trained index to disk</td>\n</tr>\n<tr>\n<td>Load</td>\n<td>O(n)</td>\n<td>Restore index from disk storage</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Architecture Decision Record:</strong></p>\n<p><strong>Decision: HNSW vs IVF Index Algorithm Selection</strong></p>\n<ul>\n<li><strong>Context</strong>: Need efficient approximate nearest neighbor search for high-dimensional embeddings</li>\n<li><strong>Options Considered</strong>:<ol>\n<li><strong>HNSW (Hierarchical Navigable Small World)</strong>: Graph-based index with excellent query performance</li>\n<li><strong>IVF (Inverted File)</strong>: Clustering-based index with good memory efficiency</li>\n<li><strong>LSH (Locality Sensitive Hashing)</strong>: Simple but lower accuracy approach</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Primary recommendation is HNSW with IVF as alternative for memory-constrained environments</li>\n<li><strong>Rationale</strong>: HNSW provides superior query latency (sub-millisecond) and higher recall accuracy, while IVF offers better memory efficiency for very large datasets</li>\n<li><strong>Consequences</strong>: HNSW requires more memory but delivers better user experience; IVF requires training phase but scales to larger datasets</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Index Algorithm</th>\n<th>Memory Usage</th>\n<th>Query Latency</th>\n<th>Build Time</th>\n<th>Incremental Updates</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>HNSW</strong></td>\n<td>High</td>\n<td>Excellent (&lt;1ms)</td>\n<td>Fast</td>\n<td>Native Support</td>\n</tr>\n<tr>\n<td><strong>IVF</strong></td>\n<td>Moderate</td>\n<td>Good (1-5ms)</td>\n<td>Slow (requires training)</td>\n<td>Requires rebuild</td>\n</tr>\n<tr>\n<td><strong>LSH</strong></td>\n<td>Low</td>\n<td>Poor (10ms+)</td>\n<td>Fast</td>\n<td>Easy</td>\n</tr>\n</tbody></table>\n<h4 id=\"hnsw-index-structure\">HNSW Index Structure</h4>\n<p>HNSW builds a multi-layer graph where each layer contains a subset of the indexed vectors. Higher layers have fewer nodes but longer edges, enabling fast navigation to the right neighborhood, while lower layers have more nodes with shorter edges for precise similarity matching.</p>\n<table>\n<thead>\n<tr>\n<th>Index Component</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>max_connections</code></td>\n<td><code>int</code></td>\n<td>Maximum edges per node (M parameter), typically 16-48</td>\n</tr>\n<tr>\n<td><code>ef_construction</code></td>\n<td><code>int</code></td>\n<td>Search width during index building, affects quality vs speed tradeoff</td>\n</tr>\n<tr>\n<td><code>ef_search</code></td>\n<td><code>int</code></td>\n<td>Search width during queries, affects recall vs latency tradeoff</td>\n</tr>\n<tr>\n<td><code>levels</code></td>\n<td><code>List[Graph]</code></td>\n<td>Hierarchical graph layers from coarse to fine resolution</td>\n</tr>\n</tbody></table>\n<p>The HNSW parameters require careful tuning based on dataset characteristics:</p>\n<ul>\n<li><strong>max_connections (M)</strong>: Higher values improve recall but increase memory usage quadratically</li>\n<li><strong>ef_construction</strong>: Should be at least as large as the desired recall level  </li>\n<li><strong>ef_search</strong>: Can be adjusted per query to trade latency for accuracy</li>\n</ul>\n<blockquote>\n<p>⚠️ <strong>Pitfall: HNSW Memory Explosion</strong>\nSetting <code>max_connections</code> too high causes memory usage to explode. Each connection stores a 32-bit integer ID, so M=64 uses 4x more memory than M=16. Start with M=16 and increase only if recall is insufficient.</p>\n</blockquote>\n<h4 id=\"ivf-index-structure\">IVF Index Structure</h4>\n<p>IVF partitions the embedding space into clusters using k-means, then builds inverted lists mapping each cluster to the vectors it contains. Search involves identifying the most relevant clusters and searching within them.</p>\n<table>\n<thead>\n<tr>\n<th>Index Component</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>n_clusters</code></td>\n<td><code>int</code></td>\n<td>Number of Voronoi cells, typically sqrt(n_vectors)</td>\n</tr>\n<tr>\n<td><code>centroids</code></td>\n<td><code>np.ndarray</code></td>\n<td>Cluster center vectors with shape <code>(n_clusters, embedding_dim)</code></td>\n</tr>\n<tr>\n<td><code>inverted_lists</code></td>\n<td><code>Dict[int, List[int]]</code></td>\n<td>Mapping from cluster ID to vector IDs in that cluster</td>\n</tr>\n<tr>\n<td><code>n_probe</code></td>\n<td><code>int</code></td>\n<td>Number of clusters to search during queries</td>\n</tr>\n</tbody></table>\n<p>IVF requires a training phase to learn good cluster boundaries. The training dataset should be representative of the full data distribution, with at least 1000x more vectors than clusters.</p>\n<blockquote>\n<p>⚠️ <strong>Pitfall: IVF Training Data Mismatch</strong><br>Training IVF on a small subset that doesn&#39;t represent the full data distribution creates poor cluster boundaries. Documents that don&#39;t fit the learned clusters will have terrible recall. Use a diverse training set with at least 100,000 vectors.</p>\n</blockquote>\n<h4 id=\"index-persistence-and-metadata\">Index Persistence and Metadata</h4>\n<p>Vector indices must persist to disk to avoid expensive rebuilding on every system restart. The persistence layer handles both the index structure and associated metadata.</p>\n<table>\n<thead>\n<tr>\n<th>Persistence Component</th>\n<th>Format</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>index_file</code></td>\n<td>Binary</td>\n<td>Serialized index structure with optimized layout</td>\n</tr>\n<tr>\n<td><code>metadata_file</code></td>\n<td>JSON</td>\n<td>Human-readable configuration and statistics</td>\n</tr>\n<tr>\n<td><code>id_mapping</code></td>\n<td>Binary</td>\n<td>Bidirectional mapping between doc_ids and internal vector IDs</td>\n</tr>\n<tr>\n<td><code>version_info</code></td>\n<td>JSON</td>\n<td>Model compatibility and index format version</td>\n</tr>\n</tbody></table>\n<p>The ID mapping is crucial because vector indices use sequential integer IDs internally, but documents use string identifiers. The mapping must stay synchronized when adding or removing documents.</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>save_index</code></td>\n<td><code>path: str</code></td>\n<td><code>None</code></td>\n<td>Persist complete index state to disk</td>\n</tr>\n<tr>\n<td><code>load_index</code></td>\n<td><code>path: str</code></td>\n<td><code>VectorIndex</code></td>\n<td>Restore index from saved state</td>\n</tr>\n<tr>\n<td><code>add_vectors</code></td>\n<td><code>embeddings: List[DocumentEmbedding]</code></td>\n<td><code>None</code></td>\n<td>Incremental addition with ID mapping</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>⚠️ <strong>Pitfall: ID Mapping Desynchronization</strong>\nAdding vectors to the index without updating the ID mapping, or vice versa, creates silent corruption where searches return wrong documents. Always update both structures atomically or use transactions.</p>\n</blockquote>\n<h3 id=\"query-and-result-model\">Query and Result Model</h3>\n<p>The query and result model defines how search requests are structured, processed, and returned to users. This model must balance expressiveness (supporting complex queries) with performance (enabling efficient processing and caching).</p>\n<h4 id=\"search-query-representation\">Search Query Representation</h4>\n<p>The <code>QueryRequest</code> structure encapsulates all information needed to process a search query. Think of it as a <strong>detailed research request</strong> submitted to a librarian—it specifies not just what to find, but how many results to return, what constraints to apply, and how to personalize the search.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>query_text</code></td>\n<td><code>str</code></td>\n<td>Primary search query string, will be embedded for semantic matching</td>\n</tr>\n<tr>\n<td><code>max_results</code></td>\n<td><code>int</code></td>\n<td>Maximum number of results to return, affects performance and relevance</td>\n</tr>\n<tr>\n<td><code>filters</code></td>\n<td><code>Optional[Dict]</code></td>\n<td>Key-value constraints on document metadata (e.g., date ranges, categories)</td>\n</tr>\n<tr>\n<td><code>personalization_context</code></td>\n<td><code>Optional[Dict]</code></td>\n<td>User preferences and history for result customization</td>\n</tr>\n<tr>\n<td><code>include_facets</code></td>\n<td><code>bool</code></td>\n<td>Whether to compute and return facet counts for filtering UI</td>\n</tr>\n</tbody></table>\n<p>The query structure supports both simple keyword searches and complex structured queries. The <code>filters</code> field enables faceted search where users can constrain results by metadata attributes. The <code>personalization_context</code> allows ranking algorithms to customize results based on user behavior and preferences.</p>\n<blockquote>\n<p><strong>Design Principle:</strong> Query structure separates semantic matching (via <code>query_text</code>) from metadata filtering and personalization. This enables the system to apply semantic search broadly, then apply filters and personalization to refine results, rather than trying to encode all constraints in a single embedding.</p>\n</blockquote>\n<h4 id=\"query-processing-pipeline-data-structures\">Query Processing Pipeline Data Structures</h4>\n<p>Query processing transforms the raw query text through several intermediate representations before generating the final embedding for similarity search.</p>\n<table>\n<thead>\n<tr>\n<th>Processing Stage</th>\n<th>Input Type</th>\n<th>Output Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Text Cleaning</strong></td>\n<td><code>str</code></td>\n<td><code>str</code></td>\n<td>Normalized query text with consistent formatting</td>\n</tr>\n<tr>\n<td><strong>Query Expansion</strong></td>\n<td><code>str</code></td>\n<td><code>List[str]</code></td>\n<td>Original query plus synonyms and related terms</td>\n</tr>\n<tr>\n<td><strong>Intent Analysis</strong></td>\n<td><code>str</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Extracted entities, query type, and semantic intent</td>\n</tr>\n<tr>\n<td><strong>Vector Generation</strong></td>\n<td><code>str</code></td>\n<td><code>np.ndarray</code></td>\n<td>Dense embedding vector for similarity matching</td>\n</tr>\n</tbody></table>\n<p>The query expansion stage is particularly important for handling <strong>vocabulary mismatch</strong>—when users and documents use different terms for the same concepts. For example, a query for &quot;car&quot; should also match documents about &quot;automobile&quot; and &quot;vehicle.&quot;</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>encode_query</code></td>\n<td><code>query_text: str</code></td>\n<td><code>np.ndarray</code></td>\n<td>Generate embedding vector from query text</td>\n</tr>\n<tr>\n<td><code>expand_query</code></td>\n<td><code>query_text: str</code></td>\n<td><code>List[str]</code></td>\n<td>Add synonyms and related terms to original query</td>\n</tr>\n<tr>\n<td><code>extract_intent</code></td>\n<td><code>query_text: str</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Identify entities, query type, and user intent</td>\n</tr>\n</tbody></table>\n<p>Multi-vector queries support complex search scenarios where different aspects of the query need different semantic representations. For example, a query like &quot;python programming -snake&quot; has positive terms (python, programming) and negative terms (snake) that require different handling.</p>\n<blockquote>\n<p><strong>Architecture Decision Record:</strong></p>\n<p><strong>Decision: Single vs Multi-Vector Query Representation</strong>  </p>\n<ul>\n<li><strong>Context</strong>: Need to handle complex queries with multiple aspects or negative terms</li>\n<li><strong>Options Considered</strong>:<ol>\n<li><strong>Single Vector</strong>: Embed entire query as one vector</li>\n<li><strong>Multi-Vector</strong>: Separate embeddings for different query aspects  </li>\n<li><strong>Weighted Combination</strong>: Multiple vectors with importance weights</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Support both single and multi-vector queries based on complexity</li>\n<li><strong>Rationale</strong>: Simple queries benefit from single vector efficiency, while complex queries need multi-vector expressiveness</li>\n<li><strong>Consequences</strong>: More complex query processing but better handling of nuanced search intent</li>\n</ul>\n</blockquote>\n<h4 id=\"search-result-representation\">Search Result Representation</h4>\n<p>The <code>SearchResult</code> structure represents individual documents returned for a query, enriched with relevance information and display formatting. Each result is like a <strong>library catalog entry</strong> that provides enough information for users to decide whether to access the full document.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>document</code></td>\n<td><code>Document</code></td>\n<td>Complete document information including title, content, and metadata</td>\n</tr>\n<tr>\n<td><code>relevance_score</code></td>\n<td><code>float</code></td>\n<td>Combined relevance score from all ranking signals, normalized 0-1</td>\n</tr>\n<tr>\n<td><code>snippet</code></td>\n<td><code>str</code></td>\n<td>Excerpt from document content highlighting query relevance</td>\n</tr>\n<tr>\n<td><code>highlighted_terms</code></td>\n<td><code>List[str]</code></td>\n<td>Query terms that should be highlighted in the result display</td>\n</tr>\n<tr>\n<td><code>ranking_signals</code></td>\n<td><code>Dict[str, float]</code></td>\n<td>Individual signal scores for debugging and tuning</td>\n</tr>\n</tbody></table>\n<p>The <code>ranking_signals</code> field provides transparency into the ranking process, storing individual scores for semantic similarity, BM25, personalization, freshness, and other factors. This enables result quality analysis and ranking algorithm debugging.</p>\n<table>\n<thead>\n<tr>\n<th>Ranking Signal</th>\n<th>Range</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>semantic_score</code></td>\n<td>0.0-1.0</td>\n<td>Cosine similarity between query and document embeddings</td>\n</tr>\n<tr>\n<td><code>lexical_score</code></td>\n<td>0.0-1.0</td>\n<td>BM25 keyword matching score</td>\n</tr>\n<tr>\n<td><code>freshness_score</code></td>\n<td>0.0-1.0</td>\n<td>Time-based relevance decay from document creation date</td>\n</tr>\n<tr>\n<td><code>personalization_score</code></td>\n<td>0.0-1.0</td>\n<td>User preference and behavior matching</td>\n</tr>\n<tr>\n<td><code>authority_score</code></td>\n<td>0.0-1.0</td>\n<td>Document quality and trustworthiness indicators</td>\n</tr>\n</tbody></table>\n<h4 id=\"query-response-structure\">Query Response Structure</h4>\n<p>The <code>QueryResponse</code> aggregates individual search results with query-level metadata and performance information. This structure supports both search results display and system monitoring.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>query</code></td>\n<td><code>str</code></td>\n<td>Original query text for reference and logging</td>\n</tr>\n<tr>\n<td><code>results</code></td>\n<td><code>List[SearchResult]</code></td>\n<td>Ordered list of matching documents with relevance scores</td>\n</tr>\n<tr>\n<td><code>total_found</code></td>\n<td><code>int</code></td>\n<td>Total matching documents before result limit applied</td>\n</tr>\n<tr>\n<td><code>processing_time_ms</code></td>\n<td><code>float</code></td>\n<td>End-to-end query processing latency for performance monitoring</td>\n</tr>\n<tr>\n<td><code>facets</code></td>\n<td><code>Optional[Dict]</code></td>\n<td>Facet counts for filters (category: count mapping)</td>\n</tr>\n</tbody></table>\n<p>The facet information enables rich filtering interfaces where users can see how many results exist in each category, author, or time period. Computing facets efficiently requires careful index design because counting requires examining many more documents than the top-K results.</p>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Expensive Facet Computation</strong>\nComputing facet counts naively requires examining all matching documents, not just the top K results. For large result sets, this can increase query latency by 10x. Use approximate counting or precomputed facet indices for better performance.</p>\n</blockquote>\n<h4 id=\"result-ranking-and-scoring\">Result Ranking and Scoring</h4>\n<p>The result ranking process combines multiple scoring signals into a final relevance score. The scoring pipeline must be both accurate (ranking truly relevant results higher) and efficient (processing thousands of candidates quickly).</p>\n<table>\n<thead>\n<tr>\n<th>Scoring Stage</th>\n<th>Input</th>\n<th>Output</th>\n<th>Latency Budget</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Candidate Retrieval</strong></td>\n<td>Query vector</td>\n<td>Top 1000 candidates</td>\n<td>&lt;10ms</td>\n</tr>\n<tr>\n<td><strong>Multi-Signal Scoring</strong></td>\n<td>Candidates + signals</td>\n<td>Scored candidates</td>\n<td>&lt;20ms</td>\n</tr>\n<tr>\n<td><strong>Cross-Encoder Reranking</strong></td>\n<td>Top 100 candidates</td>\n<td>Final ranking</td>\n<td>&lt;50ms</td>\n</tr>\n<tr>\n<td><strong>Result Formatting</strong></td>\n<td>Ranked results</td>\n<td>Formatted response</td>\n<td>&lt;10ms</td>\n</tr>\n</tbody></table>\n<p>The multi-stage approach balances quality and performance by applying expensive but accurate scoring only to a small set of high-quality candidates identified by fast approximate methods.</p>\n<h3 id=\"common-implementation-pitfalls\">Common Implementation Pitfalls</h3>\n<p>Understanding the data model means avoiding common mistakes that can silently corrupt search quality or create performance bottlenecks:</p>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Vector Normalization Inconsistency</strong><br>Failing to normalize vectors consistently between indexing and search breaks cosine similarity calculations. Some vectors may have large magnitudes that dominate similarity scores regardless of semantic content. Always apply <code>normalize_vector()</code> before indexing and searching.</p>\n</blockquote>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Embedding Dimension Mismatch</strong><br>Mixing embeddings from models with different dimensions causes crashes or silent corruption. Always validate that loaded embeddings match the expected <code>EMBEDDING_DIM</code> before adding them to indices. Store the <code>model_name</code> and <code>embedding_dim</code> in metadata for validation.</p>\n</blockquote>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Document ID String Encoding Issues</strong><br>Using document IDs with special characters or inconsistent encoding creates lookup failures. URLs and filenames often contain characters that break string matching. Normalize all document IDs to a consistent encoding (UTF-8) and consider using hash-based IDs for URLs.</p>\n</blockquote>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Metadata Serialization Problems</strong><br>Storing complex objects in the metadata dictionary that can&#39;t be serialized to JSON breaks persistence. Stick to primitive types (strings, numbers, booleans, lists, dicts) in metadata fields, or implement custom serialization for complex types.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Vector Operations</strong></td>\n<td>NumPy arrays with basic operations</td>\n<td>Faiss with optimized SIMD operations</td>\n</tr>\n<tr>\n<td><strong>Text Processing</strong></td>\n<td>Basic regex and string methods</td>\n<td>spaCy or NLTK for advanced NLP</td>\n</tr>\n<tr>\n<td><strong>Serialization</strong></td>\n<td>JSON for metadata, pickle for arrays</td>\n<td>Protocol Buffers or MessagePack</td>\n</tr>\n<tr>\n<td><strong>Persistence</strong></td>\n<td>File-based storage with JSON metadata</td>\n<td>SQLite or PostgreSQL with vector extensions</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">project</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">root</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">  src</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data_model</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">      __init__</span><span style=\"color:#E1E4E8\">.py              ← Export main types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      document.py              ← Document </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> DocumentEmbedding classes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      query.py                 ← QueryRequest </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> QueryResponse classes  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      result.py                ← SearchResult </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> ranking data structures</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      processing.py            ← TextProcessor </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> DocumentEncoder classes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      validation.py            ← Data validation </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> normalization utilities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    tests</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">      test_data_model</span><span style=\"color:#F97583\">/</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        test_document.py       ← Document structure </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> methods tests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        test_embeddings.py     ← Embedding generation </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> validation tests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        test_queries.py        ← Query processing pipeline tests</span></span></code></pre></div>\n\n<h4 id=\"core-data-structure-implementation\">Core Data Structure Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, List, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sentence_transformers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SentenceTransformer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Constants matching project naming conventions</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEFAULT_MODEL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"all-MiniLM-L6-v2\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">EMBEDDING_DIM</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 384</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">MIN_KEYWORD_LENGTH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Document</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Core document representation with metadata and content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    doc_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    url: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_searchable_text</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Combine title and content for embedding generation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            str: Formatted text optimized for semantic understanding</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Combine title and content with appropriate spacing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle cases where title or content might be empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Consider title weighting (repeat title or add special markers)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Title provides crucial context - consider repeating it or using special formatting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEmbedding</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Links document to its vector embedding representation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding: np.ndarray  </span><span style=\"color:#6A737D\"># Shape: (EMBEDDING_DIM,), dtype: float32</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    model_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embedding_dim: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate embedding dimensions and normalize vector.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate embedding.shape matches (embedding_dim,)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate embedding.dtype is float32</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize embedding to unit length for cosine similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate model_name matches expected model</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TextProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles text cleaning and normalization for consistent embeddings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Pre-compile regex patterns for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.url_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#DBEDFF\">https</span><span style=\"color:#F97583\">?</span><span style=\"color:#DBEDFF\">://</span><span style=\"color:#79B8FF\">[</span><span style=\"color:#F97583\">^</span><span style=\"color:#79B8FF\">\\s&#x3C;>\"]</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.email_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\S</span><span style=\"color:#F97583\">+</span><span style=\"color:#DBEDFF\">@</span><span style=\"color:#79B8FF\">\\S</span><span style=\"color:#F97583\">+</span><span style=\"color:#85E89D;font-weight:bold\">\\.</span><span style=\"color:#79B8FF\">\\S</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.whitespace_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\s</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clean_text</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Normalize and clean text for embedding generation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            text: Raw input text potentially containing HTML, URLs, etc.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            str: Cleaned text suitable for embedding model</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Remove URLs and email addresses (replace with placeholder or remove)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Normalize whitespace (collapse multiple spaces, remove leading/trailing)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle HTML entities and special characters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Convert to lowercase if needed (check model requirements)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Remove or replace very short tokens (&#x3C; MIN_KEYWORD_LENGTH)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"query-and-result-implementation\">Query and Result Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryRequest</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Structured search query with filters and personalization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_text: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_results: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    filters: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    personalization_context: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    include_facets: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate query parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate query_text is not empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Ensure max_results is reasonable (1-1000)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate filter format if provided</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Individual search result with relevance information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    relevance_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">  # 0.0-1.0 combined score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    snippet: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">           # Highlighted excerpt</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    highlighted_terms: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ranking_signals: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Individual signal scores</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryResponse</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete search response with results and metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    results: List[SearchResult] </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_found: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_time_ms: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    facets: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEncoder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Converts documents to normalized embeddings using transformer models.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> DEFAULT_MODEL</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load SentenceTransformer model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize text processor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store model metadata (name, dimension)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate model produces expected embedding dimension</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.model </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # Load SentenceTransformer here</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.model_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> model_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.embedding_dim </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> EMBEDDING_DIM</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.text_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TextProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_document</span><span style=\"color:#E1E4E8\">(self, document: Document) -> DocumentEmbedding:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert document to normalized embedding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            document: Source document with title and content</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            DocumentEmbedding: Document linked to its vector representation</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get searchable text from document</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clean text using text processor  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate embedding using transformer model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Normalize embedding vector to unit length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return DocumentEmbedding with metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_texts</span><span style=\"color:#E1E4E8\">(self, texts: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Batch encode multiple texts for efficiency.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            texts: List of cleaned text strings</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            np.ndarray: Normalized embeddings with shape (len(texts), EMBEDDING_DIM)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Batch encode all texts with single model call</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Normalize all embeddings to unit length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return as float32 array for memory efficiency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Encode search query to embedding vector.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_text: User search query string</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            np.ndarray: Normalized query embedding</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clean query text (similar to document processing)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate embedding using same model as documents</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize to unit length for cosine similarity</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Utility functions for vector operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> normalize_vector</span><span style=\"color:#E1E4E8\">(vec: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"L2 normalize vector to unit length for cosine similarity.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        vec: Input vector of any length</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        np.ndarray: Unit-length vector pointing in same direction</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compute L2 norm of vector</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle zero vectors (return zero vector)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Divide vector by norm to get unit length</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cosine_similarity</span><span style=\"color:#E1E4E8\">(vec1: np.ndarray, vec2: np.ndarray) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute cosine similarity between normalized vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        vec1, vec2: Normalized vectors of same dimension</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        float: Similarity score from -1 (opposite) to 1 (identical)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate vectors have same shape</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Compute dot product (for normalized vectors, this equals cosine similarity)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle numerical edge cases (clamp to [-1, 1] range)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"data-validation-and-testing\">Data Validation and Testing</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DataValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validates data model consistency and catches common errors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_document</span><span style=\"color:#E1E4E8\">(document: Document) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check document for common issues.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List[str]: List of validation error messages (empty if valid)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check required fields are not None or empty</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate doc_id format (no special characters, reasonable length)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check text content is reasonable length (not empty, not too long)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate metadata types are JSON-serializable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check created_at format if provided (ISO 8601)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_embedding</span><span style=\"color:#E1E4E8\">(embedding: DocumentEmbedding) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check embedding for consistency issues.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List[str]: List of validation error messages (empty if valid)  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        errors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate embedding array shape and dtype</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if vector is normalized (L2 norm ≈ 1.0)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate model_name and embedding_dim consistency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for NaN or infinite values in vector</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate document reference is complete</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> errors</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the data model components, verify correct behavior:</p>\n<p><strong>Testing Data Structures:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#79B8FF\">cd</span><span style=\"color:#9ECBFF\"> project-root</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> src/tests/test_data_model/</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n\n<p><strong>Expected Test Results:</strong></p>\n<ul>\n<li>Document creation and validation tests pass</li>\n<li>Text processing correctly handles HTML, URLs, and whitespace</li>\n<li>Embedding generation produces normalized vectors with correct dimensions</li>\n<li>Query and result structures serialize/deserialize properly</li>\n<li>Vector operations (normalize, cosine similarity) produce expected values</li>\n</ul>\n<p><strong>Manual Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test document processing pipeline</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">doc </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Document(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    doc_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"test-1\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    title</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Python Programming Tutorial\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    content</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Learn Python programming with examples and exercises.\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    metadata</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"category\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"education\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"difficulty\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"beginner\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">embedding </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> encoder.encode_document(doc)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Embedding shape: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">embedding.embedding.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should be (384,)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Vector norm: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">np.linalg.norm(embedding.embedding)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should be ≈1.0  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Model: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">embedding.model_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Should be \"all-MiniLM-L6-v2\"</span></span></code></pre></div>\n\n<p><strong>Signs of Problems:</strong></p>\n<ul>\n<li>Vector norms significantly different from 1.0 indicate normalization issues</li>\n<li>Embedding dimensions other than 384 suggest model loading problems  </li>\n<li>Text processing not removing HTML indicates regex pattern issues</li>\n<li>Serialization errors suggest non-JSON-compatible metadata types</li>\n</ul>\n<h2 id=\"embedding-index-component\">Embedding Index Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1: Embedding Index</p>\n</blockquote>\n<p>The <strong>Embedding Index Component</strong> serves as the core foundation of our semantic search engine, transforming text documents into high-dimensional vector representations and organizing them for efficient similarity search. This component bridges the gap between human language and mathematical computation, enabling our system to understand semantic meaning rather than relying solely on keyword matching. The embedding index acts as a specialized database optimized for finding conceptually similar documents in vector space, supporting millions of documents while maintaining sub-second query response times.</p>\n<h3 id=\"vector-search-mental-model-library-analogy\">Vector Search Mental Model: Library Analogy</h3>\n<p>Think of the embedding index as a revolutionary library system designed by a librarian who understands not just where books are located, but what they actually mean. In a traditional library, books are organized by category and call numbers—you find books by knowing exactly what to look for. But imagine a library where the librarian has read every book and can instantly recommend books that share similar themes, concepts, or ideas, even if they use completely different words.</p>\n<p>The <strong>vector embedding</strong> is like the librarian&#39;s mental summary of each book—a compact representation that captures the essence of the book&#39;s meaning in a way that can be compared mathematically. When you ask a question, the librarian doesn&#39;t just match your exact words to book titles; instead, they understand what you&#39;re really looking for and find books that address your underlying need, even if they use different terminology.</p>\n<p>The <strong>approximate nearest neighbor search</strong> works like the librarian&#39;s ability to quickly narrow down millions of books to the most relevant ones. Rather than reading every single book summary when you make a request, the librarian has organized their mental model into a sophisticated network of connections. They start with a rough area of knowledge, then follow connections through increasingly precise neighborhoods of related concepts until they find the books most similar to what you&#39;re seeking.</p>\n<p>This library analogy captures three key insights about vector search: first, that meaning can be mathematically represented and compared; second, that efficiency comes from intelligent organization rather than exhaustive searching; and third, that approximate answers delivered quickly are often more valuable than perfect answers delivered slowly.</p>\n<h3 id=\"document-embedding-pipeline\">Document Embedding Pipeline</h3>\n<p>The document embedding pipeline transforms raw text into mathematical vectors that capture semantic meaning, creating the foundation for similarity-based search. This transformation process involves multiple stages of text preprocessing, encoding, and vector normalization to ensure consistent and high-quality representations.</p>\n<h4 id=\"text-preprocessing-and-normalization\">Text Preprocessing and Normalization</h4>\n<p>Before documents can be converted to embeddings, they must undergo careful preprocessing to remove noise and standardize format. The <code>TextProcessor</code> component handles this critical preparation phase, ensuring that the embedding model receives clean, consistent input that maximizes the quality of the resulting vector representations.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>url_pattern</code></td>\n<td><code>re.Pattern</code></td>\n<td>Regular expression for detecting and cleaning URLs from document text</td>\n</tr>\n<tr>\n<td><code>email_pattern</code></td>\n<td><code>re.Pattern</code></td>\n<td>Regular expression for detecting and normalizing email addresses</td>\n</tr>\n<tr>\n<td><code>whitespace_pattern</code></td>\n<td><code>re.Pattern</code></td>\n<td>Regular expression for normalizing excessive whitespace and special characters</td>\n</tr>\n</tbody></table>\n<p>The text cleaning process follows a systematic approach designed to preserve semantic content while removing elements that could confuse the embedding model. The <code>clean_text</code> method applies multiple transformations to ensure input consistency.</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>clean_text</code></td>\n<td><code>text: str</code></td>\n<td><code>str</code></td>\n<td>Normalizes whitespace, removes URLs, standardizes punctuation, converts to lowercase</td>\n</tr>\n<tr>\n<td><code>get_searchable_text</code></td>\n<td>-</td>\n<td><code>str</code></td>\n<td>Combines document title and content with appropriate weighting for embedding</td>\n</tr>\n</tbody></table>\n<p>The preprocessing pipeline addresses several critical challenges in text normalization. URLs and email addresses are standardized rather than removed entirely, as they may contain meaningful tokens. HTML entities are decoded to their text equivalents, ensuring that encoded characters don&#39;t create vocabulary fragmentation. Multiple consecutive whitespace characters are collapsed to single spaces, and non-printable characters are removed to prevent encoding issues.</p>\n<blockquote>\n<p><strong>Key Design Insight</strong>: Text preprocessing decisions directly impact embedding quality. Overly aggressive cleaning can remove meaningful semantic signals, while insufficient cleaning introduces noise that degrades similarity calculations. The preprocessing pipeline aims to preserve semantic content while standardizing format.</p>\n</blockquote>\n<h4 id=\"transformer-model-integration\">Transformer Model Integration</h4>\n<p>The <code>DocumentEncoder</code> component wraps the Sentence Transformer model and provides the interface for converting cleaned text into vector embeddings. This component manages model initialization, batching for efficiency, and consistent embedding generation across the document collection.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>model</code></td>\n<td><code>SentenceTransformer</code></td>\n<td>Pre-trained transformer model for generating sentence embeddings</td>\n</tr>\n<tr>\n<td><code>model_name</code></td>\n<td><code>str</code></td>\n<td>Identifier for the specific embedding model being used</td>\n</tr>\n<tr>\n<td><code>embedding_dim</code></td>\n<td><code>int</code></td>\n<td>Dimensionality of the output embedding vectors</td>\n</tr>\n<tr>\n<td><code>text_processor</code></td>\n<td><code>TextProcessor</code></td>\n<td>Text preprocessing component for input normalization</td>\n</tr>\n</tbody></table>\n<p>The document encoding process transforms preprocessed text through several stages. First, the text is tokenized using the model&#39;s vocabulary, converting words and subwords into numerical tokens. These tokens are processed through the transformer&#39;s attention layers, which capture contextual relationships between words. Finally, the model generates a fixed-size embedding vector that represents the semantic content of the entire text.</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>encode_document</code></td>\n<td><code>document: Document</code></td>\n<td><code>DocumentEmbedding</code></td>\n<td>Converts document text to embedding with metadata tracking</td>\n</tr>\n<tr>\n<td><code>encode_texts</code></td>\n<td><code>texts: List[str]</code></td>\n<td><code>np.ndarray</code></td>\n<td>Batch encodes multiple texts for efficiency</td>\n</tr>\n<tr>\n<td><code>encode_query</code></td>\n<td><code>query_text: str</code></td>\n<td><code>np.ndarray</code></td>\n<td>Encodes search query with same model for consistency</td>\n</tr>\n<tr>\n<td><code>normalize_vector</code></td>\n<td><code>vec: np.ndarray</code></td>\n<td><code>np.ndarray</code></td>\n<td>L2 normalizes vector to unit length for cosine similarity</td>\n</tr>\n</tbody></table>\n<h4 id=\"embedding-generation-and-validation\">Embedding Generation and Validation</h4>\n<p>The embedding generation process creates <code>DocumentEmbedding</code> objects that combine the original document with its vector representation and model metadata. This structure ensures traceability and enables model versioning when the embedding approach evolves.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>document</code></td>\n<td><code>Document</code></td>\n<td>Original document containing text content and metadata</td>\n</tr>\n<tr>\n<td><code>embedding</code></td>\n<td><code>np.ndarray</code></td>\n<td>Dense vector representation of document semantic content</td>\n</tr>\n<tr>\n<td><code>model_name</code></td>\n<td><code>str</code></td>\n<td>Name of the transformer model used for embedding generation</td>\n</tr>\n<tr>\n<td><code>embedding_dim</code></td>\n<td><code>int</code></td>\n<td>Dimensionality of the embedding vector for validation</td>\n</tr>\n</tbody></table>\n<p>The embedding pipeline includes validation steps to ensure vector quality and consistency. Each generated embedding is checked for the correct dimensionality, verified to contain only finite values, and normalized to unit length for cosine similarity calculations. The pipeline also tracks embedding generation timestamps and model versions to support incremental reprocessing when models are updated.</p>\n<blockquote>\n<p><strong>Design Decision: Single Model Consistency</strong></p>\n<ul>\n<li><strong>Context</strong>: Documents and queries must be embedded using the same model for meaningful similarity calculations</li>\n<li><strong>Options Considered</strong>: Multiple specialized models vs. single general-purpose model vs. dynamic model selection</li>\n<li><strong>Decision</strong>: Use single model for all text encoding with version tracking</li>\n<li><strong>Rationale</strong>: Embedding spaces are model-specific—vectors from different models cannot be meaningfully compared</li>\n<li><strong>Consequences</strong>: Simpler architecture and consistent similarity calculations, but potentially suboptimal for specialized content types</li>\n</ul>\n</blockquote>\n<h3 id=\"index-algorithm-selection\">Index Algorithm Selection</h3>\n<p>The choice between <strong>HNSW (Hierarchical Navigable Small World)</strong> and <strong>IVF (Inverted File)</strong> indexing algorithms represents a fundamental architectural decision that affects search performance, memory usage, and scalability characteristics. Both algorithms solve the approximate nearest neighbor problem but with different trade-offs that align with specific use cases and operational requirements.</p>\n<h4 id=\"algorithm-comparison-and-trade-off-analysis\">Algorithm Comparison and Trade-off Analysis</h4>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Search Latency</th>\n<th>Memory Usage</th>\n<th>Build Time</th>\n<th>Update Support</th>\n<th>Accuracy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>HNSW</strong></td>\n<td>Very Low (1-5ms)</td>\n<td>High (2-4x vectors)</td>\n<td>Medium</td>\n<td>Excellent</td>\n<td>High (95%+ recall)</td>\n</tr>\n<tr>\n<td><strong>IVF</strong></td>\n<td>Low (5-20ms)</td>\n<td>Low (1.1-1.5x vectors)</td>\n<td>Fast</td>\n<td>Poor (requires rebuild)</td>\n<td>Medium (85-95% recall)</td>\n</tr>\n</tbody></table>\n<p>The performance characteristics of these algorithms create distinct optimization profiles. HNSW excels in scenarios requiring ultra-low latency and frequent updates, while IVF provides better memory efficiency and faster index construction for batch processing workflows.</p>\n<h4 id=\"hnsw-algorithm-deep-dive\">HNSW Algorithm Deep Dive</h4>\n<p>HNSW constructs a multi-layer graph structure where each layer contains a subset of the indexed vectors connected by edges to their nearest neighbors. The algorithm leverages the small-world property—the idea that in a well-connected graph, any two nodes can be reached through a small number of intermediate connections.</p>\n<p>The HNSW structure consists of multiple layers with exponentially decreasing densities. Layer 0 contains all vectors, layer 1 contains roughly half, layer 2 contains roughly a quarter, and so on. Higher layers provide long-range connections for efficient navigation, while lower layers offer fine-grained local connections for precise neighbor finding.</p>\n<p><strong>HNSW Search Process:</strong></p>\n<ol>\n<li>Begin search at the highest layer containing vectors, starting from a random entry point</li>\n<li>Perform greedy search within the current layer, following edges to progressively closer neighbors</li>\n<li>When no closer neighbors exist in the current layer, descend to the next lower layer</li>\n<li>Continue layer-by-layer descent until reaching layer 0</li>\n<li>Perform final greedy search in layer 0 to find the precise nearest neighbors</li>\n<li>Return the top-k closest vectors based on distance calculations</li>\n</ol>\n<p>The HNSW configuration requires tuning several parameters that significantly impact performance. The <code>M</code> parameter controls the maximum number of connections per vector—higher values improve recall but increase memory usage exponentially. The <code>efConstruction</code> parameter determines search effort during index construction, affecting both build time and final index quality.</p>\n<h4 id=\"ivf-algorithm-deep-dive\">IVF Algorithm Deep Dive</h4>\n<p>IVF partitions the vector space into a predetermined number of clusters (called Voronoi cells) and builds an inverted index mapping each cluster to the vectors it contains. This approach reduces search complexity from linear scanning of all vectors to targeted searching within a subset of relevant clusters.</p>\n<p>The IVF training process uses k-means clustering to learn cluster centroids that partition the vector space effectively. During search, the algorithm computes distances from the query vector to all cluster centroids, selects the closest clusters, and performs exhaustive search within those clusters only.</p>\n<p><strong>IVF Search Process:</strong></p>\n<ol>\n<li>Compute query vector distance to all trained cluster centroids</li>\n<li>Select the <code>nprobe</code> closest clusters based on centroid distances</li>\n<li>Retrieve all vectors assigned to the selected clusters from the inverted index</li>\n<li>Compute exact distances from query vector to all retrieved candidate vectors</li>\n<li>Sort candidates by distance and return the top-k closest vectors</li>\n<li>Apply post-filtering if additional constraints are specified</li>\n</ol>\n<p>The IVF configuration centers on the trade-off between search accuracy and computational cost. More clusters (<code>nlist</code>) provide finer partitioning but require more memory and longer training time. Searching more clusters (<code>nprobe</code>) improves recall but increases query latency proportionally.</p>\n<h4 id=\"architecture-decision-hnsw-selection\">Architecture Decision: HNSW Selection</h4>\n<blockquote>\n<p><strong>Decision: HNSW Algorithm for Primary Index</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to support real-time search with sub-second latency while handling frequent document updates</li>\n<li><strong>Options Considered</strong>: HNSW for low latency, IVF for memory efficiency, hybrid approach combining both</li>\n<li><strong>Decision</strong>: Implement HNSW as the primary indexing algorithm with IVF as an optional alternative</li>\n<li><strong>Rationale</strong>: HNSW&#39;s superior update performance and consistently low latency align with real-time search requirements, while memory costs are manageable for the target scale</li>\n<li><strong>Consequences</strong>: Higher memory usage but excellent search performance and simplified update logic</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Consideration</th>\n<th>HNSW Advantage</th>\n<th>IVF Advantage</th>\n<th>Impact on Decision</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Search Latency</strong></td>\n<td>1-5ms consistent</td>\n<td>5-20ms variable</td>\n<td>Critical for user experience</td>\n</tr>\n<tr>\n<td><strong>Update Frequency</strong></td>\n<td>Excellent incremental updates</td>\n<td>Requires periodic rebuilds</td>\n<td>Essential for real-time indexing</td>\n</tr>\n<tr>\n<td><strong>Memory Efficiency</strong></td>\n<td>2-4x overhead</td>\n<td>1.1-1.5x overhead</td>\n<td>Acceptable with proper provisioning</td>\n</tr>\n<tr>\n<td><strong>Implementation Complexity</strong></td>\n<td>Moderate complexity</td>\n<td>Simple implementation</td>\n<td>Manageable with FAISS library</td>\n</tr>\n</tbody></table>\n<h4 id=\"hybrid-index-strategy\">Hybrid Index Strategy</h4>\n<p>While HNSW serves as the primary algorithm, the architecture supports a hybrid approach where different content types or access patterns can utilize different indexing strategies. Large archival collections with infrequent updates might benefit from IVF&#39;s memory efficiency, while real-time content requires HNSW&#39;s update performance.</p>\n<p>The index selection logic evaluates collection characteristics to determine the optimal algorithm. Collections with high update rates, small to medium size (under 10 million documents), and latency-sensitive queries default to HNSW. Collections with low update rates, large size, and batch processing workflows may benefit from IVF indexing.</p>\n<h3 id=\"index-persistence-and-updates\">Index Persistence and Updates</h3>\n<p>Efficient index persistence and incremental updates are critical for production deployment, enabling the system to maintain search availability while incorporating new documents and handling failures gracefully. The persistence strategy must balance durability, performance, and storage efficiency while supporting both planned and unplanned system restarts.</p>\n<h4 id=\"index-serialization-and-storage-format\">Index Serialization and Storage Format</h4>\n<p>The index persistence system stores both the vector index structure and associated metadata required for proper reconstruction. FAISS provides native serialization support for both HNSW and IVF indices, but additional metadata tracking ensures consistency and enables version management.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Storage Format</th>\n<th>Size Characteristics</th>\n<th>Persistence Frequency</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Vector Index</strong></td>\n<td>FAISS binary format</td>\n<td>50-200 bytes per vector</td>\n<td>Every 1000 updates or 5 minutes</td>\n</tr>\n<tr>\n<td><strong>Document Mapping</strong></td>\n<td>JSON with compression</td>\n<td>100-500 bytes per document</td>\n<td>Every 100 updates or 1 minute</td>\n</tr>\n<tr>\n<td><strong>Model Metadata</strong></td>\n<td>JSON configuration</td>\n<td>Fixed ~1KB</td>\n<td>On model changes only</td>\n</tr>\n<tr>\n<td><strong>Update Log</strong></td>\n<td>Binary append-only</td>\n<td>50 bytes per operation</td>\n<td>Every update (real-time)</td>\n</tr>\n</tbody></table>\n<p>The persistence format includes version headers that track the embedding model, index algorithm, and configuration parameters used during construction. This versioning enables safe index loading and prevents incompatibility issues when the system configuration changes.</p>\n<p><strong>Index Checkpoint Structure:</strong></p>\n<ol>\n<li>Header containing format version, algorithm type, and model information</li>\n<li>FAISS index binary data with complete graph structure or cluster assignments</li>\n<li>Document ID to index position mapping for efficient lookups</li>\n<li>Metadata including build timestamps, update counts, and performance statistics</li>\n<li>Configuration parameters used during index construction for reproducible builds</li>\n</ol>\n<h4 id=\"incremental-update-implementation\">Incremental Update Implementation</h4>\n<p>The incremental update system maintains index consistency while adding new documents without requiring complete reconstruction. HNSW naturally supports incremental updates through its graph-based structure, while IVF requires more sophisticated handling to maintain clustering quality.</p>\n<table>\n<thead>\n<tr>\n<th>Update Type</th>\n<th>HNSW Handling</th>\n<th>IVF Handling</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Add Document</strong></td>\n<td>Insert into graph with neighbor linking</td>\n<td>Add to nearest cluster, recompute if needed</td>\n<td>Low (1-5ms)</td>\n</tr>\n<tr>\n<td><strong>Update Document</strong></td>\n<td>Remove old, add new with same ID</td>\n<td>Remove from old cluster, add to new</td>\n<td>Medium (5-15ms)</td>\n</tr>\n<tr>\n<td><strong>Delete Document</strong></td>\n<td>Mark as deleted, lazy cleanup</td>\n<td>Remove from cluster, update statistics</td>\n<td>Low (1-3ms)</td>\n</tr>\n<tr>\n<td><strong>Bulk Insert</strong></td>\n<td>Batch neighbor computation</td>\n<td>Recompute cluster assignments</td>\n<td>High (seconds)</td>\n</tr>\n</tbody></table>\n<p>The incremental update process maintains an update log that records all modifications since the last checkpoint. This log enables crash recovery and provides an audit trail for debugging index corruption issues. Updates are applied immediately to the in-memory index structure and periodically flushed to persistent storage.</p>\n<p><strong>Update Process Flow:</strong></p>\n<ol>\n<li>Validate new document and generate embedding using consistent model</li>\n<li>Acquire write lock on index structure to ensure consistency</li>\n<li>Apply update to in-memory index (add to graph or assign to cluster)</li>\n<li>Record update in persistent log with timestamp and operation details</li>\n<li>Update document ID mapping and metadata structures</li>\n<li>Release write lock and return success confirmation</li>\n<li>Periodically trigger background checkpoint creation for durability</li>\n</ol>\n<h4 id=\"index-state-management-and-recovery\">Index State Management and Recovery</h4>\n<p>The index lifecycle management system handles state transitions from initialization through active operation to shutdown, ensuring data consistency and enabling graceful recovery from failures.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Findex-state-machine.svg\" alt=\"Index Lifecycle State Machine\"></p>\n<table>\n<thead>\n<tr>\n<th>State</th>\n<th>Description</th>\n<th>Allowed Transitions</th>\n<th>Recovery Actions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Initializing</strong></td>\n<td>Loading persisted index or building new</td>\n<td>→ Training, → Active</td>\n<td>Load checkpoint or start fresh build</td>\n</tr>\n<tr>\n<td><strong>Training</strong></td>\n<td>Learning cluster centroids (IVF only)</td>\n<td>→ Active, → Failed</td>\n<td>Complete training or restart from checkpoint</td>\n</tr>\n<tr>\n<td><strong>Active</strong></td>\n<td>Serving queries and accepting updates</td>\n<td>→ Checkpointing, → Shutdown</td>\n<td>Continue normal operation</td>\n</tr>\n<tr>\n<td><strong>Checkpointing</strong></td>\n<td>Persisting index state to storage</td>\n<td>→ Active, → Failed</td>\n<td>Complete checkpoint or retry</td>\n</tr>\n<tr>\n<td><strong>Failed</strong></td>\n<td>Error state requiring intervention</td>\n<td>→ Initializing</td>\n<td>Diagnose issue and restart</td>\n</tr>\n</tbody></table>\n<p>The recovery system detects incomplete operations and determines the appropriate recovery action based on the update log and checkpoint state. If the most recent checkpoint is consistent but updates exist in the log, the system replays logged operations to restore the current state. If corruption is detected, the system falls back to the most recent valid checkpoint and discards potentially corrupted updates.</p>\n<blockquote>\n<p><strong>Design Decision: Asynchronous Checkpointing</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance search availability with data durability requirements</li>\n<li><strong>Options Considered</strong>: Synchronous checkpointing blocking updates, asynchronous background checkpointing, write-ahead logging with snapshots</li>\n<li><strong>Decision</strong>: Implement asynchronous checkpointing with write-ahead logging for immediate update durability</li>\n<li><strong>Rationale</strong>: Synchronous checkpointing creates unacceptable latency spikes, while asynchronous approach maintains performance with minimal durability risk</li>\n<li><strong>Consequences</strong>: Slightly more complex recovery logic but much better user experience and system availability</li>\n</ul>\n</blockquote>\n<h3 id=\"common-implementation-pitfalls\">Common Implementation Pitfalls</h3>\n<p>Understanding and avoiding common implementation mistakes can save significant debugging time and prevent subtle correctness issues that are difficult to diagnose in production. These pitfalls represent the most frequent errors encountered when building vector search systems, along with their symptoms and solutions.</p>\n<h4 id=\"-pitfall-vector-normalization-inconsistency\">⚠️ <strong>Pitfall: Vector Normalization Inconsistency</strong></h4>\n<p>One of the most critical and subtle errors involves inconsistent vector normalization between document embeddings and query embeddings. Cosine similarity calculations require all vectors to be normalized to unit length, but failing to apply normalization consistently leads to incorrect similarity scores and poor search results.</p>\n<p><strong>Why This Happens</strong>: Developers often normalize document vectors during index construction but forget to normalize query vectors at search time, or vice versa. The embedding model may or may not produce normalized vectors depending on its training configuration, leading to assumptions that prove incorrect.</p>\n<p><strong>Symptoms</strong>: Search results seem random, similar documents receive vastly different similarity scores, or the similarity score distribution doesn&#39;t match expected patterns (e.g., scores outside the [-1, 1] range for cosine similarity).</p>\n<p><strong>Detection Method</strong>: Compare similarity scores between identical documents—they should be exactly 1.0 for cosine similarity with normalized vectors. Verify vector norms using <code>np.linalg.norm(embedding)</code> throughout the pipeline.</p>\n<p><strong>Prevention Strategy</strong>: Apply normalization explicitly at every embedding generation point and verify vector norms during testing. Create unit tests that verify similarity calculations between known similar and dissimilar text pairs.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Correct approach - explicit normalization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> normalize_vector</span><span style=\"color:#E1E4E8\">(vec: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"L2 normalize vector to unit length for cosine similarity.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vec)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> norm </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> vec  </span><span style=\"color:#6A737D\"># Handle zero vector case</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> vec </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> norm</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Always normalize embeddings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">embedding </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> normalize_vector(model.encode(text))</span></span></code></pre></div>\n\n<h4 id=\"-pitfall-hnsw-memory-explosion-with-high-m-parameter\">⚠️ <strong>Pitfall: HNSW Memory Explosion with High M Parameter</strong></h4>\n<p>The HNSW <code>M</code> parameter controls the maximum number of connections per vector in the graph structure. Setting this value too high causes exponential memory growth that can exhaust available RAM, while setting it too low degrades search quality significantly.</p>\n<p><strong>Why This Happens</strong>: Developers assume that higher <code>M</code> values always improve search quality and set values like 64 or 128 without understanding the memory implications. Each vector stores connections to up to <code>M</code> neighbors, and memory usage scales as <code>O(N * M)</code> where N is the number of vectors.</p>\n<p><strong>Symptoms</strong>: Memory usage grows far beyond expected levels (e.g., 10-20x the raw vector data size), system becomes unresponsive due to memory pressure, or out-of-memory errors during index construction.</p>\n<p><strong>Calculation Example</strong>: For 1 million 384-dimensional vectors with M=64:</p>\n<ul>\n<li>Raw vector data: 1M × 384 × 4 bytes = 1.5 GB</li>\n<li>HNSW connections: 1M × 64 × 8 bytes = 512 MB (just for connection storage)</li>\n<li>Total memory usage: Often 8-15 GB due to additional metadata and overhead</li>\n</ul>\n<p><strong>Prevention Strategy</strong>: Start with conservative values (M=16 for most use cases, M=32 for high-accuracy requirements) and measure memory usage empirically. Monitor memory growth during index construction and establish alerts for unexpected usage patterns.</p>\n<h4 id=\"-pitfall-document-id-mapping-synchronization-issues\">⚠️ <strong>Pitfall: Document ID Mapping Synchronization Issues</strong></h4>\n<p>Vector indices store vectors by internal position indices, but applications need to map these back to document IDs. Maintaining synchronization between the vector index positions and document ID mappings becomes critical, especially during incremental updates and deletions.</p>\n<p><strong>Why This Happens</strong>: The FAISS index assigns sequential internal IDs to vectors, but these don&#39;t correspond to application document IDs. Developers create separate mapping structures but fail to maintain consistency during updates, particularly when handling deleted documents.</p>\n<p><strong>Symptoms</strong>: Search returns wrong documents (ID mapping drift), missing results for documents that should exist, or crashes when trying to retrieve documents by returned IDs.</p>\n<p><strong>Prevention Strategy</strong>: Implement atomic updates that modify both the vector index and ID mapping within the same transaction. Use consistent indexing schemes and validate mapping consistency during startup and after major operations.</p>\n<table>\n<thead>\n<tr>\n<th>Operation</th>\n<th>Index Update</th>\n<th>Mapping Update</th>\n<th>Validation Check</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Add Document</strong></td>\n<td>Insert vector at position N</td>\n<td>Map doc_id → N</td>\n<td>Verify doc exists at mapped position</td>\n</tr>\n<tr>\n<td><strong>Delete Document</strong></td>\n<td>Mark position as deleted</td>\n<td>Remove doc_id mapping</td>\n<td>Verify doc_id not in mapping</td>\n</tr>\n<tr>\n<td><strong>Update Document</strong></td>\n<td>Update vector at existing position</td>\n<td>Maintain same mapping</td>\n<td>Verify vector and mapping consistency</td>\n</tr>\n</tbody></table>\n<h4 id=\"-pitfall-ivf-training-data-insufficiency\">⚠️ <strong>Pitfall: IVF Training Data Insufficiency</strong></h4>\n<p>IVF indices require a training phase where k-means clustering learns the optimal partitioning of the vector space. Using insufficient or unrepresentative training data leads to poor cluster quality and degraded search performance.</p>\n<p><strong>Why This Happens</strong>: Developers train IVF indices on small samples (e.g., 1000 documents) or on documents from a narrow domain, then use the index for much larger or more diverse document collections. The resulting clusters don&#39;t represent the full vector space well.</p>\n<p><strong>Training Requirements</strong>: Use at least 30-50 vectors per planned cluster (30K-50K training vectors for 1000 clusters) drawn representatively from the full document collection. Training data should span the complete range of content types and topics expected in production.</p>\n<p><strong>Symptoms</strong>: Poor search quality despite high cluster counts, uneven cluster sizes with some clusters containing most documents, or degraded performance as the collection grows beyond the training distribution.</p>\n<p><strong>Prevention Strategy</strong>: Reserve a representative sample of documents for training, ensure sample size meets minimum requirements, and retrain indices when the document collection characteristics change significantly.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Production Consideration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Embedding Model</strong></td>\n<td><code>sentence-transformers/all-MiniLM-L6-v2</code></td>\n<td><code>sentence-transformers/all-mpnet-base-v2</code></td>\n<td>Balance speed vs. accuracy needs</td>\n</tr>\n<tr>\n<td><strong>Vector Index</strong></td>\n<td>FAISS with HNSW (<code>IndexHNSWFlat</code>)</td>\n<td>FAISS with GPU support (<code>IndexFlatIP</code>)</td>\n<td>HNSW for most use cases</td>\n</tr>\n<tr>\n<td><strong>Persistence</strong></td>\n<td>Pickle serialization</td>\n<td>Custom binary format with compression</td>\n<td>Consider security implications</td>\n</tr>\n<tr>\n<td><strong>Text Processing</strong></td>\n<td>Basic regex cleaning</td>\n<td>Advanced NLP preprocessing</td>\n<td>Start simple, add complexity as needed</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-filemodule-structure\">Recommended File/Module Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>semantic_search/\n  embeddings/\n    __init__.py                 ← Public interfaces\n    encoder.py                  ← DocumentEncoder and TextProcessor\n    index_manager.py           ← Index construction and persistence\n    faiss_wrapper.py           ← FAISS integration utilities\n    similarity.py              ← Vector similarity calculations\n  tests/\n    test_encoder.py            ← Embedding generation tests\n    test_index.py              ← Index operations tests\n    test_similarity.py         ← Similarity calculation tests\n  data/\n    models/                    ← Downloaded transformer models\n    indices/                   ← Persisted index files\n    documents/                 ← Sample documents for testing</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Text Processing Utilities</strong> (complete implementation):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># semantic_search/embeddings/text_processing.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> html</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TextProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles text cleaning and normalization for consistent embedding generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.url_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#DBEDFF\">https</span><span style=\"color:#F97583\">?</span><span style=\"color:#DBEDFF\">://</span><span style=\"color:#79B8FF\">[</span><span style=\"color:#F97583\">^</span><span style=\"color:#79B8FF\">\\s]</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.email_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\b[A-Za-z0-9._%+-]</span><span style=\"color:#F97583\">+</span><span style=\"color:#DBEDFF\">@</span><span style=\"color:#79B8FF\">[A-Za-z0-9.-]</span><span style=\"color:#F97583\">+</span><span style=\"color:#85E89D;font-weight:bold\">\\.</span><span style=\"color:#79B8FF\">[A-Z|a-z]</span><span style=\"color:#F97583\">{2,}</span><span style=\"color:#79B8FF\">\\b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.whitespace_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\s</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clean_text</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Normalize and clean text for embedding processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> text:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Decode HTML entities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> html.unescape(text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Replace URLs with generic token</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.url_pattern.sub(</span><span style=\"color:#9ECBFF\">'[URL]'</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Replace emails with generic token</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.email_pattern.sub(</span><span style=\"color:#9ECBFF\">'[EMAIL]'</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Normalize whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.whitespace_pattern.sub(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Remove control characters but preserve newlines and tabs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        text </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> ''</span><span style=\"color:#E1E4E8\">.join(char </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> char </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> text </span><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> ord</span><span style=\"color:#E1E4E8\">(char) </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 32</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> char </span><span style=\"color:#F97583\">in</span><span style=\"color:#9ECBFF\"> '</span><span style=\"color:#79B8FF\">\\n\\t</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Strip leading/trailing whitespace</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> text.strip()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> get_searchable_text</span><span style=\"color:#E1E4E8\">(document) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Extract searchable text from document with title weighting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    parts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> document.title:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Weight title by including it twice for emphasis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        parts.extend([document.title, document.title])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> document.content:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        parts.append(document.content)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#9ECBFF\"> ' '</span><span style=\"color:#E1E4E8\">.join(parts)</span></span></code></pre></div>\n\n<p><strong>Vector Utilities</strong> (complete implementation):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># semantic_search/embeddings/vector_utils.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Union</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> normalize_vector</span><span style=\"color:#E1E4E8\">(vec: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"L2 normalize vector to unit length for cosine similarity.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> vec.ndim </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        norm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vec)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> vec </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> norm </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> norm </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#E1E4E8\"> vec</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle batch of vectors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        norms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vec, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">keepdims</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> vec </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> np.where(norms </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, norms, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> cosine_similarity</span><span style=\"color:#E1E4E8\">(vec1: np.ndarray, vec2: np.ndarray) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute cosine similarity between two normalized vectors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Assume vectors are already normalized</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(np.dot(vec1, vec2))</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> batch_cosine_similarity</span><span style=\"color:#E1E4E8\">(query_vec: np.ndarray, doc_vecs: np.ndarray) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Compute cosine similarities between query and multiple document vectors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # All vectors should be normalized</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> np.dot(doc_vecs, query_vec)</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Document Encoder</strong> (structure with TODOs):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># semantic_search/embeddings/encoder.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sentence_transformers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SentenceTransformer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .text_processing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> TextProcessor, get_searchable_text</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .vector_utils </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> normalize_vector</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DEFAULT_MODEL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'all-MiniLM-L6-v2'</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">EMBEDDING_DIM</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 384</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentEncoder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Converts documents and queries to vector embeddings using transformer models.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> DEFAULT_MODEL</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize SentenceTransformer model with model_name</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set embedding_dim by encoding a test string and checking shape</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create TextProcessor instance for preprocessing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store model_name for metadata tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_document</span><span style=\"color:#E1E4E8\">(self, document) -> </span><span style=\"color:#9ECBFF\">'DocumentEmbedding'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Convert document to vector embedding with metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract searchable text using get_searchable_text()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clean text using text_processor.clean_text()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate embedding using self.model.encode()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Normalize embedding vector using normalize_vector()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create DocumentEmbedding object with document, embedding, model info</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Validate embedding dimensions match expected EMBEDDING_DIM</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_texts</span><span style=\"color:#E1E4E8\">(self, texts: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Batch encode multiple texts for efficiency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clean all texts using text processor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Use model.encode() with batch processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize all embedding vectors</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate output shape is (len(texts), embedding_dim)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Batching improves performance for multiple texts</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Encode search query using same model as documents.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Clean query text using text processor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate embedding using model (same as document encoding)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Normalize embedding vector</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return numpy array with shape (embedding_dim,)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Index Manager</strong> (structure with TODOs):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># semantic_search/embeddings/index_manager.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> faiss</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pickle</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HNSWIndexManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages HNSW index construction, persistence, and incremental updates.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, embedding_dim: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> EMBEDDING_DIM</span><span style=\"color:#E1E4E8\">, M: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 16</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store embedding_dim and validate it's positive</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create FAISS HNSW index using faiss.IndexHNSWFlat()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Set HNSW parameters (M=16, efConstruction=200)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Initialize document ID mapping dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Initialize update counter for checkpoint triggering</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> add_documents</span><span style=\"color:#E1E4E8\">(self, embeddings: List[</span><span style=\"color:#9ECBFF\">'DocumentEmbedding'</span><span style=\"color:#E1E4E8\">]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add document embeddings to index with ID tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract embedding vectors into numpy array</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate all embeddings have correct dimensionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add vectors to FAISS index using index.add()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update document ID mapping for each added document</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Increment update counter and trigger checkpoint if needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: FAISS assigns sequential internal IDs starting from current size</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> search_similar</span><span style=\"color:#E1E4E8\">(self, query_embedding: np.ndarray, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Find k most similar documents to query embedding.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate query embedding dimensions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Reshape query to (1, embedding_dim) for FAISS</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Search index using index.search() method</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Convert internal IDs to document IDs using mapping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return list of (document_id, similarity_score) tuples</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle case where fewer than k documents exist</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> save_index</span><span style=\"color:#E1E4E8\">(self, filepath: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Persist index and metadata to disk.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Save FAISS index using faiss.write_index()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Save document ID mapping using pickle</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Save metadata (dimensions, model info) separately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Implement atomic save (write to temp file, then rename)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use faiss.write_index() for the vector index</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> load_index</span><span style=\"color:#E1E4E8\">(self, filepath: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load persisted index and metadata from disk.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load FAISS index using faiss.read_index()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load document ID mapping from pickle file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate loaded index dimensions match expected</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Restore update counter and other metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify index consistency (mapping size matches index size)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<ul>\n<li>Use <code>sentence-transformers</code> library for embedding generation: <code>pip install sentence-transformers</code></li>\n<li>Install FAISS for vector indexing: <code>pip install faiss-cpu</code> (or <code>faiss-gpu</code> for GPU support)</li>\n<li>Use <code>numpy</code> arrays for all vector operations—avoid Python lists for performance</li>\n<li>Consider using <code>concurrent.futures</code> for parallel document processing during bulk operations</li>\n<li>Use <code>logging</code> module to track index operations and debug issues</li>\n<li>Implement proper exception handling for model loading and FAISS operations</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the embedding index component, verify functionality with these tests:</p>\n<p><strong>Test Command</strong>: <code>python -m pytest tests/test_embedding_index.py -v</code></p>\n<p><strong>Expected Behaviors</strong>:</p>\n<ol>\n<li>Document encoder should generate consistent embeddings for identical text</li>\n<li>Index should support adding documents and retrieving them by similarity</li>\n<li>Saved indices should load correctly and preserve search functionality</li>\n<li>Similarity scores should be in valid ranges (0-1 for cosine similarity)</li>\n</ol>\n<p><strong>Manual Verification Steps</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test embedding generation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from embeddings.encoder import DocumentEncoder</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">encoder = DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">doc1_emb = encoder.encode_query('machine learning algorithms')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">doc2_emb = encoder.encode_query('artificial intelligence models')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Embedding dim: {doc1_emb.shape[0]}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Similarity: {np.dot(doc1_emb, doc2_emb):.3f}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test index operations</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from embeddings.index_manager import HNSWIndexManager</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">index = HNSWIndexManager()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Add some test documents and search</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Signs of Problems</strong>:</p>\n<ul>\n<li>Embeddings have wrong dimensions (should be 384 for default model)</li>\n<li>Similarity scores outside [0,1] range indicate normalization issues</li>\n<li>Index search returns wrong number of results or throws exceptions</li>\n<li>Memory usage much higher than expected indicates parameter issues</li>\n</ul>\n<h2 id=\"query-processing-component\">Query Processing Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2: Query Processing</p>\n</blockquote>\n<p>The <strong>Query Processing Component</strong> represents the intelligence layer that sits between raw user input and our embedding index, transforming simple search queries into rich semantic representations. While our embedding index excels at finding similar vectors, the query processor ensures we&#39;re searching for the right thing by understanding user intent, expanding vocabulary, and preparing queries for optimal retrieval performance.</p>\n<h3 id=\"query-understanding-mental-model-translator-analogy-for-how-queries-are-interpreted-and-enhanced\">Query Understanding Mental Model: Translator Analogy for How Queries Are Interpreted and Enhanced</h3>\n<p>Think of the query processor as a skilled translator working at the United Nations. When a delegate speaks, the translator doesn&#39;t just convert words directly from one language to another. Instead, they understand the speaker&#39;s intent, cultural context, and implied meanings, then craft a message that conveys the full semantic richness to the audience. They might expand abbreviations, clarify ambiguous terms, and even split complex statements into multiple concepts to ensure nothing is lost in translation.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fquery-processing-flow.svg\" alt=\"Query Processing Pipeline\"></p>\n<p>Similarly, our query processor takes a user&#39;s brief search query and translates it into a rich semantic representation that our vector index can understand. A query like &quot;ML algorithms&quot; doesn&#39;t just become one vector embedding. The processor recognizes that &quot;ML&quot; expands to &quot;machine learning,&quot; identifies related concepts like &quot;artificial intelligence&quot; and &quot;neural networks,&quot; and prepares multiple query vectors to capture different aspects of what the user might be seeking.</p>\n<p>The translator analogy extends to handling ambiguity and context. When someone searches for &quot;python,&quot; are they interested in the programming language, the snake, or the comedy group? A skilled query processor, like a good translator, uses surrounding context and user history to disambiguate and focus the search appropriately.</p>\n<p><strong>Query Processing Responsibilities</strong></p>\n<p>The query processor owns several critical transformations that bridge the gap between human language and machine understanding:</p>\n<table>\n<thead>\n<tr>\n<th>Responsibility</th>\n<th>Input</th>\n<th>Output</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Text Normalization</strong></td>\n<td>Raw query string</td>\n<td>Cleaned, standardized text</td>\n<td>Remove noise, standardize formatting</td>\n</tr>\n<tr>\n<td><strong>Intent Recognition</strong></td>\n<td>Normalized query</td>\n<td>Query intent classification</td>\n<td>Understand what type of search this is</td>\n</tr>\n<tr>\n<td><strong>Entity Extraction</strong></td>\n<td>Query text</td>\n<td>Named entities and types</td>\n<td>Identify specific people, places, concepts</td>\n</tr>\n<tr>\n<td><strong>Query Expansion</strong></td>\n<td>Original terms</td>\n<td>Expanded term set</td>\n<td>Add synonyms and related concepts</td>\n</tr>\n<tr>\n<td><strong>Vector Embedding</strong></td>\n<td>Processed query</td>\n<td>Dense vector representation</td>\n<td>Convert to searchable embedding</td>\n</tr>\n<tr>\n<td><strong>Multi-Vector Composition</strong></td>\n<td>Query aspects</td>\n<td>Combined query vectors</td>\n<td>Handle complex queries with multiple facets</td>\n</tr>\n<tr>\n<td><strong>Cache Management</strong></td>\n<td>Query embeddings</td>\n<td>Cached vectors</td>\n<td>Optimize repeated query performance</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Insight:</strong> The query processor is where linguistic understanding meets computational efficiency. Every enhancement we add improves search quality but also increases latency. The key architectural challenge is determining which query understanding steps provide the highest quality improvement per millisecond of added processing time.</p>\n</blockquote>\n<h3 id=\"query-expansion-strategy-adding-synonyms-and-related-terms-while-avoiding-over-expansion\">Query Expansion Strategy: Adding Synonyms and Related Terms While Avoiding Over-Expansion</h3>\n<p>Query expansion addresses one of the fundamental challenges in information retrieval: <strong>vocabulary mismatch</strong>. Users often search using different terminology than what appears in relevant documents. A user might search for &quot;car repair&quot; while the best document uses &quot;automotive maintenance&quot; or &quot;vehicle service.&quot; Without query expansion, these semantically identical concepts would score poorly in both lexical and semantic search.</p>\n<p><strong>Architecture Decision: Hybrid Expansion Approach</strong></p>\n<blockquote>\n<p><strong>Decision: Multi-Strategy Query Expansion</strong></p>\n<ul>\n<li><strong>Context</strong>: Users and documents often use different vocabulary for the same concepts, leading to relevant documents being missed due to terminology misalignment</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>WordNet-based synonym expansion</li>\n<li>Embedding similarity expansion</li>\n<li>Corpus-specific term co-occurrence expansion</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement a hybrid approach combining embedding similarity with corpus-specific co-occurrence patterns</li>\n<li><strong>Rationale</strong>: WordNet provides broad coverage but lacks domain specificity. Embedding similarity captures semantic relationships but can drift from original intent. Corpus co-occurrence grounds expansion in actual document vocabulary.</li>\n<li><strong>Consequences</strong>: Requires maintaining co-occurrence statistics and careful weight balancing, but provides more relevant and domain-appropriate expansions</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Expansion Strategy</th>\n<th>Coverage</th>\n<th>Domain Adaptation</th>\n<th>Computational Cost</th>\n<th>Drift Risk</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>WordNet Synonyms</strong></td>\n<td>High</td>\n<td>Low</td>\n<td>Low</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td><strong>Embedding Similarity</strong></td>\n<td>Medium</td>\n<td>Medium</td>\n<td>Medium</td>\n<td>High</td>\n</tr>\n<tr>\n<td><strong>Corpus Co-occurrence</strong></td>\n<td>Medium</td>\n<td>High</td>\n<td>High</td>\n<td>Low</td>\n</tr>\n<tr>\n<td><strong>Hybrid Approach</strong></td>\n<td>High</td>\n<td>High</td>\n<td>Medium</td>\n<td>Low</td>\n</tr>\n</tbody></table>\n<p><strong>Query Expansion Pipeline</strong></p>\n<p>The expansion process follows a carefully orchestrated sequence designed to enhance recall while preserving the original query intent:</p>\n<ol>\n<li><p><strong>Original Query Analysis</strong>: Parse the input query to identify core terms, phrases, and any special operators (quotes, negation, filters). Extract the primary intent and key concepts that must be preserved throughout expansion.</p>\n</li>\n<li><p><strong>Term Importance Scoring</strong>: Calculate importance weights for each term based on inverse document frequency (IDF) and position within the query. High-importance terms (rare, specific concepts) receive conservative expansion to maintain precision, while common terms receive broader expansion to improve recall.</p>\n</li>\n<li><p><strong>Synonym Generation</strong>: For each term, generate synonyms using multiple strategies. Embedding-based expansion finds terms with similar vector representations in our semantic space. Corpus co-occurrence identifies terms that frequently appear together in our document collection, indicating semantic relationships.</p>\n</li>\n<li><p><strong>Expansion Filtering</strong>: Apply several filters to prevent expansion drift. Semantic similarity thresholds ensure expanded terms remain conceptually related to originals. Context compatibility checks verify that expanded terms make sense within the query&#39;s overall meaning. Domain relevance scoring prioritizes expansions that align with our document corpus.</p>\n</li>\n<li><p><strong>Expansion Weight Assignment</strong>: Assign confidence weights to expanded terms based on their similarity to original terms and frequency of co-occurrence in relevant documents. Original query terms receive weight 1.0, while expanded terms receive weights between 0.1 and 0.8 depending on confidence.</p>\n</li>\n<li><p><strong>Query Reconstruction</strong>: Combine original and expanded terms into an enhanced query representation that maintains the logical structure of the original while incorporating semantic expansions.</p>\n</li>\n</ol>\n<p><strong>Query Expansion Data Structures</strong></p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>original_query</code></td>\n<td><code>str</code></td>\n<td>The unmodified user input query</td>\n</tr>\n<tr>\n<td><code>core_terms</code></td>\n<td><code>List[str]</code></td>\n<td>Main concepts extracted from query</td>\n</tr>\n<tr>\n<td><code>expansion_candidates</code></td>\n<td><code>Dict[str, List[Tuple[str, float]]]</code></td>\n<td>Term -&gt; [(synonym, confidence), ...]</td>\n</tr>\n<tr>\n<td><code>expanded_terms</code></td>\n<td><code>List[Tuple[str, float, str]]</code></td>\n<td>(term, weight, source_strategy)</td>\n</tr>\n<tr>\n<td><code>filtered_expansions</code></td>\n<td><code>List[Tuple[str, float]]</code></td>\n<td>Final expanded terms after filtering</td>\n</tr>\n<tr>\n<td><code>expansion_metadata</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Debug info and expansion statistics</td>\n</tr>\n</tbody></table>\n<p><strong>Avoiding Over-Expansion</strong></p>\n<p>Over-expansion represents one of the most critical pitfalls in query enhancement. When expansion adds too many terms or strays too far from the original intent, search results become unfocused and relevance suffers dramatically.</p>\n<p>⚠️ <strong>Pitfall: Semantic Drift Through Excessive Expansion</strong></p>\n<p>A common mistake is applying expansion recursively or using overly permissive similarity thresholds. For example, expanding &quot;python programming&quot; → &quot;snake&quot; → &quot;reptile&quot; → &quot;animal&quot; creates a chain that completely loses the original computational context. This happens when expansion algorithms don&#39;t maintain connection to the root query intent.</p>\n<p><strong>Fix</strong>: Implement expansion budgets and semantic anchoring. Limit each query to a maximum expansion ratio (e.g., no more than 3 expanded terms per original term), and require all expanded terms to maintain minimum similarity to at least one original term.</p>\n<p>⚠️ <strong>Pitfall: Domain Confusion</strong></p>\n<p>Another frequent issue occurs when general-purpose expansion resources (like WordNet) suggest terms that are technically synonymous but inappropriate for the specific domain. Searching for &quot;python classes&quot; might expand to include &quot;social classes&quot; or &quot;economic classes,&quot; introducing irrelevant results from sociology documents.</p>\n<p><strong>Fix</strong>: Train domain-specific expansion models on your document corpus, and filter expansion candidates through domain relevance scoring before applying them to queries.</p>\n<p>The expansion system maintains careful balance through configurable parameters that can be tuned based on user feedback and search quality metrics:</p>\n<table>\n<thead>\n<tr>\n<th>Parameter</th>\n<th>Purpose</th>\n<th>Typical Range</th>\n<th>Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>max_expansions_per_term</code></td>\n<td>Prevent explosion</td>\n<td>2-5</td>\n<td>Controls expansion volume</td>\n</tr>\n<tr>\n<td><code>min_similarity_threshold</code></td>\n<td>Maintain relevance</td>\n<td>0.6-0.8</td>\n<td>Filters weak relationships</td>\n</tr>\n<tr>\n<td><code>expansion_weight_decay</code></td>\n<td>Balance original vs expanded</td>\n<td>0.3-0.7</td>\n<td>Controls expansion influence</td>\n</tr>\n<tr>\n<td><code>domain_relevance_threshold</code></td>\n<td>Ensure corpus alignment</td>\n<td>0.4-0.6</td>\n<td>Prevents domain drift</td>\n</tr>\n</tbody></table>\n<h3 id=\"semantic-query-analysis-entity-extraction-and-intent-understanding-from-query-text\">Semantic Query Analysis: Entity extraction and Intent Understanding from Query Text</h3>\n<p>Beyond simple term expansion, sophisticated query processing requires understanding the semantic structure and intent behind user queries. This involves recognizing named entities (people, places, organizations, dates), understanding query types (factual lookup, exploratory browsing, specific document retrieval), and extracting the underlying information need that the user is trying to satisfy.</p>\n<p><strong>Entity Recognition and Extraction</strong></p>\n<p>Named entity recognition (NER) within queries serves multiple purposes in semantic search. First, it identifies terms that should not be expanded or modified during query processing—proper names like &quot;Barack Obama&quot; or &quot;Microsoft&quot; have specific, fixed meanings that expansion could distort. Second, entity recognition enables entity-specific search strategies, such as boosting documents that contain exact entity matches or applying entity-type filters.</p>\n<p>The entity extraction pipeline processes queries through several specialized recognition stages:</p>\n<ol>\n<li><p><strong>Standard Named Entity Recognition</strong>: Apply pre-trained NER models to identify common entity types including persons, organizations, locations, dates, and monetary amounts. These entities receive special handling during expansion and embedding generation.</p>\n</li>\n<li><p><strong>Technical Term Identification</strong>: Recognize domain-specific entities like software names, technical acronyms, model numbers, and scientific terminology that require exact matching rather than semantic similarity. This prevents expansion of terms like &quot;GPT-3&quot; or &quot;TCP/IP&quot; which would lose their specific meaning.</p>\n</li>\n<li><p><strong>Temporal Expression Parsing</strong>: Extract and normalize time-related expressions like &quot;last week,&quot; &quot;2023,&quot; or &quot;recent&quot; into structured temporal constraints that can be applied as filters rather than semantic queries.</p>\n</li>\n<li><p><strong>Entity Relationship Detection</strong>: Identify relationships between entities within the query, such as &quot;CEO of Microsoft&quot; or &quot;papers by Einstein,&quot; which indicate structured queries that benefit from knowledge graph enhancement.</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Entity Type</th>\n<th>Recognition Method</th>\n<th>Search Strategy</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Person Names</strong></td>\n<td>NER + Name Dictionary</td>\n<td>Exact + Alias Matching</td>\n<td>&quot;Barack Obama&quot;, &quot;Obama&quot;</td>\n</tr>\n<tr>\n<td><strong>Organizations</strong></td>\n<td>NER + Known Entity DB</td>\n<td>Exact + Subsidiary Matching</td>\n<td>&quot;Microsoft&quot;, &quot;MS&quot;</td>\n</tr>\n<tr>\n<td><strong>Locations</strong></td>\n<td>NER + Gazetteer</td>\n<td>Geographic Expansion</td>\n<td>&quot;SF&quot; → &quot;San Francisco&quot;</td>\n</tr>\n<tr>\n<td><strong>Technical Terms</strong></td>\n<td>Domain Dictionary</td>\n<td>Exact Matching Only</td>\n<td>&quot;React.js&quot;, &quot;COVID-19&quot;</td>\n</tr>\n<tr>\n<td><strong>Dates/Times</strong></td>\n<td>Temporal Parser</td>\n<td>Range Constraints</td>\n<td>&quot;2023&quot; → date filter</td>\n</tr>\n<tr>\n<td><strong>Products/Models</strong></td>\n<td>Pattern Recognition</td>\n<td>Exact + Version Matching</td>\n<td>&quot;iPhone 14&quot;, &quot;GPT-3&quot;</td>\n</tr>\n</tbody></table>\n<p><strong>Query Intent Classification</strong></p>\n<p>Understanding query intent allows the system to apply appropriate search strategies and result formatting. Different intent types benefit from different combinations of semantic similarity, lexical matching, and result ranking approaches.</p>\n<p><strong>Intent Classification Framework</strong></p>\n<p>The system recognizes several primary intent categories, each requiring different search and ranking strategies:</p>\n<table>\n<thead>\n<tr>\n<th>Intent Type</th>\n<th>Characteristics</th>\n<th>Search Strategy</th>\n<th>Example Queries</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Factual Lookup</strong></td>\n<td>Specific answer sought</td>\n<td>Precise matching + knowledge extraction</td>\n<td>&quot;what is the capital of France&quot;</td>\n</tr>\n<tr>\n<td><strong>Exploratory Browse</strong></td>\n<td>Topic exploration</td>\n<td>Broad semantic similarity</td>\n<td>&quot;machine learning techniques&quot;</td>\n</tr>\n<tr>\n<td><strong>Document Retrieval</strong></td>\n<td>Specific document sought</td>\n<td>Combined lexical/semantic</td>\n<td>&quot;Smith 2023 neural networks paper&quot;</td>\n</tr>\n<tr>\n<td><strong>Comparative Analysis</strong></td>\n<td>Multiple entity comparison</td>\n<td>Multi-entity semantic search</td>\n<td>&quot;React vs Angular performance&quot;</td>\n</tr>\n<tr>\n<td><strong>Procedural How-to</strong></td>\n<td>Step-by-step instructions</td>\n<td>Task-oriented matching</td>\n<td>&quot;how to install Docker&quot;</td>\n</tr>\n<tr>\n<td><strong>Definitional</strong></td>\n<td>Concept explanation</td>\n<td>Authority source boosting</td>\n<td>&quot;what is quantum computing&quot;</td>\n</tr>\n</tbody></table>\n<p><strong>Intent Detection Pipeline</strong></p>\n<p>Intent classification combines multiple signal sources to determine the most likely user intent:</p>\n<ol>\n<li><p><strong>Syntactic Pattern Analysis</strong>: Examine query structure for intent indicators like question words (&quot;what,&quot; &quot;how,&quot; &quot;why&quot;), comparative terms (&quot;vs,&quot; &quot;better than&quot;), or action verbs (&quot;install,&quot; &quot;configure,&quot; &quot;troubleshoot&quot;).</p>\n</li>\n<li><p><strong>Semantic Intent Modeling</strong>: Apply trained classifiers that understand the semantic patterns associated with different intent types, trained on query-intent pairs from search logs or manually labeled data.</p>\n</li>\n<li><p><strong>Entity-Intent Correlation</strong>: Use entity types and relationships to infer intent. Queries containing multiple competing entities likely indicate comparison intent, while queries with single technical entities suggest definitional or procedural intent.</p>\n</li>\n<li><p><strong>Context Integration</strong>: Incorporate user context such as previous queries in the session, user profile information, and temporal context to disambiguate ambiguous intent signals.</p>\n</li>\n</ol>\n<p><strong>Semantic Query Structure Analysis</strong></p>\n<p>Beyond entities and intent, the query processor analyzes the semantic structure of queries to understand relationships between concepts and optimize vector representation generation.</p>\n<p><strong>Query Decomposition Strategy</strong></p>\n<p>Complex queries often contain multiple semantic concepts that benefit from separate vector representations. The decomposition process identifies these concepts and determines how to combine their embeddings:</p>\n<ol>\n<li><p><strong>Concept Boundary Detection</strong>: Identify natural breakpoints in queries where different concepts begin and end. Linguistic cues include conjunctions (&quot;and,&quot; &quot;or&quot;), prepositional phrases, and semantic topic shifts.</p>\n</li>\n<li><p><strong>Concept Importance Weighting</strong>: Assign importance scores to different query concepts based on specificity, user emphasis (capitalization, quotes), and position within the query structure.</p>\n</li>\n<li><p><strong>Relationship Identification</strong>: Determine how concepts relate to each other—whether they&#39;re additive (both concepts must be present), alternative (either concept acceptable), or hierarchical (one concept constrains the other).</p>\n</li>\n<li><p><strong>Vector Composition Planning</strong>: Decide whether to generate a single combined embedding or multiple concept-specific embeddings that will be composed during search.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Design Insight:</strong> The semantic analysis phase represents a critical trade-off between query understanding depth and processing latency. Each additional analysis step improves search quality but adds milliseconds to query processing time. The architecture prioritizes analyses that provide the highest quality improvement per unit of added latency.</p>\n</blockquote>\n<h3 id=\"multi-vector-query-support-combining-multiple-query-aspects-and-handling-negative-terms\">Multi-Vector Query Support: Combining Multiple Query Aspects and Handling Negative Terms</h3>\n<p>Complex user information needs often cannot be captured by a single vector embedding. A query like &quot;machine learning papers published after 2020 but not about computer vision&quot; contains multiple distinct aspects: a semantic concept (machine learning), a temporal constraint (after 2020), and a negative semantic constraint (excluding computer vision). Multi-vector query support enables the system to represent and search using these complex, multi-faceted requirements.</p>\n<p><strong>Multi-Vector Query Architecture</strong></p>\n<p>The multi-vector approach decomposes complex queries into separate vector representations, each capturing a different aspect of the user&#39;s information need. These vectors are then combined during search using vector arithmetic and weighted scoring to produce results that satisfy all query aspects simultaneously.</p>\n<p><strong>Architecture Decision: Additive Vector Composition vs. Separate Retrieval Paths</strong></p>\n<blockquote>\n<p><strong>Decision: Hybrid Multi-Vector Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Complex queries contain multiple concepts that interact differently—some require additive combination while others need separate retrieval and intersection</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Pure vector arithmetic (add/subtract embeddings)</li>\n<li>Separate retrieval with result intersection  </li>\n<li>Hybrid approach with both arithmetic and retrieval strategies</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement hybrid architecture that chooses composition strategy based on query analysis</li>\n<li><strong>Rationale</strong>: Vector arithmetic works well for closely related concepts but fails for orthogonal constraints like temporal filters. Separate retrieval provides precise control but is computationally expensive. Hybrid approach applies the optimal strategy per query aspect.</li>\n<li><strong>Consequences</strong>: Increases implementation complexity but provides superior result quality for complex queries while maintaining reasonable performance</li>\n</ul>\n</blockquote>\n<p><strong>Query Aspect Identification</strong></p>\n<p>The multi-vector pipeline begins by analyzing queries to identify distinct aspects that warrant separate vector representation:</p>\n<ol>\n<li><p><strong>Semantic Concept Extraction</strong>: Identify the primary semantic concepts within the query. These represent the main topical areas the user is interested in and typically become positive vector embeddings.</p>\n</li>\n<li><p><strong>Constraint Classification</strong>: Separate semantic concepts from structural constraints like temporal filters, format requirements, or source restrictions. Constraints often cannot be effectively represented as embeddings and require separate handling.</p>\n</li>\n<li><p><strong>Negation Detection</strong>: Identify negative terms introduced by words like &quot;not,&quot; &quot;except,&quot; &quot;without,&quot; or &quot;excluding.&quot; Negative concepts require special handling since vector subtraction can produce counterintuitive results.</p>\n</li>\n<li><p><strong>Relationship Analysis</strong>: Determine how different aspects relate—whether they should be combined additively, whether one constrains another, or whether they represent alternative acceptable concepts.</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Aspect Type</th>\n<th>Vector Treatment</th>\n<th>Search Strategy</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Primary Concepts</strong></td>\n<td>Positive embedding</td>\n<td>Direct similarity search</td>\n<td>&quot;machine learning&quot;</td>\n</tr>\n<tr>\n<td><strong>Secondary Concepts</strong></td>\n<td>Weighted positive embedding</td>\n<td>Boost matching results</td>\n<td>&quot;neural networks&quot;</td>\n</tr>\n<tr>\n<td><strong>Negative Concepts</strong></td>\n<td>Exclusion filter</td>\n<td>Post-retrieval filtering</td>\n<td>&quot;not computer vision&quot;</td>\n</tr>\n<tr>\n<td><strong>Temporal Constraints</strong></td>\n<td>Metadata filter</td>\n<td>Pre-retrieval filtering</td>\n<td>&quot;after 2020&quot;</td>\n</tr>\n<tr>\n<td><strong>Format Constraints</strong></td>\n<td>Document type filter</td>\n<td>Pre-retrieval filtering</td>\n<td>&quot;research papers&quot;</td>\n</tr>\n<tr>\n<td><strong>Source Constraints</strong></td>\n<td>Metadata filter</td>\n<td>Pre-retrieval filtering</td>\n<td>&quot;from arxiv.org&quot;</td>\n</tr>\n</tbody></table>\n<p><strong>Vector Arithmetic Strategies</strong></p>\n<p>When multiple semantic concepts can be meaningfully combined through vector operations, the system applies carefully designed arithmetic strategies that preserve semantic meaning while combining multiple information aspects.</p>\n<p><strong>Positive Concept Combination</strong></p>\n<p>Multiple positive concepts are combined using weighted vector addition, where weights reflect the relative importance of each concept within the overall query:</p>\n<ol>\n<li><p><strong>Equal Weight Addition</strong>: When concepts have similar importance, vectors are added with equal weights. This works well for queries like &quot;machine learning and artificial intelligence&quot; where both concepts are equally relevant.</p>\n</li>\n<li><p><strong>Importance-Weighted Addition</strong>: When one concept is more central than others, primary concepts receive higher weights. For &quot;deep learning optimization techniques,&quot; the deep learning vector might receive weight 0.6 while optimization receives 0.4.</p>\n</li>\n<li><p><strong>Hierarchical Composition</strong>: When concepts have hierarchical relationships, the broader concept provides the foundation while specific concepts add refinement. &quot;Computer science education methods&quot; combines a broad CS education base with specific methods refinement.</p>\n</li>\n</ol>\n<p><strong>Negative Term Handling</strong></p>\n<p>Negative terms present unique challenges in vector-based search because simple vector subtraction often produces semantically meaningless results or even reverses query meaning entirely.</p>\n<p>⚠️ <strong>Pitfall: Naive Vector Subtraction</strong></p>\n<p>A common mistake is directly subtracting negative concept embeddings from positive ones. For example, computing <code>embedding(&quot;animals&quot;) - embedding(&quot;dogs&quot;)</code> doesn&#39;t produce a meaningful &quot;animals except dogs&quot; vector—it often results in a vector that points toward concepts completely unrelated to animals.</p>\n<p><strong>Fix</strong>: Use negative terms for post-retrieval filtering rather than vector arithmetic. Retrieve candidates using positive concepts, then apply negative concepts as exclusion filters on the candidate set.</p>\n<p><strong>Negative Term Processing Pipeline</strong></p>\n<p>The system handles negative terms through a multi-stage approach that avoids the pitfalls of vector subtraction:</p>\n<ol>\n<li><p><strong>Negative Term Identification</strong>: Parse queries to identify negative indicators and extract the concepts they negate. Handle both explicit negation (&quot;not dogs&quot;) and implicit negation (&quot;cats except Persian breeds&quot;).</p>\n</li>\n<li><p><strong>Positive Vector Generation</strong>: Generate search vectors using only positive concepts, ignoring negative terms during the initial embedding phase.</p>\n</li>\n<li><p><strong>Negative Concept Modeling</strong>: Create separate embeddings for negative concepts that will be used for similarity-based exclusion during result filtering.</p>\n</li>\n<li><p><strong>Exclusion Threshold Calibration</strong>: Determine appropriate similarity thresholds for excluding results that match negative concepts. This typically requires lower thresholds than positive matching to avoid over-aggressive filtering.</p>\n</li>\n</ol>\n<p><strong>Multi-Vector Search Execution</strong></p>\n<p>During search execution, multi-vector queries follow a carefully orchestrated process that maximizes result quality while maintaining reasonable performance:</p>\n<ol>\n<li><p><strong>Primary Vector Retrieval</strong>: Execute the main search using the primary positive concept embedding to retrieve an initial candidate set. This set should be larger than the final result count to allow for effective filtering.</p>\n</li>\n<li><p><strong>Secondary Vector Scoring</strong>: For each candidate, compute similarity scores against secondary positive concept embeddings. These scores are combined with primary scores using learned or configured weights.</p>\n</li>\n<li><p><strong>Negative Filtering</strong>: Apply negative concept filters by computing similarity between candidates and negative concept embeddings. Remove candidates that exceed negative similarity thresholds.</p>\n</li>\n<li><p><strong>Constraint Application</strong>: Apply non-semantic constraints like temporal, format, or source filters to the remaining candidate set.</p>\n</li>\n<li><p><strong>Score Composition</strong>: Combine similarity scores from multiple positive vectors using the query&#39;s composition strategy (additive, weighted average, maximum, etc.).</p>\n</li>\n</ol>\n<p>| Multi-Vector Query Component | Data Structure | Purpose |\n|---|---|---|---|\n| <code>positive_concepts</code> | <code>List[Tuple[str, float, np.ndarray]]</code> | (concept, weight, embedding) for positive terms |\n| <code>negative_concepts</code> | <code>List[Tuple[str, float, np.ndarray]]</code> | (concept, threshold, embedding) for exclusion |\n| <code>metadata_filters</code> | <code>Dict[str, Any]</code> | Non-semantic constraints (date, type, source) |\n| <code>composition_strategy</code> | <code>str</code> | How to combine multiple positive vectors |\n| <code>retrieval_size</code> | <code>int</code> | Initial candidate set size before filtering |</p>\n<h3 id=\"query-embedding-cache-caching-frequent-query-embeddings-for-performance\">Query Embedding Cache: Caching Frequent Query Embeddings for Performance</h3>\n<p>Query embedding generation represents one of the most computationally expensive operations in semantic search. Converting text to high-dimensional vectors requires forward passes through transformer neural networks, which can add 50-200 milliseconds per query depending on model size and hardware. For production search systems serving thousands of queries per second, this latency is unacceptable without aggressive caching strategies.</p>\n<p><strong>Cache Architecture and Design</strong></p>\n<p>The query embedding cache sits between query processing and the embedding generation pipeline, intercepting frequent queries and serving pre-computed embeddings instantly. The cache design must balance hit rate optimization with memory efficiency while handling the complexities of multi-vector queries and query variations.</p>\n<p><strong>Architecture Decision: Multi-Level Cache Hierarchy</strong></p>\n<blockquote>\n<p><strong>Decision: Implement Three-Tier Query Cache Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Query embedding generation is expensive (50-200ms) but many queries repeat or have similar patterns that could benefit from caching at different granularities</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Simple query string cache with exact matching</li>\n<li>Normalized query cache with text preprocessing</li>\n<li>Multi-level cache with exact, normalized, and component-level caching</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement three-tier hierarchy: exact string cache → normalized query cache → query component cache</li>\n<li><strong>Rationale</strong>: Exact matching handles perfect repeats (highest hit rate, lowest complexity). Normalized cache handles variation in formatting/spacing. Component cache enables reuse of individual concepts across different queries.</li>\n<li><strong>Consequences</strong>: Higher implementation complexity but dramatically improved cache efficiency, especially for complex multi-vector queries with reusable components</li>\n</ul>\n</blockquote>\n<p><strong>Cache Level Architecture</strong></p>\n<table>\n<thead>\n<tr>\n<th>Cache Level</th>\n<th>Key Type</th>\n<th>Value Type</th>\n<th>Hit Rate</th>\n<th>Latency Reduction</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Exact String Cache</strong></td>\n<td>Raw query string</td>\n<td>Complete embedding result</td>\n<td>High for popular queries</td>\n<td>100% (0ms lookup)</td>\n</tr>\n<tr>\n<td><strong>Normalized Cache</strong></td>\n<td>Cleaned/normalized query</td>\n<td>Complete embedding result</td>\n<td>Medium</td>\n<td>95% (5ms normalization)</td>\n</tr>\n<tr>\n<td><strong>Component Cache</strong></td>\n<td>Individual concepts</td>\n<td>Single concept embedding</td>\n<td>High for concept reuse</td>\n<td>70% (composition required)</td>\n</tr>\n</tbody></table>\n<p><strong>Exact String Cache Implementation</strong></p>\n<p>The first cache tier maintains a direct mapping from raw query strings to complete embedding results. This handles the most common case where users repeat identical searches or where popular queries appear frequently across different users.</p>\n<p><strong>Cache Key Generation and Normalization</strong></p>\n<p>For the normalized cache tier, the system must carefully balance cache hit rate with semantic equivalence:</p>\n<ol>\n<li><p><strong>Whitespace Normalization</strong>: Remove extra spaces, normalize tabs and newlines to spaces, trim leading/trailing whitespace. This catches formatting variations without changing semantic meaning.</p>\n</li>\n<li><p><strong>Case Normalization</strong>: Convert to lowercase unless the query contains proper nouns or technical terms where case carries meaning (like &quot;SQL&quot; vs &quot;sql&quot; or &quot;US&quot; vs &quot;us&quot;).</p>\n</li>\n<li><p><strong>Punctuation Standardization</strong>: Normalize punctuation while preserving meaning-bearing punctuation like quotation marks for exact phrases or hyphens in technical terms.</p>\n</li>\n<li><p><strong>Stop Word Handling</strong>: Decide whether to normalize or preserve stop words based on their semantic contribution to the specific query context.</p>\n</li>\n</ol>\n<p><strong>Component-Level Caching</strong></p>\n<p>The most sophisticated cache tier stores embeddings for individual query components, enabling reuse across different queries that share common concepts:</p>\n<ol>\n<li><p><strong>Component Identification</strong>: Extract cacheable components from queries, including individual concepts, entity mentions, and common phrase patterns that appear across multiple queries.</p>\n</li>\n<li><p><strong>Component Embedding Storage</strong>: Maintain separate embeddings for each component along with metadata about embedding model, generation timestamp, and usage statistics.</p>\n</li>\n<li><p><strong>Component Composition</strong>: When a cache miss occurs at higher levels, attempt to construct the full query embedding by combining cached components with only the novel portions requiring fresh embedding generation.</p>\n</li>\n<li><p><strong>Component Lifecycle Management</strong>: Track component usage patterns and age out rarely-used components while prioritizing retention of frequently-reused concepts.</p>\n</li>\n</ol>\n<p><strong>Cache Invalidation and Consistency</strong></p>\n<p>Query embedding caches face unique challenges around invalidation because the underlying embedding models may change, affecting the validity of cached vectors:</p>\n<p>⚠️ <strong>Pitfall: Stale Embeddings After Model Updates</strong></p>\n<p>A critical error occurs when embedding models are updated or retrained but cached embeddings from the previous model remain in use. This creates inconsistencies where some queries use new model embeddings while cached queries use old embeddings, leading to incomparable similarity scores and poor result quality.</p>\n<p><strong>Fix</strong>: Implement model version tracking in cache keys and invalidate all cached embeddings when the underlying embedding model changes. Include model fingerprints or version hashes in cache metadata to detect model mismatches.</p>\n<p><strong>Cache Invalidation Strategies</strong></p>\n<table>\n<thead>\n<tr>\n<th>Invalidation Trigger</th>\n<th>Scope</th>\n<th>Strategy</th>\n<th>Recovery Time</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Embedding Model Update</strong></td>\n<td>Full cache clear</td>\n<td>Immediate invalidation</td>\n<td>24-48 hours for rebuild</td>\n</tr>\n<tr>\n<td><strong>Query Processing Logic Change</strong></td>\n<td>Affected query patterns</td>\n<td>Selective invalidation</td>\n<td>2-4 hours for rebuild</td>\n</tr>\n<tr>\n<td><strong>Memory Pressure</strong></td>\n<td>Least recently used entries</td>\n<td>LRU eviction</td>\n<td>Immediate (regenerate on demand)</td>\n</tr>\n<tr>\n<td><strong>Time-Based Expiration</strong></td>\n<td>Entries older than threshold</td>\n<td>TTL expiration</td>\n<td>Continuous background refresh</td>\n</tr>\n</tbody></table>\n<p><strong>Cache Performance Optimization</strong></p>\n<p>The cache implementation must be optimized for high-throughput, low-latency access patterns typical of production search systems:</p>\n<ol>\n<li><p><strong>Memory Layout Optimization</strong>: Store embeddings in contiguous memory layouts that enable efficient similarity computations without additional copying or transformation overhead.</p>\n</li>\n<li><p><strong>Concurrent Access Patterns</strong>: Support high levels of concurrent reads while minimizing lock contention during cache updates. Use read-write locks or lock-free data structures where appropriate.</p>\n</li>\n<li><p><strong>Pre-warming Strategies</strong>: Identify and pre-compute embeddings for predictably popular queries based on historical query patterns, seasonal trends, or trending topics.</p>\n</li>\n<li><p><strong>Cache Size Management</strong>: Balance cache size against available memory, using techniques like probabilistic data structures to estimate optimal cache sizes and track cache efficiency metrics.</p>\n</li>\n</ol>\n<p><strong>Cache Monitoring and Analytics</strong></p>\n<p>Effective cache management requires comprehensive monitoring of cache performance and query patterns:</p>\n<table>\n<thead>\n<tr>\n<th>Metric</th>\n<th>Purpose</th>\n<th>Target Range</th>\n<th>Alert Threshold</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Cache Hit Rate</strong></td>\n<td>Overall cache effectiveness</td>\n<td>60-80%</td>\n<td>Below 50%</td>\n</tr>\n<tr>\n<td><strong>Average Lookup Latency</strong></td>\n<td>Cache performance</td>\n<td>&lt;5ms</td>\n<td>&gt;10ms</td>\n</tr>\n<tr>\n<td><strong>Memory Utilization</strong></td>\n<td>Resource efficiency</td>\n<td>70-90%</td>\n<td>&gt;95%</td>\n</tr>\n<tr>\n<td><strong>Invalidation Rate</strong></td>\n<td>Cache stability</td>\n<td>&lt;5% daily</td>\n<td>&gt;20% daily</td>\n</tr>\n<tr>\n<td><strong>Component Reuse Rate</strong></td>\n<td>Component cache value</td>\n<td>40-60%</td>\n<td>&lt;30%</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Performance Insight:</strong> Query embedding caching typically provides 10-50x latency reduction for cache hits, transforming 100ms embedding generation into 2-10ms cache lookups. The investment in sophisticated cache architecture pays dividends through dramatically improved user experience and reduced computational costs.</p>\n</blockquote>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Query Expansion Explosion</strong></p>\n<p>Overly aggressive query expansion can transform focused queries into broad, unfocused searches. This often happens when expansion algorithms recursively apply themselves or use overly permissive similarity thresholds. A query for &quot;python programming&quot; might expand to include &quot;snake,&quot; &quot;reptile,&quot; and eventually &quot;animal,&quot; completely losing the computational context.</p>\n<p><strong>Detection</strong>: Monitor average expansion ratios and result relevance scores. Queries with &gt;5 expanded terms per original term or declining click-through rates indicate over-expansion.</p>\n<p><strong>Fix</strong>: Implement expansion budgets (max 3 expanded terms per original), semantic anchoring (all expansions must maintain &gt;0.6 similarity to original terms), and domain relevance filtering.</p>\n<p>⚠️ <strong>Pitfall: Entity Over-Normalization</strong></p>\n<p>Aggressive text normalization can destroy important semantic distinctions in entity names and technical terms. Converting &quot;SQL&quot; to &quot;sql&quot; or normalizing &quot;COVID-19&quot; to &quot;covid&quot; loses critical specificity that affects search precision.</p>\n<p><strong>Detection</strong>: Track queries with low result relevance despite high query frequency. Monitor for complaints about missing results for technical or proper noun queries.</p>\n<p><strong>Fix</strong>: Implement context-aware normalization that preserves case for known entities, technical terms, and acronyms. Maintain entity dictionaries for domain-specific preservation rules.</p>\n<p>⚠️ <strong>Pitfall: Cache Inconsistency Across Model Updates</strong></p>\n<p>When embedding models are updated but cached query embeddings remain from the previous model version, similarity scores become incomparable and result quality degrades significantly. Some queries use fresh embeddings while others use stale cached versions.</p>\n<p><strong>Detection</strong>: Monitor for sudden changes in result quality or user satisfaction scores after system deployments. Check for embedding dimension mismatches or unusual similarity score distributions.</p>\n<p><strong>Fix</strong>: Include model version hashes in cache keys, implement automatic cache invalidation on model updates, and maintain cache warming procedures for popular queries after invalidation.</p>\n<p>⚠️ <strong>Pitfall: Multi-Vector Weight Imbalance</strong></p>\n<p>Poorly calibrated weights in multi-vector queries can cause one aspect to dominate others, effectively ignoring important query constraints. A query combining &quot;machine learning&quot; (weight 0.9) with &quot;recent papers&quot; (weight 0.1) will retrieve any ML content regardless of recency.</p>\n<p><strong>Detection</strong>: Analyze result sets for queries with multiple aspects to ensure all aspects are represented. Monitor for user reformulations that repeat constrained aspects.</p>\n<p><strong>Fix</strong>: Implement adaptive weight learning from user feedback, default to balanced weights (e.g., 0.6/0.4 for two aspects), and provide explicit user controls for aspect importance in advanced search interfaces.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The Query Processing Component bridges natural language understanding with vector search, requiring careful integration of text processing, machine learning models, and caching systems. This component will likely be the most linguistically sophisticated part of your semantic search engine.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Text Processing</strong></td>\n<td>NLTK + spaCy for basic NLP</td>\n<td>Transformers library with domain-specific models</td>\n</tr>\n<tr>\n<td><strong>Entity Recognition</strong></td>\n<td>spaCy pre-trained models</td>\n<td>Custom NER models fine-tuned on your domain</td>\n</tr>\n<tr>\n<td><strong>Query Expansion</strong></td>\n<td>WordNet + manual synonym lists</td>\n<td>Word2Vec/FastText similarity + corpus co-occurrence</td>\n</tr>\n<tr>\n<td><strong>Intent Classification</strong></td>\n<td>Rule-based pattern matching</td>\n<td>Fine-tuned BERT classifier on query-intent pairs</td>\n</tr>\n<tr>\n<td><strong>Embedding Cache</strong></td>\n<td>Python dict with LRU eviction</td>\n<td>Redis with cluster support and TTL management</td>\n</tr>\n<tr>\n<td><strong>Vector Operations</strong></td>\n<td>NumPy for basic arithmetic</td>\n<td>Faiss for optimized vector operations</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>src/query_processing/\n├── __init__.py\n├── query_processor.py          ← Main QueryProcessor class\n├── text_processing/\n│   ├── __init__.py\n│   ├── normalizer.py          ← Text cleaning and normalization\n│   ├── entity_extractor.py    ← Named entity recognition\n│   └── intent_classifier.py   ← Query intent detection\n├── expansion/\n│   ├── __init__.py\n│   ├── synonym_expander.py     ← Synonym-based expansion\n│   ├── semantic_expander.py    ← Embedding-based expansion\n│   └── expansion_filter.py     ← Expansion quality filtering\n├── multi_vector/\n│   ├── __init__.py\n│   ├── query_decomposer.py     ← Multi-aspect query analysis\n│   ├── vector_composer.py      ← Vector arithmetic and composition\n│   └── negative_handler.py     ← Negative term processing\n├── caching/\n│   ├── __init__.py\n│   ├── embedding_cache.py      ← Multi-tier query cache\n│   └── cache_manager.py        ← Cache lifecycle and invalidation\n└── tests/\n    ├── test_query_processor.py\n    ├── test_expansion.py\n    └── test_caching.py</code></pre></div>\n\n<p><strong>Infrastructure Starter Code</strong></p>\n<p>Here&#39;s a complete text processing foundation that handles the linguistic complexity so you can focus on the core query processing logic:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/query_processing/text_processing/normalizer.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> unicodedata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Set</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TextNormalizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles text cleaning and normalization for query processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, preserve_entities: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.preserve_entities </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> preserve_entities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Pre-compile regex patterns for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.whitespace_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\s</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.entity_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\b[A-Z][A-Z0-9]</span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\">\\b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Acronyms like SQL, COVID-19</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.technical_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\b\\w</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">[-_.]\\w</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">\\b</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Technical terms like React.js</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Common stop words that can be removed for normalization</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stop_words </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'the'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'a'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'an'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'and'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'or'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'but'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'in'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'on'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'at'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'to'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'for'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'of'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'with'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'by'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Entities that should preserve case</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.preserve_case_terms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'SQL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'API'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'HTTP'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'TCP'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'IP'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'URL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'HTML'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'CSS'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'JavaScript'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'Python'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Java'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'React'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Angular'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'Vue'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'AWS'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'GCP'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'AI'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'ML'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> normalize_query</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Normalize query text for caching and consistency.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query: Raw query string</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Normalized query string suitable for cache keys</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Unicode normalization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        normalized </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> unicodedata.normalize(</span><span style=\"color:#9ECBFF\">'NFKD'</span><span style=\"color:#E1E4E8\">, query)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Remove extra whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        normalized </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.whitespace_pattern.sub(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, normalized).strip()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Preserve important entities and technical terms</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.preserve_entities:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            preserved_terms </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._extract_preserve_terms(normalized)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            normalized_lower </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> normalized.lower()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Restore preserved terms to their original case</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> term </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> preserved_terms:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                normalized_lower </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> normalized_lower.replace(term.lower(), term)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> normalized_lower</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> normalized.lower()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _extract_preserve_terms</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract terms that should preserve their original case.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        terms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Find known entities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        words </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text.split()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> word </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> words:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> word </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.preserve_case_terms:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                terms.append(word)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Find acronyms and technical terms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        terms.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.entity_pattern.findall(text))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        terms.extend(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.technical_pattern.findall(text))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> terms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clean_text</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clean text for embedding generation (more aggressive than normalization).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Unicode normalization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cleaned </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> unicodedata.normalize(</span><span style=\"color:#9ECBFF\">'NFKD'</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Remove special characters but preserve hyphens and periods in technical terms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cleaned </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.sub(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">[</span><span style=\"color:#F97583\">^</span><span style=\"color:#79B8FF\">\\w\\s</span><span style=\"color:#85E89D;font-weight:bold\">\\-\\.</span><span style=\"color:#79B8FF\">]</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, cleaned)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Normalize whitespace</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cleaned </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.whitespace_pattern.sub(</span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">, cleaned).strip()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> cleaned</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># src/query_processing/expansion/synonym_expander.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple, Dict, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SynonymExpander</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Provides synonym-based query expansion using configurable dictionaries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, synonym_dict_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.synonyms: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.load_synonyms(synonym_dict_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> load_synonyms</span><span style=\"color:#E1E4E8\">(self, dict_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load synonym dictionary from JSON file.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> dict_path </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> Path(dict_path).exists():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(dict_path, </span><span style=\"color:#9ECBFF\">'r'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.synonyms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> json.load(f)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Fallback to basic synonyms for common terms</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.synonyms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'ml'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'machine learning'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'artificial intelligence'</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'ai'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'artificial intelligence'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'machine learning'</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'car'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'automobile'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'vehicle'</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'fix'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'repair'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'solve'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'resolve'</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'error'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'bug'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'issue'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'problem'</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'fast'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'quick'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'rapid'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'speedy'</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'big'</span><span style=\"color:#E1E4E8\">: [</span><span style=\"color:#9ECBFF\">'large'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'huge'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'massive'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> expand_term</span><span style=\"color:#E1E4E8\">(self, term: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, max_expansions: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Get synonyms for a term with confidence scores.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            term: Original term to expand</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            max_expansions: Maximum number of synonyms to return</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of (synonym, confidence_score) tuples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        term_lower </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> term.lower()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> term_lower </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.synonyms:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Simple confidence scoring based on synonym quality</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        expansions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i, synonym </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.synonyms[term_lower][:max_expansions]):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            confidence </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">0.3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\"> (i </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 0.2</span><span style=\"color:#E1E4E8\">))  </span><span style=\"color:#6A737D\"># Decreasing confidence</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            expansions.append((synonym, confidence))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> expansions</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># src/query_processing/caching/embedding_cache.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Any, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> OrderedDict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EmbeddingCache</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Multi-tier cache for query embeddings with LRU eviction.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">, ttl_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3600</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.ttl_seconds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ttl_seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Three-tier cache structure</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.exact_cache: OrderedDict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Tuple[np.ndarray, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> OrderedDict()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.normalized_cache: OrderedDict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Tuple[np.ndarray, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> OrderedDict()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component_cache: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Tuple[np.ndarray, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Thread safety</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.RLock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Cache statistics</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'hits'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'misses'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'exact_hits'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'normalized_hits'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'component_hits'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, normalized_query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Optional[np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Retrieve cached embedding for query.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query: Original query string</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            normalized_query: Normalized version for fallback lookup</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Cached embedding array or None if not found</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Try exact match first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> query </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.exact_cache:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                embedding, timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.exact_cache[query]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> current_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> timestamp </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.ttl_seconds:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Move to end (most recently used)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.exact_cache.move_to_end(query)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'hits'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'exact_hits'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> embedding.copy()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Expired, remove from cache</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    del</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.exact_cache[query]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Try normalized match</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> normalized_query </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> normalized_query </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.normalized_cache:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                embedding, timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.normalized_cache[normalized_query]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> current_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> timestamp </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.ttl_seconds:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.normalized_cache.move_to_end(normalized_query)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'hits'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'normalized_hits'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> embedding.copy()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    del</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.normalized_cache[normalized_query]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Cache miss</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'misses'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> put</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, embedding: np.ndarray, normalized_query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Cache embedding for query.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Store in exact cache</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.exact_cache[query] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (embedding.copy(), current_time)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.exact_cache.move_to_end(query)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Store in normalized cache if provided</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> normalized_query:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.normalized_cache[normalized_query] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (embedding.copy(), current_time)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.normalized_cache.move_to_end(normalized_query)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Enforce size limits</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._enforce_size_limits()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _enforce_size_limits</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Remove oldest entries if cache exceeds size limits.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Exact cache eviction</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.exact_cache) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_size:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.exact_cache.popitem(</span><span style=\"color:#FFAB70\">last</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Remove oldest</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Normalized cache eviction</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.normalized_cache) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_size:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.normalized_cache.popitem(</span><span style=\"color:#FFAB70\">last</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> invalidate_all</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clear all cached embeddings (e.g., after model update).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.exact_cache.clear()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.normalized_cache.clear()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.component_cache.clear()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_stats</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return cache performance statistics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            total_requests </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'hits'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'misses'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hit_rate </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.stats[</span><span style=\"color:#9ECBFF\">'hits'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> total_requests </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> total_requests </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'hit_rate'</span><span style=\"color:#E1E4E8\">: hit_rate,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'total_requests'</span><span style=\"color:#E1E4E8\">: total_requests,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                'cache_sizes'</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'exact'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.exact_cache),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'normalized'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.normalized_cache),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    'component'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.component_cache)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                },</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                **</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.stats</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton</strong></p>\n<p>Here are the main interfaces you&#39;ll implement, with detailed TODO comments mapping to the design concepts:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/query_processing/query_processor.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProcessedQuery</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Result of query processing with all enhancements.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    original_query: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    normalized_query: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    primary_embedding: np.ndarray</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expanded_terms: List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]  </span><span style=\"color:#6A737D\"># (term, weight)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    entities: List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]  </span><span style=\"color:#6A737D\"># (entity, type)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    intent: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    negative_terms: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    multi_vector_components: Optional[List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, np.ndarray, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]]  </span><span style=\"color:#6A737D\"># (concept, embedding, weight)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Main query processing orchestrator combining all enhancement strategies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, embedding_model, cache: EmbeddingCache </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.embedding_model </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> embedding_model</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cache </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> EmbeddingCache()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize text normalizer, entity extractor, expansion modules</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Load domain-specific configurations and models</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ProcessedQuery:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Main query processing pipeline that transforms raw query into enhanced representation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_text: Original user query</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            context: Optional context (user history, filters, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            ProcessedQuery with all enhancements applied</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Text normalization and cleaning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply unicode normalization and whitespace cleanup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Preserve important entities and technical terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Generate normalized version for caching</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check embedding cache for existing results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Try exact query match first, then normalized match</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Return cached result if found and not expired</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Update cache statistics for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Entity extraction and recognition</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Run NER models to identify persons, organizations, locations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Detect technical terms and domain-specific entities</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Mark entities that should not be expanded</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Intent classification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Analyze query structure for intent signals (question words, comparatives)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply trained intent classifier if available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Use entity types and patterns for intent inference</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Query expansion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Generate synonyms and related terms for non-entity terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply domain-specific expansion strategies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Filter expansions to prevent drift from original intent</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Weight expanded terms based on confidence and similarity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Multi-vector analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Identify distinct concepts that warrant separate embeddings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Detect negative terms and constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Plan vector composition strategy (additive, weighted, separate)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Embedding generation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Generate primary embedding for main query concepts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Create separate embeddings for multi-vector components</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply any necessary vector normalization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Cache storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Store generated embeddings in appropriate cache tiers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Include metadata for invalidation and debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Result packaging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Combine all processing results into ProcessedQuery object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Include debugging metadata and processing statistics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> expand_query_terms</span><span style=\"color:#E1E4E8\">(self, terms: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], entities: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Apply query expansion strategies to increase recall.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            terms: Original query terms to expand</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            entities: Recognized entities that should not be expanded</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of (expanded_term, confidence_weight) tuples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Filter out entities and stop words from expansion candidates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Skip proper nouns and technical terms that have specific meanings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Consider keeping stop words in some contexts (e.g., \"to be or not to be\")</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate synonym expansions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Use WordNet or domain dictionary for basic synonyms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply semantic similarity from embedding models</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Consider corpus-specific co-occurrence patterns</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply expansion filtering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Set minimum similarity thresholds to prevent drift</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Limit number of expansions per term to prevent explosion</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Check domain relevance for specialized corpora</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Weight assignment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Higher weights for more confident expansions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Consider term importance (IDF) in weight calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Balance expansion influence vs original term importance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_multi_vector_query</span><span style=\"color:#E1E4E8\">(self, processed_query: ProcessedQuery) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, np.ndarray, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Decompose complex queries into multiple vector representations.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            processed_query: Query after initial processing</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            List of (concept_description, embedding_vector, weight) tuples</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Concept boundary detection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Identify natural breakpoints using conjunctions and prepositions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Separate semantic concepts from structural constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Group related terms that should be embedded together</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Negative term handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Extract negative concepts introduced by \"not\", \"except\", \"without\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Plan exclusion strategy (post-retrieval filtering vs vector arithmetic)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Set appropriate similarity thresholds for exclusion</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Vector composition planning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Decide which concepts can be combined through arithmetic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Determine which require separate retrieval and intersection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Calculate relative weights based on concept importance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate component embeddings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Create separate embeddings for each identified concept</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply normalization if using cosine similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Store components in cache for potential reuse</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Convert query text to embedding vector using the configured model.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            query_text: Processed query text ready for embedding</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Dense vector embedding of the query</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Text preprocessing for embedding model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply any model-specific text cleaning</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Handle special tokens or formatting requirements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Ensure text length is within model limits</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate embedding using transformer model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Forward pass through sentence transformer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Handle batch processing if multiple components</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply any post-processing (normalization, dimensionality reduction)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Vector validation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Check embedding dimensions match expected size</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Verify no NaN or infinite values in output</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Apply L2 normalization if using cosine similarity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint</strong></p>\n<p>After implementing Milestone 2, verify your query processing works correctly:</p>\n<p><strong>Test Command:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> src/query_processing/tests/</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n\n<p><strong>Expected Behavior:</strong></p>\n<ol>\n<li><strong>Basic Query Processing</strong>: Simple queries like &quot;machine learning&quot; should be normalized, expanded with 2-3 related terms, and converted to 384-dimensional embeddings</li>\n<li><strong>Entity Preservation</strong>: Queries containing proper nouns like &quot;Barack Obama&quot; or technical terms like &quot;React.js&quot; should preserve these terms without expansion</li>\n<li><strong>Multi-Vector Queries</strong>: Complex queries like &quot;machine learning papers not about computer vision&quot; should decompose into positive concepts (ML, papers) and negative exclusions (computer vision)</li>\n<li><strong>Cache Performance</strong>: Repeated queries should show cache hits with &lt;5ms lookup latency vs &gt;50ms for fresh embedding generation</li>\n</ol>\n<p><strong>Manual Verification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test script to verify query processing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.query_processing.query_processor </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryProcessor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.embedding_index.document_encoder </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DocumentEncoder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Initialize processor</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DocumentEncoder()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueryProcessor(encoder.model)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test basic processing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> processor.process_query(</span><span style=\"color:#9ECBFF\">\"machine learning algorithms\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Original: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result.original_query</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Expanded terms: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result.expanded_terms</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Embedding shape: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">result.primary_embedding.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test multi-vector query</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">complex_result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> processor.process_query(</span><span style=\"color:#9ECBFF\">\"python programming not web development\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Multi-vector components: </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(complex_result.multi_vector_components)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Negative terms: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">complex_result.negative_terms</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Signs Something Is Wrong:</strong></p>\n<ul>\n<li><strong>Embedding dimension mismatches</strong>: Check model configuration and ensure consistent dimensions across components</li>\n<li><strong>Over-expansion</strong>: If &gt;10 terms are added per original term, review expansion filtering thresholds  </li>\n<li><strong>Cache misses for identical queries</strong>: Verify normalization and cache key generation</li>\n<li><strong>Poor entity recognition</strong>: Test with domain-specific entity lists and proper noun handling</li>\n</ul>\n<h2 id=\"ranking-and-relevance-component\">Ranking and Relevance Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 3: Ranking &amp; Relevance</p>\n</blockquote>\n<p>The <strong>Ranking and Relevance Component</strong> represents the sophisticated orchestration layer that transforms raw similarity scores into meaningful, personalized search results. While the embedding index provides semantic understanding and query processing extracts user intent, this component must balance multiple competing signals—semantic similarity, keyword relevance, user preferences, content freshness, and historical behavior—to deliver the most valuable results to each user.</p>\n<h3 id=\"multi-signal-ranking-mental-model-orchestra-conductor-analogy\">Multi-Signal Ranking Mental Model: Orchestra Conductor Analogy</h3>\n<p>Think of the ranking component as a <strong>symphony conductor</strong> leading a complex orchestra where each musician represents a different ranking signal. The semantic similarity scores are like the string section—they provide the fundamental melody and emotional resonance of the search. The keyword matching (BM25) scores act like the brass section—bold, direct, and unmistakable when they hit the right notes. Personalization signals are like the woodwinds—subtle but essential for adding individual character and nuance to the performance.</p>\n<p>The conductor (ranking algorithm) must balance all these instruments to create a harmonious result. Sometimes the strings (semantic signals) should dominate when the user&#39;s query is conceptual or exploratory. Other times the brass (keyword matching) should take the lead when the user needs exact technical terms or proper nouns. The woodwinds (personalization) should weave through the performance, ensuring each user hears a slightly different interpretation that resonates with their specific needs and context.</p>\n<p>Just as a conductor must make real-time decisions about tempo, dynamics, and emphasis based on the audience and venue, the ranking component must dynamically adjust signal weights based on query type, user context, and result quality. A novice conductor might let one section overpower the others or fail to bring in instruments at the right moment. Similarly, a poorly tuned ranking system might over-rely on semantic similarity (creating results that are conceptually related but not actionable) or keyword matching (missing the user&#39;s deeper intent).</p>\n<p>The true artistry lies in knowing when to emphasize which signals. For a query like &quot;machine learning algorithms,&quot; the conductor might emphasize the brass section (keyword matching) to ensure technical precision, while still allowing the strings (semantic similarity) to include related concepts like &quot;neural networks&quot; and &quot;deep learning.&quot; For a more exploratory query like &quot;how to improve team productivity,&quot; the strings should take the lead, with personalization woodwinds adding context based on the user&#39;s role and industry.</p>\n<h3 id=\"multi-stage-ranking-pipeline-fast-retrieval-followed-by-precise-cross-encoder-reranking\">Multi-Stage Ranking Pipeline: Fast Retrieval Followed by Precise Cross-Encoder Reranking</h3>\n<p>The multi-stage ranking pipeline addresses a fundamental tension in search systems: the need for both <strong>speed and precision</strong>. Users expect sub-second response times, but the most accurate ranking methods (particularly cross-encoder transformer models) are too computationally expensive to apply to millions of candidate documents. The solution is a graduated approach that applies increasingly sophisticated but expensive ranking methods to progressively smaller candidate sets.</p>\n<blockquote>\n<p><strong>Decision: Multi-Stage Ranking Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Cross-encoder models achieve state-of-the-art ranking accuracy but require 10-100x more computation than bi-encoder similarity scores. Applying cross-encoders to all indexed documents would result in multi-second query latencies.</li>\n<li><strong>Options Considered</strong>: Single-stage ranking with fast methods only, single-stage with slow methods only, multi-stage pipeline with fast retrieval and precise reranking</li>\n<li><strong>Decision</strong>: Implement three-stage ranking pipeline: candidate retrieval, hybrid scoring, cross-encoder reranking</li>\n<li><strong>Rationale</strong>: This approach provides the best balance of speed and accuracy. Fast retrieval methods (vector similarity, BM25) can process millions of documents in milliseconds to identify promising candidates. Hybrid scoring refines the top few hundred candidates. Cross-encoder reranking provides maximum precision for the final top-K results that users actually see.</li>\n<li><strong>Consequences</strong>: Increased system complexity with multiple ranking components, but achieves both sub-second latency and high relevance quality. Requires careful tuning of stage transition thresholds.</li>\n</ul>\n</blockquote>\n<p>The <strong>first stage</strong> performs rapid candidate retrieval using the vector index and keyword index. This stage processes the entire document collection (potentially millions of documents) but uses computationally simple scoring methods. Vector similarity scores are computed via approximate nearest neighbor search, typically returning the top 1000-5000 most similar documents based on semantic embedding distance. Simultaneously, BM25 keyword scoring identifies documents containing query terms, typically retrieving another 1000-5000 candidates. The union of these candidate sets (after deduplication) advances to the second stage.</p>\n<table>\n<thead>\n<tr>\n<th>Ranking Stage</th>\n<th>Input Size</th>\n<th>Output Size</th>\n<th>Methods Used</th>\n<th>Latency Budget</th>\n<th>Accuracy Level</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Candidate Retrieval</td>\n<td>Millions</td>\n<td>5K-10K</td>\n<td>Vector ANN, BM25</td>\n<td>50-100ms</td>\n<td>Good</td>\n</tr>\n<tr>\n<td>Hybrid Scoring</td>\n<td>5K-10K</td>\n<td>100-500</td>\n<td>Combined signals</td>\n<td>50-100ms</td>\n<td>Better</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranking</td>\n<td>100-500</td>\n<td>10-50</td>\n<td>Transformer model</td>\n<td>100-200ms</td>\n<td>Best</td>\n</tr>\n</tbody></table>\n<p>The <strong>second stage</strong> applies hybrid scoring that combines multiple signals: semantic similarity scores from the vector index, BM25 lexical scores from the keyword index, personalization signals based on user context, and freshness scores based on document age. Each signal is normalized to a common scale (typically 0-1) and combined using learned or manually tuned weights. This stage processes the reduced candidate set (5K-10K documents) and selects the top 100-500 documents for final reranking. The hybrid scoring provides a more nuanced relevance assessment than any single signal alone.</p>\n<p>The <strong>third stage</strong> performs precise reranking using a cross-encoder transformer model. Unlike bi-encoder models that encode queries and documents separately, cross-encoders process query-document pairs jointly, allowing for more sophisticated reasoning about relevance. The cross-encoder receives both the original query text and each candidate document&#39;s content, producing a refined relevance score. Since cross-encoders are computationally expensive (requiring a full transformer forward pass for each query-document pair), they are applied only to the top candidates from the hybrid scoring stage.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Stage 1: Candidate Retrieval\nQuery: &quot;machine learning model deployment&quot;\nVector Search → 3,000 semantic candidates\nBM25 Search → 2,500 keyword candidates\nCombined Pool → 4,800 unique candidates (after deduplication)\n\nStage 2: Hybrid Scoring\nInput: 4,800 candidates\nSemantic Score (0.4 weight) + BM25 Score (0.3 weight) + \nPersonalization (0.2 weight) + Freshness (0.1 weight) = Final Score\nTop 200 candidates selected for reranking\n\nStage 3: Cross-Encoder Reranking\nInput: 200 candidates\nCross-Encoder processes each (query, document) pair\nFinal ranked list of 20 results returned to user\nTotal Latency: 75ms + 60ms + 150ms = 285ms</code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Stage Transition Thresholds</strong>\nA common mistake is using fixed candidate counts for stage transitions without considering query characteristics. Simple queries might only need 100 candidates for reranking, while complex queries might benefit from reranking 500 candidates. Monitor per-query result quality and adjust thresholds dynamically based on query type and semantic complexity.</p>\n<h3 id=\"hybrid-semantic-and-lexical-search-combining-bm25-keyword-scores-with-vector-similarity-scores\">Hybrid Semantic and Lexical Search: Combining BM25 Keyword Scores with Vector Similarity Scores</h3>\n<p>Hybrid search addresses the complementary strengths and weaknesses of semantic and lexical search methods. <strong>Semantic search</strong> excels at capturing conceptual similarity and handling vocabulary mismatch—when users and documents express the same ideas using different terminology. However, semantic search can sometimes miss exact matches for technical terms, proper nouns, or specific model numbers where precise lexical matching is crucial. <strong>Lexical search</strong> (particularly BM25) provides reliable exact matching and has well-understood behavior, but suffers from vocabulary mismatch and cannot capture conceptual relationships.</p>\n<p>The key insight is that these approaches are <strong>complementary rather than competing</strong>. Semantic search provides broad conceptual coverage and handles synonymy, while lexical search ensures precision for exact terms and technical specificity. The hybrid approach combines both score types to leverage their respective strengths while mitigating their individual weaknesses.</p>\n<blockquote>\n<p><strong>Decision: Hybrid Score Combination Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Pure semantic search sometimes misses exact technical matches; pure lexical search suffers from vocabulary mismatch. User queries vary in their semantic vs. lexical intent.</li>\n<li><strong>Options Considered</strong>: Query-adaptive weighting, fixed weighted combination, learning-to-rank with multiple features, separate semantic and lexical result lists</li>\n<li><strong>Decision</strong>: Implement fixed weighted combination with query-type detection for adaptive weighting</li>\n<li><strong>Rationale</strong>: Fixed weighting (0.6 semantic, 0.4 lexical) works well for most queries and is simple to tune. Query-type detection allows adaptation for technical queries (higher lexical weight) vs. exploratory queries (higher semantic weight). Learning-to-rank requires extensive training data we may not have initially.</li>\n<li><strong>Consequences</strong>: Enables both broad conceptual matching and precise technical matching. Requires careful weight tuning and ongoing evaluation of different query types.</li>\n</ul>\n</blockquote>\n<p>The <strong>BM25 scoring component</strong> computes lexical relevance using the standard BM25 algorithm, which considers term frequency within documents, inverse document frequency across the collection, and document length normalization. BM25 scores are particularly effective for queries containing specific technical terms, proper nouns, or rare keywords that should match exactly. The algorithm naturally handles cases where query terms appear multiple times in a document (increasing relevance) while downweighting overly long documents.</p>\n<table>\n<thead>\n<tr>\n<th>BM25 Parameter</th>\n<th>Value</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>k1</td>\n<td>1.6</td>\n<td>Controls term frequency saturation; higher values reward repeated terms more</td>\n</tr>\n<tr>\n<td>b</td>\n<td>0.75</td>\n<td>Document length normalization; balances absolute vs. relative term frequency</td>\n</tr>\n<tr>\n<td>k3</td>\n<td>1000</td>\n<td>Query term frequency normalization; high value since queries are typically short</td>\n</tr>\n</tbody></table>\n<p>The <strong>semantic similarity component</strong> computes vector cosine similarity between the query embedding and each candidate document embedding. Cosine similarity measures the angle between vectors, providing a normalized score between -1 and 1 that is then mapped to the 0-1 range. This score captures conceptual relatedness regardless of exact keyword matches, enabling the system to find relevant documents even when they use different terminology than the query.</p>\n<p><strong>Score normalization</strong> is critical for effective combination. BM25 scores have no fixed upper bound and vary significantly based on term rarity and document characteristics. Semantic similarity scores from cosine similarity are naturally bounded between 0 and 1. To combine these scores meaningfully, BM25 scores must be normalized to a comparable range. Common approaches include min-max normalization within the candidate set or sigmoid transformation to map unbounded scores to the 0-1 range.</p>\n<p>The <strong>hybrid combination formula</strong> applies learned or tuned weights to the normalized scores:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>hybrid_score = w_semantic * semantic_score + w_lexical * bm25_normalized + w_personalization * personalization_score + w_freshness * freshness_score\n\nWhere:\nw_semantic = 0.4-0.7 (depending on query type)\nw_lexical = 0.2-0.4 (higher for technical queries)\nw_personalization = 0.1-0.3 (based on available user context)\nw_freshness = 0.1-0.2 (domain-dependent)</code></pre></div>\n\n<p><strong>Query-adaptive weighting</strong> improves hybrid search by adjusting weights based on detected query characteristics. Technical queries containing programming languages, version numbers, or domain-specific terminology receive higher lexical weights to ensure precise matching. Exploratory or conceptual queries receive higher semantic weights to capture broader relevant concepts. Named entity recognition and technical term detection help classify queries automatically.</p>\n<table>\n<thead>\n<tr>\n<th>Query Type</th>\n<th>Example</th>\n<th>Semantic Weight</th>\n<th>Lexical Weight</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Technical</td>\n<td>&quot;Python 3.9 asyncio tutorial&quot;</td>\n<td>0.4</td>\n<td>0.6</td>\n<td>Exact version and API names crucial</td>\n</tr>\n<tr>\n<td>Conceptual</td>\n<td>&quot;improve team collaboration&quot;</td>\n<td>0.7</td>\n<td>0.3</td>\n<td>Many valid approaches and terminologies</td>\n</tr>\n<tr>\n<td>Mixed</td>\n<td>&quot;React hooks best practices&quot;</td>\n<td>0.5</td>\n<td>0.5</td>\n<td>Balance of technical terms and concepts</td>\n</tr>\n<tr>\n<td>Navigational</td>\n<td>&quot;OpenAI GPT-4 documentation&quot;</td>\n<td>0.2</td>\n<td>0.8</td>\n<td>Looking for specific resource</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Score Range Mismatch</strong>\nBM25 scores can vary dramatically between queries and document collections. A score of 15.0 might be high for one query but low for another. Always normalize BM25 scores within each query&#39;s candidate set before combining with semantic scores, or use percentile-based normalization to ensure consistent score ranges.</p>\n<h3 id=\"personalization-and-freshness-signals-user-preference-matching-and-time-based-relevance-decay\">Personalization and Freshness Signals: User Preference Matching and Time-Based Relevance Decay</h3>\n<p>Personalization and freshness signals add crucial context-aware dimensions to search ranking that move beyond the query-document relationship to consider the user and temporal context. <strong>Personalization signals</strong> help the system understand that the same query may have different ideal results for different users based on their role, experience level, historical interests, and current context. <strong>Freshness signals</strong> recognize that information value often decays over time, and users frequently prefer recent, up-to-date content over older material that may be outdated or superseded.</p>\n<p>The <strong>personalization scoring component</strong> leverages available user context to boost results that align with the user&#39;s inferred preferences and needs. User context might include explicit profile information (role, industry, experience level), historical search and click behavior, and implicit signals derived from previous interactions. The key challenge is making effective use of limited personalization data while avoiding filter bubbles that overly narrow the result diversity.</p>\n<table>\n<thead>\n<tr>\n<th>Personalization Signal</th>\n<th>Data Source</th>\n<th>Weight</th>\n<th>Computation Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Role/Industry Match</td>\n<td>User profile</td>\n<td>0.3</td>\n<td>Keyword matching on document tags</td>\n</tr>\n<tr>\n<td>Historical Topics</td>\n<td>Click history</td>\n<td>0.4</td>\n<td>Vector similarity to past clicked documents</td>\n</tr>\n<tr>\n<td>Expertise Level</td>\n<td>Inferred behavior</td>\n<td>0.2</td>\n<td>Document complexity scoring</td>\n</tr>\n<tr>\n<td>Current Context</td>\n<td>Session data</td>\n<td>0.1</td>\n<td>Similarity to recent queries</td>\n</tr>\n</tbody></table>\n<p><strong>Role-based personalization</strong> adjusts results based on the user&#39;s professional context. A query for &quot;API design&quot; might surface different results for a frontend developer (focusing on REST API consumption) versus a backend architect (emphasizing API design patterns and scalability). Role matching can be implemented through document metadata tagging and user profile information, with documents tagged for target audiences receiving personalization boosts when served to matching users.</p>\n<p><strong>Historical interest modeling</strong> uses the user&#39;s past click-through behavior to identify topic preferences and expertise areas. Documents similar to previously clicked content receive personalization boosts, implemented by computing vector similarity between candidate documents and embeddings of the user&#39;s click history. This approach requires maintaining user interaction history while respecting privacy constraints and avoiding over-fitting to recent behavior.</p>\n<p><strong>Experience level adaptation</strong> personalizes results based on the user&#39;s inferred technical expertise. Novice users might see introductory tutorials and explanations ranked higher, while expert users get advanced technical documentation and implementation details prioritized. Experience level can be inferred from query complexity, document types historically clicked, and explicit user profile information.</p>\n<p>The <strong>freshness scoring component</strong> implements time-based relevance decay to favor recent content when recency is important for the query and domain. Not all content benefits from freshness signals—evergreen educational content might remain highly relevant for years, while technology tutorials and news articles quickly become outdated. The freshness function should be domain-aware and query-adaptive.</p>\n<blockquote>\n<p><strong>Decision: Freshness Decay Function</strong></p>\n<ul>\n<li><strong>Context</strong>: Some content types (news, tutorials, documentation) lose relevance quickly, while others (fundamental concepts, research papers) remain valuable long-term. A single decay function doesn&#39;t fit all content types.</li>\n<li><strong>Options Considered</strong>: Linear decay, exponential decay, domain-specific decay functions, query-adaptive freshness weighting</li>\n<li><strong>Decision</strong>: Implement exponential decay with domain-specific half-life parameters and query-type detection</li>\n<li><strong>Rationale</strong>: Exponential decay models realistic information aging where recent content has much higher value, but value doesn&#39;t drop to zero. Domain-specific half-lives (3 months for tutorials, 12 months for research) better match content lifecycles.</li>\n<li><strong>Consequences</strong>: Requires content categorization and decay parameter tuning per domain. More complex than linear decay but much more realistic modeling of information value over time.</li>\n</ul>\n</blockquote>\n<p>The <strong>exponential freshness decay formula</strong> applies different decay rates based on content type and age:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>freshness_score = exp(-λ * age_in_days)\n\nWhere λ (decay constant) varies by content type:\n- News articles: λ = 0.1 (half-life ~7 days)\n- Technical tutorials: λ = 0.01 (half-life ~70 days) \n- Research papers: λ = 0.002 (half-life ~350 days)\n- Reference documentation: λ = 0.005 (half-life ~140 days)</code></pre></div>\n\n<p><strong>Query-adaptive freshness weighting</strong> recognizes that freshness importance varies by query intent. Queries containing temporal indicators (&quot;latest,&quot; &quot;new,&quot; &quot;recent,&quot; &quot;2024&quot;) should receive higher freshness weights. Technical queries about rapidly evolving topics (web frameworks, cloud services) benefit more from freshness than queries about stable, fundamental concepts (algorithms, mathematical proofs).</p>\n<table>\n<thead>\n<tr>\n<th>Query Pattern</th>\n<th>Freshness Weight</th>\n<th>Example</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Contains year/date</td>\n<td>0.4</td>\n<td>&quot;React 2024 best practices&quot;</td>\n<td>Explicit temporal intent</td>\n</tr>\n<tr>\n<td>Technology-specific</td>\n<td>0.3</td>\n<td>&quot;Kubernetes deployment tutorial&quot;</td>\n<td>Tech evolves quickly</td>\n</tr>\n<tr>\n<td>Conceptual/fundamental</td>\n<td>0.1</td>\n<td>&quot;binary search algorithm&quot;</td>\n<td>Timeless concepts</td>\n</tr>\n<tr>\n<td>News/current events</td>\n<td>0.5</td>\n<td>&quot;AI regulation updates&quot;</td>\n<td>Inherently time-sensitive</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Over-Personalization Filter Bubbles</strong>\nAggressive personalization can create filter bubbles where users only see content similar to their past behavior, limiting discovery of new topics and perspectives. Implement diversity injection by reserving 20-30% of top results for non-personalized ranking, and regularly evaluate result diversity metrics alongside relevance quality.</p>\n<h3 id=\"click-through-learning-using-user-interaction-data-to-improve-ranking-quality\">Click-Through Learning: Using User Interaction Data to Improve Ranking Quality</h3>\n<p>Click-through learning represents the <strong>continuous improvement engine</strong> of the ranking system, using real user interactions to validate and refine ranking decisions over time. While offline relevance evaluation provides initial quality assessment, user behavior provides the ultimate ground truth about which results are genuinely useful for specific queries. The system learns from patterns in user clicks, time spent on clicked results, and subsequent search behavior to identify ranking improvements and detect quality issues.</p>\n<p>The fundamental insight behind click-through learning is that <strong>user clicks provide implicit relevance feedback</strong> that is both abundant and aligned with actual user needs. Unlike explicit ratings (which are rare and potentially biased), click data captures real user decision-making under natural conditions. However, click data requires careful interpretation because clicks are influenced by result position, snippet quality, and user interface factors beyond true relevance.</p>\n<blockquote>\n<p><strong>Decision: Click-Through Data Collection and Learning Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: User clicks provide valuable relevance feedback but are biased by result position and presentation. We need to learn from click patterns while accounting for these biases.</li>\n<li><strong>Options Considered</strong>: Position-unaware click rates, position-bias correction models, pairwise preference learning from clicks, learning-to-rank with click features</li>\n<li><strong>Decision</strong>: Implement position-bias corrected click models with pairwise preference learning</li>\n<li><strong>Rationale</strong>: Position bias is the strongest confounding factor in click data—users click higher-ranked results more often regardless of relevance. Position-bias correction isolates true relevance signals. Pairwise learning is more robust than absolute click rates and works well with limited data.</li>\n<li><strong>Consequences</strong>: Requires sophisticated click modeling and careful statistical analysis. More complex than raw click rates but provides much more reliable relevance signals for ranking improvement.</li>\n</ul>\n</blockquote>\n<p>The <strong>click data collection system</strong> captures comprehensive user interaction signals that extend beyond simple click events. Click-through events are only meaningful in context—a click followed immediately by a return to search results suggests the clicked result was not satisfactory, while a click followed by extended engagement indicates relevance. The system logs detailed interaction patterns to enable sophisticated relevance inference.</p>\n<table>\n<thead>\n<tr>\n<th>Interaction Signal</th>\n<th>Data Captured</th>\n<th>Relevance Indication</th>\n<th>Collection Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Click Event</td>\n<td>Query, result position, timestamp</td>\n<td>Initial interest</td>\n<td>JavaScript tracking</td>\n</tr>\n<tr>\n<td>Dwell Time</td>\n<td>Time spent on clicked page</td>\n<td>Engagement quality</td>\n<td>Session duration</td>\n</tr>\n<tr>\n<td>Return to Search</td>\n<td>Time before back-button</td>\n<td>Satisfaction level</td>\n<td>Navigation tracking</td>\n</tr>\n<tr>\n<td>Follow-up Queries</td>\n<td>Subsequent searches in session</td>\n<td>Information need fulfillment</td>\n<td>Session analysis</td>\n</tr>\n<tr>\n<td>Skip Pattern</td>\n<td>Results viewed but not clicked</td>\n<td>Negative preference</td>\n<td>Scroll and view tracking</td>\n</tr>\n</tbody></table>\n<p><strong>Position bias correction</strong> addresses the fundamental challenge that higher-ranked results receive more clicks regardless of their true relevance. Users exhibit strong position bias, with the first result receiving 30-35% of clicks, the second result 15-20%, and subsequent results receiving exponentially fewer clicks. Raw click rates therefore conflate relevance with ranking position, making them unsuitable for direct ranking optimization.</p>\n<p>The <strong>position-bias correction model</strong> estimates the probability that a user examines each result position, separate from the probability that they find an examined result relevant. This separation enables estimation of true relevance probability independent of ranking position. The model learns examination probabilities from aggregate click patterns across many queries, then uses these to debias click rates for individual query-document pairs.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Observed Click Rate = P(examined) × P(relevant | examined)\n\nWhere:\nP(examined) = position-dependent examination probability (learned from data)\nP(relevant | examined) = true relevance probability (what we want to estimate)\n\nPosition bias correction:\nP(relevant | examined) = Observed Click Rate / P(examined)</code></pre></div>\n\n<p><strong>Pairwise preference learning</strong> extracts relative relevance judgments from click patterns, which are more reliable than absolute relevance scores. When users click on result A but skip result B that was ranked higher, this suggests A is more relevant than B for that query. Pairwise preferences are less sensitive to position bias and user interface factors because they compare results within the same search session.</p>\n<p>The <strong>preference extraction algorithm</strong> identifies reliable pairwise preferences from click patterns:</p>\n<ol>\n<li><strong>Skip-above preference</strong>: User clicks result at position i but skipped result at position j &lt; i, suggesting preference for result i</li>\n<li><strong>Click-through preference</strong>: User clicks result A, returns to search, then clicks result B, suggesting B provided better information than A</li>\n<li><strong>Dwell time preference</strong>: Among clicked results, longer dwell time suggests higher relevance</li>\n<li><strong>Last-click preference</strong>: The final clicked result in a search session often best satisfies the information need</li>\n</ol>\n<p>The <strong>ranking model update process</strong> uses collected preferences to improve future ranking decisions. Preferences are aggregated across multiple users and sessions to identify systematic ranking improvements. The system can detect when consistently lower-ranked results receive preference signals over higher-ranked results, indicating potential ranking quality issues that should be addressed.</p>\n<table>\n<thead>\n<tr>\n<th>Learning Signal</th>\n<th>Collection Window</th>\n<th>Confidence Threshold</th>\n<th>Action Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Skip-above patterns</td>\n<td>7 days</td>\n<td>10+ occurrences</td>\n<td>Investigate ranking weights</td>\n</tr>\n<tr>\n<td>Consistent dwell time differences</td>\n<td>14 days</td>\n<td>5+ sessions</td>\n<td>Adjust relevance scores</td>\n</tr>\n<tr>\n<td>Query reformulation patterns</td>\n<td>30 days</td>\n<td>20+ users</td>\n<td>Review query processing</td>\n</tr>\n<tr>\n<td>Zero-click queries</td>\n<td>7 days</td>\n<td>50+ occurrences</td>\n<td>Add direct answers</td>\n</tr>\n</tbody></table>\n<p><strong>Quality assurance for click-based learning</strong> protects against noisy or manipulated click data that could degrade ranking quality. Not all clicks represent genuine relevance—users sometimes click accidentally, click on misleading snippets, or exhibit unusual behavior. The system implements filtering and validation to ensure learning from high-quality interaction signals.</p>\n<p>⚠️ <strong>Pitfall: Learning from Noisy Click Data</strong>\nRaw click data contains substantial noise from accidental clicks, bot traffic, and edge cases. Always implement click quality filtering based on dwell time thresholds (clicks with &lt;3 seconds dwell time are likely accidental), session context validation, and statistical significance testing before updating ranking models.</p>\n<p>⚠️ <strong>Pitfall: Feedback Loop Amplification</strong>\nClick-based learning can create feedback loops where popular results become even more popular, potentially burying high-quality but less-discovered content. Implement exploration mechanisms that occasionally promote lower-ranked results to gather click data on their true relevance, and monitor result diversity metrics over time.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Franking-pipeline.svg\" alt=\"Multi-Stage Ranking Pipeline\"></p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fsearch-sequence.svg\" alt=\"Search Request Sequence\"></p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This implementation guidance provides the foundation for building a production-ready ranking and relevance system that balances multiple signals while maintaining sub-second query latency.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>BM25 Implementation</td>\n<td>scikit-learn TfidfVectorizer</td>\n<td>Elasticsearch BM25</td>\n</tr>\n<tr>\n<td>Cross-Encoder Model</td>\n<td>sentence-transformers cross-encoder</td>\n<td>Custom BERT fine-tuned model</td>\n</tr>\n<tr>\n<td>Click Tracking</td>\n<td>Simple JSON logging</td>\n<td>Apache Kafka + streaming</td>\n</tr>\n<tr>\n<td>Model Training</td>\n<td>Manual weight tuning</td>\n<td>Learning-to-rank with XGBoost</td>\n</tr>\n<tr>\n<td>Caching</td>\n<td>Python dict with TTL</td>\n<td>Redis with pipeline operations</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>semantic_search/\n├── ranking/\n│   ├── __init__.py\n│   ├── multi_stage_ranker.py      ← main ranking orchestrator\n│   ├── hybrid_scorer.py           ← combines semantic and lexical scores\n│   ├── personalization.py         ← user context and personalization\n│   ├── freshness.py              ← time-based relevance scoring\n│   ├── cross_encoder.py          ← transformer-based reranking\n│   ├── click_learning.py         ← click-through learning system\n│   └── ranking_test.py           ← comprehensive ranking tests\n├── models/\n│   ├── cross_encoder/            ← saved cross-encoder models\n│   └── click_models/             ← trained click prediction models\n└── data/\n    ├── click_logs/               ← user interaction logs\n    └── ranking_weights/          ← learned ranking parameters</code></pre></div>\n\n<h4 id=\"core-ranking-data-structures\">Core Ranking Data Structures</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RankingSignals</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Individual ranking signals for a query-document pair.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    semantic_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">           # Cosine similarity from embeddings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    bm25_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">              # Lexical matching score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    personalization_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">   # User preference alignment</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    freshness_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#6A737D\">         # Time-based relevance decay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    click_score: Optional[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]    </span><span style=\"color:#6A737D\"># Historical click-through signal</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RankingCandidate</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Document candidate with all ranking signals computed.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signals: RankingSignals</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    combined_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stage: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">                     # 'retrieval', 'hybrid', 'reranked'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PersonalizationContext</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"User context for personalized ranking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    user_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    role: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]            </span><span style=\"color:#6A737D\"># 'developer', 'manager', 'researcher'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    industry: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    experience_level: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#6A737D\"># 'beginner', 'intermediate', 'expert'  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recent_clicks: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]       </span><span style=\"color:#6A737D\"># Recent clicked document IDs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    topic_preferences: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Topic weights from history</span></span></code></pre></div>\n\n<h4 id=\"multi-stage-ranking-pipeline-implementation\">Multi-Stage Ranking Pipeline Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MultiStageRanker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Orchestrates multi-stage ranking pipeline for optimal speed and precision.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, vector_index, keyword_index, cross_encoder_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.vector_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vector_index</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.keyword_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> keyword_index</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.hybrid_scorer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HybridScorer()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cross_encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CrossEncoderReranker(cross_encoder_path)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.click_learner </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ClickThroughLearner()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> rank_documents</span><span style=\"color:#E1E4E8\">(self, processed_query: ProcessedQuery, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      personalization_context: Optional[PersonalizationContext] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      max_results: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#E1E4E8\">) -> List[SearchResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Execute complete multi-stage ranking pipeline.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Stage 1: Fast candidate retrieval using vector and keyword search</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Stage 2: Hybrid scoring with multiple signals  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Stage 3: Cross-encoder reranking for final precision</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve semantic candidates using vector similarity search</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Call self.vector_index.search(processed_query.primary_embedding, k=5000)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract document IDs and similarity scores from vector search results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Retrieve lexical candidates using BM25 keyword search  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Call self.keyword_index.search(processed_query.normalized_query, k=5000)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract document IDs and BM25 scores from keyword search results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Combine and deduplicate candidate sets from both retrieval methods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create union of semantic and lexical candidates, handling score conflicts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Aim for 8K-10K total candidates for hybrid scoring stage</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply hybrid scoring to combined candidate set</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # For each candidate, compute personalization and freshness scores</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Combine all signals using learned weights: semantic, lexical, personal, fresh</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Select top 200-500 candidates based on hybrid scores</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Apply cross-encoder reranking to top hybrid candidates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Pass (query_text, document_content) pairs to transformer model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Replace hybrid scores with precise cross-encoder relevance scores</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # This is the most expensive step - limit to top candidates only</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Apply click-through learning adjustments</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Boost/demote results based on historical click patterns for this query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Only apply adjustments where sufficient click data exists (>10 clicks)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Format final results with snippets and highlighting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Generate result snippets around query terms, apply highlighting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Include ranking signal breakdown for debugging and analytics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HybridScorer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Combines semantic similarity, BM25, personalization, and freshness signals.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Learned or manually tuned weights for signal combination</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.weights </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'semantic'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.4</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'bm25'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.3</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'personalization'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'freshness'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.personalizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PersonalizationScorer()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.freshness_scorer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FreshnessScorer()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> score_candidate</span><span style=\"color:#E1E4E8\">(self, document: Document, processed_query: ProcessedQuery,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       semantic_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, bm25_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       personalization_context: Optional[PersonalizationContext]) -> RankingSignals:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute all ranking signals for a query-document pair.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Normalize semantic similarity score to 0-1 range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Cosine similarity returns -1 to 1, map to 0-1: (score + 1) / 2</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Normalize BM25 score using sigmoid transformation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # BM25 scores are unbounded, apply: 1 / (1 + exp(-score/10))</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Adjust the divisor (10) based on your BM25 score distribution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compute personalization score using user context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Call self.personalizer.score() with document and user context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle case where personalization_context is None (return 0.5)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Compute freshness score based on document age</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Call self.freshness_scorer.score() with document creation date</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Apply domain-specific decay rates for different content types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return RankingSignals object with all computed scores</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> combine_signals</span><span style=\"color:#E1E4E8\">(self, signals: RankingSignals, query_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Combine individual signals into final hybrid score.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Apply query-adaptive weight adjustment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Technical queries: increase bm25 weight, decrease semantic weight</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Exploratory queries: increase semantic weight, decrease bm25 weight</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Compute weighted combination of all signals</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # combined = w_sem * semantic + w_bm25 * bm25 + w_pers * personal + w_fresh * fresh</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply score normalization and bounds checking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure final score is in valid range, handle edge cases</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"cross-encoder-reranking-component\">Cross-Encoder Reranking Component</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sentence_transformers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> CrossEncoder</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CrossEncoderReranker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"High-precision reranking using transformer cross-encoder models.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, model_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Load pre-trained cross-encoder model for relevance scoring</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.model </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CrossEncoder(model_path)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_candidates </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 500</span><span style=\"color:#6A737D\">  # Computational budget limit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> rerank_candidates</span><span style=\"color:#E1E4E8\">(self, candidates: List[RankingCandidate], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[RankingCandidate]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Apply cross-encoder reranking to top hybrid candidates.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Prepare query-document pairs for cross-encoder input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Format as [(query_text, doc.get_searchable_text()) for each candidate]</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Limit to top N candidates based on hybrid scores to control latency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Run cross-encoder prediction in batches for efficiency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Call self.model.predict() on query-document pairs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use batch processing to amortize model loading costs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Replace hybrid scores with cross-encoder scores  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Update candidate.combined_score with precise cross-encoder relevance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Mark candidates with stage='reranked' for analytics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Re-sort candidates by new cross-encoder scores</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return candidates in descending order of cross-encoder relevance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"personalization-and-freshness-scoring\">Personalization and Freshness Scoring</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PersonalizationScorer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Computes personalization scores based on user context and preferences.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> score_document</span><span style=\"color:#E1E4E8\">(self, document: Document, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                      context: PersonalizationContext) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute personalization relevance score for user context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> context </span><span style=\"color:#F97583\">or</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> context.user_id:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0.5</span><span style=\"color:#6A737D\">  # Neutral score for anonymous users</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compute role-based relevance boost</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check if document metadata tags match user role/industry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Apply boost for documents tagged as relevant to user's profession</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Compute historical interest similarity  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Compare document embedding to embeddings of previously clicked docs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use average cosine similarity to recent click history</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply experience level filtering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Boost beginner-friendly docs for novice users, advanced docs for experts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use document complexity indicators (length, technical terms, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Combine personalization signals with learned weights</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # role_boost (0.3) + history_similarity (0.5) + experience_match (0.2)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FreshnessScorer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Applies time-based relevance decay with domain-specific parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Domain-specific decay rates (higher lambda = faster decay)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.decay_rates </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'news'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">,           </span><span style=\"color:#6A737D\"># Half-life ~7 days</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'tutorial'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">,      </span><span style=\"color:#6A737D\"># Half-life ~70 days  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'documentation'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.005</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#6A737D\"># Half-life ~140 days</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'research'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.002</span><span style=\"color:#E1E4E8\">,     </span><span style=\"color:#6A737D\"># Half-life ~350 days</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'default'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.01</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> score_document</span><span style=\"color:#E1E4E8\">(self, document: Document) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute freshness score using exponential decay.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract document creation date from metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Handle missing creation dates (use current time or neutral score)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Determine content type for appropriate decay rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use document metadata, URL patterns, or content classification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Default to 'default' category if type cannot be determined</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compute document age in days</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # age_days = (current_date - creation_date).days</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply exponential decay formula</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # freshness_score = exp(-lambda * age_days)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure score is in valid range [0, 1]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"click-through-learning-system\">Click-Through Learning System</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ClickThroughLearner</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Learns from user click patterns to improve ranking quality.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, min_clicks_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.min_clicks_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> min_clicks_threshold</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.position_bias_model </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PositionBiasModel()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.preference_extractor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PreferenceExtractor()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_interaction</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, results: List[SearchResult],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          click_position: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">], dwell_time: Optional[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record user interaction for learning.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Log interaction event with full context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Store query, result list, click position, dwell time, timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Include session ID for multi-click pattern analysis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Update position bias estimates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Track examination and click rates by result position</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use for position bias correction in relevance estimation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Extract pairwise preferences from click patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Skip-above: clicked lower result vs. skipped higher result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Dwell time: longer engagement suggests higher relevance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_click_adjustments</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, candidates: List[RankingCandidate]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get learned score adjustments based on click history.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if sufficient click data exists for this query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return empty adjustments if below minimum click threshold</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Compute position-bias corrected click rates  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Apply position bias correction to get true relevance estimates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use aggregated click data across similar queries if exact match sparse</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate score adjustments for candidate documents</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Boost documents with high corrected click rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Apply conservative adjustments to avoid overfitting to noise</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the ranking and relevance component, verify the following behavior:</p>\n<p><strong>Basic Multi-Stage Ranking Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> ranking/ranking_test.py::test_multi_stage_pipeline</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n\n<p>Expected behavior:</p>\n<ul>\n<li>Stage 1 retrieval returns 5K-10K candidates in &lt;100ms</li>\n<li>Stage 2 hybrid scoring processes candidates in &lt;100ms  </li>\n<li>Stage 3 cross-encoder reranking completes in &lt;200ms</li>\n<li>Final results show diverse ranking signals in result metadata</li>\n</ul>\n<p><strong>Hybrid Scoring Validation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test semantic vs. lexical query handling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">semantic_query </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"improve team productivity\"</span><span style=\"color:#6A737D\">  # Should favor semantic signals</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">technical_query </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"Python asyncio tutorial\"</span><span style=\"color:#6A737D\">   # Should favor lexical signals</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify query-adaptive weight adjustment works correctly</span></span></code></pre></div>\n\n<p><strong>Personalization Testing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test personalized vs. anonymous ranking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PersonalizationContext(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    user_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"test_user\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    role</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"developer\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    recent_clicks</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"doc1\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"doc2\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify personalized results differ from anonymous results</span></span></code></pre></div>\n\n<h4 id=\"common-debugging-issues\">Common Debugging Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>All results have same score</td>\n<td>Score normalization broken</td>\n<td>Check score ranges before combination</td>\n<td>Implement proper min-max or sigmoid normalization</td>\n</tr>\n<tr>\n<td>Cross-encoder timeout</td>\n<td>Too many candidates sent</td>\n<td>Check candidate count before reranking</td>\n<td>Limit to &lt;500 candidates for cross-encoder</td>\n</tr>\n<tr>\n<td>Poor result diversity</td>\n<td>Over-aggressive personalization</td>\n<td>Check personalization weight distribution</td>\n<td>Reduce personalization weight below 0.3</td>\n</tr>\n<tr>\n<td>Slow query response</td>\n<td>Inefficient signal computation</td>\n<td>Profile each ranking stage latency</td>\n<td>Cache expensive computations, optimize batch processing</td>\n</tr>\n<tr>\n<td>Click learning not improving results</td>\n<td>Insufficient or noisy click data</td>\n<td>Analyze click data quality and volume</td>\n<td>Implement click filtering, increase collection period</td>\n</tr>\n</tbody></table>\n<h2 id=\"search-api-and-user-interface\">Search API and User Interface</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 4: Search API &amp; UI</p>\n</blockquote>\n<p>The <strong>Search API and User Interface</strong> represents the final presentation layer that transforms our sophisticated semantic search capabilities into a responsive, production-ready service. This component serves as the bridge between end users and the complex underlying architecture we&#39;ve built through the previous milestones. While the embedding index provides the foundation, query processing adds intelligence, and ranking ensures relevance, the search API makes these capabilities accessible through intuitive interfaces that feel instant and natural to users.</p>\n<p>The challenge in this component lies not just in exposing functionality, but in doing so with the performance characteristics that users expect from modern search experiences. Sub-100ms autocomplete responses, comprehensive result formatting with highlighted terms, and real-time analytics all require careful architectural decisions that balance functionality with speed. This component must also handle the practical concerns of production systems: graceful error handling, comprehensive logging, and the ability to monitor and improve search quality over time.</p>\n<h3 id=\"search-api-mental-model-reference-librarian-analogy\">Search API Mental Model: Reference Librarian Analogy</h3>\n<p>Think of the Search API as an expert reference librarian who has mastered the art of responsive assistance. Just as a skilled librarian can quickly understand what you&#39;re looking for from just a few words, provide instant suggestions as you describe your needs, organize results by relevant categories, and highlight exactly why each resource matches your request, our search API provides the same intuitive, helpful interface to our semantic search engine.</p>\n<p>The librarian analogy extends to the multi-layered nature of search assistance. When you approach a reference desk, the librarian doesn&#39;t just wait for your complete question—they start helping immediately. As you begin speaking, they might suggest related topics (autocomplete). Once you&#39;ve explained your need, they don&#39;t just find one book—they organize recommendations by subject area (faceted navigation), mark relevant passages (highlighting), and explain why each resource fits your request (relevance scoring). They also remember what kinds of questions people ask most often and which resources proved most helpful (analytics).</p>\n<p>This mental model guides our API design decisions. Every endpoint must respond with the immediacy users expect, every response must be structured to facilitate quick understanding, and every interaction must contribute to improving future search experiences. The API becomes not just a programmatic interface, but a conversational partner in the information discovery process.</p>\n<blockquote>\n<p><strong>Decision: RESTful JSON API Design</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to choose API style and data format for maximum compatibility and ease of use</li>\n<li><strong>Options Considered</strong>: GraphQL for flexible queries, gRPC for performance, REST with JSON for simplicity</li>\n<li><strong>Decision</strong>: RESTful JSON API with standardized endpoints and response formats</li>\n<li><strong>Rationale</strong>: REST provides universal compatibility across platforms and languages, JSON offers human-readable debugging, and the request patterns for search are well-suited to REST&#39;s resource-oriented design</li>\n<li><strong>Consequences</strong>: Slightly higher bandwidth than binary protocols, but gains in developer experience, debugging ease, and ecosystem compatibility far outweigh the costs</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>API Design Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>REST + JSON</td>\n<td>Universal compatibility, easy debugging, extensive tooling</td>\n<td>Higher bandwidth than binary formats</td>\n<td>✅ Yes</td>\n</tr>\n<tr>\n<td>GraphQL</td>\n<td>Flexible client-driven queries, single endpoint</td>\n<td>Added complexity for simple search use case</td>\n<td>❌ No</td>\n</tr>\n<tr>\n<td>gRPC + Protobuf</td>\n<td>High performance, type safety, streaming</td>\n<td>Language-specific tooling, harder debugging</td>\n<td>❌ No</td>\n</tr>\n</tbody></table>\n<h3 id=\"restful-search-endpoints\">RESTful Search Endpoints</h3>\n<p>The core search functionality exposes through a carefully designed set of REST endpoints that balance simplicity with comprehensive functionality. The primary search endpoint accepts rich query parameters while maintaining backward compatibility and intuitive defaults.</p>\n<p>The main search endpoint follows the pattern <code>/api/v1/search</code> and accepts both GET requests for simple queries and POST requests for complex search contexts. This dual approach accommodates direct URL sharing (critical for search applications) while supporting advanced features like personalization contexts that don&#39;t belong in URL parameters.</p>\n<table>\n<thead>\n<tr>\n<th>Endpoint</th>\n<th>Method</th>\n<th>Purpose</th>\n<th>Response Time Target</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>/api/v1/search</code></td>\n<td>GET/POST</td>\n<td>Primary search functionality</td>\n<td>&lt; 500ms p95</td>\n</tr>\n<tr>\n<td><code>/api/v1/autocomplete</code></td>\n<td>GET</td>\n<td>Typeahead suggestions</td>\n<td>&lt; 100ms p95</td>\n</tr>\n<tr>\n<td><code>/api/v1/facets/{field}</code></td>\n<td>GET</td>\n<td>Available filter values</td>\n<td>&lt; 200ms p95</td>\n</tr>\n<tr>\n<td><code>/api/v1/analytics</code></td>\n<td>GET</td>\n<td>Search quality metrics</td>\n<td>&lt; 2000ms p95</td>\n</tr>\n</tbody></table>\n<p>The <code>QueryRequest</code> structure accommodates both simple and sophisticated search scenarios. The design philosophy prioritizes making simple queries trivial while enabling complex use cases through optional parameters.</p>\n<table>\n<thead>\n<tr>\n<th>QueryRequest Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Default</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>query_text</code></td>\n<td>str</td>\n<td>User&#39;s search query text</td>\n<td>Required</td>\n</tr>\n<tr>\n<td><code>max_results</code></td>\n<td>int</td>\n<td>Maximum results to return</td>\n<td>20</td>\n</tr>\n<tr>\n<td><code>filters</code></td>\n<td>Optional[Dict]</td>\n<td>Category/metadata filters</td>\n<td>None</td>\n</tr>\n<tr>\n<td><code>personalization_context</code></td>\n<td>Optional[Dict]</td>\n<td>User context for ranking</td>\n<td>None</td>\n</tr>\n<tr>\n<td><code>include_facets</code></td>\n<td>bool</td>\n<td>Return facet counts with results</td>\n<td>false</td>\n</tr>\n</tbody></table>\n<p>The filters dictionary supports hierarchical filtering with intuitive operators. For example, <code>{&quot;category&quot;: [&quot;technology&quot;, &quot;science&quot;], &quot;date_range&quot;: {&quot;after&quot;: &quot;2023-01-01&quot;}}</code> enables multi-value category filtering combined with temporal constraints. This approach maintains JSON simplicity while supporting sophisticated filter combinations.</p>\n<p>Personalization context allows clients to provide user-specific information that enhances ranking quality without requiring server-side user management. The API remains stateless while enabling personalized results through client-provided context.</p>\n<table>\n<thead>\n<tr>\n<th>PersonalizationContext Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Usage Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>user_id</code></td>\n<td>Optional[str]</td>\n<td>Stable user identifier</td>\n<td>For click-through learning</td>\n</tr>\n<tr>\n<td><code>role</code></td>\n<td>Optional[str]</td>\n<td>User&#39;s professional role</td>\n<td>&quot;software engineer&quot;</td>\n</tr>\n<tr>\n<td><code>industry</code></td>\n<td>Optional[str]</td>\n<td>User&#39;s industry domain</td>\n<td>&quot;healthcare&quot;</td>\n</tr>\n<tr>\n<td><code>experience_level</code></td>\n<td>Optional[str]</td>\n<td>User&#39;s expertise level</td>\n<td>&quot;beginner&quot;</td>\n</tr>\n<tr>\n<td><code>recent_clicks</code></td>\n<td>List[str]</td>\n<td>Recently clicked document IDs</td>\n<td>For implicit feedback</td>\n</tr>\n<tr>\n<td><code>topic_preferences</code></td>\n<td>Dict[str, float]</td>\n<td>Topic interest scores</td>\n<td>{&quot;ai&quot;: 0.9, &quot;frontend&quot;: 0.3}</td>\n</tr>\n</tbody></table>\n<p>The <code>QueryResponse</code> format provides comprehensive information while maintaining efficient parsing for client applications. Each response includes not just results, but metadata that enables rich user experiences and performance monitoring.</p>\n<table>\n<thead>\n<tr>\n<th>QueryResponse Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Client Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>query</code></td>\n<td>str</td>\n<td>Processed query text</td>\n<td>Display what was actually searched</td>\n</tr>\n<tr>\n<td><code>results</code></td>\n<td>List[SearchResult]</td>\n<td>Ranked search results</td>\n<td>Primary result display</td>\n</tr>\n<tr>\n<td><code>total_found</code></td>\n<td>int</td>\n<td>Total matching documents</td>\n<td>Pagination and result count</td>\n</tr>\n<tr>\n<td><code>processing_time_ms</code></td>\n<td>float</td>\n<td>Server-side processing time</td>\n<td>Performance monitoring</td>\n</tr>\n<tr>\n<td><code>facets</code></td>\n<td>Optional[Dict]</td>\n<td>Filter counts by category</td>\n<td>Faceted navigation UI</td>\n</tr>\n</tbody></table>\n<p>Individual search results provide rich metadata that enables sophisticated result presentation. The structure balances information completeness with response size efficiency.</p>\n<table>\n<thead>\n<tr>\n<th>SearchResult Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Presentation Use</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>document</code></td>\n<td>Document</td>\n<td>Full document metadata</td>\n<td>Title, URL, creation date</td>\n</tr>\n<tr>\n<td><code>relevance_score</code></td>\n<td>float</td>\n<td>Combined ranking score (0-1)</td>\n<td>Sort order, confidence indication</td>\n</tr>\n<tr>\n<td><code>snippet</code></td>\n<td>str</td>\n<td>Contextual text excerpt</td>\n<td>Result preview</td>\n</tr>\n<tr>\n<td><code>highlighted_terms</code></td>\n<td>List[str]</td>\n<td>Query terms found in result</td>\n<td>Term highlighting logic</td>\n</tr>\n<tr>\n<td><code>ranking_signals</code></td>\n<td>Dict[str, float]</td>\n<td>Individual signal contributions</td>\n<td>Debug mode, relevance explanation</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>The ranking signals dictionary provides transparency into how results were scored, enabling both debugging and user education about why particular results appeared. This transparency builds user trust and helps identify ranking issues during development.</p>\n</blockquote>\n<h3 id=\"autocomplete-and-typeahead\">Autocomplete and Typeahead</h3>\n<p>The autocomplete system provides the immediate responsiveness that users expect from modern search interfaces. The challenge lies in generating relevant suggestions within the 100ms latency budget while maintaining high suggestion quality and avoiding the computational overhead of full semantic search.</p>\n<p>The autocomplete approach employs a multi-tier strategy that balances speed with relevance. The first tier uses a traditional prefix-based trie structure for instant character-level matching. The second tier applies lightweight semantic expansion using cached query embeddings for frequent search patterns. This hybrid approach ensures that common queries receive instant responses while less frequent queries benefit from semantic understanding.</p>\n<blockquote>\n<p><strong>Decision: Hybrid Prefix + Semantic Autocomplete</strong></p>\n<ul>\n<li><strong>Context</strong>: Need sub-100ms autocomplete responses while maintaining semantic understanding</li>\n<li><strong>Options Considered</strong>: Pure prefix matching, full semantic search, hybrid approach</li>\n<li><strong>Decision</strong>: Prefix trie for speed with semantic expansion for quality</li>\n<li><strong>Rationale</strong>: Prefix matching alone misses semantic relationships, full semantic search exceeds latency budget, hybrid approach achieves both speed and intelligence</li>\n<li><strong>Consequences</strong>: Requires maintaining dual data structures but delivers optimal user experience</li>\n</ul>\n</blockquote>\n<p>The autocomplete endpoint implements aggressive caching and precomputation strategies to meet latency requirements. Popular query prefixes and their expansions are cached in memory, while semantic similarity computations for frequent patterns are precomputed during off-peak hours.</p>\n<table>\n<thead>\n<tr>\n<th>Autocomplete Strategy</th>\n<th>Response Time</th>\n<th>Quality</th>\n<th>Implementation Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Prefix Trie Only</td>\n<td>&lt; 10ms</td>\n<td>Basic</td>\n<td>Low</td>\n</tr>\n<tr>\n<td>Full Semantic Search</td>\n<td>200-500ms</td>\n<td>Excellent</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td>Hybrid Approach</td>\n<td>&lt; 100ms</td>\n<td>Good</td>\n<td>High</td>\n</tr>\n</tbody></table>\n<p>The autocomplete processing pipeline operates through several optimized stages:</p>\n<ol>\n<li><p><strong>Prefix Matching</strong>: The system immediately identifies all cached queries that begin with the user&#39;s input characters. This provides instant baseline suggestions for common search patterns.</p>\n</li>\n<li><p><strong>Semantic Expansion</strong>: For queries that have insufficient prefix matches, the system computes a lightweight embedding of the partial query and finds semantically similar complete queries from the cache.</p>\n</li>\n<li><p><strong>Popularity Ranking</strong>: Suggestions are ranked by a combination of query frequency, recent search volume, and semantic similarity to the partial input. This ensures that popular, relevant queries appear first.</p>\n</li>\n<li><p><strong>Context Filtering</strong>: When personalization context is available, suggestions are filtered and reranked based on user preferences and search history. This personalization happens without violating the latency budget through precomputed user query clusters.</p>\n</li>\n<li><p><strong>Response Formatting</strong>: The final suggestions are formatted with highlighted matching portions and optional category indicators to help users understand why each suggestion was recommended.</p>\n</li>\n</ol>\n<p>The autocomplete cache employs a sophisticated warming strategy that anticipates user needs. During low-traffic periods, the system precomputes embeddings for trending queries, seasonal search patterns, and user-specific suggestion sets. This precomputation ensures that even semantically complex suggestions can be served within the latency budget.</p>\n<table>\n<thead>\n<tr>\n<th>Cache Layer</th>\n<th>Content</th>\n<th>Refresh Frequency</th>\n<th>Size Limit</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hot Prefix Cache</td>\n<td>Most common prefixes + completions</td>\n<td>Real-time updates</td>\n<td>10MB</td>\n</tr>\n<tr>\n<td>Semantic Cache</td>\n<td>Query embeddings + similar queries</td>\n<td>Hourly batch</td>\n<td>100MB</td>\n</tr>\n<tr>\n<td>User Cache</td>\n<td>Personalized suggestions</td>\n<td>Daily batch</td>\n<td>50MB</td>\n</tr>\n<tr>\n<td>Trending Cache</td>\n<td>Current popular queries</td>\n<td>15-minute updates</td>\n<td>25MB</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Autocomplete Latency Degradation</strong>\nMany implementations start with acceptable autocomplete performance but degrade over time as the suggestion vocabulary grows. This happens because they perform semantic similarity computations in real-time during the autocomplete request. Instead, precompute semantic relationships during off-peak hours and use the autocomplete request time only for fast lookups and ranking. Monitor P95 latency continuously—if it exceeds 80ms, you&#39;re approaching the threshold where users perceive sluggishness.</p>\n<h3 id=\"faceted-navigation\">Faceted Navigation</h3>\n<p>Faceted navigation transforms the search experience from a linear result list into an interactive exploration interface. Users can drill down through categories, filter by metadata dimensions, and understand the distribution of results across different classification schemes. The implementation challenge lies in computing facet counts efficiently while maintaining the responsiveness users expect.</p>\n<p>The faceting system operates on multiple metadata dimensions simultaneously, providing users with a comprehensive understanding of their result space. Each facet represents a different way to slice and organize the search results, from content categories to publication dates to author information.</p>\n<blockquote>\n<p>Think of faceted navigation as providing multiple organizational lenses simultaneously. Just as a library might organize the same books by subject, author, publication year, and reading level, our faceted system shows users how their search results distribute across different classification dimensions. Users can then combine these lenses to narrow their focus to exactly what they need.</p>\n</blockquote>\n<p>The facet computation pipeline balances accuracy with performance through a multi-stage approach. During the initial search request, the system computes exact facet counts only for the top result candidates. For deeper facet exploration, the system uses statistical sampling techniques to provide approximate counts that guide user exploration without requiring exhaustive computation.</p>\n<table>\n<thead>\n<tr>\n<th>Facet Type</th>\n<th>Examples</th>\n<th>Computation Strategy</th>\n<th>Update Frequency</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Category</td>\n<td>Technology, Science, Business</td>\n<td>Exact counts from search results</td>\n<td>Real-time</td>\n</tr>\n<tr>\n<td>Temporal</td>\n<td>Last week, Last month, This year</td>\n<td>Date range aggregation</td>\n<td>Real-time</td>\n</tr>\n<tr>\n<td>Author/Source</td>\n<td>Specific authors or publications</td>\n<td>Metadata aggregation</td>\n<td>Real-time</td>\n</tr>\n<tr>\n<td>Content Type</td>\n<td>Article, Tutorial, Reference</td>\n<td>Document type classification</td>\n<td>Real-time</td>\n</tr>\n<tr>\n<td>Difficulty</td>\n<td>Beginner, Intermediate, Advanced</td>\n<td>ML-based content analysis</td>\n<td>Batch processed</td>\n</tr>\n</tbody></table>\n<p>The faceting algorithm operates through several optimized stages:</p>\n<ol>\n<li><p><strong>Result Set Analysis</strong>: After the initial search retrieval, the system examines the top N results (typically 1000) to compute baseline facet distributions. This provides accurate counts for the most relevant portion of the result space.</p>\n</li>\n<li><p><strong>Sampling Extension</strong>: For facets that show interesting distributions in the top results, the system extends analysis to a statistical sample of the broader result set. This provides reasonably accurate estimates for deeper filtering.</p>\n</li>\n<li><p><strong>Cache Integration</strong>: Frequently requested facet combinations are cached with their count distributions. This enables instant facet navigation for common exploration patterns.</p>\n</li>\n<li><p><strong>Interactive Refinement</strong>: As users select facet filters, the system recomputes facet counts for the filtered result set. This maintains accuracy as the result space narrows through user interaction.</p>\n</li>\n<li><p><strong>Zero-Count Handling</strong>: Facets that would produce zero results are marked as unavailable rather than hidden entirely. This prevents user frustration from dead-end exploration paths.</p>\n</li>\n</ol>\n<p>The facet response format enables rich client-side filtering interfaces while maintaining server-side computation efficiency. Each facet includes not just counts, but metadata that helps clients build intuitive navigation experiences.</p>\n<table>\n<thead>\n<tr>\n<th>Facet Response Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Client Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>facet_name</code></td>\n<td>str</td>\n<td>Human-readable facet category</td>\n<td>Navigation section headers</td>\n</tr>\n<tr>\n<td><code>facet_values</code></td>\n<td>List[Dict]</td>\n<td>Available values with counts</td>\n<td>Filter options and counts</td>\n</tr>\n<tr>\n<td><code>selected_values</code></td>\n<td>List[str]</td>\n<td>Currently active filters</td>\n<td>UI state management</td>\n</tr>\n<tr>\n<td><code>facet_type</code></td>\n<td>str</td>\n<td>UI hint (single/multi select)</td>\n<td>Appropriate input controls</td>\n</tr>\n<tr>\n<td><code>more_available</code></td>\n<td>bool</td>\n<td>Whether additional values exist</td>\n<td>&quot;Show more&quot; functionality</td>\n</tr>\n</tbody></table>\n<p>Individual facet values include rich metadata that enables sophisticated filtering interfaces:</p>\n<table>\n<thead>\n<tr>\n<th>Facet Value Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Interface Use</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>value</code></td>\n<td>str</td>\n<td>Filter value identifier</td>\n<td>Query parameter</td>\n</tr>\n<tr>\n<td><code>display_name</code></td>\n<td>str</td>\n<td>Human-readable label</td>\n<td>User interface</td>\n</tr>\n<tr>\n<td><code>count</code></td>\n<td>int</td>\n<td>Documents matching this filter</td>\n<td>Result count display</td>\n</tr>\n<tr>\n<td><code>selected</code></td>\n<td>bool</td>\n<td>Whether currently applied</td>\n<td>UI state indication</td>\n</tr>\n<tr>\n<td><code>estimated</code></td>\n<td>bool</td>\n<td>Whether count is approximate</td>\n<td>Confidence indication</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Expensive Facet Count Computation</strong>\nComputing exact facet counts across large result sets can easily exceed response time budgets. Many implementations try to compute exact counts for all possible facet values on every search request. Instead, compute exact counts only for the most relevant results (top 1000), use sampling for broader estimates, and cache common facet combinations. Reserve exact computation for the final filtered result set when users have narrowed their search scope.</p>\n<h3 id=\"query-term-highlighting\">Query Term Highlighting</h3>\n<p>Query term highlighting transforms search results from simple text blocks into visually scannable content that clearly indicates why each result matches the user&#39;s query. The challenge extends beyond simple string matching because semantic search introduces conceptual matches that don&#39;t correspond to exact query terms. Users need to understand not just which documents matched, but why they matched.</p>\n<p>The highlighting system operates at multiple semantic levels. At the lexical level, it identifies exact query term matches and synonymous terms. At the semantic level, it identifies text passages that contributed to the document&#39;s semantic similarity score, even when they don&#39;t contain query keywords. This multi-level approach helps users understand both traditional keyword matches and the semantic relationships that make our search engine intelligent.</p>\n<blockquote>\n<p>The highlighting system acts like a knowledgeable teacher marking up a text to show a student exactly where the relevant information appears. Just as a teacher might highlight not only the exact words the student asked about, but also related concepts and supporting details, our system marks both literal matches and semantically related content that contributed to the document&#39;s relevance.</p>\n</blockquote>\n<p>The highlighting algorithm balances precision with comprehensiveness through a multi-stage analysis process:</p>\n<ol>\n<li><p><strong>Exact Match Identification</strong>: The system identifies all instances where query terms appear exactly in the document text. This includes handling case variations, punctuation differences, and word boundary detection.</p>\n</li>\n<li><p><strong>Synonym Recognition</strong>: Using the same synonym expansion logic from query processing, the system identifies terms in the document that are synonymous with query terms. These receive highlighting with visual distinction from exact matches.</p>\n</li>\n<li><p><strong>Semantic Contribution Analysis</strong>: The system analyzes which text passages contributed most strongly to the document&#39;s semantic similarity score. This involves computing attention weights between query embedding and document text segments.</p>\n</li>\n<li><p><strong>Context Window Generation</strong>: Around each highlighted term, the system extracts contextual text that helps users understand the match relevance. Context windows are sized to provide meaningful understanding without overwhelming the result display.</p>\n</li>\n<li><p><strong>Snippet Optimization</strong>: The final highlighting process selects the most representative passages from the document, ensuring that snippets contain highlighted terms while providing coherent reading experience.</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Highlighting Type</th>\n<th>Visual Treatment</th>\n<th>Confidence Threshold</th>\n<th>Context Window Size</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Exact Match</td>\n<td>Bold highlighting</td>\n<td>1.0</td>\n<td>50 characters each side</td>\n</tr>\n<tr>\n<td>Synonym Match</td>\n<td>Italic highlighting</td>\n<td>&gt; 0.8 similarity</td>\n<td>40 characters each side</td>\n</tr>\n<tr>\n<td>Semantic Match</td>\n<td>Underline highlighting</td>\n<td>&gt; 0.6 attention weight</td>\n<td>60 characters each side</td>\n</tr>\n<tr>\n<td>Related Concept</td>\n<td>Subtle highlighting</td>\n<td>&gt; 0.4 attention weight</td>\n<td>30 characters each side</td>\n</tr>\n</tbody></table>\n<p>The highlighting response format enables sophisticated client-side presentation while maintaining server-side computation control:</p>\n<table>\n<thead>\n<tr>\n<th>Highlighting Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Client Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>original_text</code></td>\n<td>str</td>\n<td>Unmodified document excerpt</td>\n<td>Fallback display</td>\n</tr>\n<tr>\n<td><code>highlighted_html</code></td>\n<td>str</td>\n<td>HTML with highlight markup</td>\n<td>Rich text presentation</td>\n</tr>\n<tr>\n<td><code>highlight_spans</code></td>\n<td>List[Dict]</td>\n<td>Structured highlight metadata</td>\n<td>Custom styling</td>\n</tr>\n<tr>\n<td><code>snippet_score</code></td>\n<td>float</td>\n<td>Relevance score for this excerpt</td>\n<td>Snippet ranking</td>\n</tr>\n</tbody></table>\n<p>Each highlight span provides detailed metadata that enables customizable presentation:</p>\n<table>\n<thead>\n<tr>\n<th>Highlight Span Field</th>\n<th>Type</th>\n<th>Description</th>\n<th>Styling Use</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>start_pos</code></td>\n<td>int</td>\n<td>Character position start</td>\n<td>Text range selection</td>\n</tr>\n<tr>\n<td><code>end_pos</code></td>\n<td>int</td>\n<td>Character position end</td>\n<td>Text range selection</td>\n</tr>\n<tr>\n<td><code>highlight_type</code></td>\n<td>str</td>\n<td>Match type (exact/synonym/semantic)</td>\n<td>CSS class selection</td>\n</tr>\n<tr>\n<td><code>confidence</code></td>\n<td>float</td>\n<td>Match confidence score</td>\n<td>Visual intensity</td>\n</tr>\n<tr>\n<td><code>query_term</code></td>\n<td>str</td>\n<td>Original query term that matched</td>\n<td>Tooltip information</td>\n</tr>\n</tbody></table>\n<p>The semantic highlighting component represents one of the most sophisticated aspects of the system. Rather than relying purely on text matching, it analyzes the attention patterns from the semantic similarity computation to identify which document passages most strongly influenced the relevance score.</p>\n<p>This semantic analysis operates through transformer attention weight extraction. When computing semantic similarity between query and document embeddings, the system captures intermediate attention weights that indicate which tokens in the document text most strongly aligned with query concepts. These attention weights are then mapped back to text positions to enable highlighting of semantically relevant passages.</p>\n<p>⚠️ <strong>Pitfall: HTML Entity Corruption in Highlighting</strong>\nWhen highlighting text that contains HTML entities or special characters, many implementations break the text structure by inserting highlight markup in the middle of entity codes. For example, highlighting &quot;amp&quot; in &quot;Smith &amp; Jones&quot; can produce &quot;Smith &amp;<mark>amp</mark>; Jones&quot; which renders incorrectly. Always parse HTML entities before highlighting analysis, perform highlighting on the decoded text, then carefully reconstruct the highlighted version while preserving entity integrity.</p>\n<h3 id=\"search-analytics-dashboard\">Search Analytics Dashboard</h3>\n<p>The analytics dashboard transforms search usage data into actionable insights for improving search quality and understanding user behavior. This component serves multiple stakeholders: developers need performance metrics and error rates, product managers need usage patterns and success metrics, and search quality engineers need relevance feedback and improvement opportunities.</p>\n<p>The analytics system captures comprehensive search telemetry without impacting search request performance. All analytics data collection happens asynchronously, with critical metrics cached in memory and periodically flushed to persistent storage. This approach ensures that search responsiveness remains unaffected by analytics overhead.</p>\n<blockquote>\n<p>Think of the analytics dashboard as a search engine health monitor that works like a fitness tracker for your system. Just as a fitness tracker passively collects data about your daily activity and then provides insights about patterns, trends, and opportunities for improvement, the analytics system continuously observes search behavior and transforms that data into actionable insights about system health and user satisfaction.</p>\n</blockquote>\n<p>The analytics data model captures both technical performance metrics and user behavior signals. This comprehensive approach enables correlation analysis between system performance and user satisfaction metrics.</p>\n<table>\n<thead>\n<tr>\n<th>Analytics Category</th>\n<th>Metrics Tracked</th>\n<th>Update Frequency</th>\n<th>Retention Period</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Performance</td>\n<td>Response time, error rate, cache hit rate</td>\n<td>Real-time aggregation</td>\n<td>90 days detailed</td>\n</tr>\n<tr>\n<td>Usage</td>\n<td>Query volume, result clicks, zero-result queries</td>\n<td>Real-time streaming</td>\n<td>1 year summarized</td>\n</tr>\n<tr>\n<td>Quality</td>\n<td>Click-through rates, dwell time, result ranking</td>\n<td>Batch processing</td>\n<td>6 months detailed</td>\n</tr>\n<tr>\n<td>System Health</td>\n<td>Index size, memory usage, disk I/O</td>\n<td>1-minute intervals</td>\n<td>30 days detailed</td>\n</tr>\n</tbody></table>\n<p>The analytics collection pipeline operates through several specialized components:</p>\n<ol>\n<li><p><strong>Request Telemetry</strong>: Every search request generates telemetry data including query text (optionally hashed for privacy), response time, result count, and user interaction context. This data is immediately queued for asynchronous processing.</p>\n</li>\n<li><p><strong>User Interaction Tracking</strong>: Click-through events, result dwell times, and query refinement patterns are captured to understand search success rates. This behavioral data provides crucial feedback about ranking quality.</p>\n</li>\n<li><p><strong>Zero-Result Analysis</strong>: Queries that return no results receive special attention, as they represent opportunities for index expansion, query processing improvement, or user education.</p>\n</li>\n<li><p><strong>Performance Monitoring</strong>: System-level metrics including memory usage, CPU utilization, and index access patterns are continuously collected to identify performance bottlenecks and capacity planning needs.</p>\n</li>\n<li><p><strong>Quality Scoring</strong>: Automated quality metrics are computed by analyzing user behavior patterns, comparing semantic similarity scores with user satisfaction signals, and identifying queries where ranking could be improved.</p>\n</li>\n</ol>\n<p>The analytics dashboard presents this data through several specialized views designed for different stakeholder needs:</p>\n<table>\n<thead>\n<tr>\n<th>Dashboard View</th>\n<th>Target Audience</th>\n<th>Key Metrics</th>\n<th>Refresh Rate</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Operations Dashboard</td>\n<td>SRE/DevOps</td>\n<td>Error rates, latency, throughput</td>\n<td>Real-time</td>\n</tr>\n<tr>\n<td>Usage Analytics</td>\n<td>Product Management</td>\n<td>Query trends, user engagement</td>\n<td>Hourly</td>\n</tr>\n<tr>\n<td>Quality Metrics</td>\n<td>Search Engineers</td>\n<td>Relevance scores, click-through rates</td>\n<td>Daily</td>\n</tr>\n<tr>\n<td>Business Intelligence</td>\n<td>Executives</td>\n<td>Search ROI, content gaps</td>\n<td>Weekly</td>\n</tr>\n</tbody></table>\n<p>The zero-result query analysis represents a particularly valuable analytics capability. These queries often indicate content gaps, query processing limitations, or opportunities for search education. The system automatically categorizes zero-result queries and provides recommendations for improvement.</p>\n<table>\n<thead>\n<tr>\n<th>Zero-Result Category</th>\n<th>Characteristics</th>\n<th>Improvement Strategy</th>\n<th>Implementation Priority</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Spelling Errors</td>\n<td>Obvious typos, character transpositions</td>\n<td>Query spelling correction</td>\n<td>High</td>\n</tr>\n<tr>\n<td>Missing Content</td>\n<td>Valid queries, no matching documents</td>\n<td>Content acquisition</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td>Processing Failures</td>\n<td>System errors, timeout failures</td>\n<td>Technical fixes</td>\n<td>Critical</td>\n</tr>\n<tr>\n<td>Over-Specific</td>\n<td>Queries too narrow for available content</td>\n<td>Query relaxation suggestions</td>\n<td>Medium</td>\n</tr>\n<tr>\n<td>Domain Mismatch</td>\n<td>Queries outside system scope</td>\n<td>User education</td>\n<td>Low</td>\n</tr>\n</tbody></table>\n<p>The analytics system implements sophisticated privacy protection while maintaining analytical value. User queries can be hashed for privacy while preserving the ability to identify trends and patterns. User interaction data is aggregated to prevent individual tracking while enabling quality improvement.</p>\n<p>Advanced analytics features include automated anomaly detection that identifies unusual search patterns, performance degradation, or quality regressions. The system establishes baseline performance and quality metrics, then alerts when significant deviations occur.</p>\n<table>\n<thead>\n<tr>\n<th>Anomaly Type</th>\n<th>Detection Method</th>\n<th>Alert Threshold</th>\n<th>Response Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Performance Degradation</td>\n<td>Response time percentile shift</td>\n<td>P95 &gt; 2x baseline</td>\n<td>Immediate investigation</td>\n</tr>\n<tr>\n<td>Quality Regression</td>\n<td>Click-through rate drop</td>\n<td>CTR &lt; 0.7x baseline</td>\n<td>Search team notification</td>\n</tr>\n<tr>\n<td>Usage Spike</td>\n<td>Query volume increase</td>\n<td>Volume &gt; 3x normal</td>\n<td>Capacity scaling</td>\n</tr>\n<tr>\n<td>Error Rate Increase</td>\n<td>Error percentage rise</td>\n<td>Error rate &gt; 5%</td>\n<td>Engineering escalation</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Analytics Data Overwhelming Search Performance</strong>\nMany search systems start with simple logging but gradually add more comprehensive analytics that eventually impact search response times. This happens because analytics collection is often implemented synchronously within the search request path. Instead, implement all analytics as asynchronous fire-and-forget operations. Use in-memory buffers for metrics collection and background threads for persistence. Never let analytics impact search latency—users will notice the performance degradation long before the analytics provide value.</p>\n<h3 id=\"component-interactions-and-data-flow\">Component Interactions and Data Flow</h3>\n<p>The Search API component orchestrates complex interactions between all previously implemented components while maintaining the illusion of simplicity for client applications. Understanding these interactions is crucial for implementing the API layer correctly and diagnosing issues that span multiple components.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fsearch-sequence.svg\" alt=\"Search Request Sequence\"></p>\n<p>The primary search request follows a carefully choreographed sequence that balances thoroughness with performance. Each step has specific timing requirements and fallback strategies to ensure robust operation.</p>\n<p>The search request processing flow operates through these coordinated stages:</p>\n<ol>\n<li><p><strong>Request Validation and Parsing</strong>: The API layer validates incoming requests, applies default values, and transforms client request format into internal processing structures. Invalid requests are rejected immediately with helpful error messages.</p>\n</li>\n<li><p><strong>Query Processing Invocation</strong>: The validated request is passed to the Query Processing component for expansion, normalization, and embedding generation. This stage can leverage cached embeddings for frequently requested queries.</p>\n</li>\n<li><p><strong>Parallel Index Search</strong>: With the processed query, the system performs parallel searches across the vector index (semantic search) and keyword index (lexical search) if hybrid ranking is enabled. These searches happen concurrently to minimize latency.</p>\n</li>\n<li><p><strong>Ranking Engine Coordination</strong>: Raw search results from both semantic and lexical searches are passed to the Ranking Engine for multi-stage ranking, personalization, and final result selection.</p>\n</li>\n<li><p><strong>Result Enhancement</strong>: The ranked results undergo highlighting, snippet generation, and metadata enrichment to produce rich result representations suitable for client consumption.</p>\n</li>\n<li><p><strong>Response Assembly</strong>: Final results are assembled into the standardized response format, including facet information if requested and analytics telemetry for later processing.</p>\n</li>\n</ol>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fapi-interaction.svg\" alt=\"Search API Interaction Flow\"></p>\n<p>The autocomplete request processing follows a streamlined path optimized for minimal latency:</p>\n<ol>\n<li><strong>Prefix Cache Lookup</strong>: Immediate lookup in the hot prefix cache for instant common completions</li>\n<li><strong>Semantic Expansion</strong>: If prefix cache is insufficient, semantic similarity computation against cached query embeddings</li>\n<li><strong>Personalization Filter</strong>: Optional filtering and reranking based on user context</li>\n<li><strong>Response Formatting</strong>: Final suggestion list assembly with highlighting and metadata</li>\n</ol>\n<p>The faceting request requires coordination with the search results to compute accurate counts:</p>\n<ol>\n<li><strong>Base Search Execution</strong>: Run the underlying search query to establish the result set</li>\n<li><strong>Facet Computation</strong>: Analyze result metadata to compute facet value distributions</li>\n<li><strong>Cache Update</strong>: Update facet cache entries for frequently requested combinations</li>\n<li><strong>Response Assembly</strong>: Format facet data with counts, selections, and UI hints</li>\n</ol>\n<p>Error handling across component interactions requires sophisticated coordination because failures can occur at multiple levels simultaneously. The API layer implements circuit breaker patterns and graceful degradation strategies.</p>\n<table>\n<thead>\n<tr>\n<th>Component Failure</th>\n<th>Detection Method</th>\n<th>Fallback Strategy</th>\n<th>User Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Processing</td>\n<td>Timeout or exception</td>\n<td>Use raw query text</td>\n<td>Reduced semantic understanding</td>\n</tr>\n<tr>\n<td>Vector Index</td>\n<td>Search failure</td>\n<td>Lexical-only search</td>\n<td>Missing semantic matches</td>\n</tr>\n<tr>\n<td>Ranking Engine</td>\n<td>Processing error</td>\n<td>Basic similarity ranking</td>\n<td>Reduced personalization</td>\n</tr>\n<tr>\n<td>Highlighting</td>\n<td>Analysis failure</td>\n<td>Plain text snippets</td>\n<td>No term highlighting</td>\n</tr>\n</tbody></table>\n<p>The analytics collection system operates as a completely separate data flow that doesn&#39;t impact primary search functionality. All search requests generate analytics events that are queued asynchronously and processed in background threads.</p>\n<p>Internal component communication follows standardized interfaces that enable independent testing and development. Each component exposes well-defined methods with clear contracts for parameters, return values, and error conditions.</p>\n<table>\n<thead>\n<tr>\n<th>Component Interface</th>\n<th>Method Signature</th>\n<th>Purpose</th>\n<th>Error Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>QueryProcessor.process_query()</code></td>\n<td><code>(query_text: str, context: Dict) -&gt; ProcessedQuery</code></td>\n<td>Query enhancement</td>\n<td>Malformed input, processing timeout</td>\n</tr>\n<tr>\n<td><code>EmbeddingIndex.search()</code></td>\n<td><code>(embedding: np.ndarray, k: int) -&gt; List[SearchResult]</code></td>\n<td>Vector similarity search</td>\n<td>Index unavailable, embedding mismatch</td>\n</tr>\n<tr>\n<td><code>RankingEngine.rank_documents()</code></td>\n<td><code>(query: ProcessedQuery, candidates: List) -&gt; List[SearchResult]</code></td>\n<td>Multi-stage ranking</td>\n<td>Ranking model failure, context error</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Component Timeout Cascades</strong>\nWhen one component experiences latency issues, timeouts can cascade through the entire search request processing pipeline, resulting in user-visible failures even when most components are functioning correctly. Implement independent timeouts for each component interaction with appropriate fallback strategies. If query processing takes too long, fall back to simple query handling. If personalized ranking fails, use generic ranking. Users prefer fast, basic results to slow, sophisticated results or error messages.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>Search API implementation involves several subtle pitfalls that can significantly impact user experience and system performance:</p>\n<p>⚠️ <strong>Pitfall: Autocomplete Cache Staleness</strong>\nAutocomplete suggestions can become stale when new content is indexed but the autocomplete cache isn&#39;t updated correspondingly. Users start seeing suggestions for content that no longer exists or missing suggestions for recently added content. Implement cache invalidation triggered by index updates, or use short TTL values (15-30 minutes) for autocomplete cache entries. Monitor cache hit rates—if they drop significantly, it may indicate cache invalidation issues.</p>\n<p>⚠️ <strong>Pitfall: Facet Count Inconsistency</strong>\nFacet counts may not sum to the total result count due to documents matching multiple facet values or having missing metadata. This confuses users who expect mathematical consistency. Always include an &quot;Other&quot; or &quot;Uncategorized&quot; facet for documents that don&#39;t match standard facet values, and clearly document that documents can appear in multiple facets. Consider showing overlapping counts explicitly rather than hiding the complexity.</p>\n<p>⚠️ <strong>Pitfall: Response Size Explosion</strong>\nAs search functionality grows sophisticated, response sizes can grow dramatically with detailed ranking signals, multiple snippet options, and comprehensive facet information. Large responses impact network performance and client parsing time. Implement response size monitoring and consider pagination or lazy loading for detailed metadata. Provide client options to control response verbosity—basic clients may only need titles and URLs, while advanced clients benefit from full metadata.</p>\n<p>⚠️ <strong>Pitfall: Error Message Information Leakage</strong>\nDetailed error messages that help developers debug can inadvertently expose system internals or sensitive information to end users. Database connection failures, file system paths, or internal component names should not appear in public API responses. Implement error message sanitization that provides helpful information to developers (in logs) while showing generic, safe messages to end users. Include correlation IDs so support can link user reports to detailed internal logs.</p>\n<p>⚠️ <strong>Pitfall: Analytics Overhead Creep</strong>\nAnalytics collection often starts lightweight but gradually adds more detailed tracking that eventually impacts search performance. This happens because each analytics addition seems minor individually, but collectively they can slow request processing significantly. Regularly audit analytics collection overhead and ensure all tracking remains asynchronous. Set strict CPU and memory budgets for analytics code—if tracking exceeds these budgets, simplify the collection or move it to background processing.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The Search API implementation focuses on building production-ready endpoints that deliver excellent user experience while maintaining system performance and reliability.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Web Framework</td>\n<td>Flask with JSON responses</td>\n<td>FastAPI with automatic OpenAPI docs</td>\n</tr>\n<tr>\n<td>Request Validation</td>\n<td>Manual parameter checking</td>\n<td>Pydantic models with validation</td>\n</tr>\n<tr>\n<td>Caching Layer</td>\n<td>In-memory Python dictionaries</td>\n<td>Redis with TTL and invalidation</td>\n</tr>\n<tr>\n<td>Analytics Storage</td>\n<td>SQLite with periodic aggregation</td>\n<td>ClickHouse for high-volume analytics</td>\n</tr>\n<tr>\n<td>Rate Limiting</td>\n<td>Flask-Limiter with memory backend</td>\n<td>Redis-based distributed rate limiting</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  api/\n    __init__.py\n    main.py                    ← FastAPI app and route definitions\n    models/\n      __init__.py\n      requests.py              ← QueryRequest, AutocompleteRequest models\n      responses.py             ← QueryResponse, SearchResult models\n    endpoints/\n      __init__.py\n      search.py                ← Primary search endpoint logic\n      autocomplete.py          ← Typeahead and suggestion logic\n      facets.py                ← Faceted navigation endpoints\n      analytics.py             ← Analytics and monitoring endpoints\n    middleware/\n      __init__.py\n      rate_limiting.py         ← Request rate limiting middleware\n      error_handling.py        ← Centralized error handling\n      analytics_collection.py  ← Request telemetry collection\n    utils/\n      __init__.py\n      highlighting.py          ← Query term highlighting logic\n      response_formatting.py   ← Result formatting utilities\n      cache_management.py      ← Cache warming and invalidation\n  tests/\n    api/\n      test_search_endpoints.py\n      test_autocomplete.py\n      test_analytics.py</code></pre></div>\n\n<p><strong>Infrastructure Starter Code - FastAPI Application Setup:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> fastapi </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> FastAPI, HTTPException, Depends</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> fastapi.middleware.cors </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> CORSMiddleware</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> fastapi.responses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> JSONResponse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asynccontextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .models.requests </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryRequest, AutocompleteRequest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .models.responses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryResponse, AutocompleteResponse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .middleware.rate_limiting </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> RateLimiter</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .middleware.analytics_collection </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> AnalyticsCollector</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .utils.cache_management </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> CacheManager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global component instances</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">search_components </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@asynccontextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> lifespan</span><span style=\"color:#E1E4E8\">(app: FastAPI):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Startup: Initialize all search components</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    from</span><span style=\"color:#E1E4E8\"> query_processing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryProcessor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    from</span><span style=\"color:#E1E4E8\"> embedding_index </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> EmbeddingIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    from</span><span style=\"color:#E1E4E8\"> ranking_engine </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> RankingEngine</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_components[</span><span style=\"color:#9ECBFF\">\"query_processor\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueryProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_components[</span><span style=\"color:#9ECBFF\">\"embedding_index\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EmbeddingIndex.load_from_disk(</span><span style=\"color:#9ECBFF\">\"./data/index\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_components[</span><span style=\"color:#9ECBFF\">\"ranking_engine\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> RankingEngine()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_components[</span><span style=\"color:#9ECBFF\">\"cache_manager\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CacheManager(</span><span style=\"color:#FFAB70\">max_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10000</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_components[</span><span style=\"color:#9ECBFF\">\"analytics\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AnalyticsCollector()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Start background tasks</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    asyncio.create_task(search_components[</span><span style=\"color:#9ECBFF\">\"cache_manager\"</span><span style=\"color:#E1E4E8\">].start_cache_warming())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    asyncio.create_task(search_components[</span><span style=\"color:#9ECBFF\">\"analytics\"</span><span style=\"color:#E1E4E8\">].start_background_processing())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    yield</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Shutdown: Clean up resources</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    await</span><span style=\"color:#E1E4E8\"> search_components[</span><span style=\"color:#9ECBFF\">\"analytics\"</span><span style=\"color:#E1E4E8\">].flush_pending_events()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_components[</span><span style=\"color:#9ECBFF\">\"cache_manager\"</span><span style=\"color:#E1E4E8\">].shutdown()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">app </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> FastAPI(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    title</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Semantic Search API\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    description</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Production-ready semantic search with autocomplete and analytics\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    version</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"1.0.0\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    lifespan</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">lifespan</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Add CORS middleware</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">app.add_middleware(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    CORSMiddleware,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    allow_origins</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"*\"</span><span style=\"color:#E1E4E8\">],  </span><span style=\"color:#6A737D\"># Configure appropriately for production</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    allow_credentials</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    allow_methods</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"GET\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"POST\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">    allow_headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"*\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global error handler</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@app.exception_handler</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> global_exception_handler</span><span style=\"color:#E1E4E8\">(request, exc):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    correlation_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> getattr</span><span style=\"color:#E1E4E8\">(request.state, </span><span style=\"color:#9ECBFF\">\"correlation_id\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"unknown\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unhandled exception </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">correlation_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(exc)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> JSONResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        content</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"Internal server error\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"correlation_id\"</span><span style=\"color:#E1E4E8\">: correlation_id}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Dependency for component access</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> get_search_components</span><span style=\"color:#E1E4E8\">() -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> search_components</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Rate limiting dependency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">rate_limiter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> RateLimiter(</span><span style=\"color:#FFAB70\">max_requests</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">window_seconds</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> rate_limit_dependency</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#F97583\"> await</span><span style=\"color:#E1E4E8\"> rate_limiter.is_allowed():</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> HTTPException(</span><span style=\"color:#FFAB70\">status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">429</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">detail</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Rate limit exceeded\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton - Main Search Endpoint:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> fastapi </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> APIRouter, Depends, HTTPException</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models.requests </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryRequest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models.responses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryResponse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.highlighting </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> highlight_query_terms</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..utils.response_formatting </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> format_search_results</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">router </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> APIRouter()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@router.post</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/search\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@router.get</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/search\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> search_documents</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request: QueryRequest,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    components: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Depends(get_search_components),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _: </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Depends(rate_limit_dependency)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">) -> QueryResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Execute semantic search query and return ranked results.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Handles both GET and POST requests for maximum compatibility.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    GET requests parse query parameters, POST requests accept JSON body.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate and normalize the search request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check query_text is not empty and not too long (max 500 chars)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Apply default values for max_results (20), filters (empty dict)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Validate filter values are in expected format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use len(request.query_text.strip()) to check meaningful content</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Process the query through QueryProcessor</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call components[\"query_processor\"].process_query(request.query_text, context)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Handle ProcessingTimeout exceptions with fallback to simple query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Log query processing time for performance monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Build context dict from request.personalization_context and filters</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Execute parallel search across vector and keyword indices</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Call embedding_index.search() with processed query embedding</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - If hybrid search enabled, also call keyword_index.search()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Combine results maintaining candidate provenance (which index)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use asyncio.gather() to run searches concurrently</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply multi-stage ranking to search candidates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Pass candidates to ranking_engine.rank_documents()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Include personalization_context for personalized ranking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Handle ranking failures by falling back to similarity-only ranking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: ranking_engine needs processed_query, candidates, and context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate result snippets and highlighting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - For each ranked result, extract relevant text snippet</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Apply query term highlighting using highlight_query_terms()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Handle highlighting failures gracefully with plain text fallback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Snippet should be 150-200 chars with query context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Compute facet information if requested</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - If request.include_facets, analyze result metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Group by category, content_type, date ranges, etc.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Cache computed facets for frequently requested combinations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Only compute facets for top 1000 results to control latency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Assemble final response with analytics tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Format results using format_search_results() utility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Record search analytics asynchronously</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Include processing time and result count in response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Analytics should not impact response time - fire and forget</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        processing_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return QueryResponse with all computed information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Include query, results, total_found, processing_time_ms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Add facets if requested, None otherwise</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Ensure all response fields match QueryResponse model</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Handle errors with appropriate HTTP status codes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - ValidationError -> 400 Bad Request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - TimeoutError -> 504 Gateway Timeout  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - ComponentUnavailable -> 503 Service Unavailable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Log full error details but return sanitized user message</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        processing_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Search error after </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">processing_time</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        raise</span><span style=\"color:#E1E4E8\"> HTTPException(</span><span style=\"color:#FFAB70\">status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">detail</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Search temporarily unavailable\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton - Autocomplete Endpoint:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">@router.get</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"/api/v1/autocomplete\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> get_autocomplete_suggestions</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_suggestions: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    personalization_context: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># JSON string for GET requests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    components: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Depends(get_search_components),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    _: </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Depends(rate_limit_dependency)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">) -> AutocompleteResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provide fast autocomplete suggestions for partial queries.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Must respond within 100ms to maintain good user experience.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Uses hybrid prefix matching + semantic similarity approach.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate and sanitize input parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Check query is not empty, limit length to 100 chars</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Ensure max_suggestions is reasonable (1-20)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Parse personalization_context JSON if provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Strip whitespace and convert to lowercase for consistency</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check prefix cache for instant responses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Look up query prefix in hot cache (tries structure)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - If found and cache entry is fresh, return immediately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - This should handle 80%+ of autocomplete requests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use normalized query (lowercase, no extra spaces) as cache key</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Perform semantic similarity matching for cache misses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Generate lightweight embedding for partial query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Find similar complete queries from semantic cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Combine with prefix matches, avoiding duplicates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Limit semantic computation to stay within 100ms budget</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply personalization filtering if context provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Rerank suggestions based on user preferences</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Boost suggestions matching user's recent queries or clicks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Filter out suggestions inappropriate for user context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Personalization should be precomputed to avoid latency impact</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Format suggestions with highlighting and metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Highlight the portion matching user's partial input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Include suggestion category/type if available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Sort by relevance score combining popularity and similarity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Format as {\"suggestion\": \"...\", \"highlight\": \"...\", \"type\": \"...\"}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update cache asynchronously with new suggestions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Cache the computed suggestions for this prefix</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Update frequency counts for suggestion popularity ranking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Don't let cache update impact response time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Fire-and-forget cache update in background task</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        processing_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return formatted autocomplete response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Include suggestions array, processing time for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Log slow requests (>80ms) for performance investigation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # - Ensure response format matches AutocompleteResponse model</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> processing_time </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 80</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logging.warning(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Slow autocomplete: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">processing_time</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms for query '</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">query</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        processing_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Autocomplete error after </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">processing_time</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Return empty suggestions rather than error for better UX</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> AutocompleteResponse(</span><span style=\"color:#FFAB70\">suggestions</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[], </span><span style=\"color:#FFAB70\">processing_time_ms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">processing_time)</span></span></code></pre></div>\n\n<p><strong>Language-Specific Implementation Hints:</strong></p>\n<ul>\n<li><p><strong>FastAPI Request Handling</strong>: Use <code>@router.get</code> and <code>@router.post</code> decorators on the same function for dual GET/POST support. FastAPI automatically handles parameter parsing from query string vs JSON body.</p>\n</li>\n<li><p><strong>Async Background Tasks</strong>: Use <code>asyncio.create_task()</code> for fire-and-forget operations like analytics collection. Never await these tasks in the request path.</p>\n</li>\n<li><p><strong>Response Time Monitoring</strong>: Use <code>time.perf_counter()</code> for high-precision timing. Log requests exceeding SLA thresholds (search &gt;500ms, autocomplete &gt;100ms).</p>\n</li>\n<li><p><strong>Error Handling</strong>: Use FastAPI&#39;s <code>HTTPException</code> for client errors. Log full exception details but return sanitized messages to prevent information leakage.</p>\n</li>\n<li><p><strong>Rate Limiting</strong>: Implement using Redis for distributed deployments or in-memory counters for single-instance deployments. Use sliding window counters for smooth rate limiting.</p>\n</li>\n</ul>\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the Search API component, verify the following behavior:</p>\n<ol>\n<li><strong>Search Endpoint Testing</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> \"http://localhost:8000/api/v1/search\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        -d</span><span style=\"color:#9ECBFF\"> '{\"query_text\": \"machine learning algorithms\", \"max_results\": 10, \"include_facets\": true}'</span></span></code></pre></div>\n<p>   Expected: JSON response with results array, facets object, processing time &lt;500ms</p>\n<ol start=\"2\">\n<li><strong>Autocomplete Performance</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   curl</span><span style=\"color:#9ECBFF\"> \"http://localhost:8000/api/v1/autocomplete?query=mach\"</span></span></code></pre></div>\n<p>   Expected: Suggestions array returned in &lt;100ms, suggestions relevant to partial query</p>\n<ol start=\"3\">\n<li><p><strong>Analytics Collection</strong>: Check that search requests generate analytics events without impacting response times. Monitor background processing queues.</p>\n</li>\n<li><p><strong>Error Handling</strong>: Test with malformed requests, very long queries, and missing parameters. All should return appropriate HTTP status codes with helpful error messages.</p>\n</li>\n</ol>\n<p>Signs that something is wrong:</p>\n<ul>\n<li>Response times consistently exceed SLA targets (search &gt;500ms, autocomplete &gt;100ms)</li>\n<li>Error responses contain system internals or file paths</li>\n<li>Analytics collection impacts search performance</li>\n<li>Autocomplete suggestions are stale or irrelevant</li>\n<li>Facet counts don&#39;t reflect actual result distributions</li>\n</ul>\n<h2 id=\"component-interactions-and-data-flow\">Component Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), showing how the components built in each milestone interact to form a cohesive semantic search engine system.</p>\n</blockquote>\n<p>The <strong>Component Interactions and Data Flow</strong> section reveals the dynamic choreography that transforms static components into a living, breathing search engine. Think of this section as the conductor&#39;s score for an orchestra — while previous sections defined each instrument (component) and its capabilities, this section shows how they play together in harmony to create the complete symphony of semantic search.</p>\n<p>Understanding component interactions is crucial because semantic search engines involve complex data transformations across multiple stages. A single search query triggers a cascade of operations: text normalization, embedding generation, vector similarity computation, hybrid scoring, cross-encoder reranking, and result formatting. Each component must coordinate precisely with others, passing the right data at the right time while maintaining performance and reliability guarantees.</p>\n<p>The challenge lies in managing the inherent complexity of multi-stage processing while preserving the illusion of simplicity for users. When someone types a query and expects results in under 500 milliseconds, our system must orchestrate document embedding pipelines that may have processed millions of texts, coordinate between lexical and semantic search indices, apply personalization signals, and format results — all while handling failures gracefully and maintaining consistency.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Fsystem-architecture.svg\" alt=\"System Architecture Overview\"></p>\n<h3 id=\"document-indexing-workflow\">Document Indexing Workflow</h3>\n<p>The <strong>document indexing workflow</strong> represents the foundational data pipeline that transforms raw text documents into searchable vector representations. Think of this process like a sophisticated book cataloging system in a research library. When new books arrive, they don&#39;t immediately become searchable — they must go through acquisition, cataloging, classification, and shelving before researchers can discover them. Similarly, our document indexing workflow takes raw text through embedding generation, vector normalization, and index integration before queries can find them.</p>\n<p>The indexing workflow operates as a multi-stage pipeline where each component performs specialized transformations on the document data. This design enables parallel processing, fault tolerance through checkpointing, and incremental updates without full index reconstruction. The workflow must handle documents of varying sizes, from short product descriptions to lengthy technical papers, while maintaining consistent embedding quality and processing performance.</p>\n<p><img src=\"/api/project/semantic-search/architecture-doc/asset?path=diagrams%2Findexing-flow.svg\" alt=\"Document Indexing Flow\"></p>\n<p>The complete document indexing workflow follows this sequence:</p>\n<ol>\n<li><p><strong>Document Ingestion</strong>: Raw documents enter the system through the Document Processor component, which validates format, extracts metadata, and assigns unique document identifiers. The processor handles multiple input formats (JSON, CSV, XML) and normalizes them into the standard <code>Document</code> structure.</p>\n</li>\n<li><p><strong>Text Preprocessing</strong>: The <code>TextProcessor</code> component cleans and normalizes document content by removing HTML tags, handling URL patterns, normalizing whitespace, and preparing text for optimal embedding generation. This step ensures consistent input quality for the embedding model.</p>\n</li>\n<li><p><strong>Searchable Text Extraction</strong>: The system calls <code>get_searchable_text()</code> to combine document title and content into a unified text representation. This method applies intelligent concatenation rules that weight titles more heavily while preserving content context.</p>\n</li>\n<li><p><strong>Embedding Generation</strong>: The <code>DocumentEncoder</code> component processes the cleaned text through the transformer model using the <code>encode_document()</code> method. This step generates dense vector representations that capture semantic meaning in the configured embedding space.</p>\n</li>\n<li><p><strong>Vector Normalization</strong>: All generated embeddings pass through <code>normalize_vector()</code> to ensure unit length, enabling efficient cosine similarity computation during search operations. Normalization is critical for consistent similarity scoring across documents.</p>\n</li>\n<li><p><strong>Index Integration</strong>: The normalized embeddings are added to the vector index using the chosen algorithm (HNSW or IVF). This step involves updating the index data structures, maintaining metadata mappings, and potentially triggering index optimization procedures.</p>\n</li>\n<li><p><strong>Persistence and Backup</strong>: The updated index state is persisted to disk using memory-mapped files for efficient access. The system maintains both the vector index and document metadata store with consistent backup procedures.</p>\n</li>\n</ol>\n<p>The document indexing workflow handles various data formats and error conditions through structured message passing between components:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Input Message</th>\n<th>Output Message</th>\n<th>Error Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Document Processor</td>\n<td>Raw document data (JSON/CSV/XML)</td>\n<td><code>Document</code> with validated fields</td>\n<td>Malformed data → Skip with warning log</td>\n</tr>\n<tr>\n<td>Text Processor</td>\n<td><code>Document.content</code> and <code>Document.title</code></td>\n<td>Cleaned text string</td>\n<td>Empty content → Use title only</td>\n</tr>\n<tr>\n<td>Document Encoder</td>\n<td>Cleaned text string</td>\n<td><code>DocumentEmbedding</code> with vector</td>\n<td>Encoding failure → Retry with truncated text</td>\n</tr>\n<tr>\n<td>Vector Index</td>\n<td><code>DocumentEmbedding</code></td>\n<td>Index position ID</td>\n<td>Index full → Trigger background optimization</td>\n</tr>\n<tr>\n<td>Persistence Layer</td>\n<td>Updated index state</td>\n<td>Confirmation status</td>\n<td>Write failure → Rollback to previous state</td>\n</tr>\n</tbody></table>\n<p>The workflow implements several critical error handling and recovery mechanisms:</p>\n<p><strong>Batch Processing Recovery</strong>: When processing large document collections, the system maintains progress checkpoints every 1000 documents. If processing fails, the workflow resumes from the last successful checkpoint rather than restarting from the beginning.</p>\n<p><strong>Embedding Model Failures</strong>: If the transformer model encounters out-of-memory errors or timeout issues, the system automatically retries with truncated text (up to model&#39;s maximum token limit) and logs the truncation for quality monitoring.</p>\n<p><strong>Index Capacity Management</strong>: As the vector index approaches memory limits, the system triggers background optimization procedures that compress the index structure and archive less frequently accessed vectors to secondary storage.</p>\n<p><strong>Consistency Guarantees</strong>: The workflow ensures that document metadata and vector embeddings remain synchronized through transactional updates. If vector insertion succeeds but metadata update fails, the system rolls back the vector insertion to maintain consistency.</p>\n<blockquote>\n<p><strong>Key Design Insight</strong>: The document indexing workflow prioritizes fault tolerance over raw speed because index corruption is far more expensive to recover from than slower initial processing. Each stage includes rollback capabilities and data validation checkpoints.</p>\n</blockquote>\n<h3 id=\"search-request-processing-flow\">Search Request Processing Flow</h3>\n<p>The <strong>search request processing flow</strong> orchestrates the complex sequence of operations that transform a user&#39;s query into ranked, relevant results. Think of this process like a reference librarian who not only understands what you&#39;re asking for but also knows how to navigate multiple catalogs, cross-reference related materials, and present findings in the most useful order. The search flow must coordinate between linguistic analysis, vector operations, multiple scoring systems, and result formatting while meeting strict latency requirements.</p>\n<p>The search processing pipeline operates under the constraint that users expect sub-second response times, which means every component must optimize for speed while maintaining result quality. This creates tension between thoroughness and performance — we want to apply sophisticated query understanding and comprehensive ranking, but we cannot afford expensive operations that delay response delivery.</p>\n<p>The complete search request processing flow follows this detailed sequence:</p>\n<ol>\n<li><p><strong>Request Validation and Parsing</strong>: The Search API receives the <code>QueryRequest</code> and validates parameters including query length (maximum <code>MAX_QUERY_LENGTH</code> characters), result count limits, and filter format. Malformed requests are rejected immediately with descriptive error messages.</p>\n</li>\n<li><p><strong>Query Normalization</strong>: The <code>TextNormalizer</code> component processes the raw query text using <code>normalize_query()</code> to handle case normalization, whitespace cleanup, and technical term preservation. This step ensures consistent query representation for caching and processing.</p>\n</li>\n<li><p><strong>Cache Lookup</strong>: The <code>EmbeddingCache</code> checks for previously computed embeddings using both exact query matching and normalized query matching through the <code>get()</code> method. Cache hits significantly reduce latency by skipping expensive embedding computation.</p>\n</li>\n<li><p><strong>Query Processing Pipeline</strong>: For cache misses, the <code>QueryProcessor</code> executes the full <code>process_query()</code> pipeline, including synonym expansion, entity recognition, intent classification, and multi-vector query decomposition. This produces a rich <code>ProcessedQuery</code> structure with multiple semantic representations.</p>\n</li>\n<li><p><strong>Primary Embedding Generation</strong>: The system generates the primary query embedding using <code>encode_query()</code> and normalizes it with <code>normalize_vector()</code> to ensure compatibility with the indexed document embeddings.</p>\n</li>\n<li><p><strong>Vector Similarity Search</strong>: The embedding index performs approximate nearest neighbor search to retrieve the top candidate documents based on cosine similarity scores. This step typically returns 2-5x more candidates than the final result count to enable effective reranking.</p>\n</li>\n<li><p><strong>Multi-Signal Scoring</strong>: The ranking engine computes multiple relevance signals for each candidate document, including semantic similarity scores, BM25 lexical scores, personalization signals, and freshness scores using the <code>score_candidate()</code> method.</p>\n</li>\n<li><p><strong>Signal Combination</strong>: The <code>combine_signals()</code> method merges individual ranking signals into hybrid scores using learned weights that vary by query type and user context. This produces an initial ranked candidate list.</p>\n</li>\n<li><p><strong>Cross-Encoder Reranking</strong>: For the highest-scoring candidates (typically top 50-100), the system applies precise cross-encoder reranking using <code>rerank_candidates()</code> to refine the ordering with more sophisticated semantic understanding.</p>\n</li>\n<li><p><strong>Result Formatting</strong>: The final ranked results are formatted using <code>format_search_results()</code> to generate snippets, highlight query terms, and include relevance metadata in the <code>QueryResponse</code> structure.</p>\n</li>\n<li><p><strong>Analytics and Learning</strong>: The system records search analytics and updates click-through learning models asynchronously to avoid impacting response latency.</p>\n</li>\n</ol>\n<p>The search flow manages complex data transformations through well-defined interfaces between components:</p>\n<table>\n<thead>\n<tr>\n<th>Processing Stage</th>\n<th>Component</th>\n<th>Input Data</th>\n<th>Output Data</th>\n<th>Latency Budget</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Validation</td>\n<td>Search API</td>\n<td>HTTP request body</td>\n<td><code>QueryRequest</code> object</td>\n<td>5ms</td>\n</tr>\n<tr>\n<td>Query Processing</td>\n<td>Query Processor</td>\n<td><code>QueryRequest.query_text</code></td>\n<td><code>ProcessedQuery</code> with embeddings</td>\n<td>100ms</td>\n</tr>\n<tr>\n<td>Vector Search</td>\n<td>Embedding Index</td>\n<td><code>ProcessedQuery.primary_embedding</code></td>\n<td>Candidate document list</td>\n<td>50ms</td>\n</tr>\n<tr>\n<td>Multi-Signal Scoring</td>\n<td>Ranking Engine</td>\n<td>Candidates + <code>ProcessedQuery</code></td>\n<td><code>RankingCandidate</code> list</td>\n<td>200ms</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranking</td>\n<td>Ranking Engine</td>\n<td>Top candidates + query</td>\n<td>Refined ranking</td>\n<td>100ms</td>\n</tr>\n<tr>\n<td>Result Formatting</td>\n<td>Search API</td>\n<td>Ranked candidates</td>\n<td><code>QueryResponse</code> JSON</td>\n<td>20ms</td>\n</tr>\n<tr>\n<td><strong>Total Latency</strong></td>\n<td></td>\n<td></td>\n<td></td>\n<td><strong>475ms (under 500ms SLA)</strong></td>\n</tr>\n</tbody></table>\n<p>The search processing flow implements sophisticated error handling and graceful degradation:</p>\n<p><strong>Embedding Generation Failures</strong>: If query embedding generation fails due to model unavailability or timeout, the system falls back to lexical search only, using BM25 scoring against indexed document text. Users receive results with a warning about reduced semantic matching.</p>\n<p><strong>Index Unavailability</strong>: When the vector index is temporarily unavailable (during updates or due to hardware issues), the system serves results using only the lexical search index with expanded query terms. Response times remain acceptable while semantic accuracy is reduced.</p>\n<p><strong>Ranking Engine Overload</strong>: If cross-encoder reranking cannot complete within the latency budget, the system returns results based only on multi-signal scoring. This maintains response time guarantees while slightly reducing result precision.</p>\n<p><strong>Partial Component Failures</strong>: The system tracks component health and adjusts processing pipelines dynamically. For example, if personalization scoring fails, the system continues with semantic and lexical signals only, ensuring core search functionality remains available.</p>\n<blockquote>\n<p><strong>Critical Performance Insight</strong>: The search processing flow achieves sub-second latency through aggressive parallelization of independent operations. Semantic similarity search, BM25 scoring, and personalization scoring run concurrently, with results synchronized before signal combination.</p>\n</blockquote>\n<p><strong>Query Processing State Management</strong>: The search flow maintains detailed state information throughout processing to enable debugging and optimization:</p>\n<table>\n<thead>\n<tr>\n<th>Processing Phase</th>\n<th>State Information</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request Receipt</td>\n<td>Correlation ID, timestamp, client IP</td>\n<td>Request tracking and rate limiting</td>\n</tr>\n<tr>\n<td>Query Analysis</td>\n<td>Normalized query, detected entities, expansion terms</td>\n<td>Debugging query understanding issues</td>\n</tr>\n<tr>\n<td>Vector Operations</td>\n<td>Embedding vectors, similarity scores, candidate counts</td>\n<td>Performance monitoring and tuning</td>\n</tr>\n<tr>\n<td>Ranking Computation</td>\n<td>Individual signal scores, combination weights</td>\n<td>Result quality analysis</td>\n</tr>\n<tr>\n<td>Response Generation</td>\n<td>Final scores, snippet generation, formatting time</td>\n<td>End-to-end performance optimization</td>\n</tr>\n</tbody></table>\n<h3 id=\"internal-component-apis\">Internal Component APIs</h3>\n<p>The <strong>internal component APIs</strong> define the precise interface contracts that enable our search engine components to communicate reliably and efficiently. Think of these APIs as the diplomatic protocols between neighboring countries — they establish the exact format, timing, and expectations for every interaction, preventing misunderstandings that could lead to system failures or degraded performance.</p>\n<p>These internal APIs differ fundamentally from public REST APIs because they prioritize performance, type safety, and rich error information over simplicity and broad compatibility. Internal APIs can make assumptions about network reliability, use binary serialization for efficiency, and include detailed context information that helps with debugging and optimization.</p>\n<p>The internal API design follows several key principles: <strong>type safety</strong> through strongly typed message structures, <strong>performance optimization</strong> through efficient serialization and minimal data copying, <strong>observability</strong> through comprehensive context propagation, and <strong>fault tolerance</strong> through explicit error modeling and timeout handling.</p>\n<h4 id=\"document-processing-apis\">Document Processing APIs</h4>\n<p>The document processing APIs handle the flow of documents from ingestion through embedding generation to index integration. These APIs must handle high-throughput batch operations while maintaining individual document error tracking:</p>\n<table>\n<thead>\n<tr>\n<th>Method Signature</th>\n<th>Component</th>\n<th>Purpose</th>\n<th>Error Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>process_document(doc: Document) -&gt; ProcessingResult</code></td>\n<td>Document Processor</td>\n<td>Validate and normalize document</td>\n<td>Returns validation errors with field-level details</td>\n</tr>\n<tr>\n<td><code>clean_text(text: str) -&gt; str</code></td>\n<td>Text Processor</td>\n<td>Clean document content for embedding</td>\n<td>Never fails; returns cleaned text even for malformed input</td>\n</tr>\n<tr>\n<td><code>encode_document(document: Document) -&gt; DocumentEmbedding</code></td>\n<td>Document Encoder</td>\n<td>Generate vector embedding</td>\n<td>Retries with truncated text; raises ModelUnavailableError</td>\n</tr>\n<tr>\n<td><code>add_document(embedding: DocumentEmbedding) -&gt; IndexPosition</code></td>\n<td>Vector Index</td>\n<td>Insert into search index</td>\n<td>Raises IndexFullError if capacity exceeded</td>\n</tr>\n<tr>\n<td><code>persist_index(checkpoint: str) -&gt; PersistenceResult</code></td>\n<td>Storage Layer</td>\n<td>Save index to disk</td>\n<td>Provides detailed disk space and I/O error information</td>\n</tr>\n</tbody></table>\n<p>The <code>DocumentEmbedding</code> message structure carries comprehensive metadata between processing stages:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Required</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>document</code></td>\n<td><code>Document</code></td>\n<td>Original document reference</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td><code>embedding</code></td>\n<td><code>np.ndarray</code></td>\n<td>Normalized vector representation</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td><code>model_name</code></td>\n<td><code>str</code></td>\n<td>Embedding model identifier</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td><code>embedding_dim</code></td>\n<td><code>int</code></td>\n<td>Vector dimensionality</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td><code>processing_time_ms</code></td>\n<td><code>float</code></td>\n<td>Generation latency</td>\n<td>No</td>\n</tr>\n<tr>\n<td><code>text_length</code></td>\n<td><code>int</code></td>\n<td>Input text character count</td>\n<td>No</td>\n</tr>\n<tr>\n<td><code>truncation_applied</code></td>\n<td><code>bool</code></td>\n<td>Whether text was truncated</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h4 id=\"query-processing-apis\">Query Processing APIs</h4>\n<p>The query processing APIs coordinate the complex transformation of user queries into rich semantic representations. These APIs emphasize caching efficiency and detailed query analysis:</p>\n<table>\n<thead>\n<tr>\n<th>Method Signature</th>\n<th>Component</th>\n<th>Purpose</th>\n<th>Caching Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>normalize_query(query: str) -&gt; str</code></td>\n<td>Text Normalizer</td>\n<td>Standardize query format</td>\n<td>Results cached for 1 hour</td>\n</tr>\n<tr>\n<td><code>process_query(query_text: str, context: Dict) -&gt; ProcessedQuery</code></td>\n<td>Query Processor</td>\n<td>Full query analysis pipeline</td>\n<td>Expensive; aggressive caching</td>\n</tr>\n<tr>\n<td><code>expand_query_terms(terms: List[str], entities: List[str]) -&gt; List[Tuple[str, float]]</code></td>\n<td>Synonym Expander</td>\n<td>Add related terms</td>\n<td>Cached per term with confidence scores</td>\n</tr>\n<tr>\n<td><code>encode_query(query_text: str) -&gt; np.ndarray</code></td>\n<td>Document Encoder</td>\n<td>Generate query embedding</td>\n<td>Cached with normalized query as key</td>\n</tr>\n<tr>\n<td><code>get(query: str, normalized_query: str) -&gt; Optional[np.ndarray]</code></td>\n<td>Embedding Cache</td>\n<td>Retrieve cached embedding</td>\n<td>LRU eviction with TTL</td>\n</tr>\n</tbody></table>\n<p>The <code>ProcessedQuery</code> structure serves as the central data exchange format for query analysis results:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Populated By</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>original_query</code></td>\n<td><code>str</code></td>\n<td>Unmodified user input</td>\n<td>Query Processor</td>\n</tr>\n<tr>\n<td><code>normalized_query</code></td>\n<td><code>str</code></td>\n<td>Cleaned, standardized text</td>\n<td>Text Normalizer</td>\n</tr>\n<tr>\n<td><code>primary_embedding</code></td>\n<td><code>np.ndarray</code></td>\n<td>Main semantic representation</td>\n<td>Document Encoder</td>\n</tr>\n<tr>\n<td><code>expanded_terms</code></td>\n<td><code>List[Tuple[str, float]]</code></td>\n<td>Synonyms with confidence</td>\n<td>Synonym Expander</td>\n</tr>\n<tr>\n<td><code>entities</code></td>\n<td><code>List[Tuple[str, str]]</code></td>\n<td>Recognized entities and types</td>\n<td>Entity Recognizer</td>\n</tr>\n<tr>\n<td><code>intent</code></td>\n<td><code>str</code></td>\n<td>Classified query intent</td>\n<td>Intent Classifier</td>\n</tr>\n<tr>\n<td><code>negative_terms</code></td>\n<td><code>List[str]</code></td>\n<td>Terms to exclude from results</td>\n<td>Query Analyzer</td>\n</tr>\n<tr>\n<td><code>multi_vector_components</code></td>\n<td><code>Optional[List[Tuple[str, np.ndarray, float]]]</code></td>\n<td>Complex query decomposition</td>\n<td>Multi-Vector Handler</td>\n</tr>\n<tr>\n<td><code>processing_metadata</code></td>\n<td><code>Dict[str, Any]</code></td>\n<td>Debugging and optimization data</td>\n<td>All components</td>\n</tr>\n</tbody></table>\n<h4 id=\"ranking-and-retrieval-apis\">Ranking and Retrieval APIs</h4>\n<p>The ranking APIs orchestrate the complex multi-stage process of candidate retrieval, signal computation, and result optimization. These APIs balance thoroughness with performance constraints:</p>\n<table>\n<thead>\n<tr>\n<th>Method Signature</th>\n<th>Component</th>\n<th>Purpose</th>\n<th>Performance Characteristics</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>search_similar(embedding: np.ndarray, k: int) -&gt; List[Tuple[str, float]]</code></td>\n<td>Vector Index</td>\n<td>Approximate nearest neighbors</td>\n<td>Sub-50ms for k≤1000</td>\n</tr>\n<tr>\n<td><code>score_candidate(document: Document, query: ProcessedQuery, context: PersonalizationContext) -&gt; RankingSignals</code></td>\n<td>Ranking Engine</td>\n<td>Compute all relevance signals</td>\n<td>Parallelized across candidates</td>\n</tr>\n<tr>\n<td><code>combine_signals(signals: RankingSignals, query_type: str) -&gt; float</code></td>\n<td>Ranking Engine</td>\n<td>Merge signals into final score</td>\n<td>Learned weights per query type</td>\n</tr>\n<tr>\n<td><code>rerank_candidates(candidates: List[RankingCandidate], query_text: str) -&gt; List[RankingCandidate]</code></td>\n<td>Cross-Encoder</td>\n<td>Precise semantic reranking</td>\n<td>Limited to top 100 candidates</td>\n</tr>\n<tr>\n<td><code>record_interaction(query: str, results: List[SearchResult], click_position: int) -&gt; None</code></td>\n<td>Learning System</td>\n<td>Update ranking models</td>\n<td>Asynchronous; never blocks search</td>\n</tr>\n</tbody></table>\n<p>The <code>RankingSignals</code> structure captures all computed relevance factors:</p>\n<table>\n<thead>\n<tr>\n<th>Signal Field</th>\n<th>Type</th>\n<th>Range</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>semantic_score</code></td>\n<td><code>float</code></td>\n<td>0.0-1.0</td>\n<td>Cosine similarity between query and document</td>\n</tr>\n<tr>\n<td><code>bm25_score</code></td>\n<td><code>float</code></td>\n<td>0.0-∞</td>\n<td>Lexical relevance from keyword matching</td>\n</tr>\n<tr>\n<td><code>personalization_score</code></td>\n<td><code>float</code></td>\n<td>0.0-1.0</td>\n<td>User preference and context matching</td>\n</tr>\n<tr>\n<td><code>freshness_score</code></td>\n<td><code>float</code></td>\n<td>0.0-1.0</td>\n<td>Time-based relevance decay</td>\n</tr>\n<tr>\n<td><code>click_score</code></td>\n<td><code>Optional[float]</code></td>\n<td>0.0-1.0</td>\n<td>Historical click-through rate adjustment</td>\n</tr>\n<tr>\n<td><code>quality_score</code></td>\n<td><code>Optional[float]</code></td>\n<td>0.0-1.0</td>\n<td>Document authority and reliability</td>\n</tr>\n</tbody></table>\n<h4 id=\"error-handling-and-context-propagation\">Error Handling and Context Propagation</h4>\n<p>All internal APIs implement consistent error handling patterns that preserve context information for debugging while enabling graceful degradation:</p>\n<p><strong>Structured Error Types</strong>: Each component defines specific error types that carry detailed context:</p>\n<table>\n<thead>\n<tr>\n<th>Error Type</th>\n<th>Component</th>\n<th>Context Information</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>EmbeddingGenerationError</code></td>\n<td>Document Encoder</td>\n<td>Model name, input length, timeout details</td>\n<td>Retry with truncated input</td>\n</tr>\n<tr>\n<td><code>IndexCapacityError</code></td>\n<td>Vector Index</td>\n<td>Current size, available memory, growth rate</td>\n<td>Trigger background optimization</td>\n</tr>\n<tr>\n<td><code>CacheEvictionError</code></td>\n<td>Embedding Cache</td>\n<td>Evicted entries, memory pressure</td>\n<td>Expand cache size or reduce TTL</td>\n</tr>\n<tr>\n<td><code>RankingTimeoutError</code></td>\n<td>Ranking Engine</td>\n<td>Processed candidates, remaining queue</td>\n<td>Return partial results</td>\n</tr>\n</tbody></table>\n<p><strong>Context Propagation</strong>: Every API call includes a <code>ContextInfo</code> parameter that tracks request flow:</p>\n<table>\n<thead>\n<tr>\n<th>Context Field</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Populated By</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>correlation_id</code></td>\n<td><code>str</code></td>\n<td>Unique request identifier</td>\n<td>API Gateway</td>\n</tr>\n<tr>\n<td><code>user_id</code></td>\n<td><code>Optional[str]</code></td>\n<td>User identification</td>\n<td>Authentication</td>\n</tr>\n<tr>\n<td><code>request_timestamp</code></td>\n<td><code>datetime</code></td>\n<td>Request initiation time</td>\n<td>API Gateway</td>\n</tr>\n<tr>\n<td><code>processing_budget_ms</code></td>\n<td><code>int</code></td>\n<td>Remaining time budget</td>\n<td>Search Coordinator</td>\n</tr>\n<tr>\n<td><code>quality_vs_speed</code></td>\n<td><code>str</code></td>\n<td>Performance preference</td>\n<td>Request parameters</td>\n</tr>\n</tbody></table>\n<p><strong>API Health Monitoring</strong>: All internal APIs expose health and performance metrics:</p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Examples</th>\n<th>Update Frequency</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Latency Percentiles</td>\n<td>p50, p95, p99 response times</td>\n<td>Per request</td>\n<td>Performance monitoring</td>\n</tr>\n<tr>\n<td>Error Rates</td>\n<td>Failures per component per minute</td>\n<td>Every 10 seconds</td>\n<td>Reliability tracking</td>\n</tr>\n<tr>\n<td>Resource Utilization</td>\n<td>CPU, memory, disk I/O per operation</td>\n<td>Every 30 seconds</td>\n<td>Capacity planning</td>\n</tr>\n<tr>\n<td>Cache Effectiveness</td>\n<td>Hit rates, eviction rates per cache</td>\n<td>Every minute</td>\n<td>Optimization guidance</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>API Design Philosophy</strong>: Internal APIs optimize for rich error information and debugging support over simplicity. When a search fails at 3 AM, the on-call engineer needs detailed context about what went wrong and where, not just a generic &quot;search failed&quot; message.</p>\n</blockquote>\n<p>The internal APIs support comprehensive request tracing through structured logging and metrics collection. Each API method logs entry and exit with parameter summaries, execution time, and result metadata. This creates an audit trail that enables performance analysis, error debugging, and system optimization.</p>\n<p><strong>API Versioning and Compatibility</strong>: Although these are internal APIs, they still require versioning as the system evolves:</p>\n<ul>\n<li><strong>Backward Compatibility</strong>: New API versions add fields but never remove existing fields within the same major version</li>\n<li><strong>Feature Flags</strong>: New functionality is introduced through optional parameters and feature flags before becoming standard</li>\n<li><strong>Graceful Degradation</strong>: APIs detect component version mismatches and adjust behavior accordingly</li>\n<li><strong>Migration Support</strong>: During upgrades, APIs support both old and new message formats simultaneously</li>\n</ul>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The component interactions require careful orchestration to maintain performance while ensuring reliability. This section provides the infrastructure and patterns needed to implement robust inter-component communication.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component Communication</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Internal APIs</td>\n<td>Direct Python method calls with type hints</td>\n<td>Protocol Buffers with async message queues</td>\n</tr>\n<tr>\n<td>Data Serialization</td>\n<td>JSON with Pydantic models</td>\n<td>Apache Arrow for large vector data</td>\n</tr>\n<tr>\n<td>Caching Layer</td>\n<td>Python dict with TTL wrapper</td>\n<td>Redis cluster with consistent hashing</td>\n</tr>\n<tr>\n<td>Error Handling</td>\n<td>Standard Python exceptions</td>\n<td>Structured error codes with context</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Python logging with correlation IDs</td>\n<td>OpenTelemetry with distributed tracing</td>\n</tr>\n</tbody></table>\n<h4 id=\"file-structure-for-component-communication\">File Structure for Component Communication</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>semantic-search/\n  internal/\n    communication/\n      __init__.py                    ← Export communication primitives  \n      message_types.py               ← All message data structures\n      api_interfaces.py              ← Abstract base classes for APIs\n      error_handling.py              ← Structured error types\n      context.py                     ← Request context propagation\n    \n    indexing/\n      workflow.py                    ← Document indexing orchestration\n      pipeline_stages.py             ← Individual processing stages\n      batch_processor.py             ← Batch processing with checkpoints\n    \n    search/\n      request_handler.py             ← Search request orchestration  \n      flow_coordinator.py            ← Multi-component coordination\n      result_assembler.py            ← Final result formatting\n    \n    monitoring/\n      metrics.py                     ← Performance and health metrics\n      tracing.py                     ← Request tracing utilities\n      health_checks.py               ← Component health monitoring\n\n  tests/\n    integration/\n      test_indexing_workflow.py      ← End-to-end indexing tests\n      test_search_flow.py            ← Complete search request tests</code></pre></div>\n\n<h4 id=\"message-types-infrastructure\">Message Types Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Any, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ContextInfo</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Request context propagated through all API calls.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    correlation_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(uuid.uuid4()))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    user_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request_timestamp: datetime </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.now)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_budget_ms: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 500</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    quality_vs_speed: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"balanced\"</span><span style=\"color:#6A737D\">  # \"speed\", \"balanced\", \"quality\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    component_trace: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProcessingResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Standard result wrapper for all processing operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    success: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data: Any </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_code: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_time_ms: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ContextInfo)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> IndexingMessage</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Message format for document indexing pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document: Document</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stage: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">  # \"validation\", \"embedding\", \"indexing\", \"persistence\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    result: ProcessingResult</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    checkpoint_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    retry_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ContextInfo)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchMessage</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Message format for search request pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    query_request: QueryRequest</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processed_query: Optional[ProcessedQuery] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    candidates: List[RankingCandidate] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    final_results: List[SearchResult] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    stage: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"received\"</span><span style=\"color:#6A737D\">  # \"received\", \"processed\", \"ranked\", \"formatted\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ContextInfo)</span></span></code></pre></div>\n\n<h4 id=\"component-communication-base-classes\">Component Communication Base Classes</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> abc </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> ABC</span><span style=\"color:#E1E4E8\">, abstractmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Protocol, runtime_checkable</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@runtime_checkable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentProcessor</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Protocol</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Interface contract for document processing components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_document</span><span style=\"color:#E1E4E8\">(self, doc: Document, context: ContextInfo) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process a single document through validation and normalization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_batch</span><span style=\"color:#E1E4E8\">(self, docs: List[Document], context: ContextInfo) -> List[ProcessingResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process multiple documents with checkpointing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_health_status</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return component health and performance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@runtime_checkable</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchCoordinator</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Protocol</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Interface contract for search request coordination.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_search_request</span><span style=\"color:#E1E4E8\">(self, request: QueryRequest, context: ContextInfo) -> QueryResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate complete search request processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_autocomplete_request</span><span style=\"color:#E1E4E8\">(self, request: AutocompleteRequest, context: ContextInfo) -> AutocompleteResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle typeahead autocomplete requests.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"error-handling-infrastructure\">Error Handling Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchEngineError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base exception for all search engine errors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, error_code: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: ContextInfo, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.error_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> error_code</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> component</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.now()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EmbeddingGenerationError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SearchEngineError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when embedding generation fails.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: ContextInfo, model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, text_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#9ECBFF\">\"EMBEDDING_FAILED\"</span><span style=\"color:#E1E4E8\">, context, </span><span style=\"color:#9ECBFF\">\"DocumentEncoder\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.model_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> model_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.text_length </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text_length</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> IndexCapacityError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SearchEngineError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raised when vector index reaches capacity limits.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, context: ContextInfo, current_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, max_capacity: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#9ECBFF\">\"INDEX_CAPACITY\"</span><span style=\"color:#E1E4E8\">, context, </span><span style=\"color:#9ECBFF\">\"VectorIndex\"</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.current_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_size</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_capacity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_capacity</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> handle_component_error</span><span style=\"color:#E1E4E8\">(error: </span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">, context: ContextInfo, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Standard error handling for component failures.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#79B8FF\"> isinstance</span><span style=\"color:#E1E4E8\">(error, SearchEngineError):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> ProcessingResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(error),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            error_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">error.error_code,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Wrap unexpected errors</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> ProcessingResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unexpected error in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">component</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(error)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            error_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"UNEXPECTED_ERROR\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            context</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">context</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span></code></pre></div>\n\n<h4 id=\"document-indexing-workflow-implementation\">Document Indexing Workflow Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DocumentIndexingWorkflow</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Orchestrates the complete document indexing pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, text_processor: TextProcessor, encoder: DocumentEncoder, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 vector_index, storage_layer):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.text_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text_processor</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> encoder  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.vector_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vector_index</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.storage_layer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> storage_layer</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.checkpoint_interval </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_document_batch</span><span style=\"color:#E1E4E8\">(self, documents: List[Document], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             context: ContextInfo) -> List[ProcessingResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Process a batch of documents through the complete indexing pipeline.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Implements checkpointing and error recovery.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize batch processing context and create checkpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each document, validate format and extract metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Clean document text using text_processor.clean_text()  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate embedding using encoder.encode_document()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Add embedding to vector index with error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update document metadata store with document info</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Create checkpoint every self.checkpoint_interval documents</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Handle partial failures - continue processing remaining docs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Persist final index state and return processing results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use try/except around each stage to isolate failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Maintain correlation_id throughout pipeline for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> resume_from_checkpoint</span><span style=\"color:#E1E4E8\">(self, checkpoint_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, remaining_docs: List[Document],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             context: ContextInfo) -> List[ProcessingResult]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Resume batch processing from a previous checkpoint.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load checkpoint state from storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify index consistency from checkpoint data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Continue processing from last successful document</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update context with checkpoint recovery information</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"search-request-flow-implementation\">Search Request Flow Implementation</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchRequestFlow</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Coordinates the complete search request processing pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, query_processor: QueryProcessor, vector_index,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 ranking_engine, result_formatter, embedding_cache: EmbeddingCache):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.query_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> query_processor</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.vector_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vector_index  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.ranking_engine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ranking_engine</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.result_formatter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> result_formatter</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.embedding_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> embedding_cache</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_search_request</span><span style=\"color:#E1E4E8\">(self, request: QueryRequest, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             context: ContextInfo) -> QueryResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Execute the complete search request processing pipeline.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Implements timeout handling and graceful degradation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate request parameters and initialize processing timer</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check embedding cache for query using normalized form</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If cache miss, run full query processing pipeline</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Execute vector similarity search with processed query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Compute multi-signal ranking scores for all candidates  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Apply cross-encoder reranking to top candidates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Format final results with snippets and highlighting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Record analytics and cache embeddings for future use</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Return formatted QueryResponse with timing information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Check context.processing_budget_ms before expensive operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Implement fallbacks if components timeout or fail</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_component_timeout</span><span style=\"color:#E1E4E8\">(self, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               context: ContextInfo) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle timeout scenarios with appropriate fallback strategies.\"\"\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Log timeout with component and operation details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Determine appropriate fallback strategy based on component</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Update context with degraded service information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return partial result with warning messages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"monitoring-and-health-checks\">Monitoring and Health Checks</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ComponentHealthMonitor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Monitors health and performance of all system components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component_metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.health_checks </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_api_call</span><span style=\"color:#E1E4E8\">(self, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, method: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       duration_ms: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, success: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, context: ContextInfo):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record API call metrics for monitoring.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Update latency percentiles for component.method</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Increment success/failure counters  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Track correlation_id for request tracing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Alert if error rates exceed thresholds</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> check_component_health</span><span style=\"color:#E1E4E8\">(self, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Perform health check on specified component.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test component's basic functionality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check resource utilization (CPU, memory)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify dependency connectivity  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return health status with detailed metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> trace_request_flow</span><span style=\"color:#E1E4E8\">(context: ContextInfo, component: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Decorator to automatically trace request flow through components.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> decorator</span><span style=\"color:#E1E4E8\">(func):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> wrapper</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Add component.operation to context.component_trace</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Record operation start time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Execute function with error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Record operation completion and duration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update monitoring metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> wrapper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> decorator</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>After implementing Document Indexing Workflow (Milestone 1):</strong></p>\n<ul>\n<li>Run <code>python -m pytest tests/integration/test_indexing_workflow.py</code></li>\n<li>Expected: All document processing stages complete successfully</li>\n<li>Verify: Index contains embedded documents with correct metadata</li>\n<li>Check: Checkpoint and recovery functionality works with partial failures</li>\n</ul>\n<p><strong>After implementing Search Request Flow (Milestone 2):</strong>  </p>\n<ul>\n<li>Run <code>python -m pytest tests/integration/test_search_flow.py</code></li>\n<li>Expected: Search requests return ranked results within timeout</li>\n<li>Verify: Component coordination works with proper error handling</li>\n<li>Check: Caching and performance optimizations function correctly</li>\n</ul>\n<p><strong>After implementing Component APIs (Milestones 3-4):</strong></p>\n<ul>\n<li>Run load test: <code>python scripts/load_test_search.py --requests 1000 --concurrency 10</code></li>\n<li>Expected: 95% of requests complete under 500ms</li>\n<li>Verify: Health monitoring detects component failures</li>\n<li>Check: Error handling provides actionable debugging information</li>\n</ul>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing robust error handling patterns that must be implemented throughout the embedding index (Milestone 1), query processing (Milestone 2), ranking engine (Milestone 3), and search API (Milestone 4).</p>\n</blockquote>\n<p>Production semantic search systems face numerous failure modes that can cascade across components, degrading user experience or causing complete service outages. Think of error handling in a semantic search engine like an emergency response system in a hospital — you need clear protocols for different types of failures, graceful degradation when specialized equipment fails, and backup procedures that maintain essential services even when advanced capabilities are unavailable.</p>\n<p>The challenge with semantic search error handling is the interdependency between components. Unlike traditional keyword search where index corruption might only affect specific terms, embedding model failures can render the entire semantic capability unusable. Similarly, ranking failures don&#39;t just return unsorted results — they can return completely irrelevant matches that destroy user trust. This section establishes comprehensive error handling strategies that maintain system availability while preserving search quality.</p>\n<h3 id=\"index-construction-failures\">Index Construction Failures</h3>\n<p>The embedding index represents the foundation of semantic search capabilities, making index construction failures particularly critical. These failures can occur during initial index creation, incremental updates, or model changes, each requiring different recovery strategies.</p>\n<p><strong>Embedding Model Failures</strong></p>\n<p>Embedding model failures represent the most fundamental type of index construction failure, as they prevent the conversion of text documents into searchable vector representations. These failures can manifest in several ways: model loading failures due to corrupted files or insufficient memory, inference failures during document encoding, and model API timeouts when using remote embedding services.</p>\n<blockquote>\n<p><strong>Decision: Embedding Model Fault Tolerance Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Embedding models can fail during loading, inference, or remote API calls, blocking entire index construction pipelines</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Fail-fast approach stopping all indexing on first model failure</li>\n<li>Retry-based approach with exponential backoff and circuit breakers</li>\n<li>Fallback model approach using simpler models when primary fails</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement retry-based approach with circuit breaker protection and optional fallback models</li>\n<li><strong>Rationale</strong>: Transient failures (network issues, temporary memory pressure) are common and recoverable, but persistent failures should trigger circuit breakers to prevent resource exhaustion</li>\n<li><strong>Consequences</strong>: Enables resilience to temporary issues while providing escape mechanisms for persistent failures, at the cost of increased complexity</li>\n</ul>\n</blockquote>\n<p>The <code>DocumentEncoder</code> component must implement robust error handling around model operations. When the primary embedding model fails, the system should attempt retries with exponential backoff, starting with a 1-second delay and doubling up to a maximum of 30 seconds. After three consecutive failures, a circuit breaker opens, temporarily bypassing embedding generation for that document and marking it for retry during the next indexing cycle.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Detection Method</th>\n<th>Immediate Response</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Model Load Failure</td>\n<td>Exception during SentenceTransformer initialization</td>\n<td>Log error, attempt fallback model</td>\n<td>Retry with exponential backoff, fallback to lighter model</td>\n</tr>\n<tr>\n<td>Inference Timeout</td>\n<td>Embedding generation exceeds 30-second timeout</td>\n<td>Cancel request, log timeout</td>\n<td>Add document to retry queue with shorter text</td>\n</tr>\n<tr>\n<td>Memory Exhaustion</td>\n<td>CUDA out-of-memory or system OOM during encoding</td>\n<td>Reduce batch size, trigger GC</td>\n<td>Process documents individually, consider model quantization</td>\n</tr>\n<tr>\n<td>Corrupted Model Files</td>\n<td>Hash mismatch or file read errors during loading</td>\n<td>Download fresh model files</td>\n<td>Verify checksums, re-download from official sources</td>\n</tr>\n<tr>\n<td>Remote API Failure</td>\n<td>HTTP errors or rate limiting from embedding service</td>\n<td>Implement circuit breaker</td>\n<td>Use local fallback model or queue for later processing</td>\n</tr>\n</tbody></table>\n<p>For memory-related failures, the system should implement dynamic batch size adjustment. When encoding fails due to memory constraints, the batch size is halved and the operation retried. This continues until either the operation succeeds or the batch size reaches 1. Documents that fail individual encoding are marked as problematic and routed through a separate error handling pipeline that attempts preprocessing steps like text truncation or content filtering.</p>\n<p><strong>Index Corruption and Recovery</strong></p>\n<p>Index corruption can occur due to hardware failures, incomplete write operations, or software bugs during index updates. The symptoms range from subtle degradation in search quality to complete index unusability. Detection requires both automated monitoring and explicit validation procedures.</p>\n<p>The system implements a multi-layered corruption detection strategy. During index construction, each major operation writes a checkpoint record containing metadata about the current state, including document count, vector dimensions, and operation timestamps. These checkpoints enable validation of index integrity and provide recovery points when corruption is detected.</p>\n<table>\n<thead>\n<tr>\n<th>Corruption Type</th>\n<th>Detection Method</th>\n<th>Symptoms</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Partial Write Failure</td>\n<td>Checkpoint validation mismatch</td>\n<td>Index reports fewer documents than expected</td>\n<td>Rollback to last valid checkpoint, replay from transaction log</td>\n</tr>\n<tr>\n<td>Vector Dimension Mismatch</td>\n<td>Dimension validation during search</td>\n<td>Search queries fail with dimension errors</td>\n<td>Rebuild affected index segments with correct model</td>\n</tr>\n<tr>\n<td>Metadata Inconsistency</td>\n<td>Cross-reference between index and document store</td>\n<td>Documents exist but not searchable</td>\n<td>Regenerate metadata from source documents</td>\n</tr>\n<tr>\n<td>File System Corruption</td>\n<td>Hash verification failures</td>\n<td>Random search failures or crashes</td>\n<td>Restore from backup, rebuild if necessary</td>\n</tr>\n<tr>\n<td>Index Format Version Conflict</td>\n<td>Version header validation</td>\n<td>Index loading fails with format errors</td>\n<td>Migrate index to current format or rebuild from source</td>\n</tr>\n</tbody></table>\n<p>The index persistence layer maintains multiple backup copies with different retention policies. Hot backups are created every hour during active indexing, warm backups daily, and cold backups weekly. Each backup includes both the index files and the associated metadata required for validation and recovery.</p>\n<p>When corruption is detected, the recovery process follows a structured approach:</p>\n<ol>\n<li><strong>Immediate Isolation</strong>: Mark the corrupted index segment as unavailable to prevent serving bad results</li>\n<li><strong>Impact Assessment</strong>: Determine which documents and queries are affected by the corruption</li>\n<li><strong>Fallback Activation</strong>: Route affected queries to backup index segments or alternative search methods</li>\n<li><strong>Recovery Planning</strong>: Choose between rollback to checkpoint, partial rebuild, or full reconstruction</li>\n<li><strong>Progressive Restoration</strong>: Gradually restore service as repairs complete, validating each step</li>\n<li><strong>Post-Recovery Validation</strong>: Run comprehensive tests to ensure full functionality restoration</li>\n</ol>\n<p><strong>Incremental Update Failures</strong></p>\n<p>Incremental index updates present unique challenges because they must maintain consistency between the existing index and new additions while handling partial failures gracefully. Update failures can leave the index in an inconsistent state where some documents are searchable while others are missing or corrupted.</p>\n<p>The system implements an atomic update mechanism using a two-phase commit protocol. During the preparation phase, new document embeddings are generated and staged in a temporary index segment. The commit phase merges the staged segment with the main index, updating all associated metadata structures. If any step fails, the entire update can be rolled back without affecting the existing index.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Incremental updates must never leave the index in a partially updated state. Either all documents in an update batch are successfully indexed, or none are. Partial updates create inconsistencies that are extremely difficult to diagnose and repair.</p>\n</blockquote>\n<p>The update failure recovery process maintains a transaction log of all attempted operations. Each update batch receives a unique transaction ID, and all operations within that batch are logged with sufficient detail to enable replay or rollback. When an update fails, the system can either replay the failed operations after addressing the underlying issue or rollback to the state before the update began.</p>\n<table>\n<thead>\n<tr>\n<th>Update Failure Type</th>\n<th>Cause</th>\n<th>Detection</th>\n<th>Recovery Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Embedding Generation Failure</td>\n<td>Model errors during new document processing</td>\n<td>Missing embeddings for expected documents</td>\n<td>Retry embedding generation, use fallback model if needed</td>\n</tr>\n<tr>\n<td>Index Merge Failure</td>\n<td>Disk space or I/O errors during segment merge</td>\n<td>Incomplete merge operations in transaction log</td>\n<td>Rollback merge, free disk space, retry with smaller batches</td>\n</tr>\n<tr>\n<td>Metadata Update Failure</td>\n<td>Database constraints or connection issues</td>\n<td>Metadata inconsistent with index contents</td>\n<td>Regenerate metadata from index, validate consistency</td>\n</tr>\n<tr>\n<td>Concurrent Update Conflict</td>\n<td>Multiple update processes modifying same segments</td>\n<td>Lock conflicts or version mismatches</td>\n<td>Queue conflicting updates, process sequentially</td>\n</tr>\n<tr>\n<td>Resource Exhaustion</td>\n<td>Memory or disk space depletion during update</td>\n<td>System resource monitoring alerts</td>\n<td>Pause updates, free resources, resume with reduced batch sizes</td>\n</tr>\n</tbody></table>\n<h3 id=\"search-time-error-handling\">Search-Time Error Handling</h3>\n<p>Search-time errors require different handling strategies than index construction failures because they directly impact user experience and must be resolved within strict latency constraints. The system must provide graceful degradation that maintains some level of search functionality even when advanced features fail.</p>\n<p><strong>Component Unavailability Handling</strong></p>\n<p>Modern semantic search systems involve multiple cooperating components, and any component failure can disrupt the search experience. The key insight is that different components contribute different value to search quality, enabling prioritized degradation strategies.</p>\n<p>Think of component availability like a restaurant kitchen during a busy evening. If the specialized pastry chef is unavailable, you don&#39;t shut down the entire restaurant — you remove desserts from the menu and focus on delivering excellent main courses. Similarly, if the cross-encoder reranking component fails, the system should continue providing semantic search results without the precision boost of neural reranking.</p>\n<p>The search request flow implements a timeout and fallback strategy for each component. When a component doesn&#39;t respond within its allocated time budget, the system logs the failure and continues processing with degraded capabilities. The final search results include metadata indicating which components were available, allowing clients to adjust their expectations and possibly retry later.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Primary Function</th>\n<th>Failure Impact</th>\n<th>Fallback Strategy</th>\n<th>User Experience</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Processor</td>\n<td>Query expansion and normalization</td>\n<td>Reduced recall, no synonym matching</td>\n<td>Use original query directly</td>\n<td>Slightly less comprehensive results</td>\n</tr>\n<tr>\n<td>Embedding Index</td>\n<td>Semantic similarity search</td>\n<td>No semantic understanding</td>\n<td>Fall back to lexical BM25 search</td>\n<td>Keyword-only search, vocabulary mismatch issues</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranker</td>\n<td>Precision ranking of top candidates</td>\n<td>Lower result quality</td>\n<td>Use semantic similarity scores only</td>\n<td>Good results but less precise ordering</td>\n</tr>\n<tr>\n<td>Personalization Engine</td>\n<td>User-specific result customization</td>\n<td>Generic results for all users</td>\n<td>Return non-personalized rankings</td>\n<td>Relevant but not customized results</td>\n</tr>\n<tr>\n<td>Autocomplete Service</td>\n<td>Typeahead query suggestions</td>\n<td>No search assistance</td>\n<td>Disable autocomplete feature</td>\n<td>Users must type complete queries</td>\n</tr>\n</tbody></table>\n<p>The <code>SearchMessage</code> processing pipeline includes circuit breaker patterns for each component integration. When a component fails repeatedly, its circuit breaker opens, automatically routing traffic around the failing component without waiting for timeouts. Circuit breakers include health check mechanisms that periodically test component availability and close the circuit when service is restored.</p>\n<p><strong>Timeout and Latency Management</strong></p>\n<p>Search systems operate under strict latency constraints, requiring aggressive timeout management to prevent slow components from degrading overall user experience. The system implements hierarchical timeouts that allocate time budgets to different processing stages based on their importance and expected execution time.</p>\n<p>The total search request timeout of 500ms is divided among components based on their criticality and typical processing time. Query processing receives 50ms, embedding generation 100ms, vector search 150ms, ranking 150ms, and result formatting 50ms. These budgets include buffer time for network communication and potential retries.</p>\n<blockquote>\n<p><strong>Decision: Timeout Allocation Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Limited 500ms search timeout must be allocated across multiple processing stages with varying importance</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Equal time allocation across all components</li>\n<li>Priority-based allocation with more time for critical components</li>\n<li>Adaptive allocation based on historical performance</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Fixed priority-based allocation with monitoring for future adaptive improvements</li>\n<li><strong>Rationale</strong>: Predictable performance is more important than optimal resource utilization in user-facing search applications</li>\n<li><strong>Consequences</strong>: Provides consistent user experience but may underutilize fast components when slow components are struggling</li>\n</ul>\n</blockquote>\n<p>When components exceed their timeout budgets, the system implements different strategies based on the processing stage. Early-stage timeouts (query processing, embedding generation) trigger fallback to simpler approaches. Late-stage timeouts (ranking, result formatting) return partial results with degraded quality rather than failing completely.</p>\n<p>The timeout management includes adaptive mechanisms that adjust budgets based on system load and performance trends. During high-load periods, non-essential components receive reduced time budgets to ensure core functionality remains responsive. The system tracks timeout frequencies and automatically increases budgets for components that consistently exceed their allocations due to legitimate processing complexity.</p>\n<p><strong>Partial Result Handling</strong></p>\n<p>Partial results occur when some components successfully process a search request while others fail or timeout. The system must decide whether to return incomplete results immediately or attempt additional processing to improve quality. This decision depends on the specific failures, result quality, and remaining time budget.</p>\n<p>The partial result evaluation uses a quality scoring mechanism that assesses result completeness across multiple dimensions: result count, relevance confidence, ranking signal availability, and personalization completeness. Results that meet minimum quality thresholds are returned immediately with appropriate metadata indicating their limitations.</p>\n<table>\n<thead>\n<tr>\n<th>Partial Result Type</th>\n<th>Quality Assessment</th>\n<th>Return Decision</th>\n<th>User Notification</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Reduced Result Count</td>\n<td>Less than requested max results</td>\n<td>Return if above minimum threshold (5 results)</td>\n<td>&quot;Showing N results (some sources temporarily unavailable)&quot;</td>\n</tr>\n<tr>\n<td>Missing Personalization</td>\n<td>Generic results without user customization</td>\n<td>Return with depersonalized ranking</td>\n<td>No explicit notification, log for analysis</td>\n</tr>\n<tr>\n<td>Degraded Ranking</td>\n<td>BM25 only without semantic reranking</td>\n<td>Return with warning about result quality</td>\n<td>&quot;Results may be less relevant due to temporary service issues&quot;</td>\n</tr>\n<tr>\n<td>Missing Facets</td>\n<td>Search results without category filtering</td>\n<td>Return results, disable faceted navigation</td>\n<td>Remove facet UI elements, show basic results</td>\n</tr>\n<tr>\n<td>Incomplete Highlighting</td>\n<td>Results without query term highlighting</td>\n<td>Return plain text snippets</td>\n<td>Show results without highlighted terms</td>\n</tr>\n</tbody></table>\n<p>The system maintains result quality metrics that track partial result frequency and user satisfaction. When partial results become frequent, automated alerts notify operators of potential systemic issues requiring investigation. The metrics differentiate between acceptable degradation (minor feature unavailability) and problematic degradation (significantly reduced result quality).</p>\n<h3 id=\"edge-case-query-handling\">Edge Case Query Handling</h3>\n<p>User queries exhibit enormous variety and often test system boundaries in unexpected ways. Robust query handling requires anticipating edge cases and implementing graceful responses that guide users toward successful searches rather than presenting cryptic errors.</p>\n<p><strong>Empty and Malformed Query Processing</strong></p>\n<p>Empty queries represent one of the most common edge cases, occurring when users submit search forms without entering text, when text processing removes all meaningful content, or when queries contain only stop words or punctuation. The system must distinguish between truly empty queries and queries that become empty after processing.</p>\n<p>The query validation pipeline implements multi-stage filtering that preserves user intent while handling malformed input. Raw query text first undergoes basic sanitization to remove control characters and excessive whitespace. The resulting text is then analyzed for meaningful content, considering factors like minimum length requirements, presence of alphanumeric characters, and language detection confidence.</p>\n<table>\n<thead>\n<tr>\n<th>Query Type</th>\n<th>Example</th>\n<th>Processing Result</th>\n<th>User Response</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Completely Empty</td>\n<td>&quot;&quot; (empty string)</td>\n<td>Return trending/popular results</td>\n<td>&quot;Here are some popular searches to get you started&quot;</td>\n</tr>\n<tr>\n<td>Whitespace Only</td>\n<td>&quot;   \\n\\t  &quot;</td>\n<td>Normalize to empty, treat as above</td>\n<td>Same as completely empty</td>\n</tr>\n<tr>\n<td>Only Punctuation</td>\n<td>&quot;!@#$%^&amp;*()&quot;</td>\n<td>Remove punctuation, treat as empty</td>\n<td>&quot;Please enter search terms using letters or numbers&quot;</td>\n</tr>\n<tr>\n<td>Only Stop Words</td>\n<td>&quot;the and or but&quot;</td>\n<td>Preserve original query for context</td>\n<td>Process as phrase search despite low content value</td>\n</tr>\n<tr>\n<td>Mixed Valid/Invalid</td>\n<td>&quot;hello @@@ world&quot;</td>\n<td>Clean to &quot;hello world&quot;</td>\n<td>Process cleaned version normally</td>\n</tr>\n<tr>\n<td>Non-ASCII Characters</td>\n<td>&quot;café naïve résumé&quot;</td>\n<td>Preserve Unicode, validate encoding</td>\n<td>Process normally with proper character handling</td>\n</tr>\n<tr>\n<td>Control Characters</td>\n<td>&quot;hello\\x00world\\x01&quot;</td>\n<td>Strip control chars, preserve content</td>\n<td>Clean and process &quot;helloworld&quot;</td>\n</tr>\n</tbody></table>\n<p>For queries that become empty after processing, the system provides contextual assistance rather than error messages. Default responses include trending searches, category suggestions, or recently popular queries relevant to the user&#39;s context. This approach transforms a potential failure into a discovery opportunity.</p>\n<p>The malformed query recovery includes spell checking and suggestion generation. When queries contain apparent typos or unusual character combinations, the system generates suggested corrections and presents them alongside search results. For queries with encoding issues or corrupted characters, the system attempts character set detection and conversion before falling back to error responses.</p>\n<p><strong>Query Length and Complexity Limits</strong></p>\n<p>Extremely long queries pose challenges for embedding generation, memory usage, and processing latency. The system implements multiple layers of query length management that balance comprehensive query understanding with performance requirements.</p>\n<p>The maximum query length of 500 characters represents a balance between supporting complex queries and preventing resource exhaustion. Queries exceeding this limit are truncated using intelligent strategies that preserve the most important query components. The truncation process identifies key phrases, proper nouns, and technical terms that should be preserved, removing common words and redundant phrases as needed.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Query truncation must preserve user intent, not just maintain arbitrary length limits. A query about &quot;machine learning algorithms for natural language processing in healthcare applications&quot; should preserve the domain-specific terms even if common words are removed.</p>\n</blockquote>\n<p>Very long queries often indicate specific information needs that benefit from different processing strategies. Instead of treating them as single semantic units, the system decomposes complex queries into multiple semantic components that can be processed independently and combined during ranking.</p>\n<table>\n<thead>\n<tr>\n<th>Query Length</th>\n<th>Processing Strategy</th>\n<th>Example Handling</th>\n<th>Performance Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>0-50 characters</td>\n<td>Standard processing</td>\n<td>Single embedding, full expansion</td>\n<td>Minimal overhead</td>\n</tr>\n<tr>\n<td>51-200 characters</td>\n<td>Enhanced processing</td>\n<td>Multi-phrase analysis, selective expansion</td>\n<td>Moderate overhead</td>\n</tr>\n<tr>\n<td>201-500 characters</td>\n<td>Complex processing</td>\n<td>Query decomposition, component weighting</td>\n<td>Higher latency</td>\n</tr>\n<tr>\n<td>501+ characters</td>\n<td>Truncation required</td>\n<td>Preserve key terms, truncate padding</td>\n<td>Prevent timeout</td>\n</tr>\n<tr>\n<td>Extremely long (1000+)</td>\n<td>Aggressive truncation</td>\n<td>Extract key concepts only</td>\n<td>Maintain responsiveness</td>\n</tr>\n</tbody></table>\n<p>The query complexity analysis identifies several patterns that require special handling: multiple questions within a single query, queries with complex boolean logic, queries mixing multiple languages, and queries containing both structured and unstructured components. Each pattern triggers specialized processing pipelines optimized for that query type.</p>\n<p><strong>Special Character and Encoding Issues</strong></p>\n<p>Modern search systems must handle queries containing diverse character sets, emoji, special symbols, and potentially corrupted text. The challenge is preserving meaningful content while preventing security issues and processing failures.</p>\n<p>The character processing pipeline implements multiple validation and normalization stages. Initial validation checks for proper UTF-8 encoding and attempts correction for common encoding problems. Character normalization handles Unicode equivalence issues, ensuring that different representations of the same character are treated consistently.</p>\n<p>Emoji and symbol handling requires domain-specific knowledge about their semantic meaning. Technical queries containing mathematical symbols, programming operators, or chemical formulas need different processing than casual queries with decorative emoji. The system maintains context-aware symbol handling that preserves meaning in technical domains while normalizing decorative elements.</p>\n<table>\n<thead>\n<tr>\n<th>Character Type</th>\n<th>Processing Approach</th>\n<th>Example</th>\n<th>Result</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Standard ASCII</td>\n<td>No processing needed</td>\n<td>&quot;hello world&quot;</td>\n<td>&quot;hello world&quot;</td>\n</tr>\n<tr>\n<td>Extended Latin</td>\n<td>Unicode normalization</td>\n<td>&quot;café naïve&quot;</td>\n<td>&quot;café naïve&quot;</td>\n</tr>\n<tr>\n<td>Technical Symbols</td>\n<td>Preserve in technical contexts</td>\n<td>&quot;c++ programming&quot;</td>\n<td>&quot;c++ programming&quot;</td>\n</tr>\n<tr>\n<td>Mathematical Notation</td>\n<td>Convert to searchable terms</td>\n<td>&quot;E=mc²&quot;</td>\n<td>&quot;E=mc² energy mass&quot;</td>\n</tr>\n<tr>\n<td>Emoji in Context</td>\n<td>Semantic interpretation</td>\n<td>&quot;python 🐍 programming&quot;</td>\n<td>&quot;python snake programming&quot;</td>\n</tr>\n<tr>\n<td>Mixed Scripts</td>\n<td>Language detection per segment</td>\n<td>&quot;hello 你好 world&quot;</td>\n<td>Process each script appropriately</td>\n</tr>\n<tr>\n<td>Corrupted Encoding</td>\n<td>Attempt repair or removal</td>\n<td>&quot;caf\\xc3\\xa9&quot;</td>\n<td>&quot;café&quot; (if repairable)</td>\n</tr>\n</tbody></table>\n<p>Security considerations include preventing injection attacks through specially crafted Unicode sequences and ensuring that character processing doesn&#39;t create buffer overflows or infinite loops. The system implements strict limits on character processing complexity and validates all text transformations to prevent exploitation.</p>\n<p>The encoding error recovery attempts automatic detection and correction for common encoding problems like double-encoding, wrong charset interpretation, and truncated multi-byte sequences. When automatic correction fails, the system gracefully degrades by removing problematic characters while preserving as much meaningful content as possible.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The error handling implementation spans all system components, requiring consistent patterns and shared infrastructure for failure detection, reporting, and recovery. This guidance provides the foundational error handling code that supports all milestones while allowing each component to implement domain-specific error handling logic.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Error Types</td>\n<td>Standard Python exceptions</td>\n<td>Custom exception hierarchy with error codes</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Python logging module</td>\n<td>Structured logging with correlation IDs</td>\n</tr>\n<tr>\n<td>Circuit Breakers</td>\n<td>Simple counter-based implementation</td>\n<td>Libraries like PyBreaker or Tenacity</td>\n</tr>\n<tr>\n<td>Retries</td>\n<td>Basic retry loops with sleep</td>\n<td>Tenacity library with exponential backoff</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Print statements and log files</td>\n<td>Prometheus metrics with Grafana dashboards</td>\n</tr>\n<tr>\n<td>Health Checks</td>\n<td>HTTP endpoint returning status</td>\n<td>Comprehensive health check framework</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  src/\n    semantic_search/\n      core/\n        errors.py              ← Custom exception types and error handling utilities\n        monitoring.py          ← Health checks and metrics collection\n        retry.py              ← Retry logic and circuit breakers\n      index/\n        error_handlers.py     ← Index-specific error handling\n      query/\n        error_handlers.py     ← Query processing error handling\n      ranking/\n        error_handlers.py     ← Ranking component error handling\n      api/\n        error_handlers.py     ← API-specific error handling\n        middleware.py         ← Request/response error middleware\n  tests/\n    error_scenarios/          ← Error simulation and recovery tests\n      test_index_failures.py\n      test_search_degradation.py\n      test_edge_cases.py</code></pre></div>\n\n<p><strong>Core Error Handling Infrastructure:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/semantic_search/core/errors.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core error handling infrastructure for semantic search engine.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides consistent error types, context tracking, and recovery patterns.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Any, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ErrorSeverity</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Severity levels for error classification and response.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    LOW</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"low\"</span><span style=\"color:#6A737D\">           # Degraded functionality, user barely notices</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MEDIUM</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"medium\"</span><span style=\"color:#6A737D\">     # Reduced functionality, user experience affected</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HIGH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"high\"</span><span style=\"color:#6A737D\">         # Major functionality loss, user experience poor</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CRITICAL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"critical\"</span><span style=\"color:#6A737D\"> # System unusable, immediate attention required</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ComponentType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"System components for error tracking and circuit breaker management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    EMBEDDING_MODEL</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"embedding_model\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    VECTOR_INDEX</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"vector_index\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    QUERY_PROCESSOR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"query_processor\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    RANKING_ENGINE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"ranking_engine\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    SEARCH_API</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"search_api\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ContextInfo</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Processing context information for error correlation and debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    correlation_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    user_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request_timestamp: datetime</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_budget_ms: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    quality_vs_speed: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"balanced\"</span><span style=\"color:#6A737D\">  # \"speed\", \"balanced\", \"quality\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    component_trace: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.component_trace </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.component_trace </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ProcessingResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Standardized result wrapper for all component operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    success: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    data: Any</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_code: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_time_ms: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: Optional[ContextInfo] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SemanticSearchError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base exception for all semantic search system errors.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, error_code: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 component: ComponentType </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, severity: ErrorSeverity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ErrorSeverity.</span><span style=\"color:#79B8FF\">MEDIUM</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, original_error: </span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.error_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> error_code </span><span style=\"color:#F97583\">or</span><span style=\"color:#9ECBFF\"> \"GENERIC_ERROR\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> component</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.severity </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> severity</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.context </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> context</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.original_error </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> original_error</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.now()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EmbeddingModelError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SemanticSearchError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Errors related to embedding model loading, inference, or configuration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#FFAB70\">component</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ComponentType.</span><span style=\"color:#79B8FF\">EMBEDDING_MODEL</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.model_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> model_name</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> IndexCorruptionError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SemanticSearchError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Errors indicating vector index corruption or inconsistency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, index_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#FFAB70\">component</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ComponentType.</span><span style=\"color:#79B8FF\">VECTOR_INDEX</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        severity</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ErrorSeverity.</span><span style=\"color:#79B8FF\">HIGH</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index_path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryProcessingError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SemanticSearchError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Errors during query parsing, expansion, or embedding generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#FFAB70\">component</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ComponentType.</span><span style=\"color:#79B8FF\">QUERY_PROCESSOR</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.query_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> query_text</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RankingError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SemanticSearchError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Errors during result ranking or relevance computation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#FFAB70\">component</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ComponentType.</span><span style=\"color:#79B8FF\">RANKING_ENGINE</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchAPIError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">SemanticSearchError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"API-level errors including validation, formatting, and response generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, message: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().</span><span style=\"color:#79B8FF\">__init__</span><span style=\"color:#E1E4E8\">(message, </span><span style=\"color:#FFAB70\">component</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ComponentType.</span><span style=\"color:#79B8FF\">SEARCH_API</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> create_context</span><span style=\"color:#E1E4E8\">(user_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, processing_budget_ms: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 500</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                   quality_vs_speed: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"balanced\"</span><span style=\"color:#E1E4E8\">) -> ContextInfo:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create processing context with unique correlation ID.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> ContextInfo(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        correlation_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(uuid.uuid4()),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        user_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">user_id,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        request_timestamp</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.now(),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        processing_budget_ms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">processing_budget_ms,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        quality_vs_speed</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">quality_vs_speed,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        component_trace</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> wrap_result</span><span style=\"color:#E1E4E8\">(func):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Decorator to wrap function results in ProcessingResult objects.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> wrapper</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            processing_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ProcessingResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                data</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                processing_time_ms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">processing_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            processing_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> ProcessingResult(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                success</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                data</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">getattr</span><span style=\"color:#E1E4E8\">(e, </span><span style=\"color:#9ECBFF\">'error_code'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'UNKNOWN_ERROR'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                processing_time_ms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">processing_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> wrapper</span></span></code></pre></div>\n\n<p><strong>Circuit Breaker and Retry Logic:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/semantic_search/core/retry.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Retry logic and circuit breaker patterns for fault-tolerant component integration.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Implements exponential backoff, circuit breakers, and timeout management.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Callable, Any, Optional, Dict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> threading </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Lock</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreakerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for circuit breaker behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failure_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#6A737D\">      # Failures before opening circuit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    success_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#6A737D\">      # Successes needed to close circuit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timeout_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#6A737D\">       # Time to wait before retry attempts</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    half_open_max_calls: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">    # Max calls to allow in half-open state</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RetryConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for retry behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_attempts: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    base_delay_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_delay_seconds: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    exponential_base: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    jitter: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreakerState</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CLOSED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"closed\"</span><span style=\"color:#6A737D\">      # Normal operation, failures counted</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    OPEN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"open\"</span><span style=\"color:#6A737D\">          # Circuit open, calls rejected immediately</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HALF_OPEN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"half_open\"</span><span style=\"color:#6A737D\">  # Testing if service recovered</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreaker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Circuit breaker implementation for component fault tolerance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, config: CircuitBreakerConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> CircuitBreakerConfig()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">CLOSED</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.failure_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.success_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.last_failure_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.half_open_calls </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Lock()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> can_execute</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if execution is allowed based on current circuit state.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">CLOSED</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">OPEN</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._should_attempt_reset():</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">HALF_OPEN</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.half_open_calls </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">HALF_OPEN</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.half_open_calls </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.half_open_max_calls</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_success</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record successful operation, potentially closing the circuit.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.failure_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">HALF_OPEN</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.success_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.success_count </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.success_threshold:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">CLOSED</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.success_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_failure</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record failed operation, potentially opening the circuit.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.failure_count </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.last_failure_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.now()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.failure_count </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.failure_threshold:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">OPEN</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">HALF_OPEN</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreakerState.</span><span style=\"color:#79B8FF\">OPEN</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.success_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _should_attempt_reset</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if enough time has passed to attempt circuit reset.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.last_failure_time </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.now() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.last_failure_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> elapsed.total_seconds() </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.timeout_seconds</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ComponentClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for fault-tolerant component clients with retry and circuit breaking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, component_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 circuit_config: CircuitBreakerConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 retry_config: RetryConfig </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.component_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> component_name</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.circuit_breaker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> CircuitBreaker(component_name, circuit_config)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.retry_config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> retry_config </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> RetryConfig()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.call_stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_calls\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"successful_calls\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"failed_calls\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"circuit_open_rejections\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> execute_with_fallback</span><span style=\"color:#E1E4E8\">(self, operation: Callable, fallback: Callable </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute operation with circuit breaker protection and optional fallback.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if circuit breaker allows execution</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If not allowed, record rejection and try fallback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Execute operation with retry logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Record success/failure with circuit breaker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: If primary fails and fallback exists, try fallback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return ProcessingResult with success/failure info</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _execute_with_retry</span><span style=\"color:#E1E4E8\">(self, operation: Callable, context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Any:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute operation with exponential backoff retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Loop through retry attempts (max_attempts)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Try operation, return result if successful</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If failure, calculate delay with exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add jitter to delay if configured</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Sleep for calculated delay before next attempt</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: If all attempts fail, raise last exception</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_health_status</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get component health and circuit breaker status.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"component\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.component_name,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"circuit_state\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.circuit_breaker.state,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"failure_count\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.circuit_breaker.failure_count,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"call_stats\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.call_stats,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"last_failure\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.circuit_breaker.last_failure_time.isoformat() </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                          if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.circuit_breaker.last_failure_time </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span></code></pre></div>\n\n<p><strong>Query Edge Case Handlers:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># src/semantic_search/query/error_handlers.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Query processing error handlers for edge cases and malformed input.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Handles empty queries, length limits, character encoding issues.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> unicodedata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, List, Tuple, Dict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryValidationResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Result of query validation with sanitized text and warnings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_valid: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sanitized_query: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    warnings: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    suggestions: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QuerySanitizer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles query cleaning and normalization for edge cases.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Common patterns for query cleaning</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.control_char_pattern </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">[</span><span style=\"color:#85E89D;font-weight:bold\">\\x00</span><span style=\"color:#79B8FF\">-</span><span style=\"color:#85E89D;font-weight:bold\">\\x1f\\x7f</span><span style=\"color:#79B8FF\">-</span><span style=\"color:#85E89D;font-weight:bold\">\\x9f</span><span style=\"color:#79B8FF\">]</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.excessive_whitespace </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\s</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.punctuation_only </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">^[</span><span style=\"color:#F97583\">^</span><span style=\"color:#79B8FF\">\\w\\s]</span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\">$</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">, re.</span><span style=\"color:#79B8FF\">UNICODE</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.stop_words </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'english'</span><span style=\"color:#E1E4E8\">: {</span><span style=\"color:#9ECBFF\">'the'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'and'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'or'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'but'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'in'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'on'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'at'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'to'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'for'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'of'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'with'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'by'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Technical term patterns to preserve</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.technical_patterns </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\w</span><span style=\"color:#F97583\">+</span><span style=\"color:#85E89D;font-weight:bold\">\\+\\+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">),     </span><span style=\"color:#6A737D\"># C++, etc.</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">[A-Z]</span><span style=\"color:#F97583\">{2,}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">),   </span><span style=\"color:#6A737D\"># Acronyms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#79B8FF\">\\w</span><span style=\"color:#F97583\">+</span><span style=\"color:#85E89D;font-weight:bold\">\\.</span><span style=\"color:#79B8FF\">\\w</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">),    </span><span style=\"color:#6A737D\"># Domains, versions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            re.compile(</span><span style=\"color:#F97583\">r</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#DBEDFF\">#</span><span style=\"color:#79B8FF\">\\w</span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">),        </span><span style=\"color:#6A737D\"># Hash tags</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_and_sanitize</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            max_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> MAX_QUERY_LENGTH</span><span style=\"color:#E1E4E8\">) -> QueryValidationResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Main entry point for query validation and sanitization.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for completely empty or None input</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Remove control characters and normalize Unicode</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle excessive whitespace and normalize spacing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Check for punctuation-only queries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate character encoding and fix common issues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Apply length limits with intelligent truncation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Generate suggestions for problematic queries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return ValidationResult with sanitized text and metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _normalize_unicode</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Normalize Unicode characters and detect encoding issues.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        warnings </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Normalize Unicode to canonical form</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            normalized </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> unicodedata.normalize(</span><span style=\"color:#9ECBFF\">'NFC'</span><span style=\"color:#E1E4E8\">, text)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Detect and fix common encoding problems</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> normalized </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> text:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                warnings.append(</span><span style=\"color:#9ECBFF\">\"Unicode characters normalized\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> normalized, warnings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            warnings.append(</span><span style=\"color:#9ECBFF\">\"Unicode normalization failed, using original text\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> text, warnings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _intelligent_truncation</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, max_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Truncate query while preserving important terms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(text) </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> max_length:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> text, []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        warnings </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Query truncated from </span><span style=\"color:#79B8FF\">{len</span><span style=\"color:#E1E4E8\">(text)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> to </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">max_length</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> characters\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Split text into words/phrases</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify technical terms and proper nouns to preserve</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Remove common words and filler text first</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If still too long, truncate from end while preserving key terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return truncated text with warnings about what was removed</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_query_suggestions</span><span style=\"color:#E1E4E8\">(self, original: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, sanitized: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  warnings: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate helpful suggestions for problematic queries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        suggestions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if query became empty after sanitization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if query is very short (&#x3C; 3 characters)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check for apparent typos or unusual patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Suggest query expansion for very specific terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Provide examples for empty or invalid queries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EdgeCaseHandler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles specific edge cases in query processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sanitizer </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QuerySanitizer()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.trending_queries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"machine learning\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"python programming\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"data science\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"web development\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"artificial intelligence\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_empty_query</span><span style=\"color:#E1E4E8\">(self, context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle empty queries by providing trending or contextual suggestions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if user context provides recent queries or interests</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Select appropriate trending queries based on context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Format response with helpful suggestions and explanations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return ProcessingResult with suggested queries and metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_malformed_query</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             validation_result: QueryValidationResult,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle queries that can't be processed normally.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Assess severity of malformation (correctable vs. unusable)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt automatic correction for common issues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If correctable, process corrected version</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If uncorrectable, provide helpful error message and suggestions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Log malformed query patterns for analysis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_excessive_length</span><span style=\"color:#E1E4E8\">(self, query_text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, max_length: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> MAX_QUERY_LENGTH</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                              context: ContextInfo </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> ProcessingResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle queries exceeding maximum length limits.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Apply intelligent truncation preserving key terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify if query contains multiple distinct questions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If multiple questions, suggest breaking into separate searches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Process truncated query with warning about limitations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Include original full query in metadata for analysis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints:</strong></p>\n<p>After implementing error handling for each milestone, verify the following behaviors:</p>\n<p><strong>Milestone 1 - Embedding Index Error Handling:</strong></p>\n<ul>\n<li>Test command: <code>python -m pytest tests/error_scenarios/test_index_failures.py</code></li>\n<li>Expected behavior: Index construction continues despite individual document failures, corrupted indices are detected and recovered</li>\n<li>Manual verification: Intentionally corrupt an index file, verify system detects corruption and rebuilds from backup</li>\n<li>Warning signs: High memory usage during error recovery, frequent index rebuilds, documents permanently failing embedding</li>\n</ul>\n<p><strong>Milestone 2 - Query Processing Error Handling:</strong></p>\n<ul>\n<li>Test command: <code>python -m pytest tests/error_scenarios/test_query_edge_cases.py</code></li>\n<li>Expected behavior: Empty queries return suggestions, malformed queries are cleaned, very long queries are intelligently truncated</li>\n<li>Manual verification: Submit queries with special characters, excessive length, and various encoding issues</li>\n<li>Warning signs: Query processing timeouts, Unicode errors in logs, sanitized queries losing important meaning</li>\n</ul>\n<p><strong>Milestone 3 - Ranking Error Handling:</strong></p>\n<ul>\n<li>Test command: <code>python -m pytest tests/error_scenarios/test_ranking_degradation.py</code></li>\n<li>Expected behavior: Ranking failures fall back to simpler scoring methods, partial results are returned with quality warnings</li>\n<li>Manual verification: Disable cross-encoder service, verify search continues with degraded ranking</li>\n<li>Warning signs: Ranking consistently timing out, significant quality degradation, circuit breakers frequently open</li>\n</ul>\n<p><strong>Milestone 4 - Search API Error Handling:</strong></p>\n<ul>\n<li>Test command: <code>python -m pytest tests/error_scenarios/test_api_resilience.py</code></li>\n<li>Expected behavior: API requests complete within timeout limits, graceful error responses with helpful messages</li>\n<li>Manual verification: Submit malformed API requests, verify appropriate HTTP status codes and error messages</li>\n<li>Warning signs: API timeouts, unhelpful error messages, clients receiving 500 errors for user input issues</li>\n</ul>\n<p><strong>Common Debugging Patterns:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Steps</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Search returns empty results frequently</td>\n<td>Index corruption or embedding model failure</td>\n<td>Check index integrity, test embedding generation</td>\n<td>Rebuild index, verify model configuration</td>\n</tr>\n<tr>\n<td>High latency on all searches</td>\n<td>Component timeouts or resource exhaustion</td>\n<td>Check component response times, monitor resource usage</td>\n<td>Increase timeouts, optimize resource allocation</td>\n</tr>\n<tr>\n<td>Circuit breakers frequently open</td>\n<td>Dependent service failures or configuration issues</td>\n<td>Review service health checks, adjust circuit breaker thresholds</td>\n<td>Fix underlying service issues, tune circuit breaker settings</td>\n</tr>\n<tr>\n<td>Unicode errors in query processing</td>\n<td>Text encoding issues or character normalization problems</td>\n<td>Log raw query bytes, test character encoding detection</td>\n<td>Improve encoding detection, add character sanitization</td>\n</tr>\n<tr>\n<td>Index updates failing silently</td>\n<td>Transaction log corruption or insufficient error handling</td>\n<td>Check transaction logs, verify error reporting</td>\n<td>Improve transaction logging, add update monitoring</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy\">Testing Strategy</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing comprehensive testing approaches that verify each milestone&#39;s acceptance criteria and ensure production readiness.</p>\n</blockquote>\n<p>Testing a semantic search engine requires a fundamentally different approach than testing traditional software systems. Think of it like <strong>testing a translator</strong> — you&#39;re not just verifying that the system doesn&#39;t crash, but that it actually understands meaning and produces results that match human expectations. Unlike deterministic systems where you can predict exact outputs, semantic search involves probabilistic models, approximate algorithms, and subjective relevance judgments that require sophisticated evaluation strategies.</p>\n<p>The challenge lies in the multi-dimensional nature of search quality. A search engine can be technically correct (fast, available, error-free) but still fail users if it doesn&#39;t understand their intent or returns irrelevant results. Conversely, a system that provides excellent semantic understanding might fail in production if it can&#39;t handle load or gracefully degrade when components fail. Our testing strategy must therefore evaluate three critical dimensions: <strong>search quality</strong> (does it understand meaning?), <strong>performance characteristics</strong> (does it meet latency and throughput requirements?), and <strong>system reliability</strong> (does it handle failures gracefully?).</p>\n<p>Each milestone introduces new complexity that requires specific testing approaches. The embedding index (Milestone 1) needs stress testing with millions of vectors and validation of approximate nearest neighbor accuracy. Query processing (Milestone 2) requires evaluation of expansion quality and semantic understanding accuracy. Ranking and relevance (Milestone 3) demands sophisticated offline evaluation metrics and online A/B testing frameworks. The search API (Milestone 4) needs end-to-end integration testing and user experience validation.</p>\n<blockquote>\n<p><strong>Key Testing Philosophy</strong>: We test semantic search engines like we evaluate human translators — not just for technical correctness, but for accuracy, fluency, and appropriateness of understanding. This requires combining quantitative metrics with qualitative evaluation and real-world usage validation.</p>\n</blockquote>\n<h3 id=\"search-quality-evaluation\">Search Quality Evaluation</h3>\n<p><strong>Mental Model: The Academic Paper Review Process</strong></p>\n<p>Think of search quality evaluation like <strong>academic peer review</strong> for research papers. Just as reviewers evaluate papers on multiple criteria — relevance to the topic, methodology soundness, novelty of insights, and clarity of presentation — we must evaluate search results on multiple quality dimensions. A single metric like &quot;precision&quot; is insufficient, just as a single criterion like &quot;grammatical correctness&quot; would be inadequate for evaluating research quality.</p>\n<p>The evaluation process involves creating <strong>test collections</strong> (like academic conferences define paper topics), establishing <strong>ground truth relevance judgments</strong> (like expert reviewers rating papers), and applying <strong>multiple evaluation metrics</strong> that capture different aspects of quality. The key insight is that search quality is fundamentally subjective and context-dependent, requiring systematic approaches to capture and measure human judgment.</p>\n<h4 id=\"relevance-metrics-and-measurement-framework\">Relevance Metrics and Measurement Framework</h4>\n<p>Our search quality evaluation framework employs multiple complementary metrics that capture different aspects of search effectiveness. These metrics form a comprehensive scorecard that evaluates both <strong>ranking quality</strong> (are the best results ranked highest?) and <strong>retrieval effectiveness</strong> (do we find all relevant documents?).</p>\n<p><strong>Core Relevance Metrics</strong></p>\n<table>\n<thead>\n<tr>\n<th>Metric Name</th>\n<th>Formula</th>\n<th>What It Measures</th>\n<th>Strengths</th>\n<th>Limitations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Precision@K</td>\n<td>Relevant results in top K / K</td>\n<td>Accuracy of top results</td>\n<td>Easy to understand, user-focused</td>\n<td>Ignores rank order within top K</td>\n</tr>\n<tr>\n<td>Recall@K</td>\n<td>Relevant results in top K / Total relevant</td>\n<td>Coverage of relevant documents</td>\n<td>Shows retrieval completeness</td>\n<td>Requires knowing all relevant docs</td>\n</tr>\n<tr>\n<td>Mean Average Precision (MAP)</td>\n<td>Average of precision at each relevant result</td>\n<td>Ranking quality across all positions</td>\n<td>Considers rank order, single number</td>\n<td>Biased toward queries with many relevant docs</td>\n</tr>\n<tr>\n<td>Normalized DCG@K</td>\n<td>DCG@K / IDCG@K</td>\n<td>Ranking quality with graded relevance</td>\n<td>Handles multiple relevance levels</td>\n<td>Requires expensive graded judgments</td>\n</tr>\n<tr>\n<td>Mean Reciprocal Rank (MRR)</td>\n<td>Average of 1/rank of first relevant result</td>\n<td>Time to first good result</td>\n<td>Critical for user satisfaction</td>\n<td>Only considers first relevant result</td>\n</tr>\n<tr>\n<td>Expected Reciprocal Rank (ERR)</td>\n<td>Models user abandonment probability</td>\n<td>Realistic user interaction model</td>\n<td>Accounts for result utility</td>\n<td>Complex to compute and interpret</td>\n</tr>\n</tbody></table>\n<p><strong>Graded Relevance Scale</strong></p>\n<p>Rather than binary relevant/irrelevant judgments, we employ a four-point relevance scale that captures the nuanced quality of search results:</p>\n<table>\n<thead>\n<tr>\n<th>Relevance Grade</th>\n<th>Score</th>\n<th>Description</th>\n<th>User Action</th>\n<th>Example Query: &quot;machine learning algorithms&quot;</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Perfect</td>\n<td>4</td>\n<td>Exactly what user wanted</td>\n<td>Clicks and stays</td>\n<td>&quot;Comprehensive Guide to ML Algorithms&quot;</td>\n</tr>\n<tr>\n<td>Excellent</td>\n<td>3</td>\n<td>Highly relevant and useful</td>\n<td>Clicks, likely to stay</td>\n<td>&quot;Top 10 Machine Learning Algorithms Explained&quot;</td>\n</tr>\n<tr>\n<td>Good</td>\n<td>2</td>\n<td>Somewhat relevant</td>\n<td>May click, may bounce</td>\n<td>&quot;Introduction to Artificial Intelligence&quot;</td>\n</tr>\n<tr>\n<td>Fair</td>\n<td>1</td>\n<td>Marginally relevant</td>\n<td>Unlikely to click</td>\n<td>&quot;Software Engineering Best Practices&quot;</td>\n</tr>\n<tr>\n<td>Bad</td>\n<td>0</td>\n<td>Not relevant</td>\n<td>Ignores completely</td>\n<td>&quot;Cooking Recipes for Beginners&quot;</td>\n</tr>\n</tbody></table>\n<p>This graded approach enables more sophisticated metrics like NDCG that reward highly relevant results more than marginally relevant ones, better reflecting real user satisfaction patterns.</p>\n<h4 id=\"test-query-development-strategy\">Test Query Development Strategy</h4>\n<p>Effective search quality evaluation requires carefully constructed test queries that represent real user needs and cover the full spectrum of search complexity. Our test query development follows a systematic approach that ensures comprehensive coverage of user intent patterns and system stress cases.</p>\n<p><strong>Query Collection Categories</strong></p>\n<table>\n<thead>\n<tr>\n<th>Category</th>\n<th>Description</th>\n<th>Example Queries</th>\n<th>Testing Focus</th>\n<th>Expected Volume</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Factual Lookup</td>\n<td>Specific information seeking</td>\n<td>&quot;Python list comprehension syntax&quot;</td>\n<td>Precision of exact matches</td>\n<td>25%</td>\n</tr>\n<tr>\n<td>Conceptual Exploration</td>\n<td>Understanding broad topics</td>\n<td>&quot;differences between SQL and NoSQL&quot;</td>\n<td>Semantic understanding depth</td>\n<td>30%</td>\n</tr>\n<tr>\n<td>Comparative Analysis</td>\n<td>Evaluating alternatives</td>\n<td>&quot;React vs Vue performance comparison&quot;</td>\n<td>Multi-faceted result ranking</td>\n<td>20%</td>\n</tr>\n<tr>\n<td>Problem Solving</td>\n<td>Solution-oriented searches</td>\n<td>&quot;how to debug memory leaks in Node.js&quot;</td>\n<td>Practical relevance ranking</td>\n<td>15%</td>\n</tr>\n<tr>\n<td>Ambiguous Intent</td>\n<td>Multiple possible interpretations</td>\n<td>&quot;apple development&quot; (fruit/company)</td>\n<td>Disambiguation and diversity</td>\n<td>10%</td>\n</tr>\n</tbody></table>\n<p><strong>Query Complexity Progression</strong></p>\n<p>Our test queries are stratified by complexity to ensure the system handles both simple and sophisticated information needs:</p>\n<ol>\n<li><strong>Simple Keyword Queries</strong>: Single concepts with clear intent (&quot;machine learning&quot;, &quot;database design&quot;)</li>\n<li><strong>Multi-Term Queries</strong>: Combined concepts requiring understanding of relationships (&quot;distributed systems scalability patterns&quot;)  </li>\n<li><strong>Natural Language Queries</strong>: Conversational or question-based searches (&quot;What are the best practices for microservices architecture?&quot;)</li>\n<li><strong>Technical Jargon Queries</strong>: Domain-specific terminology (&quot;OAuth 2.0 PKCE flow implementation&quot;)</li>\n<li><strong>Ambiguous Queries</strong>: Terms with multiple meanings requiring context (&quot;spring framework&quot; vs &quot;spring season&quot;)</li>\n<li><strong>Long-Tail Queries</strong>: Very specific, uncommon information needs (&quot;debugging segmentation faults in embedded C applications&quot;)</li>\n</ol>\n<p><strong>Ground Truth Establishment Process</strong></p>\n<p>Establishing reliable ground truth relevance judgments requires a systematic annotation process that ensures consistency and quality:</p>\n<ol>\n<li><strong>Expert Annotator Recruitment</strong>: Technical subject matter experts familiar with the document domain</li>\n<li><strong>Annotation Guidelines Development</strong>: Detailed rubrics with examples for each relevance grade</li>\n<li><strong>Inter-Annotator Agreement Measurement</strong>: Calculate Cohen&#39;s kappa or Fleiss&#39; kappa to ensure consistency</li>\n<li><strong>Disagreement Resolution Process</strong>: Systematic approach for handling conflicting judgments</li>\n<li><strong>Annotation Quality Control</strong>: Regular calibration sessions and spot-checking of judgments</li>\n</ol>\n<p><strong>Relevance Judgment Collection Workflow</strong></p>\n<table>\n<thead>\n<tr>\n<th>Stage</th>\n<th>Activity</th>\n<th>Participants</th>\n<th>Output</th>\n<th>Quality Check</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Selection</td>\n<td>Identify test queries from logs/experts</td>\n<td>Search team + domain experts</td>\n<td>200-500 test queries</td>\n<td>Coverage analysis across categories</td>\n</tr>\n<tr>\n<td>Result Pool Creation</td>\n<td>Run queries against system + baselines</td>\n<td>Automated systems</td>\n<td>Top 20 results per query</td>\n<td>Diversity verification</td>\n</tr>\n<tr>\n<td>Annotation Training</td>\n<td>Train judges on guidelines</td>\n<td>Expert annotators</td>\n<td>Calibrated judgments</td>\n<td>Inter-annotator agreement &gt;0.7</td>\n</tr>\n<tr>\n<td>Primary Annotation</td>\n<td>Judge all query-result pairs</td>\n<td>2-3 annotators per pair</td>\n<td>Graded relevance scores</td>\n<td>Disagreement rate monitoring</td>\n</tr>\n<tr>\n<td>Consensus Building</td>\n<td>Resolve annotation conflicts</td>\n<td>Senior domain expert</td>\n<td>Final relevance judgments</td>\n<td>Spot audit of 10% of judgments</td>\n</tr>\n</tbody></table>\n<h4 id=\"offline-evaluation-infrastructure\">Offline Evaluation Infrastructure</h4>\n<p>Our offline evaluation infrastructure enables rapid experimentation and systematic comparison of different system configurations without impacting production users. This infrastructure supports both <strong>point-in-time evaluations</strong> (comparing current system against baselines) and <strong>temporal analysis</strong> (tracking quality changes over time).</p>\n<p><strong>Evaluation Dataset Management</strong></p>\n<p>The evaluation infrastructure manages multiple test collections that represent different aspects of search quality:</p>\n<table>\n<thead>\n<tr>\n<th>Dataset Name</th>\n<th>Size</th>\n<th>Domain Focus</th>\n<th>Update Frequency</th>\n<th>Primary Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Core Quality Set</td>\n<td>100 queries, 2000 judgments</td>\n<td>General technical content</td>\n<td>Monthly</td>\n<td>Primary quality metric tracking</td>\n</tr>\n<tr>\n<td>Domain Specific Sets</td>\n<td>50 queries each</td>\n<td>Programming, DevOps, Architecture</td>\n<td>Quarterly</td>\n<td>Domain coverage validation</td>\n</tr>\n<tr>\n<td>Stress Test Set</td>\n<td>200 queries</td>\n<td>Edge cases, ambiguous queries</td>\n<td>As needed</td>\n<td>Robustness testing</td>\n</tr>\n<tr>\n<td>Temporal Drift Set</td>\n<td>75 queries</td>\n<td>Recently published content</td>\n<td>Weekly</td>\n<td>Freshness and drift monitoring</td>\n</tr>\n<tr>\n<td>User Intent Set</td>\n<td>150 queries</td>\n<td>Real user query patterns</td>\n<td>Bi-weekly</td>\n<td>Production alignment validation</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Evaluation Pipeline</strong></p>\n<p>The offline evaluation pipeline runs automatically on every system change, providing immediate feedback on quality impact:</p>\n<ol>\n<li><strong>Trigger Events</strong>: Code commits, model updates, index rebuilds, configuration changes</li>\n<li><strong>Execution Environment</strong>: Isolated evaluation cluster with representative data</li>\n<li><strong>Result Collection</strong>: Systematic querying and result capture for all test queries</li>\n<li><strong>Metric Computation</strong>: Calculation of all relevance metrics against ground truth</li>\n<li><strong>Regression Detection</strong>: Statistical significance testing to identify quality changes</li>\n<li><strong>Report Generation</strong>: Automated dashboards and alerts for quality degradation</li>\n</ol>\n<p><strong>Quality Regression Detection Framework</strong></p>\n<p>Changes to the search system can inadvertently degrade quality in subtle ways. Our regression detection framework provides early warning of quality issues:</p>\n<table>\n<thead>\n<tr>\n<th>Detection Method</th>\n<th>Metric Threshold</th>\n<th>Time Window</th>\n<th>Alert Trigger</th>\n<th>Response Protocol</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Absolute Threshold</td>\n<td>MAP &lt; 0.75, NDCG@10 &lt; 0.80</td>\n<td>Single evaluation</td>\n<td>Immediate</td>\n<td>Block deployment</td>\n</tr>\n<tr>\n<td>Relative Degradation</td>\n<td>&gt;5% decrease in any core metric</td>\n<td>3 evaluations</td>\n<td>Within 4 hours</td>\n<td>Investigation required</td>\n</tr>\n<tr>\n<td>Statistical Significance</td>\n<td>p &lt; 0.05 for quality decrease</td>\n<td>7 days</td>\n<td>Daily batch</td>\n<td>Monitoring intensification</td>\n</tr>\n<tr>\n<td>User-Focused Metrics</td>\n<td>MRR &lt; 0.85, P@1 &lt; 0.70</td>\n<td>Single evaluation</td>\n<td>Immediate</td>\n<td>User impact assessment</td>\n</tr>\n<tr>\n<td>Temporal Trends</td>\n<td>Declining trend &gt;2 weeks</td>\n<td>14 days</td>\n<td>Weekly</td>\n<td>Root cause analysis</td>\n</tr>\n</tbody></table>\n<h3 id=\"performance-and-load-testing\">Performance and Load Testing</h3>\n<p><strong>Mental Model: Stress Testing a Bridge</strong></p>\n<p>Think of performance testing like <strong>stress testing a bridge</strong> before it opens to traffic. Engineers don&#39;t just verify that the bridge holds its own weight — they test it with progressively heavier loads, simulate extreme weather conditions, and ensure it can handle rush hour traffic without degradation. Similarly, our semantic search engine must demonstrate that it can handle production workloads while maintaining sub-second response times and graceful degradation under stress.</p>\n<p>The key insight is that semantic search performance has multiple dimensions beyond simple response time. Vector similarity computations are CPU-intensive, large indices consume significant memory, and approximate algorithms trade accuracy for speed. Performance testing must validate that these trade-offs remain acceptable under realistic load conditions, and that the system degrades predictably when resources become constrained.</p>\n<h4 id=\"latency-benchmarks-and-sla-definition\">Latency Benchmarks and SLA Definition</h4>\n<p>Our performance testing framework establishes clear Service Level Agreements (SLAs) that define acceptable performance boundaries for different types of search operations. These SLAs provide both engineering targets and business commitments that guide system design decisions.</p>\n<p><strong>Response Time SLA Targets</strong></p>\n<table>\n<thead>\n<tr>\n<th>Operation Type</th>\n<th>50th Percentile</th>\n<th>95th Percentile</th>\n<th>99th Percentile</th>\n<th>Timeout Limit</th>\n<th>Business Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Simple Search</td>\n<td>&lt;200ms</td>\n<td>&lt;500ms</td>\n<td>&lt;1000ms</td>\n<td>2000ms</td>\n<td>Interactive user experience</td>\n</tr>\n<tr>\n<td>Complex Search</td>\n<td>&lt;500ms</td>\n<td>&lt;1000ms</td>\n<td>&lt;2000ms</td>\n<td>5000ms</td>\n<td>Acceptable for detailed queries</td>\n</tr>\n<tr>\n<td>Autocomplete</td>\n<td>&lt;50ms</td>\n<td>&lt;100ms</td>\n<td>&lt;200ms</td>\n<td>500ms</td>\n<td>Real-time typing feedback</td>\n</tr>\n<tr>\n<td>Facet Computation</td>\n<td>&lt;300ms</td>\n<td>&lt;800ms</td>\n<td>&lt;1500ms</td>\n<td>3000ms</td>\n<td>Acceptable for filtering</td>\n</tr>\n<tr>\n<td>Similar Document</td>\n<td>&lt;400ms</td>\n<td>&lt;1000ms</td>\n<td>&lt;2000ms</td>\n<td>4000ms</td>\n<td>Recommendation use case</td>\n</tr>\n<tr>\n<td>Bulk Query API</td>\n<td>&lt;100ms per query</td>\n<td>&lt;200ms per query</td>\n<td>&lt;500ms per query</td>\n<td>1000ms per query</td>\n<td>Batch processing efficiency</td>\n</tr>\n</tbody></table>\n<p>These targets are derived from user experience research showing that sub-200ms responses feel instantaneous, while responses over 1 second create noticeable delays that impact user satisfaction.</p>\n<p><strong>Latency Component Breakdown</strong></p>\n<p>Understanding where time is spent during search request processing enables targeted optimization efforts:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Target Latency</th>\n<th>Typical Range</th>\n<th>Optimization Strategies</th>\n<th>Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Processing</td>\n<td>&lt;50ms</td>\n<td>20-80ms</td>\n<td>Caching, text preprocessing optimization</td>\n<td>Custom timing instrumentation</td>\n</tr>\n<tr>\n<td>Vector Embedding</td>\n<td>&lt;100ms</td>\n<td>50-150ms</td>\n<td>Batch processing, model optimization</td>\n<td>Model inference timing</td>\n</tr>\n<tr>\n<td>Index Search</td>\n<td>&lt;150ms</td>\n<td>80-300ms</td>\n<td>Index tuning, hardware optimization</td>\n<td>FAISS internal metrics</td>\n</tr>\n<tr>\n<td>Result Ranking</td>\n<td>&lt;100ms</td>\n<td>40-200ms</td>\n<td>Multi-stage ranking, candidate pruning</td>\n<td>Ranking pipeline timing</td>\n</tr>\n<tr>\n<td>Response Formatting</td>\n<td>&lt;20ms</td>\n<td>5-40ms</td>\n<td>JSON optimization, snippet generation</td>\n<td>HTTP middleware timing</td>\n</tr>\n<tr>\n<td>Network Overhead</td>\n<td>&lt;30ms</td>\n<td>10-50ms</td>\n<td>Compression, CDN usage</td>\n<td>Load balancer metrics</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Testing Environment Setup</strong></p>\n<p>Our performance testing environment mirrors production infrastructure to ensure realistic results:</p>\n<table>\n<thead>\n<tr>\n<th>Environment Component</th>\n<th>Specification</th>\n<th>Rationale</th>\n<th>Monitoring</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Application Servers</td>\n<td>4 CPU cores, 16GB RAM</td>\n<td>Matches production capacity</td>\n<td>CPU, memory, network utilization</td>\n</tr>\n<tr>\n<td>Vector Index Storage</td>\n<td>SSD with 500MB/s read throughput</td>\n<td>Supports index scanning requirements</td>\n<td>Disk I/O metrics, cache hit rates</td>\n</tr>\n<tr>\n<td>Load Generation</td>\n<td>Distributed across 3 availability zones</td>\n<td>Realistic network conditions</td>\n<td>Request distribution, connection pooling</td>\n</tr>\n<tr>\n<td>Network Configuration</td>\n<td>100ms simulated WAN latency</td>\n<td>Represents global user distribution</td>\n<td>Round-trip time measurement</td>\n</tr>\n<tr>\n<td>Data Volume</td>\n<td>1M documents, 400MB index size</td>\n<td>Production-scale dataset</td>\n<td>Index size, memory usage</td>\n</tr>\n</tbody></table>\n<h4 id=\"throughput-validation-and-scalability-testing\">Throughput Validation and Scalability Testing</h4>\n<p>Throughput testing validates that our semantic search engine can handle production query volumes while maintaining acceptable response times. This testing reveals system bottlenecks and helps establish capacity planning guidelines for different usage patterns.</p>\n<p><strong>Throughput Testing Scenarios</strong></p>\n<table>\n<thead>\n<tr>\n<th>Scenario Name</th>\n<th>Query Rate</th>\n<th>Concurrent Users</th>\n<th>Query Pattern</th>\n<th>Duration</th>\n<th>Success Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Baseline Load</td>\n<td>100 QPS</td>\n<td>200</td>\n<td>Mixed complexity</td>\n<td>30 minutes</td>\n<td>All SLA targets met</td>\n</tr>\n<tr>\n<td>Peak Traffic</td>\n<td>500 QPS</td>\n<td>1000</td>\n<td>70% simple, 30% complex</td>\n<td>15 minutes</td>\n<td>95% of requests meet SLA</td>\n</tr>\n<tr>\n<td>Burst Load</td>\n<td>1000 QPS spike</td>\n<td>2000</td>\n<td>Primarily simple queries</td>\n<td>5 minutes</td>\n<td>Graceful degradation, no failures</td>\n</tr>\n<tr>\n<td>Sustained High Load</td>\n<td>300 QPS</td>\n<td>600</td>\n<td>Realistic user patterns</td>\n<td>2 hours</td>\n<td>Stable performance, no memory leaks</td>\n</tr>\n<tr>\n<td>Gradual Ramp</td>\n<td>50→800 QPS</td>\n<td>100→1600</td>\n<td>Linear increase over time</td>\n<td>45 minutes</td>\n<td>Smooth scaling, predictable degradation</td>\n</tr>\n<tr>\n<td>Mixed Workload</td>\n<td>Variable</td>\n<td>800</td>\n<td>40% search, 30% autocomplete, 30% facets</td>\n<td>1 hour</td>\n<td>All operation types meet targets</td>\n</tr>\n</tbody></table>\n<p><strong>Resource Utilization Monitoring</strong></p>\n<p>Understanding resource consumption patterns helps identify bottlenecks and plan infrastructure requirements:</p>\n<table>\n<thead>\n<tr>\n<th>Resource Type</th>\n<th>Monitoring Metrics</th>\n<th>Alert Thresholds</th>\n<th>Optimization Actions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CPU Usage</td>\n<td>Per-core utilization, queue depth</td>\n<td>&gt;80% sustained</td>\n<td>Scale horizontally, optimize algorithms</td>\n</tr>\n<tr>\n<td>Memory Consumption</td>\n<td>Heap usage, index size, cache hit rate</td>\n<td>&gt;85% of available</td>\n<td>Increase capacity, tune cache sizes</td>\n</tr>\n<tr>\n<td>Disk I/O</td>\n<td>Read IOPS, throughput, queue depth</td>\n<td>&gt;70% of capacity</td>\n<td>SSD upgrade, index optimization</td>\n</tr>\n<tr>\n<td>Network Bandwidth</td>\n<td>Requests/sec, bytes transferred</td>\n<td>&gt;60% of capacity</td>\n<td>Content compression, CDN usage</td>\n</tr>\n<tr>\n<td>Index Performance</td>\n<td>Search latency, accuracy degradation</td>\n<td>Latency &gt;2x baseline</td>\n<td>Index tuning, algorithm selection</td>\n</tr>\n<tr>\n<td>Cache Effectiveness</td>\n<td>Hit rate, eviction rate</td>\n<td>&lt;80% hit rate</td>\n<td>Cache size tuning, TTL optimization</td>\n</tr>\n</tbody></table>\n<p><strong>Scalability Characterization</strong></p>\n<p>Systematic scalability testing reveals how the system behaves as different dimensions scale up:</p>\n<ol>\n<li><strong>Document Volume Scaling</strong>: Test with 100K, 500K, 1M, 5M documents to understand index size impact</li>\n<li><strong>Query Complexity Scaling</strong>: Measure performance with varying query lengths and expansion factors</li>\n<li><strong>Concurrent User Scaling</strong>: Increase simultaneous users from 100 to 2000 to find connection limits</li>\n<li><strong>Multi-Tenant Scaling</strong>: Test with multiple independent search indices and query isolation</li>\n<li><strong>Geographic Distribution</strong>: Validate performance across multiple data center regions</li>\n</ol>\n<p><strong>Performance Regression Detection</strong></p>\n<p>Automated performance regression detection ensures that code changes don&#39;t inadvertently degrade system performance:</p>\n<table>\n<thead>\n<tr>\n<th>Regression Type</th>\n<th>Detection Method</th>\n<th>Alert Threshold</th>\n<th>Response Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Latency Increase</td>\n<td>Statistical comparison with baseline</td>\n<td>&gt;20% increase in P95 latency</td>\n<td>Block deployment, investigate</td>\n</tr>\n<tr>\n<td>Throughput Decrease</td>\n<td>Peak QPS comparison</td>\n<td>&gt;15% reduction in sustained QPS</td>\n<td>Performance analysis required</td>\n</tr>\n<tr>\n<td>Resource Efficiency</td>\n<td>CPU/memory per query comparison</td>\n<td>&gt;25% increase in resource usage</td>\n<td>Optimization needed</td>\n</tr>\n<tr>\n<td>Cache Performance</td>\n<td>Hit rate degradation</td>\n<td>&gt;10% reduction in cache hits</td>\n<td>Cache configuration review</td>\n</tr>\n<tr>\n<td>Error Rate Increase</td>\n<td>Success rate comparison</td>\n<td>&gt;2% increase in error rate</td>\n<td>Immediate rollback consideration</td>\n</tr>\n</tbody></table>\n<h4 id=\"load-testing-infrastructure-and-automation\">Load Testing Infrastructure and Automation</h4>\n<p>Our load testing infrastructure provides consistent, repeatable performance validation that integrates with the development workflow. This infrastructure supports both <strong>on-demand testing</strong> for specific changes and <strong>continuous performance monitoring</strong> for trend analysis.</p>\n<p><strong>Load Generation Architecture</strong></p>\n<p>The load testing infrastructure uses a distributed architecture that can simulate realistic user traffic patterns:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Purpose</th>\n<th>Implementation</th>\n<th>Scaling Capability</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Test Controller</td>\n<td>Orchestrates load tests, collects results</td>\n<td>Python with asyncio</td>\n<td>Single instance, manages distributed load</td>\n</tr>\n<tr>\n<td>Load Generators</td>\n<td>Generate HTTP requests with realistic patterns</td>\n<td>Multiple nodes, configurable concurrency</td>\n<td>Horizontal scaling to 10K+ concurrent users</td>\n</tr>\n<tr>\n<td>Query Pattern Engine</td>\n<td>Produces realistic query distributions</td>\n<td>Probability-based query selection</td>\n<td>Configurable patterns for different scenarios</td>\n</tr>\n<tr>\n<td>Response Validator</td>\n<td>Verifies result quality during load</td>\n<td>Sampling-based validation</td>\n<td>Validates 10% of responses for correctness</td>\n</tr>\n<tr>\n<td>Metrics Collector</td>\n<td>Aggregates performance data</td>\n<td>Time-series database storage</td>\n<td>Real-time dashboards and alerting</td>\n</tr>\n</tbody></table>\n<p><strong>Realistic Load Pattern Simulation</strong></p>\n<p>Load testing must simulate realistic user behavior patterns rather than uniform request rates:</p>\n<table>\n<thead>\n<tr>\n<th>User Behavior Pattern</th>\n<th>Implementation</th>\n<th>Realistic Characteristics</th>\n<th>Testing Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Search Session Simulation</td>\n<td>Multi-request sequences per user</td>\n<td>Query refinement, result clicks, related searches</td>\n<td>Tests session state and caching</td>\n</tr>\n<tr>\n<td>Geographic Distribution</td>\n<td>Requests from multiple regions</td>\n<td>Varying network latencies, timezone effects</td>\n<td>Validates CDN and edge performance</td>\n</tr>\n<tr>\n<td>Query Frequency Distribution</td>\n<td>Zipf distribution for query popularity</td>\n<td>20% of queries account for 80% of traffic</td>\n<td>Tests caching effectiveness</td>\n</tr>\n<tr>\n<td>Burst Traffic Simulation</td>\n<td>Configurable traffic spikes</td>\n<td>News events, social media sharing</td>\n<td>Tests auto-scaling and resilience</td>\n</tr>\n<tr>\n<td>Mobile vs Desktop Patterns</td>\n<td>Different query patterns and latencies</td>\n<td>Shorter queries, higher error tolerance</td>\n<td>Tests adaptive optimization</td>\n</tr>\n</tbody></table>\n<p><strong>Continuous Performance Monitoring</strong></p>\n<p>Beyond discrete load tests, continuous monitoring tracks performance trends over time:</p>\n<ol>\n<li><strong>Hourly Micro-Tests</strong>: Quick 5-minute load tests with 50 QPS to detect immediate regressions</li>\n<li><strong>Daily Benchmark Runs</strong>: Comprehensive 30-minute tests covering all usage scenarios  </li>\n<li><strong>Weekly Capacity Planning</strong>: Extended tests that project infrastructure requirements</li>\n<li><strong>Monthly Baseline Updates</strong>: Recalibration of performance targets based on system evolution</li>\n<li><strong>Quarterly Stress Testing</strong>: Extreme load conditions to identify absolute system limits</li>\n</ol>\n<h3 id=\"milestone-verification-checkpoints\">Milestone Verification Checkpoints</h3>\n<p>Each milestone in our semantic search engine development has specific acceptance criteria that must be validated through systematic testing. These checkpoints ensure that each milestone delivers the promised functionality with acceptable quality and performance characteristics before proceeding to the next phase.</p>\n<p><strong>Mental Model: Software Release Gate Reviews</strong></p>\n<p>Think of milestone verification like <strong>gate reviews in aerospace development</strong> — each phase must demonstrate that critical requirements are met before progressing to more complex integration phases. Just as aircraft systems undergo ground testing before flight testing, each search system component must prove its core functionality before integration with other components.</p>\n<h4 id=\"milestone-1-embedding-index-verification\">Milestone 1: Embedding Index Verification</h4>\n<p>The embedding index forms the foundation of semantic search capability. Verification focuses on correctness, performance, and scalability of vector operations.</p>\n<p><strong>Functional Verification Tests</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Category</th>\n<th>Test Description</th>\n<th>Expected Behavior</th>\n<th>Pass Criteria</th>\n<th>Failure Investigation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Index Construction</td>\n<td>Build index with 100K documents</td>\n<td>Index creates successfully, all documents indexed</td>\n<td>100% success rate, &lt;10 minutes build time</td>\n<td>Check memory usage, embedding failures</td>\n</tr>\n<tr>\n<td>Similarity Search Accuracy</td>\n<td>Query with known similar documents</td>\n<td>Returns expected similar documents in top 10</td>\n<td>&gt;90% of expected results in top 10</td>\n<td>Verify vector normalization, distance metrics</td>\n</tr>\n<tr>\n<td>Approximate NN Quality</td>\n<td>Compare with exact search on 1K subset</td>\n<td>Results largely overlap with exact search</td>\n<td>&gt;85% overlap in top 20 results</td>\n<td>Check HNSW parameters, index corruption</td>\n</tr>\n<tr>\n<td>Incremental Updates</td>\n<td>Add 10K new documents to existing index</td>\n<td>New documents searchable without rebuild</td>\n<td>New docs appear in search results within 5 minutes</td>\n<td>Verify ID mapping, index synchronization</td>\n</tr>\n<tr>\n<td>Index Persistence</td>\n<td>Save and reload trained index</td>\n<td>Loaded index produces identical results</td>\n<td>Exact result reproduction after reload</td>\n<td>Check serialization, file corruption</td>\n</tr>\n</tbody></table>\n<p><strong>Performance Verification Tests</strong></p>\n<table>\n<thead>\n<tr>\n<th>Performance Dimension</th>\n<th>Test Scenario</th>\n<th>Target Performance</th>\n<th>Measurement Method</th>\n<th>Optimization Actions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Latency</td>\n<td>Search 1M document index</td>\n<td>&lt;150ms P95 latency</td>\n<td>Direct timing instrumentation</td>\n<td>Tune HNSW ef parameter, optimize hardware</td>\n</tr>\n<tr>\n<td>Index Build Time</td>\n<td>Construct index from 500K docs</td>\n<td>&lt;30 minutes total time</td>\n<td>Wall clock measurement</td>\n<td>Increase threads, optimize embedding pipeline</td>\n</tr>\n<tr>\n<td>Memory Usage</td>\n<td>Load 1M document index</td>\n<td>&lt;4GB RAM consumption</td>\n<td>Process memory monitoring</td>\n<td>Adjust quantization, optimize data structures</td>\n</tr>\n<tr>\n<td>Concurrent Access</td>\n<td>100 simultaneous searches</td>\n<td>No latency degradation</td>\n<td>Multi-threaded test harness</td>\n<td>Verify thread safety, optimize locks</td>\n</tr>\n<tr>\n<td>Index Size Efficiency</td>\n<td>Compare index to raw embeddings</td>\n<td>&lt;2x raw embedding size</td>\n<td>File size comparison</td>\n<td>Enable compression, optimize storage format</td>\n</tr>\n</tbody></table>\n<p><strong>Verification Checkpoint Commands</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Core functionality verification</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">python </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">m tests.index_verification </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">suite</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">functional </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">docs</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">python </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">m tests.index_verification </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">suite</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">performance </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">concurrent</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">users</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Index construction: 100000 documents indexed in 8.5 minutes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Search accuracy: 92% top-10 precision on test queries  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Query latency: P95=127ms, P99=245ms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Memory usage: 3.2GB for 1M document index</span></span></code></pre></div>\n\n<h4 id=\"milestone-2-query-processing-verification\">Milestone 2: Query Processing Verification</h4>\n<p>Query processing verification ensures that search queries are properly understood, expanded, and converted to effective vector representations.</p>\n<p><strong>Query Understanding Verification</strong></p>\n<table>\n<thead>\n<tr>\n<th>Understanding Capability</th>\n<th>Test Method</th>\n<th>Sample Input</th>\n<th>Expected Output</th>\n<th>Quality Threshold</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Normalization</td>\n<td>Process diverse text formats</td>\n<td>&quot;Machine-Learning    algorithms!!!&quot;</td>\n<td>&quot;machine learning algorithms&quot;</td>\n<td>100% consistent normalization</td>\n</tr>\n<tr>\n<td>Entity Recognition</td>\n<td>Extract technical terms</td>\n<td>&quot;React useEffect hook performance&quot;</td>\n<td>entities=[&quot;React&quot;, &quot;useEffect&quot;]</td>\n<td>&gt;80% entity recognition accuracy</td>\n</tr>\n<tr>\n<td>Intent Classification</td>\n<td>Categorize query types</td>\n<td>&quot;how to implement OAuth 2.0&quot;</td>\n<td>intent=&quot;tutorial&quot;, type=&quot;how-to&quot;</td>\n<td>&gt;75% intent classification accuracy</td>\n</tr>\n<tr>\n<td>Synonym Expansion</td>\n<td>Expand with related terms</td>\n<td>&quot;JS frameworks&quot;</td>\n<td>expanded=[&quot;JavaScript&quot;, &quot;frameworks&quot;, &quot;libraries&quot;]</td>\n<td>&gt;70% useful expansion terms</td>\n</tr>\n<tr>\n<td>Negative Term Handling</td>\n<td>Process exclusion queries</td>\n<td>&quot;python -snake&quot;</td>\n<td>negative_terms=[&quot;snake&quot;]</td>\n<td>100% negative term extraction</td>\n</tr>\n</tbody></table>\n<p><strong>Query Processing Quality Tests</strong></p>\n<table>\n<thead>\n<tr>\n<th>Quality Dimension</th>\n<th>Test Approach</th>\n<th>Validation Method</th>\n<th>Success Criteria</th>\n<th>Debug Steps</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Expansion Quality</td>\n<td>Manual evaluation of 100 test queries</td>\n<td>Expert judgment of expansion relevance</td>\n<td>&gt;80% expansions rated helpful or neutral</td>\n<td>Check synonym database quality, expansion algorithms</td>\n</tr>\n<tr>\n<td>Semantic Preservation</td>\n<td>Compare original vs expanded query results</td>\n<td>Overlap in top 20 results</td>\n<td>&gt;70% result overlap maintained</td>\n<td>Verify expansion doesn&#39;t dilute original intent</td>\n</tr>\n<tr>\n<td>Processing Speed</td>\n<td>Time query processing pipeline</td>\n<td>End-to-end latency measurement</td>\n<td>&lt;50ms P95 processing time</td>\n<td>Profile bottlenecks in NLP pipeline</td>\n</tr>\n<tr>\n<td>Cache Effectiveness</td>\n<td>Monitor cache hit rates</td>\n<td>Cache performance metrics</td>\n<td>&gt;60% hit rate for repeated queries</td>\n<td>Tune cache size, TTL parameters</td>\n</tr>\n<tr>\n<td>Multi-Vector Handling</td>\n<td>Test complex queries with multiple aspects</td>\n<td>Result diversity and coverage</td>\n<td>Addresses all query aspects in results</td>\n<td>Check vector combination algorithms</td>\n</tr>\n</tbody></table>\n<p><strong>Verification Checkpoint Commands</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Query processing verification</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">python </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">m tests.query_verification </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">suite</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">understanding </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">queries</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">test_queries.json</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">python </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">m tests.query_verification </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">suite</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">performance </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">concurrent</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">50</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Entity recognition: 84% accuracy on technical terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Query expansion: 78% helpful expansions, 18% neutral, 4% harmful  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Processing latency: P95=42ms, cache hit rate=67%</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Multi-vector queries: 89% aspect coverage in top 20 results</span></span></code></pre></div>\n\n<h4 id=\"milestone-3-ranking-and-relevance-verification\">Milestone 3: Ranking and Relevance Verification</h4>\n<p>Ranking verification ensures that the multi-stage ranking pipeline produces high-quality, relevant results that match user expectations.</p>\n<p><strong>Ranking Quality Assessment</strong></p>\n<table>\n<thead>\n<tr>\n<th>Ranking Component</th>\n<th>Test Method</th>\n<th>Quality Metric</th>\n<th>Target Performance</th>\n<th>Validation Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Semantic Similarity Scoring</td>\n<td>Compare with human relevance judgments</td>\n<td>NDCG@10</td>\n<td>&gt;0.75</td>\n<td>Expert evaluation on 200 test queries</td>\n</tr>\n<tr>\n<td>BM25 Integration</td>\n<td>Test hybrid semantic + lexical search</td>\n<td>MAP improvement vs semantic-only</td>\n<td>&gt;15% improvement</td>\n<td>A/B test comparison</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranking</td>\n<td>Precision of top 5 results after reranking</td>\n<td>Precision@5</td>\n<td>&gt;0.85</td>\n<td>Manual relevance assessment</td>\n</tr>\n<tr>\n<td>Personalization Impact</td>\n<td>User-specific result customization</td>\n<td>Click-through rate improvement</td>\n<td>&gt;20% CTR improvement</td>\n<td>Simulated user preferences</td>\n</tr>\n<tr>\n<td>Freshness Weighting</td>\n<td>Boost recent content appropriately</td>\n<td>Temporal relevance balance</td>\n<td>Recent docs in top 10 for time-sensitive queries</td>\n<td>Query categorization and result analysis</td>\n</tr>\n</tbody></table>\n<p><strong>Multi-Stage Pipeline Verification</strong></p>\n<table>\n<thead>\n<tr>\n<th>Pipeline Stage</th>\n<th>Input</th>\n<th>Processing</th>\n<th>Output</th>\n<th>Validation Check</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Candidate Retrieval</td>\n<td>Query embedding</td>\n<td>Vector similarity search</td>\n<td>Top 1000 candidates</td>\n<td>Coverage: &gt;95% of relevant docs in candidates</td>\n</tr>\n<tr>\n<td>Fast Ranking</td>\n<td>1000 candidates</td>\n<td>BM25 + semantic scoring</td>\n<td>Top 100 candidates</td>\n<td>Speed: &lt;100ms, Quality: reasonable ranking</td>\n</tr>\n<tr>\n<td>Cross-Encoder Reranking</td>\n<td>Top 100 candidates</td>\n<td>Pairwise relevance scoring</td>\n<td>Top 20 final results</td>\n<td>Quality: &gt;90% improvement in P@5</td>\n</tr>\n<tr>\n<td>Result Formatting</td>\n<td>Top 20 results</td>\n<td>Snippet generation, highlighting</td>\n<td>Formatted responses</td>\n<td>User experience: clear, helpful snippets</td>\n</tr>\n</tbody></table>\n<p><strong>Verification Checkpoint Commands</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Ranking verification suite</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">python </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">m tests.ranking_verification </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">suite</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">quality </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#79B8FF\">eval</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">set</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">golden_queries.json</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">python </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">m tests.ranking_verification </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">suite</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">performance </span><span style=\"color:#FDAEB7;font-style:italic\">--</span><span style=\"color:#E1E4E8\">load</span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\">test</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">true</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output patterns  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Semantic ranking: NDCG@10=0.78, MAP=0.72</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Hybrid search: 18% improvement over semantic-only</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Cross-encoder: P@5 improved from 0.74 to 0.87</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Pipeline latency: P95=340ms (within 500ms target)</span></span></code></pre></div>\n\n<h4 id=\"milestone-4-search-api-and-ui-verification\">Milestone 4: Search API and UI Verification</h4>\n<p>The final milestone verification ensures that the complete search system provides a production-ready user experience with appropriate error handling and monitoring.</p>\n<p><strong>API Functionality Verification</strong></p>\n<table>\n<thead>\n<tr>\n<th>API Feature</th>\n<th>Test Scenario</th>\n<th>Expected Behavior</th>\n<th>Performance Target</th>\n<th>Error Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Search Endpoint</td>\n<td>POST /search with query parameters</td>\n<td>JSON response with ranked results</td>\n<td>&lt;500ms P95 response time</td>\n<td>Graceful error messages for malformed requests</td>\n</tr>\n<tr>\n<td>Autocomplete Endpoint</td>\n<td>GET /autocomplete with partial query</td>\n<td>Relevant suggestions in &lt;100ms</td>\n<td>&lt;100ms P95 response time</td>\n<td>Empty suggestions for invalid input</td>\n</tr>\n<tr>\n<td>Faceted Search</td>\n<td>Include facets=true in search request</td>\n<td>Facet counts for result categories</td>\n<td>&lt;800ms P95 with facets</td>\n<td>Disable facets on timeout</td>\n</tr>\n<tr>\n<td>Result Highlighting</td>\n<td>Query terms highlighted in snippets</td>\n<td>HTML-escaped highlighting markup</td>\n<td>No additional latency impact</td>\n<td>Plain text fallback if highlighting fails</td>\n</tr>\n<tr>\n<td>Pagination Support</td>\n<td>Request results with offset/limit</td>\n<td>Consistent results across pages</td>\n<td>Same performance for reasonable offsets</td>\n<td>Error for excessive offset values</td>\n</tr>\n</tbody></table>\n<p><strong>End-to-End User Experience Tests</strong></p>\n<table>\n<thead>\n<tr>\n<th>User Journey</th>\n<th>Test Steps</th>\n<th>Success Criteria</th>\n<th>Performance Expectation</th>\n<th>Quality Validation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Simple Search</td>\n<td>Enter query → view results → click result</td>\n<td>Relevant results, working links</td>\n<td>&lt;500ms search response</td>\n<td>&gt;80% top-5 relevance</td>\n</tr>\n<tr>\n<td>Query Refinement</td>\n<td>Initial search → modify query → compare results</td>\n<td>Results improve with specificity</td>\n<td>&lt;500ms for refined query</td>\n<td>Better results for more specific queries</td>\n</tr>\n<tr>\n<td>Autocomplete Flow</td>\n<td>Type characters → see suggestions → select suggestion</td>\n<td>Helpful suggestions, smooth UX</td>\n<td>&lt;100ms suggestion latency</td>\n<td>Suggestions lead to good results</td>\n</tr>\n<tr>\n<td>Faceted Browsing</td>\n<td>Search → apply filters → refine results</td>\n<td>Accurate filtering, updated counts</td>\n<td>&lt;800ms with facet computation</td>\n<td>Filters produce expected subsets</td>\n</tr>\n<tr>\n<td>Mobile Experience</td>\n<td>Same flows on mobile simulator</td>\n<td>Responsive design, touch-friendly</td>\n<td>Same performance targets</td>\n<td>Readable on small screens</td>\n</tr>\n</tbody></table>\n<p><strong>Production Readiness Checklist</strong></p>\n<table>\n<thead>\n<tr>\n<th>Readiness Category</th>\n<th>Verification Items</th>\n<th>Status Check</th>\n<th>Acceptance Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Performance SLAs</td>\n<td>All response time targets met</td>\n<td>Automated load testing</td>\n<td>95% of requests meet SLA under load</td>\n</tr>\n<tr>\n<td>Error Handling</td>\n<td>Graceful degradation tested</td>\n<td>Fault injection testing</td>\n<td>System remains available with degraded features</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Metrics collection and alerting</td>\n<td>Dashboard verification</td>\n<td>All key metrics tracked and alerted</td>\n</tr>\n<tr>\n<td>Security</td>\n<td>Input validation and sanitization</td>\n<td>Security testing scan</td>\n<td>No vulnerabilities in common attacks</td>\n</tr>\n<tr>\n<td>Documentation</td>\n<td>API docs and runbooks</td>\n<td>Manual review</td>\n<td>Complete documentation for operators</td>\n</tr>\n<tr>\n<td>Deployment</td>\n<td>Automated deployment pipeline</td>\n<td>CI/CD verification</td>\n<td>Zero-downtime deployments working</td>\n</tr>\n</tbody></table>\n<p><strong>Verification Checkpoint Commands</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Complete system verification</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> tests.integration_verification</span><span style=\"color:#79B8FF\"> --test-suite=api</span><span style=\"color:#79B8FF\"> --environment=staging</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> tests.integration_verification</span><span style=\"color:#79B8FF\"> --test-suite=e2e</span><span style=\"color:#79B8FF\"> --browser=chrome</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Search API: All endpoints responding, P95 latency within targets</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Autocomplete: &#x3C;100ms response time, 85% suggestion quality  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ End-to-end: User journeys complete successfully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># ✓ Production readiness: 18/18 checklist items verified</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Verification Success Pattern</strong>: Each milestone should demonstrate clear quality progression — Milestone 1 proves the foundation works correctly, Milestone 2 shows intelligent query understanding, Milestone 3 delivers excellent result ranking, and Milestone 4 provides production-ready user experience. Failure at any checkpoint requires fixing before proceeding to the next milestone.</p>\n</blockquote>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Test Framework</td>\n<td>pytest with fixtures</td>\n<td>pytest + hypothesis property testing</td>\n<td>pytest provides excellent search-specific fixtures</td>\n</tr>\n<tr>\n<td>Load Testing</td>\n<td>locust with custom scenarios</td>\n<td>k6 with JavaScript scenarios</td>\n<td>locust better for Python integration</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Python logging + JSON</td>\n<td>Prometheus + Grafana</td>\n<td>JSON logging sufficient for development</td>\n</tr>\n<tr>\n<td>Test Data Management</td>\n<td>JSON files + Git LFS</td>\n<td>Database with versioning</td>\n<td>JSON files easier for reproducible tests</td>\n</tr>\n<tr>\n<td>Relevance Evaluation</td>\n<td>Manual CSV judgments</td>\n<td>MLflow experiment tracking</td>\n<td>CSV sufficient for initial evaluation</td>\n</tr>\n<tr>\n<td>Performance Monitoring</td>\n<td>Python time.time()</td>\n<td>APM tool (DataDog, New Relic)</td>\n<td>Built-in timing for development phase</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-testing-structure\">Recommended Testing Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>tests/\n├── conftest.py                    ← pytest fixtures and configuration\n├── test_data/                     ← test documents and queries\n│   ├── sample_documents.json      ← 1000 representative documents\n│   ├── test_queries.json          ← 200 test queries with categories\n│   └── relevance_judgments.csv    ← expert relevance ratings\n├── unit/                          ← component unit tests\n│   ├── test_embedding.py          ← document encoding tests\n│   ├── test_index.py              ← vector index tests\n│   ├── test_query_processing.py   ← query understanding tests\n│   └── test_ranking.py            ← ranking algorithm tests\n├── integration/                   ← component integration tests\n│   ├── test_search_pipeline.py    ← end-to-end search flow\n│   ├── test_api_endpoints.py      ← REST API testing\n│   └── test_error_handling.py     ← failure mode testing\n├── performance/                   ← load and performance tests\n│   ├── test_latency.py            ← response time validation\n│   ├── test_throughput.py         ← concurrent user testing\n│   └── load_scenarios.py          ← realistic traffic patterns\n└── quality/                       ← search quality evaluation\n    ├── test_relevance.py          ← offline relevance metrics\n    ├── test_ranking_quality.py    ← ranking effectiveness\n    └── evaluation_framework.py    ← quality measurement tools</code></pre></div>\n\n<h4 id=\"complete-test-infrastructure-starter-code\">Complete Test Infrastructure Starter Code</h4>\n<p><strong>Test Configuration and Fixtures</strong> (<code>tests/conftest.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pandas </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> pd</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> unittest.mock </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Mock</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Document, DocumentEmbedding, QueryRequest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.embedding_index </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> EmbeddingIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.query_processor </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueryProcessor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.ranking_engine </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> RankingEngine</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.search_api </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SearchAPI</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test data paths</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TEST_DATA_DIR</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Path(</span><span style=\"color:#79B8FF\">__file__</span><span style=\"color:#E1E4E8\">).parent </span><span style=\"color:#F97583\">/</span><span style=\"color:#9ECBFF\"> \"test_data\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">SAMPLE_DOCS_PATH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> TEST_DATA_DIR</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"sample_documents.json\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TEST_QUERIES_PATH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> TEST_DATA_DIR</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"test_queries.json\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">RELEVANCE_JUDGMENTS_PATH</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> TEST_DATA_DIR</span><span style=\"color:#F97583\"> /</span><span style=\"color:#9ECBFF\"> \"relevance_judgments.csv\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">scope</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"session\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> sample_documents</span><span style=\"color:#E1E4E8\">() -> List[Document]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load sample documents for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">SAMPLE_DOCS_PATH</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        docs_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> json.load(f)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Document(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            doc_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">doc[</span><span style=\"color:#9ECBFF\">\"doc_id\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            title</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">doc[</span><span style=\"color:#9ECBFF\">\"title\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            content</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">doc[</span><span style=\"color:#9ECBFF\">\"content\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            url</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">doc.get(</span><span style=\"color:#9ECBFF\">\"url\"</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            metadata</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">doc.get(</span><span style=\"color:#9ECBFF\">\"metadata\"</span><span style=\"color:#E1E4E8\">, {}),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            created_at</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">doc.get(</span><span style=\"color:#9ECBFF\">\"created_at\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> doc </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> docs_data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">scope</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"session\"</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_queries</span><span style=\"color:#E1E4E8\">() -> List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load test queries with categories and metadata.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">TEST_QUERIES_PATH</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.load(f)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#FFAB70\">scope</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"session\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> relevance_judgments</span><span style=\"color:#E1E4E8\">() -> pd.DataFrame:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load expert relevance judgments for evaluation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> pd.read_csv(</span><span style=\"color:#79B8FF\">RELEVANCE_JUDGMENTS_PATH</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> embedding_index</span><span style=\"color:#E1E4E8\">(sample_documents):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create and populate embedding index for testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EmbeddingIndex(</span><span style=\"color:#FFAB70\">model_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">DEFAULT_MODEL</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Add sample documents to index</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embeddings </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> doc </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> sample_documents[:</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">]:  </span><span style=\"color:#6A737D\"># Subset for faster tests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        embedding </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index.document_encoder.encode_document(doc)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        embeddings.append(embedding)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index.build_index(embeddings)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> index</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> query_processor</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Create configured query processor.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> QueryProcessor(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        embedding_model</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">DEFAULT_MODEL</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        enable_expansion</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        enable_caching</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> search_system</span><span style=\"color:#E1E4E8\">(embedding_index, query_processor):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete search system for integration testing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ranking_engine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> RankingEngine()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    search_api </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SearchAPI(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        embedding_index</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">embedding_index,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        query_processor</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">query_processor,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        ranking_engine</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ranking_engine</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> search_api</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> performance_timer</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Utility for measuring operation timing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    class</span><span style=\"color:#B392F0\"> Timer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.times </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> time_operation</span><span style=\"color:#E1E4E8\">(self, func, </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            start </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            end </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            elapsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (end </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#6A737D\">  # Convert to milliseconds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.times.append(elapsed)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> result, elapsed</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> get_percentile</span><span style=\"color:#E1E4E8\">(self, p):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> np.percentile(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.times, p)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> Timer()</span></span></code></pre></div>\n\n<p><strong>Search Quality Evaluation Framework</strong> (<code>tests/quality/evaluation_framework.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pandas </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> pd</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EvaluationMetrics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Container for search quality metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    precision_at_k: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recall_at_k: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    map_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ndcg_at_k: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    mrr_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    err_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchQualityEvaluator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive search quality evaluation framework.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, relevance_judgments: pd.DataFrame):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.judgments </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relevance_judgments</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.query_relevance </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._build_relevance_map()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _build_relevance_map</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Build query -> doc_id -> relevance mapping.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        relevance_map </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> _, row </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.judgments.iterrows():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            query </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> row[</span><span style=\"color:#9ECBFF\">'query'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            doc_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> row[</span><span style=\"color:#9ECBFF\">'doc_id'</span><span style=\"color:#E1E4E8\">] </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relevance </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> row[</span><span style=\"color:#9ECBFF\">'relevance_grade'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relevance_map[query][doc_id] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relevance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> dict</span><span style=\"color:#E1E4E8\">(relevance_map)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> evaluate_search_results</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result_doc_ids: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        k_values: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ) -> EvaluationMetrics:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Evaluate search results against ground truth judgments.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> query </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.query_relevance:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logging.warning(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"No judgments available for query: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">query</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._empty_metrics(k_values)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        relevance_scores </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        binary_relevance </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> doc_id </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> result_doc_ids:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relevance </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.query_relevance[query].get(doc_id, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relevance_scores.append(relevance)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            binary_relevance.append(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> relevance </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total_relevant </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> rel </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.query_relevance[query].values() </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> rel </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        precision_at_k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        recall_at_k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ndcg_at_k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> k_values:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate precision@k: relevant results in top k / k</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate recall@k: relevant results in top k / total relevant</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate NDCG@k using graded relevance scores</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate MAP (Mean Average Precision)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        map_score </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate MRR (Mean Reciprocal Rank)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        mrr_score </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate ERR (Expected Reciprocal Rank)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        err_score </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> EvaluationMetrics(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            precision_at_k</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">precision_at_k,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            recall_at_k</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">recall_at_k,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            map_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">map_score,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            ndcg_at_k</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ndcg_at_k,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            mrr_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">mrr_score,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            err_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">err_score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_precision_at_k</span><span style=\"color:#E1E4E8\">(self, binary_relevance: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">], k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate precision@k metric.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement precision@k calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: relevant results in top k divided by k</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_dcg</span><span style=\"color:#E1E4E8\">(self, relevance_scores: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">], k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate Discounted Cumulative Gain.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement DCG calculation </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Formula: sum(rel_i / log2(i+1)) for i in range(min(k, len(relevance_scores)))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_ndcg</span><span style=\"color:#E1E4E8\">(self, relevance_scores: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">], k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate Normalized Discounted Cumulative Gain.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate NDCG = DCG@k / IDCG@k</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # IDCG is DCG of perfect ranking (sorted by relevance)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Performance Testing Infrastructure</strong> (<code>tests/performance/load_testing.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> aiohttp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> statistics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> concurrent.futures </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ThreadPoolExecutor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> LoadTestResult</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Results from load testing execution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    total_requests: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    successful_requests: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failed_requests: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    avg_response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    p50_response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    p95_response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    p99_response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    requests_per_second: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_rate: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchLoadTester</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load testing framework for search API.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, test_queries: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_url</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_queries </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> test_queries</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> execute_search_request</span><span style=\"color:#E1E4E8\">(self, session: aiohttp.ClientSession, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute single search request and measure timing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Make POST request to /search endpoint with query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate response has expected structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return (response_time_ms, success_boolean)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            end_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (end_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> response_time, </span><span style=\"color:#79B8FF\">False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> run_concurrent_load_test</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        self,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        concurrent_users: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        duration_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query_pattern: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"random\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ) -> LoadTestResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run load test with specified concurrency.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create aiohttp ClientSession</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Launch concurrent_users number of worker tasks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Each worker makes requests for duration_seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Collect timing and success/failure data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate and return LoadTestResult metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> simulate_realistic_user_behavior</span><span style=\"color:#E1E4E8\">(self, session: aiohttp.ClientSession) -> List[Tuple[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Simulate realistic user search patterns.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Implement realistic user session:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # 1. Start with broad query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # 2. Refine query based on results  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # 3. Maybe try autocomplete</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # 4. Click on result (simulate)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # 5. Possible follow-up search</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_traffic_spike</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        baseline_qps: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        spike_multiplier: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        spike_duration: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ) -> LoadTestResult:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test system behavior under traffic spikes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate baseline traffic for warmup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Spike traffic to baseline_qps * spike_multiplier</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return to baseline</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Measure performance degradation during spike</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-verification-scripts\">Milestone Verification Scripts</h4>\n<p><strong>Milestone 1 Index Verification</strong> (<code>tests/integration/test_milestone1.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.embedding_index </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> EmbeddingIndex</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> src.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Document, </span><span style=\"color:#79B8FF\">DEFAULT_MODEL</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestMilestone1Verification</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Verification tests for Milestone 1: Embedding Index.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_index_construction_scalability</span><span style=\"color:#E1E4E8\">(self, sample_documents):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify index can handle large document volumes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EmbeddingIndex(</span><span style=\"color:#FFAB70\">model_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">DEFAULT_MODEL</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Test with increasing document counts: 1K, 10K, 100K</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Measure build time and memory usage at each scale</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify build time grows sub-linearly with document count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assert memory usage remains within acceptable bounds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        assert</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#6A737D\">  # Replace with actual assertions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_similarity_search_accuracy</span><span style=\"color:#E1E4E8\">(self, embedding_index, test_queries):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify search results match expected similarity patterns.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> query_data </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> test_queries[:</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">]:  </span><span style=\"color:#6A737D\"># Test subset</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            query_text </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> query_data[</span><span style=\"color:#9ECBFF\">\"query\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            expected_docs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> query_data.get(</span><span style=\"color:#9ECBFF\">\"expected_similar_docs\"</span><span style=\"color:#E1E4E8\">, [])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Execute similarity search for query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if expected documents appear in top 20 results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify similarity scores are reasonable (> 0.5 for relevant docs)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assert approximate nearest neighbor quality vs exact search</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_incremental_index_updates</span><span style=\"color:#E1E4E8\">(self, embedding_index):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify new documents can be added without full rebuild.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        initial_size </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> embedding_index.get_document_count()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add batch of new documents to existing index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify new documents are immediately searchable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Verify existing search results unchanged</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assert update time is much faster than full rebuild</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_index_persistence_correctness</span><span style=\"color:#E1E4E8\">(self, embedding_index, tmp_path):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify index can be saved and loaded correctly.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Save index to temporary directory</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Load index from saved state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compare search results before and after save/load</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Assert exact result reproduction after persistence</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"debugging-and-troubleshooting-guide\">Debugging and Troubleshooting Guide</h4>\n<p><strong>Common Testing Issues and Solutions</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Search quality tests fail</td>\n<td>Poor test query selection</td>\n<td>Check query-document relevance overlap</td>\n<td>Use domain-expert created test queries</td>\n</tr>\n<tr>\n<td>Load tests show high variance</td>\n<td>Inconsistent test environment</td>\n<td>Monitor CPU, memory during tests</td>\n<td>Use dedicated test infrastructure</td>\n</tr>\n<tr>\n<td>Relevance metrics unrealistically low</td>\n<td>Judgment-result mismatch</td>\n<td>Verify judgment format matches results</td>\n<td>Align document ID formats</td>\n</tr>\n<tr>\n<td>Performance tests fail intermittently</td>\n<td>Resource contention</td>\n<td>Check for background processes</td>\n<td>Isolate test environment</td>\n</tr>\n<tr>\n<td>Index accuracy tests inconsistent</td>\n<td>Vector normalization issues</td>\n<td>Check embedding unit lengths</td>\n<td>Ensure cosine similarity normalization</td>\n</tr>\n<tr>\n<td>Memory usage grows during long tests</td>\n<td>Memory leaks in test code</td>\n<td>Profile memory usage over time</td>\n<td>Clear caches between test runs</td>\n</tr>\n</tbody></table>\n<p>This comprehensive testing strategy ensures that each milestone delivers production-ready functionality with measurable quality and performance characteristics, providing confidence for system deployment and user satisfaction.</p>\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), establishing comprehensive debugging strategies that help identify and resolve issues encountered during implementation of embedding indices (Milestone 1), query processing (Milestone 2), ranking systems (Milestone 3), and search APIs (Milestone 4).</p>\n</blockquote>\n<p>Think of debugging a semantic search engine like being a medical diagnostician examining a complex patient with multiple interconnected organ systems. Just as a doctor uses systematic symptom analysis, diagnostic tests, and treatment protocols to identify and resolve health issues, debugging our search engine requires methodical investigation of symptoms, understanding root causes, and applying targeted fixes. Each component—the embedding index, query processor, ranking engine, and search API—can exhibit distinct failure patterns, but problems often cascade across component boundaries, making systematic diagnosis essential for maintaining search quality and performance.</p>\n<p>The debugging process for semantic search systems presents unique challenges compared to traditional software debugging. Unlike deterministic systems where identical inputs always produce identical outputs, semantic search involves probabilistic components like neural embedding models, approximate nearest neighbor algorithms, and learned ranking functions. This probabilistic nature means that &quot;correct&quot; behavior exists on a spectrum rather than as binary right-or-wrong states, making it crucial to understand expected ranges of behavior and develop debugging techniques that account for statistical variation.</p>\n<p>Our debugging strategy follows a structured approach that moves from surface symptoms to root causes, then to verification of fixes. Each subsection provides comprehensive symptom-cause-fix mappings organized by component area, enabling rapid identification of issues during development and production operation. The debugging techniques presented here assume you have implemented comprehensive logging and monitoring as described in the Error Handling and Edge Cases section, providing the observability foundation necessary for effective diagnosis.</p>\n<blockquote>\n<p><strong>Key Debugging Principle</strong>: Always verify your assumptions with data. Semantic search systems often fail in subtle ways where components appear to work correctly in isolation but produce poor results when integrated. Use quantitative metrics, not intuition, to validate that fixes actually improve behavior.</p>\n</blockquote>\n<h3 id=\"embedding-and-index-issues\">Embedding and Index Issues</h3>\n<p>The embedding and index layer forms the foundation of semantic search, and problems here cascade through every other component. Think of this layer as the nervous system of your search engine—when embeddings misrepresent meaning or indices fail to find similar vectors, the entire system loses its ability to understand and match semantic intent. Debugging embedding and index issues requires understanding both the mathematical properties of vector spaces and the operational characteristics of approximate nearest neighbor algorithms.</p>\n<h4 id=\"vector-dimension-mismatches\">Vector Dimension Mismatches</h4>\n<p>Vector dimension mismatches represent one of the most common and immediately fatal errors in semantic search systems. These issues typically manifest during system integration when different components expect vectors of different dimensionalities, or when upgrading embedding models without properly migrating existing indices.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>ValueError: shapes (1,384) and (1,512) not aligned</code> during similarity calculation</td>\n<td>Mixing embeddings from different models (e.g., <code>all-MiniLM-L6-v2</code> with <code>all-mpnet-base-v2</code>)</td>\n<td>Check <code>DocumentEncoder.embedding_dim</code> and <code>ProcessedQuery.primary_embedding.shape[0]</code></td>\n<td>Rebuild index with consistent model or implement model migration</td>\n</tr>\n<tr>\n<td>FAISS index throws <code>AssertionError: d == index.d</code> when adding vectors</td>\n<td>Attempting to add vectors with wrong dimension to existing index</td>\n<td>Log <code>embedding.shape</code> before <code>index.add()</code> call, compare with index dimension</td>\n<td>Recreate index with correct dimension or fix embedding generation</td>\n</tr>\n<tr>\n<td>Search returns empty results despite having indexed documents</td>\n<td>Query embedding dimension differs from document embedding dimension</td>\n<td>Compare <code>encode_query()</code> output shape with <code>DocumentEmbedding.embedding_dim</code></td>\n<td>Ensure query and document use same <code>DocumentEncoder</code> instance</td>\n</tr>\n<tr>\n<td>Index loading fails with cryptic FAISS errors</td>\n<td>Saved index expects different dimension than current model</td>\n<td>Check saved index metadata against current <code>DEFAULT_MODEL</code> configuration</td>\n<td>Either revert to original model or rebuild index from scratch</td>\n</tr>\n</tbody></table>\n<p>⚠️ <strong>Pitfall: Silent Dimension Mismatches</strong>\nPython&#39;s NumPy broadcasting can sometimes hide dimension mismatches by automatically reshaping arrays, leading to incorrect similarity calculations that produce seemingly valid but meaningless results. Always validate embedding dimensions explicitly rather than relying on implicit broadcasting.</p>\n<p>The most insidious dimension mismatch occurs during model upgrades. Consider this scenario: you start with <code>all-MiniLM-L6-v2</code> producing 384-dimensional embeddings, build a substantial index, then decide to upgrade to <code>all-mpnet-base-v2</code> for better quality. Simply changing the model configuration will cause new queries to generate 768-dimensional embeddings that cannot be compared against the existing 384-dimensional document embeddings in your index.</p>\n<blockquote>\n<p><strong>Design Insight</strong>: Always store embedding model metadata alongside the index itself. The <code>DocumentEmbedding.model_name</code> and <code>DocumentEmbedding.embedding_dim</code> fields should be persisted with the index and validated on loading to catch model configuration drift early.</p>\n</blockquote>\n<p><strong>Model Migration Strategy</strong>: When upgrading embedding models, implement a gradual migration process rather than rebuilding everything at once:</p>\n<ol>\n<li>Deploy the new model alongside the old model, maintaining both indices</li>\n<li>Route a small percentage of traffic to the new model to validate quality</li>\n<li>Gradually increase traffic to the new model while monitoring relevance metrics</li>\n<li>Once confident in the new model, begin background reprocessing of documents</li>\n<li>Switch fully to the new model and retire the old index</li>\n</ol>\n<h4 id=\"vector-normalization-problems\">Vector Normalization Problems</h4>\n<p>Vector normalization issues create subtle but significant problems in semantic search systems. Unlike dimension mismatches which fail loudly, normalization problems often manifest as poor search quality that&#39;s difficult to diagnose because the system appears to function correctly at a surface level.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Cosine similarity scores always near zero despite relevant results</td>\n<td>Vectors not normalized to unit length before similarity calculation</td>\n<td>Check <code>np.linalg.norm()</code> of sample embeddings - should be 1.0</td>\n<td>Apply <code>normalize_vector()</code> before storing and searching</td>\n</tr>\n<tr>\n<td>Search results heavily biased toward longer documents</td>\n<td>Using dot product instead of cosine similarity with unnormalized vectors</td>\n<td>Compare similarity scores between short and long documents for same query</td>\n<td>Switch to cosine similarity with proper normalization</td>\n</tr>\n<tr>\n<td>Inconsistent similarity scores for identical content</td>\n<td>Some vectors normalized, others not, creating mixed index</td>\n<td>Audit normalization in embedding pipeline - check <code>DocumentEmbedding</code> storage</td>\n<td>Rebuild index with consistent normalization policy</td>\n</tr>\n<tr>\n<td>FAISS inner product search returns unexpected ranking</td>\n<td>Inner product assumes normalized vectors but vectors aren&#39;t normalized</td>\n<td>Verify normalization before <code>IndexFlatIP.add()</code> calls</td>\n<td>Either normalize vectors or switch to <code>IndexFlatL2</code></td>\n</tr>\n</tbody></table>\n<p>The mathematical foundation of this issue lies in the difference between dot product and cosine similarity. Dot product between vectors <code>u</code> and <code>v</code> is <code>u·v = ||u|| ||v|| cos(θ)</code>, while cosine similarity is <code>cos(θ) = (u·v)/(||u|| ||v||)</code>. When vectors aren&#39;t normalized (i.e., <code>||u|| ≠ 1</code>), dot product conflates both the angle between vectors (semantic similarity) and their magnitudes (often related to document length or embedding generation artifacts).</p>\n<blockquote>\n<p><strong>Critical Implementation Detail</strong>: FAISS&#39;s <code>IndexFlatIP</code> (inner product) assumes normalized vectors to compute cosine similarity efficiently. If you use <code>IndexFlatIP</code> with unnormalized vectors, you&#39;re actually computing dot product, which will bias results toward longer documents or vectors with higher magnitudes.</p>\n</blockquote>\n<p><strong>Normalization Verification Process</strong>: During development, implement systematic normalization checks:</p>\n<ol>\n<li>After embedding generation, assert that <code>np.abs(np.linalg.norm(embedding) - 1.0) &lt; 1e-6</code></li>\n<li>Before adding to index, sample random vectors and verify unit length</li>\n<li>During search, log normalization status of query embeddings</li>\n<li>Implement health checks that periodically sample indexed vectors and verify normalization</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Selective Normalization</strong>\nNever normalize only queries or only documents—this destroys the mathematical relationship needed for meaningful similarity calculation. Either normalize both or normalize neither, depending on whether you want cosine similarity or raw dot product.</p>\n<h4 id=\"index-corruption-and-recovery\">Index Corruption and Recovery</h4>\n<p>Index corruption represents the most severe embedding layer failure mode, potentially requiring complete index reconstruction. Think of index corruption like database corruption—the underlying data structure becomes inconsistent, leading to crashes, incorrect results, or performance degradation. Unlike database corruption which often has sophisticated recovery mechanisms, vector index corruption typically requires rebuilding from source data.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>FAISS throws segmentation faults during search</td>\n<td>Binary index file corruption from incomplete writes or disk errors</td>\n<td>Check index file size consistency, validate with <code>faiss.read_index()</code></td>\n<td>Restore from backup or rebuild from document embeddings</td>\n</tr>\n<tr>\n<td>Search returns inconsistent results for identical queries</td>\n<td>Partial index corruption affecting specific vector regions</td>\n<td>Run identical queries multiple times, check for result variance</td>\n<td>Identify corrupted region and rebuild affected partitions</td>\n</tr>\n<tr>\n<td>Index loading extremely slow or fails with memory errors</td>\n<td>Index file format corruption or version mismatch</td>\n<td>Compare file headers, check FAISS version compatibility</td>\n<td>Rebuild index with current FAISS version</td>\n</tr>\n<tr>\n<td>Search performance suddenly degrades after index update</td>\n<td>Incremental updates corrupted index structure</td>\n<td>Benchmark search latency over time, correlate with update events</td>\n<td>Disable incremental updates, schedule full rebuild</td>\n</tr>\n</tbody></table>\n<p>Index corruption typically occurs during one of several vulnerable operations:</p>\n<ol>\n<li><strong>Incremental Updates</strong>: Adding vectors to trained indices like IVF can sometimes corrupt internal data structures, especially under concurrent access</li>\n<li><strong>Incomplete Persistence</strong>: Process crashes or disk full conditions during index saving can leave partially written files</li>\n<li><strong>Memory Mapping Issues</strong>: Using memory-mapped indices with insufficient virtual memory can cause corruption on access</li>\n<li><strong>Version Incompatibility</strong>: Loading indices created with different FAISS versions may fail or produce incorrect results</li>\n</ol>\n<blockquote>\n<p><strong>Recovery Strategy</strong>: Always maintain multiple generations of index backups. Keep the last three successful index builds with their corresponding document embedding caches. This allows you to roll back to a known-good state while investigating corruption causes.</p>\n</blockquote>\n<p><strong>Corruption Prevention Measures</strong>:</p>\n<ol>\n<li><strong>Atomic Index Updates</strong>: Write new indices to temporary files and atomically rename them to replace old indices</li>\n<li><strong>Checksum Validation</strong>: Store and verify checksums for index files to detect corruption early</li>\n<li><strong>Graceful Degradation</strong>: Design your system to fall back to previous index versions when corruption is detected</li>\n<li><strong>Separate Training and Search Indices</strong>: Use read-only indices for search while building updates separately</li>\n</ol>\n<p><strong>Index Health Monitoring</strong>: Implement regular health checks that verify index integrity:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> validate_index_health</span><span style=\"color:#E1E4E8\">(index_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, sample_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Validate index integrity by performing sample searches.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Check file integrity</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> verify_index_checksum(index_path):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Load index and verify basic properties</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> faiss.read_index(index_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> index.ntotal </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Perform sample searches to detect corruption</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(sample_size):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        query_vector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> generate_random_query()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            scores, indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index.search(query_vector, </span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(indices[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#79B8FF\"> True</span></span></code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Ignoring Soft Corruption</strong>\nIndex corruption doesn&#39;t always manifest as crashes. Sometimes indices become subtly corrupted, returning plausible but incorrect results. Implement regression tests with known query-result pairs to catch soft corruption.</p>\n<h3 id=\"search-relevance-problems\">Search Relevance Problems</h3>\n<p>Search relevance problems represent the most challenging debugging category because they involve subjective quality judgments rather than objective correctness. Think of relevance debugging like wine tasting—you need trained palates (evaluation datasets), systematic methodology (relevance metrics), and understanding of complex interactions between multiple factors (ranking signals, query processing, personalization). Unlike crashes or performance issues which have clear failure indicators, relevance problems require careful measurement and analysis to identify root causes.</p>\n<p>The complexity of relevance debugging stems from the multi-layered nature of semantic search systems. A poor search result might be caused by inadequate document embeddings, failed query expansion, incorrect signal weighting in the ranking engine, or cascading effects from multiple components. Effective relevance debugging requires isolating each component&#39;s contribution to the final result and understanding how they interact.</p>\n<h4 id=\"poor-result-quality\">Poor Result Quality</h4>\n<p>Poor result quality manifests as high-level symptoms that users notice directly—irrelevant results appearing in top positions, relevant results missing entirely, or inconsistent quality across different query types. These symptoms often have multiple contributing factors, making systematic analysis essential for identifying the primary causes.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Relevant documents consistently missing from top-10 results</td>\n<td>Embedding model doesn&#39;t understand domain-specific terminology</td>\n<td>Test queries with domain-specific terms, check if embeddings cluster appropriately</td>\n<td>Fine-tune embedding model or use domain-specific pre-trained model</td>\n</tr>\n<tr>\n<td>Results quality varies dramatically across query types</td>\n<td>Query processing treats all queries identically despite different intents</td>\n<td>Analyze query distribution by intent, measure precision@k by query type</td>\n<td>Implement intent-specific processing in <code>QueryProcessor</code></td>\n</tr>\n<tr>\n<td>Search returns syntactically similar but semantically irrelevant results</td>\n<td>Over-reliance on lexical matching without semantic understanding</td>\n<td>Compare BM25-only vs. semantic-only results for sample queries</td>\n<td>Rebalance hybrid search weights in <code>combine_signals()</code></td>\n</tr>\n<tr>\n<td>Recently relevant results no longer appear after system updates</td>\n<td>Embedding model changed without reprocessing existing documents</td>\n<td>Compare embedding similarities before/after model updates</td>\n<td>Implement embedding version tracking and migration</td>\n</tr>\n</tbody></table>\n<p>The most common cause of poor result quality is <strong>vocabulary mismatch</strong> between the embedding model&#39;s training data and your search domain. Pre-trained models like <code>all-MiniLM-L6-v2</code> perform well on general text but may struggle with specialized terminology in fields like medicine, law, or engineering. This manifests as embeddings that cluster unrelated documents with similar surface-level language while separating conceptually related documents that use different terminology.</p>\n<blockquote>\n<p><strong>Quality Diagnosis Framework</strong>: For any relevance complaint, first isolate whether the problem lies in retrieval (finding candidate documents) or ranking (ordering retrieved candidates). Run the query against your index to retrieve top-100 candidates, then manually assess whether the desired result appears anywhere in those candidates.</p>\n</blockquote>\n<p><strong>Systematic Quality Analysis Process</strong>:</p>\n<ol>\n<li><p><strong>Component Isolation</strong>: Test each component independently:</p>\n<ul>\n<li>Run semantic search only (no BM25, no personalization)</li>\n<li>Run lexical search only (BM25 without semantic signals)</li>\n<li>Test query processing with simple, unambiguous queries</li>\n<li>Verify ranking with manually curated candidate sets</li>\n</ul>\n</li>\n<li><p><strong>Ground Truth Validation</strong>: Establish objective quality baselines:</p>\n<ul>\n<li>Create evaluation datasets with expert-judged query-document pairs</li>\n<li>Measure precision@k, recall@k, and NDCG across query categories</li>\n<li>Track quality metrics over time to detect regressions</li>\n</ul>\n</li>\n<li><p><strong>Error Case Analysis</strong>: Systematically analyze failed cases:</p>\n<ul>\n<li>Collect queries that return zero relevant results in top-10</li>\n<li>Identify patterns in failed queries (length, complexity, domain)</li>\n<li>Analyze embedding similarities for failed query-document pairs</li>\n</ul>\n</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Anecdotal Quality Assessment</strong>\nNever base quality judgments on individual examples or personal opinions. What seems &quot;obviously relevant&quot; to one person may not be relevant to users with different contexts or needs. Always use multiple human judges and quantitative metrics.</p>\n<h4 id=\"ranking-issues-and-score-calibration\">Ranking Issues and Score Calibration</h4>\n<p>Ranking problems occur when the multi-stage ranking pipeline produces scores that don&#39;t align with human relevance judgments. These issues are particularly subtle because the individual ranking signals (semantic similarity, BM25, personalization, freshness) might each be working correctly, but their combination produces suboptimal ordering.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Semantic scores dominate other signals regardless of query type</td>\n<td>Poor signal weight calibration in <code>combine_signals()</code></td>\n<td>Log individual signal values vs. combined scores for sample queries</td>\n<td>Retune signal weights using learning-to-rank on labeled data</td>\n</tr>\n<tr>\n<td>Recent documents always rank higher than more relevant older documents</td>\n<td>Freshness decay function too aggressive</td>\n<td>Compare ranking with/without freshness signals, analyze optimal document age</td>\n<td>Adjust freshness decay parameters or make query-type dependent</td>\n</tr>\n<tr>\n<td>Personalization creates filter bubbles, missing broadly relevant results</td>\n<td>Personalization signal weight too high</td>\n<td>Measure result diversity across different user contexts</td>\n<td>Implement diversity constraints or reduce personalization weight</td>\n</tr>\n<tr>\n<td>Cross-encoder reranking contradicts semantic retrieval frequently</td>\n<td>Cross-encoder and embedding model trained on different data</td>\n<td>Compare cross-encoder scores with semantic similarity for same pairs</td>\n<td>Use consistent training data or implement score calibration</td>\n</tr>\n</tbody></table>\n<p>Score calibration represents one of the most technically challenging aspects of relevance debugging. Each ranking signal operates on different scales and distributions:</p>\n<ul>\n<li><strong>Semantic similarity</strong>: Typically ranges from 0.0 to 1.0 with concentration around 0.3-0.7</li>\n<li><strong>BM25 scores</strong>: Unbounded positive values with high variance depending on document length and term frequency</li>\n<li><strong>Personalization scores</strong>: Often binary or categorical based on user attributes</li>\n<li><strong>Freshness scores</strong>: Exponential decay functions with parameters that dramatically affect score ranges</li>\n</ul>\n<blockquote>\n<p><strong>Signal Calibration Strategy</strong>: Convert all ranking signals to percentile ranks within their expected distributions rather than using raw scores. This ensures that each signal contributes proportionally to the final ranking regardless of its natural scale.</p>\n</blockquote>\n<p><strong>Multi-Stage Ranking Debug Process</strong>:</p>\n<ol>\n<li><p><strong>Stage-by-Stage Analysis</strong>: Debug each ranking stage independently</p>\n<ul>\n<li>Verify candidate retrieval finds relevant documents in top-100</li>\n<li>Analyze signal computation for individual query-document pairs</li>\n<li>Test cross-encoder reranking on manually selected candidates</li>\n<li>Measure correlation between individual signals and human judgments</li>\n</ul>\n</li>\n<li><p><strong>Score Distribution Analysis</strong>: Understand how scores behave across your data</p>\n<ul>\n<li>Plot histograms of each ranking signal across your document collection</li>\n<li>Identify outliers and understand their causes</li>\n<li>Measure correlation between different signals to detect redundancy</li>\n<li>Track score distributions over time to detect drift</li>\n</ul>\n</li>\n<li><p><strong>A/B Testing for Ranking Changes</strong>: Never deploy ranking changes without measurement</p>\n<ul>\n<li>Implement side-by-side ranking comparison tools</li>\n<li>Use interleaved evaluation to measure relative ranking quality</li>\n<li>Track click-through rates and user engagement metrics</li>\n<li>Maintain champion/challenger testing framework for ranking experiments</li>\n</ul>\n</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Local Ranking Optimization</strong>\nOptimizing ranking for specific query examples often hurts overall system quality by overfitting to unrepresentative cases. Always validate ranking changes against comprehensive evaluation datasets covering diverse query types and user contexts.</p>\n<p><strong>Learning from Click-Through Data</strong>: When users interact with search results, their behavior provides valuable signals about ranking quality:</p>\n<ol>\n<li><strong>Position Bias Correction</strong>: Users are more likely to click higher-ranked results regardless of relevance</li>\n<li><strong>Dwell Time Analysis</strong>: Time spent on clicked results indicates satisfaction better than click-through rate alone</li>\n<li><strong>Skip Analysis</strong>: When users click result #5 but skip results #1-4, it suggests ranking problems</li>\n<li><strong>Query Reformulation</strong>: Immediate query changes after seeing results indicate initial ranking failure</li>\n</ol>\n<h3 id=\"performance-and-latency-issues\">Performance and Latency Issues</h3>\n<p>Performance and latency problems in semantic search systems present unique debugging challenges because they involve the interaction between computationally expensive operations (neural network inference, high-dimensional vector search) and real-time user expectations. Think of performance debugging like optimizing a complex manufacturing pipeline—you need to identify bottlenecks, understand capacity constraints, and balance quality against speed while maintaining consistent throughput under varying load conditions.</p>\n<p>The performance characteristics of semantic search differ significantly from traditional database systems. While database queries have relatively predictable performance based on data size and index structure, semantic search involves probabilistic algorithms (approximate nearest neighbor search), neural network inference with variable computational complexity, and multi-stage processing pipelines where each stage has different performance characteristics and failure modes.</p>\n<blockquote>\n<p><strong>Performance Debugging Philosophy</strong>: Always measure before optimizing. Semantic search systems have many potential bottlenecks—embedding generation, vector index search, cross-encoder reranking, result formatting—and intuition about which component is slowest is often wrong. Use detailed timing instrumentation to identify actual bottlenecks.</p>\n</blockquote>\n<h4 id=\"slow-search-responses\">Slow Search Responses</h4>\n<p>Slow search responses represent the most visible performance problem, directly impacting user experience and system scalability. Search latency is particularly challenging to debug because it involves multiple components with different performance characteristics, and the bottleneck can shift based on query characteristics, system load, and data size.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Search latency exceeds 500ms consistently</td>\n<td>Query embedding generation taking too long</td>\n<td>Profile <code>encode_query()</code> execution time vs. vector search time</td>\n<td>Cache frequent query embeddings or use smaller/faster embedding model</td>\n</tr>\n<tr>\n<td>Latency highly variable (50ms to 2000ms) for similar queries</td>\n<td>Cross-encoder reranking not properly batched</td>\n<td>Measure cross-encoder inference time vs. batch size</td>\n<td>Implement proper batching or reduce cross-encoder candidate count</td>\n</tr>\n<tr>\n<td>Performance degrades significantly with index size</td>\n<td>Using brute-force search instead of approximate algorithms</td>\n<td>Compare search time growth with document count</td>\n<td>Implement HNSW or IVF indexing for large document collections</td>\n</tr>\n<tr>\n<td>Concurrent searches cause timeout cascades</td>\n<td>Embedding model inference not thread-safe or resource-constrained</td>\n<td>Load test with multiple concurrent queries, monitor CPU/GPU utilization</td>\n<td>Implement proper model sharing or request queuing</td>\n</tr>\n</tbody></table>\n<p>The query processing pipeline has several stages with different performance characteristics:</p>\n<ol>\n<li><strong>Query Understanding</strong> (1-5ms): Text normalization, entity extraction, query expansion</li>\n<li><strong>Embedding Generation</strong> (10-100ms): Neural network inference to convert query to vector</li>\n<li><strong>Vector Search</strong> (1-50ms): Approximate nearest neighbor search through index</li>\n<li><strong>Initial Ranking</strong> (5-20ms): Computing and combining ranking signals</li>\n<li><strong>Cross-Encoder Reranking</strong> (50-500ms): Precise but expensive pairwise scoring</li>\n<li><strong>Result Formatting</strong> (1-10ms): Snippet generation and highlighting</li>\n</ol>\n<blockquote>\n<p><strong>Latency Budget Allocation</strong>: Establish time budgets for each processing stage and implement timeout mechanisms. For a 500ms total latency target, a reasonable allocation might be: embedding (100ms), search (50ms), initial ranking (50ms), reranking (250ms), formatting (50ms).</p>\n</blockquote>\n<p><strong>Performance Profiling Strategy</strong>:</p>\n<ol>\n<li><strong>Component-Level Timing</strong>: Instrument each major component with detailed timing</li>\n<li><strong>Request Tracing</strong>: Use correlation IDs to track individual requests through the pipeline</li>\n<li><strong>Resource Utilization Monitoring</strong>: Track CPU, memory, and I/O usage during different operations</li>\n<li><strong>Latency Distribution Analysis</strong>: Monitor P50, P95, P99 latencies, not just averages</li>\n</ol>\n<p>⚠️ <strong>Pitfall: Average Latency Optimization</strong>\nOptimizing for average latency often ignores tail latency (P95, P99) which disproportionately affects user experience. A system with 100ms average latency but 5-second P99 latency will feel slow to users.</p>\n<p><strong>Common Performance Bottlenecks and Solutions</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Bottleneck</th>\n<th>Solution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Query Embedding</td>\n<td>Model inference on CPU</td>\n<td>Move to GPU or use quantized models</td>\n</tr>\n<tr>\n<td>Vector Search</td>\n<td>Linear scan through large index</td>\n<td>Implement HNSW or IVF approximate search</td>\n</tr>\n<tr>\n<td>Cross-Encoder</td>\n<td>Individual inference calls</td>\n<td>Batch multiple candidates together</td>\n</tr>\n<tr>\n<td>Result Formatting</td>\n<td>Regex-heavy text highlighting</td>\n<td>Pre-compute highlights or use efficient string algorithms</td>\n</tr>\n</tbody></table>\n<h4 id=\"memory-usage-problems\">Memory Usage Problems</h4>\n<p>Memory usage problems in semantic search systems stem from the high-dimensional nature of vector embeddings and the need to maintain large indices in memory for fast search. Unlike traditional search systems where memory usage grows roughly linearly with document count, semantic search memory usage depends on embedding dimensionality, index algorithm parameters, and caching strategies, creating complex memory management challenges.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Root Cause</th>\n<th>Diagnostic Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Out-of-memory errors during index construction</td>\n<td>HNSW index with excessive <code>M</code> parameter creating too many connections</td>\n<td>Monitor memory growth during index build, calculate theoretical memory usage</td>\n<td>Reduce HNSW <code>M</code> parameter or switch to IVF indexing</td>\n</tr>\n<tr>\n<td>Memory usage grows continuously during operation</td>\n<td>Embedding cache without proper eviction policy</td>\n<td>Monitor cache size growth over time, check <code>EmbeddingCache</code> statistics</td>\n<td>Implement LRU eviction with memory-based limits</td>\n</tr>\n<tr>\n<td>System becomes unresponsive under memory pressure</td>\n<td>Index larger than available RAM causing swap thrashing</td>\n<td>Monitor swap usage and page fault rates during searches</td>\n<td>Implement memory-mapped indices or distributed search</td>\n</tr>\n<tr>\n<td>Memory spikes during concurrent searches</td>\n<td>Multiple threads loading large models simultaneously</td>\n<td>Profile memory usage during concurrent operations</td>\n<td>Implement proper model sharing and resource pooling</td>\n</tr>\n</tbody></table>\n<p><strong>Memory Usage Analysis Framework</strong>:</p>\n<p>Understanding memory consumption requires analyzing several distinct categories:</p>\n<ol>\n<li><p><strong>Base Index Memory</strong>: Core vector storage and index structure</p>\n<ul>\n<li>HNSW: ~(embedding_dim × 4 bytes + M × connections × 8 bytes) per vector  </li>\n<li>IVF: ~(embedding_dim × 4 bytes) per vector plus centroid storage</li>\n<li>Flat: ~(embedding_dim × 4 bytes) per vector</li>\n</ul>\n</li>\n<li><p><strong>Model Memory</strong>: Embedding model parameters and inference caches</p>\n<ul>\n<li>Transformer models: 100MB-1GB depending on model size</li>\n<li>Model inference caches: Variable based on batch size and sequence length</li>\n</ul>\n</li>\n<li><p><strong>Query Processing Memory</strong>: Temporary allocations during search</p>\n<ul>\n<li>Query embeddings, expanded term lists, candidate rankings</li>\n<li>Cross-encoder intermediate computations</li>\n</ul>\n</li>\n<li><p><strong>Application Caches</strong>: Performance optimization caches</p>\n<ul>\n<li>Query embedding cache, BM25 score cache, personalization caches</li>\n</ul>\n</li>\n</ol>\n<blockquote>\n<p><strong>Memory Management Strategy</strong>: Design your system to gracefully degrade under memory pressure rather than crashing. Implement cache eviction policies, fall back to smaller models, or reduce result quality (fewer cross-encoder candidates) when memory becomes constrained.</p>\n</blockquote>\n<p><strong>Memory-Mapped Index Strategy</strong>: For large document collections that exceed available RAM, implement memory-mapped indices that allow the operating system to manage virtual memory:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MemoryMappedIndex</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, index_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, mmap_mode: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'r'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Load index with memory mapping for large datasets.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.index_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index_path</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.mmap_mode </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mmap_mode</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> search</span><span style=\"color:#E1E4E8\">(self, query_embedding: np.ndarray, k: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[np.ndarray, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Search with automatic memory management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Use memory mapping to avoid loading entire index into RAM</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> open</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.index_path, </span><span style=\"color:#9ECBFF\">'rb'</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> f:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            index_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.memmap(f, </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">np.float32, </span><span style=\"color:#FFAB70\">mode</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.mmap_mode)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Perform search with memory-mapped data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._search_memmap(index_data, query_embedding, k)</span></span></code></pre></div>\n\n<p>⚠️ <strong>Pitfall: Memory Fragmentation</strong>\nFrequent allocation and deallocation of large vectors can cause memory fragmentation, leading to out-of-memory errors even when sufficient total memory is available. Use object pools for frequently allocated objects like embeddings and search results.</p>\n<p><strong>Monitoring and Alerting for Memory Issues</strong>:</p>\n<ol>\n<li><strong>Memory Usage Tracking</strong>: Monitor memory usage at component granularity</li>\n<li><strong>Cache Hit Rate Monitoring</strong>: Track cache effectiveness to justify memory usage</li>\n<li><strong>Memory Pressure Detection</strong>: Alert when memory usage exceeds safe thresholds</li>\n<li><strong>Graceful Degradation Triggers</strong>: Automatically reduce functionality under memory pressure</li>\n</ol>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The debugging techniques described above require systematic instrumentation and monitoring infrastructure to be effective in practice. This implementation guidance provides complete, production-ready debugging tools that complement the conceptual debugging frameworks.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logging Framework</td>\n<td>Python <code>logging</code> with structured JSON</td>\n<td>ELK Stack (Elasticsearch, Logstash, Kibana)</td>\n</tr>\n<tr>\n<td>Performance Monitoring</td>\n<td>Manual timing with <code>time.perf_counter()</code></td>\n<td>Datadog, New Relic, or Prometheus</td>\n</tr>\n<tr>\n<td>Error Tracking</td>\n<td>Simple error logging</td>\n<td>Sentry for error aggregation and alerting</td>\n</tr>\n<tr>\n<td>Memory Profiling</td>\n<td><code>psutil</code> for basic memory monitoring</td>\n<td><code>memory_profiler</code> or <code>pympler</code> for detailed analysis</td>\n</tr>\n<tr>\n<td>Request Tracing</td>\n<td>UUID correlation IDs</td>\n<td>OpenTelemetry for distributed tracing</td>\n</tr>\n</tbody></table>\n<h4 id=\"debugging-infrastructure-code\">Debugging Infrastructure Code</h4>\n<p><strong>Complete Performance Profiler</strong>: This profiler provides detailed timing information for each component in the search pipeline:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> functools</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, field</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceMetrics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete performance metrics for search operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    operation_name: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    duration_ms: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    memory_before_mb: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    memory_after_mb: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">property</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> memory_delta_mb</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.memory_after_mb </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.memory_before_mb</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SearchProfiler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Production-ready profiler for semantic search operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.metrics: List[PerformanceMetrics] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.active_operations: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> profile_operation</span><span style=\"color:#E1E4E8\">(self, operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">metadata):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager for profiling search operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        import</span><span style=\"color:#E1E4E8\"> psutil</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        process </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psutil.Process()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Record start metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        memory_before </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> process.memory_info().rss </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> /</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#6A737D\">  # MB</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Record end metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            end_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            memory_after </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> process.memory_info().rss </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#F97583\"> /</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#6A737D\">  # MB</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            duration_ms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (end_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            metric </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> PerformanceMetrics(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                operation_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">operation_name,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                start_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                end_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">end_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                duration_ms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">duration_ms,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                memory_before_mb</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">memory_before,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                memory_after_mb</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">memory_after,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                metadata</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">metadata</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.metrics.append(metric)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Log slow operations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> duration_ms </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Log operations over 100ms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                logging.warning(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Slow operation: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">operation_name</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> took </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">duration_ms</span><span style=\"color:#F97583\">:.1f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">ms\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> profile_function</span><span style=\"color:#E1E4E8\">(self, operation_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Decorator for profiling function calls.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        def</span><span style=\"color:#B392F0\"> decorator</span><span style=\"color:#E1E4E8\">(func):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            nonlocal</span><span style=\"color:#E1E4E8\"> operation_name</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> operation_name </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                operation_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">func.</span><span style=\"color:#79B8FF\">__module__}</span><span style=\"color:#9ECBFF\">.</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">func.</span><span style=\"color:#79B8FF\">__name__}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            @functools.wraps</span><span style=\"color:#E1E4E8\">(func)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            def</span><span style=\"color:#B392F0\"> wrapper</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.profile_operation(operation_name):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> func(</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\">args, </span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">kwargs)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> wrapper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> decorator</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_summary</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate performance summary statistics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.metrics:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"No metrics recorded\"</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        operations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> metric </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.metrics:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_name </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> metric.operation_name</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> op_name </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> operations:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                operations[op_name] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"count\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"total_time_ms\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"min_time_ms\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">'inf'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"max_time_ms\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"total_memory_delta_mb\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> operations[op_name]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"count\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"total_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> metric.duration_ms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"min_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(op_stats[</span><span style=\"color:#9ECBFF\">\"min_time_ms\"</span><span style=\"color:#E1E4E8\">], metric.duration_ms)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"max_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(op_stats[</span><span style=\"color:#9ECBFF\">\"max_time_ms\"</span><span style=\"color:#E1E4E8\">], metric.duration_ms)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"total_memory_delta_mb\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> metric.memory_delta_mb</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate averages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> op_stats </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> operations.values():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"avg_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> op_stats[</span><span style=\"color:#9ECBFF\">\"total_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> op_stats[</span><span style=\"color:#9ECBFF\">\"count\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            op_stats[</span><span style=\"color:#9ECBFF\">\"avg_memory_delta_mb\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> op_stats[</span><span style=\"color:#9ECBFF\">\"total_memory_delta_mb\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> op_stats[</span><span style=\"color:#9ECBFF\">\"count\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_operations\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.metrics),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"operations\"</span><span style=\"color:#E1E4E8\">: operations,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_time_ms\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">sum</span><span style=\"color:#E1E4E8\">(m.duration_ms </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> m </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.metrics)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global profiler instance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">profiler </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SearchProfiler()</span></span></code></pre></div>\n\n<p><strong>Vector Debugging Utilities</strong>: Complete utilities for diagnosing embedding and vector issues:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> faiss</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VectorDiagnostics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive vector health diagnostics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    vector_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dimension: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm_mean: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm_std: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm_min: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    norm_max: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_normalized: </span><span style=\"color:#79B8FF\">bool</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    zero_vectors: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    identical_vectors: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dimension_stats: Dict[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VectorDebugger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Production-ready vector debugging utilities.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> diagnose_vectors</span><span style=\"color:#E1E4E8\">(vectors: np.ndarray, tolerance: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1e-6</span><span style=\"color:#E1E4E8\">) -> VectorDiagnostics:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Comprehensive vector health check.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(vectors.shape) </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Expected 2D array, got shape </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">vectors.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        vector_count, dimension </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vectors.shape</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate vector norms</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        norms </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linalg.norm(vectors, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check normalization</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        is_normalized </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.all(np.abs(norms </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> tolerance)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Count zero vectors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        zero_vectors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.sum(np.all(vectors </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Count identical vectors (computationally expensive for large arrays)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        identical_vectors </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> vector_count </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 10000</span><span style=\"color:#E1E4E8\">:  </span><span style=\"color:#6A737D\"># Only check for small arrays</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            unique_vectors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.unique(vectors, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            identical_vectors </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vector_count </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(unique_vectors)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Analyze dimension-wise statistics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        dimension_stats </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> dim </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">min</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, dimension)):  </span><span style=\"color:#6A737D\"># Only analyze first 10 dimensions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            dim_values </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> vectors[:, dim]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            dimension_stats[dim] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"mean\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.mean(dim_values)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"std\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.std(dim_values)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"min\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.min(dim_values)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"max\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.max(dim_values))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> VectorDiagnostics(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            vector_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">vector_count,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            dimension</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">dimension,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            norm_mean</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.mean(norms)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            norm_std</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.std(norms)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            norm_min</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.min(norms)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            norm_max</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.max(norms)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            is_normalized</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">is_normalized,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            zero_vectors</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">zero_vectors,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            identical_vectors</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">identical_vectors,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            dimension_stats</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">dimension_stats</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_index_health</span><span style=\"color:#E1E4E8\">(index: faiss.Index, sample_queries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate FAISS index health with sample searches.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Basic index properties</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            health_report </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"index_type\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">type</span><span style=\"color:#E1E4E8\">(index).</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"total_vectors\"</span><span style=\"color:#E1E4E8\">: index.ntotal,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"dimension\"</span><span style=\"color:#E1E4E8\">: index.d,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"is_trained\"</span><span style=\"color:#E1E4E8\">: index.is_trained,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"search_errors\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"avg_search_time_ms\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"memory_usage_mb\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> index.ntotal </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_report[</span><span style=\"color:#9ECBFF\">\"status\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"empty\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> health_report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Test sample searches</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            search_times </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> _ </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(sample_queries):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Generate random query vector</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                query </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.random.randn(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, index.d).astype(np.float32)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                query </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> query </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> np.linalg.norm(query)  </span><span style=\"color:#6A737D\"># Normalize</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    scores, indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> index.search(query, </span><span style=\"color:#FFAB70\">k</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">min</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, index.ntotal))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    search_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (time.perf_counter() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time) </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    search_times.append(search_time)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Validate results</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(indices[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]) </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        health_report[</span><span style=\"color:#9ECBFF\">\"search_errors\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    health_report[</span><span style=\"color:#9ECBFF\">\"search_errors\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Index search error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> search_times:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_report[</span><span style=\"color:#9ECBFF\">\"avg_search_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.mean(search_times)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_report[</span><span style=\"color:#9ECBFF\">\"p95_search_time_ms\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.percentile(search_times, </span><span style=\"color:#79B8FF\">95</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Estimate memory usage (rough approximation)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            health_report[</span><span style=\"color:#9ECBFF\">\"memory_usage_mb\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (index.ntotal </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> index.d </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 4</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 1024</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Overall health status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> health_report[</span><span style=\"color:#9ECBFF\">\"search_errors\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_report[</span><span style=\"color:#9ECBFF\">\"status\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"healthy\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> health_report[</span><span style=\"color:#9ECBFF\">\"search_errors\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> sample_queries </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 0.1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_report[</span><span style=\"color:#9ECBFF\">\"status\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"degraded\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_report[</span><span style=\"color:#9ECBFF\">\"status\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"unhealthy\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> health_report</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"status\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"error\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"index_type\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">type</span><span style=\"color:#E1E4E8\">(index).</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> index </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> \"None\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">staticmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compare_embeddings</span><span style=\"color:#E1E4E8\">(embeddings1: np.ndarray, embeddings2: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          labels: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compare two sets of embeddings for debugging model changes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> embeddings1.shape </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> embeddings2.shape:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"error\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Shape mismatch: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">embeddings1.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> vs </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">embeddings2.shape</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate similarities between corresponding embeddings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        similarities </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(embeddings1)):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            sim </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cosine_similarity(embeddings1[i:i</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">], embeddings2[i:i</span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">])[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            similarities.append(sim)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        similarities </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.array(similarities)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Find most different embeddings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        most_different_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.argsort(similarities)[:</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        least_different_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.argsort(similarities)[</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">:]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        comparison </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_pairs\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(similarities),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"mean_similarity\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.mean(similarities)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"std_similarity\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.std(similarities)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"min_similarity\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.min(similarities)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"max_similarity\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(np.max(similarities)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"most_different\"</span><span style=\"color:#E1E4E8\">: [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"index\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(idx),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"similarity\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(similarities[idx]),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"label\"</span><span style=\"color:#E1E4E8\">: labels[idx] </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> labels </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> idx </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> most_different_indices</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"least_different\"</span><span style=\"color:#E1E4E8\">: [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"index\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(idx), </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"similarity\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(similarities[idx]),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"label\"</span><span style=\"color:#E1E4E8\">: labels[idx] </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> labels </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> idx </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> least_different_indices</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> comparison</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Usage examples for debugging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> debug_embedding_pipeline</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Example debugging workflow for embedding issues.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Load your embeddings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    embeddings </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> load_document_embeddings()  </span><span style=\"color:#6A737D\"># Your implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Run comprehensive diagnostics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    diagnostics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> VectorDebugger.diagnose_vectors(embeddings)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Vector Diagnostics:\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Total vectors: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.vector_count</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Dimensions: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.dimension</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Normalized: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.is_normalized</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Zero vectors: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.zero_vectors</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Norm range: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.norm_min</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.norm_max</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> diagnostics.is_normalized:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"WARNING: Vectors are not normalized - this will affect cosine similarity\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    if</span><span style=\"color:#E1E4E8\"> diagnostics.zero_vectors </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"WARNING: Found </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">diagnostics.zero_vectors</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> zero vectors\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Relevance Debugging Tools</strong>: Complete framework for analyzing search quality issues:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> defaultdict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RelevanceDebugInfo</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Debug information for a single search result.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    title: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    semantic_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    bm25_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    personalization_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    freshness_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    combined_score: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rank_position: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    human_relevance: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # 0-4 scale</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    debug_notes: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> field(</span><span style=\"color:#FFAB70\">default_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RelevanceDebugger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Production-ready relevance debugging framework.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, ranking_engine):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.ranking_engine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ranking_engine</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.debug_queries: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[RelevanceDebugInfo]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> debug_search_quality</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, results: List[SearchResult], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           ground_truth: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Comprehensive search quality analysis.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        debug_info </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> i, result </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(results):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Extract individual ranking signals</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            signals </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> result.ranking_signals</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> RelevanceDebugInfo(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                document_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result.document.doc_id,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                title</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result.document.title,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                semantic_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">signals.get(</span><span style=\"color:#9ECBFF\">'semantic_score'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                bm25_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">signals.get(</span><span style=\"color:#9ECBFF\">'bm25_score'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                personalization_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">signals.get(</span><span style=\"color:#9ECBFF\">'personalization_score'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                freshness_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">signals.get(</span><span style=\"color:#9ECBFF\">'freshness_score'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                combined_score</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">result.relevance_score,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                rank_position</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Add human relevance if available</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> ground_truth </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> result.document.doc_id </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> ground_truth:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                debug_entry.human_relevance </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ground_truth[result.document.doc_id]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Generate debug notes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_entry.debug_notes </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._generate_debug_notes(debug_entry)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_info.append(debug_entry)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Store for analysis</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.debug_queries[query] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> debug_info</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate quality metrics if ground truth available</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        quality_metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> ground_truth:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            quality_metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._calculate_quality_metrics(debug_info, ground_truth)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Analyze ranking signal contributions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signal_analysis </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._analyze_signal_contributions(debug_info)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"query\"</span><span style=\"color:#E1E4E8\">: query,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"total_results\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(debug_info),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"debug_info\"</span><span style=\"color:#E1E4E8\">: [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"rank\"</span><span style=\"color:#E1E4E8\">: entry.rank_position,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"doc_id\"</span><span style=\"color:#E1E4E8\">: entry.document_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"title\"</span><span style=\"color:#E1E4E8\">: entry.title[:</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#9ECBFF\"> \"...\"</span><span style=\"color:#F97583\"> if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(entry.title) </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#F97583\"> else</span><span style=\"color:#E1E4E8\"> entry.title,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"scores\"</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        \"semantic\"</span><span style=\"color:#E1E4E8\">: entry.semantic_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        \"bm25\"</span><span style=\"color:#E1E4E8\">: entry.bm25_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        \"personalization\"</span><span style=\"color:#E1E4E8\">: entry.personalization_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        \"freshness\"</span><span style=\"color:#E1E4E8\">: entry.freshness_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                        \"combined\"</span><span style=\"color:#E1E4E8\">: entry.combined_score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    },</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"human_relevance\"</span><span style=\"color:#E1E4E8\">: entry.human_relevance,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                    \"debug_notes\"</span><span style=\"color:#E1E4E8\">: entry.debug_notes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_info[:</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Top 10 for readability</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"quality_metrics\"</span><span style=\"color:#E1E4E8\">: quality_metrics,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"signal_analysis\"</span><span style=\"color:#E1E4E8\">: signal_analysis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_debug_notes</span><span style=\"color:#E1E4E8\">(self, debug_info: RelevanceDebugInfo) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate debugging notes for ranking anomalies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        notes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check for signal dominance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signals </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_info.semantic_score,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_info.bm25_score,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_info.personalization_score,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            debug_info.freshness_score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        max_signal </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(signals)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> debug_info.semantic_score </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> max_signal </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> max_signal </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.8</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            notes.append(</span><span style=\"color:#9ECBFF\">\"Dominated by semantic similarity\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> debug_info.bm25_score </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> max_signal:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            notes.append(</span><span style=\"color:#9ECBFF\">\"Dominated by keyword matching\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> debug_info.personalization_score </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> max_signal:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            notes.append(</span><span style=\"color:#9ECBFF\">\"Heavily personalized result\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> debug_info.freshness_score </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> max_signal:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            notes.append(</span><span style=\"color:#9ECBFF\">\"Boosted by recency\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check for score inconsistencies</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> debug_info.human_relevance </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> debug_info.human_relevance </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> debug_info.rank_position </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                notes.append(</span><span style=\"color:#9ECBFF\">\"Highly relevant but ranked low\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            elif</span><span style=\"color:#E1E4E8\"> debug_info.human_relevance </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> debug_info.rank_position </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                notes.append(</span><span style=\"color:#9ECBFF\">\"Low relevance but ranked high\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Check for extreme scores</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> debug_info.combined_score </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0.95</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            notes.append(</span><span style=\"color:#9ECBFF\">\"Unusually high combined score\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> debug_info.combined_score </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 0.1</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> debug_info.rank_position </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            notes.append(</span><span style=\"color:#9ECBFF\">\"Low score in top results\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> notes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _calculate_quality_metrics</span><span style=\"color:#E1E4E8\">(self, debug_info: List[RelevanceDebugInfo], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 ground_truth: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate precision@k and other relevance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Consider documents with relevance >= 3 as relevant</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        relevant_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        metrics </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> k </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(debug_info):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                top_k </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> debug_info[:k]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                relevant_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    1</span><span style=\"color:#F97583\"> for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> top_k </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> entry.human_relevance </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#F97583\"> and</span><span style=\"color:#E1E4E8\"> entry.human_relevance </span><span style=\"color:#F97583\">>=</span><span style=\"color:#E1E4E8\"> relevant_threshold</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                metrics[</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"precision_at_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">k</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relevant_count </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> k</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate NDCG if we have enough data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(debug_info) </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relevance_scores </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_info[:</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> entry.human_relevance </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    relevance_scores.append(entry.human_relevance)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    relevance_scores.append(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> relevance_scores:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                dcg </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    (</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">rel </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> np.log2(i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    for</span><span style=\"color:#E1E4E8\"> i, rel </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(relevance_scores)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Ideal DCG (sorted by relevance)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                ideal_relevances </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(relevance_scores, </span><span style=\"color:#FFAB70\">reverse</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                idcg </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    (</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">rel </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> np.log2(i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    for</span><span style=\"color:#E1E4E8\"> i, rel </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> enumerate</span><span style=\"color:#E1E4E8\">(ideal_relevances)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                metrics[</span><span style=\"color:#9ECBFF\">\"ndcg_at_10\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> dcg </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> idcg </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> idcg </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> else</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _analyze_signal_contributions</span><span style=\"color:#E1E4E8\">(self, debug_info: List[RelevanceDebugInfo]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze how different signals contribute to ranking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signal_correlations </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"semantic_rank_correlation\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"bm25_rank_correlation\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"personalization_rank_correlation\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"freshness_rank_correlation\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">(debug_info) </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> signal_correlations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract signal values and ranks</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ranks </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [entry.rank_position </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_info]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        semantic_scores </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [entry.semantic_score </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_info]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        bm25_scores </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [entry.bm25_score </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_info]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate Spearman rank correlations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            from</span><span style=\"color:#E1E4E8\"> scipy.stats </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> spearmanr</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            signal_correlations[</span><span style=\"color:#9ECBFF\">\"semantic_rank_correlation\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                spearmanr(ranks, semantic_scores).correlation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            signal_correlations[</span><span style=\"color:#9ECBFF\">\"bm25_rank_correlation\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                spearmanr(ranks, bm25_scores).correlation  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> ImportError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Fallback to simple correlation if scipy not available</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Signal dominance analysis</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signal_wins </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> defaultdict(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_info:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            signals </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"semantic\"</span><span style=\"color:#E1E4E8\">: entry.semantic_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"bm25\"</span><span style=\"color:#E1E4E8\">: entry.bm25_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"personalization\"</span><span style=\"color:#E1E4E8\">: entry.personalization_score,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"freshness\"</span><span style=\"color:#E1E4E8\">: entry.freshness_score</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            winner </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(signals, </span><span style=\"color:#FFAB70\">key</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">signals.get)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            signal_wins[winner] </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        signal_correlations[</span><span style=\"color:#9ECBFF\">\"signal_dominance\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> dict</span><span style=\"color:#E1E4E8\">(signal_wins)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> signal_correlations</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Example usage</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> debug_relevance_issues</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Example workflow for debugging relevance problems.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ranking_engine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> RankingEngine()  </span><span style=\"color:#6A737D\"># Your implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    debugger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> RelevanceDebugger(ranking_engine)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Define test queries with ground truth</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    test_cases </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"query\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"machine learning algorithms\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"ground_truth\"</span><span style=\"color:#E1E4E8\">: {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"doc1\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Highly relevant</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"doc2\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Relevant  </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"doc3\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Not relevant</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"doc4\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">2</span><span style=\"color:#6A737D\">   # Somewhat relevant</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> test_case </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> test_cases:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Execute search</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        results </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ranking_engine.search(test_case[</span><span style=\"color:#9ECBFF\">\"query\"</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Debug search quality</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        debug_report </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> debugger.debug_search_quality(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            test_case[</span><span style=\"color:#9ECBFF\">\"query\"</span><span style=\"color:#E1E4E8\">], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            results, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            test_case[</span><span style=\"color:#9ECBFF\">\"ground_truth\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Query: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">test_case[</span><span style=\"color:#9ECBFF\">'query'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Precision@5: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">debug_report[</span><span style=\"color:#9ECBFF\">'quality_metrics'</span><span style=\"color:#E1E4E8\">].get(</span><span style=\"color:#9ECBFF\">'precision_at_5'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'N/A'</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"NDCG@10: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">debug_report[</span><span style=\"color:#9ECBFF\">'quality_metrics'</span><span style=\"color:#E1E4E8\">].get(</span><span style=\"color:#9ECBFF\">'ndcg_at_10'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'N/A'</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"Issues found:\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> entry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> debug_report[</span><span style=\"color:#9ECBFF\">\"debug_info\"</span><span style=\"color:#E1E4E8\">][:</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> entry[</span><span style=\"color:#9ECBFF\">\"debug_notes\"</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"  Rank </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">entry[</span><span style=\"color:#9ECBFF\">'rank'</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#9ECBFF\">', '</span><span style=\"color:#E1E4E8\">.join(entry[</span><span style=\"color:#9ECBFF\">'debug_notes'</span><span style=\"color:#E1E4E8\">])</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p>After implementing the debugging infrastructure, verify that your debugging tools work correctly:</p>\n<p><strong>Milestone 1 Debugging Verification</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test vector debugging utilities</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from your_project.debug import VectorDebugger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">import numpy as np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Test with sample vectors</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">vectors = np.random.randn(1000, 384).astype(np.float32)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">diagnostics = VectorDebugger.diagnose_vectors(vectors)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Vector health: normalized={diagnostics.is_normalized}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(f'Norm range: {diagnostics.norm_min:.3f} - {diagnostics.norm_max:.3f}')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Milestone 2-3 Debugging Verification</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test relevance debugging</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from your_project.debug import RelevanceDebugger</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from your_project.ranking import RankingEngine</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">debugger = RelevanceDebugger(RankingEngine())</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\"># Test with sample query - should show signal analysis</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p><strong>Performance Monitoring Verification</strong>:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test performance profiler</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">from your_project.debug import profiler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">@profiler.profile_function('test_operation')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">def slow_function():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    import time</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    time.sleep(0.1)  # Simulate work</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">slow_function()</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">print(profiler.get_summary())</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"</span></span></code></pre></div>\n\n<p>Expected output should show timing information, memory usage, and any performance warnings for operations exceeding thresholds.</p>\n<h2 id=\"future-extensions\">Future Extensions</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section builds upon all milestones (1-4), outlining advanced features and scaling strategies that extend the core semantic search engine into next-generation capabilities.</p>\n</blockquote>\n<p>The semantic search engine we&#39;ve built through the four milestones represents a solid foundation for modern information retrieval. However, the rapidly evolving landscape of search technology and user expectations demands consideration of advanced features that push beyond traditional text-based semantic search. This section explores two critical dimensions of evolution: <strong>Advanced Search Features</strong> that enhance the search experience through multi-modal capabilities, intelligent filtering, and conversational interfaces, and <strong>Scaling and Distribution</strong> strategies that enable the system to handle enterprise-scale workloads with real-time updates and global distribution.</p>\n<p>Think of our current semantic search engine as a skilled librarian who understands the meaning behind your questions and can find relevant books by understanding concepts rather than just matching keywords. The future extensions we&#39;ll explore are like transforming that librarian into a polyglot research assistant who can understand images and audio, maintain ongoing conversations about your research needs, and coordinate with a global network of specialized librarians to provide instant access to any information, anywhere in the world.</p>\n<p>These extensions represent natural evolution paths rather than revolutionary changes. Each builds upon the foundational components we&#39;ve established while introducing new capabilities that address emerging use cases in modern search applications. The mental model remains consistent: we&#39;re enhancing our ability to understand user intent and match it with relevant information, but we&#39;re expanding the definition of both &quot;intent&quot; and &quot;information&quot; to encompass richer, more diverse forms of data and interaction.</p>\n<h3 id=\"advanced-search-features\">Advanced Search Features</h3>\n<p>The next generation of semantic search transcends the boundaries of text-only retrieval, embracing multi-modal understanding, intelligent semantic filtering, and natural conversation flows. These features represent the evolution from keyword-based information retrieval to AI-powered research assistance that understands context, remembers previous interactions, and can work with diverse media types.</p>\n<h4 id=\"multi-modal-embeddings\">Multi-Modal Embeddings</h4>\n<p>Multi-modal search represents one of the most transformative advances in modern information retrieval, enabling users to search using images, audio, video, and combinations of different media types. Think of this capability as giving our semantic search engine the ability to &quot;see&quot; and &quot;hear&quot; in addition to reading, creating a unified understanding space where a user could upload an image of a product and find related documents, or hum a melody to find relevant audio content.</p>\n<p>The technical foundation for multi-modal search builds directly on our existing embedding infrastructure from Milestone 1, but expands the <code>DocumentEncoder</code> to handle multiple data types. Instead of generating a single text embedding, we create aligned embeddings across different modalities that can be meaningfully compared in the same vector space. This alignment is achieved through multi-modal training techniques like CLIP (Contrastive Language-Image Pre-training) that learn to map images and text to nearby points in the embedding space when they represent similar concepts.</p>\n<blockquote>\n<p><strong>Decision: Multi-Modal Embedding Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Users increasingly want to search using images, audio, and video content, requiring embeddings that can meaningfully compare across different data types</li>\n<li><strong>Options Considered</strong>: Separate indices per modality, modal-specific encoders with late fusion, unified multi-modal embedding space</li>\n<li><strong>Decision</strong>: Unified multi-modal embedding space with modal-specific encoders feeding into a shared dimension</li>\n<li><strong>Rationale</strong>: Enables cross-modal search (image query finding text results), simpler ranking pipeline, and better user experience with mixed-media results</li>\n<li><strong>Consequences</strong>: Requires more sophisticated embedding models, increased computational requirements, but enables revolutionary search capabilities</li>\n</ul>\n</blockquote>\n<p>The data model extensions for multi-modal search introduce new content types and embedding strategies:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>media_type</code></td>\n<td>str</td>\n<td>Content type: &#39;text&#39;, &#39;image&#39;, &#39;audio&#39;, &#39;video&#39;, &#39;mixed&#39;</td>\n</tr>\n<tr>\n<td><code>content_url</code></td>\n<td>Optional[str]</td>\n<td>URL or path to media content for non-text types</td>\n</tr>\n<tr>\n<td><code>content_metadata</code></td>\n<td>Optional[Dict]</td>\n<td>Media-specific metadata like image dimensions, audio duration</td>\n</tr>\n<tr>\n<td><code>thumbnail_url</code></td>\n<td>Optional[str]</td>\n<td>Preview image for video/audio content</td>\n</tr>\n<tr>\n<td><code>transcription</code></td>\n<td>Optional[str]</td>\n<td>Text transcription for audio/video content</td>\n</tr>\n<tr>\n<td><code>extracted_text</code></td>\n<td>Optional[str]</td>\n<td>OCR text extracted from images or video frames</td>\n</tr>\n<tr>\n<td><code>modal_embeddings</code></td>\n<td>Dict[str, np.ndarray]</td>\n<td>Separate embeddings for each modality present</td>\n</tr>\n<tr>\n<td><code>unified_embedding</code></td>\n<td>np.ndarray</td>\n<td>Cross-modal aligned embedding for similarity search</td>\n</tr>\n</tbody></table>\n<p>The multi-modal encoding pipeline extends our existing document processing workflow with media-specific processing stages. For image content, this involves feature extraction through vision transformers, object detection, and OCR text extraction. Audio processing includes speech-to-text transcription, audio fingerprinting, and acoustic feature extraction. Video combines frame sampling, object tracking, and temporal relationship modeling.</p>\n<p>Cross-modal query processing becomes significantly more sophisticated, requiring the <code>QueryProcessor</code> to handle mixed-input queries where users might combine text descriptions with uploaded images or audio clips. A user searching for &quot;red sports car like this&quot; while uploading an image requires combining text understanding (&quot;red sports car&quot;) with visual similarity matching against the uploaded image. The query expansion strategies from Milestone 2 extend to include visual concept expansion, where recognizing a &quot;Ferrari&quot; in an uploaded image might expand to related terms like &quot;Italian sports car&quot; or &quot;luxury vehicle.&quot;</p>\n<p>The ranking pipeline from Milestone 3 gains new signal types for multi-modal relevance. Visual similarity scores join semantic text scores, audio matching confidence contributes to relevance calculation, and cross-modal consistency (alignment between text description and visual content) becomes a quality signal. The <code>RankingSignals</code> structure extends to accommodate these additional dimensions:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>visual_similarity_score</code></td>\n<td>Optional[float]</td>\n<td>Image-to-image or text-to-image similarity</td>\n</tr>\n<tr>\n<td><code>audio_similarity_score</code></td>\n<td>Optional[float]</td>\n<td>Audio fingerprint or semantic audio matching</td>\n</tr>\n<tr>\n<td><code>cross_modal_consistency</code></td>\n<td>Optional[float]</td>\n<td>Alignment between different modalities in result</td>\n</tr>\n<tr>\n<td><code>media_quality_score</code></td>\n<td>Optional[float]</td>\n<td>Technical quality assessment of media content</td>\n</tr>\n<tr>\n<td><code>accessibility_score</code></td>\n<td>Optional[float]</td>\n<td>Presence of alt-text, captions, transcriptions</td>\n</tr>\n</tbody></table>\n<h4 id=\"semantic-filtering\">Semantic Filtering</h4>\n<p>Traditional faceted search operates on explicit metadata categories like &quot;date,&quot; &quot;author,&quot; or &quot;department.&quot; Semantic filtering represents a fundamental advancement that enables filtering based on conceptual understanding rather than rigid categorical boundaries. Users can filter results by abstract concepts like &quot;beginner-friendly content,&quot; &quot;urgent matters,&quot; or &quot;creative approaches&quot; without requiring explicit tagging of these subjective qualities.</p>\n<p>Think of semantic filtering as the difference between organizing books by the Dewey Decimal System (rigid categories) versus having an intelligent librarian who understands that when you ask for &quot;inspiring leadership books,&quot; you want content that embodies leadership principles even if it&#39;s filed under biography, business, or history. The system learns to recognize conceptual patterns rather than relying solely on explicit classification.</p>\n<p>The implementation builds on our existing embedding infrastructure by creating concept vectors that represent abstract filtering criteria. These concept vectors are learned through various techniques: they might be derived from example documents that exemplify the concept, generated from natural language descriptions of the filtering criteria, or learned through user interaction patterns that reveal implicit conceptual groupings.</p>\n<blockquote>\n<p><strong>Decision: Semantic Filter Implementation Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Users want to filter by abstract concepts like &quot;technical difficulty&quot; or &quot;emotional tone&quot; that can&#39;t be captured by traditional metadata fields</li>\n<li><strong>Options Considered</strong>: Rule-based classification, supervised learning with labeled examples, embedding-based conceptual similarity</li>\n<li><strong>Decision</strong>: Hybrid approach using embedding similarity for concept matching with optional supervised refinement</li>\n<li><strong>Rationale</strong>: Leverages existing embedding infrastructure, provides flexibility for undefined concepts, can be enhanced with training data when available</li>\n<li><strong>Consequences</strong>: Enables powerful conceptual filtering but requires careful UX design to make abstract filters discoverable and understandable</li>\n</ul>\n</blockquote>\n<p>The semantic filtering architecture extends the <code>QueryProcessor</code> with concept resolution capabilities:</p>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Parameters</th>\n<th>Returns</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>resolve_semantic_filters</code></td>\n<td>concepts: List[str], context: Dict</td>\n<td>List[ConceptFilter]</td>\n<td>Convert natural language filter descriptions to vector constraints</td>\n</tr>\n<tr>\n<td><code>apply_conceptual_constraints</code></td>\n<td>embeddings: np.ndarray, filters: List[ConceptFilter]</td>\n<td>np.ndarray</td>\n<td>Filter embedding space by conceptual similarity thresholds</td>\n</tr>\n<tr>\n<td><code>suggest_related_filters</code></td>\n<td>current_filters: List[str], results: List[SearchResult]</td>\n<td>List[str]</td>\n<td>Recommend additional conceptual filters based on result analysis</td>\n</tr>\n<tr>\n<td><code>explain_filter_matching</code></td>\n<td>document: Document, filter: ConceptFilter</td>\n<td>FilterExplanation</td>\n<td>Provide human-readable explanation of why document matches concept</td>\n</tr>\n</tbody></table>\n<p>Semantic filters operate through vector space constraints, where each filter defines a region in the embedding space corresponding to documents that exhibit the desired conceptual properties. A filter for &quot;beginner-friendly content&quot; might identify a vector subspace where documents cluster around concepts of simplicity, clear explanation, and foundational knowledge. The filtering process becomes a geometric operation, finding documents whose embeddings fall within the specified conceptual regions.</p>\n<p>The user experience for semantic filtering requires sophisticated interface design that makes abstract concepts discoverable and understandable. Auto-suggestion helps users discover available conceptual filters by analyzing their search results and suggesting relevant abstract qualities. Filter explanations help users understand why certain documents match conceptual criteria, building trust and enabling refinement of their search intent.</p>\n<h4 id=\"conversational-search\">Conversational Search</h4>\n<p>Conversational search transforms the traditional one-shot query model into an ongoing dialogue where the search engine maintains context across multiple interactions, clarifies ambiguous requests, and refines understanding through natural conversation. Rather than treating each search as an isolated event, the system builds a conversational context that enables follow-up questions, progressive refinement, and multi-turn problem solving.</p>\n<p>The mental model shifts from a traditional search box (like asking a question at an information desk and walking away) to having an ongoing conversation with a knowledgeable research assistant who remembers what you discussed previously, can ask clarifying questions, and helps you explore topics in depth through guided discovery.</p>\n<p>Conversational search introduces session management and context tracking capabilities that extend beyond our current stateless search API. The system maintains conversation state, tracks topic evolution, and applies contextual understanding to interpret abbreviated follow-up queries that would be ambiguous in isolation. A user asking &quot;What about Python?&quot; after searching for programming languages needs the system to understand the conversational context rather than treating it as a standalone query about snakes or mythology.</p>\n<blockquote>\n<p><strong>Decision: Conversational Context Management</strong></p>\n<ul>\n<li><strong>Context</strong>: Users want to have extended conversations with the search system, asking follow-up questions and refining their search through dialogue</li>\n<li><strong>Options Considered</strong>: Stateless query rewriting, full conversation history embedding, sliding window context with key information extraction</li>\n<li><strong>Decision</strong>: Sliding window context with intelligent key information extraction and query contextualization</li>\n<li><strong>Rationale</strong>: Balances performance with conversational capability, avoids unbounded context growth, focuses on relevant conversation elements</li>\n<li><strong>Consequences</strong>: Enables natural follow-up queries but requires sophisticated context understanding and potential loss of distant conversation elements</li>\n</ul>\n</blockquote>\n<p>The conversational search architecture introduces new data structures for session management:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>session_id</code></td>\n<td>str</td>\n<td>Unique identifier for conversational session</td>\n</tr>\n<tr>\n<td><code>conversation_history</code></td>\n<td>List[ConversationTurn]</td>\n<td>Chronological record of queries and responses</td>\n</tr>\n<tr>\n<td><code>active_topics</code></td>\n<td>List[TopicContext]</td>\n<td>Currently active conversation topics with relevance scores</td>\n</tr>\n<tr>\n<td><code>user_preferences</code></td>\n<td>UserContext</td>\n<td>Learned preferences and expertise level from conversation</td>\n</tr>\n<tr>\n<td><code>clarification_state</code></td>\n<td>Optional[ClarificationContext]</td>\n<td>Pending clarification requests and expected response types</td>\n</tr>\n</tbody></table>\n<p>Each conversation turn captures both the explicit query and the implicit context that influences interpretation:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>turn_number</code></td>\n<td>int</td>\n<td>Sequential position in conversation</td>\n</tr>\n<tr>\n<td><code>raw_query</code></td>\n<td>str</td>\n<td>User&#39;s exact input text</td>\n</tr>\n<tr>\n<td><code>contextualized_query</code></td>\n<td>str</td>\n<td>Query expanded with conversational context</td>\n</tr>\n<tr>\n<td><code>query_type</code></td>\n<td>QueryType</td>\n<td>Classification: new_topic, follow_up, clarification, refinement</td>\n</tr>\n<tr>\n<td><code>referenced_results</code></td>\n<td>List[str]</td>\n<td>Document IDs referenced in this turn</td>\n</tr>\n<tr>\n<td><code>user_feedback</code></td>\n<td>Optional[FeedbackSignal]</td>\n<td>Explicit or implicit feedback on results</td>\n</tr>\n</tbody></table>\n<p>The query contextualization process becomes significantly more sophisticated, requiring natural language understanding that goes beyond simple keyword expansion. The system must resolve pronouns (&quot;it,&quot; &quot;that approach,&quot; &quot;those examples&quot;), understand temporal references (&quot;earlier results,&quot; &quot;the previous method&quot;), and maintain topic coherence across conversation turns. Machine learning models trained on conversational data help interpret ambiguous follow-up queries by considering both conversation history and current context.</p>\n<p>Clarification dialogues represent a powerful extension where the search system can ask users for additional information when queries are ambiguous or underspecified. Rather than returning potentially irrelevant results for unclear requests, the system engages in brief clarification exchanges: &quot;When you ask about &#39;integration testing,&#39; are you interested in software testing methodologies, business system integration, or mathematical integration techniques?&quot; This proactive clarification dramatically improves result relevance and user satisfaction.</p>\n<h3 id=\"scaling-and-distribution\">Scaling and Distribution</h3>\n<p>As semantic search systems mature from prototype to production to enterprise scale, they encounter challenges that demand sophisticated distribution strategies, real-time update capabilities, and global deployment architectures. The scaling dimension addresses not just increased load, but fundamental changes in how search systems must operate: maintaining consistency across distributed indices, enabling real-time updates without service interruption, and providing global search capabilities with local latency characteristics.</p>\n<h4 id=\"distributed-indexing\">Distributed Indexing</h4>\n<p>Distributed indexing addresses the fundamental scalability challenge of semantic search: as document collections grow beyond what a single machine can handle efficiently, we must partition the embedding index across multiple nodes while maintaining fast query performance and system reliability. This transition represents a shift from centralized search architecture to a distributed system that can scale horizontally as data volume and query load increase.</p>\n<p>The mental model for distributed indexing resembles transforming our single intelligent librarian into a coordinated team of specialists, where each team member becomes an expert in specific subject areas or document collections, but they can all collaborate seamlessly to answer any research question. The challenge lies in partitioning the work effectively, coordinating responses, and ensuring that users receive complete, relevant results regardless of how the underlying data is distributed.</p>\n<p>Unlike traditional databases where distribution strategies are well-established, vector indices present unique challenges. Embedding spaces don&#39;t naturally partition along obvious boundaries like date ranges or alphabetical ordering. The high-dimensional nature of embeddings means that naive partitioning strategies can destroy the locality properties that make vector search efficient. Instead, distributed vector indexing requires sophisticated partitioning strategies that preserve semantic neighborhoods while balancing load across nodes.</p>\n<blockquote>\n<p><strong>Decision: Vector Index Partitioning Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Large document collections require distributed indexing, but naive partitioning destroys vector locality and degrades search quality</li>\n<li><strong>Options Considered</strong>: Random partitioning, clustering-based partitioning, learned partitioning with routing models</li>\n<li><strong>Decision</strong>: Hierarchical clustering-based partitioning with learned query routing</li>\n<li><strong>Rationale</strong>: Preserves semantic locality within partitions, enables efficient query routing to relevant shards, maintains search quality at scale</li>\n<li><strong>Consequences</strong>: Requires initial clustering computation and routing model training, but provides scalable search with minimal quality degradation</li>\n</ul>\n</blockquote>\n<p>The distributed indexing architecture extends our existing <code>EmbeddingIndex</code> component with coordination and partitioning capabilities:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Key Interfaces</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>IndexCoordinator</code></td>\n<td>Query routing, result aggregation, health monitoring</td>\n<td><code>route_query()</code>, <code>aggregate_results()</code>, <code>monitor_shards()</code></td>\n</tr>\n<tr>\n<td><code>IndexShard</code></td>\n<td>Local vector index management, shard-specific search</td>\n<td><code>search_local()</code>, <code>add_documents()</code>, <code>get_shard_stats()</code></td>\n</tr>\n<tr>\n<td><code>PartitionStrategy</code></td>\n<td>Determines document-to-shard assignment</td>\n<td><code>assign_shard()</code>, <code>rebalance_partitions()</code></td>\n</tr>\n<tr>\n<td><code>QueryRouter</code></td>\n<td>Selects relevant shards for each query</td>\n<td><code>select_shards()</code>, <code>estimate_relevance()</code></td>\n</tr>\n</tbody></table>\n<p>The partitioning process begins with analyzing the full document collection to identify semantic clusters that can be assigned to different shards. This clustering process uses the same embedding techniques from Milestone 1, but applies them at the collection level to identify natural groupings of related documents. Documents about machine learning might cluster together, while legal documents form another cluster, and historical texts form a third. Each cluster becomes a shard that can be hosted on separate infrastructure.</p>\n<p>Query routing becomes a critical performance optimization that determines which shards to search for each query. A naive approach would query all shards and aggregate results, but this eliminates the performance benefits of distribution. Instead, intelligent query routing uses the query embedding to predict which shards are likely to contain relevant documents, typically searching only 20-30% of available shards while maintaining high recall.</p>\n<p>The distributed ranking pipeline from Milestone 3 requires coordination across shards to ensure global result quality. Each shard returns its top local candidates with their local scores, but these local scores must be normalized and compared across shards to produce globally optimal rankings. This process, known as distributed top-k selection, requires careful score calibration and potentially multiple rounds of communication between coordinator and shards.</p>\n<p>Consistency management becomes complex when supporting concurrent updates across distributed shards. New documents must be assigned to appropriate shards, index updates must be coordinated to maintain search consistency, and shard rebalancing operations must be performed without service interruption. The system adopts an eventually consistent model where individual shards can be updated independently, with periodic synchronization to maintain global consistency.</p>\n<h4 id=\"search-federation\">Search Federation</h4>\n<p>Search federation extends distributed indexing to connect multiple independent search systems, enabling queries across heterogeneous data sources, different embedding models, and even different organizations. Think of federation as creating a &quot;search of searches&quot; that can simultaneously query your local document repository, external knowledge bases, and specialized domain-specific search engines, then intelligently combine and rank the unified results.</p>\n<p>The federation architecture addresses scenarios where organizations need to search across multiple independent systems without centralizing all data. A research organization might need to search their internal documents, public research databases, patent databases, and news archives simultaneously. Each source uses different indexing strategies, embedding models, and relevance signals, but users want a unified search experience that draws from all available sources.</p>\n<p>Federation introduces new challenges beyond distributed indexing: different embedding spaces can&#39;t be directly compared, various systems use incompatible relevance scoring, network latency varies dramatically across federated sources, and some sources might be temporarily unavailable. The federation layer must abstract these differences while providing a consistent user experience.</p>\n<blockquote>\n<p><strong>Decision: Federation Architecture Pattern</strong></p>\n<ul>\n<li><strong>Context</strong>: Organizations need to search across multiple independent systems with different embedding models, scoring systems, and availability characteristics</li>\n<li><strong>Options Considered</strong>: Centralized federation hub, peer-to-peer federation, hierarchical federation with regional coordinators</li>\n<li><strong>Decision</strong>: Hierarchical federation with adapter pattern for heterogeneous source integration</li>\n<li><strong>Rationale</strong>: Provides scalability through hierarchy, enables source-specific optimization through adapters, maintains performance through regional coordination</li>\n<li><strong>Consequences</strong>: Requires sophisticated adapter development but enables flexible integration of diverse search systems</li>\n</ul>\n</blockquote>\n<p>The federation architecture introduces adapter patterns that normalize differences between federated sources:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Responsibility</th>\n<th>Key Challenges</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>FederationCoordinator</code></td>\n<td>Query distribution, result aggregation, source selection</td>\n<td>Balancing comprehensiveness with performance</td>\n</tr>\n<tr>\n<td><code>SourceAdapter</code></td>\n<td>Translates between federation protocol and source-specific APIs</td>\n<td>Handling incompatible scoring systems and embedding spaces</td>\n</tr>\n<tr>\n<td><code>ResultNormalizer</code></td>\n<td>Harmonizes relevance scores across heterogeneous sources</td>\n<td>Calibrating scores from different ranking algorithms</td>\n</tr>\n<tr>\n<td><code>SourceHealthMonitor</code></td>\n<td>Tracks availability and performance of federated sources</td>\n<td>Managing partial failures and degraded service</td>\n</tr>\n</tbody></table>\n<p>Query translation becomes a sophisticated process where the federated query must be adapted to each source&#39;s capabilities and interface. A semantic query might be translated to vector search for systems supporting embeddings, keyword search for traditional systems, and structured queries for database sources. The federation layer maintains source capability profiles that describe each system&#39;s search features, supported query types, and performance characteristics.</p>\n<p>Result harmonization addresses the challenge of combining results from sources that use incompatible relevance scoring systems. A traditional search engine might return BM25 scores ranging 0-10, while a modern semantic system returns cosine similarity scores ranging 0-1. The federation layer learns score normalization functions that map source-specific scores to a common relevance scale, enabling meaningful cross-source ranking.</p>\n<p>The federated ranking pipeline extends beyond simple score normalization to consider source credibility, freshness differences, and user preferences for certain sources. Results from authoritative sources might receive credibility boosts, recent results from fast-updating sources gain freshness advantages, and user interaction history influences source weighting for personalized federation.</p>\n<h4 id=\"real-time-updates\">Real-Time Updates</h4>\n<p>Real-time updates transform semantic search from a batch-oriented system that periodically rebuilds indices to a dynamic platform that incorporates new documents, user feedback, and model improvements continuously without service interruption. This capability is essential for modern applications where information freshness is critical: news search, social media monitoring, collaborative knowledge bases, and any system where users expect immediate visibility of new content.</p>\n<p>The challenge of real-time updates in semantic search systems goes beyond traditional database updates because vector indices have complex internal structures that aren&#39;t easily modified incrementally. Traditional inverted indices can add new documents by simply appending to posting lists, but vector indices like HNSW maintain graph structures that require careful coordination when adding nodes. Additionally, embedding model updates can invalidate existing embeddings, requiring coordinated re-processing of the entire document collection.</p>\n<p>Real-time update architecture must balance multiple competing requirements: update latency (how quickly new documents become searchable), query performance (updates shouldn&#39;t degrade search speed), consistency (users shouldn&#39;t see partial or inconsistent results), and resource utilization (updates shouldn&#39;t overwhelm system resources during peak usage periods).</p>\n<blockquote>\n<p><strong>Decision: Real-Time Update Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Modern applications require immediate visibility of new content without degrading search performance or system stability</li>\n<li><strong>Options Considered</strong>: Direct index updates, staged update pipeline with hot-swapping, hybrid architecture with fast temporary index plus batch consolidation</li>\n<li><strong>Decision</strong>: Hybrid architecture with write-optimized temporary index and periodic consolidation to read-optimized main index</li>\n<li><strong>Rationale</strong>: Provides immediate visibility for new documents, maintains optimal search performance, enables controlled resource utilization</li>\n<li><strong>Consequences</strong>: Introduces architectural complexity but delivers both real-time capability and production performance</li>\n</ul>\n</blockquote>\n<p>The real-time update architecture introduces a multi-tier indexing strategy:</p>\n<table>\n<thead>\n<tr>\n<th>Index Tier</th>\n<th>Purpose</th>\n<th>Characteristics</th>\n<th>Update Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>FastIndex</code></td>\n<td>Recent documents (last 24-48 hours)</td>\n<td>Write-optimized, higher latency</td>\n<td>Direct real-time updates</td>\n</tr>\n<tr>\n<td><code>MainIndex</code></td>\n<td>Stable document collection</td>\n<td>Read-optimized, low latency</td>\n<td>Periodic batch consolidation</td>\n</tr>\n<tr>\n<td><code>ArchiveIndex</code></td>\n<td>Historical documents</td>\n<td>Highly compressed, moderate latency</td>\n<td>Infrequent bulk updates</td>\n</tr>\n</tbody></table>\n<p>The update pipeline processes new documents through several stages that balance speed with quality. Immediate indexing provides basic searchability within seconds by adding documents to the fast index with simplified processing. Background enrichment performs expensive operations like advanced query expansion preparation, cross-reference analysis, and quality score computation. Periodic consolidation moves stabilized documents from the fast index to the main index with full optimization.</p>\n<p>Embedding model updates represent a particularly complex real-time update scenario. When new embedding models become available (offering better accuracy or supporting new languages), the system must coordinate re-processing of existing documents without service interruption. The architecture supports gradual model rollout where new documents use updated embeddings while existing documents are re-processed in background batches, maintaining search quality during the transition period.</p>\n<p>The ranking system from Milestone 3 adapts to handle results from multiple index tiers, applying appropriate score normalization and temporal weighting to ensure recent documents receive appropriate visibility without overwhelming older but highly relevant content. Click-through learning systems must account for the different characteristics of fast versus main index results when updating relevance models.</p>\n<p>Consistency management ensures that users never see partial updates or inconsistent search results during update operations. The system maintains read consistency by completing update transactions atomically, uses versioned indices to enable hot-swapping without service interruption, and provides eventual consistency guarantees where short-term inconsistencies are acceptable but long-term convergence is guaranteed.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The future extensions described in this section represent advanced capabilities that build upon the solid foundation established in Milestones 1-4. While these features push the boundaries of what&#39;s possible with semantic search, they follow the same architectural principles and can be developed incrementally as system requirements evolve.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Multi-Modal Embeddings</td>\n<td>OpenAI CLIP + sentence-transformers for text</td>\n<td>Custom multi-modal transformer with domain-specific training</td>\n</tr>\n<tr>\n<td>Image Processing</td>\n<td>PIL + OpenCV for basic feature extraction</td>\n<td>torchvision with pre-trained ResNet/EfficientNet models</td>\n</tr>\n<tr>\n<td>Audio Processing</td>\n<td>librosa for audio features + speech_recognition</td>\n<td>Whisper for transcription + wav2vec2 for audio embeddings</td>\n</tr>\n<tr>\n<td>Video Processing</td>\n<td>OpenCV frame extraction + CLIP for frames</td>\n<td>Video transformers like VideoMAE or I3D for temporal modeling</td>\n</tr>\n<tr>\n<td>Semantic Filtering</td>\n<td>Cosine similarity with concept vectors</td>\n<td>Fine-tuned BERT classifier for concept detection</td>\n</tr>\n<tr>\n<td>Conversational Search</td>\n<td>Simple session storage + query expansion</td>\n<td>Full dialogue state tracking with conversational AI models</td>\n</tr>\n<tr>\n<td>Distributed Indexing</td>\n<td>Redis Cluster for coordination + FAISS sharding</td>\n<td>Custom distributed vector index with learned partitioning</td>\n</tr>\n<tr>\n<td>Search Federation</td>\n<td>HTTP adapters for external APIs</td>\n<td>GraphQL federation with schema stitching</td>\n</tr>\n<tr>\n<td>Real-Time Updates</td>\n<td>Redis streams for update queue + background processing</td>\n<td>Apache Kafka with stream processing framework</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure-extension\">Recommended File Structure Extension</h4>\n<p>Building on the existing project structure from previous milestones, future extensions organize into specialized modules:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  # Existing core components from Milestones 1-4\n  internal/embedding/\n  internal/query/\n  internal/ranking/\n  internal/api/\n  \n  # New future extension modules\n  internal/multimodal/\n    encoders/\n      image_encoder.py          ← CLIP-based image embedding\n      audio_encoder.py          ← Audio feature extraction and embedding\n      video_encoder.py          ← Video frame and temporal processing\n    unified_encoder.py          ← Cross-modal embedding alignment\n    media_processor.py          ← Content type detection and preprocessing\n    \n  internal/semantic_filtering/\n    concept_manager.py          ← Concept vector management\n    filter_processor.py         ← Semantic filter application\n    concept_suggester.py        ← Related concept recommendations\n    \n  internal/conversation/\n    session_manager.py          ← Conversation state tracking\n    context_processor.py        ← Query contextualization\n    clarification_engine.py     ← Clarification dialogue management\n    \n  internal/distributed/\n    coordinator.py              ← Index coordination and query routing\n    shard_manager.py            ← Individual shard management\n    partition_strategy.py       ← Document-to-shard assignment\n    result_aggregator.py        ← Cross-shard result combination\n    \n  internal/federation/\n    federation_coordinator.py   ← Cross-system query coordination\n    source_adapters/            ← Adapter pattern implementations\n      elasticsearch_adapter.py\n      solr_adapter.py\n      custom_api_adapter.py\n    result_normalizer.py        ← Score harmonization across sources\n    \n  internal/realtime/\n    update_pipeline.py          ← Real-time document processing\n    fast_index.py              ← Write-optimized temporary index\n    consolidation_engine.py    ← Batch consolidation to main index\n    model_updater.py           ← Embedding model refresh coordination</code></pre></div>\n\n<h4 id=\"multi-modal-infrastructure-starter-code\">Multi-Modal Infrastructure Starter Code</h4>\n<p>Complete infrastructure for handling multiple content types, building on the embedding foundation from Milestone 1:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Multi-modal content processing infrastructure.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides complete working implementation for media type detection,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">preprocessing, and embedding generation across text, image, audio, and video.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> torch</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#79B8FF\"> PIL</span><span style=\"color:#F97583\"> import</span><span style=\"color:#E1E4E8\"> Image</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> librosa</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> cv2</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple, Union</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sentence_transformers </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SentenceTransformer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> clip</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> whisper</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> pathlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Path</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MediaContent</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Unified representation of multi-modal content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    media_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#6A737D\">  # 'text', 'image', 'audio', 'video', 'mixed'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content_path: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    content_data: Optional[</span><span style=\"color:#79B8FF\">bytes</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    text_content: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    extracted_text: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # OCR or transcription</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MediaTypeDetector</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Automatic media type detection and validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    IMAGE_EXTENSIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'.jpg'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.jpeg'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.png'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.gif'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.bmp'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.tiff'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    AUDIO_EXTENSIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'.mp3'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.wav'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.flac'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.m4a'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.ogg'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    VIDEO_EXTENSIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#9ECBFF\">'.mp4'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.avi'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.mov'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.mkv'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'.webm'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_media_type</span><span style=\"color:#E1E4E8\">(cls, file_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect media type from file extension and content.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        path </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Path(file_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        extension </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> path.suffix.lower()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> extension </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">IMAGE_EXTENSIONS</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> 'image'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> extension </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">AUDIO_EXTENSIONS</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> 'audio'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#E1E4E8\"> extension </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">.</span><span style=\"color:#79B8FF\">VIDEO_EXTENSIONS</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> 'video'</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> 'text'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_content</span><span style=\"color:#E1E4E8\">(cls, content: MediaContent) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate content can be processed.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> content.media_type </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'text'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> content.text_content </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> content.content_path </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> content.content_data </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ImageProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete image processing pipeline with CLIP integration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.clip_model, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.clip_preprocess </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> clip.load(</span><span style=\"color:#9ECBFF\">\"ViT-B/32\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.device </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"cuda\"</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> torch.cuda.is_available() </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> \"cpu\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.clip_model </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.clip_model.to(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.device)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> extract_features</span><span style=\"color:#E1E4E8\">(self, image_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract CLIP image embeddings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        image </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Image.open(image_path).convert(</span><span style=\"color:#9ECBFF\">'RGB'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        image_tensor </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.clip_preprocess(image).unsqueeze(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">).to(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.device)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#E1E4E8\"> torch.no_grad():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            image_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.clip_model.encode_image(image_tensor)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            image_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> image_features </span><span style=\"color:#F97583\">/</span><span style=\"color:#E1E4E8\"> image_features.norm(</span><span style=\"color:#FFAB70\">dim</span><span style=\"color:#F97583\">=-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">keepdim</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> image_features.cpu().numpy().flatten()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> extract_text</span><span style=\"color:#E1E4E8\">(self, image_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract text from image using OCR.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            import</span><span style=\"color:#E1E4E8\"> pytesseract</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            image </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Image.open(image_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> pytesseract.image_to_string(image)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> ImportError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#6A737D\">  # OCR not available</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AudioProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete audio processing with transcription and feature extraction.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.whisper_model </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> whisper.load_model(</span><span style=\"color:#9ECBFF\">\"base\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sample_rate </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 16000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> transcribe_audio</span><span style=\"color:#E1E4E8\">(self, audio_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Transcribe audio to text using Whisper.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.whisper_model.transcribe(audio_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> result[</span><span style=\"color:#9ECBFF\">\"text\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> extract_audio_features</span><span style=\"color:#E1E4E8\">(self, audio_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract acoustic features from audio.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        audio, sr </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> librosa.load(audio_path, </span><span style=\"color:#FFAB70\">sr</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.sample_rate)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Extract multiple feature types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        mfccs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> librosa.feature.mfcc(</span><span style=\"color:#FFAB70\">y</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">audio, </span><span style=\"color:#FFAB70\">sr</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">sr, </span><span style=\"color:#FFAB70\">n_mfcc</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">13</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        spectral_centroids </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> librosa.feature.spectral_centroid(</span><span style=\"color:#FFAB70\">y</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">audio, </span><span style=\"color:#FFAB70\">sr</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">sr)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        zero_crossing_rate </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> librosa.feature.zero_crossing_rate(audio)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Combine features</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        features </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.concatenate([</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            np.mean(mfccs.T, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            np.mean(spectral_centroids.T, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            np.mean(zero_crossing_rate.T, </span><span style=\"color:#FFAB70\">axis</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> features</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> VideoProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete video processing pipeline.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.image_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ImageProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.audio_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AudioProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> extract_frames</span><span style=\"color:#E1E4E8\">(self, video_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, max_frames: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> List[np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract representative frames from video.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cap </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cv2.VideoCapture(video_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        total_frames </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(cap.get(cv2.</span><span style=\"color:#79B8FF\">CAP_PROP_FRAME_COUNT</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Select evenly spaced frames</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        frame_indices </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> np.linspace(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, total_frames</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, max_frames, </span><span style=\"color:#FFAB70\">dtype</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        frames </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> frame_idx </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> frame_indices:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            cap.set(cv2.</span><span style=\"color:#79B8FF\">CAP_PROP_POS_FRAMES</span><span style=\"color:#E1E4E8\">, frame_idx)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            ret, frame </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> cap.read()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> ret:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Save frame temporarily and process with image processor</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                temp_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"/tmp/frame_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">frame_idx</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">.jpg\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                cv2.imwrite(temp_path, frame)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                frame_features </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.image_processor.extract_features(temp_path)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                frames.append(frame_features)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        cap.release()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> frames</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> extract_audio_track</span><span style=\"color:#E1E4E8\">(self, video_path: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Extract audio track from video for transcription.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            import</span><span style=\"color:#E1E4E8\"> moviepy.editor </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> mp</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            video </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> mp.VideoFileClip(video_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> video.audio:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                audio_path </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"/tmp/extracted_audio.wav\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                video.audio.write_audiofile(audio_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.audio_processor.transcribe_audio(audio_path)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> ImportError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> None</span></span></code></pre></div>\n\n<h4 id=\"core-multi-modal-encoder-skeleton\">Core Multi-Modal Encoder Skeleton</h4>\n<p>The core logic that learners should implement, with detailed TODO mapping to algorithmic steps:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MultiModalEncoder</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Multi-modal document encoder that creates unified embeddings across content types.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Integrates text, image, audio, and video processing into semantic search pipeline.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, text_model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"all-MiniLM-L6-v2\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Complete infrastructure provided above</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.text_encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> SentenceTransformer(text_model_name)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.image_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ImageProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.audio_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> AudioProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.video_processor </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> VideoProcessor()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.media_detector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> MediaTypeDetector()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> encode_multimodal_content</span><span style=\"color:#E1E4E8\">(self, content: MediaContent) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, np.ndarray]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Generate embeddings for multi-modal content with cross-modal alignment.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns dictionary mapping modality names to embedding vectors.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate content using MediaTypeDetector.validate_content()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For text content, generate embedding using self.text_encoder.encode()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For image content, extract visual features using self.image_processor.extract_features()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For image content, extract OCR text using self.image_processor.extract_text()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: For audio content, transcribe using self.audio_processor.transcribe_audio()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: For audio content, extract acoustic features using self.audio_processor.extract_audio_features()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: For video content, extract frames using self.video_processor.extract_frames()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: For video content, extract audio track using self.video_processor.extract_audio_track()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Combine all text sources (original + OCR + transcription) into unified text</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Generate cross-modal aligned embedding by weighted combination of modality embeddings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use different weights for primary modality vs extracted text/features</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Normalize each modality embedding before combination</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_unified_embedding</span><span style=\"color:#E1E4E8\">(self, modal_embeddings: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, np.ndarray], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                primary_modality: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Combine embeddings from different modalities into unified cross-modal embedding.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Primary modality receives higher weight in combination.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Define weights for each modality (primary=0.6, text=0.3, others=0.1 each)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Normalize each embedding vector to unit length using normalize_vector()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply modality-specific weights to normalized embeddings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Sum weighted embeddings to create unified representation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Normalize final unified embedding to unit length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle case where primary modality is missing by adjusting weights</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Ensure final embedding has same dimensionality as text embeddings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Consider adding small random noise to prevent identical embeddings</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SemanticFilterProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Semantic filtering implementation using concept vectors and embedding similarity.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Enables filtering by abstract concepts rather than explicit metadata.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, text_encoder: SentenceTransformer):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.text_encoder </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> text_encoder</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.concept_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}  </span><span style=\"color:#6A737D\"># Cache for concept vectors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_concept_filter</span><span style=\"color:#E1E4E8\">(self, concept_description: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            example_docs: Optional[List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Create concept vector from natural language description and optional examples.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Concept vector defines region in embedding space matching the concept.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if concept already cached, return if found</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate embedding from concept_description using text_encoder</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If example_docs provided, generate embeddings for each example</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Combine concept description embedding with example embeddings (weighted average)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Normalize final concept vector to unit length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Cache concept vector for future use</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return concept vector as filter representation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Weight concept description 0.4, examples 0.6 if both provided</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use centroid of example embeddings as example representation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> apply_semantic_filter</span><span style=\"color:#E1E4E8\">(self, document_embeddings: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             concept_filter: np.ndarray,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                             similarity_threshold: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.6</span><span style=\"color:#E1E4E8\">) -> np.ndarray:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Filter documents by semantic similarity to concept vector.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns boolean mask indicating which documents match concept.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Compute cosine similarity between each document and concept filter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Apply similarity threshold to create boolean mask</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Consider soft filtering with similarity-based weights instead of hard threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return boolean mask or similarity scores based on filtering mode</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use np.dot() for efficient batch cosine similarity computation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Higher threshold = more restrictive filtering</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConversationManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Conversational search session management with context tracking.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Maintains dialogue state and contextualizes queries across conversation turns.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, max_context_turns: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sessions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}  </span><span style=\"color:#6A737D\"># session_id -> ConversationSession</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.max_context_turns </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> max_context_turns</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> contextualize_query</span><span style=\"color:#E1E4E8\">(self, session_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, raw_query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Transform raw query using conversational context from session history.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Resolves pronouns, maintains topic continuity, handles follow-up questions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve conversation session or create new one</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify query type (new_topic, follow_up, clarification, refinement)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For follow-up queries, extract relevant context from recent turns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Resolve pronouns and references using conversation context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Expand abbreviated queries with topic context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Maintain topic coherence by combining query with active topics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Update conversation session with new turn information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return contextualized query suitable for semantic search</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use simple heuristics like pronoun detection and keyword overlap for context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Recent turns (last 2-3) more important than distant conversation history</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> suggest_clarifications</span><span style=\"color:#E1E4E8\">(self, session_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                              search_results: List[SearchResult]) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Generate clarification questions when query is ambiguous or results are diverse.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Helps users refine their search intent through guided dialogue.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Analyze search results for topic diversity using clustering</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify potential ambiguities in query (multiple interpretations)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate clarification questions for each major result cluster</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Consider user's conversation history to avoid repeated clarifications</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Rank clarification questions by potential impact on result quality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return top 2-3 most useful clarification questions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use embedding clustering to identify distinct result topics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Frame clarifications as specific choices rather than open-ended questions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"distributed-system-infrastructure\">Distributed System Infrastructure</h4>\n<p>Complete working implementation of coordination and health monitoring for distributed indexing:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Distributed indexing infrastructure with coordination and monitoring.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides production-ready components for managing distributed vector indices.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Set</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ShardInfo</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Information about an individual index shard.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    shard_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    host: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    port: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    document_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_heartbeat: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_healthy: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    load_score: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">  # 0.0 = idle, 1.0 = fully loaded</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryRoute</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Query routing decision with confidence scores.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    target_shards: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    confidence_scores: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    routing_strategy: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    estimated_cost: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistributedCoordinator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Complete coordination system for distributed vector search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_host: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"localhost\"</span><span style=\"color:#E1E4E8\">, redis_port: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 6379</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis.Redis(</span><span style=\"color:#FFAB70\">host</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">redis_host, </span><span style=\"color:#FFAB70\">port</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">redis_port)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.shard_registry: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, ShardInfo] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.health_check_interval </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.load_balance_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.8</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> register_shard</span><span style=\"color:#E1E4E8\">(self, shard_info: ShardInfo):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register new shard in distributed system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.shard_registry[shard_info.shard_id] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> shard_info</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Store shard info in Redis for persistence</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        shard_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'host'</span><span style=\"color:#E1E4E8\">: shard_info.host,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'port'</span><span style=\"color:#E1E4E8\">: shard_info.port,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'document_count'</span><span style=\"color:#E1E4E8\">: shard_info.document_count,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'registered_at'</span><span style=\"color:#E1E4E8\">: time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis_client.hset(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"shard:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">shard_info.shard_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">mapping</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">shard_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Start health monitoring for new shard</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        asyncio.create_task(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._monitor_shard_health(shard_info.shard_id))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> _monitor_shard_health</span><span style=\"color:#E1E4E8\">(self, shard_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Monitor individual shard health and performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#E1E4E8\"> shard_id </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.shard_registry:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                shard </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.shard_registry[shard_id]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Simple health check (could be HTTP ping, Redis ping, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                health_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"shard_health:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">shard_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                last_ping </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis_client.get(health_key)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> last_ping:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    time_since_ping </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(last_ping)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    shard.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time_since_ping </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.health_check_interval </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    shard.last_heartbeat </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> float</span><span style=\"color:#E1E4E8\">(last_ping)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    shard.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Update load score based on query volume</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                load_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"shard_load:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">shard_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                recent_queries </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis_client.llen(load_key)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                shard.load_score </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(recent_queries </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 100.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Normalize to 0-1</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Health check failed for shard </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">shard_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.shard_registry[shard_id].is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            await</span><span style=\"color:#E1E4E8\"> asyncio.sleep(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.health_check_interval)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_healthy_shards</span><span style=\"color:#E1E4E8\">(self) -> List[ShardInfo]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Return list of currently healthy shards.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> [shard </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> shard </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.shard_registry.values() </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> shard.is_healthy]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> estimate_shard_relevance</span><span style=\"color:#E1E4E8\">(self, query_embedding: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                shard_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Estimate how relevant a shard is for given query (simplified).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # In production, this would use learned routing models</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # For now, use simple heuristic based on shard characteristics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        shard </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.shard_registry.get(shard_id)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> shard </span><span style=\"color:#F97583\">or</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> shard.is_healthy:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 0.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Favor shards with more documents (more likely to have relevant content)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # but penalize overloaded shards</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        relevance_score </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(shard.document_count </span><span style=\"color:#F97583\">/</span><span style=\"color:#79B8FF\"> 10000.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        load_penalty </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#F97583\"> -</span><span style=\"color:#E1E4E8\"> (shard.load_score </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 0.3</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># 30% penalty for full load</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> relevance_score </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> load_penalty</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueryRouter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Intelligent query routing for distributed search.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, coordinator: DistributedCoordinator):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.coordinator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> coordinator</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.default_shard_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#6A737D\">  # Query top 3 shards by default</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.min_confidence_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0.3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> route_query</span><span style=\"color:#E1E4E8\">(self, query_embedding: np.ndarray, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                   max_shards: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> QueryRoute:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Determine which shards to query for optimal results.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Balances recall (finding all relevant docs) with performance (fewer shards).</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        healthy_shards </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.coordinator.get_healthy_shards()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> healthy_shards:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> QueryRoute([], {}, </span><span style=\"color:#9ECBFF\">\"emergency_fallback\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">'inf'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate relevance scores for all healthy shards</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        shard_scores </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> shard </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> healthy_shards:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            relevance </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.coordinator.estimate_shard_relevance(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                query_embedding, shard.shard_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> relevance </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.min_confidence_threshold:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                shard_scores[shard.shard_id] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relevance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Select top shards up to max_shards limit</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        target_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(max_shards </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.default_shard_count, </span><span style=\"color:#79B8FF\">len</span><span style=\"color:#E1E4E8\">(shard_scores))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        selected_shards </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sorted</span><span style=\"color:#E1E4E8\">(shard_scores.keys(), </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                               key</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\"> x: shard_scores[x], </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                               reverse</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)[:target_count]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate estimated query cost</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        estimated_cost </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> sum</span><span style=\"color:#E1E4E8\">(</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.coordinator.shard_registry[shard_id].document_count </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 0.001</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> shard_id </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> selected_shards</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> QueryRoute(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            target_shards</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">selected_shards,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            confidence_scores</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{shard_id: shard_scores[shard_id] </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> shard_id </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> selected_shards},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            routing_strategy</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"relevance_based\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            estimated_cost</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">estimated_cost</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span></code></pre></div>\n\n<h4 id=\"real-time-update-system-skeleton\">Real-Time Update System Skeleton</h4>\n<p>Core update pipeline logic that learners implement:</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RealTimeUpdatePipeline</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Real-time document update pipeline with multi-tier indexing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provides immediate search visibility while maintaining optimized performance.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, fast_index, main_index, consolidation_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1000</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.fast_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> fast_index  </span><span style=\"color:#6A737D\"># Write-optimized for recent docs</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.main_index </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> main_index  </span><span style=\"color:#6A737D\"># Read-optimized for stable docs</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.consolidation_threshold </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> consolidation_threshold</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.update_queue </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> asyncio.Queue()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> process_document_update</span><span style=\"color:#E1E4E8\">(self, document: Document, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                    operation: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"upsert\"</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Process single document update with immediate search visibility.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if update completed successfully.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate document and operation type (upsert, delete, update)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate embedding for document using existing DocumentEncoder</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Add document to fast_index for immediate search visibility</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Queue document for background processing and quality enrichment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Check if consolidation threshold reached (fast_index too large)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: If threshold reached, trigger background consolidation to main_index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Update search analytics and monitoring metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return success/failure status with error details if failed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use try-catch around index operations for graceful error handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Log document_id and timestamp for debugging update issues</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> consolidate_indices</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Move stabilized documents from fast_index to optimized main_index.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Maintains search performance by keeping main_index read-optimized.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get list of documents eligible for consolidation (age > threshold)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract embeddings and metadata from fast_index for eligible docs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Perform batch insertion into main_index with full optimization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify successful insertion by checking document searchability</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Remove consolidated documents from fast_index</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update index statistics and capacity metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Schedule next consolidation based on current growth rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Handle partial failures by rolling back incomplete consolidation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Process in batches to avoid memory issues with large consolidations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use atomic operations where possible to maintain consistency</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> handle_embedding_model_update</span><span style=\"color:#E1E4E8\">(self, new_model_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Coordinate system-wide embedding model update without service interruption.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Gradually transitions all documents to new embedding model.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate new embedding model can be loaded and is compatible</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create new DocumentEncoder instance with updated model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Begin processing new documents with updated model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Schedule background re-processing of existing documents in batches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Maintain dual-model search capability during transition period</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Monitor search quality metrics during model transition</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Complete transition when all documents use new model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Clean up old embeddings and update system configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Process oldest documents first to minimize quality impact</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use feature flags to control rollout speed and enable rollback</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints-for-future-extensions\">Milestone Checkpoints for Future Extensions</h4>\n<p>After implementing each extension component, verify expected behavior:</p>\n<p><strong>Multi-Modal Search Checkpoint:</strong></p>\n<ul>\n<li>Command: <code>python test_multimodal.py --test-image sample.jpg --test-audio sample.wav</code></li>\n<li>Expected: System generates embeddings for image and audio, enables cross-modal search</li>\n<li>Verification: Upload image of car, search &quot;red vehicle&quot; should return the image</li>\n<li>Debug: Check embedding dimensions match, verify CLIP model loaded correctly</li>\n</ul>\n<p><strong>Semantic Filtering Checkpoint:</strong></p>\n<ul>\n<li>Command: <code>python test_filters.py --concept &quot;beginner-friendly&quot; --sample-docs docs/</code></li>\n<li>Expected: Documents filtered by conceptual similarity rather than keyword matching</li>\n<li>Verification: Filter for &quot;technical complexity&quot; should separate simple vs advanced docs</li>\n<li>Debug: Check concept vectors are normalized, verify similarity threshold tuning</li>\n</ul>\n<p><strong>Conversational Search Checkpoint:</strong></p>\n<ul>\n<li>Command: <code>python test_conversation.py --session-id test123</code></li>\n<li>Expected: Follow-up queries maintain context, pronouns resolve correctly</li>\n<li>Verification: Search &quot;python&quot;, then &quot;what about functions?&quot; should understand context</li>\n<li>Debug: Check session state persistence, verify context window management</li>\n</ul>\n<p><strong>Distributed Indexing Checkpoint:</strong></p>\n<ul>\n<li>Command: <code>python test_distributed.py --shards 3 --queries 100</code></li>\n<li>Expected: Queries route to appropriate shards, results aggregate correctly</li>\n<li>Verification: All shards should receive health checks, query routing should balance load</li>\n<li>Debug: Check Redis connectivity, verify shard registration and heartbeat system</li>\n</ul>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> This section provides foundational understanding for all milestones (1-4), defining the technical terms, algorithms, and domain-specific vocabulary used throughout the semantic search engine design and implementation.</p>\n</blockquote>\n<p>This glossary serves as the authoritative reference for understanding the specialized terminology, algorithms, and concepts that form the foundation of our semantic search engine. Think of this glossary as your <strong>technical dictionary</strong> — just as a traditional dictionary helps you understand unfamiliar words when reading literature, this glossary helps you understand unfamiliar technical concepts when implementing semantic search. Each term includes not only its definition but also its context within our system and relationships to other concepts.</p>\n<p>The terminology is organized into logical categories to help you build understanding progressively, from fundamental search concepts through advanced algorithmic techniques to implementation-specific details.</p>\n<h3 id=\"core-search-concepts\">Core Search Concepts</h3>\n<p>The foundational concepts that distinguish different approaches to information retrieval and establish the vocabulary for discussing search system behavior.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>lexical search</strong></td>\n<td>Keyword-based search using inverted indexes that matches exact terms and variations</td>\n<td>Traditional search approach we&#39;re enhancing with semantic understanding</td>\n</tr>\n<tr>\n<td><strong>semantic search</strong></td>\n<td>Meaning-based search using vector embeddings that understands conceptual similarity</td>\n<td>Primary search paradigm our system implements</td>\n</tr>\n<tr>\n<td><strong>vocabulary mismatch</strong></td>\n<td>When users and documents use different terms for same concepts</td>\n<td>Core problem that semantic search solves through embedding similarity</td>\n</tr>\n<tr>\n<td><strong>inverted index</strong></td>\n<td>Data structure mapping terms to documents containing them</td>\n<td>Used in BM25 scoring component of our hybrid search approach</td>\n</tr>\n<tr>\n<td><strong>hybrid search</strong></td>\n<td>Combining lexical and semantic search approaches</td>\n<td>Our ranking strategy that merges BM25 and vector similarity scores</td>\n</tr>\n<tr>\n<td><strong>zero-result queries</strong></td>\n<td>Searches returning no matches requiring analysis</td>\n<td>Tracked in our analytics to identify content gaps and query understanding issues</td>\n</tr>\n<tr>\n<td><strong>query expansion</strong></td>\n<td>Adding synonyms and related terms to improve recall</td>\n<td>Implemented in our <code>QueryProcessor</code> to broaden search coverage</td>\n</tr>\n<tr>\n<td><strong>semantic drift</strong></td>\n<td>When expansion strays from original query meaning</td>\n<td>Risk we mitigate through controlled expansion and confidence scoring</td>\n</tr>\n</tbody></table>\n<h3 id=\"vector-embeddings-and-similarity\">Vector Embeddings and Similarity</h3>\n<p>The mathematical foundation of semantic search, covering how text is transformed into numerical representations and how similarity is computed.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>vector embedding</strong></td>\n<td>Dense numerical representation of text</td>\n<td>Core data structure produced by <code>DocumentEncoder</code> and stored in our index</td>\n</tr>\n<tr>\n<td><strong>embedding dimension</strong></td>\n<td>Number of components in a vector embedding</td>\n<td>Set to 384 for our default all-MiniLM-L6-v2 model, stored as <code>EMBEDDING_DIM</code></td>\n</tr>\n<tr>\n<td><strong>cosine similarity</strong></td>\n<td>Measure of vector similarity based on angle between vectors</td>\n<td>Primary similarity metric implemented in <code>cosine_similarity()</code> function</td>\n</tr>\n<tr>\n<td><strong>vector normalization</strong></td>\n<td>Scaling vectors to unit length for consistent similarity computation</td>\n<td>Performed by <code>normalize_vector()</code> to enable cosine similarity calculation</td>\n</tr>\n<tr>\n<td><strong>vector arithmetic</strong></td>\n<td>Mathematical operations on embedding vectors</td>\n<td>Used in multi-vector queries and negative term handling</td>\n</tr>\n<tr>\n<td><strong>embedding space</strong></td>\n<td>High-dimensional space where similar concepts are located near each other</td>\n<td>The mathematical space our FAISS index organizes for efficient search</td>\n</tr>\n</tbody></table>\n<h3 id=\"approximate-nearest-neighbor-search\">Approximate Nearest Neighbor Search</h3>\n<p>The algorithmic techniques that enable efficient similarity search over large collections of high-dimensional vectors.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>approximate nearest neighbor</strong></td>\n<td>Efficient algorithm for finding similar vectors with controlled accuracy trade-offs</td>\n<td>Core algorithm powering our FAISS-based <code>EmbeddingIndex</code></td>\n</tr>\n<tr>\n<td><strong>HNSW</strong></td>\n<td>Hierarchical Navigable Small World graph for vector search</td>\n<td>One of two index algorithms we support, optimized for query speed</td>\n</tr>\n<tr>\n<td><strong>IVF</strong></td>\n<td>Inverted File indexing that partitions vectors into clusters</td>\n<td>Alternative index algorithm we support, optimized for memory efficiency</td>\n</tr>\n<tr>\n<td><strong>index training</strong></td>\n<td>Process of learning optimal data structure parameters from sample data</td>\n<td>Required for IVF indices before document vectors can be added</td>\n</tr>\n<tr>\n<td><strong>index persistence</strong></td>\n<td>Saving trained indices to disk for recovery and deployment</td>\n<td>Handled through FAISS serialization in our index management layer</td>\n</tr>\n<tr>\n<td><strong>incremental updates</strong></td>\n<td>Adding new vectors without full index reconstruction</td>\n<td>Supported through FAISS add operations with periodic consolidation</td>\n</tr>\n</tbody></table>\n<h3 id=\"query-understanding-and-processing\">Query Understanding and Processing</h3>\n<p>The techniques for analyzing, enhancing, and interpreting user search queries to improve result relevance.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>entity recognition</strong></td>\n<td>Identifying proper nouns and technical terms in queries</td>\n<td>Part of our <code>QueryProcessor</code> pipeline for preserving important terms</td>\n</tr>\n<tr>\n<td><strong>intent classification</strong></td>\n<td>Understanding what type of search the user wants</td>\n<td>Helps our system route queries and select appropriate processing strategies</td>\n</tr>\n<tr>\n<td><strong>multi-vector query</strong></td>\n<td>Complex query with multiple semantic aspects</td>\n<td>Handled by <code>handle_multi_vector_query()</code> to decompose and weight query components</td>\n</tr>\n<tr>\n<td><strong>query normalization</strong></td>\n<td>Standardizing query text format for consistent processing</td>\n<td>Performed by <code>TextNormalizer</code> to enable effective caching and processing</td>\n</tr>\n<tr>\n<td><strong>query sanitization</strong></td>\n<td>Cleaning and normalizing user input for safe processing</td>\n<td>Implemented in <code>validate_and_sanitize()</code> to handle malformed input</td>\n</tr>\n<tr>\n<td><strong>unicode normalization</strong></td>\n<td>Standardizing character representations for consistent processing</td>\n<td>Part of query sanitization to handle international text correctly</td>\n</tr>\n<tr>\n<td><strong>intelligent truncation</strong></td>\n<td>Shortening queries while preserving important terms</td>\n<td>Strategy for handling queries exceeding <code>MAX_QUERY_LENGTH</code></td>\n</tr>\n</tbody></table>\n<h3 id=\"ranking-and-relevance\">Ranking and Relevance</h3>\n<p>The algorithms and strategies for ordering search results by relevance, combining multiple signals to optimize user satisfaction.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>BM25</strong></td>\n<td>Ranking function for lexical search based on term frequency and document length</td>\n<td>Lexical scoring component in our hybrid <code>RankingEngine</code></td>\n</tr>\n<tr>\n<td><strong>cross-encoder reranking</strong></td>\n<td>Precise but expensive ranking using transformer models</td>\n<td>Second-stage ranking applied to top candidates for maximum accuracy</td>\n</tr>\n<tr>\n<td><strong>multi-stage ranking</strong></td>\n<td>Ranking pipeline with fast retrieval then precise reranking</td>\n<td>Our performance optimization strategy balancing speed and quality</td>\n</tr>\n<tr>\n<td><strong>position bias</strong></td>\n<td>Tendency to click higher-ranked results regardless of relevance</td>\n<td>Bias we account for in click-through learning algorithms</td>\n</tr>\n<tr>\n<td><strong>click-through learning</strong></td>\n<td>Using user interaction data to improve ranking</td>\n<td>Implemented through <code>record_interaction()</code> and score adjustments</td>\n</tr>\n<tr>\n<td><strong>personalization signals</strong></td>\n<td>User context factors for customized ranking</td>\n<td>Processed through <code>PersonalizationContext</code> for tailored results</td>\n</tr>\n<tr>\n<td><strong>freshness decay</strong></td>\n<td>Time-based relevance score reduction</td>\n<td>Applied to boost recent documents while aging older content</td>\n</tr>\n<tr>\n<td><strong>learning to rank</strong></td>\n<td>Machine learning approach to optimize ranking functions</td>\n<td>Framework for incorporating click data into our scoring model</td>\n</tr>\n</tbody></table>\n<h3 id=\"search-api-and-user-experience\">Search API and User Experience</h3>\n<p>The interface design patterns and performance characteristics that define how users interact with the search system.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>autocomplete</strong></td>\n<td>Typeahead suggestions with sub-100ms latency</td>\n<td>Provided by <code>get_autocomplete_suggestions()</code> with strict timing requirements</td>\n</tr>\n<tr>\n<td><strong>faceted navigation</strong></td>\n<td>Category filtering with filter counts per category</td>\n<td>Implemented through <code>compute_facets()</code> for structured result exploration</td>\n</tr>\n<tr>\n<td><strong>query term highlighting</strong></td>\n<td>Marking matched words in result snippets</td>\n<td>Performed by <code>highlight_query_terms()</code> to show relevance visually</td>\n</tr>\n<tr>\n<td><strong>search analytics</strong></td>\n<td>Query tracking and result quality metrics</td>\n<td>Collected through <code>record_search_analytics()</code> for system improvement</td>\n</tr>\n<tr>\n<td><strong>response time SLA</strong></td>\n<td>Service level agreement for API response latency</td>\n<td>Target of sub-500ms for search, sub-100ms for autocomplete</td>\n</tr>\n<tr>\n<td><strong>rate limiting</strong></td>\n<td>Request throttling to prevent abuse</td>\n<td>Protection mechanism for production API deployment</td>\n</tr>\n<tr>\n<td><strong>correlation ID</strong></td>\n<td>Unique identifier linking user reports to internal logs</td>\n<td>Generated in <code>create_context()</code> for debugging and support</td>\n</tr>\n</tbody></table>\n<h3 id=\"system-reliability-and-error-handling\">System Reliability and Error Handling</h3>\n<p>The patterns and techniques for building robust, fault-tolerant search systems that gracefully handle failures and edge cases.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>graceful degradation</strong></td>\n<td>Maintaining basic functionality when advanced features fail</td>\n<td>Strategy for handling component failures while preserving core search</td>\n</tr>\n<tr>\n<td><strong>circuit breaker</strong></td>\n<td>Pattern preventing cascading failures by disabling failing components</td>\n<td>Implemented in our component interaction layer for fault isolation</td>\n</tr>\n<tr>\n<td><strong>exponential backoff</strong></td>\n<td>Retry strategy with increasing delays between attempts</td>\n<td>Used in our retry mechanisms to avoid overwhelming failing services</td>\n</tr>\n<tr>\n<td><strong>timeout budget</strong></td>\n<td>Allocated time limit for different processing stages</td>\n<td>Managed through <code>ContextInfo</code> to ensure responsive user experience</td>\n</tr>\n<tr>\n<td><strong>fallback strategy</strong></td>\n<td>Alternative processing approach when primary method fails</td>\n<td>Implemented for each component to provide degraded but functional service</td>\n</tr>\n<tr>\n<td><strong>fault tolerance</strong></td>\n<td>System&#39;s ability to continue operating despite component failures</td>\n<td>Overall design principle ensuring search availability during partial outages</td>\n</tr>\n<tr>\n<td><strong>component unavailability</strong></td>\n<td>Temporary or permanent failure of system components</td>\n<td>Handled through circuit breakers and fallback mechanisms</td>\n</tr>\n<tr>\n<td><strong>partial results</strong></td>\n<td>Incomplete search results returned when some components fail</td>\n<td>Strategy for maintaining user experience during degraded system state</td>\n</tr>\n</tbody></table>\n<h3 id=\"performance-and-evaluation-metrics\">Performance and Evaluation Metrics</h3>\n<p>The quantitative measures used to assess search quality, system performance, and user satisfaction.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>precision at k</strong></td>\n<td>Fraction of top k results that are relevant</td>\n<td>Primary relevance metric calculated by <code>calculate_precision_at_k()</code></td>\n</tr>\n<tr>\n<td><strong>recall at k</strong></td>\n<td>Fraction of relevant documents found in top k</td>\n<td>Completeness metric for evaluating search coverage</td>\n</tr>\n<tr>\n<td><strong>NDCG</strong></td>\n<td>Normalized discounted cumulative gain ranking metric</td>\n<td>Gold standard ranking metric computed by <code>calculate_ndcg()</code></td>\n</tr>\n<tr>\n<td><strong>MAP</strong></td>\n<td>Mean average precision across all queries</td>\n<td>Overall search quality metric for system evaluation</td>\n</tr>\n<tr>\n<td><strong>MRR</strong></td>\n<td>Mean reciprocal rank of first relevant result</td>\n<td>Metric focusing on finding the best result quickly</td>\n</tr>\n<tr>\n<td><strong>ground truth</strong></td>\n<td>Expert judgments of query-document relevance</td>\n<td>Reference data for training and evaluating our ranking algorithms</td>\n</tr>\n<tr>\n<td><strong>relevance metrics</strong></td>\n<td>Quantitative measures of search result quality</td>\n<td>Suite of metrics for comprehensive search quality assessment</td>\n</tr>\n<tr>\n<td><strong>throughput</strong></td>\n<td>Requests per second the system can handle</td>\n<td>Performance metric measured in our load testing framework</td>\n</tr>\n<tr>\n<td><strong>latency percentiles</strong></td>\n<td>Response time distribution measurements</td>\n<td>Key SLA metrics including p50, p95, and p99 response times</td>\n</tr>\n</tbody></table>\n<h3 id=\"caching-and-performance-optimization\">Caching and Performance Optimization</h3>\n<p>The strategies for improving system performance through intelligent data storage and retrieval patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>cache invalidation</strong></td>\n<td>Removing stale cached data when underlying data changes</td>\n<td>Critical for maintaining consistency in our <code>EmbeddingCache</code></td>\n</tr>\n<tr>\n<td><strong>query embedding cache</strong></td>\n<td>Storing computed query vectors for repeated lookups</td>\n<td>Performance optimization in <code>EmbeddingCache</code> for common queries</td>\n</tr>\n<tr>\n<td><strong>cache hit ratio</strong></td>\n<td>Percentage of requests served from cache vs computed fresh</td>\n<td>Key performance metric for evaluating cache effectiveness</td>\n</tr>\n<tr>\n<td><strong>TTL</strong></td>\n<td>Time-to-live expiration for cached data</td>\n<td>Configured in cache to balance freshness and performance</td>\n</tr>\n<tr>\n<td><strong>LRU eviction</strong></td>\n<td>Least recently used cache replacement policy</td>\n<td>Strategy for managing cache memory limits</td>\n</tr>\n<tr>\n<td><strong>cache warming</strong></td>\n<td>Preloading cache with anticipated data</td>\n<td>Strategy for reducing cold start latency</td>\n</tr>\n<tr>\n<td><strong>memory-mapped access</strong></td>\n<td>Direct file system access for large datasets</td>\n<td>Enables processing datasets larger than available RAM</td>\n</tr>\n</tbody></table>\n<h3 id=\"advanced-search-features\">Advanced Search Features</h3>\n<p>The sophisticated capabilities that extend basic semantic search into specialized domains and use cases.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>multi-modal search</strong></td>\n<td>Search capability across text, image, audio, and video content</td>\n<td>Advanced feature using <code>MultiModalEncoder</code> for unified embeddings</td>\n</tr>\n<tr>\n<td><strong>cross-modal alignment</strong></td>\n<td>Mapping different media types to comparable embedding spaces</td>\n<td>Technique enabling search across different content types</td>\n</tr>\n<tr>\n<td><strong>semantic filtering</strong></td>\n<td>Filtering by abstract concepts rather than explicit metadata</td>\n<td>Advanced capability using <code>ConceptFilter</code> for conceptual constraints</td>\n</tr>\n<tr>\n<td><strong>conversational search</strong></td>\n<td>Multi-turn search dialogue with context maintenance</td>\n<td>Sophisticated interaction pattern managed by <code>ConversationManager</code></td>\n</tr>\n<tr>\n<td><strong>context window</strong></td>\n<td>Number of previous conversation turns maintained</td>\n<td>Configured as <code>MAX_CONTEXT_TURNS</code> for conversational coherence</td>\n</tr>\n<tr>\n<td><strong>query contextualization</strong></td>\n<td>Transforming queries based on conversation history</td>\n<td>Process of understanding queries in conversational context</td>\n</tr>\n</tbody></table>\n<h3 id=\"distributed-systems-and-scaling\">Distributed Systems and Scaling</h3>\n<p>The architectural patterns and techniques for scaling semantic search across multiple machines and data centers.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>distributed indexing</strong></td>\n<td>Partitioning vector indices across multiple nodes</td>\n<td>Scaling strategy for handling large document collections</td>\n</tr>\n<tr>\n<td><strong>search federation</strong></td>\n<td>Coordinating search across multiple independent systems</td>\n<td>Architecture for unified search across heterogeneous sources</td>\n</tr>\n<tr>\n<td><strong>query routing</strong></td>\n<td>Selecting optimal subset of shards for each search query</td>\n<td>Performance optimization managed by <code>QueryRouter</code></td>\n</tr>\n<tr>\n<td><strong>result harmonization</strong></td>\n<td>Normalizing relevance scores across heterogeneous sources</td>\n<td>Process ensuring consistent scoring across federated sources</td>\n</tr>\n<tr>\n<td><strong>shard balancing</strong></td>\n<td>Distributing load evenly across index partitions</td>\n<td>Strategy for optimal resource utilization in distributed deployment</td>\n</tr>\n<tr>\n<td><strong>real-time updates</strong></td>\n<td>Immediate document visibility without batch processing delays</td>\n<td>Advanced capability for dynamic content environments</td>\n</tr>\n<tr>\n<td><strong>index consolidation</strong></td>\n<td>Periodic merging of incremental updates into main index</td>\n<td>Maintenance process optimizing search performance</td>\n</tr>\n<tr>\n<td><strong>hot-cold storage</strong></td>\n<td>Tiered storage strategy based on access patterns</td>\n<td>Cost optimization for large-scale deployments</td>\n</tr>\n</tbody></table>\n<h3 id=\"data-structures-and-implementation-details\">Data Structures and Implementation Details</h3>\n<p>The specific technical constructs and patterns used in the system implementation.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>embedding model</strong></td>\n<td>Neural network that converts text to vector representations</td>\n<td>Implemented using Sentence Transformers with <code>DEFAULT_MODEL</code></td>\n</tr>\n<tr>\n<td><strong>model checkpoint</strong></td>\n<td>Saved state of trained neural network</td>\n<td>Used for consistent embedding generation across system restarts</td>\n</tr>\n<tr>\n<td><strong>batch processing</strong></td>\n<td>Processing multiple items together for efficiency</td>\n<td>Strategy used in <code>encode_texts()</code> for optimal GPU utilization</td>\n</tr>\n<tr>\n<td><strong>memory fragmentation</strong></td>\n<td>Inefficient memory allocation causing out-of-memory despite sufficient total memory</td>\n<td>Common issue in vector processing requiring careful memory management</td>\n</tr>\n<tr>\n<td><strong>index corruption</strong></td>\n<td>Data integrity issues in vector index requiring recovery</td>\n<td>Failure mode detected through health checks and requiring index rebuild</td>\n</tr>\n<tr>\n<td><strong>dimension mismatch</strong></td>\n<td>Inconsistency between expected and actual vector sizes</td>\n<td>Common bug caught in our validation and debugging framework</td>\n</tr>\n<tr>\n<td><strong>ID mapping</strong></td>\n<td>Association between external document identifiers and internal index positions</td>\n<td>Critical consistency requirement managed by our indexing layer</td>\n</tr>\n</tbody></table>\n<h3 id=\"machine-learning-and-model-management\">Machine Learning and Model Management</h3>\n<p>The concepts related to training, deploying, and maintaining the machine learning models that power semantic understanding.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>embedding model update</strong></td>\n<td>Transitioning to new embedding models without service interruption</td>\n<td>Complex process requiring coordinated re-embedding and index rebuilding</td>\n</tr>\n<tr>\n<td><strong>model drift</strong></td>\n<td>Degradation in model performance over time due to data changes</td>\n<td>Monitoring concern for maintaining search quality</td>\n</tr>\n<tr>\n<td><strong>transfer learning</strong></td>\n<td>Using pre-trained models for specific domains</td>\n<td>Strategy for adapting general language models to specialized content</td>\n</tr>\n<tr>\n<td><strong>fine-tuning</strong></td>\n<td>Adjusting pre-trained models for specific tasks or domains</td>\n<td>Potential improvement for domain-specific search applications</td>\n</tr>\n<tr>\n<td><strong>model versioning</strong></td>\n<td>Tracking different versions of embedding models</td>\n<td>Essential for reproducible results and coordinated updates</td>\n</tr>\n<tr>\n<td><strong>A/B testing</strong></td>\n<td>Comparing performance of different models or algorithms</td>\n<td>Strategy for validating improvements before full deployment</td>\n</tr>\n</tbody></table>\n<h3 id=\"quality-assurance-and-testing\">Quality Assurance and Testing</h3>\n<p>The methodologies and techniques for ensuring search system reliability, performance, and user satisfaction.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context in Our System</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>relevance evaluation</strong></td>\n<td>Systematic assessment of search result quality</td>\n<td>Process using human judgment and automated metrics</td>\n</tr>\n<tr>\n<td><strong>load testing</strong></td>\n<td>Performance testing under realistic traffic patterns</td>\n<td>Implemented through <code>run_concurrent_load_test()</code></td>\n</tr>\n<tr>\n<td><strong>regression testing</strong></td>\n<td>Detecting performance degradation from system changes</td>\n<td>Automated testing preventing quality regressions</td>\n</tr>\n<tr>\n<td><strong>golden dataset</strong></td>\n<td>Curated test queries with known correct results</td>\n<td>Reference collection for validating search improvements</td>\n</tr>\n<tr>\n<td><strong>stress testing</strong></td>\n<td>Evaluating system behavior under extreme conditions</td>\n<td>Testing approach for identifying breaking points</td>\n</tr>\n<tr>\n<td><strong>canary deployment</strong></td>\n<td>Gradual rollout to detect issues before full deployment</td>\n<td>Risk mitigation strategy for production updates</td>\n</tr>\n</tbody></table>\n<h3 id=\"constants-and-configuration\">Constants and Configuration</h3>\n<p>The specific values and settings that control system behavior and performance characteristics.</p>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Value/Context</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>DEFAULT_MODEL</strong></td>\n<td>Primary sentence transformer model for embeddings</td>\n<td><code>all-MiniLM-L6-v2</code> - balanced performance and quality</td>\n</tr>\n<tr>\n<td><strong>EMBEDDING_DIM</strong></td>\n<td>Dimensionality of vector embeddings</td>\n<td><code>384</code> dimensions for our default model</td>\n</tr>\n<tr>\n<td><strong>MAX_QUERY_LENGTH</strong></td>\n<td>Maximum allowed query length in characters</td>\n<td><code>500</code> characters to prevent processing issues</td>\n</tr>\n<tr>\n<td><strong>AUTOCOMPLETE_TIMEOUT_MS</strong></td>\n<td>Response time limit for autocomplete suggestions</td>\n<td><code>100</code> milliseconds for responsive user experience</td>\n</tr>\n<tr>\n<td><strong>SEARCH_TIMEOUT_MS</strong></td>\n<td>Response time limit for search requests</td>\n<td><code>500</code> milliseconds for acceptable user experience</td>\n</tr>\n<tr>\n<td><strong>DEFAULT_MAX_RESULTS</strong></td>\n<td>Standard number of results returned per search</td>\n<td><code>20</code> results balancing completeness and performance</td>\n</tr>\n<tr>\n<td><strong>MIN_KEYWORD_LENGTH</strong></td>\n<td>Minimum length for keywords to be indexed</td>\n<td><code>3</code> characters to filter noise terms</td>\n</tr>\n<tr>\n<td><strong>FACET_COMPUTATION_LIMIT</strong></td>\n<td>Maximum results to consider for facet counting</td>\n<td><code>1000</code> documents to balance accuracy and performance</td>\n</tr>\n</tbody></table>\n<p>This comprehensive glossary provides the shared vocabulary necessary for understanding, implementing, and maintaining our semantic search engine. Each term connects to specific components, algorithms, or design decisions documented throughout this design document, enabling precise technical communication and reducing ambiguity during development and operations.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The glossary serves not only as a reference during system design but also as a critical resource during implementation. Each technical term corresponds to specific code constructs, configuration parameters, or algorithmic implementations in your semantic search system.</p>\n<p><strong>Using the Glossary During Development:</strong></p>\n<p>When implementing each milestone, refer to this glossary to ensure consistent terminology and understanding across your codebase. For example, when working on Milestone 1 (Embedding Index), terms like &quot;vector normalization,&quot; &quot;HNSW,&quot; and &quot;index persistence&quot; directly correspond to functions and design decisions you&#39;ll need to implement.</p>\n<p><strong>Code Comments and Documentation:</strong></p>\n<p>Use these standardized terms in your code comments and documentation to maintain consistency with this design document. For instance, when implementing the <code>normalize_vector()</code> function, your comment should reference &quot;L2 normalization for cosine similarity computation&quot; using the vocabulary established here.</p>\n<p><strong>Debugging and Troubleshooting:</strong></p>\n<p>When investigating issues, this glossary helps translate between observed symptoms and underlying technical causes. If you observe &quot;poor result quality,&quot; you can trace through related terms like &quot;semantic drift,&quot; &quot;position bias,&quot; or &quot;vocabulary mismatch&quot; to identify potential root causes.</p>\n<p><strong>Team Communication:</strong></p>\n<p>This shared vocabulary enables precise communication between team members. Instead of vague descriptions like &quot;the search isn&#39;t working well,&quot; team members can use specific terms like &quot;we&#39;re seeing high semantic drift in query expansion&quot; or &quot;the circuit breaker is triggering due to embedding model timeouts.&quot;</p>\n<p>The terminology in this glossary represents industry-standard concepts and our system-specific implementations, ensuring your semantic search engine aligns with established practices while maintaining internal consistency throughout development and operations.</p>\n","toc":[{"level":1,"text":"Semantic Search Engine: Design Document","id":"semantic-search-engine-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"From Keywords to Meaning: Mental Model","id":"from-keywords-to-meaning-mental-model"},{"level":3,"text":"Existing Search Technologies","id":"existing-search-technologies"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Core Functional Requirements","id":"core-functional-requirements"},{"level":3,"text":"Performance and Scale Requirements","id":"performance-and-scale-requirements"},{"level":3,"text":"What We Won&#39;t Build","id":"what-we-won39t-build"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Core Components","id":"core-components"},{"level":3,"text":"End-to-End Data Flow","id":"end-to-end-data-flow"},{"level":3,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Document and Embedding Model","id":"document-and-embedding-model"},{"level":4,"text":"Document Representation","id":"document-representation"},{"level":4,"text":"Document Text Processing","id":"document-text-processing"},{"level":4,"text":"Vector Embedding Representation","id":"vector-embedding-representation"},{"level":4,"text":"Document Encoding Pipeline","id":"document-encoding-pipeline"},{"level":3,"text":"Index Data Structures","id":"index-data-structures"},{"level":4,"text":"Vector Index Organization","id":"vector-index-organization"},{"level":4,"text":"HNSW Index Structure","id":"hnsw-index-structure"},{"level":4,"text":"IVF Index Structure","id":"ivf-index-structure"},{"level":4,"text":"Index Persistence and Metadata","id":"index-persistence-and-metadata"},{"level":3,"text":"Query and Result Model","id":"query-and-result-model"},{"level":4,"text":"Search Query Representation","id":"search-query-representation"},{"level":4,"text":"Query Processing Pipeline Data Structures","id":"query-processing-pipeline-data-structures"},{"level":4,"text":"Search Result Representation","id":"search-result-representation"},{"level":4,"text":"Query Response Structure","id":"query-response-structure"},{"level":4,"text":"Result Ranking and Scoring","id":"result-ranking-and-scoring"},{"level":3,"text":"Common Implementation Pitfalls","id":"common-implementation-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Data Structure Implementation","id":"core-data-structure-implementation"},{"level":4,"text":"Query and Result Implementation","id":"query-and-result-implementation"},{"level":4,"text":"Data Validation and Testing","id":"data-validation-and-testing"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Embedding Index Component","id":"embedding-index-component"},{"level":3,"text":"Vector Search Mental Model: Library Analogy","id":"vector-search-mental-model-library-analogy"},{"level":3,"text":"Document Embedding Pipeline","id":"document-embedding-pipeline"},{"level":4,"text":"Text Preprocessing and Normalization","id":"text-preprocessing-and-normalization"},{"level":4,"text":"Transformer Model Integration","id":"transformer-model-integration"},{"level":4,"text":"Embedding Generation and Validation","id":"embedding-generation-and-validation"},{"level":3,"text":"Index Algorithm Selection","id":"index-algorithm-selection"},{"level":4,"text":"Algorithm Comparison and Trade-off Analysis","id":"algorithm-comparison-and-trade-off-analysis"},{"level":4,"text":"HNSW Algorithm Deep Dive","id":"hnsw-algorithm-deep-dive"},{"level":4,"text":"IVF Algorithm Deep Dive","id":"ivf-algorithm-deep-dive"},{"level":4,"text":"Architecture Decision: HNSW Selection","id":"architecture-decision-hnsw-selection"},{"level":4,"text":"Hybrid Index Strategy","id":"hybrid-index-strategy"},{"level":3,"text":"Index Persistence and Updates","id":"index-persistence-and-updates"},{"level":4,"text":"Index Serialization and Storage Format","id":"index-serialization-and-storage-format"},{"level":4,"text":"Incremental Update Implementation","id":"incremental-update-implementation"},{"level":4,"text":"Index State Management and Recovery","id":"index-state-management-and-recovery"},{"level":3,"text":"Common Implementation Pitfalls","id":"common-implementation-pitfalls"},{"level":4,"text":"⚠️ Pitfall: Vector Normalization Inconsistency","id":"-pitfall-vector-normalization-inconsistency"},{"level":4,"text":"⚠️ Pitfall: HNSW Memory Explosion with High M Parameter","id":"-pitfall-hnsw-memory-explosion-with-high-m-parameter"},{"level":4,"text":"⚠️ Pitfall: Document ID Mapping Synchronization Issues","id":"-pitfall-document-id-mapping-synchronization-issues"},{"level":4,"text":"⚠️ Pitfall: IVF Training Data Insufficiency","id":"-pitfall-ivf-training-data-insufficiency"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File/Module Structure","id":"recommended-filemodule-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Query Processing Component","id":"query-processing-component"},{"level":3,"text":"Query Understanding Mental Model: Translator Analogy for How Queries Are Interpreted and Enhanced","id":"query-understanding-mental-model-translator-analogy-for-how-queries-are-interpreted-and-enhanced"},{"level":3,"text":"Query Expansion Strategy: Adding Synonyms and Related Terms While Avoiding Over-Expansion","id":"query-expansion-strategy-adding-synonyms-and-related-terms-while-avoiding-over-expansion"},{"level":3,"text":"Semantic Query Analysis: Entity extraction and Intent Understanding from Query Text","id":"semantic-query-analysis-entity-extraction-and-intent-understanding-from-query-text"},{"level":3,"text":"Multi-Vector Query Support: Combining Multiple Query Aspects and Handling Negative Terms","id":"multi-vector-query-support-combining-multiple-query-aspects-and-handling-negative-terms"},{"level":3,"text":"Query Embedding Cache: Caching Frequent Query Embeddings for Performance","id":"query-embedding-cache-caching-frequent-query-embeddings-for-performance"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Ranking and Relevance Component","id":"ranking-and-relevance-component"},{"level":3,"text":"Multi-Signal Ranking Mental Model: Orchestra Conductor Analogy","id":"multi-signal-ranking-mental-model-orchestra-conductor-analogy"},{"level":3,"text":"Multi-Stage Ranking Pipeline: Fast Retrieval Followed by Precise Cross-Encoder Reranking","id":"multi-stage-ranking-pipeline-fast-retrieval-followed-by-precise-cross-encoder-reranking"},{"level":3,"text":"Hybrid Semantic and Lexical Search: Combining BM25 Keyword Scores with Vector Similarity Scores","id":"hybrid-semantic-and-lexical-search-combining-bm25-keyword-scores-with-vector-similarity-scores"},{"level":3,"text":"Personalization and Freshness Signals: User Preference Matching and Time-Based Relevance Decay","id":"personalization-and-freshness-signals-user-preference-matching-and-time-based-relevance-decay"},{"level":3,"text":"Click-Through Learning: Using User Interaction Data to Improve Ranking Quality","id":"click-through-learning-using-user-interaction-data-to-improve-ranking-quality"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Core Ranking Data Structures","id":"core-ranking-data-structures"},{"level":4,"text":"Multi-Stage Ranking Pipeline Implementation","id":"multi-stage-ranking-pipeline-implementation"},{"level":4,"text":"Cross-Encoder Reranking Component","id":"cross-encoder-reranking-component"},{"level":4,"text":"Personalization and Freshness Scoring","id":"personalization-and-freshness-scoring"},{"level":4,"text":"Click-Through Learning System","id":"click-through-learning-system"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":4,"text":"Common Debugging Issues","id":"common-debugging-issues"},{"level":2,"text":"Search API and User Interface","id":"search-api-and-user-interface"},{"level":3,"text":"Search API Mental Model: Reference Librarian Analogy","id":"search-api-mental-model-reference-librarian-analogy"},{"level":3,"text":"RESTful Search Endpoints","id":"restful-search-endpoints"},{"level":3,"text":"Autocomplete and Typeahead","id":"autocomplete-and-typeahead"},{"level":3,"text":"Faceted Navigation","id":"faceted-navigation"},{"level":3,"text":"Query Term Highlighting","id":"query-term-highlighting"},{"level":3,"text":"Search Analytics Dashboard","id":"search-analytics-dashboard"},{"level":3,"text":"Component Interactions and Data Flow","id":"component-interactions-and-data-flow"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Component Interactions and Data Flow","id":"component-interactions-and-data-flow"},{"level":3,"text":"Document Indexing Workflow","id":"document-indexing-workflow"},{"level":3,"text":"Search Request Processing Flow","id":"search-request-processing-flow"},{"level":3,"text":"Internal Component APIs","id":"internal-component-apis"},{"level":4,"text":"Document Processing APIs","id":"document-processing-apis"},{"level":4,"text":"Query Processing APIs","id":"query-processing-apis"},{"level":4,"text":"Ranking and Retrieval APIs","id":"ranking-and-retrieval-apis"},{"level":4,"text":"Error Handling and Context Propagation","id":"error-handling-and-context-propagation"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"File Structure for Component Communication","id":"file-structure-for-component-communication"},{"level":4,"text":"Message Types Infrastructure","id":"message-types-infrastructure"},{"level":4,"text":"Component Communication Base Classes","id":"component-communication-base-classes"},{"level":4,"text":"Error Handling Infrastructure","id":"error-handling-infrastructure"},{"level":4,"text":"Document Indexing Workflow Implementation","id":"document-indexing-workflow-implementation"},{"level":4,"text":"Search Request Flow Implementation","id":"search-request-flow-implementation"},{"level":4,"text":"Monitoring and Health Checks","id":"monitoring-and-health-checks"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Index Construction Failures","id":"index-construction-failures"},{"level":3,"text":"Search-Time Error Handling","id":"search-time-error-handling"},{"level":3,"text":"Edge Case Query Handling","id":"edge-case-query-handling"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Testing Strategy","id":"testing-strategy"},{"level":3,"text":"Search Quality Evaluation","id":"search-quality-evaluation"},{"level":4,"text":"Relevance Metrics and Measurement Framework","id":"relevance-metrics-and-measurement-framework"},{"level":4,"text":"Test Query Development Strategy","id":"test-query-development-strategy"},{"level":4,"text":"Offline Evaluation Infrastructure","id":"offline-evaluation-infrastructure"},{"level":3,"text":"Performance and Load Testing","id":"performance-and-load-testing"},{"level":4,"text":"Latency Benchmarks and SLA Definition","id":"latency-benchmarks-and-sla-definition"},{"level":4,"text":"Throughput Validation and Scalability Testing","id":"throughput-validation-and-scalability-testing"},{"level":4,"text":"Load Testing Infrastructure and Automation","id":"load-testing-infrastructure-and-automation"},{"level":3,"text":"Milestone Verification Checkpoints","id":"milestone-verification-checkpoints"},{"level":4,"text":"Milestone 1: Embedding Index Verification","id":"milestone-1-embedding-index-verification"},{"level":4,"text":"Milestone 2: Query Processing Verification","id":"milestone-2-query-processing-verification"},{"level":4,"text":"Milestone 3: Ranking and Relevance Verification","id":"milestone-3-ranking-and-relevance-verification"},{"level":4,"text":"Milestone 4: Search API and UI Verification","id":"milestone-4-search-api-and-ui-verification"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Testing Structure","id":"recommended-testing-structure"},{"level":4,"text":"Complete Test Infrastructure Starter Code","id":"complete-test-infrastructure-starter-code"},{"level":4,"text":"Milestone Verification Scripts","id":"milestone-verification-scripts"},{"level":4,"text":"Debugging and Troubleshooting Guide","id":"debugging-and-troubleshooting-guide"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Embedding and Index Issues","id":"embedding-and-index-issues"},{"level":4,"text":"Vector Dimension Mismatches","id":"vector-dimension-mismatches"},{"level":4,"text":"Vector Normalization Problems","id":"vector-normalization-problems"},{"level":4,"text":"Index Corruption and Recovery","id":"index-corruption-and-recovery"},{"level":3,"text":"Search Relevance Problems","id":"search-relevance-problems"},{"level":4,"text":"Poor Result Quality","id":"poor-result-quality"},{"level":4,"text":"Ranking Issues and Score Calibration","id":"ranking-issues-and-score-calibration"},{"level":3,"text":"Performance and Latency Issues","id":"performance-and-latency-issues"},{"level":4,"text":"Slow Search Responses","id":"slow-search-responses"},{"level":4,"text":"Memory Usage Problems","id":"memory-usage-problems"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Debugging Infrastructure Code","id":"debugging-infrastructure-code"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":2,"text":"Future Extensions","id":"future-extensions"},{"level":3,"text":"Advanced Search Features","id":"advanced-search-features"},{"level":4,"text":"Multi-Modal Embeddings","id":"multi-modal-embeddings"},{"level":4,"text":"Semantic Filtering","id":"semantic-filtering"},{"level":4,"text":"Conversational Search","id":"conversational-search"},{"level":3,"text":"Scaling and Distribution","id":"scaling-and-distribution"},{"level":4,"text":"Distributed Indexing","id":"distributed-indexing"},{"level":4,"text":"Search Federation","id":"search-federation"},{"level":4,"text":"Real-Time Updates","id":"real-time-updates"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure Extension","id":"recommended-file-structure-extension"},{"level":4,"text":"Multi-Modal Infrastructure Starter Code","id":"multi-modal-infrastructure-starter-code"},{"level":4,"text":"Core Multi-Modal Encoder Skeleton","id":"core-multi-modal-encoder-skeleton"},{"level":4,"text":"Distributed System Infrastructure","id":"distributed-system-infrastructure"},{"level":4,"text":"Real-Time Update System Skeleton","id":"real-time-update-system-skeleton"},{"level":4,"text":"Milestone Checkpoints for Future Extensions","id":"milestone-checkpoints-for-future-extensions"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Core Search Concepts","id":"core-search-concepts"},{"level":3,"text":"Vector Embeddings and Similarity","id":"vector-embeddings-and-similarity"},{"level":3,"text":"Approximate Nearest Neighbor Search","id":"approximate-nearest-neighbor-search"},{"level":3,"text":"Query Understanding and Processing","id":"query-understanding-and-processing"},{"level":3,"text":"Ranking and Relevance","id":"ranking-and-relevance"},{"level":3,"text":"Search API and User Experience","id":"search-api-and-user-experience"},{"level":3,"text":"System Reliability and Error Handling","id":"system-reliability-and-error-handling"},{"level":3,"text":"Performance and Evaluation Metrics","id":"performance-and-evaluation-metrics"},{"level":3,"text":"Caching and Performance Optimization","id":"caching-and-performance-optimization"},{"level":3,"text":"Advanced Search Features","id":"advanced-search-features"},{"level":3,"text":"Distributed Systems and Scaling","id":"distributed-systems-and-scaling"},{"level":3,"text":"Data Structures and Implementation Details","id":"data-structures-and-implementation-details"},{"level":3,"text":"Machine Learning and Model Management","id":"machine-learning-and-model-management"},{"level":3,"text":"Quality Assurance and Testing","id":"quality-assurance-and-testing"},{"level":3,"text":"Constants and Configuration","id":"constants-and-configuration"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"}],"title":"Semantic Search Engine: Design Document","markdown":"# Semantic Search Engine: Design Document\n\n\n## Overview\n\nA semantic search engine that understands meaning rather than just matching keywords, using neural embeddings to find conceptually similar documents. The key architectural challenge is efficiently indexing and searching high-dimensional vector spaces while combining multiple ranking signals for optimal relevance.\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing why semantic search is necessary and how it improves upon traditional approaches.\n\n### From Keywords to Meaning: Mental Model\n\nThink of traditional keyword search like a **librarian who can only match exact words**. When you ask for \"books about canines,\" this librarian can only find books with the exact word \"canines\" in their title or description. They completely miss excellent books about \"dogs,\" \"puppies,\" \"wolves,\" or \"German Shepherds\" — even though these are exactly what you're looking for. The librarian understands the letters and words perfectly, but has no concept that \"canine\" and \"dog\" refer to the same thing.\n\nIn contrast, semantic search works like a **knowledgeable librarian who understands concepts and meaning**. When you ask about \"canines,\" they immediately know you're interested in the broader concept of dog-family animals. They can recommend books about \"loyal companions,\" \"man's best friend,\" or even \"veterinary care for pets\" — because they understand the semantic relationships between concepts, not just the surface-level words.\n\nThis fundamental difference transforms how information retrieval works. Traditional **lexical search** operates in the space of exact character sequences — it's fast and precise for literal matches, but brittle when users express the same concept using different vocabulary. **Semantic search** operates in the space of meaning representations — it can bridge vocabulary gaps, understand synonyms, and even grasp conceptual relationships that don't share any common words.\n\nThe core challenge that semantic search solves is the **vocabulary mismatch problem**. Users naturally express their information needs using their own vocabulary, which often differs from how document authors chose to phrase the same concepts. A user searching for \"heart attack symptoms\" should find documents about \"myocardial infarction signs\" or \"cardiac event indicators.\" Traditional keyword search fails here because there are zero overlapping terms, despite the documents being highly relevant.\n\nModern semantic search engines solve this by learning **dense vector representations** (embeddings) that capture the meaning of text in high-dimensional space. Words, phrases, and documents that are conceptually similar end up close together in this vector space, even if they share no common vocabulary. The search engine can then find relevant documents by measuring distances in this semantic space rather than counting keyword overlaps.\n\n> The key insight is that semantic similarity in vector space often correlates much better with human judgments of relevance than lexical similarity based on word matching. This is why semantic search can feel almost magical — it finds what you meant, not just what you said.\n\nHowever, this conceptual power comes with significant engineering challenges. Vector representations are typically 300-1000 dimensions, making exact similarity search computationally expensive. Indexing millions of high-dimensional vectors requires sophisticated approximate algorithms like **Hierarchical Navigable Small World (HNSW)** or **Inverted File (IVF)** structures. Query processing becomes more complex because we need to balance semantic understanding with other relevance signals like freshness, popularity, and personalization.\n\nThe mental model for building a semantic search engine is like constructing a **multidimensional library** where books are organized not just by subject categories, but by their position in a vast space of meaning. Finding relevant books requires navigating this high-dimensional space efficiently while combining multiple signals to determine which books best match the user's intent.\n\n### Existing Search Technologies\n\nUnderstanding how semantic search fits into the broader landscape of information retrieval requires examining three primary approaches: lexical search, vector search, and hybrid systems. Each has distinct strengths and limitations that influence when and how they should be deployed.\n\n**Lexical Search Technologies**\n\nTraditional lexical search, exemplified by systems like **Elasticsearch** and **Apache Solr**, operates on the principle of term frequency analysis. These systems build **inverted indexes** that map each unique term to the list of documents containing it. Search queries are processed by finding documents that contain query terms, typically ranked using algorithms like **BM25 (Best Matching 25)**.\n\n| Component | Description | Strengths | Limitations |\n|-----------|-------------|-----------|-------------|\n| Inverted Index | Maps terms → document lists with frequency statistics | Fast exact matches, low storage overhead, well-understood scaling | No semantic understanding, vocabulary mismatch, requires exact or stem matches |\n| BM25 Ranking | Scores documents based on term frequency, document length, collection statistics | Excellent for precise queries, handles document length normalization, proven effectiveness | Cannot bridge vocabulary gaps, over-emphasizes rare terms, ignores concept relationships |\n| Query Processing | Term extraction, stemming, boolean operators, phrase matching | Predictable behavior, supports complex boolean logic, fast execution | Users must know exact terminology, no query intent understanding, brittle to paraphrasing |\n| Index Updates | Real-time document addition/removal with incremental index updates | Low-latency updates, consistent availability, simple rollback procedures | Full-text reindexing expensive, schema changes require rebuild, limited semantic enrichment |\n\nThe fundamental strength of lexical search is **predictable precision** — when users know the exact terminology used in documents, lexical search provides fast, accurate results. It excels in domains with standardized vocabulary, such as legal document search, product catalogs with controlled taxonomies, or technical documentation where precise terminology matters.\n\nHowever, lexical search fails catastrophically in scenarios with high vocabulary diversity. Customer support queries like \"my internet is slow\" won't match knowledge base articles titled \"troubleshooting bandwidth limitations\" or \"resolving connectivity performance issues,\" despite being directly relevant. This brittleness drives the need for semantic approaches.\n\n**Vector Search Technologies**\n\nPure vector search systems, such as **Pinecone**, **Weaviate**, or **FAISS-based** solutions, represent documents and queries as high-dimensional embeddings in continuous vector space. Similarity is measured using metrics like cosine similarity or Euclidean distance, with search performed using approximate nearest neighbor (ANN) algorithms.\n\n| Component | Description | Strengths | Limitations |\n|-----------|-------------|-----------|-------------|\n| Dense Embeddings | Documents/queries encoded as 384-1024 dimensional vectors | Captures semantic relationships, bridges vocabulary gaps, language-agnostic similarity | Opaque representations, computationally expensive, requires ML model inference |\n| ANN Indexing | HNSW, IVF, or LSH structures for efficient similarity search | Handles high-dimensional data, sub-linear search complexity, memory-efficient options | Approximate results only, complex parameter tuning, index construction overhead |\n| Embedding Models | Transformer-based encoders (BERT, Sentence-BERT, etc.) | Strong semantic understanding, transfer learning from large corpora, multilingual support | Model size and inference cost, domain adaptation challenges, potential bias |\n| Similarity Metrics | Cosine similarity, dot product, Euclidean distance calculations | Mathematically principled, differentiable for ML optimization, interpretable geometry | Distance doesn't directly correlate with relevance, sensitive to vector normalization, curse of dimensionality |\n\nVector search excels at **conceptual matching** and **cross-lingual retrieval**. It can successfully match \"heart attack symptoms\" with \"myocardial infarction signs\" because both phrases produce similar embedding vectors. It also handles paraphrasing naturally — multiple ways of expressing the same concept cluster together in vector space.\n\nThe primary limitation is **lack of exact match precision**. Vector search might miss documents containing the exact query terms if the overall semantic context differs. A query for \"Python programming\" might return results about \"machine learning\" or \"data science\" — conceptually related but potentially not what the user intended if they specifically need Python language documentation.\n\n**Hybrid Search Approaches**\n\nModern production search systems increasingly adopt **hybrid architectures** that combine lexical and semantic approaches to capture the benefits of both. These systems typically implement multi-stage retrieval pipelines that leverage different search modalities at different phases.\n\n> **Decision: Hybrid Architecture for Production Systems**\n> - **Context**: Pure lexical search misses semantic matches; pure vector search loses exact match precision; users expect both conceptual understanding and precise matching\n> - **Options Considered**: Lexical-only, vector-only, parallel hybrid (merge results), sequential hybrid (multi-stage pipeline)\n> - **Decision**: Sequential hybrid with lexical + vector retrieval followed by cross-encoder reranking\n> - **Rationale**: Sequential approach allows optimization at each stage; avoids expensive operations on full corpus; combines complementary strengths while mitigating individual weaknesses\n> - **Consequences**: Increased system complexity and latency, but significantly improved relevance across diverse query types\n\nThe most effective hybrid approaches implement **multi-stage pipelines**:\n\n1. **Fast Retrieval Stage**: Both BM25 lexical search and ANN vector search retrieve candidate documents (typically 100-1000 results each)\n2. **Result Fusion**: Combine and deduplicate candidates using techniques like Reciprocal Rank Fusion (RRF) or weighted score combination\n3. **Precision Reranking**: Apply computationally expensive but highly accurate cross-encoder models to rerank the top candidates\n4. **Signal Integration**: Incorporate additional relevance signals like freshness, popularity, personalization, and click-through data\n\n| Fusion Strategy | Mechanism | Advantages | Trade-offs |\n|-----------------|-----------|------------|------------|\n| Score Interpolation | `final_score = α × bm25_score + β × vector_score` | Simple implementation, tunable weights, interpretable scores | Requires score calibration, weights are dataset-dependent, linear combination limits expressiveness |\n| Reciprocal Rank Fusion | `rrf_score = Σ(1/(k + rank_i))` for each result list | Rank-based (avoids score calibration), proven effectiveness, robust to score distribution differences | Loses absolute score information, requires tuning k parameter, equal weighting of systems |\n| Cross-Encoder Reranking | Train transformer model on query-document pairs | Highest accuracy, can model complex relevance patterns, joint query-document understanding | Expensive inference cost, requires training data, limited to small candidate sets |\n| Learning to Rank | ML model trained on multiple features | Can optimize end-to-end relevance, incorporates diverse signals, data-driven weight selection | Requires substantial training data, complex feature engineering, model drift over time |\n\n**Comparison of Search Technology Approaches**\n\n| Approach | Query Understanding | Vocabulary Flexibility | Exact Match Precision | Computational Cost | Implementation Complexity |\n|----------|-------------------|---------------------|-------------------|-------------------|----------------------|\n| Lexical Only | Poor (keyword matching) | Low (requires exact/stem matches) | Excellent | Low | Low |\n| Vector Only | Excellent (semantic similarity) | High (concept-based matching) | Poor (approximate only) | High | Medium |\n| Hybrid Sequential | Very Good (combines both) | High (semantic + lexical coverage) | Good (lexical stage provides precision) | Medium (optimized pipeline) | High |\n| Hybrid Parallel | Good (separate then merge) | High (dual coverage) | Good (lexical results included) | High (dual computation) | Medium |\n\nThe emerging consensus in the industry is that **hybrid approaches are essential for production semantic search systems**. Companies like Google, Microsoft, and Amazon all use sophisticated multi-stage pipelines that combine lexical matching, vector similarity, machine learning reranking, and numerous other relevance signals.\n\nHowever, this complexity must be managed carefully. The key architectural challenge is building a system that can efficiently execute this multi-stage pipeline while maintaining sub-second response times and supporting incremental updates as new documents are added to the corpus.\n\n> The fundamental trade-off in semantic search system design is between relevance quality and system complexity. Pure approaches are simpler to build and debug, but hybrid systems provide significantly better user experiences across diverse query types and domains.\n\nThis context establishes why we're building a semantic search engine with hybrid capabilities, and sets up the architectural decisions we'll explore in subsequent sections. The goal is to capture the semantic understanding benefits of vector search while maintaining the precision and performance characteristics that users expect from modern search systems.\n\n### Implementation Guidance\n\n**A. Technology Recommendations Table:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Embedding Model | `sentence-transformers` with `all-MiniLM-L6-v2` (384 dim, fast) | `sentence-transformers` with `all-mpnet-base-v2` (768 dim, higher quality) |\n| Vector Index | `faiss.IndexFlatIP` (exact search, good for <100K docs) | `faiss.IndexHNSWFlat` (approximate, scales to millions) |\n| Text Processing | `nltk` for basic tokenization and stemming | `spacy` with full NLP pipeline for advanced processing |\n| Lexical Search | In-memory inverted index with Python dict | `elasticsearch` or `whoosh` for production-scale lexical search |\n| Web Framework | `flask` with simple JSON endpoints | `fastapi` with async support and automatic OpenAPI docs |\n| Vector Storage | `numpy` arrays with `pickle` serialization | `numpy` with `memmap` for memory-efficient large datasets |\n\n**B. Recommended File/Module Structure**\n\n```\nsemantic-search/\n├── requirements.txt                    ← Python dependencies\n├── config/\n│   ├── __init__.py\n│   └── settings.py                     ← Configuration management\n├── src/\n│   ├── __init__.py\n│   ├── models/                         ← Data structures and schemas\n│   │   ├── __init__.py\n│   │   ├── document.py                 ← Document and embedding models\n│   │   ├── query.py                    ← Query and result models\n│   │   └── index.py                    ← Index metadata structures\n│   ├── embeddings/                     ← Embedding pipeline (Milestone 1)\n│   │   ├── __init__.py\n│   │   ├── encoder.py                  ← Text-to-vector encoding\n│   │   ├── indexer.py                  ← Vector index management\n│   │   └── persistence.py              ← Save/load index state\n│   ├── query/                          ← Query processing (Milestone 2)\n│   │   ├── __init__.py\n│   │   ├── processor.py                ← Query understanding and expansion\n│   │   ├── searcher.py                 ← Similarity search execution\n│   │   └── cache.py                    ← Query embedding cache\n│   ├── ranking/                        ← Ranking and relevance (Milestone 3)\n│   │   ├── __init__.py\n│   │   ├── scorer.py                   ← Multi-signal scoring\n│   │   ├── reranker.py                 ← Cross-encoder reranking\n│   │   └── fusion.py                   ← Result fusion strategies\n│   ├── api/                           ← Search API (Milestone 4)\n│   │   ├── __init__.py\n│   │   ├── endpoints.py               ← REST API routes\n│   │   ├── formatting.py              ← Result formatting and highlighting\n│   │   └── analytics.py               ← Search analytics and logging\n│   └── utils/                         ← Shared utilities\n│       ├── __init__.py\n│       ├── text_processing.py         ← Text cleaning and preprocessing\n│       └── metrics.py                 ← Distance calculations and evaluation\n├── tests/                             ← Test suites for each component\n│   ├── test_embeddings/\n│   ├── test_query/\n│   ├── test_ranking/\n│   └── test_api/\n├── data/                              ← Sample datasets and trained models\n│   ├── documents/                     ← Document corpus for indexing\n│   ├── models/                        ← Downloaded embedding models\n│   └── indices/                       ← Serialized vector indices\n└── scripts/                           ← Utility scripts\n    ├── build_index.py                 ← Offline index construction\n    ├── evaluate_search.py             ← Search quality evaluation\n    └── benchmark_performance.py       ← Performance testing\n```\n\n**C. Infrastructure Starter Code (Complete, Ready to Use)**\n\n**File: `src/models/document.py`**\n```python\n\"\"\"\nDocument and embedding data models.\n\"\"\"\nfrom dataclasses import dataclass\nfrom typing import Optional, Dict, Any, List\nimport numpy as np\n\n@dataclass\nclass Document:\n    \"\"\"Represents a searchable document with metadata.\"\"\"\n    doc_id: str\n    title: str\n    content: str\n    url: Optional[str] = None\n    metadata: Optional[Dict[str, Any]] = None\n    created_at: Optional[str] = None\n    \n    def get_searchable_text(self) -> str:\n        \"\"\"Combine title and content for embedding generation.\"\"\"\n        return f\"{self.title}\\n{self.content}\"\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert document to dictionary for JSON serialization.\"\"\"\n        return {\n            'doc_id': self.doc_id,\n            'title': self.title,\n            'content': self.content,\n            'url': self.url,\n            'metadata': self.metadata or {},\n            'created_at': self.created_at\n        }\n\n@dataclass \nclass DocumentEmbedding:\n    \"\"\"Pairs a document with its vector embedding.\"\"\"\n    document: Document\n    embedding: np.ndarray\n    model_name: str\n    embedding_dim: int\n    \n    def __post_init__(self):\n        \"\"\"Validate embedding dimensions match expected size.\"\"\"\n        if self.embedding.shape[0] != self.embedding_dim:\n            raise ValueError(f\"Embedding dimension mismatch: expected {self.embedding_dim}, got {self.embedding.shape[0]}\")\n```\n\n**File: `src/utils/text_processing.py`**\n```python\n\"\"\"\nText preprocessing utilities for consistent document processing.\n\"\"\"\nimport re\nfrom typing import List\nimport unicodedata\n\nclass TextProcessor:\n    \"\"\"Handles text cleaning and normalization for search.\"\"\"\n    \n    def __init__(self):\n        # Common patterns for cleaning\n        self.url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n        self.email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n        self.whitespace_pattern = re.compile(r'\\s+')\n    \n    def clean_text(self, text: str) -> str:\n        \"\"\"\n        Clean and normalize text for embedding generation.\n        Removes URLs, excess whitespace, normalizes unicode.\n        \"\"\"\n        # Normalize unicode characters\n        text = unicodedata.normalize('NFKD', text)\n        \n        # Remove URLs and email addresses (often not semantically useful)\n        text = self.url_pattern.sub(' ', text)\n        text = self.email_pattern.sub(' ', text)\n        \n        # Normalize whitespace\n        text = self.whitespace_pattern.sub(' ', text)\n        \n        # Strip and return\n        return text.strip()\n    \n    def extract_keywords(self, text: str) -> List[str]:\n        \"\"\"\n        Simple keyword extraction for lexical search.\n        Splits on whitespace and removes short terms.\n        \"\"\"\n        # Clean text first\n        cleaned = self.clean_text(text.lower())\n        \n        # Split into terms and filter\n        terms = [term.strip('.,!?;:\"()[]{}') for term in cleaned.split()]\n        keywords = [term for term in terms if len(term) >= 3 and term.isalpha()]\n        \n        return keywords\n```\n\n**File: `src/utils/metrics.py`**\n```python\n\"\"\"\nDistance and similarity calculations for vector search.\n\"\"\"\nimport numpy as np\nfrom typing import Union\n\ndef cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n    \"\"\"\n    Compute cosine similarity between two vectors.\n    Returns value between -1 and 1, where 1 = identical direction.\n    \"\"\"\n    # Ensure vectors are 1-dimensional\n    vec1 = vec1.flatten()\n    vec2 = vec2.flatten()\n    \n    # Compute dot product and magnitudes\n    dot_product = np.dot(vec1, vec2)\n    magnitude1 = np.linalg.norm(vec1)\n    magnitude2 = np.linalg.norm(vec2)\n    \n    # Handle zero vectors\n    if magnitude1 == 0 or magnitude2 == 0:\n        return 0.0\n    \n    return dot_product / (magnitude1 * magnitude2)\n\ndef normalize_vector(vec: np.ndarray) -> np.ndarray:\n    \"\"\"\n    L2 normalize vector to unit length for cosine similarity.\n    Critical for efficient similarity search in FAISS.\n    \"\"\"\n    vec_flat = vec.flatten()\n    norm = np.linalg.norm(vec_flat)\n    \n    if norm == 0:\n        return vec_flat\n    \n    return vec_flat / norm\n\ndef euclidean_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:\n    \"\"\"Compute Euclidean distance between two vectors.\"\"\"\n    return float(np.linalg.norm(vec1.flatten() - vec2.flatten()))\n```\n\n**D. Core Logic Skeleton Code**\n\n**File: `src/embeddings/encoder.py`**\n```python\n\"\"\"\nDocument embedding generation using sentence transformers.\n\"\"\"\nfrom sentence_transformers import SentenceTransformer\nfrom typing import List, Union\nimport numpy as np\nfrom ..models.document import Document, DocumentEmbedding\nfrom ..utils.text_processing import TextProcessor\n\nclass DocumentEncoder:\n    \"\"\"Generates semantic embeddings for documents and queries.\"\"\"\n    \n    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n        # TODO 1: Initialize the sentence transformer model\n        # TODO 2: Store model name and embedding dimension \n        # TODO 3: Initialize text processor for cleaning\n        # Hint: Use SentenceTransformer(model_name) and model.get_sentence_embedding_dimension()\n        pass\n    \n    def encode_document(self, document: Document) -> DocumentEmbedding:\n        \"\"\"\n        Convert document to vector embedding.\n        Combines title and content, cleans text, generates embedding.\n        \"\"\"\n        # TODO 1: Extract searchable text from document (title + content)\n        # TODO 2: Clean the text using text processor\n        # TODO 3: Generate embedding using sentence transformer\n        # TODO 4: Normalize the embedding vector for cosine similarity\n        # TODO 5: Create and return DocumentEmbedding object\n        # Hint: Use document.get_searchable_text() and normalize_vector()\n        pass\n    \n    def encode_texts(self, texts: List[str]) -> np.ndarray:\n        \"\"\"\n        Batch encode multiple texts for efficiency.\n        Returns 2D array where each row is an embedding.\n        \"\"\"\n        # TODO 1: Clean all input texts\n        # TODO 2: Use model.encode() with show_progress_bar=True for batch processing\n        # TODO 3: Normalize all embeddings for consistent similarity calculation\n        # TODO 4: Return as numpy array with shape (n_texts, embedding_dim)\n        pass\n    \n    def encode_query(self, query_text: str) -> np.ndarray:\n        \"\"\"Encode search query to embedding vector.\"\"\"\n        # TODO 1: Clean query text\n        # TODO 2: Generate embedding (single text, not batch)\n        # TODO 3: Normalize embedding vector\n        # TODO 4: Return as 1D numpy array\n        pass\n```\n\n**E. Language-Specific Hints**\n\n**Python-Specific Implementation Tips:**\n\n- Use `sentence-transformers` library for embeddings: `pip install sentence-transformers`\n- FAISS installation: `pip install faiss-cpu` (or `faiss-gpu` if you have CUDA)\n- For large datasets, use `numpy.memmap` to handle arrays larger than RAM\n- Use `@functools.lru_cache` decorator for caching expensive operations like model loading\n- Handle memory efficiently: `del large_arrays` and `gc.collect()` after processing batches\n- Use `logging` module instead of print statements for production code\n- Type hints are crucial for maintainability: `from typing import List, Dict, Optional, Union`\n\n**Performance Optimization:**\n- Batch embedding generation: `model.encode(texts, batch_size=32)` is much faster than individual calls\n- Use `numpy.float32` instead of `float64` for embeddings to halve memory usage\n- Pre-allocate numpy arrays when possible: `np.zeros((n_docs, embedding_dim), dtype=np.float32)`\n- Consider using `multiprocessing.Pool` for CPU-intensive text preprocessing\n\n**Common Python Gotchas:**\n- FAISS expects `np.float32` arrays, not `float64` (default numpy type)\n- Sentence transformers return tensors by default — convert with `.numpy()` if needed\n- When loading large models, they're cached in `~/.cache/huggingface/` by default\n- Dictionary iteration order is guaranteed in Python 3.7+ but be explicit with `collections.OrderedDict` if order matters\n\n**F. Milestone Checkpoint**\n\nAfter implementing the foundational components, verify your understanding:\n\n**What to Test:**\n```bash\n# Install dependencies\npip install sentence-transformers faiss-cpu nltk numpy\n\n# Test document encoding\npython -c \"\nfrom src.models.document import Document\nfrom src.embeddings.encoder import DocumentEncoder\n\ndoc = Document('1', 'Test Title', 'This is test content about machine learning.')\nencoder = DocumentEncoder()\nembedding = encoder.encode_document(doc)\nprint(f'Document encoded to {embedding.embedding.shape} vector')\nprint(f'Embedding dimension: {embedding.embedding_dim}')\n\"\n```\n\n**Expected Output:**\n- Document successfully encoded to shape `(384,)` for MiniLM model\n- Embedding dimension matches model specification (384 for MiniLM-L6-v2)\n- No errors during text processing or embedding generation\n\n**What Behavior to Verify:**\n1. Load a sentence transformer model without errors\n2. Process document text (title + content combination)\n3. Generate consistent embedding vectors for same input\n4. Handle edge cases like empty content or very long documents\n5. Text cleaning removes URLs and normalizes whitespace\n\n**Signs Something is Wrong:**\n- `RuntimeError: CUDA out of memory` → Use CPU model or reduce batch size\n- `ValueError: embedding dimension mismatch` → Check model loading and vector normalization\n- Very slow encoding (>1 second per document) → Verify you're not loading model repeatedly\n- Embeddings are all zeros → Check text preprocessing isn't removing all content\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing what the semantic search engine must accomplish and what we deliberately exclude to maintain focus.\n\nBefore diving into specific technical requirements, let's establish a clear mental model for what we're building. **Think of our semantic search engine as an intelligent research assistant** rather than a simple filing cabinet. Traditional keyword search is like asking someone to find all documents containing the exact words \"car\" and \"maintenance\" — they'll dutifully return every document with those precise terms but miss documents about \"automobile servicing\" or \"vehicle upkeep.\" Our semantic search engine, by contrast, understands that these concepts are related and can find relevant documents even when they use different vocabulary. This understanding comes from **vector embeddings** that capture semantic meaning in high-dimensional space, allowing us to find documents by conceptual similarity rather than just word matching.\n\nHowever, building such a system requires careful scoping. The space of possible search features is vast — from real-time collaborative filtering to multi-modal image search to conversational query interfaces. Without clear boundaries, we risk building a system that does many things poorly rather than core semantic search exceptionally well. This section establishes both what we commit to building and what we deliberately exclude to maintain focus and achievability.\n\n### Core Functional Requirements\n\nThe heart of our semantic search engine lies in its ability to understand meaning rather than just match keywords. This semantic understanding manifests through several essential capabilities that work together to provide a fundamentally superior search experience.\n\n**Semantic Query Understanding** forms the foundation of our system. When a user searches for \"python web framework performance,\" our engine must understand that this query relates to concepts like Django, Flask, FastAPI, benchmarking, scalability, and response times — even if those exact terms don't appear in the query. This understanding comes through **query expansion** that enriches the original query with related terms while preserving the user's intent. Unlike simple synonym expansion that might add \"snake\" as a synonym for \"python,\" our semantic expansion understands context and adds relevant programming-related terms.\n\n| Requirement | Description | Success Criteria |\n|-------------|-------------|------------------|\n| Semantic Query Processing | Convert natural language queries to meaningful vector representations | Query \"fast web server\" matches documents about \"high-performance HTTP services\" |\n| Concept-Based Matching | Find documents by conceptual similarity, not just keyword overlap | Query about \"machine learning\" finds documents mentioning \"neural networks\" and \"AI\" |\n| Multi-Intent Query Support | Handle queries with multiple semantic aspects | \"Python web scraping tutorial\" finds docs covering both Python AND web scraping AND tutorials |\n| Negation Handling | Support excluding concepts from search results | \"machine learning -deep learning\" excludes deep learning content |\n| Query Context Preservation | Maintain original user intent throughout processing | Expansion doesn't dilute or shift the core meaning of user queries |\n\n**Vector Similarity Search** represents our core technical capability — the ability to find documents that are conceptually similar to a query, even when they share few common words. This addresses the fundamental **vocabulary mismatch problem** where users and document authors use different terms for the same concepts. Our system must convert both queries and documents into **vector embeddings** in the same semantic space, then use **cosine similarity** or other distance metrics to identify the most relevant matches.\n\nThe embedding process itself must be robust and consistent. We'll use transformer-based models like `all-MiniLM-L6-v2` that have been trained on large text corpora to understand semantic relationships. The resulting embeddings live in a high-dimensional space (typically 384 or 768 dimensions) where semantically similar concepts cluster together. The challenge lies in efficiently searching this high-dimensional space — with millions of documents, a naive linear search would be far too slow for production use.\n\n> **Critical Design Insight**: The quality of our embeddings directly determines search quality. A poor embedding model will create a semantic space where conceptually similar documents are far apart, making even perfect similarity search useless. This is why we invest heavily in embedding quality and consistency rather than just search speed.\n\n**Efficient Approximate Nearest Neighbor Search** enables us to find the most similar documents without examining every vector in our index. We'll implement this using algorithms like **HNSW** (Hierarchical Navigable Small World) or **IVF** (Inverted File) that can search millions of vectors in sub-second time. The \"approximate\" nature means we might occasionally miss the true nearest neighbor, but the trade-off between speed and perfect recall is essential for real-time search.\n\n**Hybrid Search Capabilities** combine the strengths of both lexical and semantic search. While semantic search excels at handling vocabulary mismatch and conceptual queries, traditional **lexical search** using **BM25** scoring still performs better for exact term matching, proper nouns, and technical terminology. Our system must intelligently blend these approaches, using semantic similarity to cast a wide net for relevant documents, then applying lexical signals to boost documents with exact term matches.\n\n| Search Type | Strengths | Example Query | When Most Effective |\n|-------------|-----------|---------------|---------------------|\n| Semantic | Handles vocabulary mismatch, conceptual queries | \"improve code quality\" | Broad, conceptual searches |\n| Lexical | Exact term matching, proper nouns, technical terms | \"FastAPI dependency injection\" | Specific technical queries |\n| Hybrid | Combines both approaches for comprehensive results | \"REST API best practices\" | Most production queries |\n\n**Sub-Second Response Times** represent a non-negotiable performance requirement. Search latency directly impacts user experience — studies show that users abandon searches when response times exceed 1-2 seconds. Our architecture must support response times under 500 milliseconds for typical queries, including the time for query processing, vector search, result ranking, and response formatting.\n\nThis latency requirement drives several architectural decisions. We need **query embedding caching** for frequent searches, **approximate algorithms** rather than exact search, **multi-stage ranking** that applies expensive operations only to top candidates, and **efficient data structures** that minimize memory access patterns. The `encode_query()` function must complete embedding generation in under 100 milliseconds, while our vector index must support similarity search across millions of documents in under 200 milliseconds.\n\n### Performance and Scale Requirements\n\nOur semantic search engine must handle production workloads with predictable performance characteristics. These requirements shape our architectural decisions and technology choices throughout the system.\n\n**Query Throughput and Concurrency** define our system's ability to serve multiple users simultaneously. We target supporting at least **1,000 concurrent users** with **500 queries per second** sustained throughput. This requires careful attention to resource management — embedding models are computationally expensive, vector indices consume significant memory, and ranking operations can create CPU bottlenecks.\n\n| Metric | Target | Measurement Method | Impact of Missing Target |\n|---------|--------|--------------------|-------------------------|\n| Concurrent Users | 1,000+ | Load testing with realistic query patterns | Users experience timeouts and failed requests |\n| Query Throughput | 500 QPS sustained | Monitor queries/second under load | Service becomes unavailable during peak usage |\n| Response Latency | <500ms p95, <200ms p50 | Histogram of end-to-end response times | Users abandon searches, poor user experience |\n| Memory Usage | <8GB per index | Monitor RSS memory consumption | Out of memory crashes, expensive hosting |\n| CPU Utilization | <80% sustained | Monitor CPU during peak load | Resource starvation, increased latency |\n\n**Index Size and Document Capacity** determine how much content our system can handle. We target indexing **10 million documents** with the ability to scale to 100 million through partitioning strategies. Each document embedding requires `EMBEDDING_DIM * 4` bytes (assuming 32-bit floats), so 10 million documents with 384-dimensional embeddings consume approximately 15GB of raw vector data. Our indexing structures add overhead, so we plan for 25-30GB total memory for the vector index.\n\nThe document ingestion pipeline must handle **10,000 documents per hour** for batch updates and **100 documents per minute** for real-time updates. This throughput requirement influences our choice of embedding models — while larger models might provide better semantic understanding, they may be too slow for our ingestion rate requirements.\n\n**Memory and Storage Constraints** reflect realistic deployment environments. Our system must operate effectively within **16GB RAM** for the complete search service, including the vector index, embedding models, query cache, and application overhead. This constraint drives our selection of compact embedding models like `all-MiniLM-L6-v2` (384 dimensions) rather than larger alternatives that might require 1GB+ just for model weights.\n\nFor persistent storage, we target **100GB maximum** for the complete system, including the vector index, document metadata, and operational data. This requires efficient index serialization formats and careful management of auxiliary data structures.\n\n> **Scalability Philosophy**: We design for vertical scaling first (larger machines) before horizontal scaling (more machines). This simplifies our initial implementation while still supporting production workloads. Horizontal scaling becomes an optimization once the core system proves effective.\n\n**Cache Hit Rates and Memory Efficiency** directly impact both performance and cost. Our query embedding cache should achieve **80% hit rate** for repeated queries, dramatically reducing the computational cost of re-encoding common searches. The cache must be **size-bounded** to prevent memory exhaustion and use **LRU eviction** to maintain relevance.\n\nDocument-level caching for frequently accessed results should achieve **60% hit rate**, reducing the need to reconstruct result snippets and metadata. However, we must balance cache benefits against memory consumption — a cache that uses too much memory can degrade index performance by forcing virtual memory paging.\n\n### What We Won't Build\n\nDefining what we exclude is as important as defining what we include. These deliberate limitations keep our project focused on core semantic search capabilities rather than attempting to build a complete enterprise search platform.\n\n**Advanced Multi-Modal Search** capabilities like image similarity, video content analysis, or audio search are explicitly out of scope. While semantic search principles extend to other modalities, each requires specialized embedding models, preprocessing pipelines, and similarity metrics. Adding multi-modal support would triple our complexity without strengthening our core text search competency.\n\n| Excluded Feature | Rationale for Exclusion | Complexity Impact |\n|------------------|------------------------|-------------------|\n| Image Search | Requires computer vision models, image preprocessing | 3x increase in model complexity |\n| Video Content Analysis | Needs video frame extraction, temporal modeling | 5x increase in processing pipeline |\n| Audio/Speech Search | Requires speech-to-text, audio feature extraction | 4x increase in preprocessing complexity |\n| PDF/Document Parsing | Complex format handling, OCR for scanned content | 2x increase in ingestion pipeline |\n\n**Real-Time Collaborative Features** such as shared search sessions, real-time query suggestions from other users, or collaborative result curation would require complex state synchronization and user management systems. These features, while valuable, represent a different product category focused on collaboration rather than search quality.\n\n**Advanced Personalization and User Modeling** beyond basic preference signals are excluded. Building comprehensive user profiles, learning individual query patterns, or providing personalized result ranking would require extensive user data collection, privacy controls, and machine learning pipelines. Our system will support basic personalization hooks but won't implement sophisticated user modeling.\n\n**Enterprise Security and Access Control** features like role-based permissions, document-level security, audit logging, and integration with identity providers are outside our scope. These are essential for enterprise deployment but represent operational concerns rather than search technology advancement.\n\n> **Focus Principle**: We're building a semantic search engine, not a complete search platform. Each excluded feature represents a separate product area that could absorb months of development effort without improving our core semantic understanding capabilities.\n\n**Distributed Search Federation** across multiple data sources or external search engines is excluded. While production systems often need to search across databases, file systems, cloud storage, and third-party APIs, implementing federation would require building connectors, handling different data formats, and managing distributed query coordination. Our system will excel at searching a unified document corpus rather than attempting to federate diverse sources.\n\n**Advanced Analytics and Search Intelligence** beyond basic query volume and zero-result tracking are out of scope. Features like query intent classification, search funnel analysis, content gap identification, or automated search quality scoring would require significant analytics infrastructure and data science expertise. We'll provide basic metrics for operational monitoring but won't build comprehensive search analytics.\n\n**Natural Language Query Interfaces** that attempt to understand complex conversational queries or provide natural language responses are excluded. While our semantic understanding enables better query interpretation, we won't implement chatbot-style interfaces or attempt to generate natural language explanations of search results. Our interface remains a traditional search box with structured results.\n\nThe key insight behind these exclusions is that **semantic search technology** represents a foundational capability that can power many different user experiences. By focusing intensively on the quality of semantic understanding, efficient vector search, and intelligent result ranking, we create a strong foundation that could later support any of these excluded features if desired.\n\n### Implementation Guidance\n\nThis section provides concrete technology recommendations and project structure guidance to bridge the gap between our requirements and actual implementation.\n\n**Technology Stack Recommendations:**\n\n| Component | Simple Option | Advanced Option | Rationale |\n|-----------|---------------|-----------------|-----------|\n| Embedding Model | sentence-transformers with `all-MiniLM-L6-v2` | Custom fine-tuned transformer | Pre-trained model provides good quality with minimal complexity |\n| Vector Index | FAISS FlatIP for small datasets | FAISS HNSW for production scale | HNSW provides best latency/recall trade-off at scale |\n| Web Framework | FastAPI with async support | Custom async HTTP server | FastAPI provides good performance with minimal boilerplate |\n| Database | SQLite for metadata, files for vectors | PostgreSQL with pgvector extension | File-based approach simpler for initial implementation |\n| Caching | Python dict with manual LRU | Redis for distributed caching | In-memory caching sufficient for single-node deployment |\n\n**Recommended Project Structure:**\n\nOur project organization reflects the clear separation between document processing, search infrastructure, and user-facing APIs:\n\n```\nsemantic-search/\n├── src/\n│   ├── embedding/\n│   │   ├── __init__.py\n│   │   ├── encoder.py           # DocumentEncoder class\n│   │   ├── processor.py         # TextProcessor for cleaning\n│   │   └── models.py           # Document and DocumentEmbedding classes\n│   ├── index/\n│   │   ├── __init__.py\n│   │   ├── vector_index.py     # FAISS index wrapper\n│   │   ├── builder.py          # Index construction pipeline\n│   │   └── updater.py          # Incremental updates\n│   ├── search/\n│   │   ├── __init__.py\n│   │   ├── query_processor.py  # Query expansion and encoding\n│   │   ├── retriever.py        # Vector similarity search\n│   │   └── ranker.py           # Multi-signal ranking\n│   ├── api/\n│   │   ├── __init__.py\n│   │   ├── server.py           # FastAPI application\n│   │   ├── models.py           # API request/response models\n│   │   └── handlers.py         # Search endpoint handlers\n│   └── utils/\n│       ├── __init__.py\n│       ├── config.py           # Configuration management\n│       └── metrics.py          # Performance monitoring\n├── tests/\n│   ├── test_embedding/\n│   ├── test_index/\n│   ├── test_search/\n│   └── test_api/\n├── data/\n│   ├── documents/              # Input document corpus\n│   ├── indexes/                # Serialized vector indexes\n│   └── cache/                  # Query embedding cache\n├── scripts/\n│   ├── build_index.py          # Offline index construction\n│   ├── evaluate_search.py      # Search quality evaluation\n│   └── load_test.py            # Performance testing\n├── requirements.txt\n├── README.md\n└── docker-compose.yml          # Development environment\n```\n\n**Core Infrastructure Setup:**\n\nThe following code provides complete, working infrastructure that supports our semantic search requirements without implementing the core learning algorithms:\n\n```python\n# src/utils/config.py - Complete configuration management\nimport os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass SearchConfig:\n    # Model configuration\n    model_name: str = \"all-MiniLM-L6-v2\"\n    embedding_dim: int = 384\n    max_sequence_length: int = 512\n    \n    # Index configuration  \n    index_type: str = \"hnsw\"  # or \"flat\" for small datasets\n    hnsw_m: int = 16  # HNSW connectivity parameter\n    hnsw_ef_construction: int = 200  # Build-time search depth\n    hnsw_ef_search: int = 100  # Query-time search depth\n    \n    # Search configuration\n    max_results: int = 100\n    min_score_threshold: float = 0.0\n    query_cache_size: int = 10000\n    \n    # Performance limits\n    max_concurrent_queries: int = 100\n    query_timeout_seconds: float = 30.0\n    embedding_batch_size: int = 32\n    \n    @classmethod\n    def from_env(cls) -> 'SearchConfig':\n        \"\"\"Load configuration from environment variables with defaults.\"\"\"\n        return cls(\n            model_name=os.getenv('MODEL_NAME', cls.model_name),\n            embedding_dim=int(os.getenv('EMBEDDING_DIM', cls.embedding_dim)),\n            max_sequence_length=int(os.getenv('MAX_SEQ_LEN', cls.max_sequence_length)),\n            index_type=os.getenv('INDEX_TYPE', cls.index_type),\n            hnsw_m=int(os.getenv('HNSW_M', cls.hnsw_m)),\n            max_results=int(os.getenv('MAX_RESULTS', cls.max_results)),\n            query_cache_size=int(os.getenv('CACHE_SIZE', cls.query_cache_size))\n        )\n\n# Global configuration instance\nCONFIG = SearchConfig.from_env()\n```\n\n```python\n# src/utils/metrics.py - Complete performance monitoring\nimport time\nimport logging\nfrom collections import defaultdict, deque\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List\nfrom contextlib import contextmanager\n\n@dataclass\nclass MetricsCollector:\n    query_latencies: deque = field(default_factory=lambda: deque(maxlen=1000))\n    query_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))\n    error_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))\n    cache_hits: int = 0\n    cache_misses: int = 0\n    \n    @contextmanager\n    def time_operation(self, operation_name: str):\n        \"\"\"Context manager to time operations and collect metrics.\"\"\"\n        start_time = time.time()\n        try:\n            yield\n            self.query_counts[operation_name] += 1\n        except Exception as e:\n            self.error_counts[f\"{operation_name}_error\"] += 1\n            logging.error(f\"Operation {operation_name} failed: {e}\")\n            raise\n        finally:\n            elapsed = time.time() - start_time\n            self.query_latencies.append(elapsed)\n    \n    def record_cache_hit(self):\n        self.cache_hits += 1\n    \n    def record_cache_miss(self):\n        self.cache_misses += 1\n    \n    def get_stats(self) -> Dict:\n        \"\"\"Return current performance statistics.\"\"\"\n        latencies = list(self.query_latencies)\n        return {\n            'total_queries': sum(self.query_counts.values()),\n            'avg_latency_ms': sum(latencies) / len(latencies) * 1000 if latencies else 0,\n            'p95_latency_ms': sorted(latencies)[int(0.95 * len(latencies))] * 1000 if latencies else 0,\n            'cache_hit_rate': self.cache_hits / (self.cache_hits + self.cache_misses) if (self.cache_hits + self.cache_misses) > 0 else 0,\n            'error_rate': sum(self.error_counts.values()) / sum(self.query_counts.values()) if sum(self.query_counts.values()) > 0 else 0,\n            'operations': dict(self.query_counts),\n            'errors': dict(self.error_counts)\n        }\n\n# Global metrics instance\nMETRICS = MetricsCollector()\n```\n\n**Core Algorithm Skeletons:**\n\nThe following skeletons provide the structure for implementing our core semantic search algorithms. Each function maps directly to the requirements established above:\n\n```python\n# src/embedding/encoder.py - Core embedding logic (SKELETON)\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nfrom typing import List\nfrom .processor import TextProcessor\nfrom .models import Document, DocumentEmbedding\n\nclass DocumentEncoder:\n    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n        self.model_name = model_name\n        self.embedding_dim = 384  # all-MiniLM-L6-v2 dimension\n        self.text_processor = TextProcessor()\n        # TODO 1: Initialize SentenceTransformer model with model_name\n        # TODO 2: Verify model.get_sentence_embedding_dimension() matches embedding_dim\n        # Hint: Store model as self.model for use in encoding methods\n    \n    def encode_document(self, document: Document) -> DocumentEmbedding:\n        \"\"\"Convert a document to its vector embedding representation.\"\"\"\n        # TODO 1: Call document.get_searchable_text() to get text for embedding\n        # TODO 2: Clean the text using self.text_processor.clean_text()\n        # TODO 3: Generate embedding using self.model.encode() - returns numpy array\n        # TODO 4: Normalize the embedding vector using normalize_vector()\n        # TODO 5: Create and return DocumentEmbedding with document, embedding, model info\n        # Hint: Handle empty text by returning zero vector of correct dimension\n        pass\n    \n    def encode_texts(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Batch encode multiple texts for efficiency.\"\"\"\n        # TODO 1: Filter out empty/None texts, keep track of original indices\n        # TODO 2: Clean all valid texts using text_processor.clean_text()\n        # TODO 3: Use self.model.encode() with batch processing for efficiency\n        # TODO 4: Normalize all embedding vectors\n        # TODO 5: Handle empty texts by inserting zero vectors at correct positions\n        # Hint: model.encode() accepts List[str] and returns np.ndarray of shape (n, dim)\n        pass\n    \n    def encode_query(self, query_text: str) -> np.ndarray:\n        \"\"\"Encode a search query to embedding vector.\"\"\"\n        # TODO 1: Clean query text using text_processor.clean_text()\n        # TODO 2: Handle empty query case - return zero vector or raise ValueError\n        # TODO 3: Generate embedding using self.model.encode() for single text\n        # TODO 4: Normalize the query embedding vector\n        # TODO 5: Return normalized embedding ready for similarity search\n        # Hint: Single text encoding returns shape (384,) array, not (1, 384)\n        pass\n```\n\n```python\n# src/search/retriever.py - Vector similarity search (SKELETON)\nimport numpy as np\nimport faiss\nfrom typing import List, Tuple\nfrom ..utils.metrics import METRICS\n\nclass VectorRetriever:\n    def __init__(self, index_path: str = None):\n        self.index = None\n        self.document_ids = []  # Maps index positions to document IDs\n        # TODO 1: Initialize FAISS index (either load from index_path or create new)\n        # TODO 2: Load document ID mapping from companion file\n        # Hint: Use faiss.read_index() for loading, check if file exists first\n    \n    def search_similar(self, query_embedding: np.ndarray, k: int = 10) -> List[Tuple[str, float]]:\n        \"\"\"Find k most similar documents to query embedding.\"\"\"\n        with METRICS.time_operation(\"vector_search\"):\n            # TODO 1: Validate query_embedding shape matches index dimension\n            # TODO 2: Reshape query to (1, dim) format required by FAISS\n            # TODO 3: Call self.index.search(query, k) to get distances and indices\n            # TODO 4: Convert distances to cosine similarity scores (if using IP index)\n            # TODO 5: Map internal indices to document IDs using self.document_ids\n            # TODO 6: Filter results by minimum score threshold from config\n            # TODO 7: Return List[(doc_id, similarity_score)] sorted by score descending\n            # Hint: FAISS returns (distances, indices) arrays of shape (1, k)\n            pass\n    \n    def add_documents(self, embeddings: np.ndarray, doc_ids: List[str]):\n        \"\"\"Add new document embeddings to the search index.\"\"\"\n        # TODO 1: Validate embeddings shape (n_docs, embedding_dim)\n        # TODO 2: Normalize embeddings if not already normalized\n        # TODO 3: Add embeddings to FAISS index using index.add()\n        # TODO 4: Append doc_ids to self.document_ids to maintain mapping\n        # TODO 5: Handle index training if using IVF-style index\n        # Hint: Some index types require training before adding vectors\n        pass\n```\n\n**Milestone Checkpoints:**\n\nAfter implementing each milestone, verify your system meets these concrete behavioral expectations:\n\n**Milestone 1 Checkpoint (Embedding Index):**\n```bash\n# Test basic embedding functionality\npython -c \"\nfrom src.embedding.encoder import DocumentEncoder\nfrom src.embedding.models import Document\n\nencoder = DocumentEncoder()\ndoc = Document(doc_id='test1', title='Python Tutorial', content='Learn Python programming')\nembedding = encoder.encode_document(doc)\nprint(f'Embedding shape: {embedding.embedding.shape}')  # Should be (384,)\nprint(f'Embedding norm: {np.linalg.norm(embedding.embedding):.3f}')  # Should be ~1.0\n\"\n```\n\nExpected output: Embedding shape (384,) with norm close to 1.0, indicating proper normalization.\n\n**Milestone 2 Checkpoint (Query Processing):**\n```bash\n# Test query encoding and basic search\npython -c \"\nfrom src.search.retriever import VectorRetriever  \nfrom src.embedding.encoder import DocumentEncoder\n\nencoder = DocumentEncoder()\nquery_vec = encoder.encode_query('machine learning tutorial')\nprint(f'Query vector shape: {query_vec.shape}')  # Should be (384,)\nprint('Query encoding successful')\n\"\n```\n\nExpected behavior: Query successfully converts to normalized 384-dimensional vector without errors.\n\n**Performance Verification:**\nAfter each milestone, run this performance check to ensure you're meeting latency requirements:\n\n```python\n# scripts/performance_check.py\nimport time\nfrom src.embedding.encoder import DocumentEncoder\n\nencoder = DocumentEncoder()\nstart_time = time.time()\nembedding = encoder.encode_query(\"test query performance\")\nelapsed_ms = (time.time() - start_time) * 1000\n\nprint(f\"Query encoding latency: {elapsed_ms:.2f}ms\")\nassert elapsed_ms < 100, f\"Query encoding too slow: {elapsed_ms}ms > 100ms\"\nprint(\"✓ Performance check passed\")\n```\n\nThis systematic approach ensures each component meets our established requirements before moving to the next milestone.\n\n\n## High-Level Architecture\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing how the major system components work together to deliver semantic search capabilities.\n\nThink of a semantic search engine as a **digital librarian with superhuman understanding**. Unlike a traditional librarian who relies on card catalogs with exact keyword matches, our digital librarian has read every book in the library and understands the meaning and relationships between concepts. When you ask about \"car maintenance,\" they instantly know you might also be interested in documents about \"automotive repair,\" \"vehicle servicing,\" or \"engine troubleshooting\" – even if those exact words weren't in your query.\n\nThis mental model guides our architecture: we need components that can \"read\" and \"understand\" documents (embedding generation), organize this understanding efficiently (vector indexing), interpret what users really want (query processing), and combine multiple signals to deliver the best results (ranking and relevance).\n\nThe semantic search engine architecture consists of four core components working in concert to transform the way users discover information. Each component has distinct responsibilities but must integrate seamlessly to deliver sub-second search experiences across millions of documents.\n\n### Core Components\n\nThe semantic search engine is built around five primary components, each handling a specific aspect of the search pipeline from document ingestion to result delivery.\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n**Document Processor** serves as the entry point for all content entering the search engine. This component handles the ingestion of raw documents, extracting searchable text from various formats, and preparing content for embedding generation. The processor normalizes document metadata, validates content quality, and manages the document lifecycle from creation to updates.\n\n| Component Responsibility | Description | Key Operations |\n|-------------------------|-------------|----------------|\n| Content Ingestion | Accept documents from various sources (files, APIs, databases) | Parse formats, validate structure, extract metadata |\n| Text Extraction | Extract clean, searchable text from document content | Remove markup, normalize whitespace, handle encoding |\n| Document Validation | Ensure content quality and completeness | Check required fields, validate content length, detect duplicates |\n| Lifecycle Management | Track document states and handle updates | Version tracking, deletion handling, update notifications |\n\n**Embedding Index** forms the heart of semantic search capabilities. This component converts textual content into high-dimensional vector representations using transformer models, then organizes these vectors into efficient searchable indices. The index must support both batch processing during initial construction and incremental updates as new documents arrive.\n\n| Component Responsibility | Description | Key Operations |\n|-------------------------|-------------|----------------|\n| Vector Generation | Convert text to dense numerical representations | Batch encoding, model management, dimension consistency |\n| Index Construction | Build efficient approximate nearest neighbor indices | HNSW/IVF algorithm implementation, memory management, persistence |\n| Similarity Search | Find most similar vectors for query embeddings | Top-K retrieval, distance calculation, result ranking |\n| Incremental Updates | Add new vectors without full index reconstruction | Dynamic insertion, ID mapping, index optimization |\n\n**Query Processor** interprets user search intent and transforms natural language queries into optimized vector representations. This component handles query expansion, semantic analysis, and the generation of multiple query variants to improve recall while maintaining precision.\n\n| Component Responsibility | Description | Key Operations |\n|-------------------------|-------------|----------------|\n| Query Understanding | Parse and analyze user search intent | Entity extraction, intent classification, query normalization |\n| Query Expansion | Generate related terms and synonyms | Synonym lookup, related term generation, context expansion |\n| Multi-Vector Queries | Support complex queries with multiple aspects | Query decomposition, vector arithmetic, negative term handling |\n| Embedding Generation | Convert processed queries to vector format | Query encoding, vector normalization, cache management |\n\n**Ranking Engine** combines multiple relevance signals to produce optimal result ordering. This component implements a multi-stage ranking pipeline that balances semantic similarity with lexical matching, freshness, personalization, and learned relevance signals from user interactions.\n\n| Component Responsibility | Description | Key Operations |\n|-------------------------|-------------|----------------|\n| Multi-Signal Scoring | Combine semantic, lexical, and contextual signals | Score normalization, weight tuning, signal combination |\n| Cross-Encoder Reranking | Apply precise but expensive ranking to top candidates | Transformer reranking, pairwise comparison, score calibration |\n| Personalization | Adjust results based on user preferences and history | User profiling, preference matching, privacy preservation |\n| Learning Integration | Incorporate click-through data for ranking improvement | Feature extraction, model updates, A/B testing support |\n\n**Search API** provides the external interface for all search operations, handling request routing, response formatting, and advanced features like autocomplete and faceted navigation. This component ensures consistent API contracts while optimizing for different client needs and usage patterns.\n\n| Component Responsibility | Description | Key Operations |\n|-------------------------|-------------|----------------|\n| Request Handling | Process and validate search requests | Parameter parsing, input validation, rate limiting |\n| Response Formatting | Structure results for client consumption | Result serialization, snippet generation, metadata inclusion |\n| Advanced Features | Support autocomplete, faceting, and analytics | Typeahead suggestions, filter navigation, usage tracking |\n| Performance Optimization | Ensure fast response times and efficient resource usage | Request caching, connection pooling, response compression |\n\n### End-to-End Data Flow\n\nThe semantic search engine processes information through two primary workflows: document indexing (preparing content for search) and query processing (serving search requests). Understanding these flows is crucial for implementing components that work together seamlessly.\n\n**Document Indexing Workflow** transforms raw documents into searchable vector representations. This process begins when new content enters the system and culminates with updated search indices ready to serve queries.\n\nThe indexing flow starts when the Document Processor receives new content through various ingestion channels. Raw documents arrive in different formats – text files, web pages, database records, or API payloads. The processor extracts clean, searchable text using the `get_searchable_text()` method, which combines document title and content while removing formatting artifacts and normalizing encoding.\n\nOnce text extraction completes, the system creates a `Document` instance containing the cleaned content along with metadata like creation timestamps, source URLs, and custom attributes. This structured representation ensures consistent handling throughout the pipeline regardless of the original document format.\n\nThe Document Encoder receives validated `Document` instances and generates vector embeddings using the `encode_document()` method. This process loads the configured transformer model (typically `DEFAULT_MODEL` all-MiniLM-L6-v2 with `EMBEDDING_DIM` 384 dimensions) and converts the searchable text into a `DocumentEmbedding` containing both the original document reference and its vector representation.\n\nVector embeddings flow into the Embedding Index component for storage and indexing. The index applies vector normalization using `normalize_vector()` to ensure consistent cosine similarity calculations, then adds the embedding to the approximate nearest neighbor index structure. For HNSW indices, this involves finding optimal insertion points in the navigable graph. For IVF indices, the system assigns vectors to appropriate clusters based on the trained quantizer.\n\nThe indexing workflow concludes with persistence operations that save the updated index to disk along with document metadata and ID mappings. This ensures that search capabilities remain available after system restarts and provides a foundation for incremental updates when new documents arrive.\n\n**Query Processing Workflow** handles real-time search requests from users, combining the indexed content with ranking signals to deliver relevant results within sub-second latency requirements.\n\nQuery processing begins when the Search API receives a search request containing the user's query text along with optional parameters like filters, result limits, and personalization context. The API validates input parameters and routes the request to the Query Processor for semantic analysis.\n\nThe Query Processor analyzes the incoming query using multiple techniques. Query expansion generates related terms and synonyms that might appear in relevant documents, helping address vocabulary mismatch between user language and document content. Entity extraction identifies specific concepts, locations, or topics within the query. Intent classification determines whether the user seeks factual information, product recommendations, or specific document types.\n\nEnhanced query understanding produces multiple query representations that flow into the embedding generation phase. The system applies the same transformer model used during indexing to convert query text into vector form using `encode_query()`. This ensures embedding compatibility and meaningful similarity calculations between queries and documents.\n\nQuery embeddings enter the Embedding Index for similarity search operations. The index performs approximate nearest neighbor search to identify the most semantically similar documents, typically retrieving a larger candidate set (e.g., top-1000) for subsequent ranking refinement. Vector similarity calculations use `cosine_similarity()` between normalized query and document embeddings.\n\nRetrieved candidates flow into the Ranking Engine for multi-signal scoring. The ranking pipeline combines semantic similarity scores with lexical BM25 matching, document freshness signals, personalization factors, and learned relevance weights. For the highest-quality results, cross-encoder reranking applies transformer models that directly compare query-document pairs, though this expensive operation typically processes only the top-100 candidates.\n\nFinal ranked results return to the Search API for formatting and delivery. The API generates result snippets with query term highlighting, includes relevance scores and metadata, and structures the response according to the client's requirements. Response caching optimizes performance for repeated queries while analytics collection enables continuous system improvement.\n\n> **Design Insight**: The separation between indexing and search workflows enables independent scaling and optimization. Heavy indexing operations can run during off-peak hours or on dedicated hardware, while the search path optimizes for low-latency response to user queries.\n\n### Recommended Project Structure\n\nA well-organized project structure helps developers understand component boundaries and facilitates maintainable code as the system grows. The recommended structure separates core search logic from infrastructure concerns while providing clear interfaces between components.\n\nThe project organization follows domain-driven design principles, grouping related functionality while maintaining clear separation of concerns. Each major component resides in its own module with dedicated interfaces, implementation files, and test coverage.\n\n```\nsemantic_search/\n├── main.py                          # Application entry point and server setup\n├── config/\n│   ├── __init__.py\n│   ├── settings.py                  # Configuration management and environment variables\n│   └── models.py                    # Transformer model configuration and loading\n├── core/\n│   ├── __init__.py\n│   ├── document.py                  # Document and DocumentEmbedding data models\n│   ├── query.py                     # Query processing data structures\n│   └── result.py                    # Search result formatting and response models\n├── components/\n│   ├── __init__.py\n│   ├── document_processor/\n│   │   ├── __init__.py\n│   │   ├── processor.py             # Document ingestion and text extraction\n│   │   ├── text_cleaner.py          # TextProcessor for content normalization\n│   │   └── validator.py             # Content validation and quality checks\n│   ├── embedding_index/\n│   │   ├── __init__.py\n│   │   ├── encoder.py               # DocumentEncoder with embedding generation\n│   │   ├── vector_index.py          # HNSW/IVF index implementation\n│   │   ├── similarity.py            # Cosine similarity and vector operations\n│   │   └── persistence.py           # Index saving and loading operations\n│   ├── query_processor/\n│   │   ├── __init__.py\n│   │   ├── understanding.py         # Query analysis and intent extraction\n│   │   ├── expansion.py             # Synonym and related term generation\n│   │   ├── embedding.py             # Query embedding generation and caching\n│   │   └── multi_vector.py          # Multi-aspect query handling\n│   ├── ranking/\n│   │   ├── __init__.py\n│   │   ├── multi_stage.py           # Multi-stage ranking pipeline coordination\n│   │   ├── hybrid_scorer.py         # Semantic and lexical score combination\n│   │   ├── cross_encoder.py         # Transformer-based reranking\n│   │   └── personalization.py       # User preference and freshness signals\n│   └── search_api/\n│       ├── __init__.py\n│       ├── endpoints.py             # RESTful API route handlers\n│       ├── autocomplete.py          # Typeahead and query suggestions\n│       ├── faceting.py              # Faceted navigation and filtering\n│       └── analytics.py             # Search metrics and usage tracking\n├── utils/\n│   ├── __init__.py\n│   ├── vector_utils.py              # Vector normalization and distance functions\n│   ├── text_utils.py                # Text processing utilities\n│   └── performance.py               # Timing and profiling helpers\n├── tests/\n│   ├── __init__.py\n│   ├── integration/                 # End-to-end workflow tests\n│   ├── unit/                        # Component-specific unit tests\n│   └── fixtures/                    # Test data and mock documents\n└── requirements.txt                 # Python dependencies\n```\n\n**Core Module Organization** provides shared data structures and interfaces used across all components. The `core` directory contains the fundamental types like `Document`, `DocumentEmbedding`, and result formatting classes that establish contracts between components. This centralized definition prevents circular dependencies and ensures consistent data handling.\n\n**Component Module Structure** organizes each major system component into its own directory with clear internal organization. Each component directory includes an `__init__.py` file that exports the main classes and functions, making it easy for other components to import required functionality. Implementation files focus on specific responsibilities within each component.\n\n**Utility Module Support** provides common functionality needed across multiple components without creating tight coupling. Vector operations, text processing utilities, and performance monitoring tools live in the `utils` directory where they can be imported as needed without forcing architectural dependencies.\n\n**Testing Organization** mirrors the main code structure while providing dedicated spaces for different testing approaches. Integration tests verify end-to-end workflows across component boundaries, while unit tests focus on individual component behavior. Fixture management centralizes test data creation and management.\n\n> **Architecture Decision: Module Boundaries**\n> - **Context**: Need to organize code for maintainability while avoiding circular dependencies\n> - **Options Considered**: Monolithic single module, feature-based modules, layer-based modules\n> - **Decision**: Domain-driven component modules with shared core types\n> - **Rationale**: Component boundaries match system architecture, core types prevent circular imports, each module can be developed and tested independently\n> - **Consequences**: Clear ownership of functionality, easier testing, potential for future service extraction, requires discipline to maintain boundaries\n\nThe project structure supports both development efficiency and production deployment. During development, the modular organization enables parallel work on different components while the shared core ensures integration compatibility. For deployment, the structure facilitates packaging decisions – the entire application can deploy as a single service, or components can be extracted into separate microservices as scaling needs evolve.\n\n**Import Strategy** follows a clear hierarchy to prevent circular dependencies. Core types are imported by all components but import nothing from components. Components may import from utils and other components as needed, but the dependency graph must remain acyclic. The main application module ties everything together for server initialization and request routing.\n\n**Configuration Management** centralizes all system configuration in the `config` module, including transformer model selection, index parameters, API settings, and environment-specific values. This approach enables easy configuration changes without code modification and supports different deployment environments with appropriate parameter tuning.\n\n### Implementation Guidance\n\nThe architecture implementation requires careful attention to component interfaces and data flow patterns. The following guidance provides concrete starting points for each major component while establishing the integration patterns that enable seamless operation.\n\n**A. Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Web Framework | Flask with JSON responses | FastAPI with automatic OpenAPI docs |\n| Vector Library | FAISS with CPU-only indices | FAISS with GPU acceleration |\n| Embedding Model | Sentence-Transformers all-MiniLM-L6-v2 | Custom fine-tuned domain-specific model |\n| Text Processing | Built-in string methods with regex | spaCy with advanced NLP pipelines |\n| Caching | Python dict with TTL cleanup | Redis with automatic expiration |\n| Configuration | JSON config files | YAML with environment variable substitution |\n| Logging | Python logging module | Structured logging with JSON output |\n\n**B. Core Data Models**\n\nThe following data models establish the foundation for all component interactions. These should be implemented first as they define the contracts between system components.\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nimport numpy as np\nfrom datetime import datetime\n\n@dataclass\nclass Document:\n    \"\"\"Core document representation used throughout the system.\"\"\"\n    doc_id: str\n    title: str\n    content: str\n    url: Optional[str] = None\n    metadata: Optional[Dict] = None\n    created_at: Optional[str] = None\n    \n    def get_searchable_text(self) -> str:\n        \"\"\"Combine title and content for embedding generation.\"\"\"\n        # TODO: Implement text combination with proper spacing\n        # TODO: Handle cases where title or content might be empty\n        # TODO: Consider metadata fields that should be searchable\n        pass\n\n@dataclass\nclass DocumentEmbedding:\n    \"\"\"Document with its vector embedding representation.\"\"\"\n    document: Document\n    embedding: np.ndarray\n    model_name: str\n    embedding_dim: int\n    \n    def __post_init__(self):\n        \"\"\"Validate embedding dimensions match expected size.\"\"\"\n        # TODO: Check embedding.shape[0] == embedding_dim\n        # TODO: Verify embedding is normalized for cosine similarity\n        # TODO: Validate model_name matches current configuration\n        pass\n\n@dataclass\nclass QueryRequest:\n    \"\"\"Search request from client with all parameters.\"\"\"\n    query_text: str\n    max_results: int = 10\n    filters: Optional[Dict] = None\n    personalization_context: Optional[Dict] = None\n    include_facets: bool = False\n    \n@dataclass\nclass SearchResult:\n    \"\"\"Individual search result with ranking information.\"\"\"\n    document: Document\n    relevance_score: float\n    snippet: str\n    highlighted_terms: List[str]\n    ranking_signals: Dict[str, float]\n\n@dataclass\nclass QueryResponse:\n    \"\"\"Complete search response with results and metadata.\"\"\"\n    query: str\n    results: List[SearchResult]\n    total_found: int\n    processing_time_ms: float\n    facets: Optional[Dict] = None\n```\n\n**C. Component Integration Patterns**\n\nThe system uses dependency injection and interface-based design to enable component composition while maintaining testability. Each component exposes a clear interface and accepts dependencies through constructor injection.\n\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\n\nclass DocumentProcessorInterface(ABC):\n    \"\"\"Interface for document ingestion and processing.\"\"\"\n    \n    @abstractmethod\n    def process_document(self, raw_content: str, metadata: Dict) -> Document:\n        \"\"\"Process raw content into structured Document.\"\"\"\n        pass\n    \n    @abstractmethod\n    def validate_document(self, document: Document) -> bool:\n        \"\"\"Validate document meets quality requirements.\"\"\"\n        pass\n\nclass EmbeddingIndexInterface(ABC):\n    \"\"\"Interface for vector indexing and similarity search.\"\"\"\n    \n    @abstractmethod\n    def add_document_embedding(self, embedding: DocumentEmbedding) -> None:\n        \"\"\"Add new document embedding to searchable index.\"\"\"\n        pass\n    \n    @abstractmethod\n    def search_similar(self, query_embedding: np.ndarray, k: int) -> List[Tuple[str, float]]:\n        \"\"\"Find k most similar documents returning (doc_id, similarity_score).\"\"\"\n        pass\n    \n    @abstractmethod\n    def save_index(self, filepath: str) -> None:\n        \"\"\"Persist index to disk for reload after restart.\"\"\"\n        pass\n\nclass SemanticSearchEngine:\n    \"\"\"Main orchestrator that coordinates all components.\"\"\"\n    \n    def __init__(self, \n                 document_processor: DocumentProcessorInterface,\n                 embedding_index: EmbeddingIndexInterface,\n                 query_processor: QueryProcessorInterface,\n                 ranking_engine: RankingEngineInterface):\n        self.document_processor = document_processor\n        self.embedding_index = embedding_index\n        self.query_processor = query_processor\n        self.ranking_engine = ranking_engine\n    \n    def add_documents(self, raw_documents: List[Dict]) -> None:\n        \"\"\"End-to-end document indexing workflow.\"\"\"\n        # TODO: Process each raw document through document_processor\n        # TODO: Generate embeddings for processed documents\n        # TODO: Add embeddings to the searchable index\n        # TODO: Handle errors gracefully and provide progress feedback\n        pass\n    \n    def search(self, query_request: QueryRequest) -> QueryResponse:\n        \"\"\"End-to-end search request processing.\"\"\"\n        # TODO: Process query through query_processor for understanding and expansion\n        # TODO: Generate query embedding for similarity search\n        # TODO: Retrieve candidate documents from embedding_index\n        # TODO: Apply ranking_engine to combine multiple relevance signals\n        # TODO: Format results and return complete response\n        pass\n```\n\n**D. Configuration Management**\n\nCentralized configuration enables easy deployment across different environments while providing sensible defaults for development.\n\n```python\nimport os\nfrom dataclasses import dataclass\nfrom typing import Dict, Any\n\n@dataclass\nclass SearchConfig:\n    \"\"\"Central configuration for all search engine components.\"\"\"\n    \n    # Embedding configuration\n    default_model: str = \"all-MiniLM-L6-v2\"\n    embedding_dim: int = 384\n    batch_size: int = 32\n    \n    # Index configuration\n    index_type: str = \"hnsw\"  # or \"ivf\"\n    hnsw_m: int = 16\n    hnsw_ef_construction: int = 200\n    hnsw_ef_search: int = 100\n    \n    # Query processing configuration\n    query_expansion_enabled: bool = True\n    max_query_length: int = 512\n    min_keyword_length: int = 3\n    \n    # Ranking configuration\n    semantic_weight: float = 0.7\n    lexical_weight: float = 0.3\n    freshness_decay_days: float = 30.0\n    \n    # API configuration\n    max_results: int = 100\n    default_results: int = 10\n    autocomplete_timeout_ms: int = 100\n    \n    @classmethod\n    def from_environment(cls) -> 'SearchConfig':\n        \"\"\"Load configuration from environment variables.\"\"\"\n        # TODO: Read environment variables with fallback to defaults\n        # TODO: Validate configuration values are within acceptable ranges\n        # TODO: Log configuration values for debugging (excluding secrets)\n        pass\n\ndef load_config() -> SearchConfig:\n    \"\"\"Load configuration based on environment.\"\"\"\n    env = os.getenv('SEARCH_ENV', 'development')\n    if env == 'production':\n        return SearchConfig.from_environment()\n    else:\n        return SearchConfig()  # Use defaults for development\n```\n\n**E. Application Entry Point**\n\nThe main application file ties all components together and provides the server entry point.\n\n```python\nimport uvicorn\nfrom fastapi import FastAPI\nfrom semantic_search.config.settings import load_config\nfrom semantic_search.components.document_processor.processor import DocumentProcessor\nfrom semantic_search.components.embedding_index.encoder import DocumentEncoder\nfrom semantic_search.components.embedding_index.vector_index import VectorIndex\nfrom semantic_search.components.query_processor.understanding import QueryProcessor\nfrom semantic_search.components.ranking.multi_stage import RankingEngine\nfrom semantic_search.components.search_api.endpoints import SearchAPI\n\ndef create_application() -> FastAPI:\n    \"\"\"Create and configure the FastAPI application.\"\"\"\n    config = load_config()\n    app = FastAPI(title=\"Semantic Search Engine\", version=\"1.0.0\")\n    \n    # TODO: Initialize all components with proper dependency injection\n    # TODO: Set up API routes with the SearchAPI component\n    # TODO: Configure middleware for logging, CORS, and request timing\n    # TODO: Add health check endpoints for monitoring\n    \n    return app\n\ndef main():\n    \"\"\"Application entry point.\"\"\"\n    config = load_config()\n    app = create_application()\n    \n    # TODO: Load any existing indices from disk\n    # TODO: Start the web server with appropriate configuration\n    # TODO: Handle graceful shutdown to save indices\n    \n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n**F. Development Workflow**\n\nThe recommended development approach builds components incrementally, with each milestone providing a working system that can be tested and validated.\n\n**Milestone 1 Development Flow:**\n1. Implement core data models (`Document`, `DocumentEmbedding`) with proper validation\n2. Create the `DocumentEncoder` with embedding generation using sentence-transformers\n3. Build the vector index with FAISS HNSW implementation\n4. Add index persistence for saving and loading trained indices\n5. Test with a small document collection to verify embedding generation and similarity search\n\n**Milestone 2 Development Flow:**\n1. Implement query text processing with normalization and validation\n2. Add query expansion using synonym lookups or word embeddings\n3. Build query embedding generation using the same model as document encoding\n4. Implement basic similarity search returning top-K results\n5. Test query processing with various query types and verify result relevance\n\n**Milestone 3 Development Flow:**\n1. Implement BM25 lexical scoring for keyword matching\n2. Build hybrid search combining semantic and lexical scores\n3. Add cross-encoder reranking for top candidate refinement\n4. Implement freshness and personalization signal integration\n5. Test ranking quality with evaluation queries and manually assess result ordering\n\n**Milestone 4 Development Flow:**\n1. Create RESTful API endpoints using FastAPI with proper request/response models\n2. Implement autocomplete functionality with cached query suggestions\n3. Build faceted navigation with efficient facet count computation\n4. Add query term highlighting in result snippets\n5. Create analytics dashboard for monitoring search performance and quality\n\n\n## Data Model\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing the core data structures that flow through the embedding index (Milestone 1), query processing (Milestone 2), ranking and relevance (Milestone 3), and search API (Milestone 4).\n\nThe data model defines the fundamental structures that represent documents, embeddings, queries, and results throughout the semantic search engine. Think of the data model as the **vocabulary** that all system components use to communicate—just as a library needs consistent cataloging standards so librarians can find books regardless of which department they work in, our search engine needs consistent data representations so the embedding index, query processor, and ranking engine can seamlessly exchange information.\n\nUnderstanding these data structures is crucial because they directly influence system performance, scalability, and maintainability. A well-designed data model reduces memory usage, enables efficient serialization, and provides clear interfaces between components. Conversely, poor data modeling decisions create bottlenecks that are expensive to fix later in the system's lifecycle.\n\n![Data Model Relationships](./diagrams/data-model.svg)\n\n### Document and Embedding Model\n\nThe document and embedding model captures how textual content is represented both in its original form and as vector embeddings for semantic search. This dual representation is essential because we need the original text for result display and highlighting, while the vector embeddings enable semantic similarity matching.\n\n#### Document Representation\n\nThe `Document` structure serves as the foundational unit of searchable content. Think of it as a **digital index card** in a library catalog system—it contains all the essential metadata needed to identify, retrieve, and display a piece of content to users.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `doc_id` | `str` | Unique identifier for the document, must be stable across updates and consistent with external systems |\n| `title` | `str` | Document title or headline, used for display and as primary text for embedding generation |\n| `content` | `str` | Full document body text, preprocessed to remove HTML tags and formatting artifacts |\n| `url` | `Optional[str]` | Source URL for web documents, enables click-through tracking and external link generation |\n| `metadata` | `Optional[Dict]` | Flexible key-value storage for domain-specific fields like author, publication date, categories |\n| `created_at` | `Optional[str]` | Document creation timestamp in ISO 8601 format, used for freshness scoring in ranking |\n\nThe `Document` structure balances simplicity with extensibility. The core fields (`doc_id`, `title`, `content`) are mandatory because they're required for basic search functionality, while optional fields support advanced features without complicating the basic use case.\n\n> **Design Insight:** The `metadata` field uses a dictionary rather than predefined fields because document schemas vary dramatically across domains. A news article needs author and publication date, while a product page needs price and category. The flexible metadata approach allows the same core system to handle diverse content types.\n\n#### Document Text Processing\n\nDocuments require preprocessing before embedding generation to ensure consistent, high-quality vector representations. The `get_searchable_text()` method combines title and content into a single string optimized for semantic understanding:\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `get_searchable_text` | None | `str` | Combines document title and content with appropriate weighting for embedding generation |\n| `clean_text` | `text: str` | `str` | Normalizes whitespace, removes special characters, and handles encoding issues |\n\nThe text processing pipeline addresses common issues that degrade embedding quality. HTML entities, excessive whitespace, and encoding artifacts create noise in vector representations. By standardizing text format before embedding generation, we ensure that similar content produces similar vectors regardless of original formatting.\n\n> **Critical Design Decision:** We concatenate title and content rather than embedding them separately because transformer models excel at understanding document-level context. The title provides crucial semantic context that helps disambiguate content meaning—the word \"python\" means different things in a programming tutorial versus a nature documentary.\n\n#### Vector Embedding Representation\n\nThe `DocumentEmbedding` structure bridges the gap between text documents and numerical vector representations that enable semantic search. Think of embeddings as **semantic fingerprints**—dense numerical signatures that capture the meaning and context of the original text.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `document` | `Document` | Reference to the original document, maintains connection between text and vector |\n| `embedding` | `np.ndarray` | Dense vector representation with shape `(embedding_dim,)` and dtype `float32` |\n| `model_name` | `str` | Identifier for the embedding model used, enables compatibility checks and model versioning |\n| `embedding_dim` | `int` | Dimensionality of the embedding vector, must match the model's output dimension |\n\nThe embedding vector is the heart of semantic search—it encodes the document's meaning in a high-dimensional space where similar concepts cluster together. The `model_name` field is crucial for production systems because embedding models evolve over time, and mixing embeddings from different models destroys similarity relationships.\n\n> **Architecture Decision Record:**\n> \n> **Decision: Store Document Reference in DocumentEmbedding**\n> - **Context**: We need to connect embeddings back to original documents for result display\n> - **Options Considered**:\n>   1. Store only `doc_id` string reference\n>   2. Store full `Document` object reference  \n>   3. Store embeddings and documents in separate collections with ID-based lookup\n> - **Decision**: Store full `Document` object reference\n> - **Rationale**: Reduces lookup overhead during search result generation, simplifies serialization, and ensures embedding-document consistency\n> - **Consequences**: Slightly higher memory usage per embedding, but eliminates expensive joins during result formatting\n\n#### Document Encoding Pipeline\n\nThe document encoding process transforms raw text into vector embeddings through several stages. The `DocumentEncoder` encapsulates the embedding model and text processing logic:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `model` | `SentenceTransformer` | Pre-trained transformer model for generating embeddings |\n| `model_name` | `str` | Model identifier matching the `DEFAULT_MODEL` constant |\n| `embedding_dim` | `int` | Output dimension of the model, typically `EMBEDDING_DIM` (384) |\n| `text_processor` | `TextProcessor` | Text cleaning and normalization utilities |\n\nThe encoding pipeline follows a consistent sequence:\n\n1. Extract searchable text using `get_searchable_text()` to combine title and content\n2. Clean and normalize the text using `clean_text()` to remove formatting artifacts  \n3. Generate embedding vector using the transformer model's encode method\n4. Normalize the embedding to unit length using `normalize_vector()` for cosine similarity\n5. Create `DocumentEmbedding` object linking the vector to its source document\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `encode_document` | `document: Document` | `DocumentEmbedding` | Complete pipeline from document to normalized embedding |\n| `encode_texts` | `texts: List[str]` | `np.ndarray` | Batch encoding for efficiency, returns shape `(n_texts, embedding_dim)` |\n\nBatch encoding is essential for performance because transformer models have high fixed overhead per forward pass. Processing documents in batches of 32-128 can improve throughput by 5-10x compared to individual encoding.\n\n### Index Data Structures\n\nThe index data structures define how vector embeddings are organized for efficient similarity search. Think of vector indices as **specialized filing systems** optimized for finding similar items rather than exact matches—like organizing books by topic and theme rather than alphabetically.\n\n#### Vector Index Organization\n\nVector indices face the fundamental challenge of the **curse of dimensionality**—naive similarity search requires comparing the query vector against every indexed vector, which becomes prohibitively expensive with millions of documents. Approximate nearest neighbor algorithms solve this by building data structures that quickly identify candidate similar vectors.\n\nThe index must support several key operations:\n\n| Operation | Time Complexity | Description |\n|-----------|-----------------|-------------|\n| Build Index | O(n log n) | Construct search structure from embeddings |\n| Add Vectors | O(log n) | Incrementally add new embeddings |\n| Search | O(log n) | Find k most similar vectors to query |\n| Persist | O(n) | Save trained index to disk |\n| Load | O(n) | Restore index from disk storage |\n\n> **Architecture Decision Record:**\n>\n> **Decision: HNSW vs IVF Index Algorithm Selection**\n> - **Context**: Need efficient approximate nearest neighbor search for high-dimensional embeddings\n> - **Options Considered**:\n>   1. **HNSW (Hierarchical Navigable Small World)**: Graph-based index with excellent query performance\n>   2. **IVF (Inverted File)**: Clustering-based index with good memory efficiency\n>   3. **LSH (Locality Sensitive Hashing)**: Simple but lower accuracy approach\n> - **Decision**: Primary recommendation is HNSW with IVF as alternative for memory-constrained environments\n> - **Rationale**: HNSW provides superior query latency (sub-millisecond) and higher recall accuracy, while IVF offers better memory efficiency for very large datasets\n> - **Consequences**: HNSW requires more memory but delivers better user experience; IVF requires training phase but scales to larger datasets\n\n| Index Algorithm | Memory Usage | Query Latency | Build Time | Incremental Updates |\n|-----------------|--------------|---------------|------------|-------------------|\n| **HNSW** | High | Excellent (<1ms) | Fast | Native Support |\n| **IVF** | Moderate | Good (1-5ms) | Slow (requires training) | Requires rebuild |\n| **LSH** | Low | Poor (10ms+) | Fast | Easy |\n\n#### HNSW Index Structure\n\nHNSW builds a multi-layer graph where each layer contains a subset of the indexed vectors. Higher layers have fewer nodes but longer edges, enabling fast navigation to the right neighborhood, while lower layers have more nodes with shorter edges for precise similarity matching.\n\n| Index Component | Type | Description |\n|-----------------|------|-------------|\n| `max_connections` | `int` | Maximum edges per node (M parameter), typically 16-48 |\n| `ef_construction` | `int` | Search width during index building, affects quality vs speed tradeoff |\n| `ef_search` | `int` | Search width during queries, affects recall vs latency tradeoff |\n| `levels` | `List[Graph]` | Hierarchical graph layers from coarse to fine resolution |\n\nThe HNSW parameters require careful tuning based on dataset characteristics:\n\n- **max_connections (M)**: Higher values improve recall but increase memory usage quadratically\n- **ef_construction**: Should be at least as large as the desired recall level  \n- **ef_search**: Can be adjusted per query to trade latency for accuracy\n\n> ⚠️ **Pitfall: HNSW Memory Explosion**\n> Setting `max_connections` too high causes memory usage to explode. Each connection stores a 32-bit integer ID, so M=64 uses 4x more memory than M=16. Start with M=16 and increase only if recall is insufficient.\n\n#### IVF Index Structure  \n\nIVF partitions the embedding space into clusters using k-means, then builds inverted lists mapping each cluster to the vectors it contains. Search involves identifying the most relevant clusters and searching within them.\n\n| Index Component | Type | Description |\n|-----------------|------|-------------|\n| `n_clusters` | `int` | Number of Voronoi cells, typically sqrt(n_vectors) |\n| `centroids` | `np.ndarray` | Cluster center vectors with shape `(n_clusters, embedding_dim)` |\n| `inverted_lists` | `Dict[int, List[int]]` | Mapping from cluster ID to vector IDs in that cluster |\n| `n_probe` | `int` | Number of clusters to search during queries |\n\nIVF requires a training phase to learn good cluster boundaries. The training dataset should be representative of the full data distribution, with at least 1000x more vectors than clusters.\n\n> ⚠️ **Pitfall: IVF Training Data Mismatch**  \n> Training IVF on a small subset that doesn't represent the full data distribution creates poor cluster boundaries. Documents that don't fit the learned clusters will have terrible recall. Use a diverse training set with at least 100,000 vectors.\n\n#### Index Persistence and Metadata\n\nVector indices must persist to disk to avoid expensive rebuilding on every system restart. The persistence layer handles both the index structure and associated metadata.\n\n| Persistence Component | Format | Description |\n|----------------------|--------|-------------|\n| `index_file` | Binary | Serialized index structure with optimized layout |\n| `metadata_file` | JSON | Human-readable configuration and statistics |\n| `id_mapping` | Binary | Bidirectional mapping between doc_ids and internal vector IDs |\n| `version_info` | JSON | Model compatibility and index format version |\n\nThe ID mapping is crucial because vector indices use sequential integer IDs internally, but documents use string identifiers. The mapping must stay synchronized when adding or removing documents.\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `save_index` | `path: str` | `None` | Persist complete index state to disk |\n| `load_index` | `path: str` | `VectorIndex` | Restore index from saved state |\n| `add_vectors` | `embeddings: List[DocumentEmbedding]` | `None` | Incremental addition with ID mapping |\n\n> ⚠️ **Pitfall: ID Mapping Desynchronization**\n> Adding vectors to the index without updating the ID mapping, or vice versa, creates silent corruption where searches return wrong documents. Always update both structures atomically or use transactions.\n\n### Query and Result Model\n\nThe query and result model defines how search requests are structured, processed, and returned to users. This model must balance expressiveness (supporting complex queries) with performance (enabling efficient processing and caching).\n\n#### Search Query Representation\n\nThe `QueryRequest` structure encapsulates all information needed to process a search query. Think of it as a **detailed research request** submitted to a librarian—it specifies not just what to find, but how many results to return, what constraints to apply, and how to personalize the search.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `query_text` | `str` | Primary search query string, will be embedded for semantic matching |\n| `max_results` | `int` | Maximum number of results to return, affects performance and relevance |\n| `filters` | `Optional[Dict]` | Key-value constraints on document metadata (e.g., date ranges, categories) |\n| `personalization_context` | `Optional[Dict]` | User preferences and history for result customization |\n| `include_facets` | `bool` | Whether to compute and return facet counts for filtering UI |\n\nThe query structure supports both simple keyword searches and complex structured queries. The `filters` field enables faceted search where users can constrain results by metadata attributes. The `personalization_context` allows ranking algorithms to customize results based on user behavior and preferences.\n\n> **Design Principle:** Query structure separates semantic matching (via `query_text`) from metadata filtering and personalization. This enables the system to apply semantic search broadly, then apply filters and personalization to refine results, rather than trying to encode all constraints in a single embedding.\n\n#### Query Processing Pipeline Data Structures\n\nQuery processing transforms the raw query text through several intermediate representations before generating the final embedding for similarity search.\n\n| Processing Stage | Input Type | Output Type | Description |\n|------------------|------------|-------------|-------------|\n| **Text Cleaning** | `str` | `str` | Normalized query text with consistent formatting |\n| **Query Expansion** | `str` | `List[str]` | Original query plus synonyms and related terms |\n| **Intent Analysis** | `str` | `Dict[str, Any]` | Extracted entities, query type, and semantic intent |\n| **Vector Generation** | `str` | `np.ndarray` | Dense embedding vector for similarity matching |\n\nThe query expansion stage is particularly important for handling **vocabulary mismatch**—when users and documents use different terms for the same concepts. For example, a query for \"car\" should also match documents about \"automobile\" and \"vehicle.\"\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `encode_query` | `query_text: str` | `np.ndarray` | Generate embedding vector from query text |\n| `expand_query` | `query_text: str` | `List[str]` | Add synonyms and related terms to original query |\n| `extract_intent` | `query_text: str` | `Dict[str, Any]` | Identify entities, query type, and user intent |\n\nMulti-vector queries support complex search scenarios where different aspects of the query need different semantic representations. For example, a query like \"python programming -snake\" has positive terms (python, programming) and negative terms (snake) that require different handling.\n\n> **Architecture Decision Record:**\n>\n> **Decision: Single vs Multi-Vector Query Representation**  \n> - **Context**: Need to handle complex queries with multiple aspects or negative terms\n> - **Options Considered**:\n>   1. **Single Vector**: Embed entire query as one vector\n>   2. **Multi-Vector**: Separate embeddings for different query aspects  \n>   3. **Weighted Combination**: Multiple vectors with importance weights\n> - **Decision**: Support both single and multi-vector queries based on complexity\n> - **Rationale**: Simple queries benefit from single vector efficiency, while complex queries need multi-vector expressiveness\n> - **Consequences**: More complex query processing but better handling of nuanced search intent\n\n#### Search Result Representation\n\nThe `SearchResult` structure represents individual documents returned for a query, enriched with relevance information and display formatting. Each result is like a **library catalog entry** that provides enough information for users to decide whether to access the full document.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `document` | `Document` | Complete document information including title, content, and metadata |\n| `relevance_score` | `float` | Combined relevance score from all ranking signals, normalized 0-1 |\n| `snippet` | `str` | Excerpt from document content highlighting query relevance |\n| `highlighted_terms` | `List[str]` | Query terms that should be highlighted in the result display |\n| `ranking_signals` | `Dict[str, float]` | Individual signal scores for debugging and tuning |\n\nThe `ranking_signals` field provides transparency into the ranking process, storing individual scores for semantic similarity, BM25, personalization, freshness, and other factors. This enables result quality analysis and ranking algorithm debugging.\n\n| Ranking Signal | Range | Description |\n|----------------|-------|-------------|\n| `semantic_score` | 0.0-1.0 | Cosine similarity between query and document embeddings |\n| `lexical_score` | 0.0-1.0 | BM25 keyword matching score |\n| `freshness_score` | 0.0-1.0 | Time-based relevance decay from document creation date |\n| `personalization_score` | 0.0-1.0 | User preference and behavior matching |\n| `authority_score` | 0.0-1.0 | Document quality and trustworthiness indicators |\n\n#### Query Response Structure\n\nThe `QueryResponse` aggregates individual search results with query-level metadata and performance information. This structure supports both search results display and system monitoring.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `query` | `str` | Original query text for reference and logging |\n| `results` | `List[SearchResult]` | Ordered list of matching documents with relevance scores |\n| `total_found` | `int` | Total matching documents before result limit applied |\n| `processing_time_ms` | `float` | End-to-end query processing latency for performance monitoring |\n| `facets` | `Optional[Dict]` | Facet counts for filters (category: count mapping) |\n\nThe facet information enables rich filtering interfaces where users can see how many results exist in each category, author, or time period. Computing facets efficiently requires careful index design because counting requires examining many more documents than the top-K results.\n\n> ⚠️ **Pitfall: Expensive Facet Computation**\n> Computing facet counts naively requires examining all matching documents, not just the top K results. For large result sets, this can increase query latency by 10x. Use approximate counting or precomputed facet indices for better performance.\n\n#### Result Ranking and Scoring\n\nThe result ranking process combines multiple scoring signals into a final relevance score. The scoring pipeline must be both accurate (ranking truly relevant results higher) and efficient (processing thousands of candidates quickly).\n\n| Scoring Stage | Input | Output | Latency Budget |\n|---------------|-------|--------|----------------|\n| **Candidate Retrieval** | Query vector | Top 1000 candidates | <10ms |\n| **Multi-Signal Scoring** | Candidates + signals | Scored candidates | <20ms |\n| **Cross-Encoder Reranking** | Top 100 candidates | Final ranking | <50ms |\n| **Result Formatting** | Ranked results | Formatted response | <10ms |\n\nThe multi-stage approach balances quality and performance by applying expensive but accurate scoring only to a small set of high-quality candidates identified by fast approximate methods.\n\n### Common Implementation Pitfalls\n\nUnderstanding the data model means avoiding common mistakes that can silently corrupt search quality or create performance bottlenecks:\n\n> ⚠️ **Pitfall: Vector Normalization Inconsistency**  \n> Failing to normalize vectors consistently between indexing and search breaks cosine similarity calculations. Some vectors may have large magnitudes that dominate similarity scores regardless of semantic content. Always apply `normalize_vector()` before indexing and searching.\n\n> ⚠️ **Pitfall: Embedding Dimension Mismatch**  \n> Mixing embeddings from models with different dimensions causes crashes or silent corruption. Always validate that loaded embeddings match the expected `EMBEDDING_DIM` before adding them to indices. Store the `model_name` and `embedding_dim` in metadata for validation.\n\n> ⚠️ **Pitfall: Document ID String Encoding Issues**  \n> Using document IDs with special characters or inconsistent encoding creates lookup failures. URLs and filenames often contain characters that break string matching. Normalize all document IDs to a consistent encoding (UTF-8) and consider using hash-based IDs for URLs.\n\n> ⚠️ **Pitfall: Metadata Serialization Problems**  \n> Storing complex objects in the metadata dictionary that can't be serialized to JSON breaks persistence. Stick to primitive types (strings, numbers, booleans, lists, dicts) in metadata fields, or implement custom serialization for complex types.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **Vector Operations** | NumPy arrays with basic operations | Faiss with optimized SIMD operations |\n| **Text Processing** | Basic regex and string methods | spaCy or NLTK for advanced NLP |\n| **Serialization** | JSON for metadata, pickle for arrays | Protocol Buffers or MessagePack |\n| **Persistence** | File-based storage with JSON metadata | SQLite or PostgreSQL with vector extensions |\n\n#### Recommended File Structure\n\n```python\nproject-root/\n  src/\n    data_model/\n      __init__.py              ← Export main types\n      document.py              ← Document and DocumentEmbedding classes\n      query.py                 ← QueryRequest and QueryResponse classes  \n      result.py                ← SearchResult and ranking data structures\n      processing.py            ← TextProcessor and DocumentEncoder classes\n      validation.py            ← Data validation and normalization utilities\n    tests/\n      test_data_model/\n        test_document.py       ← Document structure and methods tests\n        test_embeddings.py     ← Embedding generation and validation tests\n        test_queries.py        ← Query processing pipeline tests\n```\n\n#### Core Data Structure Implementation\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Optional, Dict, List, Any\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nimport re\nfrom datetime import datetime\n\n# Constants matching project naming conventions\nDEFAULT_MODEL = \"all-MiniLM-L6-v2\"\nEMBEDDING_DIM = 384\nMIN_KEYWORD_LENGTH = 3\n\n@dataclass\nclass Document:\n    \"\"\"Core document representation with metadata and content.\"\"\"\n    doc_id: str\n    title: str \n    content: str\n    url: Optional[str] = None\n    metadata: Optional[Dict] = None\n    created_at: Optional[str] = None\n    \n    def get_searchable_text(self) -> str:\n        \"\"\"Combine title and content for embedding generation.\n        \n        Returns:\n            str: Formatted text optimized for semantic understanding\n        \"\"\"\n        # TODO 1: Combine title and content with appropriate spacing\n        # TODO 2: Handle cases where title or content might be empty\n        # TODO 3: Consider title weighting (repeat title or add special markers)\n        # Hint: Title provides crucial context - consider repeating it or using special formatting\n        pass\n\n@dataclass  \nclass DocumentEmbedding:\n    \"\"\"Links document to its vector embedding representation.\"\"\"\n    document: Document\n    embedding: np.ndarray  # Shape: (EMBEDDING_DIM,), dtype: float32\n    model_name: str\n    embedding_dim: int\n    \n    def __post_init__(self):\n        \"\"\"Validate embedding dimensions and normalize vector.\"\"\"\n        # TODO 1: Validate embedding.shape matches (embedding_dim,)\n        # TODO 2: Validate embedding.dtype is float32\n        # TODO 3: Normalize embedding to unit length for cosine similarity\n        # TODO 4: Validate model_name matches expected model\n        pass\n\nclass TextProcessor:\n    \"\"\"Handles text cleaning and normalization for consistent embeddings.\"\"\"\n    \n    def __init__(self):\n        # Pre-compile regex patterns for efficiency\n        self.url_pattern = re.compile(r'https?://[^\\s<>\"]+')\n        self.email_pattern = re.compile(r'\\S+@\\S+\\.\\S+')\n        self.whitespace_pattern = re.compile(r'\\s+')\n    \n    def clean_text(self, text: str) -> str:\n        \"\"\"Normalize and clean text for embedding generation.\n        \n        Args:\n            text: Raw input text potentially containing HTML, URLs, etc.\n            \n        Returns:\n            str: Cleaned text suitable for embedding model\n        \"\"\"\n        # TODO 1: Remove URLs and email addresses (replace with placeholder or remove)\n        # TODO 2: Normalize whitespace (collapse multiple spaces, remove leading/trailing)\n        # TODO 3: Handle HTML entities and special characters\n        # TODO 4: Convert to lowercase if needed (check model requirements)\n        # TODO 5: Remove or replace very short tokens (< MIN_KEYWORD_LENGTH)\n        pass\n```\n\n#### Query and Result Implementation\n\n```python\n@dataclass\nclass QueryRequest:\n    \"\"\"Structured search query with filters and personalization.\"\"\"\n    query_text: str\n    max_results: int = 20\n    filters: Optional[Dict] = None\n    personalization_context: Optional[Dict] = None  \n    include_facets: bool = False\n    \n    def __post_init__(self):\n        \"\"\"Validate query parameters.\"\"\"\n        # TODO 1: Validate query_text is not empty\n        # TODO 2: Ensure max_results is reasonable (1-1000)\n        # TODO 3: Validate filter format if provided\n        pass\n\n@dataclass\nclass SearchResult:\n    \"\"\"Individual search result with relevance information.\"\"\"\n    document: Document\n    relevance_score: float  # 0.0-1.0 combined score\n    snippet: str           # Highlighted excerpt\n    highlighted_terms: List[str]\n    ranking_signals: Dict[str, float]  # Individual signal scores\n\n@dataclass  \nclass QueryResponse:\n    \"\"\"Complete search response with results and metadata.\"\"\"\n    query: str\n    results: List[SearchResult] \n    total_found: int\n    processing_time_ms: float\n    facets: Optional[Dict] = None\n\nclass DocumentEncoder:\n    \"\"\"Converts documents to normalized embeddings using transformer models.\"\"\"\n    \n    def __init__(self, model_name: str = DEFAULT_MODEL):\n        # TODO 1: Load SentenceTransformer model\n        # TODO 2: Initialize text processor\n        # TODO 3: Store model metadata (name, dimension)\n        # TODO 4: Validate model produces expected embedding dimension\n        self.model = None  # Load SentenceTransformer here\n        self.model_name = model_name\n        self.embedding_dim = EMBEDDING_DIM  \n        self.text_processor = TextProcessor()\n    \n    def encode_document(self, document: Document) -> DocumentEmbedding:\n        \"\"\"Convert document to normalized embedding.\n        \n        Args:\n            document: Source document with title and content\n            \n        Returns:\n            DocumentEmbedding: Document linked to its vector representation\n        \"\"\"\n        # TODO 1: Get searchable text from document\n        # TODO 2: Clean text using text processor  \n        # TODO 3: Generate embedding using transformer model\n        # TODO 4: Normalize embedding vector to unit length\n        # TODO 5: Return DocumentEmbedding with metadata\n        pass\n    \n    def encode_texts(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Batch encode multiple texts for efficiency.\n        \n        Args:\n            texts: List of cleaned text strings\n            \n        Returns:\n            np.ndarray: Normalized embeddings with shape (len(texts), EMBEDDING_DIM)\n        \"\"\"\n        # TODO 1: Batch encode all texts with single model call\n        # TODO 2: Normalize all embeddings to unit length\n        # TODO 3: Return as float32 array for memory efficiency\n        pass\n    \n    def encode_query(self, query_text: str) -> np.ndarray:\n        \"\"\"Encode search query to embedding vector.\n        \n        Args:\n            query_text: User search query string\n            \n        Returns:\n            np.ndarray: Normalized query embedding\n        \"\"\"\n        # TODO 1: Clean query text (similar to document processing)\n        # TODO 2: Generate embedding using same model as documents\n        # TODO 3: Normalize to unit length for cosine similarity\n        pass\n\n# Utility functions for vector operations\ndef normalize_vector(vec: np.ndarray) -> np.ndarray:\n    \"\"\"L2 normalize vector to unit length for cosine similarity.\n    \n    Args:\n        vec: Input vector of any length\n        \n    Returns:\n        np.ndarray: Unit-length vector pointing in same direction\n    \"\"\"\n    # TODO 1: Compute L2 norm of vector\n    # TODO 2: Handle zero vectors (return zero vector)\n    # TODO 3: Divide vector by norm to get unit length\n    pass\n\ndef cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n    \"\"\"Compute cosine similarity between normalized vectors.\n    \n    Args:\n        vec1, vec2: Normalized vectors of same dimension\n        \n    Returns:\n        float: Similarity score from -1 (opposite) to 1 (identical)\n    \"\"\"\n    # TODO 1: Validate vectors have same shape\n    # TODO 2: Compute dot product (for normalized vectors, this equals cosine similarity)\n    # TODO 3: Handle numerical edge cases (clamp to [-1, 1] range)\n    pass\n```\n\n#### Data Validation and Testing\n\n```python\nclass DataValidator:\n    \"\"\"Validates data model consistency and catches common errors.\"\"\"\n    \n    @staticmethod\n    def validate_document(document: Document) -> List[str]:\n        \"\"\"Check document for common issues.\n        \n        Returns:\n            List[str]: List of validation error messages (empty if valid)\n        \"\"\"\n        errors = []\n        # TODO 1: Check required fields are not None or empty\n        # TODO 2: Validate doc_id format (no special characters, reasonable length)\n        # TODO 3: Check text content is reasonable length (not empty, not too long)\n        # TODO 4: Validate metadata types are JSON-serializable\n        # TODO 5: Check created_at format if provided (ISO 8601)\n        return errors\n    \n    @staticmethod \n    def validate_embedding(embedding: DocumentEmbedding) -> List[str]:\n        \"\"\"Check embedding for consistency issues.\n        \n        Returns:\n            List[str]: List of validation error messages (empty if valid)  \n        \"\"\"\n        errors = []\n        # TODO 1: Validate embedding array shape and dtype\n        # TODO 2: Check if vector is normalized (L2 norm ≈ 1.0)\n        # TODO 3: Validate model_name and embedding_dim consistency\n        # TODO 4: Check for NaN or infinite values in vector\n        # TODO 5: Validate document reference is complete\n        return errors\n```\n\n#### Milestone Checkpoint\n\nAfter implementing the data model components, verify correct behavior:\n\n**Testing Data Structures:**\n```bash\ncd project-root\npython -m pytest src/tests/test_data_model/ -v\n```\n\n**Expected Test Results:**\n- Document creation and validation tests pass\n- Text processing correctly handles HTML, URLs, and whitespace\n- Embedding generation produces normalized vectors with correct dimensions\n- Query and result structures serialize/deserialize properly\n- Vector operations (normalize, cosine similarity) produce expected values\n\n**Manual Verification:**\n```python\n# Test document processing pipeline\ndoc = Document(\n    doc_id=\"test-1\",\n    title=\"Python Programming Tutorial\", \n    content=\"Learn Python programming with examples and exercises.\",\n    metadata={\"category\": \"education\", \"difficulty\": \"beginner\"}\n)\n\nencoder = DocumentEncoder()\nembedding = encoder.encode_document(doc)\n\nprint(f\"Embedding shape: {embedding.embedding.shape}\")  # Should be (384,)\nprint(f\"Vector norm: {np.linalg.norm(embedding.embedding)}\")  # Should be ≈1.0  \nprint(f\"Model: {embedding.model_name}\")  # Should be \"all-MiniLM-L6-v2\"\n```\n\n**Signs of Problems:**\n- Vector norms significantly different from 1.0 indicate normalization issues\n- Embedding dimensions other than 384 suggest model loading problems  \n- Text processing not removing HTML indicates regex pattern issues\n- Serialization errors suggest non-JSON-compatible metadata types\n\n\n## Embedding Index Component\n\n> **Milestone(s):** Milestone 1: Embedding Index\n\nThe **Embedding Index Component** serves as the core foundation of our semantic search engine, transforming text documents into high-dimensional vector representations and organizing them for efficient similarity search. This component bridges the gap between human language and mathematical computation, enabling our system to understand semantic meaning rather than relying solely on keyword matching. The embedding index acts as a specialized database optimized for finding conceptually similar documents in vector space, supporting millions of documents while maintaining sub-second query response times.\n\n### Vector Search Mental Model: Library Analogy\n\nThink of the embedding index as a revolutionary library system designed by a librarian who understands not just where books are located, but what they actually mean. In a traditional library, books are organized by category and call numbers—you find books by knowing exactly what to look for. But imagine a library where the librarian has read every book and can instantly recommend books that share similar themes, concepts, or ideas, even if they use completely different words.\n\nThe **vector embedding** is like the librarian's mental summary of each book—a compact representation that captures the essence of the book's meaning in a way that can be compared mathematically. When you ask a question, the librarian doesn't just match your exact words to book titles; instead, they understand what you're really looking for and find books that address your underlying need, even if they use different terminology.\n\nThe **approximate nearest neighbor search** works like the librarian's ability to quickly narrow down millions of books to the most relevant ones. Rather than reading every single book summary when you make a request, the librarian has organized their mental model into a sophisticated network of connections. They start with a rough area of knowledge, then follow connections through increasingly precise neighborhoods of related concepts until they find the books most similar to what you're seeking.\n\nThis library analogy captures three key insights about vector search: first, that meaning can be mathematically represented and compared; second, that efficiency comes from intelligent organization rather than exhaustive searching; and third, that approximate answers delivered quickly are often more valuable than perfect answers delivered slowly.\n\n### Document Embedding Pipeline\n\nThe document embedding pipeline transforms raw text into mathematical vectors that capture semantic meaning, creating the foundation for similarity-based search. This transformation process involves multiple stages of text preprocessing, encoding, and vector normalization to ensure consistent and high-quality representations.\n\n#### Text Preprocessing and Normalization\n\nBefore documents can be converted to embeddings, they must undergo careful preprocessing to remove noise and standardize format. The `TextProcessor` component handles this critical preparation phase, ensuring that the embedding model receives clean, consistent input that maximizes the quality of the resulting vector representations.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `url_pattern` | `re.Pattern` | Regular expression for detecting and cleaning URLs from document text |\n| `email_pattern` | `re.Pattern` | Regular expression for detecting and normalizing email addresses |\n| `whitespace_pattern` | `re.Pattern` | Regular expression for normalizing excessive whitespace and special characters |\n\nThe text cleaning process follows a systematic approach designed to preserve semantic content while removing elements that could confuse the embedding model. The `clean_text` method applies multiple transformations to ensure input consistency.\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `clean_text` | `text: str` | `str` | Normalizes whitespace, removes URLs, standardizes punctuation, converts to lowercase |\n| `get_searchable_text` | - | `str` | Combines document title and content with appropriate weighting for embedding |\n\nThe preprocessing pipeline addresses several critical challenges in text normalization. URLs and email addresses are standardized rather than removed entirely, as they may contain meaningful tokens. HTML entities are decoded to their text equivalents, ensuring that encoded characters don't create vocabulary fragmentation. Multiple consecutive whitespace characters are collapsed to single spaces, and non-printable characters are removed to prevent encoding issues.\n\n> **Key Design Insight**: Text preprocessing decisions directly impact embedding quality. Overly aggressive cleaning can remove meaningful semantic signals, while insufficient cleaning introduces noise that degrades similarity calculations. The preprocessing pipeline aims to preserve semantic content while standardizing format.\n\n#### Transformer Model Integration\n\nThe `DocumentEncoder` component wraps the Sentence Transformer model and provides the interface for converting cleaned text into vector embeddings. This component manages model initialization, batching for efficiency, and consistent embedding generation across the document collection.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `model` | `SentenceTransformer` | Pre-trained transformer model for generating sentence embeddings |\n| `model_name` | `str` | Identifier for the specific embedding model being used |\n| `embedding_dim` | `int` | Dimensionality of the output embedding vectors |\n| `text_processor` | `TextProcessor` | Text preprocessing component for input normalization |\n\nThe document encoding process transforms preprocessed text through several stages. First, the text is tokenized using the model's vocabulary, converting words and subwords into numerical tokens. These tokens are processed through the transformer's attention layers, which capture contextual relationships between words. Finally, the model generates a fixed-size embedding vector that represents the semantic content of the entire text.\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `encode_document` | `document: Document` | `DocumentEmbedding` | Converts document text to embedding with metadata tracking |\n| `encode_texts` | `texts: List[str]` | `np.ndarray` | Batch encodes multiple texts for efficiency |\n| `encode_query` | `query_text: str` | `np.ndarray` | Encodes search query with same model for consistency |\n| `normalize_vector` | `vec: np.ndarray` | `np.ndarray` | L2 normalizes vector to unit length for cosine similarity |\n\n#### Embedding Generation and Validation\n\nThe embedding generation process creates `DocumentEmbedding` objects that combine the original document with its vector representation and model metadata. This structure ensures traceability and enables model versioning when the embedding approach evolves.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `document` | `Document` | Original document containing text content and metadata |\n| `embedding` | `np.ndarray` | Dense vector representation of document semantic content |\n| `model_name` | `str` | Name of the transformer model used for embedding generation |\n| `embedding_dim` | `int` | Dimensionality of the embedding vector for validation |\n\nThe embedding pipeline includes validation steps to ensure vector quality and consistency. Each generated embedding is checked for the correct dimensionality, verified to contain only finite values, and normalized to unit length for cosine similarity calculations. The pipeline also tracks embedding generation timestamps and model versions to support incremental reprocessing when models are updated.\n\n> **Design Decision: Single Model Consistency**\n> - **Context**: Documents and queries must be embedded using the same model for meaningful similarity calculations\n> - **Options Considered**: Multiple specialized models vs. single general-purpose model vs. dynamic model selection\n> - **Decision**: Use single model for all text encoding with version tracking\n> - **Rationale**: Embedding spaces are model-specific—vectors from different models cannot be meaningfully compared\n> - **Consequences**: Simpler architecture and consistent similarity calculations, but potentially suboptimal for specialized content types\n\n### Index Algorithm Selection\n\nThe choice between **HNSW (Hierarchical Navigable Small World)** and **IVF (Inverted File)** indexing algorithms represents a fundamental architectural decision that affects search performance, memory usage, and scalability characteristics. Both algorithms solve the approximate nearest neighbor problem but with different trade-offs that align with specific use cases and operational requirements.\n\n#### Algorithm Comparison and Trade-off Analysis\n\n| Algorithm | Search Latency | Memory Usage | Build Time | Update Support | Accuracy |\n|-----------|---------------|--------------|------------|----------------|-----------|\n| **HNSW** | Very Low (1-5ms) | High (2-4x vectors) | Medium | Excellent | High (95%+ recall) |\n| **IVF** | Low (5-20ms) | Low (1.1-1.5x vectors) | Fast | Poor (requires rebuild) | Medium (85-95% recall) |\n\nThe performance characteristics of these algorithms create distinct optimization profiles. HNSW excels in scenarios requiring ultra-low latency and frequent updates, while IVF provides better memory efficiency and faster index construction for batch processing workflows.\n\n#### HNSW Algorithm Deep Dive\n\nHNSW constructs a multi-layer graph structure where each layer contains a subset of the indexed vectors connected by edges to their nearest neighbors. The algorithm leverages the small-world property—the idea that in a well-connected graph, any two nodes can be reached through a small number of intermediate connections.\n\nThe HNSW structure consists of multiple layers with exponentially decreasing densities. Layer 0 contains all vectors, layer 1 contains roughly half, layer 2 contains roughly a quarter, and so on. Higher layers provide long-range connections for efficient navigation, while lower layers offer fine-grained local connections for precise neighbor finding.\n\n**HNSW Search Process:**\n1. Begin search at the highest layer containing vectors, starting from a random entry point\n2. Perform greedy search within the current layer, following edges to progressively closer neighbors\n3. When no closer neighbors exist in the current layer, descend to the next lower layer\n4. Continue layer-by-layer descent until reaching layer 0\n5. Perform final greedy search in layer 0 to find the precise nearest neighbors\n6. Return the top-k closest vectors based on distance calculations\n\nThe HNSW configuration requires tuning several parameters that significantly impact performance. The `M` parameter controls the maximum number of connections per vector—higher values improve recall but increase memory usage exponentially. The `efConstruction` parameter determines search effort during index construction, affecting both build time and final index quality.\n\n#### IVF Algorithm Deep Dive\n\nIVF partitions the vector space into a predetermined number of clusters (called Voronoi cells) and builds an inverted index mapping each cluster to the vectors it contains. This approach reduces search complexity from linear scanning of all vectors to targeted searching within a subset of relevant clusters.\n\nThe IVF training process uses k-means clustering to learn cluster centroids that partition the vector space effectively. During search, the algorithm computes distances from the query vector to all cluster centroids, selects the closest clusters, and performs exhaustive search within those clusters only.\n\n**IVF Search Process:**\n1. Compute query vector distance to all trained cluster centroids\n2. Select the `nprobe` closest clusters based on centroid distances\n3. Retrieve all vectors assigned to the selected clusters from the inverted index\n4. Compute exact distances from query vector to all retrieved candidate vectors\n5. Sort candidates by distance and return the top-k closest vectors\n6. Apply post-filtering if additional constraints are specified\n\nThe IVF configuration centers on the trade-off between search accuracy and computational cost. More clusters (`nlist`) provide finer partitioning but require more memory and longer training time. Searching more clusters (`nprobe`) improves recall but increases query latency proportionally.\n\n#### Architecture Decision: HNSW Selection\n\n> **Decision: HNSW Algorithm for Primary Index**\n> - **Context**: Need to support real-time search with sub-second latency while handling frequent document updates\n> - **Options Considered**: HNSW for low latency, IVF for memory efficiency, hybrid approach combining both\n> - **Decision**: Implement HNSW as the primary indexing algorithm with IVF as an optional alternative\n> - **Rationale**: HNSW's superior update performance and consistently low latency align with real-time search requirements, while memory costs are manageable for the target scale\n> - **Consequences**: Higher memory usage but excellent search performance and simplified update logic\n\n| Consideration | HNSW Advantage | IVF Advantage | Impact on Decision |\n|---------------|----------------|---------------|-------------------|\n| **Search Latency** | 1-5ms consistent | 5-20ms variable | Critical for user experience |\n| **Update Frequency** | Excellent incremental updates | Requires periodic rebuilds | Essential for real-time indexing |\n| **Memory Efficiency** | 2-4x overhead | 1.1-1.5x overhead | Acceptable with proper provisioning |\n| **Implementation Complexity** | Moderate complexity | Simple implementation | Manageable with FAISS library |\n\n#### Hybrid Index Strategy\n\nWhile HNSW serves as the primary algorithm, the architecture supports a hybrid approach where different content types or access patterns can utilize different indexing strategies. Large archival collections with infrequent updates might benefit from IVF's memory efficiency, while real-time content requires HNSW's update performance.\n\nThe index selection logic evaluates collection characteristics to determine the optimal algorithm. Collections with high update rates, small to medium size (under 10 million documents), and latency-sensitive queries default to HNSW. Collections with low update rates, large size, and batch processing workflows may benefit from IVF indexing.\n\n### Index Persistence and Updates\n\nEfficient index persistence and incremental updates are critical for production deployment, enabling the system to maintain search availability while incorporating new documents and handling failures gracefully. The persistence strategy must balance durability, performance, and storage efficiency while supporting both planned and unplanned system restarts.\n\n#### Index Serialization and Storage Format\n\nThe index persistence system stores both the vector index structure and associated metadata required for proper reconstruction. FAISS provides native serialization support for both HNSW and IVF indices, but additional metadata tracking ensures consistency and enables version management.\n\n| Component | Storage Format | Size Characteristics | Persistence Frequency |\n|-----------|----------------|---------------------|----------------------|\n| **Vector Index** | FAISS binary format | 50-200 bytes per vector | Every 1000 updates or 5 minutes |\n| **Document Mapping** | JSON with compression | 100-500 bytes per document | Every 100 updates or 1 minute |\n| **Model Metadata** | JSON configuration | Fixed ~1KB | On model changes only |\n| **Update Log** | Binary append-only | 50 bytes per operation | Every update (real-time) |\n\nThe persistence format includes version headers that track the embedding model, index algorithm, and configuration parameters used during construction. This versioning enables safe index loading and prevents incompatibility issues when the system configuration changes.\n\n**Index Checkpoint Structure:**\n1. Header containing format version, algorithm type, and model information\n2. FAISS index binary data with complete graph structure or cluster assignments\n3. Document ID to index position mapping for efficient lookups\n4. Metadata including build timestamps, update counts, and performance statistics\n5. Configuration parameters used during index construction for reproducible builds\n\n#### Incremental Update Implementation\n\nThe incremental update system maintains index consistency while adding new documents without requiring complete reconstruction. HNSW naturally supports incremental updates through its graph-based structure, while IVF requires more sophisticated handling to maintain clustering quality.\n\n| Update Type | HNSW Handling | IVF Handling | Performance Impact |\n|-------------|---------------|--------------|-------------------|\n| **Add Document** | Insert into graph with neighbor linking | Add to nearest cluster, recompute if needed | Low (1-5ms) |\n| **Update Document** | Remove old, add new with same ID | Remove from old cluster, add to new | Medium (5-15ms) |\n| **Delete Document** | Mark as deleted, lazy cleanup | Remove from cluster, update statistics | Low (1-3ms) |\n| **Bulk Insert** | Batch neighbor computation | Recompute cluster assignments | High (seconds) |\n\nThe incremental update process maintains an update log that records all modifications since the last checkpoint. This log enables crash recovery and provides an audit trail for debugging index corruption issues. Updates are applied immediately to the in-memory index structure and periodically flushed to persistent storage.\n\n**Update Process Flow:**\n1. Validate new document and generate embedding using consistent model\n2. Acquire write lock on index structure to ensure consistency\n3. Apply update to in-memory index (add to graph or assign to cluster)\n4. Record update in persistent log with timestamp and operation details\n5. Update document ID mapping and metadata structures\n6. Release write lock and return success confirmation\n7. Periodically trigger background checkpoint creation for durability\n\n#### Index State Management and Recovery\n\nThe index lifecycle management system handles state transitions from initialization through active operation to shutdown, ensuring data consistency and enabling graceful recovery from failures.\n\n![Index Lifecycle State Machine](./diagrams/index-state-machine.svg)\n\n| State | Description | Allowed Transitions | Recovery Actions |\n|-------|-------------|-------------------|------------------|\n| **Initializing** | Loading persisted index or building new | → Training, → Active | Load checkpoint or start fresh build |\n| **Training** | Learning cluster centroids (IVF only) | → Active, → Failed | Complete training or restart from checkpoint |\n| **Active** | Serving queries and accepting updates | → Checkpointing, → Shutdown | Continue normal operation |\n| **Checkpointing** | Persisting index state to storage | → Active, → Failed | Complete checkpoint or retry |\n| **Failed** | Error state requiring intervention | → Initializing | Diagnose issue and restart |\n\nThe recovery system detects incomplete operations and determines the appropriate recovery action based on the update log and checkpoint state. If the most recent checkpoint is consistent but updates exist in the log, the system replays logged operations to restore the current state. If corruption is detected, the system falls back to the most recent valid checkpoint and discards potentially corrupted updates.\n\n> **Design Decision: Asynchronous Checkpointing**\n> - **Context**: Need to balance search availability with data durability requirements\n> - **Options Considered**: Synchronous checkpointing blocking updates, asynchronous background checkpointing, write-ahead logging with snapshots\n> - **Decision**: Implement asynchronous checkpointing with write-ahead logging for immediate update durability\n> - **Rationale**: Synchronous checkpointing creates unacceptable latency spikes, while asynchronous approach maintains performance with minimal durability risk\n> - **Consequences**: Slightly more complex recovery logic but much better user experience and system availability\n\n### Common Implementation Pitfalls\n\nUnderstanding and avoiding common implementation mistakes can save significant debugging time and prevent subtle correctness issues that are difficult to diagnose in production. These pitfalls represent the most frequent errors encountered when building vector search systems, along with their symptoms and solutions.\n\n#### ⚠️ **Pitfall: Vector Normalization Inconsistency**\n\nOne of the most critical and subtle errors involves inconsistent vector normalization between document embeddings and query embeddings. Cosine similarity calculations require all vectors to be normalized to unit length, but failing to apply normalization consistently leads to incorrect similarity scores and poor search results.\n\n**Why This Happens**: Developers often normalize document vectors during index construction but forget to normalize query vectors at search time, or vice versa. The embedding model may or may not produce normalized vectors depending on its training configuration, leading to assumptions that prove incorrect.\n\n**Symptoms**: Search results seem random, similar documents receive vastly different similarity scores, or the similarity score distribution doesn't match expected patterns (e.g., scores outside the [-1, 1] range for cosine similarity).\n\n**Detection Method**: Compare similarity scores between identical documents—they should be exactly 1.0 for cosine similarity with normalized vectors. Verify vector norms using `np.linalg.norm(embedding)` throughout the pipeline.\n\n**Prevention Strategy**: Apply normalization explicitly at every embedding generation point and verify vector norms during testing. Create unit tests that verify similarity calculations between known similar and dissimilar text pairs.\n\n```python\n# Correct approach - explicit normalization\ndef normalize_vector(vec: np.ndarray) -> np.ndarray:\n    \"\"\"L2 normalize vector to unit length for cosine similarity.\"\"\"\n    norm = np.linalg.norm(vec)\n    if norm == 0:\n        return vec  # Handle zero vector case\n    return vec / norm\n\n# Always normalize embeddings\nembedding = normalize_vector(model.encode(text))\n```\n\n#### ⚠️ **Pitfall: HNSW Memory Explosion with High M Parameter**\n\nThe HNSW `M` parameter controls the maximum number of connections per vector in the graph structure. Setting this value too high causes exponential memory growth that can exhaust available RAM, while setting it too low degrades search quality significantly.\n\n**Why This Happens**: Developers assume that higher `M` values always improve search quality and set values like 64 or 128 without understanding the memory implications. Each vector stores connections to up to `M` neighbors, and memory usage scales as `O(N * M)` where N is the number of vectors.\n\n**Symptoms**: Memory usage grows far beyond expected levels (e.g., 10-20x the raw vector data size), system becomes unresponsive due to memory pressure, or out-of-memory errors during index construction.\n\n**Calculation Example**: For 1 million 384-dimensional vectors with M=64:\n- Raw vector data: 1M × 384 × 4 bytes = 1.5 GB\n- HNSW connections: 1M × 64 × 8 bytes = 512 MB (just for connection storage)\n- Total memory usage: Often 8-15 GB due to additional metadata and overhead\n\n**Prevention Strategy**: Start with conservative values (M=16 for most use cases, M=32 for high-accuracy requirements) and measure memory usage empirically. Monitor memory growth during index construction and establish alerts for unexpected usage patterns.\n\n#### ⚠️ **Pitfall: Document ID Mapping Synchronization Issues**\n\nVector indices store vectors by internal position indices, but applications need to map these back to document IDs. Maintaining synchronization between the vector index positions and document ID mappings becomes critical, especially during incremental updates and deletions.\n\n**Why This Happens**: The FAISS index assigns sequential internal IDs to vectors, but these don't correspond to application document IDs. Developers create separate mapping structures but fail to maintain consistency during updates, particularly when handling deleted documents.\n\n**Symptoms**: Search returns wrong documents (ID mapping drift), missing results for documents that should exist, or crashes when trying to retrieve documents by returned IDs.\n\n**Prevention Strategy**: Implement atomic updates that modify both the vector index and ID mapping within the same transaction. Use consistent indexing schemes and validate mapping consistency during startup and after major operations.\n\n| Operation | Index Update | Mapping Update | Validation Check |\n|-----------|--------------|----------------|------------------|\n| **Add Document** | Insert vector at position N | Map doc_id → N | Verify doc exists at mapped position |\n| **Delete Document** | Mark position as deleted | Remove doc_id mapping | Verify doc_id not in mapping |\n| **Update Document** | Update vector at existing position | Maintain same mapping | Verify vector and mapping consistency |\n\n#### ⚠️ **Pitfall: IVF Training Data Insufficiency**\n\nIVF indices require a training phase where k-means clustering learns the optimal partitioning of the vector space. Using insufficient or unrepresentative training data leads to poor cluster quality and degraded search performance.\n\n**Why This Happens**: Developers train IVF indices on small samples (e.g., 1000 documents) or on documents from a narrow domain, then use the index for much larger or more diverse document collections. The resulting clusters don't represent the full vector space well.\n\n**Training Requirements**: Use at least 30-50 vectors per planned cluster (30K-50K training vectors for 1000 clusters) drawn representatively from the full document collection. Training data should span the complete range of content types and topics expected in production.\n\n**Symptoms**: Poor search quality despite high cluster counts, uneven cluster sizes with some clusters containing most documents, or degraded performance as the collection grows beyond the training distribution.\n\n**Prevention Strategy**: Reserve a representative sample of documents for training, ensure sample size meets minimum requirements, and retrain indices when the document collection characteristics change significantly.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Production Consideration |\n|-----------|---------------|-----------------|-------------------------|\n| **Embedding Model** | `sentence-transformers/all-MiniLM-L6-v2` | `sentence-transformers/all-mpnet-base-v2` | Balance speed vs. accuracy needs |\n| **Vector Index** | FAISS with HNSW (`IndexHNSWFlat`) | FAISS with GPU support (`IndexFlatIP`) | HNSW for most use cases |\n| **Persistence** | Pickle serialization | Custom binary format with compression | Consider security implications |\n| **Text Processing** | Basic regex cleaning | Advanced NLP preprocessing | Start simple, add complexity as needed |\n\n#### Recommended File/Module Structure\n\n```\nsemantic_search/\n  embeddings/\n    __init__.py                 ← Public interfaces\n    encoder.py                  ← DocumentEncoder and TextProcessor\n    index_manager.py           ← Index construction and persistence\n    faiss_wrapper.py           ← FAISS integration utilities\n    similarity.py              ← Vector similarity calculations\n  tests/\n    test_encoder.py            ← Embedding generation tests\n    test_index.py              ← Index operations tests\n    test_similarity.py         ← Similarity calculation tests\n  data/\n    models/                    ← Downloaded transformer models\n    indices/                   ← Persisted index files\n    documents/                 ← Sample documents for testing\n```\n\n#### Infrastructure Starter Code\n\n**Text Processing Utilities** (complete implementation):\n\n```python\n# semantic_search/embeddings/text_processing.py\nimport re\nimport html\nfrom typing import Optional\n\nclass TextProcessor:\n    \"\"\"Handles text cleaning and normalization for consistent embedding generation.\"\"\"\n    \n    def __init__(self):\n        self.url_pattern = re.compile(r'https?://[^\\s]+')\n        self.email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n        self.whitespace_pattern = re.compile(r'\\s+')\n        \n    def clean_text(self, text: str) -> str:\n        \"\"\"Normalize and clean text for embedding processing.\"\"\"\n        if not text:\n            return \"\"\n            \n        # Decode HTML entities\n        text = html.unescape(text)\n        \n        # Replace URLs with generic token\n        text = self.url_pattern.sub('[URL]', text)\n        \n        # Replace emails with generic token\n        text = self.email_pattern.sub('[EMAIL]', text)\n        \n        # Normalize whitespace\n        text = self.whitespace_pattern.sub(' ', text)\n        \n        # Remove control characters but preserve newlines and tabs\n        text = ''.join(char for char in text if ord(char) >= 32 or char in '\\n\\t')\n        \n        # Strip leading/trailing whitespace\n        return text.strip()\n\ndef get_searchable_text(document) -> str:\n    \"\"\"Extract searchable text from document with title weighting.\"\"\"\n    parts = []\n    \n    if document.title:\n        # Weight title by including it twice for emphasis\n        parts.extend([document.title, document.title])\n    \n    if document.content:\n        parts.append(document.content)\n        \n    return ' '.join(parts)\n```\n\n**Vector Utilities** (complete implementation):\n\n```python\n# semantic_search/embeddings/vector_utils.py\nimport numpy as np\nfrom typing import Union\n\ndef normalize_vector(vec: np.ndarray) -> np.ndarray:\n    \"\"\"L2 normalize vector to unit length for cosine similarity.\"\"\"\n    if vec.ndim == 1:\n        norm = np.linalg.norm(vec)\n        return vec / norm if norm > 0 else vec\n    else:\n        # Handle batch of vectors\n        norms = np.linalg.norm(vec, axis=1, keepdims=True)\n        return vec / np.where(norms > 0, norms, 1)\n\ndef cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n    \"\"\"Compute cosine similarity between two normalized vectors.\"\"\"\n    # Assume vectors are already normalized\n    return float(np.dot(vec1, vec2))\n\ndef batch_cosine_similarity(query_vec: np.ndarray, doc_vecs: np.ndarray) -> np.ndarray:\n    \"\"\"Compute cosine similarities between query and multiple document vectors.\"\"\"\n    # All vectors should be normalized\n    return np.dot(doc_vecs, query_vec)\n```\n\n#### Core Logic Skeleton Code\n\n**Document Encoder** (structure with TODOs):\n\n```python\n# semantic_search/embeddings/encoder.py\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nfrom typing import List, Optional\nfrom .text_processing import TextProcessor, get_searchable_text\nfrom .vector_utils import normalize_vector\n\nDEFAULT_MODEL = 'all-MiniLM-L6-v2'\nEMBEDDING_DIM = 384\n\nclass DocumentEncoder:\n    \"\"\"Converts documents and queries to vector embeddings using transformer models.\"\"\"\n    \n    def __init__(self, model_name: str = DEFAULT_MODEL):\n        # TODO 1: Initialize SentenceTransformer model with model_name\n        # TODO 2: Set embedding_dim by encoding a test string and checking shape\n        # TODO 3: Create TextProcessor instance for preprocessing\n        # TODO 4: Store model_name for metadata tracking\n        pass\n    \n    def encode_document(self, document) -> 'DocumentEmbedding':\n        \"\"\"Convert document to vector embedding with metadata.\"\"\"\n        # TODO 1: Extract searchable text using get_searchable_text()\n        # TODO 2: Clean text using text_processor.clean_text()\n        # TODO 3: Generate embedding using self.model.encode()\n        # TODO 4: Normalize embedding vector using normalize_vector()\n        # TODO 5: Create DocumentEmbedding object with document, embedding, model info\n        # TODO 6: Validate embedding dimensions match expected EMBEDDING_DIM\n        pass\n    \n    def encode_texts(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Batch encode multiple texts for efficiency.\"\"\"\n        # TODO 1: Clean all texts using text processor\n        # TODO 2: Use model.encode() with batch processing\n        # TODO 3: Normalize all embedding vectors\n        # TODO 4: Validate output shape is (len(texts), embedding_dim)\n        # Hint: Batching improves performance for multiple texts\n        pass\n    \n    def encode_query(self, query_text: str) -> np.ndarray:\n        \"\"\"Encode search query using same model as documents.\"\"\"\n        # TODO 1: Clean query text using text processor\n        # TODO 2: Generate embedding using model (same as document encoding)\n        # TODO 3: Normalize embedding vector\n        # TODO 4: Return numpy array with shape (embedding_dim,)\n        pass\n```\n\n**Index Manager** (structure with TODOs):\n\n```python\n# semantic_search/embeddings/index_manager.py\nimport faiss\nimport numpy as np\nimport pickle\nfrom typing import Dict, List, Optional, Tuple\nimport logging\n\nclass HNSWIndexManager:\n    \"\"\"Manages HNSW index construction, persistence, and incremental updates.\"\"\"\n    \n    def __init__(self, embedding_dim: int = EMBEDDING_DIM, M: int = 16):\n        # TODO 1: Store embedding_dim and validate it's positive\n        # TODO 2: Create FAISS HNSW index using faiss.IndexHNSWFlat()\n        # TODO 3: Set HNSW parameters (M=16, efConstruction=200)\n        # TODO 4: Initialize document ID mapping dictionary\n        # TODO 5: Initialize update counter for checkpoint triggering\n        pass\n    \n    def add_documents(self, embeddings: List['DocumentEmbedding']) -> None:\n        \"\"\"Add document embeddings to index with ID tracking.\"\"\"\n        # TODO 1: Extract embedding vectors into numpy array\n        # TODO 2: Validate all embeddings have correct dimensionality\n        # TODO 3: Add vectors to FAISS index using index.add()\n        # TODO 4: Update document ID mapping for each added document\n        # TODO 5: Increment update counter and trigger checkpoint if needed\n        # Hint: FAISS assigns sequential internal IDs starting from current size\n        pass\n    \n    def search_similar(self, query_embedding: np.ndarray, k: int = 10) -> List[Tuple[str, float]]:\n        \"\"\"Find k most similar documents to query embedding.\"\"\"\n        # TODO 1: Validate query embedding dimensions\n        # TODO 2: Reshape query to (1, embedding_dim) for FAISS\n        # TODO 3: Search index using index.search() method\n        # TODO 4: Convert internal IDs to document IDs using mapping\n        # TODO 5: Return list of (document_id, similarity_score) tuples\n        # TODO 6: Handle case where fewer than k documents exist\n        pass\n    \n    def save_index(self, filepath: str) -> None:\n        \"\"\"Persist index and metadata to disk.\"\"\"\n        # TODO 1: Save FAISS index using faiss.write_index()\n        # TODO 2: Save document ID mapping using pickle\n        # TODO 3: Save metadata (dimensions, model info) separately\n        # TODO 4: Implement atomic save (write to temp file, then rename)\n        # Hint: Use faiss.write_index() for the vector index\n        pass\n    \n    def load_index(self, filepath: str) -> None:\n        \"\"\"Load persisted index and metadata from disk.\"\"\"\n        # TODO 1: Load FAISS index using faiss.read_index()\n        # TODO 2: Load document ID mapping from pickle file\n        # TODO 3: Validate loaded index dimensions match expected\n        # TODO 4: Restore update counter and other metadata\n        # TODO 5: Verify index consistency (mapping size matches index size)\n        pass\n```\n\n#### Language-Specific Hints\n\n- Use `sentence-transformers` library for embedding generation: `pip install sentence-transformers`\n- Install FAISS for vector indexing: `pip install faiss-cpu` (or `faiss-gpu` for GPU support)\n- Use `numpy` arrays for all vector operations—avoid Python lists for performance\n- Consider using `concurrent.futures` for parallel document processing during bulk operations\n- Use `logging` module to track index operations and debug issues\n- Implement proper exception handling for model loading and FAISS operations\n\n#### Milestone Checkpoint\n\nAfter implementing the embedding index component, verify functionality with these tests:\n\n**Test Command**: `python -m pytest tests/test_embedding_index.py -v`\n\n**Expected Behaviors**:\n1. Document encoder should generate consistent embeddings for identical text\n2. Index should support adding documents and retrieving them by similarity\n3. Saved indices should load correctly and preserve search functionality\n4. Similarity scores should be in valid ranges (0-1 for cosine similarity)\n\n**Manual Verification Steps**:\n```bash\n# Test embedding generation\npython -c \"\nfrom embeddings.encoder import DocumentEncoder\nencoder = DocumentEncoder()\ndoc1_emb = encoder.encode_query('machine learning algorithms')\ndoc2_emb = encoder.encode_query('artificial intelligence models')\nprint(f'Embedding dim: {doc1_emb.shape[0]}')\nprint(f'Similarity: {np.dot(doc1_emb, doc2_emb):.3f}')\n\"\n\n# Test index operations\npython -c \"\nfrom embeddings.index_manager import HNSWIndexManager\nindex = HNSWIndexManager()\n# Add some test documents and search\n\"\n```\n\n**Signs of Problems**:\n- Embeddings have wrong dimensions (should be 384 for default model)\n- Similarity scores outside [0,1] range indicate normalization issues\n- Index search returns wrong number of results or throws exceptions\n- Memory usage much higher than expected indicates parameter issues\n\n\n## Query Processing Component\n\n> **Milestone(s):** Milestone 2: Query Processing\n\nThe **Query Processing Component** represents the intelligence layer that sits between raw user input and our embedding index, transforming simple search queries into rich semantic representations. While our embedding index excels at finding similar vectors, the query processor ensures we're searching for the right thing by understanding user intent, expanding vocabulary, and preparing queries for optimal retrieval performance.\n\n### Query Understanding Mental Model: Translator Analogy for How Queries Are Interpreted and Enhanced\n\nThink of the query processor as a skilled translator working at the United Nations. When a delegate speaks, the translator doesn't just convert words directly from one language to another. Instead, they understand the speaker's intent, cultural context, and implied meanings, then craft a message that conveys the full semantic richness to the audience. They might expand abbreviations, clarify ambiguous terms, and even split complex statements into multiple concepts to ensure nothing is lost in translation.\n\n![Query Processing Pipeline](./diagrams/query-processing-flow.svg)\n\nSimilarly, our query processor takes a user's brief search query and translates it into a rich semantic representation that our vector index can understand. A query like \"ML algorithms\" doesn't just become one vector embedding. The processor recognizes that \"ML\" expands to \"machine learning,\" identifies related concepts like \"artificial intelligence\" and \"neural networks,\" and prepares multiple query vectors to capture different aspects of what the user might be seeking.\n\nThe translator analogy extends to handling ambiguity and context. When someone searches for \"python,\" are they interested in the programming language, the snake, or the comedy group? A skilled query processor, like a good translator, uses surrounding context and user history to disambiguate and focus the search appropriately.\n\n**Query Processing Responsibilities**\n\nThe query processor owns several critical transformations that bridge the gap between human language and machine understanding:\n\n| Responsibility | Input | Output | Purpose |\n|---|---|---|---|\n| **Text Normalization** | Raw query string | Cleaned, standardized text | Remove noise, standardize formatting |\n| **Intent Recognition** | Normalized query | Query intent classification | Understand what type of search this is |\n| **Entity Extraction** | Query text | Named entities and types | Identify specific people, places, concepts |\n| **Query Expansion** | Original terms | Expanded term set | Add synonyms and related concepts |\n| **Vector Embedding** | Processed query | Dense vector representation | Convert to searchable embedding |\n| **Multi-Vector Composition** | Query aspects | Combined query vectors | Handle complex queries with multiple facets |\n| **Cache Management** | Query embeddings | Cached vectors | Optimize repeated query performance |\n\n> **Design Insight:** The query processor is where linguistic understanding meets computational efficiency. Every enhancement we add improves search quality but also increases latency. The key architectural challenge is determining which query understanding steps provide the highest quality improvement per millisecond of added processing time.\n\n### Query Expansion Strategy: Adding Synonyms and Related Terms While Avoiding Over-Expansion\n\nQuery expansion addresses one of the fundamental challenges in information retrieval: **vocabulary mismatch**. Users often search using different terminology than what appears in relevant documents. A user might search for \"car repair\" while the best document uses \"automotive maintenance\" or \"vehicle service.\" Without query expansion, these semantically identical concepts would score poorly in both lexical and semantic search.\n\n**Architecture Decision: Hybrid Expansion Approach**\n\n> **Decision: Multi-Strategy Query Expansion**\n> - **Context**: Users and documents often use different vocabulary for the same concepts, leading to relevant documents being missed due to terminology misalignment\n> - **Options Considered**: \n>   1. WordNet-based synonym expansion\n>   2. Embedding similarity expansion\n>   3. Corpus-specific term co-occurrence expansion\n> - **Decision**: Implement a hybrid approach combining embedding similarity with corpus-specific co-occurrence patterns\n> - **Rationale**: WordNet provides broad coverage but lacks domain specificity. Embedding similarity captures semantic relationships but can drift from original intent. Corpus co-occurrence grounds expansion in actual document vocabulary.\n> - **Consequences**: Requires maintaining co-occurrence statistics and careful weight balancing, but provides more relevant and domain-appropriate expansions\n\n| Expansion Strategy | Coverage | Domain Adaptation | Computational Cost | Drift Risk |\n|---|---|---|---|---|\n| **WordNet Synonyms** | High | Low | Low | Medium |\n| **Embedding Similarity** | Medium | Medium | Medium | High |\n| **Corpus Co-occurrence** | Medium | High | High | Low |\n| **Hybrid Approach** | High | High | Medium | Low |\n\n**Query Expansion Pipeline**\n\nThe expansion process follows a carefully orchestrated sequence designed to enhance recall while preserving the original query intent:\n\n1. **Original Query Analysis**: Parse the input query to identify core terms, phrases, and any special operators (quotes, negation, filters). Extract the primary intent and key concepts that must be preserved throughout expansion.\n\n2. **Term Importance Scoring**: Calculate importance weights for each term based on inverse document frequency (IDF) and position within the query. High-importance terms (rare, specific concepts) receive conservative expansion to maintain precision, while common terms receive broader expansion to improve recall.\n\n3. **Synonym Generation**: For each term, generate synonyms using multiple strategies. Embedding-based expansion finds terms with similar vector representations in our semantic space. Corpus co-occurrence identifies terms that frequently appear together in our document collection, indicating semantic relationships.\n\n4. **Expansion Filtering**: Apply several filters to prevent expansion drift. Semantic similarity thresholds ensure expanded terms remain conceptually related to originals. Context compatibility checks verify that expanded terms make sense within the query's overall meaning. Domain relevance scoring prioritizes expansions that align with our document corpus.\n\n5. **Expansion Weight Assignment**: Assign confidence weights to expanded terms based on their similarity to original terms and frequency of co-occurrence in relevant documents. Original query terms receive weight 1.0, while expanded terms receive weights between 0.1 and 0.8 depending on confidence.\n\n6. **Query Reconstruction**: Combine original and expanded terms into an enhanced query representation that maintains the logical structure of the original while incorporating semantic expansions.\n\n**Query Expansion Data Structures**\n\n| Field Name | Type | Description |\n|---|---|---|\n| `original_query` | `str` | The unmodified user input query |\n| `core_terms` | `List[str]` | Main concepts extracted from query |\n| `expansion_candidates` | `Dict[str, List[Tuple[str, float]]]` | Term -> [(synonym, confidence), ...] |\n| `expanded_terms` | `List[Tuple[str, float, str]]` | (term, weight, source_strategy) |\n| `filtered_expansions` | `List[Tuple[str, float]]` | Final expanded terms after filtering |\n| `expansion_metadata` | `Dict[str, Any]` | Debug info and expansion statistics |\n\n**Avoiding Over-Expansion**\n\nOver-expansion represents one of the most critical pitfalls in query enhancement. When expansion adds too many terms or strays too far from the original intent, search results become unfocused and relevance suffers dramatically.\n\n⚠️ **Pitfall: Semantic Drift Through Excessive Expansion**\n\nA common mistake is applying expansion recursively or using overly permissive similarity thresholds. For example, expanding \"python programming\" → \"snake\" → \"reptile\" → \"animal\" creates a chain that completely loses the original computational context. This happens when expansion algorithms don't maintain connection to the root query intent.\n\n**Fix**: Implement expansion budgets and semantic anchoring. Limit each query to a maximum expansion ratio (e.g., no more than 3 expanded terms per original term), and require all expanded terms to maintain minimum similarity to at least one original term.\n\n⚠️ **Pitfall: Domain Confusion**\n\nAnother frequent issue occurs when general-purpose expansion resources (like WordNet) suggest terms that are technically synonymous but inappropriate for the specific domain. Searching for \"python classes\" might expand to include \"social classes\" or \"economic classes,\" introducing irrelevant results from sociology documents.\n\n**Fix**: Train domain-specific expansion models on your document corpus, and filter expansion candidates through domain relevance scoring before applying them to queries.\n\nThe expansion system maintains careful balance through configurable parameters that can be tuned based on user feedback and search quality metrics:\n\n| Parameter | Purpose | Typical Range | Impact |\n|---|---|---|---|\n| `max_expansions_per_term` | Prevent explosion | 2-5 | Controls expansion volume |\n| `min_similarity_threshold` | Maintain relevance | 0.6-0.8 | Filters weak relationships |\n| `expansion_weight_decay` | Balance original vs expanded | 0.3-0.7 | Controls expansion influence |\n| `domain_relevance_threshold` | Ensure corpus alignment | 0.4-0.6 | Prevents domain drift |\n\n### Semantic Query Analysis: Entity extraction and Intent Understanding from Query Text\n\nBeyond simple term expansion, sophisticated query processing requires understanding the semantic structure and intent behind user queries. This involves recognizing named entities (people, places, organizations, dates), understanding query types (factual lookup, exploratory browsing, specific document retrieval), and extracting the underlying information need that the user is trying to satisfy.\n\n**Entity Recognition and Extraction**\n\nNamed entity recognition (NER) within queries serves multiple purposes in semantic search. First, it identifies terms that should not be expanded or modified during query processing—proper names like \"Barack Obama\" or \"Microsoft\" have specific, fixed meanings that expansion could distort. Second, entity recognition enables entity-specific search strategies, such as boosting documents that contain exact entity matches or applying entity-type filters.\n\nThe entity extraction pipeline processes queries through several specialized recognition stages:\n\n1. **Standard Named Entity Recognition**: Apply pre-trained NER models to identify common entity types including persons, organizations, locations, dates, and monetary amounts. These entities receive special handling during expansion and embedding generation.\n\n2. **Technical Term Identification**: Recognize domain-specific entities like software names, technical acronyms, model numbers, and scientific terminology that require exact matching rather than semantic similarity. This prevents expansion of terms like \"GPT-3\" or \"TCP/IP\" which would lose their specific meaning.\n\n3. **Temporal Expression Parsing**: Extract and normalize time-related expressions like \"last week,\" \"2023,\" or \"recent\" into structured temporal constraints that can be applied as filters rather than semantic queries.\n\n4. **Entity Relationship Detection**: Identify relationships between entities within the query, such as \"CEO of Microsoft\" or \"papers by Einstein,\" which indicate structured queries that benefit from knowledge graph enhancement.\n\n| Entity Type | Recognition Method | Search Strategy | Example |\n|---|---|---|---|\n| **Person Names** | NER + Name Dictionary | Exact + Alias Matching | \"Barack Obama\", \"Obama\" |\n| **Organizations** | NER + Known Entity DB | Exact + Subsidiary Matching | \"Microsoft\", \"MS\" |\n| **Locations** | NER + Gazetteer | Geographic Expansion | \"SF\" → \"San Francisco\" |\n| **Technical Terms** | Domain Dictionary | Exact Matching Only | \"React.js\", \"COVID-19\" |\n| **Dates/Times** | Temporal Parser | Range Constraints | \"2023\" → date filter |\n| **Products/Models** | Pattern Recognition | Exact + Version Matching | \"iPhone 14\", \"GPT-3\" |\n\n**Query Intent Classification**\n\nUnderstanding query intent allows the system to apply appropriate search strategies and result formatting. Different intent types benefit from different combinations of semantic similarity, lexical matching, and result ranking approaches.\n\n**Intent Classification Framework**\n\nThe system recognizes several primary intent categories, each requiring different search and ranking strategies:\n\n| Intent Type | Characteristics | Search Strategy | Example Queries |\n|---|---|---|---|\n| **Factual Lookup** | Specific answer sought | Precise matching + knowledge extraction | \"what is the capital of France\" |\n| **Exploratory Browse** | Topic exploration | Broad semantic similarity | \"machine learning techniques\" |\n| **Document Retrieval** | Specific document sought | Combined lexical/semantic | \"Smith 2023 neural networks paper\" |\n| **Comparative Analysis** | Multiple entity comparison | Multi-entity semantic search | \"React vs Angular performance\" |\n| **Procedural How-to** | Step-by-step instructions | Task-oriented matching | \"how to install Docker\" |\n| **Definitional** | Concept explanation | Authority source boosting | \"what is quantum computing\" |\n\n**Intent Detection Pipeline**\n\nIntent classification combines multiple signal sources to determine the most likely user intent:\n\n1. **Syntactic Pattern Analysis**: Examine query structure for intent indicators like question words (\"what,\" \"how,\" \"why\"), comparative terms (\"vs,\" \"better than\"), or action verbs (\"install,\" \"configure,\" \"troubleshoot\").\n\n2. **Semantic Intent Modeling**: Apply trained classifiers that understand the semantic patterns associated with different intent types, trained on query-intent pairs from search logs or manually labeled data.\n\n3. **Entity-Intent Correlation**: Use entity types and relationships to infer intent. Queries containing multiple competing entities likely indicate comparison intent, while queries with single technical entities suggest definitional or procedural intent.\n\n4. **Context Integration**: Incorporate user context such as previous queries in the session, user profile information, and temporal context to disambiguate ambiguous intent signals.\n\n**Semantic Query Structure Analysis**\n\nBeyond entities and intent, the query processor analyzes the semantic structure of queries to understand relationships between concepts and optimize vector representation generation.\n\n**Query Decomposition Strategy**\n\nComplex queries often contain multiple semantic concepts that benefit from separate vector representations. The decomposition process identifies these concepts and determines how to combine their embeddings:\n\n1. **Concept Boundary Detection**: Identify natural breakpoints in queries where different concepts begin and end. Linguistic cues include conjunctions (\"and,\" \"or\"), prepositional phrases, and semantic topic shifts.\n\n2. **Concept Importance Weighting**: Assign importance scores to different query concepts based on specificity, user emphasis (capitalization, quotes), and position within the query structure.\n\n3. **Relationship Identification**: Determine how concepts relate to each other—whether they're additive (both concepts must be present), alternative (either concept acceptable), or hierarchical (one concept constrains the other).\n\n4. **Vector Composition Planning**: Decide whether to generate a single combined embedding or multiple concept-specific embeddings that will be composed during search.\n\n> **Design Insight:** The semantic analysis phase represents a critical trade-off between query understanding depth and processing latency. Each additional analysis step improves search quality but adds milliseconds to query processing time. The architecture prioritizes analyses that provide the highest quality improvement per unit of added latency.\n\n### Multi-Vector Query Support: Combining Multiple Query Aspects and Handling Negative Terms\n\nComplex user information needs often cannot be captured by a single vector embedding. A query like \"machine learning papers published after 2020 but not about computer vision\" contains multiple distinct aspects: a semantic concept (machine learning), a temporal constraint (after 2020), and a negative semantic constraint (excluding computer vision). Multi-vector query support enables the system to represent and search using these complex, multi-faceted requirements.\n\n**Multi-Vector Query Architecture**\n\nThe multi-vector approach decomposes complex queries into separate vector representations, each capturing a different aspect of the user's information need. These vectors are then combined during search using vector arithmetic and weighted scoring to produce results that satisfy all query aspects simultaneously.\n\n**Architecture Decision: Additive Vector Composition vs. Separate Retrieval Paths**\n\n> **Decision: Hybrid Multi-Vector Architecture**\n> - **Context**: Complex queries contain multiple concepts that interact differently—some require additive combination while others need separate retrieval and intersection\n> - **Options Considered**:\n>   1. Pure vector arithmetic (add/subtract embeddings)\n>   2. Separate retrieval with result intersection  \n>   3. Hybrid approach with both arithmetic and retrieval strategies\n> - **Decision**: Implement hybrid architecture that chooses composition strategy based on query analysis\n> - **Rationale**: Vector arithmetic works well for closely related concepts but fails for orthogonal constraints like temporal filters. Separate retrieval provides precise control but is computationally expensive. Hybrid approach applies the optimal strategy per query aspect.\n> - **Consequences**: Increases implementation complexity but provides superior result quality for complex queries while maintaining reasonable performance\n\n**Query Aspect Identification**\n\nThe multi-vector pipeline begins by analyzing queries to identify distinct aspects that warrant separate vector representation:\n\n1. **Semantic Concept Extraction**: Identify the primary semantic concepts within the query. These represent the main topical areas the user is interested in and typically become positive vector embeddings.\n\n2. **Constraint Classification**: Separate semantic concepts from structural constraints like temporal filters, format requirements, or source restrictions. Constraints often cannot be effectively represented as embeddings and require separate handling.\n\n3. **Negation Detection**: Identify negative terms introduced by words like \"not,\" \"except,\" \"without,\" or \"excluding.\" Negative concepts require special handling since vector subtraction can produce counterintuitive results.\n\n4. **Relationship Analysis**: Determine how different aspects relate—whether they should be combined additively, whether one constrains another, or whether they represent alternative acceptable concepts.\n\n| Aspect Type | Vector Treatment | Search Strategy | Example |\n|---|---|---|---|\n| **Primary Concepts** | Positive embedding | Direct similarity search | \"machine learning\" |\n| **Secondary Concepts** | Weighted positive embedding | Boost matching results | \"neural networks\" |\n| **Negative Concepts** | Exclusion filter | Post-retrieval filtering | \"not computer vision\" |\n| **Temporal Constraints** | Metadata filter | Pre-retrieval filtering | \"after 2020\" |\n| **Format Constraints** | Document type filter | Pre-retrieval filtering | \"research papers\" |\n| **Source Constraints** | Metadata filter | Pre-retrieval filtering | \"from arxiv.org\" |\n\n**Vector Arithmetic Strategies**\n\nWhen multiple semantic concepts can be meaningfully combined through vector operations, the system applies carefully designed arithmetic strategies that preserve semantic meaning while combining multiple information aspects.\n\n**Positive Concept Combination**\n\nMultiple positive concepts are combined using weighted vector addition, where weights reflect the relative importance of each concept within the overall query:\n\n1. **Equal Weight Addition**: When concepts have similar importance, vectors are added with equal weights. This works well for queries like \"machine learning and artificial intelligence\" where both concepts are equally relevant.\n\n2. **Importance-Weighted Addition**: When one concept is more central than others, primary concepts receive higher weights. For \"deep learning optimization techniques,\" the deep learning vector might receive weight 0.6 while optimization receives 0.4.\n\n3. **Hierarchical Composition**: When concepts have hierarchical relationships, the broader concept provides the foundation while specific concepts add refinement. \"Computer science education methods\" combines a broad CS education base with specific methods refinement.\n\n**Negative Term Handling**\n\nNegative terms present unique challenges in vector-based search because simple vector subtraction often produces semantically meaningless results or even reverses query meaning entirely.\n\n⚠️ **Pitfall: Naive Vector Subtraction**\n\nA common mistake is directly subtracting negative concept embeddings from positive ones. For example, computing `embedding(\"animals\") - embedding(\"dogs\")` doesn't produce a meaningful \"animals except dogs\" vector—it often results in a vector that points toward concepts completely unrelated to animals.\n\n**Fix**: Use negative terms for post-retrieval filtering rather than vector arithmetic. Retrieve candidates using positive concepts, then apply negative concepts as exclusion filters on the candidate set.\n\n**Negative Term Processing Pipeline**\n\nThe system handles negative terms through a multi-stage approach that avoids the pitfalls of vector subtraction:\n\n1. **Negative Term Identification**: Parse queries to identify negative indicators and extract the concepts they negate. Handle both explicit negation (\"not dogs\") and implicit negation (\"cats except Persian breeds\").\n\n2. **Positive Vector Generation**: Generate search vectors using only positive concepts, ignoring negative terms during the initial embedding phase.\n\n3. **Negative Concept Modeling**: Create separate embeddings for negative concepts that will be used for similarity-based exclusion during result filtering.\n\n4. **Exclusion Threshold Calibration**: Determine appropriate similarity thresholds for excluding results that match negative concepts. This typically requires lower thresholds than positive matching to avoid over-aggressive filtering.\n\n**Multi-Vector Search Execution**\n\nDuring search execution, multi-vector queries follow a carefully orchestrated process that maximizes result quality while maintaining reasonable performance:\n\n1. **Primary Vector Retrieval**: Execute the main search using the primary positive concept embedding to retrieve an initial candidate set. This set should be larger than the final result count to allow for effective filtering.\n\n2. **Secondary Vector Scoring**: For each candidate, compute similarity scores against secondary positive concept embeddings. These scores are combined with primary scores using learned or configured weights.\n\n3. **Negative Filtering**: Apply negative concept filters by computing similarity between candidates and negative concept embeddings. Remove candidates that exceed negative similarity thresholds.\n\n4. **Constraint Application**: Apply non-semantic constraints like temporal, format, or source filters to the remaining candidate set.\n\n5. **Score Composition**: Combine similarity scores from multiple positive vectors using the query's composition strategy (additive, weighted average, maximum, etc.).\n\n| Multi-Vector Query Component | Data Structure | Purpose |\n|---|---|---|---|\n| `positive_concepts` | `List[Tuple[str, float, np.ndarray]]` | (concept, weight, embedding) for positive terms |\n| `negative_concepts` | `List[Tuple[str, float, np.ndarray]]` | (concept, threshold, embedding) for exclusion |\n| `metadata_filters` | `Dict[str, Any]` | Non-semantic constraints (date, type, source) |\n| `composition_strategy` | `str` | How to combine multiple positive vectors |\n| `retrieval_size` | `int` | Initial candidate set size before filtering |\n\n### Query Embedding Cache: Caching Frequent Query Embeddings for Performance\n\nQuery embedding generation represents one of the most computationally expensive operations in semantic search. Converting text to high-dimensional vectors requires forward passes through transformer neural networks, which can add 50-200 milliseconds per query depending on model size and hardware. For production search systems serving thousands of queries per second, this latency is unacceptable without aggressive caching strategies.\n\n**Cache Architecture and Design**\n\nThe query embedding cache sits between query processing and the embedding generation pipeline, intercepting frequent queries and serving pre-computed embeddings instantly. The cache design must balance hit rate optimization with memory efficiency while handling the complexities of multi-vector queries and query variations.\n\n**Architecture Decision: Multi-Level Cache Hierarchy**\n\n> **Decision: Implement Three-Tier Query Cache Architecture**\n> - **Context**: Query embedding generation is expensive (50-200ms) but many queries repeat or have similar patterns that could benefit from caching at different granularities\n> - **Options Considered**:\n>   1. Simple query string cache with exact matching\n>   2. Normalized query cache with text preprocessing\n>   3. Multi-level cache with exact, normalized, and component-level caching\n> - **Decision**: Implement three-tier hierarchy: exact string cache → normalized query cache → query component cache\n> - **Rationale**: Exact matching handles perfect repeats (highest hit rate, lowest complexity). Normalized cache handles variation in formatting/spacing. Component cache enables reuse of individual concepts across different queries.\n> - **Consequences**: Higher implementation complexity but dramatically improved cache efficiency, especially for complex multi-vector queries with reusable components\n\n**Cache Level Architecture**\n\n| Cache Level | Key Type | Value Type | Hit Rate | Latency Reduction |\n|---|---|---|---|---|\n| **Exact String Cache** | Raw query string | Complete embedding result | High for popular queries | 100% (0ms lookup) |\n| **Normalized Cache** | Cleaned/normalized query | Complete embedding result | Medium | 95% (5ms normalization) |\n| **Component Cache** | Individual concepts | Single concept embedding | High for concept reuse | 70% (composition required) |\n\n**Exact String Cache Implementation**\n\nThe first cache tier maintains a direct mapping from raw query strings to complete embedding results. This handles the most common case where users repeat identical searches or where popular queries appear frequently across different users.\n\n**Cache Key Generation and Normalization**\n\nFor the normalized cache tier, the system must carefully balance cache hit rate with semantic equivalence:\n\n1. **Whitespace Normalization**: Remove extra spaces, normalize tabs and newlines to spaces, trim leading/trailing whitespace. This catches formatting variations without changing semantic meaning.\n\n2. **Case Normalization**: Convert to lowercase unless the query contains proper nouns or technical terms where case carries meaning (like \"SQL\" vs \"sql\" or \"US\" vs \"us\").\n\n3. **Punctuation Standardization**: Normalize punctuation while preserving meaning-bearing punctuation like quotation marks for exact phrases or hyphens in technical terms.\n\n4. **Stop Word Handling**: Decide whether to normalize or preserve stop words based on their semantic contribution to the specific query context.\n\n**Component-Level Caching**\n\nThe most sophisticated cache tier stores embeddings for individual query components, enabling reuse across different queries that share common concepts:\n\n1. **Component Identification**: Extract cacheable components from queries, including individual concepts, entity mentions, and common phrase patterns that appear across multiple queries.\n\n2. **Component Embedding Storage**: Maintain separate embeddings for each component along with metadata about embedding model, generation timestamp, and usage statistics.\n\n3. **Component Composition**: When a cache miss occurs at higher levels, attempt to construct the full query embedding by combining cached components with only the novel portions requiring fresh embedding generation.\n\n4. **Component Lifecycle Management**: Track component usage patterns and age out rarely-used components while prioritizing retention of frequently-reused concepts.\n\n**Cache Invalidation and Consistency**\n\nQuery embedding caches face unique challenges around invalidation because the underlying embedding models may change, affecting the validity of cached vectors:\n\n⚠️ **Pitfall: Stale Embeddings After Model Updates**\n\nA critical error occurs when embedding models are updated or retrained but cached embeddings from the previous model remain in use. This creates inconsistencies where some queries use new model embeddings while cached queries use old embeddings, leading to incomparable similarity scores and poor result quality.\n\n**Fix**: Implement model version tracking in cache keys and invalidate all cached embeddings when the underlying embedding model changes. Include model fingerprints or version hashes in cache metadata to detect model mismatches.\n\n**Cache Invalidation Strategies**\n\n| Invalidation Trigger | Scope | Strategy | Recovery Time |\n|---|---|---|---|\n| **Embedding Model Update** | Full cache clear | Immediate invalidation | 24-48 hours for rebuild |\n| **Query Processing Logic Change** | Affected query patterns | Selective invalidation | 2-4 hours for rebuild |\n| **Memory Pressure** | Least recently used entries | LRU eviction | Immediate (regenerate on demand) |\n| **Time-Based Expiration** | Entries older than threshold | TTL expiration | Continuous background refresh |\n\n**Cache Performance Optimization**\n\nThe cache implementation must be optimized for high-throughput, low-latency access patterns typical of production search systems:\n\n1. **Memory Layout Optimization**: Store embeddings in contiguous memory layouts that enable efficient similarity computations without additional copying or transformation overhead.\n\n2. **Concurrent Access Patterns**: Support high levels of concurrent reads while minimizing lock contention during cache updates. Use read-write locks or lock-free data structures where appropriate.\n\n3. **Pre-warming Strategies**: Identify and pre-compute embeddings for predictably popular queries based on historical query patterns, seasonal trends, or trending topics.\n\n4. **Cache Size Management**: Balance cache size against available memory, using techniques like probabilistic data structures to estimate optimal cache sizes and track cache efficiency metrics.\n\n**Cache Monitoring and Analytics**\n\nEffective cache management requires comprehensive monitoring of cache performance and query patterns:\n\n| Metric | Purpose | Target Range | Alert Threshold |\n|---|---|---|---|\n| **Cache Hit Rate** | Overall cache effectiveness | 60-80% | Below 50% |\n| **Average Lookup Latency** | Cache performance | <5ms | >10ms |\n| **Memory Utilization** | Resource efficiency | 70-90% | >95% |\n| **Invalidation Rate** | Cache stability | <5% daily | >20% daily |\n| **Component Reuse Rate** | Component cache value | 40-60% | <30% |\n\n> **Performance Insight:** Query embedding caching typically provides 10-50x latency reduction for cache hits, transforming 100ms embedding generation into 2-10ms cache lookups. The investment in sophisticated cache architecture pays dividends through dramatically improved user experience and reduced computational costs.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Query Expansion Explosion**\n\nOverly aggressive query expansion can transform focused queries into broad, unfocused searches. This often happens when expansion algorithms recursively apply themselves or use overly permissive similarity thresholds. A query for \"python programming\" might expand to include \"snake,\" \"reptile,\" and eventually \"animal,\" completely losing the computational context.\n\n**Detection**: Monitor average expansion ratios and result relevance scores. Queries with >5 expanded terms per original term or declining click-through rates indicate over-expansion.\n\n**Fix**: Implement expansion budgets (max 3 expanded terms per original), semantic anchoring (all expansions must maintain >0.6 similarity to original terms), and domain relevance filtering.\n\n⚠️ **Pitfall: Entity Over-Normalization**\n\nAggressive text normalization can destroy important semantic distinctions in entity names and technical terms. Converting \"SQL\" to \"sql\" or normalizing \"COVID-19\" to \"covid\" loses critical specificity that affects search precision.\n\n**Detection**: Track queries with low result relevance despite high query frequency. Monitor for complaints about missing results for technical or proper noun queries.\n\n**Fix**: Implement context-aware normalization that preserves case for known entities, technical terms, and acronyms. Maintain entity dictionaries for domain-specific preservation rules.\n\n⚠️ **Pitfall: Cache Inconsistency Across Model Updates**\n\nWhen embedding models are updated but cached query embeddings remain from the previous model version, similarity scores become incomparable and result quality degrades significantly. Some queries use fresh embeddings while others use stale cached versions.\n\n**Detection**: Monitor for sudden changes in result quality or user satisfaction scores after system deployments. Check for embedding dimension mismatches or unusual similarity score distributions.\n\n**Fix**: Include model version hashes in cache keys, implement automatic cache invalidation on model updates, and maintain cache warming procedures for popular queries after invalidation.\n\n⚠️ **Pitfall: Multi-Vector Weight Imbalance**\n\nPoorly calibrated weights in multi-vector queries can cause one aspect to dominate others, effectively ignoring important query constraints. A query combining \"machine learning\" (weight 0.9) with \"recent papers\" (weight 0.1) will retrieve any ML content regardless of recency.\n\n**Detection**: Analyze result sets for queries with multiple aspects to ensure all aspects are represented. Monitor for user reformulations that repeat constrained aspects.\n\n**Fix**: Implement adaptive weight learning from user feedback, default to balanced weights (e.g., 0.6/0.4 for two aspects), and provide explicit user controls for aspect importance in advanced search interfaces.\n\n### Implementation Guidance\n\nThe Query Processing Component bridges natural language understanding with vector search, requiring careful integration of text processing, machine learning models, and caching systems. This component will likely be the most linguistically sophisticated part of your semantic search engine.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|---|---|---|\n| **Text Processing** | NLTK + spaCy for basic NLP | Transformers library with domain-specific models |\n| **Entity Recognition** | spaCy pre-trained models | Custom NER models fine-tuned on your domain |\n| **Query Expansion** | WordNet + manual synonym lists | Word2Vec/FastText similarity + corpus co-occurrence |\n| **Intent Classification** | Rule-based pattern matching | Fine-tuned BERT classifier on query-intent pairs |\n| **Embedding Cache** | Python dict with LRU eviction | Redis with cluster support and TTL management |\n| **Vector Operations** | NumPy for basic arithmetic | Faiss for optimized vector operations |\n\n**Recommended File Structure**\n\n```\nsrc/query_processing/\n├── __init__.py\n├── query_processor.py          ← Main QueryProcessor class\n├── text_processing/\n│   ├── __init__.py\n│   ├── normalizer.py          ← Text cleaning and normalization\n│   ├── entity_extractor.py    ← Named entity recognition\n│   └── intent_classifier.py   ← Query intent detection\n├── expansion/\n│   ├── __init__.py\n│   ├── synonym_expander.py     ← Synonym-based expansion\n│   ├── semantic_expander.py    ← Embedding-based expansion\n│   └── expansion_filter.py     ← Expansion quality filtering\n├── multi_vector/\n│   ├── __init__.py\n│   ├── query_decomposer.py     ← Multi-aspect query analysis\n│   ├── vector_composer.py      ← Vector arithmetic and composition\n│   └── negative_handler.py     ← Negative term processing\n├── caching/\n│   ├── __init__.py\n│   ├── embedding_cache.py      ← Multi-tier query cache\n│   └── cache_manager.py        ← Cache lifecycle and invalidation\n└── tests/\n    ├── test_query_processor.py\n    ├── test_expansion.py\n    └── test_caching.py\n```\n\n**Infrastructure Starter Code**\n\nHere's a complete text processing foundation that handles the linguistic complexity so you can focus on the core query processing logic:\n\n```python\n# src/query_processing/text_processing/normalizer.py\nimport re\nimport unicodedata\nfrom typing import List, Set\n\nclass TextNormalizer:\n    \"\"\"Handles text cleaning and normalization for query processing.\"\"\"\n    \n    def __init__(self, preserve_entities: bool = True):\n        self.preserve_entities = preserve_entities\n        # Pre-compile regex patterns for efficiency\n        self.whitespace_pattern = re.compile(r'\\s+')\n        self.entity_pattern = re.compile(r'\\b[A-Z][A-Z0-9]*\\b')  # Acronyms like SQL, COVID-19\n        self.technical_pattern = re.compile(r'\\b\\w+[-_.]\\w+\\b')  # Technical terms like React.js\n        \n        # Common stop words that can be removed for normalization\n        self.stop_words = {\n            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'\n        }\n        \n        # Entities that should preserve case\n        self.preserve_case_terms = {\n            'SQL', 'API', 'HTTP', 'TCP', 'IP', 'URL', 'HTML', 'CSS', 'JavaScript',\n            'Python', 'Java', 'React', 'Angular', 'Vue', 'AWS', 'GCP', 'AI', 'ML'\n        }\n    \n    def normalize_query(self, query: str) -> str:\n        \"\"\"\n        Normalize query text for caching and consistency.\n        \n        Args:\n            query: Raw query string\n            \n        Returns:\n            Normalized query string suitable for cache keys\n        \"\"\"\n        # Unicode normalization\n        normalized = unicodedata.normalize('NFKD', query)\n        \n        # Remove extra whitespace\n        normalized = self.whitespace_pattern.sub(' ', normalized).strip()\n        \n        # Preserve important entities and technical terms\n        if self.preserve_entities:\n            preserved_terms = self._extract_preserve_terms(normalized)\n            normalized_lower = normalized.lower()\n            \n            # Restore preserved terms to their original case\n            for term in preserved_terms:\n                normalized_lower = normalized_lower.replace(term.lower(), term)\n            \n            return normalized_lower\n        else:\n            return normalized.lower()\n    \n    def _extract_preserve_terms(self, text: str) -> List[str]:\n        \"\"\"Extract terms that should preserve their original case.\"\"\"\n        terms = []\n        \n        # Find known entities\n        words = text.split()\n        for word in words:\n            if word in self.preserve_case_terms:\n                terms.append(word)\n        \n        # Find acronyms and technical terms\n        terms.extend(self.entity_pattern.findall(text))\n        terms.extend(self.technical_pattern.findall(text))\n        \n        return terms\n    \n    def clean_text(self, text: str) -> str:\n        \"\"\"Clean text for embedding generation (more aggressive than normalization).\"\"\"\n        # Unicode normalization\n        cleaned = unicodedata.normalize('NFKD', text)\n        \n        # Remove special characters but preserve hyphens and periods in technical terms\n        cleaned = re.sub(r'[^\\w\\s\\-\\.]', ' ', cleaned)\n        \n        # Normalize whitespace\n        cleaned = self.whitespace_pattern.sub(' ', cleaned).strip()\n        \n        return cleaned\n\n# src/query_processing/expansion/synonym_expander.py\nfrom typing import List, Tuple, Dict, Set\nimport json\nfrom pathlib import Path\n\nclass SynonymExpander:\n    \"\"\"Provides synonym-based query expansion using configurable dictionaries.\"\"\"\n    \n    def __init__(self, synonym_dict_path: str = None):\n        self.synonyms: Dict[str, List[str]] = {}\n        self.load_synonyms(synonym_dict_path)\n    \n    def load_synonyms(self, dict_path: str = None):\n        \"\"\"Load synonym dictionary from JSON file.\"\"\"\n        if dict_path and Path(dict_path).exists():\n            with open(dict_path, 'r') as f:\n                self.synonyms = json.load(f)\n        else:\n            # Fallback to basic synonyms for common terms\n            self.synonyms = {\n                'ml': ['machine learning', 'artificial intelligence'],\n                'ai': ['artificial intelligence', 'machine learning'],\n                'car': ['automobile', 'vehicle'],\n                'fix': ['repair', 'solve', 'resolve'],\n                'error': ['bug', 'issue', 'problem'],\n                'fast': ['quick', 'rapid', 'speedy'],\n                'big': ['large', 'huge', 'massive']\n            }\n    \n    def expand_term(self, term: str, max_expansions: int = 3) -> List[Tuple[str, float]]:\n        \"\"\"\n        Get synonyms for a term with confidence scores.\n        \n        Args:\n            term: Original term to expand\n            max_expansions: Maximum number of synonyms to return\n            \n        Returns:\n            List of (synonym, confidence_score) tuples\n        \"\"\"\n        term_lower = term.lower()\n        if term_lower not in self.synonyms:\n            return []\n        \n        # Simple confidence scoring based on synonym quality\n        expansions = []\n        for i, synonym in enumerate(self.synonyms[term_lower][:max_expansions]):\n            confidence = max(0.3, 1.0 - (i * 0.2))  # Decreasing confidence\n            expansions.append((synonym, confidence))\n        \n        return expansions\n\n# src/query_processing/caching/embedding_cache.py\nimport hashlib\nimport time\nfrom typing import Optional, Dict, Any, Tuple\nimport numpy as np\nfrom collections import OrderedDict\nimport threading\n\nclass EmbeddingCache:\n    \"\"\"Multi-tier cache for query embeddings with LRU eviction.\"\"\"\n    \n    def __init__(self, max_size: int = 10000, ttl_seconds: int = 3600):\n        self.max_size = max_size\n        self.ttl_seconds = ttl_seconds\n        \n        # Three-tier cache structure\n        self.exact_cache: OrderedDict[str, Tuple[np.ndarray, float]] = OrderedDict()\n        self.normalized_cache: OrderedDict[str, Tuple[np.ndarray, float]] = OrderedDict()\n        self.component_cache: Dict[str, Tuple[np.ndarray, float]] = {}\n        \n        # Thread safety\n        self._lock = threading.RLock()\n        \n        # Cache statistics\n        self.stats = {\n            'hits': 0, 'misses': 0, 'exact_hits': 0, \n            'normalized_hits': 0, 'component_hits': 0\n        }\n    \n    def get(self, query: str, normalized_query: str = None) -> Optional[np.ndarray]:\n        \"\"\"\n        Retrieve cached embedding for query.\n        \n        Args:\n            query: Original query string\n            normalized_query: Normalized version for fallback lookup\n            \n        Returns:\n            Cached embedding array or None if not found\n        \"\"\"\n        with self._lock:\n            current_time = time.time()\n            \n            # Try exact match first\n            if query in self.exact_cache:\n                embedding, timestamp = self.exact_cache[query]\n                if current_time - timestamp < self.ttl_seconds:\n                    # Move to end (most recently used)\n                    self.exact_cache.move_to_end(query)\n                    self.stats['hits'] += 1\n                    self.stats['exact_hits'] += 1\n                    return embedding.copy()\n                else:\n                    # Expired, remove from cache\n                    del self.exact_cache[query]\n            \n            # Try normalized match\n            if normalized_query and normalized_query in self.normalized_cache:\n                embedding, timestamp = self.normalized_cache[normalized_query]\n                if current_time - timestamp < self.ttl_seconds:\n                    self.normalized_cache.move_to_end(normalized_query)\n                    self.stats['hits'] += 1\n                    self.stats['normalized_hits'] += 1\n                    return embedding.copy()\n                else:\n                    del self.normalized_cache[normalized_query]\n            \n            # Cache miss\n            self.stats['misses'] += 1\n            return None\n    \n    def put(self, query: str, embedding: np.ndarray, normalized_query: str = None):\n        \"\"\"Cache embedding for query.\"\"\"\n        with self._lock:\n            current_time = time.time()\n            \n            # Store in exact cache\n            self.exact_cache[query] = (embedding.copy(), current_time)\n            self.exact_cache.move_to_end(query)\n            \n            # Store in normalized cache if provided\n            if normalized_query:\n                self.normalized_cache[normalized_query] = (embedding.copy(), current_time)\n                self.normalized_cache.move_to_end(normalized_query)\n            \n            # Enforce size limits\n            self._enforce_size_limits()\n    \n    def _enforce_size_limits(self):\n        \"\"\"Remove oldest entries if cache exceeds size limits.\"\"\"\n        # Exact cache eviction\n        while len(self.exact_cache) > self.max_size:\n            self.exact_cache.popitem(last=False)  # Remove oldest\n        \n        # Normalized cache eviction\n        while len(self.normalized_cache) > self.max_size:\n            self.normalized_cache.popitem(last=False)\n    \n    def invalidate_all(self):\n        \"\"\"Clear all cached embeddings (e.g., after model update).\"\"\"\n        with self._lock:\n            self.exact_cache.clear()\n            self.normalized_cache.clear()\n            self.component_cache.clear()\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Return cache performance statistics.\"\"\"\n        with self._lock:\n            total_requests = self.stats['hits'] + self.stats['misses']\n            hit_rate = self.stats['hits'] / total_requests if total_requests > 0 else 0.0\n            \n            return {\n                'hit_rate': hit_rate,\n                'total_requests': total_requests,\n                'cache_sizes': {\n                    'exact': len(self.exact_cache),\n                    'normalized': len(self.normalized_cache),\n                    'component': len(self.component_cache)\n                },\n                **self.stats\n            }\n```\n\n**Core Logic Skeleton**\n\nHere are the main interfaces you'll implement, with detailed TODO comments mapping to the design concepts:\n\n```python\n# src/query_processing/query_processor.py\nfrom typing import List, Dict, Any, Optional, Tuple\nimport numpy as np\nfrom dataclasses import dataclass\n\n@dataclass\nclass ProcessedQuery:\n    \"\"\"Result of query processing with all enhancements.\"\"\"\n    original_query: str\n    normalized_query: str\n    primary_embedding: np.ndarray\n    expanded_terms: List[Tuple[str, float]]  # (term, weight)\n    entities: List[Tuple[str, str]]  # (entity, type)\n    intent: str\n    negative_terms: List[str]\n    multi_vector_components: Optional[List[Tuple[str, np.ndarray, float]]]  # (concept, embedding, weight)\n    processing_metadata: Dict[str, Any]\n\nclass QueryProcessor:\n    \"\"\"Main query processing orchestrator combining all enhancement strategies.\"\"\"\n    \n    def __init__(self, embedding_model, cache: EmbeddingCache = None):\n        self.embedding_model = embedding_model\n        self.cache = cache or EmbeddingCache()\n        # TODO: Initialize text normalizer, entity extractor, expansion modules\n        # TODO: Load domain-specific configurations and models\n    \n    def process_query(self, query_text: str, context: Dict[str, Any] = None) -> ProcessedQuery:\n        \"\"\"\n        Main query processing pipeline that transforms raw query into enhanced representation.\n        \n        Args:\n            query_text: Original user query\n            context: Optional context (user history, filters, etc.)\n            \n        Returns:\n            ProcessedQuery with all enhancements applied\n        \"\"\"\n        # TODO 1: Text normalization and cleaning\n        #   - Apply unicode normalization and whitespace cleanup\n        #   - Preserve important entities and technical terms\n        #   - Generate normalized version for caching\n        \n        # TODO 2: Check embedding cache for existing results\n        #   - Try exact query match first, then normalized match\n        #   - Return cached result if found and not expired\n        #   - Update cache statistics for monitoring\n        \n        # TODO 3: Entity extraction and recognition\n        #   - Run NER models to identify persons, organizations, locations\n        #   - Detect technical terms and domain-specific entities\n        #   - Mark entities that should not be expanded\n        \n        # TODO 4: Intent classification\n        #   - Analyze query structure for intent signals (question words, comparatives)\n        #   - Apply trained intent classifier if available\n        #   - Use entity types and patterns for intent inference\n        \n        # TODO 5: Query expansion\n        #   - Generate synonyms and related terms for non-entity terms\n        #   - Apply domain-specific expansion strategies\n        #   - Filter expansions to prevent drift from original intent\n        #   - Weight expanded terms based on confidence and similarity\n        \n        # TODO 6: Multi-vector analysis\n        #   - Identify distinct concepts that warrant separate embeddings\n        #   - Detect negative terms and constraints\n        #   - Plan vector composition strategy (additive, weighted, separate)\n        \n        # TODO 7: Embedding generation\n        #   - Generate primary embedding for main query concepts\n        #   - Create separate embeddings for multi-vector components\n        #   - Apply any necessary vector normalization\n        \n        # TODO 8: Cache storage\n        #   - Store generated embeddings in appropriate cache tiers\n        #   - Include metadata for invalidation and debugging\n        \n        # TODO 9: Result packaging\n        #   - Combine all processing results into ProcessedQuery object\n        #   - Include debugging metadata and processing statistics\n        \n        pass\n    \n    def expand_query_terms(self, terms: List[str], entities: List[str]) -> List[Tuple[str, float]]:\n        \"\"\"\n        Apply query expansion strategies to increase recall.\n        \n        Args:\n            terms: Original query terms to expand\n            entities: Recognized entities that should not be expanded\n            \n        Returns:\n            List of (expanded_term, confidence_weight) tuples\n        \"\"\"\n        # TODO 1: Filter out entities and stop words from expansion candidates\n        #   - Skip proper nouns and technical terms that have specific meanings\n        #   - Consider keeping stop words in some contexts (e.g., \"to be or not to be\")\n        \n        # TODO 2: Generate synonym expansions\n        #   - Use WordNet or domain dictionary for basic synonyms\n        #   - Apply semantic similarity from embedding models\n        #   - Consider corpus-specific co-occurrence patterns\n        \n        # TODO 3: Apply expansion filtering\n        #   - Set minimum similarity thresholds to prevent drift\n        #   - Limit number of expansions per term to prevent explosion\n        #   - Check domain relevance for specialized corpora\n        \n        # TODO 4: Weight assignment\n        #   - Higher weights for more confident expansions\n        #   - Consider term importance (IDF) in weight calculation\n        #   - Balance expansion influence vs original term importance\n        \n        pass\n    \n    def handle_multi_vector_query(self, processed_query: ProcessedQuery) -> List[Tuple[str, np.ndarray, float]]:\n        \"\"\"\n        Decompose complex queries into multiple vector representations.\n        \n        Args:\n            processed_query: Query after initial processing\n            \n        Returns:\n            List of (concept_description, embedding_vector, weight) tuples\n        \"\"\"\n        # TODO 1: Concept boundary detection\n        #   - Identify natural breakpoints using conjunctions and prepositions\n        #   - Separate semantic concepts from structural constraints\n        #   - Group related terms that should be embedded together\n        \n        # TODO 2: Negative term handling\n        #   - Extract negative concepts introduced by \"not\", \"except\", \"without\"\n        #   - Plan exclusion strategy (post-retrieval filtering vs vector arithmetic)\n        #   - Set appropriate similarity thresholds for exclusion\n        \n        # TODO 3: Vector composition planning\n        #   - Decide which concepts can be combined through arithmetic\n        #   - Determine which require separate retrieval and intersection\n        #   - Calculate relative weights based on concept importance\n        \n        # TODO 4: Generate component embeddings\n        #   - Create separate embeddings for each identified concept\n        #   - Apply normalization if using cosine similarity\n        #   - Store components in cache for potential reuse\n        \n        pass\n\n    def encode_query(self, query_text: str) -> np.ndarray:\n        \"\"\"\n        Convert query text to embedding vector using the configured model.\n        \n        Args:\n            query_text: Processed query text ready for embedding\n            \n        Returns:\n            Dense vector embedding of the query\n        \"\"\"\n        # TODO 1: Text preprocessing for embedding model\n        #   - Apply any model-specific text cleaning\n        #   - Handle special tokens or formatting requirements\n        #   - Ensure text length is within model limits\n        \n        # TODO 2: Generate embedding using transformer model\n        #   - Forward pass through sentence transformer\n        #   - Handle batch processing if multiple components\n        #   - Apply any post-processing (normalization, dimensionality reduction)\n        \n        # TODO 3: Vector validation\n        #   - Check embedding dimensions match expected size\n        #   - Verify no NaN or infinite values in output\n        #   - Apply L2 normalization if using cosine similarity\n        \n        pass\n```\n\n**Milestone Checkpoint**\n\nAfter implementing Milestone 2, verify your query processing works correctly:\n\n**Test Command:**\n```bash\npython -m pytest src/query_processing/tests/ -v\n```\n\n**Expected Behavior:**\n1. **Basic Query Processing**: Simple queries like \"machine learning\" should be normalized, expanded with 2-3 related terms, and converted to 384-dimensional embeddings\n2. **Entity Preservation**: Queries containing proper nouns like \"Barack Obama\" or technical terms like \"React.js\" should preserve these terms without expansion\n3. **Multi-Vector Queries**: Complex queries like \"machine learning papers not about computer vision\" should decompose into positive concepts (ML, papers) and negative exclusions (computer vision)\n4. **Cache Performance**: Repeated queries should show cache hits with <5ms lookup latency vs >50ms for fresh embedding generation\n\n**Manual Verification:**\n```python\n# Test script to verify query processing\nfrom src.query_processing.query_processor import QueryProcessor\nfrom src.embedding_index.document_encoder import DocumentEncoder\n\n# Initialize processor\nencoder = DocumentEncoder()\nprocessor = QueryProcessor(encoder.model)\n\n# Test basic processing\nresult = processor.process_query(\"machine learning algorithms\")\nprint(f\"Original: {result.original_query}\")\nprint(f\"Expanded terms: {result.expanded_terms}\")\nprint(f\"Embedding shape: {result.primary_embedding.shape}\")\n\n# Test multi-vector query\ncomplex_result = processor.process_query(\"python programming not web development\")\nprint(f\"Multi-vector components: {len(complex_result.multi_vector_components)}\")\nprint(f\"Negative terms: {complex_result.negative_terms}\")\n```\n\n**Signs Something Is Wrong:**\n- **Embedding dimension mismatches**: Check model configuration and ensure consistent dimensions across components\n- **Over-expansion**: If >10 terms are added per original term, review expansion filtering thresholds  \n- **Cache misses for identical queries**: Verify normalization and cache key generation\n- **Poor entity recognition**: Test with domain-specific entity lists and proper noun handling\n\n\n## Ranking and Relevance Component\n\n> **Milestone(s):** Milestone 3: Ranking & Relevance\n\nThe **Ranking and Relevance Component** represents the sophisticated orchestration layer that transforms raw similarity scores into meaningful, personalized search results. While the embedding index provides semantic understanding and query processing extracts user intent, this component must balance multiple competing signals—semantic similarity, keyword relevance, user preferences, content freshness, and historical behavior—to deliver the most valuable results to each user.\n\n### Multi-Signal Ranking Mental Model: Orchestra Conductor Analogy\n\nThink of the ranking component as a **symphony conductor** leading a complex orchestra where each musician represents a different ranking signal. The semantic similarity scores are like the string section—they provide the fundamental melody and emotional resonance of the search. The keyword matching (BM25) scores act like the brass section—bold, direct, and unmistakable when they hit the right notes. Personalization signals are like the woodwinds—subtle but essential for adding individual character and nuance to the performance.\n\nThe conductor (ranking algorithm) must balance all these instruments to create a harmonious result. Sometimes the strings (semantic signals) should dominate when the user's query is conceptual or exploratory. Other times the brass (keyword matching) should take the lead when the user needs exact technical terms or proper nouns. The woodwinds (personalization) should weave through the performance, ensuring each user hears a slightly different interpretation that resonates with their specific needs and context.\n\nJust as a conductor must make real-time decisions about tempo, dynamics, and emphasis based on the audience and venue, the ranking component must dynamically adjust signal weights based on query type, user context, and result quality. A novice conductor might let one section overpower the others or fail to bring in instruments at the right moment. Similarly, a poorly tuned ranking system might over-rely on semantic similarity (creating results that are conceptually related but not actionable) or keyword matching (missing the user's deeper intent).\n\nThe true artistry lies in knowing when to emphasize which signals. For a query like \"machine learning algorithms,\" the conductor might emphasize the brass section (keyword matching) to ensure technical precision, while still allowing the strings (semantic similarity) to include related concepts like \"neural networks\" and \"deep learning.\" For a more exploratory query like \"how to improve team productivity,\" the strings should take the lead, with personalization woodwinds adding context based on the user's role and industry.\n\n### Multi-Stage Ranking Pipeline: Fast Retrieval Followed by Precise Cross-Encoder Reranking\n\nThe multi-stage ranking pipeline addresses a fundamental tension in search systems: the need for both **speed and precision**. Users expect sub-second response times, but the most accurate ranking methods (particularly cross-encoder transformer models) are too computationally expensive to apply to millions of candidate documents. The solution is a graduated approach that applies increasingly sophisticated but expensive ranking methods to progressively smaller candidate sets.\n\n> **Decision: Multi-Stage Ranking Architecture**\n> - **Context**: Cross-encoder models achieve state-of-the-art ranking accuracy but require 10-100x more computation than bi-encoder similarity scores. Applying cross-encoders to all indexed documents would result in multi-second query latencies.\n> - **Options Considered**: Single-stage ranking with fast methods only, single-stage with slow methods only, multi-stage pipeline with fast retrieval and precise reranking\n> - **Decision**: Implement three-stage ranking pipeline: candidate retrieval, hybrid scoring, cross-encoder reranking\n> - **Rationale**: This approach provides the best balance of speed and accuracy. Fast retrieval methods (vector similarity, BM25) can process millions of documents in milliseconds to identify promising candidates. Hybrid scoring refines the top few hundred candidates. Cross-encoder reranking provides maximum precision for the final top-K results that users actually see.\n> - **Consequences**: Increased system complexity with multiple ranking components, but achieves both sub-second latency and high relevance quality. Requires careful tuning of stage transition thresholds.\n\nThe **first stage** performs rapid candidate retrieval using the vector index and keyword index. This stage processes the entire document collection (potentially millions of documents) but uses computationally simple scoring methods. Vector similarity scores are computed via approximate nearest neighbor search, typically returning the top 1000-5000 most similar documents based on semantic embedding distance. Simultaneously, BM25 keyword scoring identifies documents containing query terms, typically retrieving another 1000-5000 candidates. The union of these candidate sets (after deduplication) advances to the second stage.\n\n| Ranking Stage | Input Size | Output Size | Methods Used | Latency Budget | Accuracy Level |\n|---------------|------------|-------------|--------------|----------------|----------------|\n| Candidate Retrieval | Millions | 5K-10K | Vector ANN, BM25 | 50-100ms | Good |\n| Hybrid Scoring | 5K-10K | 100-500 | Combined signals | 50-100ms | Better |\n| Cross-Encoder Reranking | 100-500 | 10-50 | Transformer model | 100-200ms | Best |\n\nThe **second stage** applies hybrid scoring that combines multiple signals: semantic similarity scores from the vector index, BM25 lexical scores from the keyword index, personalization signals based on user context, and freshness scores based on document age. Each signal is normalized to a common scale (typically 0-1) and combined using learned or manually tuned weights. This stage processes the reduced candidate set (5K-10K documents) and selects the top 100-500 documents for final reranking. The hybrid scoring provides a more nuanced relevance assessment than any single signal alone.\n\nThe **third stage** performs precise reranking using a cross-encoder transformer model. Unlike bi-encoder models that encode queries and documents separately, cross-encoders process query-document pairs jointly, allowing for more sophisticated reasoning about relevance. The cross-encoder receives both the original query text and each candidate document's content, producing a refined relevance score. Since cross-encoders are computationally expensive (requiring a full transformer forward pass for each query-document pair), they are applied only to the top candidates from the hybrid scoring stage.\n\n```\nStage 1: Candidate Retrieval\nQuery: \"machine learning model deployment\"\nVector Search → 3,000 semantic candidates\nBM25 Search → 2,500 keyword candidates\nCombined Pool → 4,800 unique candidates (after deduplication)\n\nStage 2: Hybrid Scoring\nInput: 4,800 candidates\nSemantic Score (0.4 weight) + BM25 Score (0.3 weight) + \nPersonalization (0.2 weight) + Freshness (0.1 weight) = Final Score\nTop 200 candidates selected for reranking\n\nStage 3: Cross-Encoder Reranking\nInput: 200 candidates\nCross-Encoder processes each (query, document) pair\nFinal ranked list of 20 results returned to user\nTotal Latency: 75ms + 60ms + 150ms = 285ms\n```\n\n⚠️ **Pitfall: Stage Transition Thresholds**\nA common mistake is using fixed candidate counts for stage transitions without considering query characteristics. Simple queries might only need 100 candidates for reranking, while complex queries might benefit from reranking 500 candidates. Monitor per-query result quality and adjust thresholds dynamically based on query type and semantic complexity.\n\n### Hybrid Semantic and Lexical Search: Combining BM25 Keyword Scores with Vector Similarity Scores\n\nHybrid search addresses the complementary strengths and weaknesses of semantic and lexical search methods. **Semantic search** excels at capturing conceptual similarity and handling vocabulary mismatch—when users and documents express the same ideas using different terminology. However, semantic search can sometimes miss exact matches for technical terms, proper nouns, or specific model numbers where precise lexical matching is crucial. **Lexical search** (particularly BM25) provides reliable exact matching and has well-understood behavior, but suffers from vocabulary mismatch and cannot capture conceptual relationships.\n\nThe key insight is that these approaches are **complementary rather than competing**. Semantic search provides broad conceptual coverage and handles synonymy, while lexical search ensures precision for exact terms and technical specificity. The hybrid approach combines both score types to leverage their respective strengths while mitigating their individual weaknesses.\n\n> **Decision: Hybrid Score Combination Strategy**\n> - **Context**: Pure semantic search sometimes misses exact technical matches; pure lexical search suffers from vocabulary mismatch. User queries vary in their semantic vs. lexical intent.\n> - **Options Considered**: Query-adaptive weighting, fixed weighted combination, learning-to-rank with multiple features, separate semantic and lexical result lists\n> - **Decision**: Implement fixed weighted combination with query-type detection for adaptive weighting\n> - **Rationale**: Fixed weighting (0.6 semantic, 0.4 lexical) works well for most queries and is simple to tune. Query-type detection allows adaptation for technical queries (higher lexical weight) vs. exploratory queries (higher semantic weight). Learning-to-rank requires extensive training data we may not have initially.\n> - **Consequences**: Enables both broad conceptual matching and precise technical matching. Requires careful weight tuning and ongoing evaluation of different query types.\n\nThe **BM25 scoring component** computes lexical relevance using the standard BM25 algorithm, which considers term frequency within documents, inverse document frequency across the collection, and document length normalization. BM25 scores are particularly effective for queries containing specific technical terms, proper nouns, or rare keywords that should match exactly. The algorithm naturally handles cases where query terms appear multiple times in a document (increasing relevance) while downweighting overly long documents.\n\n| BM25 Parameter | Value | Rationale |\n|----------------|-------|-----------|\n| k1 | 1.6 | Controls term frequency saturation; higher values reward repeated terms more |\n| b | 0.75 | Document length normalization; balances absolute vs. relative term frequency |\n| k3 | 1000 | Query term frequency normalization; high value since queries are typically short |\n\nThe **semantic similarity component** computes vector cosine similarity between the query embedding and each candidate document embedding. Cosine similarity measures the angle between vectors, providing a normalized score between -1 and 1 that is then mapped to the 0-1 range. This score captures conceptual relatedness regardless of exact keyword matches, enabling the system to find relevant documents even when they use different terminology than the query.\n\n**Score normalization** is critical for effective combination. BM25 scores have no fixed upper bound and vary significantly based on term rarity and document characteristics. Semantic similarity scores from cosine similarity are naturally bounded between 0 and 1. To combine these scores meaningfully, BM25 scores must be normalized to a comparable range. Common approaches include min-max normalization within the candidate set or sigmoid transformation to map unbounded scores to the 0-1 range.\n\nThe **hybrid combination formula** applies learned or tuned weights to the normalized scores:\n\n```\nhybrid_score = w_semantic * semantic_score + w_lexical * bm25_normalized + w_personalization * personalization_score + w_freshness * freshness_score\n\nWhere:\nw_semantic = 0.4-0.7 (depending on query type)\nw_lexical = 0.2-0.4 (higher for technical queries)\nw_personalization = 0.1-0.3 (based on available user context)\nw_freshness = 0.1-0.2 (domain-dependent)\n```\n\n**Query-adaptive weighting** improves hybrid search by adjusting weights based on detected query characteristics. Technical queries containing programming languages, version numbers, or domain-specific terminology receive higher lexical weights to ensure precise matching. Exploratory or conceptual queries receive higher semantic weights to capture broader relevant concepts. Named entity recognition and technical term detection help classify queries automatically.\n\n| Query Type | Example | Semantic Weight | Lexical Weight | Rationale |\n|------------|---------|-----------------|----------------|-----------|\n| Technical | \"Python 3.9 asyncio tutorial\" | 0.4 | 0.6 | Exact version and API names crucial |\n| Conceptual | \"improve team collaboration\" | 0.7 | 0.3 | Many valid approaches and terminologies |\n| Mixed | \"React hooks best practices\" | 0.5 | 0.5 | Balance of technical terms and concepts |\n| Navigational | \"OpenAI GPT-4 documentation\" | 0.2 | 0.8 | Looking for specific resource |\n\n⚠️ **Pitfall: Score Range Mismatch**\nBM25 scores can vary dramatically between queries and document collections. A score of 15.0 might be high for one query but low for another. Always normalize BM25 scores within each query's candidate set before combining with semantic scores, or use percentile-based normalization to ensure consistent score ranges.\n\n### Personalization and Freshness Signals: User Preference Matching and Time-Based Relevance Decay\n\nPersonalization and freshness signals add crucial context-aware dimensions to search ranking that move beyond the query-document relationship to consider the user and temporal context. **Personalization signals** help the system understand that the same query may have different ideal results for different users based on their role, experience level, historical interests, and current context. **Freshness signals** recognize that information value often decays over time, and users frequently prefer recent, up-to-date content over older material that may be outdated or superseded.\n\nThe **personalization scoring component** leverages available user context to boost results that align with the user's inferred preferences and needs. User context might include explicit profile information (role, industry, experience level), historical search and click behavior, and implicit signals derived from previous interactions. The key challenge is making effective use of limited personalization data while avoiding filter bubbles that overly narrow the result diversity.\n\n| Personalization Signal | Data Source | Weight | Computation Method |\n|------------------------|-------------|--------|-------------------|\n| Role/Industry Match | User profile | 0.3 | Keyword matching on document tags |\n| Historical Topics | Click history | 0.4 | Vector similarity to past clicked documents |\n| Expertise Level | Inferred behavior | 0.2 | Document complexity scoring |\n| Current Context | Session data | 0.1 | Similarity to recent queries |\n\n**Role-based personalization** adjusts results based on the user's professional context. A query for \"API design\" might surface different results for a frontend developer (focusing on REST API consumption) versus a backend architect (emphasizing API design patterns and scalability). Role matching can be implemented through document metadata tagging and user profile information, with documents tagged for target audiences receiving personalization boosts when served to matching users.\n\n**Historical interest modeling** uses the user's past click-through behavior to identify topic preferences and expertise areas. Documents similar to previously clicked content receive personalization boosts, implemented by computing vector similarity between candidate documents and embeddings of the user's click history. This approach requires maintaining user interaction history while respecting privacy constraints and avoiding over-fitting to recent behavior.\n\n**Experience level adaptation** personalizes results based on the user's inferred technical expertise. Novice users might see introductory tutorials and explanations ranked higher, while expert users get advanced technical documentation and implementation details prioritized. Experience level can be inferred from query complexity, document types historically clicked, and explicit user profile information.\n\nThe **freshness scoring component** implements time-based relevance decay to favor recent content when recency is important for the query and domain. Not all content benefits from freshness signals—evergreen educational content might remain highly relevant for years, while technology tutorials and news articles quickly become outdated. The freshness function should be domain-aware and query-adaptive.\n\n> **Decision: Freshness Decay Function**\n> - **Context**: Some content types (news, tutorials, documentation) lose relevance quickly, while others (fundamental concepts, research papers) remain valuable long-term. A single decay function doesn't fit all content types.\n> - **Options Considered**: Linear decay, exponential decay, domain-specific decay functions, query-adaptive freshness weighting\n> - **Decision**: Implement exponential decay with domain-specific half-life parameters and query-type detection\n> - **Rationale**: Exponential decay models realistic information aging where recent content has much higher value, but value doesn't drop to zero. Domain-specific half-lives (3 months for tutorials, 12 months for research) better match content lifecycles.\n> - **Consequences**: Requires content categorization and decay parameter tuning per domain. More complex than linear decay but much more realistic modeling of information value over time.\n\nThe **exponential freshness decay formula** applies different decay rates based on content type and age:\n\n```\nfreshness_score = exp(-λ * age_in_days)\n\nWhere λ (decay constant) varies by content type:\n- News articles: λ = 0.1 (half-life ~7 days)\n- Technical tutorials: λ = 0.01 (half-life ~70 days) \n- Research papers: λ = 0.002 (half-life ~350 days)\n- Reference documentation: λ = 0.005 (half-life ~140 days)\n```\n\n**Query-adaptive freshness weighting** recognizes that freshness importance varies by query intent. Queries containing temporal indicators (\"latest,\" \"new,\" \"recent,\" \"2024\") should receive higher freshness weights. Technical queries about rapidly evolving topics (web frameworks, cloud services) benefit more from freshness than queries about stable, fundamental concepts (algorithms, mathematical proofs).\n\n| Query Pattern | Freshness Weight | Example | Rationale |\n|---------------|------------------|---------|-----------|\n| Contains year/date | 0.4 | \"React 2024 best practices\" | Explicit temporal intent |\n| Technology-specific | 0.3 | \"Kubernetes deployment tutorial\" | Tech evolves quickly |\n| Conceptual/fundamental | 0.1 | \"binary search algorithm\" | Timeless concepts |\n| News/current events | 0.5 | \"AI regulation updates\" | Inherently time-sensitive |\n\n⚠️ **Pitfall: Over-Personalization Filter Bubbles**\nAggressive personalization can create filter bubbles where users only see content similar to their past behavior, limiting discovery of new topics and perspectives. Implement diversity injection by reserving 20-30% of top results for non-personalized ranking, and regularly evaluate result diversity metrics alongside relevance quality.\n\n### Click-Through Learning: Using User Interaction Data to Improve Ranking Quality\n\nClick-through learning represents the **continuous improvement engine** of the ranking system, using real user interactions to validate and refine ranking decisions over time. While offline relevance evaluation provides initial quality assessment, user behavior provides the ultimate ground truth about which results are genuinely useful for specific queries. The system learns from patterns in user clicks, time spent on clicked results, and subsequent search behavior to identify ranking improvements and detect quality issues.\n\nThe fundamental insight behind click-through learning is that **user clicks provide implicit relevance feedback** that is both abundant and aligned with actual user needs. Unlike explicit ratings (which are rare and potentially biased), click data captures real user decision-making under natural conditions. However, click data requires careful interpretation because clicks are influenced by result position, snippet quality, and user interface factors beyond true relevance.\n\n> **Decision: Click-Through Data Collection and Learning Strategy**\n> - **Context**: User clicks provide valuable relevance feedback but are biased by result position and presentation. We need to learn from click patterns while accounting for these biases.\n> - **Options Considered**: Position-unaware click rates, position-bias correction models, pairwise preference learning from clicks, learning-to-rank with click features\n> - **Decision**: Implement position-bias corrected click models with pairwise preference learning\n> - **Rationale**: Position bias is the strongest confounding factor in click data—users click higher-ranked results more often regardless of relevance. Position-bias correction isolates true relevance signals. Pairwise learning is more robust than absolute click rates and works well with limited data.\n> - **Consequences**: Requires sophisticated click modeling and careful statistical analysis. More complex than raw click rates but provides much more reliable relevance signals for ranking improvement.\n\nThe **click data collection system** captures comprehensive user interaction signals that extend beyond simple click events. Click-through events are only meaningful in context—a click followed immediately by a return to search results suggests the clicked result was not satisfactory, while a click followed by extended engagement indicates relevance. The system logs detailed interaction patterns to enable sophisticated relevance inference.\n\n| Interaction Signal | Data Captured | Relevance Indication | Collection Method |\n|-------------------|---------------|---------------------|------------------|\n| Click Event | Query, result position, timestamp | Initial interest | JavaScript tracking |\n| Dwell Time | Time spent on clicked page | Engagement quality | Session duration |\n| Return to Search | Time before back-button | Satisfaction level | Navigation tracking |\n| Follow-up Queries | Subsequent searches in session | Information need fulfillment | Session analysis |\n| Skip Pattern | Results viewed but not clicked | Negative preference | Scroll and view tracking |\n\n**Position bias correction** addresses the fundamental challenge that higher-ranked results receive more clicks regardless of their true relevance. Users exhibit strong position bias, with the first result receiving 30-35% of clicks, the second result 15-20%, and subsequent results receiving exponentially fewer clicks. Raw click rates therefore conflate relevance with ranking position, making them unsuitable for direct ranking optimization.\n\nThe **position-bias correction model** estimates the probability that a user examines each result position, separate from the probability that they find an examined result relevant. This separation enables estimation of true relevance probability independent of ranking position. The model learns examination probabilities from aggregate click patterns across many queries, then uses these to debias click rates for individual query-document pairs.\n\n```\nObserved Click Rate = P(examined) × P(relevant | examined)\n\nWhere:\nP(examined) = position-dependent examination probability (learned from data)\nP(relevant | examined) = true relevance probability (what we want to estimate)\n\nPosition bias correction:\nP(relevant | examined) = Observed Click Rate / P(examined)\n```\n\n**Pairwise preference learning** extracts relative relevance judgments from click patterns, which are more reliable than absolute relevance scores. When users click on result A but skip result B that was ranked higher, this suggests A is more relevant than B for that query. Pairwise preferences are less sensitive to position bias and user interface factors because they compare results within the same search session.\n\nThe **preference extraction algorithm** identifies reliable pairwise preferences from click patterns:\n\n1. **Skip-above preference**: User clicks result at position i but skipped result at position j < i, suggesting preference for result i\n2. **Click-through preference**: User clicks result A, returns to search, then clicks result B, suggesting B provided better information than A\n3. **Dwell time preference**: Among clicked results, longer dwell time suggests higher relevance\n4. **Last-click preference**: The final clicked result in a search session often best satisfies the information need\n\nThe **ranking model update process** uses collected preferences to improve future ranking decisions. Preferences are aggregated across multiple users and sessions to identify systematic ranking improvements. The system can detect when consistently lower-ranked results receive preference signals over higher-ranked results, indicating potential ranking quality issues that should be addressed.\n\n| Learning Signal | Collection Window | Confidence Threshold | Action Taken |\n|----------------|------------------|---------------------|--------------|\n| Skip-above patterns | 7 days | 10+ occurrences | Investigate ranking weights |\n| Consistent dwell time differences | 14 days | 5+ sessions | Adjust relevance scores |\n| Query reformulation patterns | 30 days | 20+ users | Review query processing |\n| Zero-click queries | 7 days | 50+ occurrences | Add direct answers |\n\n**Quality assurance for click-based learning** protects against noisy or manipulated click data that could degrade ranking quality. Not all clicks represent genuine relevance—users sometimes click accidentally, click on misleading snippets, or exhibit unusual behavior. The system implements filtering and validation to ensure learning from high-quality interaction signals.\n\n⚠️ **Pitfall: Learning from Noisy Click Data**\nRaw click data contains substantial noise from accidental clicks, bot traffic, and edge cases. Always implement click quality filtering based on dwell time thresholds (clicks with <3 seconds dwell time are likely accidental), session context validation, and statistical significance testing before updating ranking models.\n\n⚠️ **Pitfall: Feedback Loop Amplification**\nClick-based learning can create feedback loops where popular results become even more popular, potentially burying high-quality but less-discovered content. Implement exploration mechanisms that occasionally promote lower-ranked results to gather click data on their true relevance, and monitor result diversity metrics over time.\n\n![Multi-Stage Ranking Pipeline](./diagrams/ranking-pipeline.svg)\n\n![Search Request Sequence](./diagrams/search-sequence.svg)\n\n### Implementation Guidance\n\nThis implementation guidance provides the foundation for building a production-ready ranking and relevance system that balances multiple signals while maintaining sub-second query latency.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| BM25 Implementation | scikit-learn TfidfVectorizer | Elasticsearch BM25 |\n| Cross-Encoder Model | sentence-transformers cross-encoder | Custom BERT fine-tuned model |\n| Click Tracking | Simple JSON logging | Apache Kafka + streaming |\n| Model Training | Manual weight tuning | Learning-to-rank with XGBoost |\n| Caching | Python dict with TTL | Redis with pipeline operations |\n\n#### Recommended File Structure\n\n```\nsemantic_search/\n├── ranking/\n│   ├── __init__.py\n│   ├── multi_stage_ranker.py      ← main ranking orchestrator\n│   ├── hybrid_scorer.py           ← combines semantic and lexical scores\n│   ├── personalization.py         ← user context and personalization\n│   ├── freshness.py              ← time-based relevance scoring\n│   ├── cross_encoder.py          ← transformer-based reranking\n│   ├── click_learning.py         ← click-through learning system\n│   └── ranking_test.py           ← comprehensive ranking tests\n├── models/\n│   ├── cross_encoder/            ← saved cross-encoder models\n│   └── click_models/             ← trained click prediction models\n└── data/\n    ├── click_logs/               ← user interaction logs\n    └── ranking_weights/          ← learned ranking parameters\n```\n\n#### Core Ranking Data Structures\n\n```python\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Optional, Tuple\nimport numpy as np\nfrom datetime import datetime\n\n@dataclass\nclass RankingSignals:\n    \"\"\"Individual ranking signals for a query-document pair.\"\"\"\n    semantic_score: float           # Cosine similarity from embeddings\n    bm25_score: float              # Lexical matching score\n    personalization_score: float   # User preference alignment\n    freshness_score: float         # Time-based relevance decay\n    click_score: Optional[float]    # Historical click-through signal\n    \n@dataclass  \nclass RankingCandidate:\n    \"\"\"Document candidate with all ranking signals computed.\"\"\"\n    document: Document\n    signals: RankingSignals\n    combined_score: float\n    stage: str                     # 'retrieval', 'hybrid', 'reranked'\n    \n@dataclass\nclass PersonalizationContext:\n    \"\"\"User context for personalized ranking.\"\"\"\n    user_id: Optional[str]\n    role: Optional[str]            # 'developer', 'manager', 'researcher'\n    industry: Optional[str]\n    experience_level: Optional[str] # 'beginner', 'intermediate', 'expert'  \n    recent_clicks: List[str]       # Recent clicked document IDs\n    topic_preferences: Dict[str, float]  # Topic weights from history\n```\n\n#### Multi-Stage Ranking Pipeline Implementation\n\n```python\nclass MultiStageRanker:\n    \"\"\"Orchestrates multi-stage ranking pipeline for optimal speed and precision.\"\"\"\n    \n    def __init__(self, vector_index, keyword_index, cross_encoder_path: str):\n        self.vector_index = vector_index\n        self.keyword_index = keyword_index\n        self.hybrid_scorer = HybridScorer()\n        self.cross_encoder = CrossEncoderReranker(cross_encoder_path)\n        self.click_learner = ClickThroughLearner()\n        \n    def rank_documents(self, processed_query: ProcessedQuery, \n                      personalization_context: Optional[PersonalizationContext] = None,\n                      max_results: int = 20) -> List[SearchResult]:\n        \"\"\"\n        Execute complete multi-stage ranking pipeline.\n        \n        Stage 1: Fast candidate retrieval using vector and keyword search\n        Stage 2: Hybrid scoring with multiple signals  \n        Stage 3: Cross-encoder reranking for final precision\n        \"\"\"\n        # TODO 1: Retrieve semantic candidates using vector similarity search\n        # Call self.vector_index.search(processed_query.primary_embedding, k=5000)\n        # Extract document IDs and similarity scores from vector search results\n        \n        # TODO 2: Retrieve lexical candidates using BM25 keyword search  \n        # Call self.keyword_index.search(processed_query.normalized_query, k=5000)\n        # Extract document IDs and BM25 scores from keyword search results\n        \n        # TODO 3: Combine and deduplicate candidate sets from both retrieval methods\n        # Create union of semantic and lexical candidates, handling score conflicts\n        # Aim for 8K-10K total candidates for hybrid scoring stage\n        \n        # TODO 4: Apply hybrid scoring to combined candidate set\n        # For each candidate, compute personalization and freshness scores\n        # Combine all signals using learned weights: semantic, lexical, personal, fresh\n        # Select top 200-500 candidates based on hybrid scores\n        \n        # TODO 5: Apply cross-encoder reranking to top hybrid candidates\n        # Pass (query_text, document_content) pairs to transformer model\n        # Replace hybrid scores with precise cross-encoder relevance scores\n        # This is the most expensive step - limit to top candidates only\n        \n        # TODO 6: Apply click-through learning adjustments\n        # Boost/demote results based on historical click patterns for this query\n        # Only apply adjustments where sufficient click data exists (>10 clicks)\n        \n        # TODO 7: Format final results with snippets and highlighting\n        # Generate result snippets around query terms, apply highlighting\n        # Include ranking signal breakdown for debugging and analytics\n        \n        pass\n\nclass HybridScorer:\n    \"\"\"Combines semantic similarity, BM25, personalization, and freshness signals.\"\"\"\n    \n    def __init__(self):\n        # Learned or manually tuned weights for signal combination\n        self.weights = {\n            'semantic': 0.4,\n            'bm25': 0.3, \n            'personalization': 0.2,\n            'freshness': 0.1\n        }\n        self.personalizer = PersonalizationScorer()\n        self.freshness_scorer = FreshnessScorer()\n        \n    def score_candidate(self, document: Document, processed_query: ProcessedQuery,\n                       semantic_score: float, bm25_score: float,\n                       personalization_context: Optional[PersonalizationContext]) -> RankingSignals:\n        \"\"\"Compute all ranking signals for a query-document pair.\"\"\"\n        # TODO 1: Normalize semantic similarity score to 0-1 range\n        # Cosine similarity returns -1 to 1, map to 0-1: (score + 1) / 2\n        \n        # TODO 2: Normalize BM25 score using sigmoid transformation\n        # BM25 scores are unbounded, apply: 1 / (1 + exp(-score/10))\n        # Adjust the divisor (10) based on your BM25 score distribution\n        \n        # TODO 3: Compute personalization score using user context\n        # Call self.personalizer.score() with document and user context\n        # Handle case where personalization_context is None (return 0.5)\n        \n        # TODO 4: Compute freshness score based on document age\n        # Call self.freshness_scorer.score() with document creation date\n        # Apply domain-specific decay rates for different content types\n        \n        # TODO 5: Return RankingSignals object with all computed scores\n        \n        pass\n        \n    def combine_signals(self, signals: RankingSignals, query_type: str) -> float:\n        \"\"\"Combine individual signals into final hybrid score.\"\"\"\n        # TODO 1: Apply query-adaptive weight adjustment\n        # Technical queries: increase bm25 weight, decrease semantic weight\n        # Exploratory queries: increase semantic weight, decrease bm25 weight\n        \n        # TODO 2: Compute weighted combination of all signals\n        # combined = w_sem * semantic + w_bm25 * bm25 + w_pers * personal + w_fresh * fresh\n        \n        # TODO 3: Apply score normalization and bounds checking\n        # Ensure final score is in valid range, handle edge cases\n        \n        pass\n```\n\n#### Cross-Encoder Reranking Component\n\n```python\nfrom sentence_transformers import CrossEncoder\n\nclass CrossEncoderReranker:\n    \"\"\"High-precision reranking using transformer cross-encoder models.\"\"\"\n    \n    def __init__(self, model_path: str):\n        # Load pre-trained cross-encoder model for relevance scoring\n        self.model = CrossEncoder(model_path)\n        self.max_candidates = 500  # Computational budget limit\n        \n    def rerank_candidates(self, candidates: List[RankingCandidate], \n                         query_text: str) -> List[RankingCandidate]:\n        \"\"\"Apply cross-encoder reranking to top hybrid candidates.\"\"\"\n        # TODO 1: Prepare query-document pairs for cross-encoder input\n        # Format as [(query_text, doc.get_searchable_text()) for each candidate]\n        # Limit to top N candidates based on hybrid scores to control latency\n        \n        # TODO 2: Run cross-encoder prediction in batches for efficiency\n        # Call self.model.predict() on query-document pairs\n        # Use batch processing to amortize model loading costs\n        \n        # TODO 3: Replace hybrid scores with cross-encoder scores  \n        # Update candidate.combined_score with precise cross-encoder relevance\n        # Mark candidates with stage='reranked' for analytics\n        \n        # TODO 4: Re-sort candidates by new cross-encoder scores\n        # Return candidates in descending order of cross-encoder relevance\n        \n        pass\n```\n\n#### Personalization and Freshness Scoring\n\n```python\nclass PersonalizationScorer:\n    \"\"\"Computes personalization scores based on user context and preferences.\"\"\"\n    \n    def score_document(self, document: Document, \n                      context: PersonalizationContext) -> float:\n        \"\"\"Compute personalization relevance score for user context.\"\"\"\n        if not context or not context.user_id:\n            return 0.5  # Neutral score for anonymous users\n            \n        # TODO 1: Compute role-based relevance boost\n        # Check if document metadata tags match user role/industry\n        # Apply boost for documents tagged as relevant to user's profession\n        \n        # TODO 2: Compute historical interest similarity  \n        # Compare document embedding to embeddings of previously clicked docs\n        # Use average cosine similarity to recent click history\n        \n        # TODO 3: Apply experience level filtering\n        # Boost beginner-friendly docs for novice users, advanced docs for experts\n        # Use document complexity indicators (length, technical terms, etc.)\n        \n        # TODO 4: Combine personalization signals with learned weights\n        # role_boost (0.3) + history_similarity (0.5) + experience_match (0.2)\n        \n        pass\n\nclass FreshnessScorer:\n    \"\"\"Applies time-based relevance decay with domain-specific parameters.\"\"\"\n    \n    def __init__(self):\n        # Domain-specific decay rates (higher lambda = faster decay)\n        self.decay_rates = {\n            'news': 0.1,           # Half-life ~7 days\n            'tutorial': 0.01,      # Half-life ~70 days  \n            'documentation': 0.005, # Half-life ~140 days\n            'research': 0.002,     # Half-life ~350 days\n            'default': 0.01\n        }\n        \n    def score_document(self, document: Document) -> float:\n        \"\"\"Compute freshness score using exponential decay.\"\"\"\n        # TODO 1: Extract document creation date from metadata\n        # Handle missing creation dates (use current time or neutral score)\n        \n        # TODO 2: Determine content type for appropriate decay rate\n        # Use document metadata, URL patterns, or content classification\n        # Default to 'default' category if type cannot be determined\n        \n        # TODO 3: Compute document age in days\n        # age_days = (current_date - creation_date).days\n        \n        # TODO 4: Apply exponential decay formula\n        # freshness_score = exp(-lambda * age_days)\n        # Ensure score is in valid range [0, 1]\n        \n        pass\n```\n\n#### Click-Through Learning System\n\n```python\nclass ClickThroughLearner:\n    \"\"\"Learns from user click patterns to improve ranking quality.\"\"\"\n    \n    def __init__(self, min_clicks_threshold: int = 10):\n        self.min_clicks_threshold = min_clicks_threshold\n        self.position_bias_model = PositionBiasModel()\n        self.preference_extractor = PreferenceExtractor()\n        \n    def record_interaction(self, query: str, results: List[SearchResult],\n                          click_position: Optional[int], dwell_time: Optional[float]):\n        \"\"\"Record user interaction for learning.\"\"\"\n        # TODO 1: Log interaction event with full context\n        # Store query, result list, click position, dwell time, timestamp\n        # Include session ID for multi-click pattern analysis\n        \n        # TODO 2: Update position bias estimates\n        # Track examination and click rates by result position\n        # Use for position bias correction in relevance estimation\n        \n        # TODO 3: Extract pairwise preferences from click patterns\n        # Skip-above: clicked lower result vs. skipped higher result\n        # Dwell time: longer engagement suggests higher relevance\n        \n        pass\n        \n    def get_click_adjustments(self, query: str, candidates: List[RankingCandidate]) -> Dict[str, float]:\n        \"\"\"Get learned score adjustments based on click history.\"\"\"\n        # TODO 1: Check if sufficient click data exists for this query\n        # Return empty adjustments if below minimum click threshold\n        \n        # TODO 2: Compute position-bias corrected click rates  \n        # Apply position bias correction to get true relevance estimates\n        # Use aggregated click data across similar queries if exact match sparse\n        \n        # TODO 3: Generate score adjustments for candidate documents\n        # Boost documents with high corrected click rates\n        # Apply conservative adjustments to avoid overfitting to noise\n        \n        pass\n```\n\n#### Milestone Checkpoint\n\nAfter implementing the ranking and relevance component, verify the following behavior:\n\n**Basic Multi-Stage Ranking Test:**\n```bash\npython -m pytest ranking/ranking_test.py::test_multi_stage_pipeline -v\n```\n\nExpected behavior:\n- Stage 1 retrieval returns 5K-10K candidates in <100ms\n- Stage 2 hybrid scoring processes candidates in <100ms  \n- Stage 3 cross-encoder reranking completes in <200ms\n- Final results show diverse ranking signals in result metadata\n\n**Hybrid Scoring Validation:**\n```python\n# Test semantic vs. lexical query handling\nsemantic_query = \"improve team productivity\"  # Should favor semantic signals\ntechnical_query = \"Python asyncio tutorial\"   # Should favor lexical signals\n\n# Verify query-adaptive weight adjustment works correctly\n```\n\n**Personalization Testing:**\n```python\n# Test personalized vs. anonymous ranking\ncontext = PersonalizationContext(\n    user_id=\"test_user\",\n    role=\"developer\", \n    recent_clicks=[\"doc1\", \"doc2\"]\n)\n# Verify personalized results differ from anonymous results\n```\n\n#### Common Debugging Issues\n\n| Symptom | Likely Cause | Diagnosis | Fix |\n|---------|--------------|-----------|-----|\n| All results have same score | Score normalization broken | Check score ranges before combination | Implement proper min-max or sigmoid normalization |\n| Cross-encoder timeout | Too many candidates sent | Check candidate count before reranking | Limit to <500 candidates for cross-encoder |\n| Poor result diversity | Over-aggressive personalization | Check personalization weight distribution | Reduce personalization weight below 0.3 |\n| Slow query response | Inefficient signal computation | Profile each ranking stage latency | Cache expensive computations, optimize batch processing |\n| Click learning not improving results | Insufficient or noisy click data | Analyze click data quality and volume | Implement click filtering, increase collection period |\n\n\n## Search API and User Interface\n\n> **Milestone(s):** Milestone 4: Search API & UI\n\nThe **Search API and User Interface** represents the final presentation layer that transforms our sophisticated semantic search capabilities into a responsive, production-ready service. This component serves as the bridge between end users and the complex underlying architecture we've built through the previous milestones. While the embedding index provides the foundation, query processing adds intelligence, and ranking ensures relevance, the search API makes these capabilities accessible through intuitive interfaces that feel instant and natural to users.\n\nThe challenge in this component lies not just in exposing functionality, but in doing so with the performance characteristics that users expect from modern search experiences. Sub-100ms autocomplete responses, comprehensive result formatting with highlighted terms, and real-time analytics all require careful architectural decisions that balance functionality with speed. This component must also handle the practical concerns of production systems: graceful error handling, comprehensive logging, and the ability to monitor and improve search quality over time.\n\n### Search API Mental Model: Reference Librarian Analogy\n\nThink of the Search API as an expert reference librarian who has mastered the art of responsive assistance. Just as a skilled librarian can quickly understand what you're looking for from just a few words, provide instant suggestions as you describe your needs, organize results by relevant categories, and highlight exactly why each resource matches your request, our search API provides the same intuitive, helpful interface to our semantic search engine.\n\nThe librarian analogy extends to the multi-layered nature of search assistance. When you approach a reference desk, the librarian doesn't just wait for your complete question—they start helping immediately. As you begin speaking, they might suggest related topics (autocomplete). Once you've explained your need, they don't just find one book—they organize recommendations by subject area (faceted navigation), mark relevant passages (highlighting), and explain why each resource fits your request (relevance scoring). They also remember what kinds of questions people ask most often and which resources proved most helpful (analytics).\n\nThis mental model guides our API design decisions. Every endpoint must respond with the immediacy users expect, every response must be structured to facilitate quick understanding, and every interaction must contribute to improving future search experiences. The API becomes not just a programmatic interface, but a conversational partner in the information discovery process.\n\n> **Decision: RESTful JSON API Design**\n> - **Context**: Need to choose API style and data format for maximum compatibility and ease of use\n> - **Options Considered**: GraphQL for flexible queries, gRPC for performance, REST with JSON for simplicity\n> - **Decision**: RESTful JSON API with standardized endpoints and response formats\n> - **Rationale**: REST provides universal compatibility across platforms and languages, JSON offers human-readable debugging, and the request patterns for search are well-suited to REST's resource-oriented design\n> - **Consequences**: Slightly higher bandwidth than binary protocols, but gains in developer experience, debugging ease, and ecosystem compatibility far outweigh the costs\n\n| API Design Option | Pros | Cons | Chosen? |\n|-------------------|------|------|---------|\n| REST + JSON | Universal compatibility, easy debugging, extensive tooling | Higher bandwidth than binary formats | ✅ Yes |\n| GraphQL | Flexible client-driven queries, single endpoint | Added complexity for simple search use case | ❌ No |\n| gRPC + Protobuf | High performance, type safety, streaming | Language-specific tooling, harder debugging | ❌ No |\n\n### RESTful Search Endpoints\n\nThe core search functionality exposes through a carefully designed set of REST endpoints that balance simplicity with comprehensive functionality. The primary search endpoint accepts rich query parameters while maintaining backward compatibility and intuitive defaults.\n\nThe main search endpoint follows the pattern `/api/v1/search` and accepts both GET requests for simple queries and POST requests for complex search contexts. This dual approach accommodates direct URL sharing (critical for search applications) while supporting advanced features like personalization contexts that don't belong in URL parameters.\n\n| Endpoint | Method | Purpose | Response Time Target |\n|----------|--------|---------|---------------------|\n| `/api/v1/search` | GET/POST | Primary search functionality | < 500ms p95 |\n| `/api/v1/autocomplete` | GET | Typeahead suggestions | < 100ms p95 |\n| `/api/v1/facets/{field}` | GET | Available filter values | < 200ms p95 |\n| `/api/v1/analytics` | GET | Search quality metrics | < 2000ms p95 |\n\nThe `QueryRequest` structure accommodates both simple and sophisticated search scenarios. The design philosophy prioritizes making simple queries trivial while enabling complex use cases through optional parameters.\n\n| QueryRequest Field | Type | Description | Default |\n|--------------------|------|-------------|---------|\n| `query_text` | str | User's search query text | Required |\n| `max_results` | int | Maximum results to return | 20 |\n| `filters` | Optional[Dict] | Category/metadata filters | None |\n| `personalization_context` | Optional[Dict] | User context for ranking | None |\n| `include_facets` | bool | Return facet counts with results | false |\n\nThe filters dictionary supports hierarchical filtering with intuitive operators. For example, `{\"category\": [\"technology\", \"science\"], \"date_range\": {\"after\": \"2023-01-01\"}}` enables multi-value category filtering combined with temporal constraints. This approach maintains JSON simplicity while supporting sophisticated filter combinations.\n\nPersonalization context allows clients to provide user-specific information that enhances ranking quality without requiring server-side user management. The API remains stateless while enabling personalized results through client-provided context.\n\n| PersonalizationContext Field | Type | Description | Usage Example |\n|------------------------------|------|-------------|---------------|\n| `user_id` | Optional[str] | Stable user identifier | For click-through learning |\n| `role` | Optional[str] | User's professional role | \"software engineer\" |\n| `industry` | Optional[str] | User's industry domain | \"healthcare\" |\n| `experience_level` | Optional[str] | User's expertise level | \"beginner\" |\n| `recent_clicks` | List[str] | Recently clicked document IDs | For implicit feedback |\n| `topic_preferences` | Dict[str, float] | Topic interest scores | {\"ai\": 0.9, \"frontend\": 0.3} |\n\nThe `QueryResponse` format provides comprehensive information while maintaining efficient parsing for client applications. Each response includes not just results, but metadata that enables rich user experiences and performance monitoring.\n\n| QueryResponse Field | Type | Description | Client Usage |\n|---------------------|------|-------------|--------------|\n| `query` | str | Processed query text | Display what was actually searched |\n| `results` | List[SearchResult] | Ranked search results | Primary result display |\n| `total_found` | int | Total matching documents | Pagination and result count |\n| `processing_time_ms` | float | Server-side processing time | Performance monitoring |\n| `facets` | Optional[Dict] | Filter counts by category | Faceted navigation UI |\n\nIndividual search results provide rich metadata that enables sophisticated result presentation. The structure balances information completeness with response size efficiency.\n\n| SearchResult Field | Type | Description | Presentation Use |\n|-------------------|------|-------------|------------------|\n| `document` | Document | Full document metadata | Title, URL, creation date |\n| `relevance_score` | float | Combined ranking score (0-1) | Sort order, confidence indication |\n| `snippet` | str | Contextual text excerpt | Result preview |\n| `highlighted_terms` | List[str] | Query terms found in result | Term highlighting logic |\n| `ranking_signals` | Dict[str, float] | Individual signal contributions | Debug mode, relevance explanation |\n\n> The ranking signals dictionary provides transparency into how results were scored, enabling both debugging and user education about why particular results appeared. This transparency builds user trust and helps identify ranking issues during development.\n\n### Autocomplete and Typeahead\n\nThe autocomplete system provides the immediate responsiveness that users expect from modern search interfaces. The challenge lies in generating relevant suggestions within the 100ms latency budget while maintaining high suggestion quality and avoiding the computational overhead of full semantic search.\n\nThe autocomplete approach employs a multi-tier strategy that balances speed with relevance. The first tier uses a traditional prefix-based trie structure for instant character-level matching. The second tier applies lightweight semantic expansion using cached query embeddings for frequent search patterns. This hybrid approach ensures that common queries receive instant responses while less frequent queries benefit from semantic understanding.\n\n> **Decision: Hybrid Prefix + Semantic Autocomplete**\n> - **Context**: Need sub-100ms autocomplete responses while maintaining semantic understanding\n> - **Options Considered**: Pure prefix matching, full semantic search, hybrid approach\n> - **Decision**: Prefix trie for speed with semantic expansion for quality\n> - **Rationale**: Prefix matching alone misses semantic relationships, full semantic search exceeds latency budget, hybrid approach achieves both speed and intelligence\n> - **Consequences**: Requires maintaining dual data structures but delivers optimal user experience\n\nThe autocomplete endpoint implements aggressive caching and precomputation strategies to meet latency requirements. Popular query prefixes and their expansions are cached in memory, while semantic similarity computations for frequent patterns are precomputed during off-peak hours.\n\n| Autocomplete Strategy | Response Time | Quality | Implementation Complexity |\n|----------------------|---------------|---------|---------------------------|\n| Prefix Trie Only | < 10ms | Basic | Low |\n| Full Semantic Search | 200-500ms | Excellent | Medium |\n| Hybrid Approach | < 100ms | Good | High |\n\nThe autocomplete processing pipeline operates through several optimized stages:\n\n1. **Prefix Matching**: The system immediately identifies all cached queries that begin with the user's input characters. This provides instant baseline suggestions for common search patterns.\n\n2. **Semantic Expansion**: For queries that have insufficient prefix matches, the system computes a lightweight embedding of the partial query and finds semantically similar complete queries from the cache.\n\n3. **Popularity Ranking**: Suggestions are ranked by a combination of query frequency, recent search volume, and semantic similarity to the partial input. This ensures that popular, relevant queries appear first.\n\n4. **Context Filtering**: When personalization context is available, suggestions are filtered and reranked based on user preferences and search history. This personalization happens without violating the latency budget through precomputed user query clusters.\n\n5. **Response Formatting**: The final suggestions are formatted with highlighted matching portions and optional category indicators to help users understand why each suggestion was recommended.\n\nThe autocomplete cache employs a sophisticated warming strategy that anticipates user needs. During low-traffic periods, the system precomputes embeddings for trending queries, seasonal search patterns, and user-specific suggestion sets. This precomputation ensures that even semantically complex suggestions can be served within the latency budget.\n\n| Cache Layer | Content | Refresh Frequency | Size Limit |\n|-------------|---------|-------------------|------------|\n| Hot Prefix Cache | Most common prefixes + completions | Real-time updates | 10MB |\n| Semantic Cache | Query embeddings + similar queries | Hourly batch | 100MB |\n| User Cache | Personalized suggestions | Daily batch | 50MB |\n| Trending Cache | Current popular queries | 15-minute updates | 25MB |\n\n⚠️ **Pitfall: Autocomplete Latency Degradation**\nMany implementations start with acceptable autocomplete performance but degrade over time as the suggestion vocabulary grows. This happens because they perform semantic similarity computations in real-time during the autocomplete request. Instead, precompute semantic relationships during off-peak hours and use the autocomplete request time only for fast lookups and ranking. Monitor P95 latency continuously—if it exceeds 80ms, you're approaching the threshold where users perceive sluggishness.\n\n### Faceted Navigation\n\nFaceted navigation transforms the search experience from a linear result list into an interactive exploration interface. Users can drill down through categories, filter by metadata dimensions, and understand the distribution of results across different classification schemes. The implementation challenge lies in computing facet counts efficiently while maintaining the responsiveness users expect.\n\nThe faceting system operates on multiple metadata dimensions simultaneously, providing users with a comprehensive understanding of their result space. Each facet represents a different way to slice and organize the search results, from content categories to publication dates to author information.\n\n> Think of faceted navigation as providing multiple organizational lenses simultaneously. Just as a library might organize the same books by subject, author, publication year, and reading level, our faceted system shows users how their search results distribute across different classification dimensions. Users can then combine these lenses to narrow their focus to exactly what they need.\n\nThe facet computation pipeline balances accuracy with performance through a multi-stage approach. During the initial search request, the system computes exact facet counts only for the top result candidates. For deeper facet exploration, the system uses statistical sampling techniques to provide approximate counts that guide user exploration without requiring exhaustive computation.\n\n| Facet Type | Examples | Computation Strategy | Update Frequency |\n|------------|----------|---------------------|------------------|\n| Category | Technology, Science, Business | Exact counts from search results | Real-time |\n| Temporal | Last week, Last month, This year | Date range aggregation | Real-time |\n| Author/Source | Specific authors or publications | Metadata aggregation | Real-time |\n| Content Type | Article, Tutorial, Reference | Document type classification | Real-time |\n| Difficulty | Beginner, Intermediate, Advanced | ML-based content analysis | Batch processed |\n\nThe faceting algorithm operates through several optimized stages:\n\n1. **Result Set Analysis**: After the initial search retrieval, the system examines the top N results (typically 1000) to compute baseline facet distributions. This provides accurate counts for the most relevant portion of the result space.\n\n2. **Sampling Extension**: For facets that show interesting distributions in the top results, the system extends analysis to a statistical sample of the broader result set. This provides reasonably accurate estimates for deeper filtering.\n\n3. **Cache Integration**: Frequently requested facet combinations are cached with their count distributions. This enables instant facet navigation for common exploration patterns.\n\n4. **Interactive Refinement**: As users select facet filters, the system recomputes facet counts for the filtered result set. This maintains accuracy as the result space narrows through user interaction.\n\n5. **Zero-Count Handling**: Facets that would produce zero results are marked as unavailable rather than hidden entirely. This prevents user frustration from dead-end exploration paths.\n\nThe facet response format enables rich client-side filtering interfaces while maintaining server-side computation efficiency. Each facet includes not just counts, but metadata that helps clients build intuitive navigation experiences.\n\n| Facet Response Field | Type | Description | Client Usage |\n|---------------------|------|-------------|--------------|\n| `facet_name` | str | Human-readable facet category | Navigation section headers |\n| `facet_values` | List[Dict] | Available values with counts | Filter options and counts |\n| `selected_values` | List[str] | Currently active filters | UI state management |\n| `facet_type` | str | UI hint (single/multi select) | Appropriate input controls |\n| `more_available` | bool | Whether additional values exist | \"Show more\" functionality |\n\nIndividual facet values include rich metadata that enables sophisticated filtering interfaces:\n\n| Facet Value Field | Type | Description | Interface Use |\n|-------------------|------|-------------|---------------|\n| `value` | str | Filter value identifier | Query parameter |\n| `display_name` | str | Human-readable label | User interface |\n| `count` | int | Documents matching this filter | Result count display |\n| `selected` | bool | Whether currently applied | UI state indication |\n| `estimated` | bool | Whether count is approximate | Confidence indication |\n\n⚠️ **Pitfall: Expensive Facet Count Computation**\nComputing exact facet counts across large result sets can easily exceed response time budgets. Many implementations try to compute exact counts for all possible facet values on every search request. Instead, compute exact counts only for the most relevant results (top 1000), use sampling for broader estimates, and cache common facet combinations. Reserve exact computation for the final filtered result set when users have narrowed their search scope.\n\n### Query Term Highlighting\n\nQuery term highlighting transforms search results from simple text blocks into visually scannable content that clearly indicates why each result matches the user's query. The challenge extends beyond simple string matching because semantic search introduces conceptual matches that don't correspond to exact query terms. Users need to understand not just which documents matched, but why they matched.\n\nThe highlighting system operates at multiple semantic levels. At the lexical level, it identifies exact query term matches and synonymous terms. At the semantic level, it identifies text passages that contributed to the document's semantic similarity score, even when they don't contain query keywords. This multi-level approach helps users understand both traditional keyword matches and the semantic relationships that make our search engine intelligent.\n\n> The highlighting system acts like a knowledgeable teacher marking up a text to show a student exactly where the relevant information appears. Just as a teacher might highlight not only the exact words the student asked about, but also related concepts and supporting details, our system marks both literal matches and semantically related content that contributed to the document's relevance.\n\nThe highlighting algorithm balances precision with comprehensiveness through a multi-stage analysis process:\n\n1. **Exact Match Identification**: The system identifies all instances where query terms appear exactly in the document text. This includes handling case variations, punctuation differences, and word boundary detection.\n\n2. **Synonym Recognition**: Using the same synonym expansion logic from query processing, the system identifies terms in the document that are synonymous with query terms. These receive highlighting with visual distinction from exact matches.\n\n3. **Semantic Contribution Analysis**: The system analyzes which text passages contributed most strongly to the document's semantic similarity score. This involves computing attention weights between query embedding and document text segments.\n\n4. **Context Window Generation**: Around each highlighted term, the system extracts contextual text that helps users understand the match relevance. Context windows are sized to provide meaningful understanding without overwhelming the result display.\n\n5. **Snippet Optimization**: The final highlighting process selects the most representative passages from the document, ensuring that snippets contain highlighted terms while providing coherent reading experience.\n\n| Highlighting Type | Visual Treatment | Confidence Threshold | Context Window Size |\n|-------------------|------------------|---------------------|---------------------|\n| Exact Match | Bold highlighting | 1.0 | 50 characters each side |\n| Synonym Match | Italic highlighting | > 0.8 similarity | 40 characters each side |\n| Semantic Match | Underline highlighting | > 0.6 attention weight | 60 characters each side |\n| Related Concept | Subtle highlighting | > 0.4 attention weight | 30 characters each side |\n\nThe highlighting response format enables sophisticated client-side presentation while maintaining server-side computation control:\n\n| Highlighting Field | Type | Description | Client Usage |\n|-------------------|------|-------------|--------------|\n| `original_text` | str | Unmodified document excerpt | Fallback display |\n| `highlighted_html` | str | HTML with highlight markup | Rich text presentation |\n| `highlight_spans` | List[Dict] | Structured highlight metadata | Custom styling |\n| `snippet_score` | float | Relevance score for this excerpt | Snippet ranking |\n\nEach highlight span provides detailed metadata that enables customizable presentation:\n\n| Highlight Span Field | Type | Description | Styling Use |\n|---------------------|------|-------------|-------------|\n| `start_pos` | int | Character position start | Text range selection |\n| `end_pos` | int | Character position end | Text range selection |\n| `highlight_type` | str | Match type (exact/synonym/semantic) | CSS class selection |\n| `confidence` | float | Match confidence score | Visual intensity |\n| `query_term` | str | Original query term that matched | Tooltip information |\n\nThe semantic highlighting component represents one of the most sophisticated aspects of the system. Rather than relying purely on text matching, it analyzes the attention patterns from the semantic similarity computation to identify which document passages most strongly influenced the relevance score.\n\nThis semantic analysis operates through transformer attention weight extraction. When computing semantic similarity between query and document embeddings, the system captures intermediate attention weights that indicate which tokens in the document text most strongly aligned with query concepts. These attention weights are then mapped back to text positions to enable highlighting of semantically relevant passages.\n\n⚠️ **Pitfall: HTML Entity Corruption in Highlighting**\nWhen highlighting text that contains HTML entities or special characters, many implementations break the text structure by inserting highlight markup in the middle of entity codes. For example, highlighting \"amp\" in \"Smith &amp; Jones\" can produce \"Smith &<mark>amp</mark>; Jones\" which renders incorrectly. Always parse HTML entities before highlighting analysis, perform highlighting on the decoded text, then carefully reconstruct the highlighted version while preserving entity integrity.\n\n### Search Analytics Dashboard\n\nThe analytics dashboard transforms search usage data into actionable insights for improving search quality and understanding user behavior. This component serves multiple stakeholders: developers need performance metrics and error rates, product managers need usage patterns and success metrics, and search quality engineers need relevance feedback and improvement opportunities.\n\nThe analytics system captures comprehensive search telemetry without impacting search request performance. All analytics data collection happens asynchronously, with critical metrics cached in memory and periodically flushed to persistent storage. This approach ensures that search responsiveness remains unaffected by analytics overhead.\n\n> Think of the analytics dashboard as a search engine health monitor that works like a fitness tracker for your system. Just as a fitness tracker passively collects data about your daily activity and then provides insights about patterns, trends, and opportunities for improvement, the analytics system continuously observes search behavior and transforms that data into actionable insights about system health and user satisfaction.\n\nThe analytics data model captures both technical performance metrics and user behavior signals. This comprehensive approach enables correlation analysis between system performance and user satisfaction metrics.\n\n| Analytics Category | Metrics Tracked | Update Frequency | Retention Period |\n|-------------------|----------------|------------------|------------------|\n| Performance | Response time, error rate, cache hit rate | Real-time aggregation | 90 days detailed |\n| Usage | Query volume, result clicks, zero-result queries | Real-time streaming | 1 year summarized |\n| Quality | Click-through rates, dwell time, result ranking | Batch processing | 6 months detailed |\n| System Health | Index size, memory usage, disk I/O | 1-minute intervals | 30 days detailed |\n\nThe analytics collection pipeline operates through several specialized components:\n\n1. **Request Telemetry**: Every search request generates telemetry data including query text (optionally hashed for privacy), response time, result count, and user interaction context. This data is immediately queued for asynchronous processing.\n\n2. **User Interaction Tracking**: Click-through events, result dwell times, and query refinement patterns are captured to understand search success rates. This behavioral data provides crucial feedback about ranking quality.\n\n3. **Zero-Result Analysis**: Queries that return no results receive special attention, as they represent opportunities for index expansion, query processing improvement, or user education.\n\n4. **Performance Monitoring**: System-level metrics including memory usage, CPU utilization, and index access patterns are continuously collected to identify performance bottlenecks and capacity planning needs.\n\n5. **Quality Scoring**: Automated quality metrics are computed by analyzing user behavior patterns, comparing semantic similarity scores with user satisfaction signals, and identifying queries where ranking could be improved.\n\nThe analytics dashboard presents this data through several specialized views designed for different stakeholder needs:\n\n| Dashboard View | Target Audience | Key Metrics | Refresh Rate |\n|----------------|----------------|-------------|--------------|\n| Operations Dashboard | SRE/DevOps | Error rates, latency, throughput | Real-time |\n| Usage Analytics | Product Management | Query trends, user engagement | Hourly |\n| Quality Metrics | Search Engineers | Relevance scores, click-through rates | Daily |\n| Business Intelligence | Executives | Search ROI, content gaps | Weekly |\n\nThe zero-result query analysis represents a particularly valuable analytics capability. These queries often indicate content gaps, query processing limitations, or opportunities for search education. The system automatically categorizes zero-result queries and provides recommendations for improvement.\n\n| Zero-Result Category | Characteristics | Improvement Strategy | Implementation Priority |\n|---------------------|----------------|---------------------|------------------------|\n| Spelling Errors | Obvious typos, character transpositions | Query spelling correction | High |\n| Missing Content | Valid queries, no matching documents | Content acquisition | Medium |\n| Processing Failures | System errors, timeout failures | Technical fixes | Critical |\n| Over-Specific | Queries too narrow for available content | Query relaxation suggestions | Medium |\n| Domain Mismatch | Queries outside system scope | User education | Low |\n\nThe analytics system implements sophisticated privacy protection while maintaining analytical value. User queries can be hashed for privacy while preserving the ability to identify trends and patterns. User interaction data is aggregated to prevent individual tracking while enabling quality improvement.\n\nAdvanced analytics features include automated anomaly detection that identifies unusual search patterns, performance degradation, or quality regressions. The system establishes baseline performance and quality metrics, then alerts when significant deviations occur.\n\n| Anomaly Type | Detection Method | Alert Threshold | Response Action |\n|--------------|------------------|----------------|-----------------|\n| Performance Degradation | Response time percentile shift | P95 > 2x baseline | Immediate investigation |\n| Quality Regression | Click-through rate drop | CTR < 0.7x baseline | Search team notification |\n| Usage Spike | Query volume increase | Volume > 3x normal | Capacity scaling |\n| Error Rate Increase | Error percentage rise | Error rate > 5% | Engineering escalation |\n\n⚠️ **Pitfall: Analytics Data Overwhelming Search Performance**\nMany search systems start with simple logging but gradually add more comprehensive analytics that eventually impact search response times. This happens because analytics collection is often implemented synchronously within the search request path. Instead, implement all analytics as asynchronous fire-and-forget operations. Use in-memory buffers for metrics collection and background threads for persistence. Never let analytics impact search latency—users will notice the performance degradation long before the analytics provide value.\n\n### Component Interactions and Data Flow\n\nThe Search API component orchestrates complex interactions between all previously implemented components while maintaining the illusion of simplicity for client applications. Understanding these interactions is crucial for implementing the API layer correctly and diagnosing issues that span multiple components.\n\n![Search Request Sequence](./diagrams/search-sequence.svg)\n\nThe primary search request follows a carefully choreographed sequence that balances thoroughness with performance. Each step has specific timing requirements and fallback strategies to ensure robust operation.\n\nThe search request processing flow operates through these coordinated stages:\n\n1. **Request Validation and Parsing**: The API layer validates incoming requests, applies default values, and transforms client request format into internal processing structures. Invalid requests are rejected immediately with helpful error messages.\n\n2. **Query Processing Invocation**: The validated request is passed to the Query Processing component for expansion, normalization, and embedding generation. This stage can leverage cached embeddings for frequently requested queries.\n\n3. **Parallel Index Search**: With the processed query, the system performs parallel searches across the vector index (semantic search) and keyword index (lexical search) if hybrid ranking is enabled. These searches happen concurrently to minimize latency.\n\n4. **Ranking Engine Coordination**: Raw search results from both semantic and lexical searches are passed to the Ranking Engine for multi-stage ranking, personalization, and final result selection.\n\n5. **Result Enhancement**: The ranked results undergo highlighting, snippet generation, and metadata enrichment to produce rich result representations suitable for client consumption.\n\n6. **Response Assembly**: Final results are assembled into the standardized response format, including facet information if requested and analytics telemetry for later processing.\n\n![Search API Interaction Flow](./diagrams/api-interaction.svg)\n\nThe autocomplete request processing follows a streamlined path optimized for minimal latency:\n\n1. **Prefix Cache Lookup**: Immediate lookup in the hot prefix cache for instant common completions\n2. **Semantic Expansion**: If prefix cache is insufficient, semantic similarity computation against cached query embeddings\n3. **Personalization Filter**: Optional filtering and reranking based on user context\n4. **Response Formatting**: Final suggestion list assembly with highlighting and metadata\n\nThe faceting request requires coordination with the search results to compute accurate counts:\n\n1. **Base Search Execution**: Run the underlying search query to establish the result set\n2. **Facet Computation**: Analyze result metadata to compute facet value distributions\n3. **Cache Update**: Update facet cache entries for frequently requested combinations\n4. **Response Assembly**: Format facet data with counts, selections, and UI hints\n\nError handling across component interactions requires sophisticated coordination because failures can occur at multiple levels simultaneously. The API layer implements circuit breaker patterns and graceful degradation strategies.\n\n| Component Failure | Detection Method | Fallback Strategy | User Impact |\n|-------------------|------------------|------------------|-------------|\n| Query Processing | Timeout or exception | Use raw query text | Reduced semantic understanding |\n| Vector Index | Search failure | Lexical-only search | Missing semantic matches |\n| Ranking Engine | Processing error | Basic similarity ranking | Reduced personalization |\n| Highlighting | Analysis failure | Plain text snippets | No term highlighting |\n\nThe analytics collection system operates as a completely separate data flow that doesn't impact primary search functionality. All search requests generate analytics events that are queued asynchronously and processed in background threads.\n\nInternal component communication follows standardized interfaces that enable independent testing and development. Each component exposes well-defined methods with clear contracts for parameters, return values, and error conditions.\n\n| Component Interface | Method Signature | Purpose | Error Conditions |\n|---------------------|-----------------|---------|------------------|\n| `QueryProcessor.process_query()` | `(query_text: str, context: Dict) -> ProcessedQuery` | Query enhancement | Malformed input, processing timeout |\n| `EmbeddingIndex.search()` | `(embedding: np.ndarray, k: int) -> List[SearchResult]` | Vector similarity search | Index unavailable, embedding mismatch |\n| `RankingEngine.rank_documents()` | `(query: ProcessedQuery, candidates: List) -> List[SearchResult]` | Multi-stage ranking | Ranking model failure, context error |\n\n⚠️ **Pitfall: Component Timeout Cascades**\nWhen one component experiences latency issues, timeouts can cascade through the entire search request processing pipeline, resulting in user-visible failures even when most components are functioning correctly. Implement independent timeouts for each component interaction with appropriate fallback strategies. If query processing takes too long, fall back to simple query handling. If personalized ranking fails, use generic ranking. Users prefer fast, basic results to slow, sophisticated results or error messages.\n\n### Common Pitfalls\n\nSearch API implementation involves several subtle pitfalls that can significantly impact user experience and system performance:\n\n⚠️ **Pitfall: Autocomplete Cache Staleness**\nAutocomplete suggestions can become stale when new content is indexed but the autocomplete cache isn't updated correspondingly. Users start seeing suggestions for content that no longer exists or missing suggestions for recently added content. Implement cache invalidation triggered by index updates, or use short TTL values (15-30 minutes) for autocomplete cache entries. Monitor cache hit rates—if they drop significantly, it may indicate cache invalidation issues.\n\n⚠️ **Pitfall: Facet Count Inconsistency**\nFacet counts may not sum to the total result count due to documents matching multiple facet values or having missing metadata. This confuses users who expect mathematical consistency. Always include an \"Other\" or \"Uncategorized\" facet for documents that don't match standard facet values, and clearly document that documents can appear in multiple facets. Consider showing overlapping counts explicitly rather than hiding the complexity.\n\n⚠️ **Pitfall: Response Size Explosion**\nAs search functionality grows sophisticated, response sizes can grow dramatically with detailed ranking signals, multiple snippet options, and comprehensive facet information. Large responses impact network performance and client parsing time. Implement response size monitoring and consider pagination or lazy loading for detailed metadata. Provide client options to control response verbosity—basic clients may only need titles and URLs, while advanced clients benefit from full metadata.\n\n⚠️ **Pitfall: Error Message Information Leakage**\nDetailed error messages that help developers debug can inadvertently expose system internals or sensitive information to end users. Database connection failures, file system paths, or internal component names should not appear in public API responses. Implement error message sanitization that provides helpful information to developers (in logs) while showing generic, safe messages to end users. Include correlation IDs so support can link user reports to detailed internal logs.\n\n⚠️ **Pitfall: Analytics Overhead Creep**\nAnalytics collection often starts lightweight but gradually adds more detailed tracking that eventually impacts search performance. This happens because each analytics addition seems minor individually, but collectively they can slow request processing significantly. Regularly audit analytics collection overhead and ensure all tracking remains asynchronous. Set strict CPU and memory budgets for analytics code—if tracking exceeds these budgets, simplify the collection or move it to background processing.\n\n### Implementation Guidance\n\nThe Search API implementation focuses on building production-ready endpoints that deliver excellent user experience while maintaining system performance and reliability.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Web Framework | Flask with JSON responses | FastAPI with automatic OpenAPI docs |\n| Request Validation | Manual parameter checking | Pydantic models with validation |\n| Caching Layer | In-memory Python dictionaries | Redis with TTL and invalidation |\n| Analytics Storage | SQLite with periodic aggregation | ClickHouse for high-volume analytics |\n| Rate Limiting | Flask-Limiter with memory backend | Redis-based distributed rate limiting |\n\n**Recommended File Structure:**\n```\nproject-root/\n  api/\n    __init__.py\n    main.py                    ← FastAPI app and route definitions\n    models/\n      __init__.py\n      requests.py              ← QueryRequest, AutocompleteRequest models\n      responses.py             ← QueryResponse, SearchResult models\n    endpoints/\n      __init__.py\n      search.py                ← Primary search endpoint logic\n      autocomplete.py          ← Typeahead and suggestion logic\n      facets.py                ← Faceted navigation endpoints\n      analytics.py             ← Analytics and monitoring endpoints\n    middleware/\n      __init__.py\n      rate_limiting.py         ← Request rate limiting middleware\n      error_handling.py        ← Centralized error handling\n      analytics_collection.py  ← Request telemetry collection\n    utils/\n      __init__.py\n      highlighting.py          ← Query term highlighting logic\n      response_formatting.py   ← Result formatting utilities\n      cache_management.py      ← Cache warming and invalidation\n  tests/\n    api/\n      test_search_endpoints.py\n      test_autocomplete.py\n      test_analytics.py\n```\n\n**Infrastructure Starter Code - FastAPI Application Setup:**\n\n```python\nfrom fastapi import FastAPI, HTTPException, Depends\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import JSONResponse\nimport time\nimport logging\nfrom typing import Dict, Any\nimport asyncio\nfrom contextlib import asynccontextmanager\n\nfrom .models.requests import QueryRequest, AutocompleteRequest\nfrom .models.responses import QueryResponse, AutocompleteResponse\nfrom .middleware.rate_limiting import RateLimiter\nfrom .middleware.analytics_collection import AnalyticsCollector\nfrom .utils.cache_management import CacheManager\n\n# Global component instances\nsearch_components = {}\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup: Initialize all search components\n    from query_processing import QueryProcessor\n    from embedding_index import EmbeddingIndex\n    from ranking_engine import RankingEngine\n    \n    search_components[\"query_processor\"] = QueryProcessor()\n    search_components[\"embedding_index\"] = EmbeddingIndex.load_from_disk(\"./data/index\")\n    search_components[\"ranking_engine\"] = RankingEngine()\n    search_components[\"cache_manager\"] = CacheManager(max_size=10000)\n    search_components[\"analytics\"] = AnalyticsCollector()\n    \n    # Start background tasks\n    asyncio.create_task(search_components[\"cache_manager\"].start_cache_warming())\n    asyncio.create_task(search_components[\"analytics\"].start_background_processing())\n    \n    yield\n    \n    # Shutdown: Clean up resources\n    await search_components[\"analytics\"].flush_pending_events()\n    search_components[\"cache_manager\"].shutdown()\n\napp = FastAPI(\n    title=\"Semantic Search API\",\n    description=\"Production-ready semantic search with autocomplete and analytics\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# Add CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # Configure appropriately for production\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\"],\n    allow_headers=[\"*\"],\n)\n\n# Global error handler\n@app.exception_handler(Exception)\nasync def global_exception_handler(request, exc):\n    correlation_id = getattr(request.state, \"correlation_id\", \"unknown\")\n    logging.error(f\"Unhandled exception {correlation_id}: {str(exc)}\")\n    return JSONResponse(\n        status_code=500,\n        content={\"error\": \"Internal server error\", \"correlation_id\": correlation_id}\n    )\n\n# Dependency for component access\nasync def get_search_components() -> Dict[str, Any]:\n    return search_components\n\n# Rate limiting dependency\nrate_limiter = RateLimiter(max_requests=100, window_seconds=60)\n\nasync def rate_limit_dependency():\n    if not await rate_limiter.is_allowed():\n        raise HTTPException(status_code=429, detail=\"Rate limit exceeded\")\n```\n\n**Core Logic Skeleton - Main Search Endpoint:**\n\n```python\nfrom fastapi import APIRouter, Depends, HTTPException\nimport time\nimport logging\nfrom typing import Dict, Any\n\nfrom ..models.requests import QueryRequest\nfrom ..models.responses import QueryResponse\nfrom ..utils.highlighting import highlight_query_terms\nfrom ..utils.response_formatting import format_search_results\n\nrouter = APIRouter()\n\n@router.post(\"/api/v1/search\")\n@router.get(\"/api/v1/search\")\nasync def search_documents(\n    request: QueryRequest,\n    components: Dict[str, Any] = Depends(get_search_components),\n    _: None = Depends(rate_limit_dependency)\n) -> QueryResponse:\n    \"\"\"\n    Execute semantic search query and return ranked results.\n    \n    Handles both GET and POST requests for maximum compatibility.\n    GET requests parse query parameters, POST requests accept JSON body.\n    \"\"\"\n    start_time = time.time()\n    \n    try:\n        # TODO 1: Validate and normalize the search request\n        # - Check query_text is not empty and not too long (max 500 chars)\n        # - Apply default values for max_results (20), filters (empty dict)\n        # - Validate filter values are in expected format\n        # Hint: Use len(request.query_text.strip()) to check meaningful content\n        \n        # TODO 2: Process the query through QueryProcessor\n        # - Call components[\"query_processor\"].process_query(request.query_text, context)\n        # - Handle ProcessingTimeout exceptions with fallback to simple query\n        # - Log query processing time for performance monitoring\n        # Hint: Build context dict from request.personalization_context and filters\n        \n        # TODO 3: Execute parallel search across vector and keyword indices\n        # - Call embedding_index.search() with processed query embedding\n        # - If hybrid search enabled, also call keyword_index.search()\n        # - Combine results maintaining candidate provenance (which index)\n        # Hint: Use asyncio.gather() to run searches concurrently\n        \n        # TODO 4: Apply multi-stage ranking to search candidates\n        # - Pass candidates to ranking_engine.rank_documents()\n        # - Include personalization_context for personalized ranking\n        # - Handle ranking failures by falling back to similarity-only ranking\n        # Hint: ranking_engine needs processed_query, candidates, and context\n        \n        # TODO 5: Generate result snippets and highlighting\n        # - For each ranked result, extract relevant text snippet\n        # - Apply query term highlighting using highlight_query_terms()\n        # - Handle highlighting failures gracefully with plain text fallback\n        # Hint: Snippet should be 150-200 chars with query context\n        \n        # TODO 6: Compute facet information if requested\n        # - If request.include_facets, analyze result metadata\n        # - Group by category, content_type, date ranges, etc.\n        # - Cache computed facets for frequently requested combinations\n        # Hint: Only compute facets for top 1000 results to control latency\n        \n        # TODO 7: Assemble final response with analytics tracking\n        # - Format results using format_search_results() utility\n        # - Record search analytics asynchronously\n        # - Include processing time and result count in response\n        # Hint: Analytics should not impact response time - fire and forget\n        \n        processing_time = (time.time() - start_time) * 1000\n        \n        # TODO 8: Return QueryResponse with all computed information\n        # - Include query, results, total_found, processing_time_ms\n        # - Add facets if requested, None otherwise\n        # - Ensure all response fields match QueryResponse model\n        \n    except Exception as e:\n        # TODO 9: Handle errors with appropriate HTTP status codes\n        # - ValidationError -> 400 Bad Request\n        # - TimeoutError -> 504 Gateway Timeout  \n        # - ComponentUnavailable -> 503 Service Unavailable\n        # - Log full error details but return sanitized user message\n        processing_time = (time.time() - start_time) * 1000\n        logging.error(f\"Search error after {processing_time}ms: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Search temporarily unavailable\")\n```\n\n**Core Logic Skeleton - Autocomplete Endpoint:**\n\n```python\n@router.get(\"/api/v1/autocomplete\")\nasync def get_autocomplete_suggestions(\n    query: str,\n    max_suggestions: int = 10,\n    personalization_context: str = None,  # JSON string for GET requests\n    components: Dict[str, Any] = Depends(get_search_components),\n    _: None = Depends(rate_limit_dependency)\n) -> AutocompleteResponse:\n    \"\"\"\n    Provide fast autocomplete suggestions for partial queries.\n    \n    Must respond within 100ms to maintain good user experience.\n    Uses hybrid prefix matching + semantic similarity approach.\n    \"\"\"\n    start_time = time.time()\n    \n    try:\n        # TODO 1: Validate and sanitize input parameters\n        # - Check query is not empty, limit length to 100 chars\n        # - Ensure max_suggestions is reasonable (1-20)\n        # - Parse personalization_context JSON if provided\n        # Hint: Strip whitespace and convert to lowercase for consistency\n        \n        # TODO 2: Check prefix cache for instant responses\n        # - Look up query prefix in hot cache (tries structure)\n        # - If found and cache entry is fresh, return immediately\n        # - This should handle 80%+ of autocomplete requests\n        # Hint: Use normalized query (lowercase, no extra spaces) as cache key\n        \n        # TODO 3: Perform semantic similarity matching for cache misses\n        # - Generate lightweight embedding for partial query\n        # - Find similar complete queries from semantic cache\n        # - Combine with prefix matches, avoiding duplicates\n        # Hint: Limit semantic computation to stay within 100ms budget\n        \n        # TODO 4: Apply personalization filtering if context provided\n        # - Rerank suggestions based on user preferences\n        # - Boost suggestions matching user's recent queries or clicks\n        # - Filter out suggestions inappropriate for user context\n        # Hint: Personalization should be precomputed to avoid latency impact\n        \n        # TODO 5: Format suggestions with highlighting and metadata\n        # - Highlight the portion matching user's partial input\n        # - Include suggestion category/type if available\n        # - Sort by relevance score combining popularity and similarity\n        # Hint: Format as {\"suggestion\": \"...\", \"highlight\": \"...\", \"type\": \"...\"}\n        \n        # TODO 6: Update cache asynchronously with new suggestions\n        # - Cache the computed suggestions for this prefix\n        # - Update frequency counts for suggestion popularity ranking\n        # - Don't let cache update impact response time\n        # Hint: Fire-and-forget cache update in background task\n        \n        processing_time = (time.time() - start_time) * 1000\n        \n        # TODO 7: Return formatted autocomplete response\n        # - Include suggestions array, processing time for monitoring\n        # - Log slow requests (>80ms) for performance investigation\n        # - Ensure response format matches AutocompleteResponse model\n        \n        if processing_time > 80:\n            logging.warning(f\"Slow autocomplete: {processing_time}ms for query '{query}'\")\n        \n    except Exception as e:\n        processing_time = (time.time() - start_time) * 1000\n        logging.error(f\"Autocomplete error after {processing_time}ms: {str(e)}\")\n        # Return empty suggestions rather than error for better UX\n        return AutocompleteResponse(suggestions=[], processing_time_ms=processing_time)\n```\n\n**Language-Specific Implementation Hints:**\n\n- **FastAPI Request Handling**: Use `@router.get` and `@router.post` decorators on the same function for dual GET/POST support. FastAPI automatically handles parameter parsing from query string vs JSON body.\n\n- **Async Background Tasks**: Use `asyncio.create_task()` for fire-and-forget operations like analytics collection. Never await these tasks in the request path.\n\n- **Response Time Monitoring**: Use `time.perf_counter()` for high-precision timing. Log requests exceeding SLA thresholds (search >500ms, autocomplete >100ms).\n\n- **Error Handling**: Use FastAPI's `HTTPException` for client errors. Log full exception details but return sanitized messages to prevent information leakage.\n\n- **Rate Limiting**: Implement using Redis for distributed deployments or in-memory counters for single-instance deployments. Use sliding window counters for smooth rate limiting.\n\n**Milestone Checkpoint:**\n\nAfter implementing the Search API component, verify the following behavior:\n\n1. **Search Endpoint Testing**: \n   ```bash\n   curl -X POST \"http://localhost:8000/api/v1/search\" \\\n        -H \"Content-Type: application/json\" \\\n        -d '{\"query_text\": \"machine learning algorithms\", \"max_results\": 10, \"include_facets\": true}'\n   ```\n   Expected: JSON response with results array, facets object, processing time <500ms\n\n2. **Autocomplete Performance**:\n   ```bash\n   curl \"http://localhost:8000/api/v1/autocomplete?query=mach\"\n   ```\n   Expected: Suggestions array returned in <100ms, suggestions relevant to partial query\n\n3. **Analytics Collection**: Check that search requests generate analytics events without impacting response times. Monitor background processing queues.\n\n4. **Error Handling**: Test with malformed requests, very long queries, and missing parameters. All should return appropriate HTTP status codes with helpful error messages.\n\nSigns that something is wrong:\n- Response times consistently exceed SLA targets (search >500ms, autocomplete >100ms)\n- Error responses contain system internals or file paths\n- Analytics collection impacts search performance\n- Autocomplete suggestions are stale or irrelevant\n- Facet counts don't reflect actual result distributions\n\n\n## Component Interactions and Data Flow\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), showing how the components built in each milestone interact to form a cohesive semantic search engine system.\n\nThe **Component Interactions and Data Flow** section reveals the dynamic choreography that transforms static components into a living, breathing search engine. Think of this section as the conductor's score for an orchestra — while previous sections defined each instrument (component) and its capabilities, this section shows how they play together in harmony to create the complete symphony of semantic search.\n\nUnderstanding component interactions is crucial because semantic search engines involve complex data transformations across multiple stages. A single search query triggers a cascade of operations: text normalization, embedding generation, vector similarity computation, hybrid scoring, cross-encoder reranking, and result formatting. Each component must coordinate precisely with others, passing the right data at the right time while maintaining performance and reliability guarantees.\n\nThe challenge lies in managing the inherent complexity of multi-stage processing while preserving the illusion of simplicity for users. When someone types a query and expects results in under 500 milliseconds, our system must orchestrate document embedding pipelines that may have processed millions of texts, coordinate between lexical and semantic search indices, apply personalization signals, and format results — all while handling failures gracefully and maintaining consistency.\n\n![System Architecture Overview](./diagrams/system-architecture.svg)\n\n### Document Indexing Workflow\n\nThe **document indexing workflow** represents the foundational data pipeline that transforms raw text documents into searchable vector representations. Think of this process like a sophisticated book cataloging system in a research library. When new books arrive, they don't immediately become searchable — they must go through acquisition, cataloging, classification, and shelving before researchers can discover them. Similarly, our document indexing workflow takes raw text through embedding generation, vector normalization, and index integration before queries can find them.\n\nThe indexing workflow operates as a multi-stage pipeline where each component performs specialized transformations on the document data. This design enables parallel processing, fault tolerance through checkpointing, and incremental updates without full index reconstruction. The workflow must handle documents of varying sizes, from short product descriptions to lengthy technical papers, while maintaining consistent embedding quality and processing performance.\n\n![Document Indexing Flow](./diagrams/indexing-flow.svg)\n\nThe complete document indexing workflow follows this sequence:\n\n1. **Document Ingestion**: Raw documents enter the system through the Document Processor component, which validates format, extracts metadata, and assigns unique document identifiers. The processor handles multiple input formats (JSON, CSV, XML) and normalizes them into the standard `Document` structure.\n\n2. **Text Preprocessing**: The `TextProcessor` component cleans and normalizes document content by removing HTML tags, handling URL patterns, normalizing whitespace, and preparing text for optimal embedding generation. This step ensures consistent input quality for the embedding model.\n\n3. **Searchable Text Extraction**: The system calls `get_searchable_text()` to combine document title and content into a unified text representation. This method applies intelligent concatenation rules that weight titles more heavily while preserving content context.\n\n4. **Embedding Generation**: The `DocumentEncoder` component processes the cleaned text through the transformer model using the `encode_document()` method. This step generates dense vector representations that capture semantic meaning in the configured embedding space.\n\n5. **Vector Normalization**: All generated embeddings pass through `normalize_vector()` to ensure unit length, enabling efficient cosine similarity computation during search operations. Normalization is critical for consistent similarity scoring across documents.\n\n6. **Index Integration**: The normalized embeddings are added to the vector index using the chosen algorithm (HNSW or IVF). This step involves updating the index data structures, maintaining metadata mappings, and potentially triggering index optimization procedures.\n\n7. **Persistence and Backup**: The updated index state is persisted to disk using memory-mapped files for efficient access. The system maintains both the vector index and document metadata store with consistent backup procedures.\n\nThe document indexing workflow handles various data formats and error conditions through structured message passing between components:\n\n| Component | Input Message | Output Message | Error Handling |\n|-----------|---------------|----------------|----------------|\n| Document Processor | Raw document data (JSON/CSV/XML) | `Document` with validated fields | Malformed data → Skip with warning log |\n| Text Processor | `Document.content` and `Document.title` | Cleaned text string | Empty content → Use title only |\n| Document Encoder | Cleaned text string | `DocumentEmbedding` with vector | Encoding failure → Retry with truncated text |\n| Vector Index | `DocumentEmbedding` | Index position ID | Index full → Trigger background optimization |\n| Persistence Layer | Updated index state | Confirmation status | Write failure → Rollback to previous state |\n\nThe workflow implements several critical error handling and recovery mechanisms:\n\n**Batch Processing Recovery**: When processing large document collections, the system maintains progress checkpoints every 1000 documents. If processing fails, the workflow resumes from the last successful checkpoint rather than restarting from the beginning.\n\n**Embedding Model Failures**: If the transformer model encounters out-of-memory errors or timeout issues, the system automatically retries with truncated text (up to model's maximum token limit) and logs the truncation for quality monitoring.\n\n**Index Capacity Management**: As the vector index approaches memory limits, the system triggers background optimization procedures that compress the index structure and archive less frequently accessed vectors to secondary storage.\n\n**Consistency Guarantees**: The workflow ensures that document metadata and vector embeddings remain synchronized through transactional updates. If vector insertion succeeds but metadata update fails, the system rolls back the vector insertion to maintain consistency.\n\n> **Key Design Insight**: The document indexing workflow prioritizes fault tolerance over raw speed because index corruption is far more expensive to recover from than slower initial processing. Each stage includes rollback capabilities and data validation checkpoints.\n\n### Search Request Processing Flow\n\nThe **search request processing flow** orchestrates the complex sequence of operations that transform a user's query into ranked, relevant results. Think of this process like a reference librarian who not only understands what you're asking for but also knows how to navigate multiple catalogs, cross-reference related materials, and present findings in the most useful order. The search flow must coordinate between linguistic analysis, vector operations, multiple scoring systems, and result formatting while meeting strict latency requirements.\n\nThe search processing pipeline operates under the constraint that users expect sub-second response times, which means every component must optimize for speed while maintaining result quality. This creates tension between thoroughness and performance — we want to apply sophisticated query understanding and comprehensive ranking, but we cannot afford expensive operations that delay response delivery.\n\nThe complete search request processing flow follows this detailed sequence:\n\n1. **Request Validation and Parsing**: The Search API receives the `QueryRequest` and validates parameters including query length (maximum `MAX_QUERY_LENGTH` characters), result count limits, and filter format. Malformed requests are rejected immediately with descriptive error messages.\n\n2. **Query Normalization**: The `TextNormalizer` component processes the raw query text using `normalize_query()` to handle case normalization, whitespace cleanup, and technical term preservation. This step ensures consistent query representation for caching and processing.\n\n3. **Cache Lookup**: The `EmbeddingCache` checks for previously computed embeddings using both exact query matching and normalized query matching through the `get()` method. Cache hits significantly reduce latency by skipping expensive embedding computation.\n\n4. **Query Processing Pipeline**: For cache misses, the `QueryProcessor` executes the full `process_query()` pipeline, including synonym expansion, entity recognition, intent classification, and multi-vector query decomposition. This produces a rich `ProcessedQuery` structure with multiple semantic representations.\n\n5. **Primary Embedding Generation**: The system generates the primary query embedding using `encode_query()` and normalizes it with `normalize_vector()` to ensure compatibility with the indexed document embeddings.\n\n6. **Vector Similarity Search**: The embedding index performs approximate nearest neighbor search to retrieve the top candidate documents based on cosine similarity scores. This step typically returns 2-5x more candidates than the final result count to enable effective reranking.\n\n7. **Multi-Signal Scoring**: The ranking engine computes multiple relevance signals for each candidate document, including semantic similarity scores, BM25 lexical scores, personalization signals, and freshness scores using the `score_candidate()` method.\n\n8. **Signal Combination**: The `combine_signals()` method merges individual ranking signals into hybrid scores using learned weights that vary by query type and user context. This produces an initial ranked candidate list.\n\n9. **Cross-Encoder Reranking**: For the highest-scoring candidates (typically top 50-100), the system applies precise cross-encoder reranking using `rerank_candidates()` to refine the ordering with more sophisticated semantic understanding.\n\n10. **Result Formatting**: The final ranked results are formatted using `format_search_results()` to generate snippets, highlight query terms, and include relevance metadata in the `QueryResponse` structure.\n\n11. **Analytics and Learning**: The system records search analytics and updates click-through learning models asynchronously to avoid impacting response latency.\n\nThe search flow manages complex data transformations through well-defined interfaces between components:\n\n| Processing Stage | Component | Input Data | Output Data | Latency Budget |\n|------------------|-----------|------------|-------------|----------------|\n| Request Validation | Search API | HTTP request body | `QueryRequest` object | 5ms |\n| Query Processing | Query Processor | `QueryRequest.query_text` | `ProcessedQuery` with embeddings | 100ms |\n| Vector Search | Embedding Index | `ProcessedQuery.primary_embedding` | Candidate document list | 50ms |\n| Multi-Signal Scoring | Ranking Engine | Candidates + `ProcessedQuery` | `RankingCandidate` list | 200ms |\n| Cross-Encoder Reranking | Ranking Engine | Top candidates + query | Refined ranking | 100ms |\n| Result Formatting | Search API | Ranked candidates | `QueryResponse` JSON | 20ms |\n| **Total Latency** | | | | **475ms (under 500ms SLA)** |\n\nThe search processing flow implements sophisticated error handling and graceful degradation:\n\n**Embedding Generation Failures**: If query embedding generation fails due to model unavailability or timeout, the system falls back to lexical search only, using BM25 scoring against indexed document text. Users receive results with a warning about reduced semantic matching.\n\n**Index Unavailability**: When the vector index is temporarily unavailable (during updates or due to hardware issues), the system serves results using only the lexical search index with expanded query terms. Response times remain acceptable while semantic accuracy is reduced.\n\n**Ranking Engine Overload**: If cross-encoder reranking cannot complete within the latency budget, the system returns results based only on multi-signal scoring. This maintains response time guarantees while slightly reducing result precision.\n\n**Partial Component Failures**: The system tracks component health and adjusts processing pipelines dynamically. For example, if personalization scoring fails, the system continues with semantic and lexical signals only, ensuring core search functionality remains available.\n\n> **Critical Performance Insight**: The search processing flow achieves sub-second latency through aggressive parallelization of independent operations. Semantic similarity search, BM25 scoring, and personalization scoring run concurrently, with results synchronized before signal combination.\n\n**Query Processing State Management**: The search flow maintains detailed state information throughout processing to enable debugging and optimization:\n\n| Processing Phase | State Information | Purpose |\n|------------------|------------------|---------|\n| Request Receipt | Correlation ID, timestamp, client IP | Request tracking and rate limiting |\n| Query Analysis | Normalized query, detected entities, expansion terms | Debugging query understanding issues |\n| Vector Operations | Embedding vectors, similarity scores, candidate counts | Performance monitoring and tuning |\n| Ranking Computation | Individual signal scores, combination weights | Result quality analysis |\n| Response Generation | Final scores, snippet generation, formatting time | End-to-end performance optimization |\n\n### Internal Component APIs\n\nThe **internal component APIs** define the precise interface contracts that enable our search engine components to communicate reliably and efficiently. Think of these APIs as the diplomatic protocols between neighboring countries — they establish the exact format, timing, and expectations for every interaction, preventing misunderstandings that could lead to system failures or degraded performance.\n\nThese internal APIs differ fundamentally from public REST APIs because they prioritize performance, type safety, and rich error information over simplicity and broad compatibility. Internal APIs can make assumptions about network reliability, use binary serialization for efficiency, and include detailed context information that helps with debugging and optimization.\n\nThe internal API design follows several key principles: **type safety** through strongly typed message structures, **performance optimization** through efficient serialization and minimal data copying, **observability** through comprehensive context propagation, and **fault tolerance** through explicit error modeling and timeout handling.\n\n#### Document Processing APIs\n\nThe document processing APIs handle the flow of documents from ingestion through embedding generation to index integration. These APIs must handle high-throughput batch operations while maintaining individual document error tracking:\n\n| Method Signature | Component | Purpose | Error Handling |\n|------------------|-----------|---------|----------------|\n| `process_document(doc: Document) -> ProcessingResult` | Document Processor | Validate and normalize document | Returns validation errors with field-level details |\n| `clean_text(text: str) -> str` | Text Processor | Clean document content for embedding | Never fails; returns cleaned text even for malformed input |\n| `encode_document(document: Document) -> DocumentEmbedding` | Document Encoder | Generate vector embedding | Retries with truncated text; raises ModelUnavailableError |\n| `add_document(embedding: DocumentEmbedding) -> IndexPosition` | Vector Index | Insert into search index | Raises IndexFullError if capacity exceeded |\n| `persist_index(checkpoint: str) -> PersistenceResult` | Storage Layer | Save index to disk | Provides detailed disk space and I/O error information |\n\nThe `DocumentEmbedding` message structure carries comprehensive metadata between processing stages:\n\n| Field | Type | Purpose | Required |\n|-------|------|---------|----------|\n| `document` | `Document` | Original document reference | Yes |\n| `embedding` | `np.ndarray` | Normalized vector representation | Yes |\n| `model_name` | `str` | Embedding model identifier | Yes |\n| `embedding_dim` | `int` | Vector dimensionality | Yes |\n| `processing_time_ms` | `float` | Generation latency | No |\n| `text_length` | `int` | Input text character count | No |\n| `truncation_applied` | `bool` | Whether text was truncated | No |\n\n#### Query Processing APIs\n\nThe query processing APIs coordinate the complex transformation of user queries into rich semantic representations. These APIs emphasize caching efficiency and detailed query analysis:\n\n| Method Signature | Component | Purpose | Caching Behavior |\n|------------------|-----------|---------|-----------------|\n| `normalize_query(query: str) -> str` | Text Normalizer | Standardize query format | Results cached for 1 hour |\n| `process_query(query_text: str, context: Dict) -> ProcessedQuery` | Query Processor | Full query analysis pipeline | Expensive; aggressive caching |\n| `expand_query_terms(terms: List[str], entities: List[str]) -> List[Tuple[str, float]]` | Synonym Expander | Add related terms | Cached per term with confidence scores |\n| `encode_query(query_text: str) -> np.ndarray` | Document Encoder | Generate query embedding | Cached with normalized query as key |\n| `get(query: str, normalized_query: str) -> Optional[np.ndarray]` | Embedding Cache | Retrieve cached embedding | LRU eviction with TTL |\n\nThe `ProcessedQuery` structure serves as the central data exchange format for query analysis results:\n\n| Field | Type | Purpose | Populated By |\n|-------|------|---------|--------------|\n| `original_query` | `str` | Unmodified user input | Query Processor |\n| `normalized_query` | `str` | Cleaned, standardized text | Text Normalizer |\n| `primary_embedding` | `np.ndarray` | Main semantic representation | Document Encoder |\n| `expanded_terms` | `List[Tuple[str, float]]` | Synonyms with confidence | Synonym Expander |\n| `entities` | `List[Tuple[str, str]]` | Recognized entities and types | Entity Recognizer |\n| `intent` | `str` | Classified query intent | Intent Classifier |\n| `negative_terms` | `List[str]` | Terms to exclude from results | Query Analyzer |\n| `multi_vector_components` | `Optional[List[Tuple[str, np.ndarray, float]]]` | Complex query decomposition | Multi-Vector Handler |\n| `processing_metadata` | `Dict[str, Any]` | Debugging and optimization data | All components |\n\n#### Ranking and Retrieval APIs\n\nThe ranking APIs orchestrate the complex multi-stage process of candidate retrieval, signal computation, and result optimization. These APIs balance thoroughness with performance constraints:\n\n| Method Signature | Component | Purpose | Performance Characteristics |\n|------------------|-----------|---------|---------------------------|\n| `search_similar(embedding: np.ndarray, k: int) -> List[Tuple[str, float]]` | Vector Index | Approximate nearest neighbors | Sub-50ms for k≤1000 |\n| `score_candidate(document: Document, query: ProcessedQuery, context: PersonalizationContext) -> RankingSignals` | Ranking Engine | Compute all relevance signals | Parallelized across candidates |\n| `combine_signals(signals: RankingSignals, query_type: str) -> float` | Ranking Engine | Merge signals into final score | Learned weights per query type |\n| `rerank_candidates(candidates: List[RankingCandidate], query_text: str) -> List[RankingCandidate]` | Cross-Encoder | Precise semantic reranking | Limited to top 100 candidates |\n| `record_interaction(query: str, results: List[SearchResult], click_position: int) -> None` | Learning System | Update ranking models | Asynchronous; never blocks search |\n\nThe `RankingSignals` structure captures all computed relevance factors:\n\n| Signal Field | Type | Range | Purpose |\n|--------------|------|-------|---------|\n| `semantic_score` | `float` | 0.0-1.0 | Cosine similarity between query and document |\n| `bm25_score` | `float` | 0.0-∞ | Lexical relevance from keyword matching |\n| `personalization_score` | `float` | 0.0-1.0 | User preference and context matching |\n| `freshness_score` | `float` | 0.0-1.0 | Time-based relevance decay |\n| `click_score` | `Optional[float]` | 0.0-1.0 | Historical click-through rate adjustment |\n| `quality_score` | `Optional[float]` | 0.0-1.0 | Document authority and reliability |\n\n#### Error Handling and Context Propagation\n\nAll internal APIs implement consistent error handling patterns that preserve context information for debugging while enabling graceful degradation:\n\n**Structured Error Types**: Each component defines specific error types that carry detailed context:\n\n| Error Type | Component | Context Information | Recovery Strategy |\n|------------|-----------|-------------------|------------------|\n| `EmbeddingGenerationError` | Document Encoder | Model name, input length, timeout details | Retry with truncated input |\n| `IndexCapacityError` | Vector Index | Current size, available memory, growth rate | Trigger background optimization |\n| `CacheEvictionError` | Embedding Cache | Evicted entries, memory pressure | Expand cache size or reduce TTL |\n| `RankingTimeoutError` | Ranking Engine | Processed candidates, remaining queue | Return partial results |\n\n**Context Propagation**: Every API call includes a `ContextInfo` parameter that tracks request flow:\n\n| Context Field | Type | Purpose | Populated By |\n|---------------|------|---------|--------------|\n| `correlation_id` | `str` | Unique request identifier | API Gateway |\n| `user_id` | `Optional[str]` | User identification | Authentication |\n| `request_timestamp` | `datetime` | Request initiation time | API Gateway |\n| `processing_budget_ms` | `int` | Remaining time budget | Search Coordinator |\n| `quality_vs_speed` | `str` | Performance preference | Request parameters |\n\n**API Health Monitoring**: All internal APIs expose health and performance metrics:\n\n| Metric Category | Examples | Update Frequency | Purpose |\n|-----------------|----------|-----------------|---------|\n| Latency Percentiles | p50, p95, p99 response times | Per request | Performance monitoring |\n| Error Rates | Failures per component per minute | Every 10 seconds | Reliability tracking |\n| Resource Utilization | CPU, memory, disk I/O per operation | Every 30 seconds | Capacity planning |\n| Cache Effectiveness | Hit rates, eviction rates per cache | Every minute | Optimization guidance |\n\n> **API Design Philosophy**: Internal APIs optimize for rich error information and debugging support over simplicity. When a search fails at 3 AM, the on-call engineer needs detailed context about what went wrong and where, not just a generic \"search failed\" message.\n\nThe internal APIs support comprehensive request tracing through structured logging and metrics collection. Each API method logs entry and exit with parameter summaries, execution time, and result metadata. This creates an audit trail that enables performance analysis, error debugging, and system optimization.\n\n**API Versioning and Compatibility**: Although these are internal APIs, they still require versioning as the system evolves:\n\n- **Backward Compatibility**: New API versions add fields but never remove existing fields within the same major version\n- **Feature Flags**: New functionality is introduced through optional parameters and feature flags before becoming standard\n- **Graceful Degradation**: APIs detect component version mismatches and adjust behavior accordingly\n- **Migration Support**: During upgrades, APIs support both old and new message formats simultaneously\n\n### Implementation Guidance\n\nThe component interactions require careful orchestration to maintain performance while ensuring reliability. This section provides the infrastructure and patterns needed to implement robust inter-component communication.\n\n#### Technology Recommendations\n\n| Component Communication | Simple Option | Advanced Option |\n|-------------------------|---------------|-----------------|\n| Internal APIs | Direct Python method calls with type hints | Protocol Buffers with async message queues |\n| Data Serialization | JSON with Pydantic models | Apache Arrow for large vector data |\n| Caching Layer | Python dict with TTL wrapper | Redis cluster with consistent hashing |\n| Error Handling | Standard Python exceptions | Structured error codes with context |\n| Monitoring | Python logging with correlation IDs | OpenTelemetry with distributed tracing |\n\n#### File Structure for Component Communication\n\n```\nsemantic-search/\n  internal/\n    communication/\n      __init__.py                    ← Export communication primitives  \n      message_types.py               ← All message data structures\n      api_interfaces.py              ← Abstract base classes for APIs\n      error_handling.py              ← Structured error types\n      context.py                     ← Request context propagation\n    \n    indexing/\n      workflow.py                    ← Document indexing orchestration\n      pipeline_stages.py             ← Individual processing stages\n      batch_processor.py             ← Batch processing with checkpoints\n    \n    search/\n      request_handler.py             ← Search request orchestration  \n      flow_coordinator.py            ← Multi-component coordination\n      result_assembler.py            ← Final result formatting\n    \n    monitoring/\n      metrics.py                     ← Performance and health metrics\n      tracing.py                     ← Request tracing utilities\n      health_checks.py               ← Component health monitoring\n\n  tests/\n    integration/\n      test_indexing_workflow.py      ← End-to-end indexing tests\n      test_search_flow.py            ← Complete search request tests\n```\n\n#### Message Types Infrastructure\n\n```python\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Optional, Any, Tuple\nimport numpy as np\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass ContextInfo:\n    \"\"\"Request context propagated through all API calls.\"\"\"\n    correlation_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    user_id: Optional[str] = None\n    request_timestamp: datetime = field(default_factory=datetime.now)\n    processing_budget_ms: int = 500\n    quality_vs_speed: str = \"balanced\"  # \"speed\", \"balanced\", \"quality\"\n    component_trace: List[str] = field(default_factory=list)\n\n@dataclass \nclass ProcessingResult:\n    \"\"\"Standard result wrapper for all processing operations.\"\"\"\n    success: bool\n    data: Any = None\n    error_message: Optional[str] = None\n    error_code: Optional[str] = None\n    processing_time_ms: float = 0.0\n    context: ContextInfo = field(default_factory=ContextInfo)\n\n@dataclass\nclass IndexingMessage:\n    \"\"\"Message format for document indexing pipeline.\"\"\"\n    document: Document\n    stage: str  # \"validation\", \"embedding\", \"indexing\", \"persistence\"\n    result: ProcessingResult\n    checkpoint_id: Optional[str] = None\n    retry_count: int = 0\n    context: ContextInfo = field(default_factory=ContextInfo)\n\n@dataclass\nclass SearchMessage:\n    \"\"\"Message format for search request pipeline.\"\"\"\n    query_request: QueryRequest\n    processed_query: Optional[ProcessedQuery] = None\n    candidates: List[RankingCandidate] = field(default_factory=list)\n    final_results: List[SearchResult] = field(default_factory=list)\n    stage: str = \"received\"  # \"received\", \"processed\", \"ranked\", \"formatted\"\n    context: ContextInfo = field(default_factory=ContextInfo)\n```\n\n#### Component Communication Base Classes\n\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass DocumentProcessor(Protocol):\n    \"\"\"Interface contract for document processing components.\"\"\"\n    \n    def process_document(self, doc: Document, context: ContextInfo) -> ProcessingResult:\n        \"\"\"Process a single document through validation and normalization.\"\"\"\n        pass\n    \n    def process_batch(self, docs: List[Document], context: ContextInfo) -> List[ProcessingResult]:\n        \"\"\"Process multiple documents with checkpointing.\"\"\"\n        pass\n    \n    def get_health_status(self) -> Dict[str, Any]:\n        \"\"\"Return component health and performance metrics.\"\"\"\n        pass\n\n@runtime_checkable  \nclass SearchCoordinator(Protocol):\n    \"\"\"Interface contract for search request coordination.\"\"\"\n    \n    def handle_search_request(self, request: QueryRequest, context: ContextInfo) -> QueryResponse:\n        \"\"\"Coordinate complete search request processing.\"\"\"\n        pass\n    \n    def handle_autocomplete_request(self, request: AutocompleteRequest, context: ContextInfo) -> AutocompleteResponse:\n        \"\"\"Handle typeahead autocomplete requests.\"\"\"\n        pass\n```\n\n#### Error Handling Infrastructure  \n\n```python\nclass SearchEngineError(Exception):\n    \"\"\"Base exception for all search engine errors.\"\"\"\n    \n    def __init__(self, message: str, error_code: str, context: ContextInfo, component: str):\n        super().__init__(message)\n        self.error_code = error_code\n        self.context = context\n        self.component = component\n        self.timestamp = datetime.now()\n\nclass EmbeddingGenerationError(SearchEngineError):\n    \"\"\"Raised when embedding generation fails.\"\"\"\n    \n    def __init__(self, message: str, context: ContextInfo, model_name: str, text_length: int):\n        super().__init__(message, \"EMBEDDING_FAILED\", context, \"DocumentEncoder\")\n        self.model_name = model_name\n        self.text_length = text_length\n\nclass IndexCapacityError(SearchEngineError):\n    \"\"\"Raised when vector index reaches capacity limits.\"\"\"\n    \n    def __init__(self, message: str, context: ContextInfo, current_size: int, max_capacity: int):\n        super().__init__(message, \"INDEX_CAPACITY\", context, \"VectorIndex\") \n        self.current_size = current_size\n        self.max_capacity = max_capacity\n\ndef handle_component_error(error: Exception, context: ContextInfo, component: str) -> ProcessingResult:\n    \"\"\"Standard error handling for component failures.\"\"\"\n    if isinstance(error, SearchEngineError):\n        return ProcessingResult(\n            success=False,\n            error_message=str(error),\n            error_code=error.error_code,\n            context=context\n        )\n    else:\n        # Wrap unexpected errors\n        return ProcessingResult(\n            success=False, \n            error_message=f\"Unexpected error in {component}: {str(error)}\",\n            error_code=\"UNEXPECTED_ERROR\",\n            context=context\n        )\n```\n\n#### Document Indexing Workflow Implementation\n\n```python\nclass DocumentIndexingWorkflow:\n    \"\"\"Orchestrates the complete document indexing pipeline.\"\"\"\n    \n    def __init__(self, text_processor: TextProcessor, encoder: DocumentEncoder, \n                 vector_index, storage_layer):\n        self.text_processor = text_processor\n        self.encoder = encoder  \n        self.vector_index = vector_index\n        self.storage_layer = storage_layer\n        self.checkpoint_interval = 1000\n        \n    def process_document_batch(self, documents: List[Document], \n                             context: ContextInfo) -> List[ProcessingResult]:\n        \"\"\"\n        Process a batch of documents through the complete indexing pipeline.\n        Implements checkpointing and error recovery.\n        \"\"\"\n        # TODO 1: Initialize batch processing context and create checkpoint\n        # TODO 2: For each document, validate format and extract metadata\n        # TODO 3: Clean document text using text_processor.clean_text()  \n        # TODO 4: Generate embedding using encoder.encode_document()\n        # TODO 5: Add embedding to vector index with error handling\n        # TODO 6: Update document metadata store with document info\n        # TODO 7: Create checkpoint every self.checkpoint_interval documents\n        # TODO 8: Handle partial failures - continue processing remaining docs\n        # TODO 9: Persist final index state and return processing results\n        # Hint: Use try/except around each stage to isolate failures\n        # Hint: Maintain correlation_id throughout pipeline for debugging\n        pass\n        \n    def resume_from_checkpoint(self, checkpoint_id: str, remaining_docs: List[Document],\n                             context: ContextInfo) -> List[ProcessingResult]:\n        \"\"\"Resume batch processing from a previous checkpoint.\"\"\"\n        # TODO 1: Load checkpoint state from storage\n        # TODO 2: Verify index consistency from checkpoint data\n        # TODO 3: Continue processing from last successful document\n        # TODO 4: Update context with checkpoint recovery information\n        pass\n```\n\n#### Search Request Flow Implementation\n\n```python\nclass SearchRequestFlow:\n    \"\"\"Coordinates the complete search request processing pipeline.\"\"\"\n    \n    def __init__(self, query_processor: QueryProcessor, vector_index,\n                 ranking_engine, result_formatter, embedding_cache: EmbeddingCache):\n        self.query_processor = query_processor\n        self.vector_index = vector_index  \n        self.ranking_engine = ranking_engine\n        self.result_formatter = result_formatter\n        self.embedding_cache = embedding_cache\n        \n    def process_search_request(self, request: QueryRequest, \n                             context: ContextInfo) -> QueryResponse:\n        \"\"\"\n        Execute the complete search request processing pipeline.\n        Implements timeout handling and graceful degradation.\n        \"\"\"\n        # TODO 1: Validate request parameters and initialize processing timer\n        # TODO 2: Check embedding cache for query using normalized form\n        # TODO 3: If cache miss, run full query processing pipeline\n        # TODO 4: Execute vector similarity search with processed query\n        # TODO 5: Compute multi-signal ranking scores for all candidates  \n        # TODO 6: Apply cross-encoder reranking to top candidates\n        # TODO 7: Format final results with snippets and highlighting\n        # TODO 8: Record analytics and cache embeddings for future use\n        # TODO 9: Return formatted QueryResponse with timing information\n        # Hint: Check context.processing_budget_ms before expensive operations\n        # Hint: Implement fallbacks if components timeout or fail\n        pass\n        \n    def handle_component_timeout(self, component: str, operation: str,\n                               context: ContextInfo) -> ProcessingResult:\n        \"\"\"Handle timeout scenarios with appropriate fallback strategies.\"\"\" \n        # TODO 1: Log timeout with component and operation details\n        # TODO 2: Determine appropriate fallback strategy based on component\n        # TODO 3: Update context with degraded service information\n        # TODO 4: Return partial result with warning messages\n        pass\n```\n\n#### Monitoring and Health Checks\n\n```python\nclass ComponentHealthMonitor:\n    \"\"\"Monitors health and performance of all system components.\"\"\"\n    \n    def __init__(self):\n        self.component_metrics = {}\n        self.health_checks = {}\n        \n    def record_api_call(self, component: str, method: str, \n                       duration_ms: float, success: bool, context: ContextInfo):\n        \"\"\"Record API call metrics for monitoring.\"\"\"\n        # TODO 1: Update latency percentiles for component.method\n        # TODO 2: Increment success/failure counters  \n        # TODO 3: Track correlation_id for request tracing\n        # TODO 4: Alert if error rates exceed thresholds\n        pass\n        \n    def check_component_health(self, component: str) -> Dict[str, Any]:\n        \"\"\"Perform health check on specified component.\"\"\"\n        # TODO 1: Test component's basic functionality\n        # TODO 2: Check resource utilization (CPU, memory)\n        # TODO 3: Verify dependency connectivity  \n        # TODO 4: Return health status with detailed metrics\n        pass\n\ndef trace_request_flow(context: ContextInfo, component: str, operation: str):\n    \"\"\"Decorator to automatically trace request flow through components.\"\"\"\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            # TODO 1: Add component.operation to context.component_trace\n            # TODO 2: Record operation start time\n            # TODO 3: Execute function with error handling\n            # TODO 4: Record operation completion and duration\n            # TODO 5: Update monitoring metrics\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n```\n\n#### Milestone Checkpoints\n\n**After implementing Document Indexing Workflow (Milestone 1):**\n- Run `python -m pytest tests/integration/test_indexing_workflow.py`\n- Expected: All document processing stages complete successfully\n- Verify: Index contains embedded documents with correct metadata\n- Check: Checkpoint and recovery functionality works with partial failures\n\n**After implementing Search Request Flow (Milestone 2):**  \n- Run `python -m pytest tests/integration/test_search_flow.py`\n- Expected: Search requests return ranked results within timeout\n- Verify: Component coordination works with proper error handling\n- Check: Caching and performance optimizations function correctly\n\n**After implementing Component APIs (Milestones 3-4):**\n- Run load test: `python scripts/load_test_search.py --requests 1000 --concurrency 10`\n- Expected: 95% of requests complete under 500ms\n- Verify: Health monitoring detects component failures\n- Check: Error handling provides actionable debugging information\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing robust error handling patterns that must be implemented throughout the embedding index (Milestone 1), query processing (Milestone 2), ranking engine (Milestone 3), and search API (Milestone 4).\n\nProduction semantic search systems face numerous failure modes that can cascade across components, degrading user experience or causing complete service outages. Think of error handling in a semantic search engine like an emergency response system in a hospital — you need clear protocols for different types of failures, graceful degradation when specialized equipment fails, and backup procedures that maintain essential services even when advanced capabilities are unavailable.\n\nThe challenge with semantic search error handling is the interdependency between components. Unlike traditional keyword search where index corruption might only affect specific terms, embedding model failures can render the entire semantic capability unusable. Similarly, ranking failures don't just return unsorted results — they can return completely irrelevant matches that destroy user trust. This section establishes comprehensive error handling strategies that maintain system availability while preserving search quality.\n\n### Index Construction Failures\n\nThe embedding index represents the foundation of semantic search capabilities, making index construction failures particularly critical. These failures can occur during initial index creation, incremental updates, or model changes, each requiring different recovery strategies.\n\n**Embedding Model Failures**\n\nEmbedding model failures represent the most fundamental type of index construction failure, as they prevent the conversion of text documents into searchable vector representations. These failures can manifest in several ways: model loading failures due to corrupted files or insufficient memory, inference failures during document encoding, and model API timeouts when using remote embedding services.\n\n> **Decision: Embedding Model Fault Tolerance Strategy**\n> - **Context**: Embedding models can fail during loading, inference, or remote API calls, blocking entire index construction pipelines\n> - **Options Considered**: \n>   1. Fail-fast approach stopping all indexing on first model failure\n>   2. Retry-based approach with exponential backoff and circuit breakers\n>   3. Fallback model approach using simpler models when primary fails\n> - **Decision**: Implement retry-based approach with circuit breaker protection and optional fallback models\n> - **Rationale**: Transient failures (network issues, temporary memory pressure) are common and recoverable, but persistent failures should trigger circuit breakers to prevent resource exhaustion\n> - **Consequences**: Enables resilience to temporary issues while providing escape mechanisms for persistent failures, at the cost of increased complexity\n\nThe `DocumentEncoder` component must implement robust error handling around model operations. When the primary embedding model fails, the system should attempt retries with exponential backoff, starting with a 1-second delay and doubling up to a maximum of 30 seconds. After three consecutive failures, a circuit breaker opens, temporarily bypassing embedding generation for that document and marking it for retry during the next indexing cycle.\n\n| Failure Type | Detection Method | Immediate Response | Recovery Strategy |\n|--------------|-----------------|-------------------|------------------|\n| Model Load Failure | Exception during SentenceTransformer initialization | Log error, attempt fallback model | Retry with exponential backoff, fallback to lighter model |\n| Inference Timeout | Embedding generation exceeds 30-second timeout | Cancel request, log timeout | Add document to retry queue with shorter text |\n| Memory Exhaustion | CUDA out-of-memory or system OOM during encoding | Reduce batch size, trigger GC | Process documents individually, consider model quantization |\n| Corrupted Model Files | Hash mismatch or file read errors during loading | Download fresh model files | Verify checksums, re-download from official sources |\n| Remote API Failure | HTTP errors or rate limiting from embedding service | Implement circuit breaker | Use local fallback model or queue for later processing |\n\nFor memory-related failures, the system should implement dynamic batch size adjustment. When encoding fails due to memory constraints, the batch size is halved and the operation retried. This continues until either the operation succeeds or the batch size reaches 1. Documents that fail individual encoding are marked as problematic and routed through a separate error handling pipeline that attempts preprocessing steps like text truncation or content filtering.\n\n**Index Corruption and Recovery**\n\nIndex corruption can occur due to hardware failures, incomplete write operations, or software bugs during index updates. The symptoms range from subtle degradation in search quality to complete index unusability. Detection requires both automated monitoring and explicit validation procedures.\n\nThe system implements a multi-layered corruption detection strategy. During index construction, each major operation writes a checkpoint record containing metadata about the current state, including document count, vector dimensions, and operation timestamps. These checkpoints enable validation of index integrity and provide recovery points when corruption is detected.\n\n| Corruption Type | Detection Method | Symptoms | Recovery Action |\n|-----------------|-----------------|----------|-----------------|\n| Partial Write Failure | Checkpoint validation mismatch | Index reports fewer documents than expected | Rollback to last valid checkpoint, replay from transaction log |\n| Vector Dimension Mismatch | Dimension validation during search | Search queries fail with dimension errors | Rebuild affected index segments with correct model |\n| Metadata Inconsistency | Cross-reference between index and document store | Documents exist but not searchable | Regenerate metadata from source documents |\n| File System Corruption | Hash verification failures | Random search failures or crashes | Restore from backup, rebuild if necessary |\n| Index Format Version Conflict | Version header validation | Index loading fails with format errors | Migrate index to current format or rebuild from source |\n\nThe index persistence layer maintains multiple backup copies with different retention policies. Hot backups are created every hour during active indexing, warm backups daily, and cold backups weekly. Each backup includes both the index files and the associated metadata required for validation and recovery.\n\nWhen corruption is detected, the recovery process follows a structured approach:\n\n1. **Immediate Isolation**: Mark the corrupted index segment as unavailable to prevent serving bad results\n2. **Impact Assessment**: Determine which documents and queries are affected by the corruption\n3. **Fallback Activation**: Route affected queries to backup index segments or alternative search methods\n4. **Recovery Planning**: Choose between rollback to checkpoint, partial rebuild, or full reconstruction\n5. **Progressive Restoration**: Gradually restore service as repairs complete, validating each step\n6. **Post-Recovery Validation**: Run comprehensive tests to ensure full functionality restoration\n\n**Incremental Update Failures**\n\nIncremental index updates present unique challenges because they must maintain consistency between the existing index and new additions while handling partial failures gracefully. Update failures can leave the index in an inconsistent state where some documents are searchable while others are missing or corrupted.\n\nThe system implements an atomic update mechanism using a two-phase commit protocol. During the preparation phase, new document embeddings are generated and staged in a temporary index segment. The commit phase merges the staged segment with the main index, updating all associated metadata structures. If any step fails, the entire update can be rolled back without affecting the existing index.\n\n> **Critical Insight**: Incremental updates must never leave the index in a partially updated state. Either all documents in an update batch are successfully indexed, or none are. Partial updates create inconsistencies that are extremely difficult to diagnose and repair.\n\nThe update failure recovery process maintains a transaction log of all attempted operations. Each update batch receives a unique transaction ID, and all operations within that batch are logged with sufficient detail to enable replay or rollback. When an update fails, the system can either replay the failed operations after addressing the underlying issue or rollback to the state before the update began.\n\n| Update Failure Type | Cause | Detection | Recovery Strategy |\n|---------------------|-------|-----------|------------------|\n| Embedding Generation Failure | Model errors during new document processing | Missing embeddings for expected documents | Retry embedding generation, use fallback model if needed |\n| Index Merge Failure | Disk space or I/O errors during segment merge | Incomplete merge operations in transaction log | Rollback merge, free disk space, retry with smaller batches |\n| Metadata Update Failure | Database constraints or connection issues | Metadata inconsistent with index contents | Regenerate metadata from index, validate consistency |\n| Concurrent Update Conflict | Multiple update processes modifying same segments | Lock conflicts or version mismatches | Queue conflicting updates, process sequentially |\n| Resource Exhaustion | Memory or disk space depletion during update | System resource monitoring alerts | Pause updates, free resources, resume with reduced batch sizes |\n\n### Search-Time Error Handling\n\nSearch-time errors require different handling strategies than index construction failures because they directly impact user experience and must be resolved within strict latency constraints. The system must provide graceful degradation that maintains some level of search functionality even when advanced features fail.\n\n**Component Unavailability Handling**\n\nModern semantic search systems involve multiple cooperating components, and any component failure can disrupt the search experience. The key insight is that different components contribute different value to search quality, enabling prioritized degradation strategies.\n\nThink of component availability like a restaurant kitchen during a busy evening. If the specialized pastry chef is unavailable, you don't shut down the entire restaurant — you remove desserts from the menu and focus on delivering excellent main courses. Similarly, if the cross-encoder reranking component fails, the system should continue providing semantic search results without the precision boost of neural reranking.\n\nThe search request flow implements a timeout and fallback strategy for each component. When a component doesn't respond within its allocated time budget, the system logs the failure and continues processing with degraded capabilities. The final search results include metadata indicating which components were available, allowing clients to adjust their expectations and possibly retry later.\n\n| Component | Primary Function | Failure Impact | Fallback Strategy | User Experience |\n|-----------|------------------|----------------|------------------|-----------------|\n| Query Processor | Query expansion and normalization | Reduced recall, no synonym matching | Use original query directly | Slightly less comprehensive results |\n| Embedding Index | Semantic similarity search | No semantic understanding | Fall back to lexical BM25 search | Keyword-only search, vocabulary mismatch issues |\n| Cross-Encoder Reranker | Precision ranking of top candidates | Lower result quality | Use semantic similarity scores only | Good results but less precise ordering |\n| Personalization Engine | User-specific result customization | Generic results for all users | Return non-personalized rankings | Relevant but not customized results |\n| Autocomplete Service | Typeahead query suggestions | No search assistance | Disable autocomplete feature | Users must type complete queries |\n\nThe `SearchMessage` processing pipeline includes circuit breaker patterns for each component integration. When a component fails repeatedly, its circuit breaker opens, automatically routing traffic around the failing component without waiting for timeouts. Circuit breakers include health check mechanisms that periodically test component availability and close the circuit when service is restored.\n\n**Timeout and Latency Management**\n\nSearch systems operate under strict latency constraints, requiring aggressive timeout management to prevent slow components from degrading overall user experience. The system implements hierarchical timeouts that allocate time budgets to different processing stages based on their importance and expected execution time.\n\nThe total search request timeout of 500ms is divided among components based on their criticality and typical processing time. Query processing receives 50ms, embedding generation 100ms, vector search 150ms, ranking 150ms, and result formatting 50ms. These budgets include buffer time for network communication and potential retries.\n\n> **Decision: Timeout Allocation Strategy**\n> - **Context**: Limited 500ms search timeout must be allocated across multiple processing stages with varying importance\n> - **Options Considered**:\n>   1. Equal time allocation across all components\n>   2. Priority-based allocation with more time for critical components\n>   3. Adaptive allocation based on historical performance\n> - **Decision**: Fixed priority-based allocation with monitoring for future adaptive improvements\n> - **Rationale**: Predictable performance is more important than optimal resource utilization in user-facing search applications\n> - **Consequences**: Provides consistent user experience but may underutilize fast components when slow components are struggling\n\nWhen components exceed their timeout budgets, the system implements different strategies based on the processing stage. Early-stage timeouts (query processing, embedding generation) trigger fallback to simpler approaches. Late-stage timeouts (ranking, result formatting) return partial results with degraded quality rather than failing completely.\n\nThe timeout management includes adaptive mechanisms that adjust budgets based on system load and performance trends. During high-load periods, non-essential components receive reduced time budgets to ensure core functionality remains responsive. The system tracks timeout frequencies and automatically increases budgets for components that consistently exceed their allocations due to legitimate processing complexity.\n\n**Partial Result Handling**\n\nPartial results occur when some components successfully process a search request while others fail or timeout. The system must decide whether to return incomplete results immediately or attempt additional processing to improve quality. This decision depends on the specific failures, result quality, and remaining time budget.\n\nThe partial result evaluation uses a quality scoring mechanism that assesses result completeness across multiple dimensions: result count, relevance confidence, ranking signal availability, and personalization completeness. Results that meet minimum quality thresholds are returned immediately with appropriate metadata indicating their limitations.\n\n| Partial Result Type | Quality Assessment | Return Decision | User Notification |\n|---------------------|-------------------|------------------|-------------------|\n| Reduced Result Count | Less than requested max results | Return if above minimum threshold (5 results) | \"Showing N results (some sources temporarily unavailable)\" |\n| Missing Personalization | Generic results without user customization | Return with depersonalized ranking | No explicit notification, log for analysis |\n| Degraded Ranking | BM25 only without semantic reranking | Return with warning about result quality | \"Results may be less relevant due to temporary service issues\" |\n| Missing Facets | Search results without category filtering | Return results, disable faceted navigation | Remove facet UI elements, show basic results |\n| Incomplete Highlighting | Results without query term highlighting | Return plain text snippets | Show results without highlighted terms |\n\nThe system maintains result quality metrics that track partial result frequency and user satisfaction. When partial results become frequent, automated alerts notify operators of potential systemic issues requiring investigation. The metrics differentiate between acceptable degradation (minor feature unavailability) and problematic degradation (significantly reduced result quality).\n\n### Edge Case Query Handling\n\nUser queries exhibit enormous variety and often test system boundaries in unexpected ways. Robust query handling requires anticipating edge cases and implementing graceful responses that guide users toward successful searches rather than presenting cryptic errors.\n\n**Empty and Malformed Query Processing**\n\nEmpty queries represent one of the most common edge cases, occurring when users submit search forms without entering text, when text processing removes all meaningful content, or when queries contain only stop words or punctuation. The system must distinguish between truly empty queries and queries that become empty after processing.\n\nThe query validation pipeline implements multi-stage filtering that preserves user intent while handling malformed input. Raw query text first undergoes basic sanitization to remove control characters and excessive whitespace. The resulting text is then analyzed for meaningful content, considering factors like minimum length requirements, presence of alphanumeric characters, and language detection confidence.\n\n| Query Type | Example | Processing Result | User Response |\n|------------|---------|-------------------|---------------|\n| Completely Empty | \"\" (empty string) | Return trending/popular results | \"Here are some popular searches to get you started\" |\n| Whitespace Only | \"   \\n\\t  \" | Normalize to empty, treat as above | Same as completely empty |\n| Only Punctuation | \"!@#$%^&*()\" | Remove punctuation, treat as empty | \"Please enter search terms using letters or numbers\" |\n| Only Stop Words | \"the and or but\" | Preserve original query for context | Process as phrase search despite low content value |\n| Mixed Valid/Invalid | \"hello @@@ world\" | Clean to \"hello world\" | Process cleaned version normally |\n| Non-ASCII Characters | \"café naïve résumé\" | Preserve Unicode, validate encoding | Process normally with proper character handling |\n| Control Characters | \"hello\\x00world\\x01\" | Strip control chars, preserve content | Clean and process \"helloworld\" |\n\nFor queries that become empty after processing, the system provides contextual assistance rather than error messages. Default responses include trending searches, category suggestions, or recently popular queries relevant to the user's context. This approach transforms a potential failure into a discovery opportunity.\n\nThe malformed query recovery includes spell checking and suggestion generation. When queries contain apparent typos or unusual character combinations, the system generates suggested corrections and presents them alongside search results. For queries with encoding issues or corrupted characters, the system attempts character set detection and conversion before falling back to error responses.\n\n**Query Length and Complexity Limits**\n\nExtremely long queries pose challenges for embedding generation, memory usage, and processing latency. The system implements multiple layers of query length management that balance comprehensive query understanding with performance requirements.\n\nThe maximum query length of 500 characters represents a balance between supporting complex queries and preventing resource exhaustion. Queries exceeding this limit are truncated using intelligent strategies that preserve the most important query components. The truncation process identifies key phrases, proper nouns, and technical terms that should be preserved, removing common words and redundant phrases as needed.\n\n> **Critical Insight**: Query truncation must preserve user intent, not just maintain arbitrary length limits. A query about \"machine learning algorithms for natural language processing in healthcare applications\" should preserve the domain-specific terms even if common words are removed.\n\nVery long queries often indicate specific information needs that benefit from different processing strategies. Instead of treating them as single semantic units, the system decomposes complex queries into multiple semantic components that can be processed independently and combined during ranking.\n\n| Query Length | Processing Strategy | Example Handling | Performance Impact |\n|--------------|-------------------|------------------|-------------------|\n| 0-50 characters | Standard processing | Single embedding, full expansion | Minimal overhead |\n| 51-200 characters | Enhanced processing | Multi-phrase analysis, selective expansion | Moderate overhead |\n| 201-500 characters | Complex processing | Query decomposition, component weighting | Higher latency |\n| 501+ characters | Truncation required | Preserve key terms, truncate padding | Prevent timeout |\n| Extremely long (1000+) | Aggressive truncation | Extract key concepts only | Maintain responsiveness |\n\nThe query complexity analysis identifies several patterns that require special handling: multiple questions within a single query, queries with complex boolean logic, queries mixing multiple languages, and queries containing both structured and unstructured components. Each pattern triggers specialized processing pipelines optimized for that query type.\n\n**Special Character and Encoding Issues**\n\nModern search systems must handle queries containing diverse character sets, emoji, special symbols, and potentially corrupted text. The challenge is preserving meaningful content while preventing security issues and processing failures.\n\nThe character processing pipeline implements multiple validation and normalization stages. Initial validation checks for proper UTF-8 encoding and attempts correction for common encoding problems. Character normalization handles Unicode equivalence issues, ensuring that different representations of the same character are treated consistently.\n\nEmoji and symbol handling requires domain-specific knowledge about their semantic meaning. Technical queries containing mathematical symbols, programming operators, or chemical formulas need different processing than casual queries with decorative emoji. The system maintains context-aware symbol handling that preserves meaning in technical domains while normalizing decorative elements.\n\n| Character Type | Processing Approach | Example | Result |\n|----------------|-------------------|---------|--------|\n| Standard ASCII | No processing needed | \"hello world\" | \"hello world\" |\n| Extended Latin | Unicode normalization | \"café naïve\" | \"café naïve\" |\n| Technical Symbols | Preserve in technical contexts | \"c++ programming\" | \"c++ programming\" |\n| Mathematical Notation | Convert to searchable terms | \"E=mc²\" | \"E=mc² energy mass\" |\n| Emoji in Context | Semantic interpretation | \"python 🐍 programming\" | \"python snake programming\" |\n| Mixed Scripts | Language detection per segment | \"hello 你好 world\" | Process each script appropriately |\n| Corrupted Encoding | Attempt repair or removal | \"caf\\xc3\\xa9\" | \"café\" (if repairable) |\n\nSecurity considerations include preventing injection attacks through specially crafted Unicode sequences and ensuring that character processing doesn't create buffer overflows or infinite loops. The system implements strict limits on character processing complexity and validates all text transformations to prevent exploitation.\n\nThe encoding error recovery attempts automatic detection and correction for common encoding problems like double-encoding, wrong charset interpretation, and truncated multi-byte sequences. When automatic correction fails, the system gracefully degrades by removing problematic characters while preserving as much meaningful content as possible.\n\n### Implementation Guidance\n\nThe error handling implementation spans all system components, requiring consistent patterns and shared infrastructure for failure detection, reporting, and recovery. This guidance provides the foundational error handling code that supports all milestones while allowing each component to implement domain-specific error handling logic.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Error Types | Standard Python exceptions | Custom exception hierarchy with error codes |\n| Logging | Python logging module | Structured logging with correlation IDs |\n| Circuit Breakers | Simple counter-based implementation | Libraries like PyBreaker or Tenacity |\n| Retries | Basic retry loops with sleep | Tenacity library with exponential backoff |\n| Monitoring | Print statements and log files | Prometheus metrics with Grafana dashboards |\n| Health Checks | HTTP endpoint returning status | Comprehensive health check framework |\n\n**Recommended File Structure:**\n```\nproject-root/\n  src/\n    semantic_search/\n      core/\n        errors.py              ← Custom exception types and error handling utilities\n        monitoring.py          ← Health checks and metrics collection\n        retry.py              ← Retry logic and circuit breakers\n      index/\n        error_handlers.py     ← Index-specific error handling\n      query/\n        error_handlers.py     ← Query processing error handling\n      ranking/\n        error_handlers.py     ← Ranking component error handling\n      api/\n        error_handlers.py     ← API-specific error handling\n        middleware.py         ← Request/response error middleware\n  tests/\n    error_scenarios/          ← Error simulation and recovery tests\n      test_index_failures.py\n      test_search_degradation.py\n      test_edge_cases.py\n```\n\n**Core Error Handling Infrastructure:**\n\n```python\n# src/semantic_search/core/errors.py\n\"\"\"\nCore error handling infrastructure for semantic search engine.\nProvides consistent error types, context tracking, and recovery patterns.\n\"\"\"\nimport time\nimport uuid\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any, List\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass ErrorSeverity(Enum):\n    \"\"\"Severity levels for error classification and response.\"\"\"\n    LOW = \"low\"           # Degraded functionality, user barely notices\n    MEDIUM = \"medium\"     # Reduced functionality, user experience affected\n    HIGH = \"high\"         # Major functionality loss, user experience poor\n    CRITICAL = \"critical\" # System unusable, immediate attention required\n\nclass ComponentType(Enum):\n    \"\"\"System components for error tracking and circuit breaker management.\"\"\"\n    EMBEDDING_MODEL = \"embedding_model\"\n    VECTOR_INDEX = \"vector_index\"\n    QUERY_PROCESSOR = \"query_processor\"\n    RANKING_ENGINE = \"ranking_engine\"\n    SEARCH_API = \"search_api\"\n\n@dataclass\nclass ContextInfo:\n    \"\"\"Processing context information for error correlation and debugging.\"\"\"\n    correlation_id: str\n    user_id: Optional[str]\n    request_timestamp: datetime\n    processing_budget_ms: int\n    quality_vs_speed: str = \"balanced\"  # \"speed\", \"balanced\", \"quality\"\n    component_trace: List[str] = None\n    \n    def __post_init__(self):\n        if self.component_trace is None:\n            self.component_trace = []\n\n@dataclass\nclass ProcessingResult:\n    \"\"\"Standardized result wrapper for all component operations.\"\"\"\n    success: bool\n    data: Any\n    error_message: Optional[str] = None\n    error_code: Optional[str] = None\n    processing_time_ms: float = 0.0\n    context: Optional[ContextInfo] = None\n\nclass SemanticSearchError(Exception):\n    \"\"\"Base exception for all semantic search system errors.\"\"\"\n    def __init__(self, message: str, error_code: str = None, \n                 component: ComponentType = None, severity: ErrorSeverity = ErrorSeverity.MEDIUM,\n                 context: ContextInfo = None, original_error: Exception = None):\n        super().__init__(message)\n        self.error_code = error_code or \"GENERIC_ERROR\"\n        self.component = component\n        self.severity = severity\n        self.context = context\n        self.original_error = original_error\n        self.timestamp = datetime.now()\n\nclass EmbeddingModelError(SemanticSearchError):\n    \"\"\"Errors related to embedding model loading, inference, or configuration.\"\"\"\n    def __init__(self, message: str, model_name: str = None, **kwargs):\n        super().__init__(message, component=ComponentType.EMBEDDING_MODEL, **kwargs)\n        self.model_name = model_name\n\nclass IndexCorruptionError(SemanticSearchError):\n    \"\"\"Errors indicating vector index corruption or inconsistency.\"\"\"\n    def __init__(self, message: str, index_path: str = None, **kwargs):\n        super().__init__(message, component=ComponentType.VECTOR_INDEX, \n                        severity=ErrorSeverity.HIGH, **kwargs)\n        self.index_path = index_path\n\nclass QueryProcessingError(SemanticSearchError):\n    \"\"\"Errors during query parsing, expansion, or embedding generation.\"\"\"\n    def __init__(self, message: str, query_text: str = None, **kwargs):\n        super().__init__(message, component=ComponentType.QUERY_PROCESSOR, **kwargs)\n        self.query_text = query_text\n\nclass RankingError(SemanticSearchError):\n    \"\"\"Errors during result ranking or relevance computation.\"\"\"\n    def __init__(self, message: str, **kwargs):\n        super().__init__(message, component=ComponentType.RANKING_ENGINE, **kwargs)\n\nclass SearchAPIError(SemanticSearchError):\n    \"\"\"API-level errors including validation, formatting, and response generation.\"\"\"\n    def __init__(self, message: str, **kwargs):\n        super().__init__(message, component=ComponentType.SEARCH_API, **kwargs)\n\ndef create_context(user_id: str = None, processing_budget_ms: int = 500, \n                   quality_vs_speed: str = \"balanced\") -> ContextInfo:\n    \"\"\"Create processing context with unique correlation ID.\"\"\"\n    return ContextInfo(\n        correlation_id=str(uuid.uuid4()),\n        user_id=user_id,\n        request_timestamp=datetime.now(),\n        processing_budget_ms=processing_budget_ms,\n        quality_vs_speed=quality_vs_speed,\n        component_trace=[]\n    )\n\ndef wrap_result(func):\n    \"\"\"Decorator to wrap function results in ProcessingResult objects.\"\"\"\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        try:\n            result = func(*args, **kwargs)\n            processing_time = (time.time() - start_time) * 1000\n            return ProcessingResult(\n                success=True,\n                data=result,\n                processing_time_ms=processing_time\n            )\n        except Exception as e:\n            processing_time = (time.time() - start_time) * 1000\n            return ProcessingResult(\n                success=False,\n                data=None,\n                error_message=str(e),\n                error_code=getattr(e, 'error_code', 'UNKNOWN_ERROR'),\n                processing_time_ms=processing_time\n            )\n    return wrapper\n```\n\n**Circuit Breaker and Retry Logic:**\n\n```python\n# src/semantic_search/core/retry.py\n\"\"\"\nRetry logic and circuit breaker patterns for fault-tolerant component integration.\nImplements exponential backoff, circuit breakers, and timeout management.\n\"\"\"\nimport time\nimport random\nfrom typing import Callable, Any, Optional, Dict\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom threading import Lock\n\n@dataclass\nclass CircuitBreakerConfig:\n    \"\"\"Configuration for circuit breaker behavior.\"\"\"\n    failure_threshold: int = 5      # Failures before opening circuit\n    success_threshold: int = 3      # Successes needed to close circuit\n    timeout_seconds: int = 60       # Time to wait before retry attempts\n    half_open_max_calls: int = 1    # Max calls to allow in half-open state\n\n@dataclass\nclass RetryConfig:\n    \"\"\"Configuration for retry behavior.\"\"\"\n    max_attempts: int = 3\n    base_delay_seconds: float = 1.0\n    max_delay_seconds: float = 30.0\n    exponential_base: float = 2.0\n    jitter: bool = True\n\nclass CircuitBreakerState:\n    CLOSED = \"closed\"      # Normal operation, failures counted\n    OPEN = \"open\"          # Circuit open, calls rejected immediately\n    HALF_OPEN = \"half_open\"  # Testing if service recovered\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker implementation for component fault tolerance.\"\"\"\n    \n    def __init__(self, name: str, config: CircuitBreakerConfig = None):\n        self.name = name\n        self.config = config or CircuitBreakerConfig()\n        self.state = CircuitBreakerState.CLOSED\n        self.failure_count = 0\n        self.success_count = 0\n        self.last_failure_time = None\n        self.half_open_calls = 0\n        self._lock = Lock()\n    \n    def can_execute(self) -> bool:\n        \"\"\"Check if execution is allowed based on current circuit state.\"\"\"\n        with self._lock:\n            if self.state == CircuitBreakerState.CLOSED:\n                return True\n            \n            if self.state == CircuitBreakerState.OPEN:\n                if self._should_attempt_reset():\n                    self.state = CircuitBreakerState.HALF_OPEN\n                    self.half_open_calls = 0\n                    return True\n                return False\n            \n            if self.state == CircuitBreakerState.HALF_OPEN:\n                return self.half_open_calls < self.config.half_open_max_calls\n            \n            return False\n    \n    def record_success(self):\n        \"\"\"Record successful operation, potentially closing the circuit.\"\"\"\n        with self._lock:\n            self.failure_count = 0\n            \n            if self.state == CircuitBreakerState.HALF_OPEN:\n                self.success_count += 1\n                if self.success_count >= self.config.success_threshold:\n                    self.state = CircuitBreakerState.CLOSED\n                    self.success_count = 0\n    \n    def record_failure(self):\n        \"\"\"Record failed operation, potentially opening the circuit.\"\"\"\n        with self._lock:\n            self.failure_count += 1\n            self.last_failure_time = datetime.now()\n            \n            if self.failure_count >= self.config.failure_threshold:\n                self.state = CircuitBreakerState.OPEN\n            \n            if self.state == CircuitBreakerState.HALF_OPEN:\n                self.state = CircuitBreakerState.OPEN\n                self.success_count = 0\n    \n    def _should_attempt_reset(self) -> bool:\n        \"\"\"Check if enough time has passed to attempt circuit reset.\"\"\"\n        if self.last_failure_time is None:\n            return True\n        \n        elapsed = datetime.now() - self.last_failure_time\n        return elapsed.total_seconds() >= self.config.timeout_seconds\n\nclass ComponentClient:\n    \"\"\"Base class for fault-tolerant component clients with retry and circuit breaking.\"\"\"\n    \n    def __init__(self, component_name: str, \n                 circuit_config: CircuitBreakerConfig = None,\n                 retry_config: RetryConfig = None):\n        self.component_name = component_name\n        self.circuit_breaker = CircuitBreaker(component_name, circuit_config)\n        self.retry_config = retry_config or RetryConfig()\n        self.call_stats = {\n            \"total_calls\": 0,\n            \"successful_calls\": 0,\n            \"failed_calls\": 0,\n            \"circuit_open_rejections\": 0\n        }\n    \n    def execute_with_fallback(self, operation: Callable, fallback: Callable = None, \n                            context: ContextInfo = None) -> ProcessingResult:\n        \"\"\"Execute operation with circuit breaker protection and optional fallback.\"\"\"\n        # TODO 1: Check if circuit breaker allows execution\n        # TODO 2: If not allowed, record rejection and try fallback\n        # TODO 3: Execute operation with retry logic\n        # TODO 4: Record success/failure with circuit breaker\n        # TODO 5: If primary fails and fallback exists, try fallback\n        # TODO 6: Return ProcessingResult with success/failure info\n        pass\n    \n    def _execute_with_retry(self, operation: Callable, context: ContextInfo = None) -> Any:\n        \"\"\"Execute operation with exponential backoff retry logic.\"\"\"\n        # TODO 1: Loop through retry attempts (max_attempts)\n        # TODO 2: Try operation, return result if successful\n        # TODO 3: If failure, calculate delay with exponential backoff\n        # TODO 4: Add jitter to delay if configured\n        # TODO 5: Sleep for calculated delay before next attempt\n        # TODO 6: If all attempts fail, raise last exception\n        pass\n    \n    def get_health_status(self) -> Dict[str, Any]:\n        \"\"\"Get component health and circuit breaker status.\"\"\"\n        return {\n            \"component\": self.component_name,\n            \"circuit_state\": self.circuit_breaker.state,\n            \"failure_count\": self.circuit_breaker.failure_count,\n            \"call_stats\": self.call_stats,\n            \"last_failure\": self.circuit_breaker.last_failure_time.isoformat() \n                          if self.circuit_breaker.last_failure_time else None\n        }\n```\n\n**Query Edge Case Handlers:**\n\n```python\n# src/semantic_search/query/error_handlers.py\n\"\"\"\nQuery processing error handlers for edge cases and malformed input.\nHandles empty queries, length limits, character encoding issues.\n\"\"\"\nimport re\nimport unicodedata\nfrom typing import Optional, List, Tuple, Dict\nfrom dataclasses import dataclass\n\n@dataclass\nclass QueryValidationResult:\n    \"\"\"Result of query validation with sanitized text and warnings.\"\"\"\n    is_valid: bool\n    sanitized_query: str\n    warnings: List[str]\n    suggestions: List[str]\n    metadata: Dict[str, Any]\n\nclass QuerySanitizer:\n    \"\"\"Handles query cleaning and normalization for edge cases.\"\"\"\n    \n    def __init__(self):\n        # Common patterns for query cleaning\n        self.control_char_pattern = re.compile(r'[\\x00-\\x1f\\x7f-\\x9f]')\n        self.excessive_whitespace = re.compile(r'\\s+')\n        self.punctuation_only = re.compile(r'^[^\\w\\s]*$', re.UNICODE)\n        self.stop_words = {\n            'english': {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n        }\n        \n        # Technical term patterns to preserve\n        self.technical_patterns = [\n            re.compile(r'\\w+\\+\\+'),     # C++, etc.\n            re.compile(r'[A-Z]{2,}'),   # Acronyms\n            re.compile(r'\\w+\\.\\w+'),    # Domains, versions\n            re.compile(r'#\\w+'),        # Hash tags\n        ]\n    \n    def validate_and_sanitize(self, query_text: str, \n                            max_length: int = MAX_QUERY_LENGTH) -> QueryValidationResult:\n        \"\"\"Main entry point for query validation and sanitization.\"\"\"\n        # TODO 1: Check for completely empty or None input\n        # TODO 2: Remove control characters and normalize Unicode\n        # TODO 3: Handle excessive whitespace and normalize spacing\n        # TODO 4: Check for punctuation-only queries\n        # TODO 5: Validate character encoding and fix common issues\n        # TODO 6: Apply length limits with intelligent truncation\n        # TODO 7: Generate suggestions for problematic queries\n        # TODO 8: Return ValidationResult with sanitized text and metadata\n        pass\n    \n    def _normalize_unicode(self, text: str) -> Tuple[str, List[str]]:\n        \"\"\"Normalize Unicode characters and detect encoding issues.\"\"\"\n        warnings = []\n        try:\n            # Normalize Unicode to canonical form\n            normalized = unicodedata.normalize('NFC', text)\n            \n            # Detect and fix common encoding problems\n            if normalized != text:\n                warnings.append(\"Unicode characters normalized\")\n            \n            return normalized, warnings\n        except Exception:\n            warnings.append(\"Unicode normalization failed, using original text\")\n            return text, warnings\n    \n    def _intelligent_truncation(self, text: str, max_length: int) -> Tuple[str, List[str]]:\n        \"\"\"Truncate query while preserving important terms.\"\"\"\n        if len(text) <= max_length:\n            return text, []\n        \n        warnings = [f\"Query truncated from {len(text)} to {max_length} characters\"]\n        \n        # TODO 1: Split text into words/phrases\n        # TODO 2: Identify technical terms and proper nouns to preserve\n        # TODO 3: Remove common words and filler text first\n        # TODO 4: If still too long, truncate from end while preserving key terms\n        # TODO 5: Return truncated text with warnings about what was removed\n        pass\n    \n    def _generate_query_suggestions(self, original: str, sanitized: str, \n                                  warnings: List[str]) -> List[str]:\n        \"\"\"Generate helpful suggestions for problematic queries.\"\"\"\n        suggestions = []\n        \n        # TODO 1: Check if query became empty after sanitization\n        # TODO 2: Check if query is very short (< 3 characters)\n        # TODO 3: Check for apparent typos or unusual patterns\n        # TODO 4: Suggest query expansion for very specific terms\n        # TODO 5: Provide examples for empty or invalid queries\n        pass\n\nclass EdgeCaseHandler:\n    \"\"\"Handles specific edge cases in query processing.\"\"\"\n    \n    def __init__(self):\n        self.sanitizer = QuerySanitizer()\n        self.trending_queries = [\n            \"machine learning\", \"python programming\", \"data science\",\n            \"web development\", \"artificial intelligence\"\n        ]\n    \n    def handle_empty_query(self, context: ContextInfo = None) -> ProcessingResult:\n        \"\"\"Handle empty queries by providing trending or contextual suggestions.\"\"\"\n        # TODO 1: Check if user context provides recent queries or interests\n        # TODO 2: Select appropriate trending queries based on context\n        # TODO 3: Format response with helpful suggestions and explanations\n        # TODO 4: Return ProcessingResult with suggested queries and metadata\n        pass\n    \n    def handle_malformed_query(self, query_text: str, \n                             validation_result: QueryValidationResult,\n                             context: ContextInfo = None) -> ProcessingResult:\n        \"\"\"Handle queries that can't be processed normally.\"\"\"\n        # TODO 1: Assess severity of malformation (correctable vs. unusable)\n        # TODO 2: Attempt automatic correction for common issues\n        # TODO 3: If correctable, process corrected version\n        # TODO 4: If uncorrectable, provide helpful error message and suggestions\n        # TODO 5: Log malformed query patterns for analysis\n        pass\n    \n    def handle_excessive_length(self, query_text: str, max_length: int = MAX_QUERY_LENGTH,\n                              context: ContextInfo = None) -> ProcessingResult:\n        \"\"\"Handle queries exceeding maximum length limits.\"\"\"\n        # TODO 1: Apply intelligent truncation preserving key terms\n        # TODO 2: Identify if query contains multiple distinct questions\n        # TODO 3: If multiple questions, suggest breaking into separate searches\n        # TODO 4: Process truncated query with warning about limitations\n        # TODO 5: Include original full query in metadata for analysis\n        pass\n```\n\n**Milestone Checkpoints:**\n\nAfter implementing error handling for each milestone, verify the following behaviors:\n\n**Milestone 1 - Embedding Index Error Handling:**\n- Test command: `python -m pytest tests/error_scenarios/test_index_failures.py`\n- Expected behavior: Index construction continues despite individual document failures, corrupted indices are detected and recovered\n- Manual verification: Intentionally corrupt an index file, verify system detects corruption and rebuilds from backup\n- Warning signs: High memory usage during error recovery, frequent index rebuilds, documents permanently failing embedding\n\n**Milestone 2 - Query Processing Error Handling:**\n- Test command: `python -m pytest tests/error_scenarios/test_query_edge_cases.py`\n- Expected behavior: Empty queries return suggestions, malformed queries are cleaned, very long queries are intelligently truncated\n- Manual verification: Submit queries with special characters, excessive length, and various encoding issues\n- Warning signs: Query processing timeouts, Unicode errors in logs, sanitized queries losing important meaning\n\n**Milestone 3 - Ranking Error Handling:**\n- Test command: `python -m pytest tests/error_scenarios/test_ranking_degradation.py`\n- Expected behavior: Ranking failures fall back to simpler scoring methods, partial results are returned with quality warnings\n- Manual verification: Disable cross-encoder service, verify search continues with degraded ranking\n- Warning signs: Ranking consistently timing out, significant quality degradation, circuit breakers frequently open\n\n**Milestone 4 - Search API Error Handling:**\n- Test command: `python -m pytest tests/error_scenarios/test_api_resilience.py`\n- Expected behavior: API requests complete within timeout limits, graceful error responses with helpful messages\n- Manual verification: Submit malformed API requests, verify appropriate HTTP status codes and error messages\n- Warning signs: API timeouts, unhelpful error messages, clients receiving 500 errors for user input issues\n\n**Common Debugging Patterns:**\n\n| Symptom | Likely Cause | Diagnostic Steps | Resolution |\n|---------|--------------|------------------|------------|\n| Search returns empty results frequently | Index corruption or embedding model failure | Check index integrity, test embedding generation | Rebuild index, verify model configuration |\n| High latency on all searches | Component timeouts or resource exhaustion | Check component response times, monitor resource usage | Increase timeouts, optimize resource allocation |\n| Circuit breakers frequently open | Dependent service failures or configuration issues | Review service health checks, adjust circuit breaker thresholds | Fix underlying service issues, tune circuit breaker settings |\n| Unicode errors in query processing | Text encoding issues or character normalization problems | Log raw query bytes, test character encoding detection | Improve encoding detection, add character sanitization |\n| Index updates failing silently | Transaction log corruption or insufficient error handling | Check transaction logs, verify error reporting | Improve transaction logging, add update monitoring |\n\n\n## Testing Strategy\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing comprehensive testing approaches that verify each milestone's acceptance criteria and ensure production readiness.\n\nTesting a semantic search engine requires a fundamentally different approach than testing traditional software systems. Think of it like **testing a translator** — you're not just verifying that the system doesn't crash, but that it actually understands meaning and produces results that match human expectations. Unlike deterministic systems where you can predict exact outputs, semantic search involves probabilistic models, approximate algorithms, and subjective relevance judgments that require sophisticated evaluation strategies.\n\nThe challenge lies in the multi-dimensional nature of search quality. A search engine can be technically correct (fast, available, error-free) but still fail users if it doesn't understand their intent or returns irrelevant results. Conversely, a system that provides excellent semantic understanding might fail in production if it can't handle load or gracefully degrade when components fail. Our testing strategy must therefore evaluate three critical dimensions: **search quality** (does it understand meaning?), **performance characteristics** (does it meet latency and throughput requirements?), and **system reliability** (does it handle failures gracefully?).\n\nEach milestone introduces new complexity that requires specific testing approaches. The embedding index (Milestone 1) needs stress testing with millions of vectors and validation of approximate nearest neighbor accuracy. Query processing (Milestone 2) requires evaluation of expansion quality and semantic understanding accuracy. Ranking and relevance (Milestone 3) demands sophisticated offline evaluation metrics and online A/B testing frameworks. The search API (Milestone 4) needs end-to-end integration testing and user experience validation.\n\n> **Key Testing Philosophy**: We test semantic search engines like we evaluate human translators — not just for technical correctness, but for accuracy, fluency, and appropriateness of understanding. This requires combining quantitative metrics with qualitative evaluation and real-world usage validation.\n\n### Search Quality Evaluation\n\n**Mental Model: The Academic Paper Review Process**\n\nThink of search quality evaluation like **academic peer review** for research papers. Just as reviewers evaluate papers on multiple criteria — relevance to the topic, methodology soundness, novelty of insights, and clarity of presentation — we must evaluate search results on multiple quality dimensions. A single metric like \"precision\" is insufficient, just as a single criterion like \"grammatical correctness\" would be inadequate for evaluating research quality.\n\nThe evaluation process involves creating **test collections** (like academic conferences define paper topics), establishing **ground truth relevance judgments** (like expert reviewers rating papers), and applying **multiple evaluation metrics** that capture different aspects of quality. The key insight is that search quality is fundamentally subjective and context-dependent, requiring systematic approaches to capture and measure human judgment.\n\n#### Relevance Metrics and Measurement Framework\n\nOur search quality evaluation framework employs multiple complementary metrics that capture different aspects of search effectiveness. These metrics form a comprehensive scorecard that evaluates both **ranking quality** (are the best results ranked highest?) and **retrieval effectiveness** (do we find all relevant documents?).\n\n**Core Relevance Metrics**\n\n| Metric Name | Formula | What It Measures | Strengths | Limitations |\n|-------------|---------|------------------|-----------|-------------|\n| Precision@K | Relevant results in top K / K | Accuracy of top results | Easy to understand, user-focused | Ignores rank order within top K |\n| Recall@K | Relevant results in top K / Total relevant | Coverage of relevant documents | Shows retrieval completeness | Requires knowing all relevant docs |\n| Mean Average Precision (MAP) | Average of precision at each relevant result | Ranking quality across all positions | Considers rank order, single number | Biased toward queries with many relevant docs |\n| Normalized DCG@K | DCG@K / IDCG@K | Ranking quality with graded relevance | Handles multiple relevance levels | Requires expensive graded judgments |\n| Mean Reciprocal Rank (MRR) | Average of 1/rank of first relevant result | Time to first good result | Critical for user satisfaction | Only considers first relevant result |\n| Expected Reciprocal Rank (ERR) | Models user abandonment probability | Realistic user interaction model | Accounts for result utility | Complex to compute and interpret |\n\n**Graded Relevance Scale**\n\nRather than binary relevant/irrelevant judgments, we employ a four-point relevance scale that captures the nuanced quality of search results:\n\n| Relevance Grade | Score | Description | User Action | Example Query: \"machine learning algorithms\" |\n|----------------|-------|-------------|-------------|------------------------------------------|\n| Perfect | 4 | Exactly what user wanted | Clicks and stays | \"Comprehensive Guide to ML Algorithms\" |\n| Excellent | 3 | Highly relevant and useful | Clicks, likely to stay | \"Top 10 Machine Learning Algorithms Explained\" |\n| Good | 2 | Somewhat relevant | May click, may bounce | \"Introduction to Artificial Intelligence\" |\n| Fair | 1 | Marginally relevant | Unlikely to click | \"Software Engineering Best Practices\" |\n| Bad | 0 | Not relevant | Ignores completely | \"Cooking Recipes for Beginners\" |\n\nThis graded approach enables more sophisticated metrics like NDCG that reward highly relevant results more than marginally relevant ones, better reflecting real user satisfaction patterns.\n\n#### Test Query Development Strategy\n\nEffective search quality evaluation requires carefully constructed test queries that represent real user needs and cover the full spectrum of search complexity. Our test query development follows a systematic approach that ensures comprehensive coverage of user intent patterns and system stress cases.\n\n**Query Collection Categories**\n\n| Category | Description | Example Queries | Testing Focus | Expected Volume |\n|----------|-------------|-----------------|---------------|----------------|\n| Factual Lookup | Specific information seeking | \"Python list comprehension syntax\" | Precision of exact matches | 25% |\n| Conceptual Exploration | Understanding broad topics | \"differences between SQL and NoSQL\" | Semantic understanding depth | 30% |\n| Comparative Analysis | Evaluating alternatives | \"React vs Vue performance comparison\" | Multi-faceted result ranking | 20% |\n| Problem Solving | Solution-oriented searches | \"how to debug memory leaks in Node.js\" | Practical relevance ranking | 15% |\n| Ambiguous Intent | Multiple possible interpretations | \"apple development\" (fruit/company) | Disambiguation and diversity | 10% |\n\n**Query Complexity Progression**\n\nOur test queries are stratified by complexity to ensure the system handles both simple and sophisticated information needs:\n\n1. **Simple Keyword Queries**: Single concepts with clear intent (\"machine learning\", \"database design\")\n2. **Multi-Term Queries**: Combined concepts requiring understanding of relationships (\"distributed systems scalability patterns\")  \n3. **Natural Language Queries**: Conversational or question-based searches (\"What are the best practices for microservices architecture?\")\n4. **Technical Jargon Queries**: Domain-specific terminology (\"OAuth 2.0 PKCE flow implementation\")\n5. **Ambiguous Queries**: Terms with multiple meanings requiring context (\"spring framework\" vs \"spring season\")\n6. **Long-Tail Queries**: Very specific, uncommon information needs (\"debugging segmentation faults in embedded C applications\")\n\n**Ground Truth Establishment Process**\n\nEstablishing reliable ground truth relevance judgments requires a systematic annotation process that ensures consistency and quality:\n\n1. **Expert Annotator Recruitment**: Technical subject matter experts familiar with the document domain\n2. **Annotation Guidelines Development**: Detailed rubrics with examples for each relevance grade\n3. **Inter-Annotator Agreement Measurement**: Calculate Cohen's kappa or Fleiss' kappa to ensure consistency\n4. **Disagreement Resolution Process**: Systematic approach for handling conflicting judgments\n5. **Annotation Quality Control**: Regular calibration sessions and spot-checking of judgments\n\n**Relevance Judgment Collection Workflow**\n\n| Stage | Activity | Participants | Output | Quality Check |\n|-------|----------|--------------|--------|---------------|\n| Query Selection | Identify test queries from logs/experts | Search team + domain experts | 200-500 test queries | Coverage analysis across categories |\n| Result Pool Creation | Run queries against system + baselines | Automated systems | Top 20 results per query | Diversity verification |\n| Annotation Training | Train judges on guidelines | Expert annotators | Calibrated judgments | Inter-annotator agreement >0.7 |\n| Primary Annotation | Judge all query-result pairs | 2-3 annotators per pair | Graded relevance scores | Disagreement rate monitoring |\n| Consensus Building | Resolve annotation conflicts | Senior domain expert | Final relevance judgments | Spot audit of 10% of judgments |\n\n#### Offline Evaluation Infrastructure\n\nOur offline evaluation infrastructure enables rapid experimentation and systematic comparison of different system configurations without impacting production users. This infrastructure supports both **point-in-time evaluations** (comparing current system against baselines) and **temporal analysis** (tracking quality changes over time).\n\n**Evaluation Dataset Management**\n\nThe evaluation infrastructure manages multiple test collections that represent different aspects of search quality:\n\n| Dataset Name | Size | Domain Focus | Update Frequency | Primary Use Case |\n|-------------|------|--------------|------------------|------------------|\n| Core Quality Set | 100 queries, 2000 judgments | General technical content | Monthly | Primary quality metric tracking |\n| Domain Specific Sets | 50 queries each | Programming, DevOps, Architecture | Quarterly | Domain coverage validation |\n| Stress Test Set | 200 queries | Edge cases, ambiguous queries | As needed | Robustness testing |\n| Temporal Drift Set | 75 queries | Recently published content | Weekly | Freshness and drift monitoring |\n| User Intent Set | 150 queries | Real user query patterns | Bi-weekly | Production alignment validation |\n\n**Automated Evaluation Pipeline**\n\nThe offline evaluation pipeline runs automatically on every system change, providing immediate feedback on quality impact:\n\n1. **Trigger Events**: Code commits, model updates, index rebuilds, configuration changes\n2. **Execution Environment**: Isolated evaluation cluster with representative data\n3. **Result Collection**: Systematic querying and result capture for all test queries\n4. **Metric Computation**: Calculation of all relevance metrics against ground truth\n5. **Regression Detection**: Statistical significance testing to identify quality changes\n6. **Report Generation**: Automated dashboards and alerts for quality degradation\n\n**Quality Regression Detection Framework**\n\nChanges to the search system can inadvertently degrade quality in subtle ways. Our regression detection framework provides early warning of quality issues:\n\n| Detection Method | Metric Threshold | Time Window | Alert Trigger | Response Protocol |\n|------------------|------------------|-------------|---------------|-------------------|\n| Absolute Threshold | MAP < 0.75, NDCG@10 < 0.80 | Single evaluation | Immediate | Block deployment |\n| Relative Degradation | >5% decrease in any core metric | 3 evaluations | Within 4 hours | Investigation required |\n| Statistical Significance | p < 0.05 for quality decrease | 7 days | Daily batch | Monitoring intensification |\n| User-Focused Metrics | MRR < 0.85, P@1 < 0.70 | Single evaluation | Immediate | User impact assessment |\n| Temporal Trends | Declining trend >2 weeks | 14 days | Weekly | Root cause analysis |\n\n### Performance and Load Testing\n\n**Mental Model: Stress Testing a Bridge**\n\nThink of performance testing like **stress testing a bridge** before it opens to traffic. Engineers don't just verify that the bridge holds its own weight — they test it with progressively heavier loads, simulate extreme weather conditions, and ensure it can handle rush hour traffic without degradation. Similarly, our semantic search engine must demonstrate that it can handle production workloads while maintaining sub-second response times and graceful degradation under stress.\n\nThe key insight is that semantic search performance has multiple dimensions beyond simple response time. Vector similarity computations are CPU-intensive, large indices consume significant memory, and approximate algorithms trade accuracy for speed. Performance testing must validate that these trade-offs remain acceptable under realistic load conditions, and that the system degrades predictably when resources become constrained.\n\n#### Latency Benchmarks and SLA Definition\n\nOur performance testing framework establishes clear Service Level Agreements (SLAs) that define acceptable performance boundaries for different types of search operations. These SLAs provide both engineering targets and business commitments that guide system design decisions.\n\n**Response Time SLA Targets**\n\n| Operation Type | 50th Percentile | 95th Percentile | 99th Percentile | Timeout Limit | Business Rationale |\n|----------------|-----------------|-----------------|-----------------|---------------|-------------------|\n| Simple Search | <200ms | <500ms | <1000ms | 2000ms | Interactive user experience |\n| Complex Search | <500ms | <1000ms | <2000ms | 5000ms | Acceptable for detailed queries |\n| Autocomplete | <50ms | <100ms | <200ms | 500ms | Real-time typing feedback |\n| Facet Computation | <300ms | <800ms | <1500ms | 3000ms | Acceptable for filtering |\n| Similar Document | <400ms | <1000ms | <2000ms | 4000ms | Recommendation use case |\n| Bulk Query API | <100ms per query | <200ms per query | <500ms per query | 1000ms per query | Batch processing efficiency |\n\nThese targets are derived from user experience research showing that sub-200ms responses feel instantaneous, while responses over 1 second create noticeable delays that impact user satisfaction.\n\n**Latency Component Breakdown**\n\nUnderstanding where time is spent during search request processing enables targeted optimization efforts:\n\n| Component | Target Latency | Typical Range | Optimization Strategies | Measurement Method |\n|-----------|----------------|---------------|------------------------|-------------------|\n| Query Processing | <50ms | 20-80ms | Caching, text preprocessing optimization | Custom timing instrumentation |\n| Vector Embedding | <100ms | 50-150ms | Batch processing, model optimization | Model inference timing |\n| Index Search | <150ms | 80-300ms | Index tuning, hardware optimization | FAISS internal metrics |\n| Result Ranking | <100ms | 40-200ms | Multi-stage ranking, candidate pruning | Ranking pipeline timing |\n| Response Formatting | <20ms | 5-40ms | JSON optimization, snippet generation | HTTP middleware timing |\n| Network Overhead | <30ms | 10-50ms | Compression, CDN usage | Load balancer metrics |\n\n**Performance Testing Environment Setup**\n\nOur performance testing environment mirrors production infrastructure to ensure realistic results:\n\n| Environment Component | Specification | Rationale | Monitoring |\n|----------------------|---------------|-----------|------------|\n| Application Servers | 4 CPU cores, 16GB RAM | Matches production capacity | CPU, memory, network utilization |\n| Vector Index Storage | SSD with 500MB/s read throughput | Supports index scanning requirements | Disk I/O metrics, cache hit rates |\n| Load Generation | Distributed across 3 availability zones | Realistic network conditions | Request distribution, connection pooling |\n| Network Configuration | 100ms simulated WAN latency | Represents global user distribution | Round-trip time measurement |\n| Data Volume | 1M documents, 400MB index size | Production-scale dataset | Index size, memory usage |\n\n#### Throughput Validation and Scalability Testing\n\nThroughput testing validates that our semantic search engine can handle production query volumes while maintaining acceptable response times. This testing reveals system bottlenecks and helps establish capacity planning guidelines for different usage patterns.\n\n**Throughput Testing Scenarios**\n\n| Scenario Name | Query Rate | Concurrent Users | Query Pattern | Duration | Success Criteria |\n|---------------|------------|------------------|---------------|----------|------------------|\n| Baseline Load | 100 QPS | 200 | Mixed complexity | 30 minutes | All SLA targets met |\n| Peak Traffic | 500 QPS | 1000 | 70% simple, 30% complex | 15 minutes | 95% of requests meet SLA |\n| Burst Load | 1000 QPS spike | 2000 | Primarily simple queries | 5 minutes | Graceful degradation, no failures |\n| Sustained High Load | 300 QPS | 600 | Realistic user patterns | 2 hours | Stable performance, no memory leaks |\n| Gradual Ramp | 50→800 QPS | 100→1600 | Linear increase over time | 45 minutes | Smooth scaling, predictable degradation |\n| Mixed Workload | Variable | 800 | 40% search, 30% autocomplete, 30% facets | 1 hour | All operation types meet targets |\n\n**Resource Utilization Monitoring**\n\nUnderstanding resource consumption patterns helps identify bottlenecks and plan infrastructure requirements:\n\n| Resource Type | Monitoring Metrics | Alert Thresholds | Optimization Actions |\n|---------------|-------------------|------------------|---------------------|\n| CPU Usage | Per-core utilization, queue depth | >80% sustained | Scale horizontally, optimize algorithms |\n| Memory Consumption | Heap usage, index size, cache hit rate | >85% of available | Increase capacity, tune cache sizes |\n| Disk I/O | Read IOPS, throughput, queue depth | >70% of capacity | SSD upgrade, index optimization |\n| Network Bandwidth | Requests/sec, bytes transferred | >60% of capacity | Content compression, CDN usage |\n| Index Performance | Search latency, accuracy degradation | Latency >2x baseline | Index tuning, algorithm selection |\n| Cache Effectiveness | Hit rate, eviction rate | <80% hit rate | Cache size tuning, TTL optimization |\n\n**Scalability Characterization**\n\nSystematic scalability testing reveals how the system behaves as different dimensions scale up:\n\n1. **Document Volume Scaling**: Test with 100K, 500K, 1M, 5M documents to understand index size impact\n2. **Query Complexity Scaling**: Measure performance with varying query lengths and expansion factors\n3. **Concurrent User Scaling**: Increase simultaneous users from 100 to 2000 to find connection limits\n4. **Multi-Tenant Scaling**: Test with multiple independent search indices and query isolation\n5. **Geographic Distribution**: Validate performance across multiple data center regions\n\n**Performance Regression Detection**\n\nAutomated performance regression detection ensures that code changes don't inadvertently degrade system performance:\n\n| Regression Type | Detection Method | Alert Threshold | Response Action |\n|-----------------|------------------|-----------------|-----------------|\n| Latency Increase | Statistical comparison with baseline | >20% increase in P95 latency | Block deployment, investigate |\n| Throughput Decrease | Peak QPS comparison | >15% reduction in sustained QPS | Performance analysis required |\n| Resource Efficiency | CPU/memory per query comparison | >25% increase in resource usage | Optimization needed |\n| Cache Performance | Hit rate degradation | >10% reduction in cache hits | Cache configuration review |\n| Error Rate Increase | Success rate comparison | >2% increase in error rate | Immediate rollback consideration |\n\n#### Load Testing Infrastructure and Automation\n\nOur load testing infrastructure provides consistent, repeatable performance validation that integrates with the development workflow. This infrastructure supports both **on-demand testing** for specific changes and **continuous performance monitoring** for trend analysis.\n\n**Load Generation Architecture**\n\nThe load testing infrastructure uses a distributed architecture that can simulate realistic user traffic patterns:\n\n| Component | Purpose | Implementation | Scaling Capability |\n|-----------|---------|----------------|-------------------|\n| Test Controller | Orchestrates load tests, collects results | Python with asyncio | Single instance, manages distributed load |\n| Load Generators | Generate HTTP requests with realistic patterns | Multiple nodes, configurable concurrency | Horizontal scaling to 10K+ concurrent users |\n| Query Pattern Engine | Produces realistic query distributions | Probability-based query selection | Configurable patterns for different scenarios |\n| Response Validator | Verifies result quality during load | Sampling-based validation | Validates 10% of responses for correctness |\n| Metrics Collector | Aggregates performance data | Time-series database storage | Real-time dashboards and alerting |\n\n**Realistic Load Pattern Simulation**\n\nLoad testing must simulate realistic user behavior patterns rather than uniform request rates:\n\n| User Behavior Pattern | Implementation | Realistic Characteristics | Testing Value |\n|-----------------------|----------------|---------------------------|---------------|\n| Search Session Simulation | Multi-request sequences per user | Query refinement, result clicks, related searches | Tests session state and caching |\n| Geographic Distribution | Requests from multiple regions | Varying network latencies, timezone effects | Validates CDN and edge performance |\n| Query Frequency Distribution | Zipf distribution for query popularity | 20% of queries account for 80% of traffic | Tests caching effectiveness |\n| Burst Traffic Simulation | Configurable traffic spikes | News events, social media sharing | Tests auto-scaling and resilience |\n| Mobile vs Desktop Patterns | Different query patterns and latencies | Shorter queries, higher error tolerance | Tests adaptive optimization |\n\n**Continuous Performance Monitoring**\n\nBeyond discrete load tests, continuous monitoring tracks performance trends over time:\n\n1. **Hourly Micro-Tests**: Quick 5-minute load tests with 50 QPS to detect immediate regressions\n2. **Daily Benchmark Runs**: Comprehensive 30-minute tests covering all usage scenarios  \n3. **Weekly Capacity Planning**: Extended tests that project infrastructure requirements\n4. **Monthly Baseline Updates**: Recalibration of performance targets based on system evolution\n5. **Quarterly Stress Testing**: Extreme load conditions to identify absolute system limits\n\n### Milestone Verification Checkpoints\n\nEach milestone in our semantic search engine development has specific acceptance criteria that must be validated through systematic testing. These checkpoints ensure that each milestone delivers the promised functionality with acceptable quality and performance characteristics before proceeding to the next phase.\n\n**Mental Model: Software Release Gate Reviews**\n\nThink of milestone verification like **gate reviews in aerospace development** — each phase must demonstrate that critical requirements are met before progressing to more complex integration phases. Just as aircraft systems undergo ground testing before flight testing, each search system component must prove its core functionality before integration with other components.\n\n#### Milestone 1: Embedding Index Verification\n\nThe embedding index forms the foundation of semantic search capability. Verification focuses on correctness, performance, and scalability of vector operations.\n\n**Functional Verification Tests**\n\n| Test Category | Test Description | Expected Behavior | Pass Criteria | Failure Investigation |\n|---------------|------------------|-------------------|---------------|----------------------|\n| Index Construction | Build index with 100K documents | Index creates successfully, all documents indexed | 100% success rate, <10 minutes build time | Check memory usage, embedding failures |\n| Similarity Search Accuracy | Query with known similar documents | Returns expected similar documents in top 10 | >90% of expected results in top 10 | Verify vector normalization, distance metrics |\n| Approximate NN Quality | Compare with exact search on 1K subset | Results largely overlap with exact search | >85% overlap in top 20 results | Check HNSW parameters, index corruption |\n| Incremental Updates | Add 10K new documents to existing index | New documents searchable without rebuild | New docs appear in search results within 5 minutes | Verify ID mapping, index synchronization |\n| Index Persistence | Save and reload trained index | Loaded index produces identical results | Exact result reproduction after reload | Check serialization, file corruption |\n\n**Performance Verification Tests**\n\n| Performance Dimension | Test Scenario | Target Performance | Measurement Method | Optimization Actions |\n|----------------------|---------------|-------------------|-------------------|---------------------|\n| Query Latency | Search 1M document index | <150ms P95 latency | Direct timing instrumentation | Tune HNSW ef parameter, optimize hardware |\n| Index Build Time | Construct index from 500K docs | <30 minutes total time | Wall clock measurement | Increase threads, optimize embedding pipeline |\n| Memory Usage | Load 1M document index | <4GB RAM consumption | Process memory monitoring | Adjust quantization, optimize data structures |\n| Concurrent Access | 100 simultaneous searches | No latency degradation | Multi-threaded test harness | Verify thread safety, optimize locks |\n| Index Size Efficiency | Compare index to raw embeddings | <2x raw embedding size | File size comparison | Enable compression, optimize storage format |\n\n**Verification Checkpoint Commands**\n\n```python\n# Core functionality verification\npython -m tests.index_verification --test-suite=functional --docs=100000\npython -m tests.index_verification --test-suite=performance --concurrent-users=100\n\n# Expected output patterns\n# ✓ Index construction: 100000 documents indexed in 8.5 minutes\n# ✓ Search accuracy: 92% top-10 precision on test queries  \n# ✓ Query latency: P95=127ms, P99=245ms\n# ✓ Memory usage: 3.2GB for 1M document index\n```\n\n#### Milestone 2: Query Processing Verification\n\nQuery processing verification ensures that search queries are properly understood, expanded, and converted to effective vector representations.\n\n**Query Understanding Verification**\n\n| Understanding Capability | Test Method | Sample Input | Expected Output | Quality Threshold |\n|-------------------------|-------------|--------------|-----------------|-------------------|\n| Query Normalization | Process diverse text formats | \"Machine-Learning    algorithms!!!\" | \"machine learning algorithms\" | 100% consistent normalization |\n| Entity Recognition | Extract technical terms | \"React useEffect hook performance\" | entities=[\"React\", \"useEffect\"] | >80% entity recognition accuracy |\n| Intent Classification | Categorize query types | \"how to implement OAuth 2.0\" | intent=\"tutorial\", type=\"how-to\" | >75% intent classification accuracy |\n| Synonym Expansion | Expand with related terms | \"JS frameworks\" | expanded=[\"JavaScript\", \"frameworks\", \"libraries\"] | >70% useful expansion terms |\n| Negative Term Handling | Process exclusion queries | \"python -snake\" | negative_terms=[\"snake\"] | 100% negative term extraction |\n\n**Query Processing Quality Tests**\n\n| Quality Dimension | Test Approach | Validation Method | Success Criteria | Debug Steps |\n|------------------|---------------|-------------------|------------------|-------------|\n| Expansion Quality | Manual evaluation of 100 test queries | Expert judgment of expansion relevance | >80% expansions rated helpful or neutral | Check synonym database quality, expansion algorithms |\n| Semantic Preservation | Compare original vs expanded query results | Overlap in top 20 results | >70% result overlap maintained | Verify expansion doesn't dilute original intent |\n| Processing Speed | Time query processing pipeline | End-to-end latency measurement | <50ms P95 processing time | Profile bottlenecks in NLP pipeline |\n| Cache Effectiveness | Monitor cache hit rates | Cache performance metrics | >60% hit rate for repeated queries | Tune cache size, TTL parameters |\n| Multi-Vector Handling | Test complex queries with multiple aspects | Result diversity and coverage | Addresses all query aspects in results | Check vector combination algorithms |\n\n**Verification Checkpoint Commands**\n\n```python\n# Query processing verification\npython -m tests.query_verification --test-suite=understanding --queries=test_queries.json\npython -m tests.query_verification --test-suite=performance --concurrent=50\n\n# Expected output patterns\n# ✓ Entity recognition: 84% accuracy on technical terms\n# ✓ Query expansion: 78% helpful expansions, 18% neutral, 4% harmful  \n# ✓ Processing latency: P95=42ms, cache hit rate=67%\n# ✓ Multi-vector queries: 89% aspect coverage in top 20 results\n```\n\n#### Milestone 3: Ranking and Relevance Verification\n\nRanking verification ensures that the multi-stage ranking pipeline produces high-quality, relevant results that match user expectations.\n\n**Ranking Quality Assessment**\n\n| Ranking Component | Test Method | Quality Metric | Target Performance | Validation Approach |\n|------------------|-------------|----------------|-------------------|-------------------|\n| Semantic Similarity Scoring | Compare with human relevance judgments | NDCG@10 | >0.75 | Expert evaluation on 200 test queries |\n| BM25 Integration | Test hybrid semantic + lexical search | MAP improvement vs semantic-only | >15% improvement | A/B test comparison |\n| Cross-Encoder Reranking | Precision of top 5 results after reranking | Precision@5 | >0.85 | Manual relevance assessment |\n| Personalization Impact | User-specific result customization | Click-through rate improvement | >20% CTR improvement | Simulated user preferences |\n| Freshness Weighting | Boost recent content appropriately | Temporal relevance balance | Recent docs in top 10 for time-sensitive queries | Query categorization and result analysis |\n\n**Multi-Stage Pipeline Verification**\n\n| Pipeline Stage | Input | Processing | Output | Validation Check |\n|----------------|-------|------------|--------|------------------|\n| Candidate Retrieval | Query embedding | Vector similarity search | Top 1000 candidates | Coverage: >95% of relevant docs in candidates |\n| Fast Ranking | 1000 candidates | BM25 + semantic scoring | Top 100 candidates | Speed: <100ms, Quality: reasonable ranking |\n| Cross-Encoder Reranking | Top 100 candidates | Pairwise relevance scoring | Top 20 final results | Quality: >90% improvement in P@5 |\n| Result Formatting | Top 20 results | Snippet generation, highlighting | Formatted responses | User experience: clear, helpful snippets |\n\n**Verification Checkpoint Commands**\n\n```python\n# Ranking verification suite\npython -m tests.ranking_verification --test-suite=quality --eval-set=golden_queries.json\npython -m tests.ranking_verification --test-suite=performance --load-test=true\n\n# Expected output patterns  \n# ✓ Semantic ranking: NDCG@10=0.78, MAP=0.72\n# ✓ Hybrid search: 18% improvement over semantic-only\n# ✓ Cross-encoder: P@5 improved from 0.74 to 0.87\n# ✓ Pipeline latency: P95=340ms (within 500ms target)\n```\n\n#### Milestone 4: Search API and UI Verification\n\nThe final milestone verification ensures that the complete search system provides a production-ready user experience with appropriate error handling and monitoring.\n\n**API Functionality Verification**\n\n| API Feature | Test Scenario | Expected Behavior | Performance Target | Error Handling |\n|-------------|---------------|-------------------|-------------------|----------------|\n| Search Endpoint | POST /search with query parameters | JSON response with ranked results | <500ms P95 response time | Graceful error messages for malformed requests |\n| Autocomplete Endpoint | GET /autocomplete with partial query | Relevant suggestions in <100ms | <100ms P95 response time | Empty suggestions for invalid input |\n| Faceted Search | Include facets=true in search request | Facet counts for result categories | <800ms P95 with facets | Disable facets on timeout |\n| Result Highlighting | Query terms highlighted in snippets | HTML-escaped highlighting markup | No additional latency impact | Plain text fallback if highlighting fails |\n| Pagination Support | Request results with offset/limit | Consistent results across pages | Same performance for reasonable offsets | Error for excessive offset values |\n\n**End-to-End User Experience Tests**\n\n| User Journey | Test Steps | Success Criteria | Performance Expectation | Quality Validation |\n|-------------|------------|-------------------|------------------------|-------------------|\n| Simple Search | Enter query → view results → click result | Relevant results, working links | <500ms search response | >80% top-5 relevance |\n| Query Refinement | Initial search → modify query → compare results | Results improve with specificity | <500ms for refined query | Better results for more specific queries |\n| Autocomplete Flow | Type characters → see suggestions → select suggestion | Helpful suggestions, smooth UX | <100ms suggestion latency | Suggestions lead to good results |\n| Faceted Browsing | Search → apply filters → refine results | Accurate filtering, updated counts | <800ms with facet computation | Filters produce expected subsets |\n| Mobile Experience | Same flows on mobile simulator | Responsive design, touch-friendly | Same performance targets | Readable on small screens |\n\n**Production Readiness Checklist**\n\n| Readiness Category | Verification Items | Status Check | Acceptance Criteria |\n|-------------------|-------------------|--------------|-------------------|\n| Performance SLAs | All response time targets met | Automated load testing | 95% of requests meet SLA under load |\n| Error Handling | Graceful degradation tested | Fault injection testing | System remains available with degraded features |\n| Monitoring | Metrics collection and alerting | Dashboard verification | All key metrics tracked and alerted |\n| Security | Input validation and sanitization | Security testing scan | No vulnerabilities in common attacks |\n| Documentation | API docs and runbooks | Manual review | Complete documentation for operators |\n| Deployment | Automated deployment pipeline | CI/CD verification | Zero-downtime deployments working |\n\n**Verification Checkpoint Commands**\n\n```bash\n# Complete system verification\npython -m tests.integration_verification --test-suite=api --environment=staging\npython -m tests.integration_verification --test-suite=e2e --browser=chrome\n\n# Expected output patterns\n# ✓ Search API: All endpoints responding, P95 latency within targets\n# ✓ Autocomplete: <100ms response time, 85% suggestion quality  \n# ✓ End-to-end: User journeys complete successfully\n# ✓ Production readiness: 18/18 checklist items verified\n```\n\n> **Verification Success Pattern**: Each milestone should demonstrate clear quality progression — Milestone 1 proves the foundation works correctly, Milestone 2 shows intelligent query understanding, Milestone 3 delivers excellent result ranking, and Milestone 4 provides production-ready user experience. Failure at any checkpoint requires fixing before proceeding to the next milestone.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Rationale |\n|-----------|---------------|-----------------|-----------|\n| Test Framework | pytest with fixtures | pytest + hypothesis property testing | pytest provides excellent search-specific fixtures |\n| Load Testing | locust with custom scenarios | k6 with JavaScript scenarios | locust better for Python integration |\n| Metrics Collection | Python logging + JSON | Prometheus + Grafana | JSON logging sufficient for development |\n| Test Data Management | JSON files + Git LFS | Database with versioning | JSON files easier for reproducible tests |\n| Relevance Evaluation | Manual CSV judgments | MLflow experiment tracking | CSV sufficient for initial evaluation |\n| Performance Monitoring | Python time.time() | APM tool (DataDog, New Relic) | Built-in timing for development phase |\n\n#### Recommended Testing Structure\n\n```\ntests/\n├── conftest.py                    ← pytest fixtures and configuration\n├── test_data/                     ← test documents and queries\n│   ├── sample_documents.json      ← 1000 representative documents\n│   ├── test_queries.json          ← 200 test queries with categories\n│   └── relevance_judgments.csv    ← expert relevance ratings\n├── unit/                          ← component unit tests\n│   ├── test_embedding.py          ← document encoding tests\n│   ├── test_index.py              ← vector index tests\n│   ├── test_query_processing.py   ← query understanding tests\n│   └── test_ranking.py            ← ranking algorithm tests\n├── integration/                   ← component integration tests\n│   ├── test_search_pipeline.py    ← end-to-end search flow\n│   ├── test_api_endpoints.py      ← REST API testing\n│   └── test_error_handling.py     ← failure mode testing\n├── performance/                   ← load and performance tests\n│   ├── test_latency.py            ← response time validation\n│   ├── test_throughput.py         ← concurrent user testing\n│   └── load_scenarios.py          ← realistic traffic patterns\n└── quality/                       ← search quality evaluation\n    ├── test_relevance.py          ← offline relevance metrics\n    ├── test_ranking_quality.py    ← ranking effectiveness\n    └── evaluation_framework.py    ← quality measurement tools\n```\n\n#### Complete Test Infrastructure Starter Code\n\n**Test Configuration and Fixtures** (`tests/conftest.py`):\n\n```python\nimport pytest\nimport json\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nimport asyncio\nfrom unittest.mock import Mock\n\nfrom src.models import Document, DocumentEmbedding, QueryRequest\nfrom src.embedding_index import EmbeddingIndex\nfrom src.query_processor import QueryProcessor\nfrom src.ranking_engine import RankingEngine\nfrom src.search_api import SearchAPI\n\n# Test data paths\nTEST_DATA_DIR = Path(__file__).parent / \"test_data\"\nSAMPLE_DOCS_PATH = TEST_DATA_DIR / \"sample_documents.json\"\nTEST_QUERIES_PATH = TEST_DATA_DIR / \"test_queries.json\"\nRELEVANCE_JUDGMENTS_PATH = TEST_DATA_DIR / \"relevance_judgments.csv\"\n\n@pytest.fixture(scope=\"session\")\ndef sample_documents() -> List[Document]:\n    \"\"\"Load sample documents for testing.\"\"\"\n    with open(SAMPLE_DOCS_PATH) as f:\n        docs_data = json.load(f)\n    \n    return [\n        Document(\n            doc_id=doc[\"doc_id\"],\n            title=doc[\"title\"],\n            content=doc[\"content\"],\n            url=doc.get(\"url\"),\n            metadata=doc.get(\"metadata\", {}),\n            created_at=doc.get(\"created_at\")\n        )\n        for doc in docs_data\n    ]\n\n@pytest.fixture(scope=\"session\") \ndef test_queries() -> List[Dict[str, Any]]:\n    \"\"\"Load test queries with categories and metadata.\"\"\"\n    with open(TEST_QUERIES_PATH) as f:\n        return json.load(f)\n\n@pytest.fixture(scope=\"session\")\ndef relevance_judgments() -> pd.DataFrame:\n    \"\"\"Load expert relevance judgments for evaluation.\"\"\"\n    return pd.read_csv(RELEVANCE_JUDGMENTS_PATH)\n\n@pytest.fixture\ndef embedding_index(sample_documents):\n    \"\"\"Create and populate embedding index for testing.\"\"\"\n    index = EmbeddingIndex(model_name=DEFAULT_MODEL)\n    \n    # Add sample documents to index\n    embeddings = []\n    for doc in sample_documents[:100]:  # Subset for faster tests\n        embedding = index.document_encoder.encode_document(doc)\n        embeddings.append(embedding)\n    \n    index.build_index(embeddings)\n    return index\n\n@pytest.fixture\ndef query_processor():\n    \"\"\"Create configured query processor.\"\"\"\n    return QueryProcessor(\n        embedding_model=DEFAULT_MODEL,\n        enable_expansion=True,\n        enable_caching=True\n    )\n\n@pytest.fixture\ndef search_system(embedding_index, query_processor):\n    \"\"\"Complete search system for integration testing.\"\"\"\n    ranking_engine = RankingEngine()\n    search_api = SearchAPI(\n        embedding_index=embedding_index,\n        query_processor=query_processor,\n        ranking_engine=ranking_engine\n    )\n    return search_api\n\n@pytest.fixture\ndef performance_timer():\n    \"\"\"Utility for measuring operation timing.\"\"\"\n    class Timer:\n        def __init__(self):\n            self.times = []\n        \n        def time_operation(self, func, *args, **kwargs):\n            start = time.time()\n            result = func(*args, **kwargs)\n            end = time.time()\n            elapsed = (end - start) * 1000  # Convert to milliseconds\n            self.times.append(elapsed)\n            return result, elapsed\n        \n        def get_percentile(self, p):\n            return np.percentile(self.times, p)\n    \n    return Timer()\n```\n\n**Search Quality Evaluation Framework** (`tests/quality/evaluation_framework.py`):\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Dict, Any, Tuple\nfrom dataclasses import dataclass\nfrom collections import defaultdict\nimport logging\n\n@dataclass\nclass EvaluationMetrics:\n    \"\"\"Container for search quality metrics.\"\"\"\n    precision_at_k: Dict[int, float]\n    recall_at_k: Dict[int, float] \n    map_score: float\n    ndcg_at_k: Dict[int, float]\n    mrr_score: float\n    err_score: float\n\nclass SearchQualityEvaluator:\n    \"\"\"Comprehensive search quality evaluation framework.\"\"\"\n    \n    def __init__(self, relevance_judgments: pd.DataFrame):\n        self.judgments = relevance_judgments\n        self.query_relevance = self._build_relevance_map()\n    \n    def _build_relevance_map(self) -> Dict[str, Dict[str, int]]:\n        \"\"\"Build query -> doc_id -> relevance mapping.\"\"\"\n        relevance_map = defaultdict(dict)\n        \n        for _, row in self.judgments.iterrows():\n            query = row['query']\n            doc_id = row['doc_id'] \n            relevance = row['relevance_grade']\n            relevance_map[query][doc_id] = relevance\n        \n        return dict(relevance_map)\n    \n    def evaluate_search_results(\n        self, \n        query: str, \n        result_doc_ids: List[str],\n        k_values: List[int] = [5, 10, 20]\n    ) -> EvaluationMetrics:\n        \"\"\"Evaluate search results against ground truth judgments.\"\"\"\n        \n        if query not in self.query_relevance:\n            logging.warning(f\"No judgments available for query: {query}\")\n            return self._empty_metrics(k_values)\n        \n        relevance_scores = []\n        binary_relevance = []\n        \n        for doc_id in result_doc_ids:\n            relevance = self.query_relevance[query].get(doc_id, 0)\n            relevance_scores.append(relevance)\n            binary_relevance.append(1 if relevance > 0 else 0)\n        \n        total_relevant = sum(1 for rel in self.query_relevance[query].values() if rel > 0)\n        \n        # Calculate metrics\n        precision_at_k = {}\n        recall_at_k = {}\n        ndcg_at_k = {}\n        \n        for k in k_values:\n            # TODO: Calculate precision@k: relevant results in top k / k\n            # TODO: Calculate recall@k: relevant results in top k / total relevant\n            # TODO: Calculate NDCG@k using graded relevance scores\n            pass\n        \n        # TODO: Calculate MAP (Mean Average Precision)\n        map_score = 0.0\n        \n        # TODO: Calculate MRR (Mean Reciprocal Rank)\n        mrr_score = 0.0\n        \n        # TODO: Calculate ERR (Expected Reciprocal Rank)\n        err_score = 0.0\n        \n        return EvaluationMetrics(\n            precision_at_k=precision_at_k,\n            recall_at_k=recall_at_k,\n            map_score=map_score,\n            ndcg_at_k=ndcg_at_k,\n            mrr_score=mrr_score,\n            err_score=err_score\n        )\n    \n    def calculate_precision_at_k(self, binary_relevance: List[int], k: int) -> float:\n        \"\"\"Calculate precision@k metric.\"\"\"\n        # TODO: Implement precision@k calculation\n        # Hint: relevant results in top k divided by k\n        pass\n    \n    def calculate_dcg(self, relevance_scores: List[int], k: int) -> float:\n        \"\"\"Calculate Discounted Cumulative Gain.\"\"\"\n        # TODO: Implement DCG calculation \n        # Formula: sum(rel_i / log2(i+1)) for i in range(min(k, len(relevance_scores)))\n        pass\n    \n    def calculate_ndcg(self, relevance_scores: List[int], k: int) -> float:\n        \"\"\"Calculate Normalized Discounted Cumulative Gain.\"\"\"\n        # TODO: Calculate NDCG = DCG@k / IDCG@k\n        # IDCG is DCG of perfect ranking (sorted by relevance)\n        pass\n```\n\n**Performance Testing Infrastructure** (`tests/performance/load_testing.py`):\n\n```python\nimport asyncio\nimport aiohttp\nimport time\nimport statistics\nfrom typing import List, Dict, Any, Callable\nfrom dataclasses import dataclass\nfrom concurrent.futures import ThreadPoolExecutor\nimport random\nimport json\n\n@dataclass \nclass LoadTestResult:\n    \"\"\"Results from load testing execution.\"\"\"\n    total_requests: int\n    successful_requests: int\n    failed_requests: int\n    avg_response_time: float\n    p50_response_time: float\n    p95_response_time: float\n    p99_response_time: float\n    requests_per_second: float\n    error_rate: float\n\nclass SearchLoadTester:\n    \"\"\"Load testing framework for search API.\"\"\"\n    \n    def __init__(self, base_url: str, test_queries: List[str]):\n        self.base_url = base_url\n        self.test_queries = test_queries\n        self.results = []\n    \n    async def execute_search_request(self, session: aiohttp.ClientSession, query: str) -> Tuple[float, bool]:\n        \"\"\"Execute single search request and measure timing.\"\"\"\n        start_time = time.time()\n        \n        try:\n            # TODO: Make POST request to /search endpoint with query\n            # TODO: Validate response has expected structure\n            # TODO: Return (response_time_ms, success_boolean)\n            pass\n            \n        except Exception as e:\n            end_time = time.time()\n            response_time = (end_time - start_time) * 1000\n            return response_time, False\n    \n    async def run_concurrent_load_test(\n        self,\n        concurrent_users: int,\n        duration_seconds: int,\n        query_pattern: str = \"random\"\n    ) -> LoadTestResult:\n        \"\"\"Run load test with specified concurrency.\"\"\"\n        \n        # TODO: Create aiohttp ClientSession\n        # TODO: Launch concurrent_users number of worker tasks\n        # TODO: Each worker makes requests for duration_seconds\n        # TODO: Collect timing and success/failure data\n        # TODO: Calculate and return LoadTestResult metrics\n        pass\n    \n    def simulate_realistic_user_behavior(self, session: aiohttp.ClientSession) -> List[Tuple[float, bool]]:\n        \"\"\"Simulate realistic user search patterns.\"\"\"\n        # TODO: Implement realistic user session:\n        # 1. Start with broad query\n        # 2. Refine query based on results  \n        # 3. Maybe try autocomplete\n        # 4. Click on result (simulate)\n        # 5. Possible follow-up search\n        pass\n    \n    def generate_traffic_spike(\n        self, \n        baseline_qps: int, \n        spike_multiplier: float, \n        spike_duration: int\n    ) -> LoadTestResult:\n        \"\"\"Test system behavior under traffic spikes.\"\"\"\n        # TODO: Generate baseline traffic for warmup\n        # TODO: Spike traffic to baseline_qps * spike_multiplier\n        # TODO: Return to baseline\n        # TODO: Measure performance degradation during spike\n        pass\n```\n\n#### Milestone Verification Scripts\n\n**Milestone 1 Index Verification** (`tests/integration/test_milestone1.py`):\n\n```python\nimport pytest\nimport time\nimport numpy as np\nfrom src.embedding_index import EmbeddingIndex\nfrom src.models import Document, DEFAULT_MODEL\n\nclass TestMilestone1Verification:\n    \"\"\"Verification tests for Milestone 1: Embedding Index.\"\"\"\n    \n    def test_index_construction_scalability(self, sample_documents):\n        \"\"\"Verify index can handle large document volumes.\"\"\"\n        index = EmbeddingIndex(model_name=DEFAULT_MODEL)\n        \n        # TODO: Test with increasing document counts: 1K, 10K, 100K\n        # TODO: Measure build time and memory usage at each scale\n        # TODO: Verify build time grows sub-linearly with document count\n        # TODO: Assert memory usage remains within acceptable bounds\n        \n        assert True  # Replace with actual assertions\n    \n    def test_similarity_search_accuracy(self, embedding_index, test_queries):\n        \"\"\"Verify search results match expected similarity patterns.\"\"\"\n        \n        for query_data in test_queries[:10]:  # Test subset\n            query_text = query_data[\"query\"]\n            expected_docs = query_data.get(\"expected_similar_docs\", [])\n            \n            # TODO: Execute similarity search for query\n            # TODO: Check if expected documents appear in top 20 results\n            # TODO: Verify similarity scores are reasonable (> 0.5 for relevant docs)\n            # TODO: Assert approximate nearest neighbor quality vs exact search\n            \n            pass\n    \n    def test_incremental_index_updates(self, embedding_index):\n        \"\"\"Verify new documents can be added without full rebuild.\"\"\"\n        initial_size = embedding_index.get_document_count()\n        \n        # TODO: Add batch of new documents to existing index\n        # TODO: Verify new documents are immediately searchable\n        # TODO: Verify existing search results unchanged\n        # TODO: Assert update time is much faster than full rebuild\n        \n        pass\n    \n    def test_index_persistence_correctness(self, embedding_index, tmp_path):\n        \"\"\"Verify index can be saved and loaded correctly.\"\"\"\n        \n        # TODO: Save index to temporary directory\n        # TODO: Load index from saved state\n        # TODO: Compare search results before and after save/load\n        # TODO: Assert exact result reproduction after persistence\n        \n        pass\n```\n\n#### Debugging and Troubleshooting Guide\n\n**Common Testing Issues and Solutions**\n\n| Symptom | Likely Cause | Diagnostic Steps | Fix |\n|---------|-------------|------------------|-----|\n| Search quality tests fail | Poor test query selection | Check query-document relevance overlap | Use domain-expert created test queries |\n| Load tests show high variance | Inconsistent test environment | Monitor CPU, memory during tests | Use dedicated test infrastructure |\n| Relevance metrics unrealistically low | Judgment-result mismatch | Verify judgment format matches results | Align document ID formats |\n| Performance tests fail intermittently | Resource contention | Check for background processes | Isolate test environment |\n| Index accuracy tests inconsistent | Vector normalization issues | Check embedding unit lengths | Ensure cosine similarity normalization |\n| Memory usage grows during long tests | Memory leaks in test code | Profile memory usage over time | Clear caches between test runs |\n\nThis comprehensive testing strategy ensures that each milestone delivers production-ready functionality with measurable quality and performance characteristics, providing confidence for system deployment and user satisfaction.\n\n\n## Debugging Guide\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), establishing comprehensive debugging strategies that help identify and resolve issues encountered during implementation of embedding indices (Milestone 1), query processing (Milestone 2), ranking systems (Milestone 3), and search APIs (Milestone 4).\n\nThink of debugging a semantic search engine like being a medical diagnostician examining a complex patient with multiple interconnected organ systems. Just as a doctor uses systematic symptom analysis, diagnostic tests, and treatment protocols to identify and resolve health issues, debugging our search engine requires methodical investigation of symptoms, understanding root causes, and applying targeted fixes. Each component—the embedding index, query processor, ranking engine, and search API—can exhibit distinct failure patterns, but problems often cascade across component boundaries, making systematic diagnosis essential for maintaining search quality and performance.\n\nThe debugging process for semantic search systems presents unique challenges compared to traditional software debugging. Unlike deterministic systems where identical inputs always produce identical outputs, semantic search involves probabilistic components like neural embedding models, approximate nearest neighbor algorithms, and learned ranking functions. This probabilistic nature means that \"correct\" behavior exists on a spectrum rather than as binary right-or-wrong states, making it crucial to understand expected ranges of behavior and develop debugging techniques that account for statistical variation.\n\nOur debugging strategy follows a structured approach that moves from surface symptoms to root causes, then to verification of fixes. Each subsection provides comprehensive symptom-cause-fix mappings organized by component area, enabling rapid identification of issues during development and production operation. The debugging techniques presented here assume you have implemented comprehensive logging and monitoring as described in the Error Handling and Edge Cases section, providing the observability foundation necessary for effective diagnosis.\n\n> **Key Debugging Principle**: Always verify your assumptions with data. Semantic search systems often fail in subtle ways where components appear to work correctly in isolation but produce poor results when integrated. Use quantitative metrics, not intuition, to validate that fixes actually improve behavior.\n\n### Embedding and Index Issues\n\nThe embedding and index layer forms the foundation of semantic search, and problems here cascade through every other component. Think of this layer as the nervous system of your search engine—when embeddings misrepresent meaning or indices fail to find similar vectors, the entire system loses its ability to understand and match semantic intent. Debugging embedding and index issues requires understanding both the mathematical properties of vector spaces and the operational characteristics of approximate nearest neighbor algorithms.\n\n#### Vector Dimension Mismatches\n\nVector dimension mismatches represent one of the most common and immediately fatal errors in semantic search systems. These issues typically manifest during system integration when different components expect vectors of different dimensionalities, or when upgrading embedding models without properly migrating existing indices.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| `ValueError: shapes (1,384) and (1,512) not aligned` during similarity calculation | Mixing embeddings from different models (e.g., `all-MiniLM-L6-v2` with `all-mpnet-base-v2`) | Check `DocumentEncoder.embedding_dim` and `ProcessedQuery.primary_embedding.shape[0]` | Rebuild index with consistent model or implement model migration |\n| FAISS index throws `AssertionError: d == index.d` when adding vectors | Attempting to add vectors with wrong dimension to existing index | Log `embedding.shape` before `index.add()` call, compare with index dimension | Recreate index with correct dimension or fix embedding generation |\n| Search returns empty results despite having indexed documents | Query embedding dimension differs from document embedding dimension | Compare `encode_query()` output shape with `DocumentEmbedding.embedding_dim` | Ensure query and document use same `DocumentEncoder` instance |\n| Index loading fails with cryptic FAISS errors | Saved index expects different dimension than current model | Check saved index metadata against current `DEFAULT_MODEL` configuration | Either revert to original model or rebuild index from scratch |\n\n⚠️ **Pitfall: Silent Dimension Mismatches**\nPython's NumPy broadcasting can sometimes hide dimension mismatches by automatically reshaping arrays, leading to incorrect similarity calculations that produce seemingly valid but meaningless results. Always validate embedding dimensions explicitly rather than relying on implicit broadcasting.\n\nThe most insidious dimension mismatch occurs during model upgrades. Consider this scenario: you start with `all-MiniLM-L6-v2` producing 384-dimensional embeddings, build a substantial index, then decide to upgrade to `all-mpnet-base-v2` for better quality. Simply changing the model configuration will cause new queries to generate 768-dimensional embeddings that cannot be compared against the existing 384-dimensional document embeddings in your index.\n\n> **Design Insight**: Always store embedding model metadata alongside the index itself. The `DocumentEmbedding.model_name` and `DocumentEmbedding.embedding_dim` fields should be persisted with the index and validated on loading to catch model configuration drift early.\n\n**Model Migration Strategy**: When upgrading embedding models, implement a gradual migration process rather than rebuilding everything at once:\n\n1. Deploy the new model alongside the old model, maintaining both indices\n2. Route a small percentage of traffic to the new model to validate quality\n3. Gradually increase traffic to the new model while monitoring relevance metrics\n4. Once confident in the new model, begin background reprocessing of documents\n5. Switch fully to the new model and retire the old index\n\n#### Vector Normalization Problems\n\nVector normalization issues create subtle but significant problems in semantic search systems. Unlike dimension mismatches which fail loudly, normalization problems often manifest as poor search quality that's difficult to diagnose because the system appears to function correctly at a surface level.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| Cosine similarity scores always near zero despite relevant results | Vectors not normalized to unit length before similarity calculation | Check `np.linalg.norm()` of sample embeddings - should be 1.0 | Apply `normalize_vector()` before storing and searching |\n| Search results heavily biased toward longer documents | Using dot product instead of cosine similarity with unnormalized vectors | Compare similarity scores between short and long documents for same query | Switch to cosine similarity with proper normalization |\n| Inconsistent similarity scores for identical content | Some vectors normalized, others not, creating mixed index | Audit normalization in embedding pipeline - check `DocumentEmbedding` storage | Rebuild index with consistent normalization policy |\n| FAISS inner product search returns unexpected ranking | Inner product assumes normalized vectors but vectors aren't normalized | Verify normalization before `IndexFlatIP.add()` calls | Either normalize vectors or switch to `IndexFlatL2` |\n\nThe mathematical foundation of this issue lies in the difference between dot product and cosine similarity. Dot product between vectors `u` and `v` is `u·v = ||u|| ||v|| cos(θ)`, while cosine similarity is `cos(θ) = (u·v)/(||u|| ||v||)`. When vectors aren't normalized (i.e., `||u|| ≠ 1`), dot product conflates both the angle between vectors (semantic similarity) and their magnitudes (often related to document length or embedding generation artifacts).\n\n> **Critical Implementation Detail**: FAISS's `IndexFlatIP` (inner product) assumes normalized vectors to compute cosine similarity efficiently. If you use `IndexFlatIP` with unnormalized vectors, you're actually computing dot product, which will bias results toward longer documents or vectors with higher magnitudes.\n\n**Normalization Verification Process**: During development, implement systematic normalization checks:\n\n1. After embedding generation, assert that `np.abs(np.linalg.norm(embedding) - 1.0) < 1e-6`\n2. Before adding to index, sample random vectors and verify unit length\n3. During search, log normalization status of query embeddings\n4. Implement health checks that periodically sample indexed vectors and verify normalization\n\n⚠️ **Pitfall: Selective Normalization**\nNever normalize only queries or only documents—this destroys the mathematical relationship needed for meaningful similarity calculation. Either normalize both or normalize neither, depending on whether you want cosine similarity or raw dot product.\n\n#### Index Corruption and Recovery\n\nIndex corruption represents the most severe embedding layer failure mode, potentially requiring complete index reconstruction. Think of index corruption like database corruption—the underlying data structure becomes inconsistent, leading to crashes, incorrect results, or performance degradation. Unlike database corruption which often has sophisticated recovery mechanisms, vector index corruption typically requires rebuilding from source data.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| FAISS throws segmentation faults during search | Binary index file corruption from incomplete writes or disk errors | Check index file size consistency, validate with `faiss.read_index()` | Restore from backup or rebuild from document embeddings |\n| Search returns inconsistent results for identical queries | Partial index corruption affecting specific vector regions | Run identical queries multiple times, check for result variance | Identify corrupted region and rebuild affected partitions |\n| Index loading extremely slow or fails with memory errors | Index file format corruption or version mismatch | Compare file headers, check FAISS version compatibility | Rebuild index with current FAISS version |\n| Search performance suddenly degrades after index update | Incremental updates corrupted index structure | Benchmark search latency over time, correlate with update events | Disable incremental updates, schedule full rebuild |\n\nIndex corruption typically occurs during one of several vulnerable operations:\n\n1. **Incremental Updates**: Adding vectors to trained indices like IVF can sometimes corrupt internal data structures, especially under concurrent access\n2. **Incomplete Persistence**: Process crashes or disk full conditions during index saving can leave partially written files\n3. **Memory Mapping Issues**: Using memory-mapped indices with insufficient virtual memory can cause corruption on access\n4. **Version Incompatibility**: Loading indices created with different FAISS versions may fail or produce incorrect results\n\n> **Recovery Strategy**: Always maintain multiple generations of index backups. Keep the last three successful index builds with their corresponding document embedding caches. This allows you to roll back to a known-good state while investigating corruption causes.\n\n**Corruption Prevention Measures**:\n\n1. **Atomic Index Updates**: Write new indices to temporary files and atomically rename them to replace old indices\n2. **Checksum Validation**: Store and verify checksums for index files to detect corruption early\n3. **Graceful Degradation**: Design your system to fall back to previous index versions when corruption is detected\n4. **Separate Training and Search Indices**: Use read-only indices for search while building updates separately\n\n**Index Health Monitoring**: Implement regular health checks that verify index integrity:\n\n```python\ndef validate_index_health(index_path: str, sample_size: int = 1000) -> bool:\n    \"\"\"Validate index integrity by performing sample searches.\"\"\"\n    # Check file integrity\n    if not verify_index_checksum(index_path):\n        return False\n    \n    # Load index and verify basic properties\n    index = faiss.read_index(index_path)\n    if index.ntotal == 0:\n        return False\n    \n    # Perform sample searches to detect corruption\n    for _ in range(sample_size):\n        query_vector = generate_random_query()\n        try:\n            scores, indices = index.search(query_vector, k=10)\n            if len(indices[0]) == 0:\n                return False\n        except Exception:\n            return False\n    \n    return True\n```\n\n⚠️ **Pitfall: Ignoring Soft Corruption**\nIndex corruption doesn't always manifest as crashes. Sometimes indices become subtly corrupted, returning plausible but incorrect results. Implement regression tests with known query-result pairs to catch soft corruption.\n\n### Search Relevance Problems\n\nSearch relevance problems represent the most challenging debugging category because they involve subjective quality judgments rather than objective correctness. Think of relevance debugging like wine tasting—you need trained palates (evaluation datasets), systematic methodology (relevance metrics), and understanding of complex interactions between multiple factors (ranking signals, query processing, personalization). Unlike crashes or performance issues which have clear failure indicators, relevance problems require careful measurement and analysis to identify root causes.\n\nThe complexity of relevance debugging stems from the multi-layered nature of semantic search systems. A poor search result might be caused by inadequate document embeddings, failed query expansion, incorrect signal weighting in the ranking engine, or cascading effects from multiple components. Effective relevance debugging requires isolating each component's contribution to the final result and understanding how they interact.\n\n#### Poor Result Quality\n\nPoor result quality manifests as high-level symptoms that users notice directly—irrelevant results appearing in top positions, relevant results missing entirely, or inconsistent quality across different query types. These symptoms often have multiple contributing factors, making systematic analysis essential for identifying the primary causes.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| Relevant documents consistently missing from top-10 results | Embedding model doesn't understand domain-specific terminology | Test queries with domain-specific terms, check if embeddings cluster appropriately | Fine-tune embedding model or use domain-specific pre-trained model |\n| Results quality varies dramatically across query types | Query processing treats all queries identically despite different intents | Analyze query distribution by intent, measure precision@k by query type | Implement intent-specific processing in `QueryProcessor` |\n| Search returns syntactically similar but semantically irrelevant results | Over-reliance on lexical matching without semantic understanding | Compare BM25-only vs. semantic-only results for sample queries | Rebalance hybrid search weights in `combine_signals()` |\n| Recently relevant results no longer appear after system updates | Embedding model changed without reprocessing existing documents | Compare embedding similarities before/after model updates | Implement embedding version tracking and migration |\n\nThe most common cause of poor result quality is **vocabulary mismatch** between the embedding model's training data and your search domain. Pre-trained models like `all-MiniLM-L6-v2` perform well on general text but may struggle with specialized terminology in fields like medicine, law, or engineering. This manifests as embeddings that cluster unrelated documents with similar surface-level language while separating conceptually related documents that use different terminology.\n\n> **Quality Diagnosis Framework**: For any relevance complaint, first isolate whether the problem lies in retrieval (finding candidate documents) or ranking (ordering retrieved candidates). Run the query against your index to retrieve top-100 candidates, then manually assess whether the desired result appears anywhere in those candidates.\n\n**Systematic Quality Analysis Process**:\n\n1. **Component Isolation**: Test each component independently:\n   - Run semantic search only (no BM25, no personalization)\n   - Run lexical search only (BM25 without semantic signals)\n   - Test query processing with simple, unambiguous queries\n   - Verify ranking with manually curated candidate sets\n\n2. **Ground Truth Validation**: Establish objective quality baselines:\n   - Create evaluation datasets with expert-judged query-document pairs\n   - Measure precision@k, recall@k, and NDCG across query categories\n   - Track quality metrics over time to detect regressions\n\n3. **Error Case Analysis**: Systematically analyze failed cases:\n   - Collect queries that return zero relevant results in top-10\n   - Identify patterns in failed queries (length, complexity, domain)\n   - Analyze embedding similarities for failed query-document pairs\n\n⚠️ **Pitfall: Anecdotal Quality Assessment**\nNever base quality judgments on individual examples or personal opinions. What seems \"obviously relevant\" to one person may not be relevant to users with different contexts or needs. Always use multiple human judges and quantitative metrics.\n\n#### Ranking Issues and Score Calibration\n\nRanking problems occur when the multi-stage ranking pipeline produces scores that don't align with human relevance judgments. These issues are particularly subtle because the individual ranking signals (semantic similarity, BM25, personalization, freshness) might each be working correctly, but their combination produces suboptimal ordering.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| Semantic scores dominate other signals regardless of query type | Poor signal weight calibration in `combine_signals()` | Log individual signal values vs. combined scores for sample queries | Retune signal weights using learning-to-rank on labeled data |\n| Recent documents always rank higher than more relevant older documents | Freshness decay function too aggressive | Compare ranking with/without freshness signals, analyze optimal document age | Adjust freshness decay parameters or make query-type dependent |\n| Personalization creates filter bubbles, missing broadly relevant results | Personalization signal weight too high | Measure result diversity across different user contexts | Implement diversity constraints or reduce personalization weight |\n| Cross-encoder reranking contradicts semantic retrieval frequently | Cross-encoder and embedding model trained on different data | Compare cross-encoder scores with semantic similarity for same pairs | Use consistent training data or implement score calibration |\n\nScore calibration represents one of the most technically challenging aspects of relevance debugging. Each ranking signal operates on different scales and distributions:\n\n- **Semantic similarity**: Typically ranges from 0.0 to 1.0 with concentration around 0.3-0.7\n- **BM25 scores**: Unbounded positive values with high variance depending on document length and term frequency\n- **Personalization scores**: Often binary or categorical based on user attributes\n- **Freshness scores**: Exponential decay functions with parameters that dramatically affect score ranges\n\n> **Signal Calibration Strategy**: Convert all ranking signals to percentile ranks within their expected distributions rather than using raw scores. This ensures that each signal contributes proportionally to the final ranking regardless of its natural scale.\n\n**Multi-Stage Ranking Debug Process**:\n\n1. **Stage-by-Stage Analysis**: Debug each ranking stage independently\n   - Verify candidate retrieval finds relevant documents in top-100\n   - Analyze signal computation for individual query-document pairs\n   - Test cross-encoder reranking on manually selected candidates\n   - Measure correlation between individual signals and human judgments\n\n2. **Score Distribution Analysis**: Understand how scores behave across your data\n   - Plot histograms of each ranking signal across your document collection\n   - Identify outliers and understand their causes\n   - Measure correlation between different signals to detect redundancy\n   - Track score distributions over time to detect drift\n\n3. **A/B Testing for Ranking Changes**: Never deploy ranking changes without measurement\n   - Implement side-by-side ranking comparison tools\n   - Use interleaved evaluation to measure relative ranking quality\n   - Track click-through rates and user engagement metrics\n   - Maintain champion/challenger testing framework for ranking experiments\n\n⚠️ **Pitfall: Local Ranking Optimization**\nOptimizing ranking for specific query examples often hurts overall system quality by overfitting to unrepresentative cases. Always validate ranking changes against comprehensive evaluation datasets covering diverse query types and user contexts.\n\n**Learning from Click-Through Data**: When users interact with search results, their behavior provides valuable signals about ranking quality:\n\n1. **Position Bias Correction**: Users are more likely to click higher-ranked results regardless of relevance\n2. **Dwell Time Analysis**: Time spent on clicked results indicates satisfaction better than click-through rate alone\n3. **Skip Analysis**: When users click result #5 but skip results #1-4, it suggests ranking problems\n4. **Query Reformulation**: Immediate query changes after seeing results indicate initial ranking failure\n\n### Performance and Latency Issues\n\nPerformance and latency problems in semantic search systems present unique debugging challenges because they involve the interaction between computationally expensive operations (neural network inference, high-dimensional vector search) and real-time user expectations. Think of performance debugging like optimizing a complex manufacturing pipeline—you need to identify bottlenecks, understand capacity constraints, and balance quality against speed while maintaining consistent throughput under varying load conditions.\n\nThe performance characteristics of semantic search differ significantly from traditional database systems. While database queries have relatively predictable performance based on data size and index structure, semantic search involves probabilistic algorithms (approximate nearest neighbor search), neural network inference with variable computational complexity, and multi-stage processing pipelines where each stage has different performance characteristics and failure modes.\n\n> **Performance Debugging Philosophy**: Always measure before optimizing. Semantic search systems have many potential bottlenecks—embedding generation, vector index search, cross-encoder reranking, result formatting—and intuition about which component is slowest is often wrong. Use detailed timing instrumentation to identify actual bottlenecks.\n\n#### Slow Search Responses\n\nSlow search responses represent the most visible performance problem, directly impacting user experience and system scalability. Search latency is particularly challenging to debug because it involves multiple components with different performance characteristics, and the bottleneck can shift based on query characteristics, system load, and data size.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| Search latency exceeds 500ms consistently | Query embedding generation taking too long | Profile `encode_query()` execution time vs. vector search time | Cache frequent query embeddings or use smaller/faster embedding model |\n| Latency highly variable (50ms to 2000ms) for similar queries | Cross-encoder reranking not properly batched | Measure cross-encoder inference time vs. batch size | Implement proper batching or reduce cross-encoder candidate count |\n| Performance degrades significantly with index size | Using brute-force search instead of approximate algorithms | Compare search time growth with document count | Implement HNSW or IVF indexing for large document collections |\n| Concurrent searches cause timeout cascades | Embedding model inference not thread-safe or resource-constrained | Load test with multiple concurrent queries, monitor CPU/GPU utilization | Implement proper model sharing or request queuing |\n\nThe query processing pipeline has several stages with different performance characteristics:\n\n1. **Query Understanding** (1-5ms): Text normalization, entity extraction, query expansion\n2. **Embedding Generation** (10-100ms): Neural network inference to convert query to vector\n3. **Vector Search** (1-50ms): Approximate nearest neighbor search through index\n4. **Initial Ranking** (5-20ms): Computing and combining ranking signals\n5. **Cross-Encoder Reranking** (50-500ms): Precise but expensive pairwise scoring\n6. **Result Formatting** (1-10ms): Snippet generation and highlighting\n\n> **Latency Budget Allocation**: Establish time budgets for each processing stage and implement timeout mechanisms. For a 500ms total latency target, a reasonable allocation might be: embedding (100ms), search (50ms), initial ranking (50ms), reranking (250ms), formatting (50ms).\n\n**Performance Profiling Strategy**:\n\n1. **Component-Level Timing**: Instrument each major component with detailed timing\n2. **Request Tracing**: Use correlation IDs to track individual requests through the pipeline\n3. **Resource Utilization Monitoring**: Track CPU, memory, and I/O usage during different operations\n4. **Latency Distribution Analysis**: Monitor P50, P95, P99 latencies, not just averages\n\n⚠️ **Pitfall: Average Latency Optimization**\nOptimizing for average latency often ignores tail latency (P95, P99) which disproportionately affects user experience. A system with 100ms average latency but 5-second P99 latency will feel slow to users.\n\n**Common Performance Bottlenecks and Solutions**:\n\n| Component | Bottleneck | Solution |\n|-----------|------------|----------|\n| Query Embedding | Model inference on CPU | Move to GPU or use quantized models |\n| Vector Search | Linear scan through large index | Implement HNSW or IVF approximate search |\n| Cross-Encoder | Individual inference calls | Batch multiple candidates together |\n| Result Formatting | Regex-heavy text highlighting | Pre-compute highlights or use efficient string algorithms |\n\n#### Memory Usage Problems\n\nMemory usage problems in semantic search systems stem from the high-dimensional nature of vector embeddings and the need to maintain large indices in memory for fast search. Unlike traditional search systems where memory usage grows roughly linearly with document count, semantic search memory usage depends on embedding dimensionality, index algorithm parameters, and caching strategies, creating complex memory management challenges.\n\n| Symptom | Root Cause | Diagnostic Steps | Fix |\n|---------|------------|------------------|-----|\n| Out-of-memory errors during index construction | HNSW index with excessive `M` parameter creating too many connections | Monitor memory growth during index build, calculate theoretical memory usage | Reduce HNSW `M` parameter or switch to IVF indexing |\n| Memory usage grows continuously during operation | Embedding cache without proper eviction policy | Monitor cache size growth over time, check `EmbeddingCache` statistics | Implement LRU eviction with memory-based limits |\n| System becomes unresponsive under memory pressure | Index larger than available RAM causing swap thrashing | Monitor swap usage and page fault rates during searches | Implement memory-mapped indices or distributed search |\n| Memory spikes during concurrent searches | Multiple threads loading large models simultaneously | Profile memory usage during concurrent operations | Implement proper model sharing and resource pooling |\n\n**Memory Usage Analysis Framework**:\n\nUnderstanding memory consumption requires analyzing several distinct categories:\n\n1. **Base Index Memory**: Core vector storage and index structure\n   - HNSW: ~(embedding_dim × 4 bytes + M × connections × 8 bytes) per vector  \n   - IVF: ~(embedding_dim × 4 bytes) per vector plus centroid storage\n   - Flat: ~(embedding_dim × 4 bytes) per vector\n\n2. **Model Memory**: Embedding model parameters and inference caches\n   - Transformer models: 100MB-1GB depending on model size\n   - Model inference caches: Variable based on batch size and sequence length\n\n3. **Query Processing Memory**: Temporary allocations during search\n   - Query embeddings, expanded term lists, candidate rankings\n   - Cross-encoder intermediate computations\n\n4. **Application Caches**: Performance optimization caches\n   - Query embedding cache, BM25 score cache, personalization caches\n\n> **Memory Management Strategy**: Design your system to gracefully degrade under memory pressure rather than crashing. Implement cache eviction policies, fall back to smaller models, or reduce result quality (fewer cross-encoder candidates) when memory becomes constrained.\n\n**Memory-Mapped Index Strategy**: For large document collections that exceed available RAM, implement memory-mapped indices that allow the operating system to manage virtual memory:\n\n```python\nclass MemoryMappedIndex:\n    def __init__(self, index_path: str, mmap_mode: str = 'r'):\n        \"\"\"Load index with memory mapping for large datasets.\"\"\"\n        self.index_path = index_path\n        self.mmap_mode = mmap_mode\n        \n    def search(self, query_embedding: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Search with automatic memory management.\"\"\"\n        # Use memory mapping to avoid loading entire index into RAM\n        with open(self.index_path, 'rb') as f:\n            index_data = np.memmap(f, dtype=np.float32, mode=self.mmap_mode)\n            # Perform search with memory-mapped data\n            return self._search_memmap(index_data, query_embedding, k)\n```\n\n⚠️ **Pitfall: Memory Fragmentation**\nFrequent allocation and deallocation of large vectors can cause memory fragmentation, leading to out-of-memory errors even when sufficient total memory is available. Use object pools for frequently allocated objects like embeddings and search results.\n\n**Monitoring and Alerting for Memory Issues**:\n\n1. **Memory Usage Tracking**: Monitor memory usage at component granularity\n2. **Cache Hit Rate Monitoring**: Track cache effectiveness to justify memory usage\n3. **Memory Pressure Detection**: Alert when memory usage exceeds safe thresholds\n4. **Graceful Degradation Triggers**: Automatically reduce functionality under memory pressure\n\n### Implementation Guidance\n\nThe debugging techniques described above require systematic instrumentation and monitoring infrastructure to be effective in practice. This implementation guidance provides complete, production-ready debugging tools that complement the conceptual debugging frameworks.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Logging Framework | Python `logging` with structured JSON | ELK Stack (Elasticsearch, Logstash, Kibana) |\n| Performance Monitoring | Manual timing with `time.perf_counter()` | Datadog, New Relic, or Prometheus |\n| Error Tracking | Simple error logging | Sentry for error aggregation and alerting |\n| Memory Profiling | `psutil` for basic memory monitoring | `memory_profiler` or `pympler` for detailed analysis |\n| Request Tracing | UUID correlation IDs | OpenTelemetry for distributed tracing |\n\n#### Debugging Infrastructure Code\n\n**Complete Performance Profiler**: This profiler provides detailed timing information for each component in the search pipeline:\n\n```python\nimport time\nimport functools\nimport logging\nfrom typing import Dict, List, Any, Optional\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass PerformanceMetrics:\n    \"\"\"Complete performance metrics for search operations.\"\"\"\n    operation_name: str\n    start_time: float\n    end_time: float\n    duration_ms: float\n    memory_before_mb: float\n    memory_after_mb: float\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    \n    @property\n    def memory_delta_mb(self) -> float:\n        return self.memory_after_mb - self.memory_before_mb\n\nclass SearchProfiler:\n    \"\"\"Production-ready profiler for semantic search operations.\"\"\"\n    \n    def __init__(self):\n        self.metrics: List[PerformanceMetrics] = []\n        self.active_operations: Dict[str, float] = {}\n        \n    @contextmanager\n    def profile_operation(self, operation_name: str, **metadata):\n        \"\"\"Context manager for profiling search operations.\"\"\"\n        import psutil\n        process = psutil.Process()\n        \n        # Record start metrics\n        start_time = time.perf_counter()\n        memory_before = process.memory_info().rss / 1024 / 1024  # MB\n        \n        try:\n            yield\n        finally:\n            # Record end metrics\n            end_time = time.perf_counter()\n            memory_after = process.memory_info().rss / 1024 / 1024  # MB\n            duration_ms = (end_time - start_time) * 1000\n            \n            metric = PerformanceMetrics(\n                operation_name=operation_name,\n                start_time=start_time,\n                end_time=end_time,\n                duration_ms=duration_ms,\n                memory_before_mb=memory_before,\n                memory_after_mb=memory_after,\n                metadata=metadata\n            )\n            \n            self.metrics.append(metric)\n            \n            # Log slow operations\n            if duration_ms > 100:  # Log operations over 100ms\n                logging.warning(f\"Slow operation: {operation_name} took {duration_ms:.1f}ms\")\n    \n    def profile_function(self, operation_name: str = None):\n        \"\"\"Decorator for profiling function calls.\"\"\"\n        def decorator(func):\n            nonlocal operation_name\n            if operation_name is None:\n                operation_name = f\"{func.__module__}.{func.__name__}\"\n                \n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                with self.profile_operation(operation_name):\n                    return func(*args, **kwargs)\n            return wrapper\n        return decorator\n    \n    def get_summary(self) -> Dict[str, Any]:\n        \"\"\"Generate performance summary statistics.\"\"\"\n        if not self.metrics:\n            return {\"error\": \"No metrics recorded\"}\n            \n        operations = {}\n        for metric in self.metrics:\n            op_name = metric.operation_name\n            if op_name not in operations:\n                operations[op_name] = {\n                    \"count\": 0,\n                    \"total_time_ms\": 0,\n                    \"min_time_ms\": float('inf'),\n                    \"max_time_ms\": 0,\n                    \"total_memory_delta_mb\": 0\n                }\n            \n            op_stats = operations[op_name]\n            op_stats[\"count\"] += 1\n            op_stats[\"total_time_ms\"] += metric.duration_ms\n            op_stats[\"min_time_ms\"] = min(op_stats[\"min_time_ms\"], metric.duration_ms)\n            op_stats[\"max_time_ms\"] = max(op_stats[\"max_time_ms\"], metric.duration_ms)\n            op_stats[\"total_memory_delta_mb\"] += metric.memory_delta_mb\n        \n        # Calculate averages\n        for op_stats in operations.values():\n            op_stats[\"avg_time_ms\"] = op_stats[\"total_time_ms\"] / op_stats[\"count\"]\n            op_stats[\"avg_memory_delta_mb\"] = op_stats[\"total_memory_delta_mb\"] / op_stats[\"count\"]\n        \n        return {\n            \"total_operations\": len(self.metrics),\n            \"operations\": operations,\n            \"total_time_ms\": sum(m.duration_ms for m in self.metrics)\n        }\n\n# Global profiler instance\nprofiler = SearchProfiler()\n```\n\n**Vector Debugging Utilities**: Complete utilities for diagnosing embedding and vector issues:\n\n```python\nimport numpy as np\nimport faiss\nfrom typing import List, Tuple, Dict, Any, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass VectorDiagnostics:\n    \"\"\"Comprehensive vector health diagnostics.\"\"\"\n    vector_count: int\n    dimension: int\n    norm_mean: float\n    norm_std: float\n    norm_min: float\n    norm_max: float\n    is_normalized: bool\n    zero_vectors: int\n    identical_vectors: int\n    dimension_stats: Dict[int, Dict[str, float]]\n\nclass VectorDebugger:\n    \"\"\"Production-ready vector debugging utilities.\"\"\"\n    \n    @staticmethod\n    def diagnose_vectors(vectors: np.ndarray, tolerance: float = 1e-6) -> VectorDiagnostics:\n        \"\"\"Comprehensive vector health check.\"\"\"\n        if len(vectors.shape) != 2:\n            raise ValueError(f\"Expected 2D array, got shape {vectors.shape}\")\n        \n        vector_count, dimension = vectors.shape\n        \n        # Calculate vector norms\n        norms = np.linalg.norm(vectors, axis=1)\n        \n        # Check normalization\n        is_normalized = np.all(np.abs(norms - 1.0) < tolerance)\n        \n        # Count zero vectors\n        zero_vectors = np.sum(np.all(vectors == 0, axis=1))\n        \n        # Count identical vectors (computationally expensive for large arrays)\n        identical_vectors = 0\n        if vector_count < 10000:  # Only check for small arrays\n            unique_vectors = np.unique(vectors, axis=0)\n            identical_vectors = vector_count - len(unique_vectors)\n        \n        # Analyze dimension-wise statistics\n        dimension_stats = {}\n        for dim in range(min(10, dimension)):  # Only analyze first 10 dimensions\n            dim_values = vectors[:, dim]\n            dimension_stats[dim] = {\n                \"mean\": float(np.mean(dim_values)),\n                \"std\": float(np.std(dim_values)),\n                \"min\": float(np.min(dim_values)),\n                \"max\": float(np.max(dim_values))\n            }\n        \n        return VectorDiagnostics(\n            vector_count=vector_count,\n            dimension=dimension,\n            norm_mean=float(np.mean(norms)),\n            norm_std=float(np.std(norms)),\n            norm_min=float(np.min(norms)),\n            norm_max=float(np.max(norms)),\n            is_normalized=is_normalized,\n            zero_vectors=zero_vectors,\n            identical_vectors=identical_vectors,\n            dimension_stats=dimension_stats\n        )\n    \n    @staticmethod\n    def validate_index_health(index: faiss.Index, sample_queries: int = 100) -> Dict[str, Any]:\n        \"\"\"Validate FAISS index health with sample searches.\"\"\"\n        try:\n            # Basic index properties\n            health_report = {\n                \"index_type\": type(index).__name__,\n                \"total_vectors\": index.ntotal,\n                \"dimension\": index.d,\n                \"is_trained\": index.is_trained,\n                \"search_errors\": 0,\n                \"avg_search_time_ms\": 0,\n                \"memory_usage_mb\": 0\n            }\n            \n            if index.ntotal == 0:\n                health_report[\"status\"] = \"empty\"\n                return health_report\n            \n            # Test sample searches\n            search_times = []\n            for _ in range(sample_queries):\n                # Generate random query vector\n                query = np.random.randn(1, index.d).astype(np.float32)\n                query = query / np.linalg.norm(query)  # Normalize\n                \n                try:\n                    start_time = time.perf_counter()\n                    scores, indices = index.search(query, k=min(10, index.ntotal))\n                    search_time = (time.perf_counter() - start_time) * 1000\n                    search_times.append(search_time)\n                    \n                    # Validate results\n                    if len(indices[0]) == 0:\n                        health_report[\"search_errors\"] += 1\n                        \n                except Exception as e:\n                    health_report[\"search_errors\"] += 1\n                    logging.error(f\"Index search error: {e}\")\n            \n            if search_times:\n                health_report[\"avg_search_time_ms\"] = np.mean(search_times)\n                health_report[\"p95_search_time_ms\"] = np.percentile(search_times, 95)\n            \n            # Estimate memory usage (rough approximation)\n            health_report[\"memory_usage_mb\"] = (index.ntotal * index.d * 4) / (1024 * 1024)\n            \n            # Overall health status\n            if health_report[\"search_errors\"] == 0:\n                health_report[\"status\"] = \"healthy\"\n            elif health_report[\"search_errors\"] < sample_queries * 0.1:\n                health_report[\"status\"] = \"degraded\"\n            else:\n                health_report[\"status\"] = \"unhealthy\"\n                \n            return health_report\n            \n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"error\": str(e),\n                \"index_type\": type(index).__name__ if index else \"None\"\n            }\n    \n    @staticmethod\n    def compare_embeddings(embeddings1: np.ndarray, embeddings2: np.ndarray, \n                          labels: List[str] = None) -> Dict[str, Any]:\n        \"\"\"Compare two sets of embeddings for debugging model changes.\"\"\"\n        if embeddings1.shape != embeddings2.shape:\n            return {\n                \"error\": f\"Shape mismatch: {embeddings1.shape} vs {embeddings2.shape}\"\n            }\n        \n        # Calculate similarities between corresponding embeddings\n        similarities = []\n        for i in range(len(embeddings1)):\n            sim = cosine_similarity(embeddings1[i:i+1], embeddings2[i:i+1])[0, 0]\n            similarities.append(sim)\n        \n        similarities = np.array(similarities)\n        \n        # Find most different embeddings\n        most_different_indices = np.argsort(similarities)[:5]\n        least_different_indices = np.argsort(similarities)[-5:]\n        \n        comparison = {\n            \"total_pairs\": len(similarities),\n            \"mean_similarity\": float(np.mean(similarities)),\n            \"std_similarity\": float(np.std(similarities)),\n            \"min_similarity\": float(np.min(similarities)),\n            \"max_similarity\": float(np.max(similarities)),\n            \"most_different\": [\n                {\n                    \"index\": int(idx),\n                    \"similarity\": float(similarities[idx]),\n                    \"label\": labels[idx] if labels else None\n                }\n                for idx in most_different_indices\n            ],\n            \"least_different\": [\n                {\n                    \"index\": int(idx), \n                    \"similarity\": float(similarities[idx]),\n                    \"label\": labels[idx] if labels else None\n                }\n                for idx in least_different_indices\n            ]\n        }\n        \n        return comparison\n\n# Usage examples for debugging\ndef debug_embedding_pipeline():\n    \"\"\"Example debugging workflow for embedding issues.\"\"\"\n    # Load your embeddings\n    embeddings = load_document_embeddings()  # Your implementation\n    \n    # Run comprehensive diagnostics\n    diagnostics = VectorDebugger.diagnose_vectors(embeddings)\n    \n    print(\"Vector Diagnostics:\")\n    print(f\"  Total vectors: {diagnostics.vector_count}\")\n    print(f\"  Dimensions: {diagnostics.dimension}\")\n    print(f\"  Normalized: {diagnostics.is_normalized}\")\n    print(f\"  Zero vectors: {diagnostics.zero_vectors}\")\n    print(f\"  Norm range: {diagnostics.norm_min:.3f} - {diagnostics.norm_max:.3f}\")\n    \n    if not diagnostics.is_normalized:\n        print(\"WARNING: Vectors are not normalized - this will affect cosine similarity\")\n    \n    if diagnostics.zero_vectors > 0:\n        print(f\"WARNING: Found {diagnostics.zero_vectors} zero vectors\")\n```\n\n**Relevance Debugging Tools**: Complete framework for analyzing search quality issues:\n\n```python\nfrom typing import List, Dict, Any, Tuple\nimport numpy as np\nfrom dataclasses import dataclass\nfrom collections import defaultdict\n\n@dataclass \nclass RelevanceDebugInfo:\n    \"\"\"Debug information for a single search result.\"\"\"\n    document_id: str\n    title: str\n    semantic_score: float\n    bm25_score: float\n    personalization_score: float\n    freshness_score: float\n    combined_score: float\n    rank_position: int\n    human_relevance: Optional[int] = None  # 0-4 scale\n    debug_notes: List[str] = field(default_factory=list)\n\nclass RelevanceDebugger:\n    \"\"\"Production-ready relevance debugging framework.\"\"\"\n    \n    def __init__(self, ranking_engine):\n        self.ranking_engine = ranking_engine\n        self.debug_queries: Dict[str, List[RelevanceDebugInfo]] = {}\n    \n    def debug_search_quality(self, query: str, results: List[SearchResult], \n                           ground_truth: Dict[str, int] = None) -> Dict[str, Any]:\n        \"\"\"Comprehensive search quality analysis.\"\"\"\n        debug_info = []\n        \n        for i, result in enumerate(results):\n            # Extract individual ranking signals\n            signals = result.ranking_signals\n            \n            debug_entry = RelevanceDebugInfo(\n                document_id=result.document.doc_id,\n                title=result.document.title,\n                semantic_score=signals.get('semantic_score', 0.0),\n                bm25_score=signals.get('bm25_score', 0.0),\n                personalization_score=signals.get('personalization_score', 0.0),\n                freshness_score=signals.get('freshness_score', 0.0),\n                combined_score=result.relevance_score,\n                rank_position=i + 1\n            )\n            \n            # Add human relevance if available\n            if ground_truth and result.document.doc_id in ground_truth:\n                debug_entry.human_relevance = ground_truth[result.document.doc_id]\n            \n            # Generate debug notes\n            debug_entry.debug_notes = self._generate_debug_notes(debug_entry)\n            debug_info.append(debug_entry)\n        \n        # Store for analysis\n        self.debug_queries[query] = debug_info\n        \n        # Calculate quality metrics if ground truth available\n        quality_metrics = {}\n        if ground_truth:\n            quality_metrics = self._calculate_quality_metrics(debug_info, ground_truth)\n        \n        # Analyze ranking signal contributions\n        signal_analysis = self._analyze_signal_contributions(debug_info)\n        \n        return {\n            \"query\": query,\n            \"total_results\": len(debug_info),\n            \"debug_info\": [\n                {\n                    \"rank\": entry.rank_position,\n                    \"doc_id\": entry.document_id,\n                    \"title\": entry.title[:100] + \"...\" if len(entry.title) > 100 else entry.title,\n                    \"scores\": {\n                        \"semantic\": entry.semantic_score,\n                        \"bm25\": entry.bm25_score,\n                        \"personalization\": entry.personalization_score,\n                        \"freshness\": entry.freshness_score,\n                        \"combined\": entry.combined_score\n                    },\n                    \"human_relevance\": entry.human_relevance,\n                    \"debug_notes\": entry.debug_notes\n                }\n                for entry in debug_info[:10]  # Top 10 for readability\n            ],\n            \"quality_metrics\": quality_metrics,\n            \"signal_analysis\": signal_analysis\n        }\n    \n    def _generate_debug_notes(self, debug_info: RelevanceDebugInfo) -> List[str]:\n        \"\"\"Generate debugging notes for ranking anomalies.\"\"\"\n        notes = []\n        \n        # Check for signal dominance\n        signals = [\n            debug_info.semantic_score,\n            debug_info.bm25_score,\n            debug_info.personalization_score,\n            debug_info.freshness_score\n        ]\n        max_signal = max(signals)\n        \n        if debug_info.semantic_score == max_signal and max_signal > 0.8:\n            notes.append(\"Dominated by semantic similarity\")\n        elif debug_info.bm25_score == max_signal:\n            notes.append(\"Dominated by keyword matching\")\n        elif debug_info.personalization_score == max_signal:\n            notes.append(\"Heavily personalized result\")\n        elif debug_info.freshness_score == max_signal:\n            notes.append(\"Boosted by recency\")\n        \n        # Check for score inconsistencies\n        if debug_info.human_relevance is not None:\n            if debug_info.human_relevance >= 3 and debug_info.rank_position > 10:\n                notes.append(\"Highly relevant but ranked low\")\n            elif debug_info.human_relevance <= 1 and debug_info.rank_position <= 5:\n                notes.append(\"Low relevance but ranked high\")\n        \n        # Check for extreme scores\n        if debug_info.combined_score > 0.95:\n            notes.append(\"Unusually high combined score\")\n        elif debug_info.combined_score < 0.1 and debug_info.rank_position <= 10:\n            notes.append(\"Low score in top results\")\n        \n        return notes\n    \n    def _calculate_quality_metrics(self, debug_info: List[RelevanceDebugInfo], \n                                 ground_truth: Dict[str, int]) -> Dict[str, float]:\n        \"\"\"Calculate precision@k and other relevance metrics.\"\"\"\n        # Consider documents with relevance >= 3 as relevant\n        relevant_threshold = 3\n        \n        metrics = {}\n        for k in [1, 3, 5, 10]:\n            if k <= len(debug_info):\n                top_k = debug_info[:k]\n                relevant_count = sum(\n                    1 for entry in top_k \n                    if entry.human_relevance is not None and entry.human_relevance >= relevant_threshold\n                )\n                metrics[f\"precision_at_{k}\"] = relevant_count / k\n        \n        # Calculate NDCG if we have enough data\n        if len(debug_info) >= 5:\n            relevance_scores = []\n            for entry in debug_info[:10]:\n                if entry.human_relevance is not None:\n                    relevance_scores.append(entry.human_relevance)\n                else:\n                    relevance_scores.append(0)\n            \n            if relevance_scores:\n                dcg = sum(\n                    (2**rel - 1) / np.log2(i + 2) \n                    for i, rel in enumerate(relevance_scores)\n                )\n                \n                # Ideal DCG (sorted by relevance)\n                ideal_relevances = sorted(relevance_scores, reverse=True)\n                idcg = sum(\n                    (2**rel - 1) / np.log2(i + 2) \n                    for i, rel in enumerate(ideal_relevances)\n                )\n                \n                metrics[\"ndcg_at_10\"] = dcg / idcg if idcg > 0 else 0.0\n        \n        return metrics\n    \n    def _analyze_signal_contributions(self, debug_info: List[RelevanceDebugInfo]) -> Dict[str, Any]:\n        \"\"\"Analyze how different signals contribute to ranking.\"\"\"\n        signal_correlations = {\n            \"semantic_rank_correlation\": 0.0,\n            \"bm25_rank_correlation\": 0.0,\n            \"personalization_rank_correlation\": 0.0,\n            \"freshness_rank_correlation\": 0.0\n        }\n        \n        if len(debug_info) < 2:\n            return signal_correlations\n        \n        # Extract signal values and ranks\n        ranks = [entry.rank_position for entry in debug_info]\n        semantic_scores = [entry.semantic_score for entry in debug_info]\n        bm25_scores = [entry.bm25_score for entry in debug_info]\n        \n        # Calculate Spearman rank correlations\n        try:\n            from scipy.stats import spearmanr\n            \n            signal_correlations[\"semantic_rank_correlation\"] = float(\n                spearmanr(ranks, semantic_scores).correlation\n            )\n            signal_correlations[\"bm25_rank_correlation\"] = float(\n                spearmanr(ranks, bm25_scores).correlation  \n            )\n            \n        except ImportError:\n            # Fallback to simple correlation if scipy not available\n            pass\n        \n        # Signal dominance analysis\n        signal_wins = defaultdict(int)\n        for entry in debug_info:\n            signals = {\n                \"semantic\": entry.semantic_score,\n                \"bm25\": entry.bm25_score,\n                \"personalization\": entry.personalization_score,\n                \"freshness\": entry.freshness_score\n            }\n            winner = max(signals, key=signals.get)\n            signal_wins[winner] += 1\n        \n        signal_correlations[\"signal_dominance\"] = dict(signal_wins)\n        \n        return signal_correlations\n\n# Example usage\ndef debug_relevance_issues():\n    \"\"\"Example workflow for debugging relevance problems.\"\"\"\n    ranking_engine = RankingEngine()  # Your implementation\n    debugger = RelevanceDebugger(ranking_engine)\n    \n    # Define test queries with ground truth\n    test_cases = [\n        {\n            \"query\": \"machine learning algorithms\",\n            \"ground_truth\": {\n                \"doc1\": 4,  # Highly relevant\n                \"doc2\": 3,  # Relevant  \n                \"doc3\": 1,  # Not relevant\n                \"doc4\": 2   # Somewhat relevant\n            }\n        }\n    ]\n    \n    for test_case in test_cases:\n        # Execute search\n        results = ranking_engine.search(test_case[\"query\"])\n        \n        # Debug search quality\n        debug_report = debugger.debug_search_quality(\n            test_case[\"query\"], \n            results, \n            test_case[\"ground_truth\"]\n        )\n        \n        print(f\"Query: {test_case['query']}\")\n        print(f\"Precision@5: {debug_report['quality_metrics'].get('precision_at_5', 'N/A')}\")\n        print(f\"NDCG@10: {debug_report['quality_metrics'].get('ndcg_at_10', 'N/A')}\")\n        print(\"Issues found:\")\n        for entry in debug_report[\"debug_info\"][:5]:\n            if entry[\"debug_notes\"]:\n                print(f\"  Rank {entry['rank']}: {', '.join(entry['debug_notes'])}\")\n```\n\n#### Milestone Checkpoints\n\nAfter implementing the debugging infrastructure, verify that your debugging tools work correctly:\n\n**Milestone 1 Debugging Verification**:\n```bash\n# Test vector debugging utilities\npython -c \"\nfrom your_project.debug import VectorDebugger\nimport numpy as np\n\n# Test with sample vectors\nvectors = np.random.randn(1000, 384).astype(np.float32)\ndiagnostics = VectorDebugger.diagnose_vectors(vectors)\nprint(f'Vector health: normalized={diagnostics.is_normalized}')\nprint(f'Norm range: {diagnostics.norm_min:.3f} - {diagnostics.norm_max:.3f}')\n\"\n```\n\n**Milestone 2-3 Debugging Verification**:\n```bash\n# Test relevance debugging\npython -c \"\nfrom your_project.debug import RelevanceDebugger\nfrom your_project.ranking import RankingEngine\n\ndebugger = RelevanceDebugger(RankingEngine())\n# Test with sample query - should show signal analysis\n\"\n```\n\n**Performance Monitoring Verification**:\n```bash\n# Test performance profiler\npython -c \"\nfrom your_project.debug import profiler\n\n@profiler.profile_function('test_operation')\ndef slow_function():\n    import time\n    time.sleep(0.1)  # Simulate work\n\nslow_function()\nprint(profiler.get_summary())\n\"\n```\n\nExpected output should show timing information, memory usage, and any performance warnings for operations exceeding thresholds.\n\n\n## Future Extensions\n\n> **Milestone(s):** This section builds upon all milestones (1-4), outlining advanced features and scaling strategies that extend the core semantic search engine into next-generation capabilities.\n\nThe semantic search engine we've built through the four milestones represents a solid foundation for modern information retrieval. However, the rapidly evolving landscape of search technology and user expectations demands consideration of advanced features that push beyond traditional text-based semantic search. This section explores two critical dimensions of evolution: **Advanced Search Features** that enhance the search experience through multi-modal capabilities, intelligent filtering, and conversational interfaces, and **Scaling and Distribution** strategies that enable the system to handle enterprise-scale workloads with real-time updates and global distribution.\n\nThink of our current semantic search engine as a skilled librarian who understands the meaning behind your questions and can find relevant books by understanding concepts rather than just matching keywords. The future extensions we'll explore are like transforming that librarian into a polyglot research assistant who can understand images and audio, maintain ongoing conversations about your research needs, and coordinate with a global network of specialized librarians to provide instant access to any information, anywhere in the world.\n\nThese extensions represent natural evolution paths rather than revolutionary changes. Each builds upon the foundational components we've established while introducing new capabilities that address emerging use cases in modern search applications. The mental model remains consistent: we're enhancing our ability to understand user intent and match it with relevant information, but we're expanding the definition of both \"intent\" and \"information\" to encompass richer, more diverse forms of data and interaction.\n\n### Advanced Search Features\n\nThe next generation of semantic search transcends the boundaries of text-only retrieval, embracing multi-modal understanding, intelligent semantic filtering, and natural conversation flows. These features represent the evolution from keyword-based information retrieval to AI-powered research assistance that understands context, remembers previous interactions, and can work with diverse media types.\n\n#### Multi-Modal Embeddings\n\nMulti-modal search represents one of the most transformative advances in modern information retrieval, enabling users to search using images, audio, video, and combinations of different media types. Think of this capability as giving our semantic search engine the ability to \"see\" and \"hear\" in addition to reading, creating a unified understanding space where a user could upload an image of a product and find related documents, or hum a melody to find relevant audio content.\n\nThe technical foundation for multi-modal search builds directly on our existing embedding infrastructure from Milestone 1, but expands the `DocumentEncoder` to handle multiple data types. Instead of generating a single text embedding, we create aligned embeddings across different modalities that can be meaningfully compared in the same vector space. This alignment is achieved through multi-modal training techniques like CLIP (Contrastive Language-Image Pre-training) that learn to map images and text to nearby points in the embedding space when they represent similar concepts.\n\n> **Decision: Multi-Modal Embedding Architecture**\n> - **Context**: Users increasingly want to search using images, audio, and video content, requiring embeddings that can meaningfully compare across different data types\n> - **Options Considered**: Separate indices per modality, modal-specific encoders with late fusion, unified multi-modal embedding space\n> - **Decision**: Unified multi-modal embedding space with modal-specific encoders feeding into a shared dimension\n> - **Rationale**: Enables cross-modal search (image query finding text results), simpler ranking pipeline, and better user experience with mixed-media results\n> - **Consequences**: Requires more sophisticated embedding models, increased computational requirements, but enables revolutionary search capabilities\n\nThe data model extensions for multi-modal search introduce new content types and embedding strategies:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `media_type` | str | Content type: 'text', 'image', 'audio', 'video', 'mixed' |\n| `content_url` | Optional[str] | URL or path to media content for non-text types |\n| `content_metadata` | Optional[Dict] | Media-specific metadata like image dimensions, audio duration |\n| `thumbnail_url` | Optional[str] | Preview image for video/audio content |\n| `transcription` | Optional[str] | Text transcription for audio/video content |\n| `extracted_text` | Optional[str] | OCR text extracted from images or video frames |\n| `modal_embeddings` | Dict[str, np.ndarray] | Separate embeddings for each modality present |\n| `unified_embedding` | np.ndarray | Cross-modal aligned embedding for similarity search |\n\nThe multi-modal encoding pipeline extends our existing document processing workflow with media-specific processing stages. For image content, this involves feature extraction through vision transformers, object detection, and OCR text extraction. Audio processing includes speech-to-text transcription, audio fingerprinting, and acoustic feature extraction. Video combines frame sampling, object tracking, and temporal relationship modeling.\n\nCross-modal query processing becomes significantly more sophisticated, requiring the `QueryProcessor` to handle mixed-input queries where users might combine text descriptions with uploaded images or audio clips. A user searching for \"red sports car like this\" while uploading an image requires combining text understanding (\"red sports car\") with visual similarity matching against the uploaded image. The query expansion strategies from Milestone 2 extend to include visual concept expansion, where recognizing a \"Ferrari\" in an uploaded image might expand to related terms like \"Italian sports car\" or \"luxury vehicle.\"\n\nThe ranking pipeline from Milestone 3 gains new signal types for multi-modal relevance. Visual similarity scores join semantic text scores, audio matching confidence contributes to relevance calculation, and cross-modal consistency (alignment between text description and visual content) becomes a quality signal. The `RankingSignals` structure extends to accommodate these additional dimensions:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `visual_similarity_score` | Optional[float] | Image-to-image or text-to-image similarity |\n| `audio_similarity_score` | Optional[float] | Audio fingerprint or semantic audio matching |\n| `cross_modal_consistency` | Optional[float] | Alignment between different modalities in result |\n| `media_quality_score` | Optional[float] | Technical quality assessment of media content |\n| `accessibility_score` | Optional[float] | Presence of alt-text, captions, transcriptions |\n\n#### Semantic Filtering\n\nTraditional faceted search operates on explicit metadata categories like \"date,\" \"author,\" or \"department.\" Semantic filtering represents a fundamental advancement that enables filtering based on conceptual understanding rather than rigid categorical boundaries. Users can filter results by abstract concepts like \"beginner-friendly content,\" \"urgent matters,\" or \"creative approaches\" without requiring explicit tagging of these subjective qualities.\n\nThink of semantic filtering as the difference between organizing books by the Dewey Decimal System (rigid categories) versus having an intelligent librarian who understands that when you ask for \"inspiring leadership books,\" you want content that embodies leadership principles even if it's filed under biography, business, or history. The system learns to recognize conceptual patterns rather than relying solely on explicit classification.\n\nThe implementation builds on our existing embedding infrastructure by creating concept vectors that represent abstract filtering criteria. These concept vectors are learned through various techniques: they might be derived from example documents that exemplify the concept, generated from natural language descriptions of the filtering criteria, or learned through user interaction patterns that reveal implicit conceptual groupings.\n\n> **Decision: Semantic Filter Implementation Strategy**\n> - **Context**: Users want to filter by abstract concepts like \"technical difficulty\" or \"emotional tone\" that can't be captured by traditional metadata fields\n> - **Options Considered**: Rule-based classification, supervised learning with labeled examples, embedding-based conceptual similarity\n> - **Decision**: Hybrid approach using embedding similarity for concept matching with optional supervised refinement\n> - **Rationale**: Leverages existing embedding infrastructure, provides flexibility for undefined concepts, can be enhanced with training data when available\n> - **Consequences**: Enables powerful conceptual filtering but requires careful UX design to make abstract filters discoverable and understandable\n\nThe semantic filtering architecture extends the `QueryProcessor` with concept resolution capabilities:\n\n| Method | Parameters | Returns | Description |\n|--------|------------|---------|-------------|\n| `resolve_semantic_filters` | concepts: List[str], context: Dict | List[ConceptFilter] | Convert natural language filter descriptions to vector constraints |\n| `apply_conceptual_constraints` | embeddings: np.ndarray, filters: List[ConceptFilter] | np.ndarray | Filter embedding space by conceptual similarity thresholds |\n| `suggest_related_filters` | current_filters: List[str], results: List[SearchResult] | List[str] | Recommend additional conceptual filters based on result analysis |\n| `explain_filter_matching` | document: Document, filter: ConceptFilter | FilterExplanation | Provide human-readable explanation of why document matches concept |\n\nSemantic filters operate through vector space constraints, where each filter defines a region in the embedding space corresponding to documents that exhibit the desired conceptual properties. A filter for \"beginner-friendly content\" might identify a vector subspace where documents cluster around concepts of simplicity, clear explanation, and foundational knowledge. The filtering process becomes a geometric operation, finding documents whose embeddings fall within the specified conceptual regions.\n\nThe user experience for semantic filtering requires sophisticated interface design that makes abstract concepts discoverable and understandable. Auto-suggestion helps users discover available conceptual filters by analyzing their search results and suggesting relevant abstract qualities. Filter explanations help users understand why certain documents match conceptual criteria, building trust and enabling refinement of their search intent.\n\n#### Conversational Search\n\nConversational search transforms the traditional one-shot query model into an ongoing dialogue where the search engine maintains context across multiple interactions, clarifies ambiguous requests, and refines understanding through natural conversation. Rather than treating each search as an isolated event, the system builds a conversational context that enables follow-up questions, progressive refinement, and multi-turn problem solving.\n\nThe mental model shifts from a traditional search box (like asking a question at an information desk and walking away) to having an ongoing conversation with a knowledgeable research assistant who remembers what you discussed previously, can ask clarifying questions, and helps you explore topics in depth through guided discovery.\n\nConversational search introduces session management and context tracking capabilities that extend beyond our current stateless search API. The system maintains conversation state, tracks topic evolution, and applies contextual understanding to interpret abbreviated follow-up queries that would be ambiguous in isolation. A user asking \"What about Python?\" after searching for programming languages needs the system to understand the conversational context rather than treating it as a standalone query about snakes or mythology.\n\n> **Decision: Conversational Context Management**\n> - **Context**: Users want to have extended conversations with the search system, asking follow-up questions and refining their search through dialogue\n> - **Options Considered**: Stateless query rewriting, full conversation history embedding, sliding window context with key information extraction\n> - **Decision**: Sliding window context with intelligent key information extraction and query contextualization\n> - **Rationale**: Balances performance with conversational capability, avoids unbounded context growth, focuses on relevant conversation elements\n> - **Consequences**: Enables natural follow-up queries but requires sophisticated context understanding and potential loss of distant conversation elements\n\nThe conversational search architecture introduces new data structures for session management:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `session_id` | str | Unique identifier for conversational session |\n| `conversation_history` | List[ConversationTurn] | Chronological record of queries and responses |\n| `active_topics` | List[TopicContext] | Currently active conversation topics with relevance scores |\n| `user_preferences` | UserContext | Learned preferences and expertise level from conversation |\n| `clarification_state` | Optional[ClarificationContext] | Pending clarification requests and expected response types |\n\nEach conversation turn captures both the explicit query and the implicit context that influences interpretation:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `turn_number` | int | Sequential position in conversation |\n| `raw_query` | str | User's exact input text |\n| `contextualized_query` | str | Query expanded with conversational context |\n| `query_type` | QueryType | Classification: new_topic, follow_up, clarification, refinement |\n| `referenced_results` | List[str] | Document IDs referenced in this turn |\n| `user_feedback` | Optional[FeedbackSignal] | Explicit or implicit feedback on results |\n\nThe query contextualization process becomes significantly more sophisticated, requiring natural language understanding that goes beyond simple keyword expansion. The system must resolve pronouns (\"it,\" \"that approach,\" \"those examples\"), understand temporal references (\"earlier results,\" \"the previous method\"), and maintain topic coherence across conversation turns. Machine learning models trained on conversational data help interpret ambiguous follow-up queries by considering both conversation history and current context.\n\nClarification dialogues represent a powerful extension where the search system can ask users for additional information when queries are ambiguous or underspecified. Rather than returning potentially irrelevant results for unclear requests, the system engages in brief clarification exchanges: \"When you ask about 'integration testing,' are you interested in software testing methodologies, business system integration, or mathematical integration techniques?\" This proactive clarification dramatically improves result relevance and user satisfaction.\n\n### Scaling and Distribution\n\nAs semantic search systems mature from prototype to production to enterprise scale, they encounter challenges that demand sophisticated distribution strategies, real-time update capabilities, and global deployment architectures. The scaling dimension addresses not just increased load, but fundamental changes in how search systems must operate: maintaining consistency across distributed indices, enabling real-time updates without service interruption, and providing global search capabilities with local latency characteristics.\n\n#### Distributed Indexing\n\nDistributed indexing addresses the fundamental scalability challenge of semantic search: as document collections grow beyond what a single machine can handle efficiently, we must partition the embedding index across multiple nodes while maintaining fast query performance and system reliability. This transition represents a shift from centralized search architecture to a distributed system that can scale horizontally as data volume and query load increase.\n\nThe mental model for distributed indexing resembles transforming our single intelligent librarian into a coordinated team of specialists, where each team member becomes an expert in specific subject areas or document collections, but they can all collaborate seamlessly to answer any research question. The challenge lies in partitioning the work effectively, coordinating responses, and ensuring that users receive complete, relevant results regardless of how the underlying data is distributed.\n\nUnlike traditional databases where distribution strategies are well-established, vector indices present unique challenges. Embedding spaces don't naturally partition along obvious boundaries like date ranges or alphabetical ordering. The high-dimensional nature of embeddings means that naive partitioning strategies can destroy the locality properties that make vector search efficient. Instead, distributed vector indexing requires sophisticated partitioning strategies that preserve semantic neighborhoods while balancing load across nodes.\n\n> **Decision: Vector Index Partitioning Strategy**\n> - **Context**: Large document collections require distributed indexing, but naive partitioning destroys vector locality and degrades search quality\n> - **Options Considered**: Random partitioning, clustering-based partitioning, learned partitioning with routing models\n> - **Decision**: Hierarchical clustering-based partitioning with learned query routing\n> - **Rationale**: Preserves semantic locality within partitions, enables efficient query routing to relevant shards, maintains search quality at scale\n> - **Consequences**: Requires initial clustering computation and routing model training, but provides scalable search with minimal quality degradation\n\nThe distributed indexing architecture extends our existing `EmbeddingIndex` component with coordination and partitioning capabilities:\n\n| Component | Responsibility | Key Interfaces |\n|-----------|----------------|----------------|\n| `IndexCoordinator` | Query routing, result aggregation, health monitoring | `route_query()`, `aggregate_results()`, `monitor_shards()` |\n| `IndexShard` | Local vector index management, shard-specific search | `search_local()`, `add_documents()`, `get_shard_stats()` |\n| `PartitionStrategy` | Determines document-to-shard assignment | `assign_shard()`, `rebalance_partitions()` |\n| `QueryRouter` | Selects relevant shards for each query | `select_shards()`, `estimate_relevance()` |\n\nThe partitioning process begins with analyzing the full document collection to identify semantic clusters that can be assigned to different shards. This clustering process uses the same embedding techniques from Milestone 1, but applies them at the collection level to identify natural groupings of related documents. Documents about machine learning might cluster together, while legal documents form another cluster, and historical texts form a third. Each cluster becomes a shard that can be hosted on separate infrastructure.\n\nQuery routing becomes a critical performance optimization that determines which shards to search for each query. A naive approach would query all shards and aggregate results, but this eliminates the performance benefits of distribution. Instead, intelligent query routing uses the query embedding to predict which shards are likely to contain relevant documents, typically searching only 20-30% of available shards while maintaining high recall.\n\nThe distributed ranking pipeline from Milestone 3 requires coordination across shards to ensure global result quality. Each shard returns its top local candidates with their local scores, but these local scores must be normalized and compared across shards to produce globally optimal rankings. This process, known as distributed top-k selection, requires careful score calibration and potentially multiple rounds of communication between coordinator and shards.\n\nConsistency management becomes complex when supporting concurrent updates across distributed shards. New documents must be assigned to appropriate shards, index updates must be coordinated to maintain search consistency, and shard rebalancing operations must be performed without service interruption. The system adopts an eventually consistent model where individual shards can be updated independently, with periodic synchronization to maintain global consistency.\n\n#### Search Federation\n\nSearch federation extends distributed indexing to connect multiple independent search systems, enabling queries across heterogeneous data sources, different embedding models, and even different organizations. Think of federation as creating a \"search of searches\" that can simultaneously query your local document repository, external knowledge bases, and specialized domain-specific search engines, then intelligently combine and rank the unified results.\n\nThe federation architecture addresses scenarios where organizations need to search across multiple independent systems without centralizing all data. A research organization might need to search their internal documents, public research databases, patent databases, and news archives simultaneously. Each source uses different indexing strategies, embedding models, and relevance signals, but users want a unified search experience that draws from all available sources.\n\nFederation introduces new challenges beyond distributed indexing: different embedding spaces can't be directly compared, various systems use incompatible relevance scoring, network latency varies dramatically across federated sources, and some sources might be temporarily unavailable. The federation layer must abstract these differences while providing a consistent user experience.\n\n> **Decision: Federation Architecture Pattern**\n> - **Context**: Organizations need to search across multiple independent systems with different embedding models, scoring systems, and availability characteristics\n> - **Options Considered**: Centralized federation hub, peer-to-peer federation, hierarchical federation with regional coordinators\n> - **Decision**: Hierarchical federation with adapter pattern for heterogeneous source integration\n> - **Rationale**: Provides scalability through hierarchy, enables source-specific optimization through adapters, maintains performance through regional coordination\n> - **Consequences**: Requires sophisticated adapter development but enables flexible integration of diverse search systems\n\nThe federation architecture introduces adapter patterns that normalize differences between federated sources:\n\n| Component | Responsibility | Key Challenges |\n|-----------|----------------|-----------------| \n| `FederationCoordinator` | Query distribution, result aggregation, source selection | Balancing comprehensiveness with performance |\n| `SourceAdapter` | Translates between federation protocol and source-specific APIs | Handling incompatible scoring systems and embedding spaces |\n| `ResultNormalizer` | Harmonizes relevance scores across heterogeneous sources | Calibrating scores from different ranking algorithms |\n| `SourceHealthMonitor` | Tracks availability and performance of federated sources | Managing partial failures and degraded service |\n\nQuery translation becomes a sophisticated process where the federated query must be adapted to each source's capabilities and interface. A semantic query might be translated to vector search for systems supporting embeddings, keyword search for traditional systems, and structured queries for database sources. The federation layer maintains source capability profiles that describe each system's search features, supported query types, and performance characteristics.\n\nResult harmonization addresses the challenge of combining results from sources that use incompatible relevance scoring systems. A traditional search engine might return BM25 scores ranging 0-10, while a modern semantic system returns cosine similarity scores ranging 0-1. The federation layer learns score normalization functions that map source-specific scores to a common relevance scale, enabling meaningful cross-source ranking.\n\nThe federated ranking pipeline extends beyond simple score normalization to consider source credibility, freshness differences, and user preferences for certain sources. Results from authoritative sources might receive credibility boosts, recent results from fast-updating sources gain freshness advantages, and user interaction history influences source weighting for personalized federation.\n\n#### Real-Time Updates\n\nReal-time updates transform semantic search from a batch-oriented system that periodically rebuilds indices to a dynamic platform that incorporates new documents, user feedback, and model improvements continuously without service interruption. This capability is essential for modern applications where information freshness is critical: news search, social media monitoring, collaborative knowledge bases, and any system where users expect immediate visibility of new content.\n\nThe challenge of real-time updates in semantic search systems goes beyond traditional database updates because vector indices have complex internal structures that aren't easily modified incrementally. Traditional inverted indices can add new documents by simply appending to posting lists, but vector indices like HNSW maintain graph structures that require careful coordination when adding nodes. Additionally, embedding model updates can invalidate existing embeddings, requiring coordinated re-processing of the entire document collection.\n\nReal-time update architecture must balance multiple competing requirements: update latency (how quickly new documents become searchable), query performance (updates shouldn't degrade search speed), consistency (users shouldn't see partial or inconsistent results), and resource utilization (updates shouldn't overwhelm system resources during peak usage periods).\n\n> **Decision: Real-Time Update Architecture**\n> - **Context**: Modern applications require immediate visibility of new content without degrading search performance or system stability\n> - **Options Considered**: Direct index updates, staged update pipeline with hot-swapping, hybrid architecture with fast temporary index plus batch consolidation\n> - **Decision**: Hybrid architecture with write-optimized temporary index and periodic consolidation to read-optimized main index\n> - **Rationale**: Provides immediate visibility for new documents, maintains optimal search performance, enables controlled resource utilization\n> - **Consequences**: Introduces architectural complexity but delivers both real-time capability and production performance\n\nThe real-time update architecture introduces a multi-tier indexing strategy:\n\n| Index Tier | Purpose | Characteristics | Update Method |\n|------------|---------|-----------------|---------------|\n| `FastIndex` | Recent documents (last 24-48 hours) | Write-optimized, higher latency | Direct real-time updates |\n| `MainIndex` | Stable document collection | Read-optimized, low latency | Periodic batch consolidation |\n| `ArchiveIndex` | Historical documents | Highly compressed, moderate latency | Infrequent bulk updates |\n\nThe update pipeline processes new documents through several stages that balance speed with quality. Immediate indexing provides basic searchability within seconds by adding documents to the fast index with simplified processing. Background enrichment performs expensive operations like advanced query expansion preparation, cross-reference analysis, and quality score computation. Periodic consolidation moves stabilized documents from the fast index to the main index with full optimization.\n\nEmbedding model updates represent a particularly complex real-time update scenario. When new embedding models become available (offering better accuracy or supporting new languages), the system must coordinate re-processing of existing documents without service interruption. The architecture supports gradual model rollout where new documents use updated embeddings while existing documents are re-processed in background batches, maintaining search quality during the transition period.\n\nThe ranking system from Milestone 3 adapts to handle results from multiple index tiers, applying appropriate score normalization and temporal weighting to ensure recent documents receive appropriate visibility without overwhelming older but highly relevant content. Click-through learning systems must account for the different characteristics of fast versus main index results when updating relevance models.\n\nConsistency management ensures that users never see partial updates or inconsistent search results during update operations. The system maintains read consistency by completing update transactions atomically, uses versioned indices to enable hot-swapping without service interruption, and provides eventual consistency guarantees where short-term inconsistencies are acceptable but long-term convergence is guaranteed.\n\n### Implementation Guidance\n\nThe future extensions described in this section represent advanced capabilities that build upon the solid foundation established in Milestones 1-4. While these features push the boundaries of what's possible with semantic search, they follow the same architectural principles and can be developed incrementally as system requirements evolve.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Multi-Modal Embeddings | OpenAI CLIP + sentence-transformers for text | Custom multi-modal transformer with domain-specific training |\n| Image Processing | PIL + OpenCV for basic feature extraction | torchvision with pre-trained ResNet/EfficientNet models |\n| Audio Processing | librosa for audio features + speech_recognition | Whisper for transcription + wav2vec2 for audio embeddings |\n| Video Processing | OpenCV frame extraction + CLIP for frames | Video transformers like VideoMAE or I3D for temporal modeling |\n| Semantic Filtering | Cosine similarity with concept vectors | Fine-tuned BERT classifier for concept detection |\n| Conversational Search | Simple session storage + query expansion | Full dialogue state tracking with conversational AI models |\n| Distributed Indexing | Redis Cluster for coordination + FAISS sharding | Custom distributed vector index with learned partitioning |\n| Search Federation | HTTP adapters for external APIs | GraphQL federation with schema stitching |\n| Real-Time Updates | Redis streams for update queue + background processing | Apache Kafka with stream processing framework |\n\n#### Recommended File Structure Extension\n\nBuilding on the existing project structure from previous milestones, future extensions organize into specialized modules:\n\n```\nproject-root/\n  # Existing core components from Milestones 1-4\n  internal/embedding/\n  internal/query/\n  internal/ranking/\n  internal/api/\n  \n  # New future extension modules\n  internal/multimodal/\n    encoders/\n      image_encoder.py          ← CLIP-based image embedding\n      audio_encoder.py          ← Audio feature extraction and embedding\n      video_encoder.py          ← Video frame and temporal processing\n    unified_encoder.py          ← Cross-modal embedding alignment\n    media_processor.py          ← Content type detection and preprocessing\n    \n  internal/semantic_filtering/\n    concept_manager.py          ← Concept vector management\n    filter_processor.py         ← Semantic filter application\n    concept_suggester.py        ← Related concept recommendations\n    \n  internal/conversation/\n    session_manager.py          ← Conversation state tracking\n    context_processor.py        ← Query contextualization\n    clarification_engine.py     ← Clarification dialogue management\n    \n  internal/distributed/\n    coordinator.py              ← Index coordination and query routing\n    shard_manager.py            ← Individual shard management\n    partition_strategy.py       ← Document-to-shard assignment\n    result_aggregator.py        ← Cross-shard result combination\n    \n  internal/federation/\n    federation_coordinator.py   ← Cross-system query coordination\n    source_adapters/            ← Adapter pattern implementations\n      elasticsearch_adapter.py\n      solr_adapter.py\n      custom_api_adapter.py\n    result_normalizer.py        ← Score harmonization across sources\n    \n  internal/realtime/\n    update_pipeline.py          ← Real-time document processing\n    fast_index.py              ← Write-optimized temporary index\n    consolidation_engine.py    ← Batch consolidation to main index\n    model_updater.py           ← Embedding model refresh coordination\n```\n\n#### Multi-Modal Infrastructure Starter Code\n\nComplete infrastructure for handling multiple content types, building on the embedding foundation from Milestone 1:\n\n```python\n\"\"\"\nMulti-modal content processing infrastructure.\nProvides complete working implementation for media type detection,\npreprocessing, and embedding generation across text, image, audio, and video.\n\"\"\"\n\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport librosa\nimport cv2\nfrom typing import Dict, List, Optional, Tuple, Union\nfrom sentence_transformers import SentenceTransformer\nimport clip\nimport whisper\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass MediaContent:\n    \"\"\"Unified representation of multi-modal content.\"\"\"\n    content_id: str\n    media_type: str  # 'text', 'image', 'audio', 'video', 'mixed'\n    content_path: Optional[str] = None\n    content_data: Optional[bytes] = None\n    text_content: Optional[str] = None\n    extracted_text: Optional[str] = None  # OCR or transcription\n    metadata: Optional[Dict] = None\n\nclass MediaTypeDetector:\n    \"\"\"Automatic media type detection and validation.\"\"\"\n    \n    IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}\n    AUDIO_EXTENSIONS = {'.mp3', '.wav', '.flac', '.m4a', '.ogg'}\n    VIDEO_EXTENSIONS = {'.mp4', '.avi', '.mov', '.mkv', '.webm'}\n    \n    @classmethod\n    def detect_media_type(cls, file_path: str) -> str:\n        \"\"\"Detect media type from file extension and content.\"\"\"\n        path = Path(file_path)\n        extension = path.suffix.lower()\n        \n        if extension in cls.IMAGE_EXTENSIONS:\n            return 'image'\n        elif extension in cls.AUDIO_EXTENSIONS:\n            return 'audio'\n        elif extension in cls.VIDEO_EXTENSIONS:\n            return 'video'\n        else:\n            return 'text'\n    \n    @classmethod\n    def validate_content(cls, content: MediaContent) -> bool:\n        \"\"\"Validate content can be processed.\"\"\"\n        if content.media_type == 'text':\n            return content.text_content is not None\n        else:\n            return content.content_path is not None or content.content_data is not None\n\nclass ImageProcessor:\n    \"\"\"Complete image processing pipeline with CLIP integration.\"\"\"\n    \n    def __init__(self):\n        self.clip_model, self.clip_preprocess = clip.load(\"ViT-B/32\")\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.clip_model = self.clip_model.to(self.device)\n    \n    def extract_features(self, image_path: str) -> np.ndarray:\n        \"\"\"Extract CLIP image embeddings.\"\"\"\n        image = Image.open(image_path).convert('RGB')\n        image_tensor = self.clip_preprocess(image).unsqueeze(0).to(self.device)\n        \n        with torch.no_grad():\n            image_features = self.clip_model.encode_image(image_tensor)\n            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n        \n        return image_features.cpu().numpy().flatten()\n    \n    def extract_text(self, image_path: str) -> str:\n        \"\"\"Extract text from image using OCR.\"\"\"\n        try:\n            import pytesseract\n            image = Image.open(image_path)\n            return pytesseract.image_to_string(image)\n        except ImportError:\n            return \"\"  # OCR not available\n\nclass AudioProcessor:\n    \"\"\"Complete audio processing with transcription and feature extraction.\"\"\"\n    \n    def __init__(self):\n        self.whisper_model = whisper.load_model(\"base\")\n        self.sample_rate = 16000\n    \n    def transcribe_audio(self, audio_path: str) -> str:\n        \"\"\"Transcribe audio to text using Whisper.\"\"\"\n        result = self.whisper_model.transcribe(audio_path)\n        return result[\"text\"]\n    \n    def extract_audio_features(self, audio_path: str) -> np.ndarray:\n        \"\"\"Extract acoustic features from audio.\"\"\"\n        audio, sr = librosa.load(audio_path, sr=self.sample_rate)\n        \n        # Extract multiple feature types\n        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n        zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)\n        \n        # Combine features\n        features = np.concatenate([\n            np.mean(mfccs.T, axis=0),\n            np.mean(spectral_centroids.T, axis=0),\n            np.mean(zero_crossing_rate.T, axis=0)\n        ])\n        \n        return features\n\nclass VideoProcessor:\n    \"\"\"Complete video processing pipeline.\"\"\"\n    \n    def __init__(self):\n        self.image_processor = ImageProcessor()\n        self.audio_processor = AudioProcessor()\n    \n    def extract_frames(self, video_path: str, max_frames: int = 10) -> List[np.ndarray]:\n        \"\"\"Extract representative frames from video.\"\"\"\n        cap = cv2.VideoCapture(video_path)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        \n        # Select evenly spaced frames\n        frame_indices = np.linspace(0, total_frames-1, max_frames, dtype=int)\n        frames = []\n        \n        for frame_idx in frame_indices:\n            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n            ret, frame = cap.read()\n            if ret:\n                # Save frame temporarily and process with image processor\n                temp_path = f\"/tmp/frame_{frame_idx}.jpg\"\n                cv2.imwrite(temp_path, frame)\n                frame_features = self.image_processor.extract_features(temp_path)\n                frames.append(frame_features)\n        \n        cap.release()\n        return frames\n    \n    def extract_audio_track(self, video_path: str) -> Optional[str]:\n        \"\"\"Extract audio track from video for transcription.\"\"\"\n        try:\n            import moviepy.editor as mp\n            video = mp.VideoFileClip(video_path)\n            if video.audio:\n                audio_path = \"/tmp/extracted_audio.wav\"\n                video.audio.write_audiofile(audio_path)\n                return self.audio_processor.transcribe_audio(audio_path)\n        except ImportError:\n            pass\n        return None\n```\n\n#### Core Multi-Modal Encoder Skeleton\n\nThe core logic that learners should implement, with detailed TODO mapping to algorithmic steps:\n\n```python\nclass MultiModalEncoder:\n    \"\"\"\n    Multi-modal document encoder that creates unified embeddings across content types.\n    Integrates text, image, audio, and video processing into semantic search pipeline.\n    \"\"\"\n    \n    def __init__(self, text_model_name: str = \"all-MiniLM-L6-v2\"):\n        # Complete infrastructure provided above\n        self.text_encoder = SentenceTransformer(text_model_name)\n        self.image_processor = ImageProcessor()\n        self.audio_processor = AudioProcessor()\n        self.video_processor = VideoProcessor()\n        self.media_detector = MediaTypeDetector()\n    \n    def encode_multimodal_content(self, content: MediaContent) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Generate embeddings for multi-modal content with cross-modal alignment.\n        Returns dictionary mapping modality names to embedding vectors.\n        \"\"\"\n        # TODO 1: Validate content using MediaTypeDetector.validate_content()\n        # TODO 2: For text content, generate embedding using self.text_encoder.encode()\n        # TODO 3: For image content, extract visual features using self.image_processor.extract_features()\n        # TODO 4: For image content, extract OCR text using self.image_processor.extract_text()\n        # TODO 5: For audio content, transcribe using self.audio_processor.transcribe_audio()\n        # TODO 6: For audio content, extract acoustic features using self.audio_processor.extract_audio_features()\n        # TODO 7: For video content, extract frames using self.video_processor.extract_frames()\n        # TODO 8: For video content, extract audio track using self.video_processor.extract_audio_track()\n        # TODO 9: Combine all text sources (original + OCR + transcription) into unified text\n        # TODO 10: Generate cross-modal aligned embedding by weighted combination of modality embeddings\n        # Hint: Use different weights for primary modality vs extracted text/features\n        # Hint: Normalize each modality embedding before combination\n        pass\n    \n    def create_unified_embedding(self, modal_embeddings: Dict[str, np.ndarray], \n                                primary_modality: str) -> np.ndarray:\n        \"\"\"\n        Combine embeddings from different modalities into unified cross-modal embedding.\n        Primary modality receives higher weight in combination.\n        \"\"\"\n        # TODO 1: Define weights for each modality (primary=0.6, text=0.3, others=0.1 each)\n        # TODO 2: Normalize each embedding vector to unit length using normalize_vector()\n        # TODO 3: Apply modality-specific weights to normalized embeddings\n        # TODO 4: Sum weighted embeddings to create unified representation\n        # TODO 5: Normalize final unified embedding to unit length\n        # TODO 6: Handle case where primary modality is missing by adjusting weights\n        # Hint: Ensure final embedding has same dimensionality as text embeddings\n        # Hint: Consider adding small random noise to prevent identical embeddings\n        pass\n\nclass SemanticFilterProcessor:\n    \"\"\"\n    Semantic filtering implementation using concept vectors and embedding similarity.\n    Enables filtering by abstract concepts rather than explicit metadata.\n    \"\"\"\n    \n    def __init__(self, text_encoder: SentenceTransformer):\n        self.text_encoder = text_encoder\n        self.concept_cache = {}  # Cache for concept vectors\n        \n    def create_concept_filter(self, concept_description: str, \n                            example_docs: Optional[List[str]] = None) -> np.ndarray:\n        \"\"\"\n        Create concept vector from natural language description and optional examples.\n        Concept vector defines region in embedding space matching the concept.\n        \"\"\"\n        # TODO 1: Check if concept already cached, return if found\n        # TODO 2: Generate embedding from concept_description using text_encoder\n        # TODO 3: If example_docs provided, generate embeddings for each example\n        # TODO 4: Combine concept description embedding with example embeddings (weighted average)\n        # TODO 5: Normalize final concept vector to unit length\n        # TODO 6: Cache concept vector for future use\n        # TODO 7: Return concept vector as filter representation\n        # Hint: Weight concept description 0.4, examples 0.6 if both provided\n        # Hint: Use centroid of example embeddings as example representation\n        pass\n    \n    def apply_semantic_filter(self, document_embeddings: np.ndarray,\n                             concept_filter: np.ndarray,\n                             similarity_threshold: float = 0.6) -> np.ndarray:\n        \"\"\"\n        Filter documents by semantic similarity to concept vector.\n        Returns boolean mask indicating which documents match concept.\n        \"\"\"\n        # TODO 1: Compute cosine similarity between each document and concept filter\n        # TODO 2: Apply similarity threshold to create boolean mask\n        # TODO 3: Consider soft filtering with similarity-based weights instead of hard threshold\n        # TODO 4: Return boolean mask or similarity scores based on filtering mode\n        # Hint: Use np.dot() for efficient batch cosine similarity computation\n        # Hint: Higher threshold = more restrictive filtering\n        pass\n\nclass ConversationManager:\n    \"\"\"\n    Conversational search session management with context tracking.\n    Maintains dialogue state and contextualizes queries across conversation turns.\n    \"\"\"\n    \n    def __init__(self, max_context_turns: int = 10):\n        self.sessions = {}  # session_id -> ConversationSession\n        self.max_context_turns = max_context_turns\n        \n    def contextualize_query(self, session_id: str, raw_query: str) -> str:\n        \"\"\"\n        Transform raw query using conversational context from session history.\n        Resolves pronouns, maintains topic continuity, handles follow-up questions.\n        \"\"\"\n        # TODO 1: Retrieve conversation session or create new one\n        # TODO 2: Identify query type (new_topic, follow_up, clarification, refinement)\n        # TODO 3: For follow-up queries, extract relevant context from recent turns\n        # TODO 4: Resolve pronouns and references using conversation context\n        # TODO 5: Expand abbreviated queries with topic context\n        # TODO 6: Maintain topic coherence by combining query with active topics\n        # TODO 7: Update conversation session with new turn information\n        # TODO 8: Return contextualized query suitable for semantic search\n        # Hint: Use simple heuristics like pronoun detection and keyword overlap for context\n        # Hint: Recent turns (last 2-3) more important than distant conversation history\n        pass\n    \n    def suggest_clarifications(self, session_id: str, query: str, \n                              search_results: List[SearchResult]) -> List[str]:\n        \"\"\"\n        Generate clarification questions when query is ambiguous or results are diverse.\n        Helps users refine their search intent through guided dialogue.\n        \"\"\"\n        # TODO 1: Analyze search results for topic diversity using clustering\n        # TODO 2: Identify potential ambiguities in query (multiple interpretations)\n        # TODO 3: Generate clarification questions for each major result cluster\n        # TODO 4: Consider user's conversation history to avoid repeated clarifications\n        # TODO 5: Rank clarification questions by potential impact on result quality\n        # TODO 6: Return top 2-3 most useful clarification questions\n        # Hint: Use embedding clustering to identify distinct result topics\n        # Hint: Frame clarifications as specific choices rather than open-ended questions\n        pass\n```\n\n#### Distributed System Infrastructure\n\nComplete working implementation of coordination and health monitoring for distributed indexing:\n\n```python\n\"\"\"\nDistributed indexing infrastructure with coordination and monitoring.\nProvides production-ready components for managing distributed vector indices.\n\"\"\"\n\nimport asyncio\nimport hashlib\nimport time\nfrom typing import Dict, List, Optional, Set\nfrom dataclasses import dataclass\nimport redis\nimport json\nimport numpy as np\n\n@dataclass\nclass ShardInfo:\n    \"\"\"Information about an individual index shard.\"\"\"\n    shard_id: str\n    host: str\n    port: int\n    document_count: int\n    last_heartbeat: float\n    is_healthy: bool = True\n    load_score: float = 0.0  # 0.0 = idle, 1.0 = fully loaded\n\n@dataclass\nclass QueryRoute:\n    \"\"\"Query routing decision with confidence scores.\"\"\"\n    target_shards: List[str]\n    confidence_scores: Dict[str, float]\n    routing_strategy: str\n    estimated_cost: float\n\nclass DistributedCoordinator:\n    \"\"\"Complete coordination system for distributed vector search.\"\"\"\n    \n    def __init__(self, redis_host: str = \"localhost\", redis_port: int = 6379):\n        self.redis_client = redis.Redis(host=redis_host, port=redis_port)\n        self.shard_registry: Dict[str, ShardInfo] = {}\n        self.health_check_interval = 30  # seconds\n        self.load_balance_threshold = 0.8\n        \n    async def register_shard(self, shard_info: ShardInfo):\n        \"\"\"Register new shard in distributed system.\"\"\"\n        self.shard_registry[shard_info.shard_id] = shard_info\n        \n        # Store shard info in Redis for persistence\n        shard_data = {\n            'host': shard_info.host,\n            'port': shard_info.port,\n            'document_count': shard_info.document_count,\n            'registered_at': time.time()\n        }\n        self.redis_client.hset(f\"shard:{shard_info.shard_id}\", mapping=shard_data)\n        \n        # Start health monitoring for new shard\n        asyncio.create_task(self._monitor_shard_health(shard_info.shard_id))\n    \n    async def _monitor_shard_health(self, shard_id: str):\n        \"\"\"Monitor individual shard health and performance.\"\"\"\n        while shard_id in self.shard_registry:\n            try:\n                shard = self.shard_registry[shard_id]\n                \n                # Simple health check (could be HTTP ping, Redis ping, etc.)\n                health_key = f\"shard_health:{shard_id}\"\n                last_ping = self.redis_client.get(health_key)\n                \n                if last_ping:\n                    time_since_ping = time.time() - float(last_ping)\n                    shard.is_healthy = time_since_ping < self.health_check_interval * 2\n                    shard.last_heartbeat = float(last_ping)\n                else:\n                    shard.is_healthy = False\n                \n                # Update load score based on query volume\n                load_key = f\"shard_load:{shard_id}\"\n                recent_queries = self.redis_client.llen(load_key)\n                shard.load_score = min(recent_queries / 100.0, 1.0)  # Normalize to 0-1\n                \n            except Exception as e:\n                print(f\"Health check failed for shard {shard_id}: {e}\")\n                self.shard_registry[shard_id].is_healthy = False\n            \n            await asyncio.sleep(self.health_check_interval)\n    \n    def get_healthy_shards(self) -> List[ShardInfo]:\n        \"\"\"Return list of currently healthy shards.\"\"\"\n        return [shard for shard in self.shard_registry.values() if shard.is_healthy]\n    \n    def estimate_shard_relevance(self, query_embedding: np.ndarray, \n                                shard_id: str) -> float:\n        \"\"\"Estimate how relevant a shard is for given query (simplified).\"\"\"\n        # In production, this would use learned routing models\n        # For now, use simple heuristic based on shard characteristics\n        shard = self.shard_registry.get(shard_id)\n        if not shard or not shard.is_healthy:\n            return 0.0\n        \n        # Favor shards with more documents (more likely to have relevant content)\n        # but penalize overloaded shards\n        relevance_score = min(shard.document_count / 10000.0, 1.0)\n        load_penalty = 1.0 - (shard.load_score * 0.3)  # 30% penalty for full load\n        \n        return relevance_score * load_penalty\n\nclass QueryRouter:\n    \"\"\"Intelligent query routing for distributed search.\"\"\"\n    \n    def __init__(self, coordinator: DistributedCoordinator):\n        self.coordinator = coordinator\n        self.default_shard_count = 3  # Query top 3 shards by default\n        self.min_confidence_threshold = 0.3\n        \n    def route_query(self, query_embedding: np.ndarray, \n                   max_shards: Optional[int] = None) -> QueryRoute:\n        \"\"\"\n        Determine which shards to query for optimal results.\n        Balances recall (finding all relevant docs) with performance (fewer shards).\n        \"\"\"\n        healthy_shards = self.coordinator.get_healthy_shards()\n        \n        if not healthy_shards:\n            return QueryRoute([], {}, \"emergency_fallback\", float('inf'))\n        \n        # Calculate relevance scores for all healthy shards\n        shard_scores = {}\n        for shard in healthy_shards:\n            relevance = self.coordinator.estimate_shard_relevance(\n                query_embedding, shard.shard_id\n            )\n            if relevance >= self.min_confidence_threshold:\n                shard_scores[shard.shard_id] = relevance\n        \n        # Select top shards up to max_shards limit\n        target_count = min(max_shards or self.default_shard_count, len(shard_scores))\n        selected_shards = sorted(shard_scores.keys(), \n                               key=lambda x: shard_scores[x], \n                               reverse=True)[:target_count]\n        \n        # Calculate estimated query cost\n        estimated_cost = sum(\n            self.coordinator.shard_registry[shard_id].document_count * 0.001\n            for shard_id in selected_shards\n        )\n        \n        return QueryRoute(\n            target_shards=selected_shards,\n            confidence_scores={shard_id: shard_scores[shard_id] for shard_id in selected_shards},\n            routing_strategy=\"relevance_based\",\n            estimated_cost=estimated_cost\n        )\n```\n\n#### Real-Time Update System Skeleton\n\nCore update pipeline logic that learners implement:\n\n```python\nclass RealTimeUpdatePipeline:\n    \"\"\"\n    Real-time document update pipeline with multi-tier indexing.\n    Provides immediate search visibility while maintaining optimized performance.\n    \"\"\"\n    \n    def __init__(self, fast_index, main_index, consolidation_threshold: int = 1000):\n        self.fast_index = fast_index  # Write-optimized for recent docs\n        self.main_index = main_index  # Read-optimized for stable docs\n        self.consolidation_threshold = consolidation_threshold\n        self.update_queue = asyncio.Queue()\n        \n    async def process_document_update(self, document: Document, \n                                    operation: str = \"upsert\") -> bool:\n        \"\"\"\n        Process single document update with immediate search visibility.\n        Returns True if update completed successfully.\n        \"\"\"\n        # TODO 1: Validate document and operation type (upsert, delete, update)\n        # TODO 2: Generate embedding for document using existing DocumentEncoder\n        # TODO 3: Add document to fast_index for immediate search visibility\n        # TODO 4: Queue document for background processing and quality enrichment\n        # TODO 5: Check if consolidation threshold reached (fast_index too large)\n        # TODO 6: If threshold reached, trigger background consolidation to main_index\n        # TODO 7: Update search analytics and monitoring metrics\n        # TODO 8: Return success/failure status with error details if failed\n        # Hint: Use try-catch around index operations for graceful error handling\n        # Hint: Log document_id and timestamp for debugging update issues\n        pass\n    \n    async def consolidate_indices(self) -> bool:\n        \"\"\"\n        Move stabilized documents from fast_index to optimized main_index.\n        Maintains search performance by keeping main_index read-optimized.\n        \"\"\"\n        # TODO 1: Get list of documents eligible for consolidation (age > threshold)\n        # TODO 2: Extract embeddings and metadata from fast_index for eligible docs\n        # TODO 3: Perform batch insertion into main_index with full optimization\n        # TODO 4: Verify successful insertion by checking document searchability\n        # TODO 5: Remove consolidated documents from fast_index\n        # TODO 6: Update index statistics and capacity metrics\n        # TODO 7: Schedule next consolidation based on current growth rate\n        # TODO 8: Handle partial failures by rolling back incomplete consolidation\n        # Hint: Process in batches to avoid memory issues with large consolidations\n        # Hint: Use atomic operations where possible to maintain consistency\n        pass\n    \n    async def handle_embedding_model_update(self, new_model_name: str) -> bool:\n        \"\"\"\n        Coordinate system-wide embedding model update without service interruption.\n        Gradually transitions all documents to new embedding model.\n        \"\"\"\n        # TODO 1: Validate new embedding model can be loaded and is compatible\n        # TODO 2: Create new DocumentEncoder instance with updated model\n        # TODO 3: Begin processing new documents with updated model\n        # TODO 4: Schedule background re-processing of existing documents in batches\n        # TODO 5: Maintain dual-model search capability during transition period\n        # TODO 6: Monitor search quality metrics during model transition\n        # TODO 7: Complete transition when all documents use new model\n        # TODO 8: Clean up old embeddings and update system configuration\n        # Hint: Process oldest documents first to minimize quality impact\n        # Hint: Use feature flags to control rollout speed and enable rollback\n        pass\n```\n\n#### Milestone Checkpoints for Future Extensions\n\nAfter implementing each extension component, verify expected behavior:\n\n**Multi-Modal Search Checkpoint:**\n- Command: `python test_multimodal.py --test-image sample.jpg --test-audio sample.wav`\n- Expected: System generates embeddings for image and audio, enables cross-modal search\n- Verification: Upload image of car, search \"red vehicle\" should return the image\n- Debug: Check embedding dimensions match, verify CLIP model loaded correctly\n\n**Semantic Filtering Checkpoint:**\n- Command: `python test_filters.py --concept \"beginner-friendly\" --sample-docs docs/`\n- Expected: Documents filtered by conceptual similarity rather than keyword matching\n- Verification: Filter for \"technical complexity\" should separate simple vs advanced docs\n- Debug: Check concept vectors are normalized, verify similarity threshold tuning\n\n**Conversational Search Checkpoint:**\n- Command: `python test_conversation.py --session-id test123`\n- Expected: Follow-up queries maintain context, pronouns resolve correctly\n- Verification: Search \"python\", then \"what about functions?\" should understand context\n- Debug: Check session state persistence, verify context window management\n\n**Distributed Indexing Checkpoint:**\n- Command: `python test_distributed.py --shards 3 --queries 100`\n- Expected: Queries route to appropriate shards, results aggregate correctly\n- Verification: All shards should receive health checks, query routing should balance load\n- Debug: Check Redis connectivity, verify shard registration and heartbeat system\n\n\n## Glossary\n\n> **Milestone(s):** This section provides foundational understanding for all milestones (1-4), defining the technical terms, algorithms, and domain-specific vocabulary used throughout the semantic search engine design and implementation.\n\nThis glossary serves as the authoritative reference for understanding the specialized terminology, algorithms, and concepts that form the foundation of our semantic search engine. Think of this glossary as your **technical dictionary** — just as a traditional dictionary helps you understand unfamiliar words when reading literature, this glossary helps you understand unfamiliar technical concepts when implementing semantic search. Each term includes not only its definition but also its context within our system and relationships to other concepts.\n\nThe terminology is organized into logical categories to help you build understanding progressively, from fundamental search concepts through advanced algorithmic techniques to implementation-specific details.\n\n### Core Search Concepts\n\nThe foundational concepts that distinguish different approaches to information retrieval and establish the vocabulary for discussing search system behavior.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **lexical search** | Keyword-based search using inverted indexes that matches exact terms and variations | Traditional search approach we're enhancing with semantic understanding |\n| **semantic search** | Meaning-based search using vector embeddings that understands conceptual similarity | Primary search paradigm our system implements |\n| **vocabulary mismatch** | When users and documents use different terms for same concepts | Core problem that semantic search solves through embedding similarity |\n| **inverted index** | Data structure mapping terms to documents containing them | Used in BM25 scoring component of our hybrid search approach |\n| **hybrid search** | Combining lexical and semantic search approaches | Our ranking strategy that merges BM25 and vector similarity scores |\n| **zero-result queries** | Searches returning no matches requiring analysis | Tracked in our analytics to identify content gaps and query understanding issues |\n| **query expansion** | Adding synonyms and related terms to improve recall | Implemented in our `QueryProcessor` to broaden search coverage |\n| **semantic drift** | When expansion strays from original query meaning | Risk we mitigate through controlled expansion and confidence scoring |\n\n### Vector Embeddings and Similarity\n\nThe mathematical foundation of semantic search, covering how text is transformed into numerical representations and how similarity is computed.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **vector embedding** | Dense numerical representation of text | Core data structure produced by `DocumentEncoder` and stored in our index |\n| **embedding dimension** | Number of components in a vector embedding | Set to 384 for our default all-MiniLM-L6-v2 model, stored as `EMBEDDING_DIM` |\n| **cosine similarity** | Measure of vector similarity based on angle between vectors | Primary similarity metric implemented in `cosine_similarity()` function |\n| **vector normalization** | Scaling vectors to unit length for consistent similarity computation | Performed by `normalize_vector()` to enable cosine similarity calculation |\n| **vector arithmetic** | Mathematical operations on embedding vectors | Used in multi-vector queries and negative term handling |\n| **embedding space** | High-dimensional space where similar concepts are located near each other | The mathematical space our FAISS index organizes for efficient search |\n\n### Approximate Nearest Neighbor Search\n\nThe algorithmic techniques that enable efficient similarity search over large collections of high-dimensional vectors.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **approximate nearest neighbor** | Efficient algorithm for finding similar vectors with controlled accuracy trade-offs | Core algorithm powering our FAISS-based `EmbeddingIndex` |\n| **HNSW** | Hierarchical Navigable Small World graph for vector search | One of two index algorithms we support, optimized for query speed |\n| **IVF** | Inverted File indexing that partitions vectors into clusters | Alternative index algorithm we support, optimized for memory efficiency |\n| **index training** | Process of learning optimal data structure parameters from sample data | Required for IVF indices before document vectors can be added |\n| **index persistence** | Saving trained indices to disk for recovery and deployment | Handled through FAISS serialization in our index management layer |\n| **incremental updates** | Adding new vectors without full index reconstruction | Supported through FAISS add operations with periodic consolidation |\n\n### Query Understanding and Processing\n\nThe techniques for analyzing, enhancing, and interpreting user search queries to improve result relevance.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **entity recognition** | Identifying proper nouns and technical terms in queries | Part of our `QueryProcessor` pipeline for preserving important terms |\n| **intent classification** | Understanding what type of search the user wants | Helps our system route queries and select appropriate processing strategies |\n| **multi-vector query** | Complex query with multiple semantic aspects | Handled by `handle_multi_vector_query()` to decompose and weight query components |\n| **query normalization** | Standardizing query text format for consistent processing | Performed by `TextNormalizer` to enable effective caching and processing |\n| **query sanitization** | Cleaning and normalizing user input for safe processing | Implemented in `validate_and_sanitize()` to handle malformed input |\n| **unicode normalization** | Standardizing character representations for consistent processing | Part of query sanitization to handle international text correctly |\n| **intelligent truncation** | Shortening queries while preserving important terms | Strategy for handling queries exceeding `MAX_QUERY_LENGTH` |\n\n### Ranking and Relevance\n\nThe algorithms and strategies for ordering search results by relevance, combining multiple signals to optimize user satisfaction.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **BM25** | Ranking function for lexical search based on term frequency and document length | Lexical scoring component in our hybrid `RankingEngine` |\n| **cross-encoder reranking** | Precise but expensive ranking using transformer models | Second-stage ranking applied to top candidates for maximum accuracy |\n| **multi-stage ranking** | Ranking pipeline with fast retrieval then precise reranking | Our performance optimization strategy balancing speed and quality |\n| **position bias** | Tendency to click higher-ranked results regardless of relevance | Bias we account for in click-through learning algorithms |\n| **click-through learning** | Using user interaction data to improve ranking | Implemented through `record_interaction()` and score adjustments |\n| **personalization signals** | User context factors for customized ranking | Processed through `PersonalizationContext` for tailored results |\n| **freshness decay** | Time-based relevance score reduction | Applied to boost recent documents while aging older content |\n| **learning to rank** | Machine learning approach to optimize ranking functions | Framework for incorporating click data into our scoring model |\n\n### Search API and User Experience\n\nThe interface design patterns and performance characteristics that define how users interact with the search system.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **autocomplete** | Typeahead suggestions with sub-100ms latency | Provided by `get_autocomplete_suggestions()` with strict timing requirements |\n| **faceted navigation** | Category filtering with filter counts per category | Implemented through `compute_facets()` for structured result exploration |\n| **query term highlighting** | Marking matched words in result snippets | Performed by `highlight_query_terms()` to show relevance visually |\n| **search analytics** | Query tracking and result quality metrics | Collected through `record_search_analytics()` for system improvement |\n| **response time SLA** | Service level agreement for API response latency | Target of sub-500ms for search, sub-100ms for autocomplete |\n| **rate limiting** | Request throttling to prevent abuse | Protection mechanism for production API deployment |\n| **correlation ID** | Unique identifier linking user reports to internal logs | Generated in `create_context()` for debugging and support |\n\n### System Reliability and Error Handling\n\nThe patterns and techniques for building robust, fault-tolerant search systems that gracefully handle failures and edge cases.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **graceful degradation** | Maintaining basic functionality when advanced features fail | Strategy for handling component failures while preserving core search |\n| **circuit breaker** | Pattern preventing cascading failures by disabling failing components | Implemented in our component interaction layer for fault isolation |\n| **exponential backoff** | Retry strategy with increasing delays between attempts | Used in our retry mechanisms to avoid overwhelming failing services |\n| **timeout budget** | Allocated time limit for different processing stages | Managed through `ContextInfo` to ensure responsive user experience |\n| **fallback strategy** | Alternative processing approach when primary method fails | Implemented for each component to provide degraded but functional service |\n| **fault tolerance** | System's ability to continue operating despite component failures | Overall design principle ensuring search availability during partial outages |\n| **component unavailability** | Temporary or permanent failure of system components | Handled through circuit breakers and fallback mechanisms |\n| **partial results** | Incomplete search results returned when some components fail | Strategy for maintaining user experience during degraded system state |\n\n### Performance and Evaluation Metrics\n\nThe quantitative measures used to assess search quality, system performance, and user satisfaction.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **precision at k** | Fraction of top k results that are relevant | Primary relevance metric calculated by `calculate_precision_at_k()` |\n| **recall at k** | Fraction of relevant documents found in top k | Completeness metric for evaluating search coverage |\n| **NDCG** | Normalized discounted cumulative gain ranking metric | Gold standard ranking metric computed by `calculate_ndcg()` |\n| **MAP** | Mean average precision across all queries | Overall search quality metric for system evaluation |\n| **MRR** | Mean reciprocal rank of first relevant result | Metric focusing on finding the best result quickly |\n| **ground truth** | Expert judgments of query-document relevance | Reference data for training and evaluating our ranking algorithms |\n| **relevance metrics** | Quantitative measures of search result quality | Suite of metrics for comprehensive search quality assessment |\n| **throughput** | Requests per second the system can handle | Performance metric measured in our load testing framework |\n| **latency percentiles** | Response time distribution measurements | Key SLA metrics including p50, p95, and p99 response times |\n\n### Caching and Performance Optimization\n\nThe strategies for improving system performance through intelligent data storage and retrieval patterns.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **cache invalidation** | Removing stale cached data when underlying data changes | Critical for maintaining consistency in our `EmbeddingCache` |\n| **query embedding cache** | Storing computed query vectors for repeated lookups | Performance optimization in `EmbeddingCache` for common queries |\n| **cache hit ratio** | Percentage of requests served from cache vs computed fresh | Key performance metric for evaluating cache effectiveness |\n| **TTL** | Time-to-live expiration for cached data | Configured in cache to balance freshness and performance |\n| **LRU eviction** | Least recently used cache replacement policy | Strategy for managing cache memory limits |\n| **cache warming** | Preloading cache with anticipated data | Strategy for reducing cold start latency |\n| **memory-mapped access** | Direct file system access for large datasets | Enables processing datasets larger than available RAM |\n\n### Advanced Search Features\n\nThe sophisticated capabilities that extend basic semantic search into specialized domains and use cases.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **multi-modal search** | Search capability across text, image, audio, and video content | Advanced feature using `MultiModalEncoder` for unified embeddings |\n| **cross-modal alignment** | Mapping different media types to comparable embedding spaces | Technique enabling search across different content types |\n| **semantic filtering** | Filtering by abstract concepts rather than explicit metadata | Advanced capability using `ConceptFilter` for conceptual constraints |\n| **conversational search** | Multi-turn search dialogue with context maintenance | Sophisticated interaction pattern managed by `ConversationManager` |\n| **context window** | Number of previous conversation turns maintained | Configured as `MAX_CONTEXT_TURNS` for conversational coherence |\n| **query contextualization** | Transforming queries based on conversation history | Process of understanding queries in conversational context |\n\n### Distributed Systems and Scaling\n\nThe architectural patterns and techniques for scaling semantic search across multiple machines and data centers.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **distributed indexing** | Partitioning vector indices across multiple nodes | Scaling strategy for handling large document collections |\n| **search federation** | Coordinating search across multiple independent systems | Architecture for unified search across heterogeneous sources |\n| **query routing** | Selecting optimal subset of shards for each search query | Performance optimization managed by `QueryRouter` |\n| **result harmonization** | Normalizing relevance scores across heterogeneous sources | Process ensuring consistent scoring across federated sources |\n| **shard balancing** | Distributing load evenly across index partitions | Strategy for optimal resource utilization in distributed deployment |\n| **real-time updates** | Immediate document visibility without batch processing delays | Advanced capability for dynamic content environments |\n| **index consolidation** | Periodic merging of incremental updates into main index | Maintenance process optimizing search performance |\n| **hot-cold storage** | Tiered storage strategy based on access patterns | Cost optimization for large-scale deployments |\n\n### Data Structures and Implementation Details\n\nThe specific technical constructs and patterns used in the system implementation.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **embedding model** | Neural network that converts text to vector representations | Implemented using Sentence Transformers with `DEFAULT_MODEL` |\n| **model checkpoint** | Saved state of trained neural network | Used for consistent embedding generation across system restarts |\n| **batch processing** | Processing multiple items together for efficiency | Strategy used in `encode_texts()` for optimal GPU utilization |\n| **memory fragmentation** | Inefficient memory allocation causing out-of-memory despite sufficient total memory | Common issue in vector processing requiring careful memory management |\n| **index corruption** | Data integrity issues in vector index requiring recovery | Failure mode detected through health checks and requiring index rebuild |\n| **dimension mismatch** | Inconsistency between expected and actual vector sizes | Common bug caught in our validation and debugging framework |\n| **ID mapping** | Association between external document identifiers and internal index positions | Critical consistency requirement managed by our indexing layer |\n\n### Machine Learning and Model Management\n\nThe concepts related to training, deploying, and maintaining the machine learning models that power semantic understanding.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **embedding model update** | Transitioning to new embedding models without service interruption | Complex process requiring coordinated re-embedding and index rebuilding |\n| **model drift** | Degradation in model performance over time due to data changes | Monitoring concern for maintaining search quality |\n| **transfer learning** | Using pre-trained models for specific domains | Strategy for adapting general language models to specialized content |\n| **fine-tuning** | Adjusting pre-trained models for specific tasks or domains | Potential improvement for domain-specific search applications |\n| **model versioning** | Tracking different versions of embedding models | Essential for reproducible results and coordinated updates |\n| **A/B testing** | Comparing performance of different models or algorithms | Strategy for validating improvements before full deployment |\n\n### Quality Assurance and Testing\n\nThe methodologies and techniques for ensuring search system reliability, performance, and user satisfaction.\n\n| Term | Definition | Context in Our System |\n|------|------------|----------------------|\n| **relevance evaluation** | Systematic assessment of search result quality | Process using human judgment and automated metrics |\n| **load testing** | Performance testing under realistic traffic patterns | Implemented through `run_concurrent_load_test()` |\n| **regression testing** | Detecting performance degradation from system changes | Automated testing preventing quality regressions |\n| **golden dataset** | Curated test queries with known correct results | Reference collection for validating search improvements |\n| **stress testing** | Evaluating system behavior under extreme conditions | Testing approach for identifying breaking points |\n| **canary deployment** | Gradual rollout to detect issues before full deployment | Risk mitigation strategy for production updates |\n\n### Constants and Configuration\n\nThe specific values and settings that control system behavior and performance characteristics.\n\n| Term | Definition | Value/Context |\n|------|------------|---------------|\n| **DEFAULT_MODEL** | Primary sentence transformer model for embeddings | `all-MiniLM-L6-v2` - balanced performance and quality |\n| **EMBEDDING_DIM** | Dimensionality of vector embeddings | `384` dimensions for our default model |\n| **MAX_QUERY_LENGTH** | Maximum allowed query length in characters | `500` characters to prevent processing issues |\n| **AUTOCOMPLETE_TIMEOUT_MS** | Response time limit for autocomplete suggestions | `100` milliseconds for responsive user experience |\n| **SEARCH_TIMEOUT_MS** | Response time limit for search requests | `500` milliseconds for acceptable user experience |\n| **DEFAULT_MAX_RESULTS** | Standard number of results returned per search | `20` results balancing completeness and performance |\n| **MIN_KEYWORD_LENGTH** | Minimum length for keywords to be indexed | `3` characters to filter noise terms |\n| **FACET_COMPUTATION_LIMIT** | Maximum results to consider for facet counting | `1000` documents to balance accuracy and performance |\n\nThis comprehensive glossary provides the shared vocabulary necessary for understanding, implementing, and maintaining our semantic search engine. Each term connects to specific components, algorithms, or design decisions documented throughout this design document, enabling precise technical communication and reducing ambiguity during development and operations.\n\n### Implementation Guidance\n\nThe glossary serves not only as a reference during system design but also as a critical resource during implementation. Each technical term corresponds to specific code constructs, configuration parameters, or algorithmic implementations in your semantic search system.\n\n**Using the Glossary During Development:**\n\nWhen implementing each milestone, refer to this glossary to ensure consistent terminology and understanding across your codebase. For example, when working on Milestone 1 (Embedding Index), terms like \"vector normalization,\" \"HNSW,\" and \"index persistence\" directly correspond to functions and design decisions you'll need to implement.\n\n**Code Comments and Documentation:**\n\nUse these standardized terms in your code comments and documentation to maintain consistency with this design document. For instance, when implementing the `normalize_vector()` function, your comment should reference \"L2 normalization for cosine similarity computation\" using the vocabulary established here.\n\n**Debugging and Troubleshooting:**\n\nWhen investigating issues, this glossary helps translate between observed symptoms and underlying technical causes. If you observe \"poor result quality,\" you can trace through related terms like \"semantic drift,\" \"position bias,\" or \"vocabulary mismatch\" to identify potential root causes.\n\n**Team Communication:**\n\nThis shared vocabulary enables precise communication between team members. Instead of vague descriptions like \"the search isn't working well,\" team members can use specific terms like \"we're seeing high semantic drift in query expansion\" or \"the circuit breaker is triggering due to embedding model timeouts.\"\n\nThe terminology in this glossary represents industry-standard concepts and our system-specific implementations, ensuring your semantic search engine aligns with established practices while maintaining internal consistency throughout development and operations.\n"}