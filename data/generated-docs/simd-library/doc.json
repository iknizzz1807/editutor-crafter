{"html":"<h1 id=\"simd-optimization-library-atlas\">SIMD Optimization Library Atlas</h1>\n<p>A comprehensive blueprint for a high-performance SIMD library utilizing SSE, AVX2, and AVX-512 intrinsics to accelerate string search, memory operations, and checksum calculations through hardware-level parallelism.</p>\n<div id=\"ms-cpu-dispatch\"></div>\n\n<h1 id=\"dynamic-cpu-feature-dispatching-the-universal-translator\">Dynamic CPU Feature Dispatching: The Universal Translator</h1>\n<p>Imagine you are a world-class chef traveling to different kitchens. In a basic kitchen, you only have a hand-knife (Scalar code). In a modern kitchen, you might find a food processor (SSE). In a professional industrial kitchen, you have a high-speed industrial slicer (AVX-512). </p>\n<p>If you try to plug your industrial slicer into a basic kitchen&#39;s outlet, you’ll blow a fuse (the program crashes with an <code>Illegal Instruction</code> error). <strong>Dynamic Dispatching</strong> is the process of walking into the kitchen, checking the equipment first, and then deciding which &quot;recipe&quot; (function implementation) to use for the rest of the night.</p>\n<h3 id=\"technical-rationale-the-quotwhyquot\">Technical Rationale: The &quot;Why&quot;</h3>\n<p>We write SIMD code to squeeze every drop of performance out of the hardware. However, hardware is fragmented. A user on a 2012 laptop has SSE4.2, while a user on a 2023 workstation has AVX-512. </p>\n<p>If we compile our program specifically for AVX-512, it won&#39;t run on 90% of computers. If we compile only for the &quot;lowest common denominator&quot; (Scalar), we waste the power of modern CPUs. Dynamic Dispatching allows us to ship <strong>one binary</strong> that detects the CPU at runtime and &quot;patches&quot; itself to use the fastest available instructions.</p>\n<blockquote>\n<p><strong>Quick Breakdown: Function Pointer</strong>\nThink of a standard function as a fixed path on a map. A <strong>Function Pointer</strong> is a signpost that you can turn. Initially, it points to a &quot;Detection&quot; function. Once the detection is done, you turn the signpost to point directly to the &quot;SSE&quot; or &quot;AVX&quot; version of the logic.</p>\n</blockquote>\n<hr>\n<h3 id=\"internal-mechanics-the-quothowquot\">Internal Mechanics: The &quot;How&quot;</h3>\n<p>The heart of this system is the <code>CPUID</code> instruction. This is a special CPU opcode that doesn&#39;t perform math; instead, it returns a &quot;map&quot; of the processor&#39;s soul into four general-purpose registers: <code>EAX</code>, <code>EBX</code>, <code>ECX</code>, and <code>EDX</code>.</p>\n<h4 id=\"the-microscope-bit-level-detection\">The Microscope: Bit-Level Detection</h4>\n<p>To detect AVX2 support, we don&#39;t just ask the CPU &quot;Are you fast?&quot; We perform a surgical bit-check:</p>\n<ol>\n<li>We call <code>CPUID</code> with <code>EAX</code> set to <code>7</code> (the &quot;leaf&quot; for extended features).</li>\n<li>The CPU fills <code>EBX</code> with a series of flags.</li>\n<li>We check <strong>Bit 5</strong> of the <code>EBX</code> register. If it&#39;s <code>1</code>, AVX2 is supported.</li>\n</ol>\n<p>However, there is a catch! Even if the CPU supports AVX, the Operating System (Windows/Linux) must also support saving the massive YMM/ZMM registers during context switches. We must check the <strong>XCR0 (Extended Control Register)</strong> to ensure the OS is &quot;SIMD-aware.&quot;</p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-02.svg\" alt=\"CPU Dispatcher Flow\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-03.svg\" alt=\"CPUID Leaf Analysis\"></p>\n<hr>\n<h3 id=\"the-debugging-lab-common-pitfalls\">The Debugging Lab: Common Pitfalls</h3>\n<ul>\n<li><strong>The &quot;Illegal Instruction&quot; Crash</strong>: This usually happens because you detected the CPU feature (e.g., AVX) but forgot to check if the OS supports it. The CPU says &quot;I can do it,&quot; but the OS says &quot;I don&#39;t know how to store those big registers,&quot; and kills the process.</li>\n<li><strong>The Dispatch Overhead</strong>: If you check the CPU features <em>inside</em> a loop that runs a million times, you&#39;ll destroy your performance.<ul>\n<li><em>The Fix</em>: Use a <strong>Static Initializer</strong> or a <strong>Function Pointer Patch</strong>. Check once at startup, set the pointer, and never check again.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"code-scaffold-the-dispatcher\">Code Scaffold: The Dispatcher</h3>\n<p>Below is the blueprint for your dispatcher. It uses a &quot;Lazy Initialization&quot; pattern to ensure we only check the CPU once.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">cpp</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;iostream></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cpuid.h></span><span style=\"color:#6A737D\"> // GCC/Clang header for __get_cpuid</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// 1. Define the function signature (The \"Recipe\")</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">typedef</span><span style=\"color:#F97583\"> void</span><span style=\"color:#E1E4E8\"> (*ProcessingFunc)(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> float*</span><span style=\"color:#FFAB70\"> input</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">float*</span><span style=\"color:#FFAB70\"> output</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// 2. The \"Slow &#x26; Safe\" Scalar Implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> Process_Scalar</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> float*</span><span style=\"color:#FFAB70\"> input</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">float*</span><span style=\"color:#FFAB70\"> output</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> count; </span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">i) output[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> input[i] </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 2.0</span><span style=\"color:#F97583\">f</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// 3. The \"High-Speed\" AVX Implementation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> Process_AVX</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> float*</span><span style=\"color:#FFAB70\"> input</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">float*</span><span style=\"color:#FFAB70\"> output</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Imagine __m256 registers and _mm256_add_ps intrinsics here</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    std</span><span style=\"color:#E1E4E8\">::cout </span><span style=\"color:#F97583\">&#x3C;&#x3C;</span><span style=\"color:#9ECBFF\"> \"[System] Using AVX Optimized Path</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// 4. The Dispatcher Logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> Processor</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">public:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    static</span><span style=\"color:#F97583\"> void</span><span style=\"color:#B392F0\"> Execute</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> float*</span><span style=\"color:#FFAB70\"> input</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">float*</span><span style=\"color:#FFAB70\"> output</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // This function pointer is the \"Signpost\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        static</span><span style=\"color:#E1E4E8\"> ProcessingFunc best_func </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> ResolveImplementation</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        best_func</span><span style=\"color:#E1E4E8\">(input, output, count);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">private:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    static</span><span style=\"color:#B392F0\"> ProcessingFunc</span><span style=\"color:#B392F0\"> ResolveImplementation</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        unsigned</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> eax, ebx, ecx, edx;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Call CPUID Leaf 7, Subleaf 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#B392F0\">__get_cpuid_count</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">eax, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ebx, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">ecx, </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">edx)) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // Check Bit 5 of EBX for AVX2</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> (ebx </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#F97583\"> &#x3C;&#x3C;</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">)) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> Process_AVX;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> Process_Scalar;</span><span style=\"color:#6A737D\"> // Fallback</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">};</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Quick Breakdown: Intrinsics</strong>\nThese are C++ functions (like <code>_mm256_add_ps</code>) that look like normal code but are actually direct commands to the CPU hardware. They allow you to write assembly-level logic without leaving C++.</p>\n</blockquote>\n<p><a href=\"#satellite-map\">↑ Back to System Map</a></p>\n<div id=\"ms-mem-align\"></div>\n\n<h1 id=\"memory-alignment-amp-buffer-management-the-tile-floor-principle\">Memory Alignment &amp; Buffer Management: The Tile Floor Principle</h1>\n<p>Imagine you are laying down large, heavy marble tiles that are exactly 32 inches wide. The floor has pre-etched grooves every 32 inches. If you place a tile perfectly within the grooves, it drops into place instantly. </p>\n<p>However, if you try to place a tile so that it overlaps a groove—covering 16 inches of one section and 16 inches of the next—the floor&#39;s support structure can&#39;t handle it. In the world of high-performance computing, the CPU either has to do double the work to &quot;stitch&quot; those two sections together, or it simply gives up and crashes your program. This is <strong>Memory Alignment</strong>.</p>\n<h3 id=\"technical-rationale-the-quotwhyquot\">Technical Rationale: The &quot;Why&quot;</h3>\n<p>CPUs do not read memory one byte at a time. They read in &quot;chunks&quot; called <strong>Cache Lines</strong> (usually 64 bytes). </p>\n<p>When you use SIMD instructions, you are moving massive amounts of data (128, 256, or 512 bits) at once. </p>\n<ol>\n<li><strong>Performance</strong>: If a 256-bit AVX register loads data that straddles two different cache lines, the CPU must perform two memory fetches instead of one. This &quot;split load&quot; can cut your throughput in half.</li>\n<li><strong>Correctness</strong>: Many optimized SIMD instructions (like <code>MOVDQA</code> — Move Double Quadword <strong>Aligned</strong>) are hard-wired to expect addresses that are multiples of 16, 32, or 64. If you give them an &quot;odd&quot; address, the CPU triggers a <strong>General Protection Fault</strong>, and your application segfaults immediately.</li>\n</ol>\n<blockquote>\n<p><strong>Quick Breakdown: GP Fault (General Protection Fault)</strong>\nThis is the CPU&#39;s way of saying &quot;You broke the rules of the architecture.&quot; It’s a hardware-level emergency stop that happens when you try to execute an instruction on data that isn&#39;t prepared correctly (like unaligned memory).</p>\n</blockquote>\n<hr>\n<h3 id=\"internal-mechanics-the-quothowquot\">Internal Mechanics: The &quot;How&quot;</h3>\n<p>To achieve alignment, we use two primary strategies: <strong>Aligned Allocation</strong> and <strong>Buffer Peeling</strong>.</p>\n<h4 id=\"the-microscope-the-math-of-the-mask\">The Microscope: The Math of the Mask</h4>\n<p>How do we know if an address is aligned? We look at the pointer&#39;s binary representation. For a 64-byte alignment, the last 6 bits of the memory address must be zero ($2^6 = 64$).</p>\n<p>To align an arbitrary pointer <code>p</code> to a boundary <code>a</code>, we use this bitwise trick:\n<code>aligned_p = (p + (a - 1)) &amp; ~(a - 1)</code></p>\n<ol>\n<li><strong>Add <code>a-1</code></strong>: This pushes the pointer forward just enough to cross the next alignment boundary.</li>\n<li><strong>NOT <code>a-1</code></strong>: This creates a &quot;mask&quot; (e.g., for 64, it creates a mask where the last 6 bits are <code>0</code> and all others are <code>1</code>).</li>\n<li><strong>AND <code>&amp;</code></strong>: This &quot;chops off&quot; the extra bits, rounding the address down to the nearest perfect boundary.</li>\n</ol>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-04.svg\" alt=\"Memory Alignment Strategy\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-22.svg\" alt=\"Cache Line Alignment Visualization\"></p>\n<h4 id=\"handling-the-quotheadquot-and-quottailquot\">Handling the &quot;Head&quot; and &quot;Tail&quot;</h4>\n<p>Most data buffers don&#39;t start or end perfectly on a 64-byte boundary. </p>\n<ul>\n<li><strong>The Peel</strong>: We process the first few &quot;unaligned&quot; bytes using slow, scalar code until we hit the first aligned boundary.</li>\n<li><strong>The Main Loop</strong>: We blast through the bulk of the data using high-speed, aligned SIMD instructions.</li>\n<li><strong>The Remainder</strong>: We process the final leftover bytes (the &quot;tail&quot;) that don&#39;t fill a whole SIMD register.</li>\n</ul>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-05.svg\" alt=\"Unaligned Access Micro-Logic\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-15.svg\" alt=\"Buffer Padding & Tail Handling\"></p>\n<hr>\n<h3 id=\"the-debugging-lab-common-pitfalls\">The Debugging Lab: Common Pitfalls</h3>\n<ul>\n<li><strong>The &quot;Off-By-One&quot; Alignment</strong>: You allocated 1024 bytes, but your alignment padding pushed the start pointer forward by 32 bytes. If you try to write 1024 bytes starting from that new pointer, you will overflow the buffer.<ul>\n<li><em>The Fix</em>: Always allocate <code>Size + Alignment</code> bytes to ensure there is enough &quot;runway&quot; for the padding.</li>\n</ul>\n</li>\n<li><strong>Stack vs. Heap</strong>: Standard <code>malloc</code> usually only guarantees 8 or 16-byte alignment. If you need 64-byte alignment for AVX-512, <code>malloc</code> will eventually fail you.<ul>\n<li><em>The Fix</em>: Use specialized allocators like <code>_aligned_malloc</code> (Windows) or <code>posix_memalign</code> (Linux).</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"code-scaffold-the-aligned-buffer\">Code Scaffold: The Aligned Buffer</h3>\n<p>This scaffold demonstrates how to create a wrapper that ensures memory is always ready for AVX-512 (64-byte alignment).</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">cpp</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cstdlib></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cstdint></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;stdexcept></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">template</span><span style=\"color:#E1E4E8\"> &#x3C;</span><span style=\"color:#F97583\">typename</span><span style=\"color:#B392F0\"> T</span><span style=\"color:#E1E4E8\">></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AlignedBuffer</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    T</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> raw_ptr </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> nullptr</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    T</span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> aligned_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> nullptr</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> element_count;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">public:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // We target 64-byte alignment to satisfy AVX-512 and Cache Line requirements</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    static</span><span style=\"color:#F97583\"> constexpr</span><span style=\"color:#F97583\"> size_t</span><span style=\"color:#E1E4E8\"> ALIGNMENT </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 64</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    AlignedBuffer</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) : </span><span style=\"color:#B392F0\">element_count</span><span style=\"color:#E1E4E8\">(count) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 1. Allocate extra space to allow for shifting the pointer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        size_t</span><span style=\"color:#E1E4E8\"> total_bytes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (count </span><span style=\"color:#F97583\">*</span><span style=\"color:#F97583\"> sizeof</span><span style=\"color:#E1E4E8\">(T)) </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> ALIGNMENT;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        raw_ptr </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> static_cast&#x3C;</span><span style=\"color:#E1E4E8\">T</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">std</span><span style=\"color:#E1E4E8\">::</span><span style=\"color:#B392F0\">malloc</span><span style=\"color:#E1E4E8\">(total_bytes));</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">!</span><span style=\"color:#E1E4E8\">raw_ptr) </span><span style=\"color:#F97583\">throw</span><span style=\"color:#B392F0\"> std</span><span style=\"color:#E1E4E8\">::</span><span style=\"color:#B392F0\">bad_alloc</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 2. Perform the Bitwise Alignment Math</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uintptr_t</span><span style=\"color:#E1E4E8\"> address </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> reinterpret_cast&#x3C;uintptr_t></span><span style=\"color:#E1E4E8\">(raw_ptr);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        uintptr_t</span><span style=\"color:#E1E4E8\"> aligned_address </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> (address </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> (ALIGNMENT </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">)) </span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#F97583\"> ~</span><span style=\"color:#E1E4E8\">(ALIGNMENT </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        aligned_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> reinterpret_cast&#x3C;</span><span style=\"color:#E1E4E8\">T</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(aligned_address);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    ~AlignedBuffer</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Always free the ORIGINAL pointer, not the aligned one!</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        std</span><span style=\"color:#E1E4E8\">::</span><span style=\"color:#B392F0\">free</span><span style=\"color:#E1E4E8\">(raw_ptr);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    T</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#F97583\"> operator</span><span style=\"color:#B392F0\">[]</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> index</span><span style=\"color:#E1E4E8\">) { </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\"> aligned_data[index]; }</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    T</span><span style=\"color:#F97583\">*</span><span style=\"color:#B392F0\"> data</span><span style=\"color:#E1E4E8\">() { </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\"> aligned_data; }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">};</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Quick Breakdown: uintptr_t</strong>\nYou cannot perform bitwise math (like <code>&amp;</code> or <code>~</code>) directly on a pointer. <code>uintptr_t</code> is an unsigned integer type that is guaranteed to be the same size as a pointer, allowing us to treat a memory address like a regular number for calculations.</p>\n</blockquote>\n<p><a href=\"#satellite-map\">↑ Back to System Map</a></p>\n<div id=\"ms-string-simd\"></div>\n\n<h1 id=\"vectorized-string-search-the-magic-stencil\">Vectorized String Search: The Magic Stencil</h1>\n<p>Imagine you are looking for a specific letter &#39;Z&#39; in a massive book. A <strong>Scalar</strong> approach is like reading every single letter one by one with a magnifying glass. It works, but it’s exhausting.</p>\n<p>Now, imagine you have a <strong>Magic Stencil</strong>. This stencil is 32 letters wide. You slap it down on a line of text, and it instantly highlights every &#39;Z&#39; in that entire block. You don&#39;t &quot;read&quot; the block; you &quot;see&quot; the results all at once. <strong>Vectorized String Search</strong> is the art of using the CPU&#39;s SIMD registers as these magic stencils to find patterns in data at speeds exceeding 10GB/s.</p>\n<h3 id=\"technical-rationale-the-quotwhyquot\">Technical Rationale: The &quot;Why&quot;</h3>\n<p>In standard C++, <code>std::string::find</code> or <code>strstr</code> typically compares characters one at a time. While highly optimized, they are fundamentally limited by the &quot;one-at-a-time&quot; bottleneck. </p>\n<p>Modern CPUs have 256-bit (AVX2) or 512-bit (AVX-512) registers. A single AVX2 register can hold <strong>32 characters</strong> (8-bit bytes) simultaneously. By loading a chunk of the haystack into a register and comparing it against a &quot;broadcasted&quot; version of our needle, we can perform 32 comparisons in a single CPU cycle.</p>\n<blockquote>\n<p><strong>Quick Breakdown: Broadcast</strong>\nTo &quot;Broadcast&quot; means to take a single value (like the character &#39;A&#39;) and copy it into every slot of a SIMD register. If you broadcast &#39;A&#39; into a 256-bit register, you get a register containing 32 &#39;A&#39;s.</p>\n</blockquote>\n<hr>\n<h3 id=\"internal-mechanics-the-quothowquot\">Internal Mechanics: The &quot;How&quot;</h3>\n<p>We use two primary hardware &quot;superpowers&quot; for this:</p>\n<h4 id=\"1-the-avx2-masking-strategy\">1. The AVX2 Masking Strategy</h4>\n<p>This is the most common modern approach. </p>\n<ol>\n<li><strong>Load</strong>: We load 32 bytes of the &quot;Haystack&quot; into a YMM register.</li>\n<li><strong>Compare</strong>: We use <code>_mm256_cmpeq_epi8</code> to compare our Haystack register against a register full of our &quot;Needle&quot; character.</li>\n<li><strong>The Mask</strong>: The CPU returns a &quot;Mask&quot;—a register where slots that matched are filled with <code>0xFF</code> (all ones) and slots that didn&#39;t are <code>0x00</code>.</li>\n<li><strong>Compress</strong>: We use <code>_mm256_movemask_epi8</code> to turn that massive 256-bit register into a simple 32-bit integer. Each bit in this integer represents one character. If bit 5 is <code>1</code>, the 5th character was a match!</li>\n</ol>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-06.svg\" alt=\"String Search Pipeline\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-08.svg\" alt=\"AVX2 Mask Generation\"></p>\n<h4 id=\"2-the-sse42-quotstring-specialistquot-pcmpestri\">2. The SSE4.2 &quot;String Specialist&quot; (<code>PCMPESTRI</code>)</h4>\n<p>Intel introduced a specific instruction just for strings: <code>PCMPESTRI</code>. It is a &quot;CISC&quot; (Complex Instruction Set) powerhouse. In one instruction, it can perform &quot;Equal Each,&quot; &quot;Equal Any,&quot; or &quot;Equal Ordered&quot; comparisons. It is incredibly powerful for finding substrings but is limited to 128-bit (16-byte) chunks.</p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-07.svg\" alt=\"SSE4.2 PCMPESTRI Internals\"></p>\n<hr>\n<h3 id=\"the-microscope-from-bits-to-indices\">The Microscope: From Bits to Indices</h3>\n<p>Once we have our 32-bit integer mask from the AVX2 comparison, how do we know <em>where</em> the match is? We use a specialized CPU instruction called <strong>Trailing Zero Count (TZCNT)</strong> or <strong>Bit Scan Forward (BSF)</strong>.</p>\n<p>If our mask is <code>00001000</code>, the CPU counts the zeros from the right. It sees 3 zeros, meaning the first match is at index 3. This allows us to jump directly to the match without ever looping through the bits.</p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-21.svg\" alt=\"Bitmask Bit-Scan (BSF/BSR)\"></p>\n<hr>\n<h3 id=\"the-debugging-lab-common-pitfalls\">The Debugging Lab: Common Pitfalls</h3>\n<ul>\n<li><strong>The Page Boundary Segfault</strong>: This is the &quot;Final Boss&quot; of SIMD. If you try to read 32 bytes from a string that only has 5 bytes left, and those extra 27 bytes happen to cross over into a &quot;forbidden&quot; memory page, the CPU will crash your program—even if you intended to ignore those extra bytes!<ul>\n<li><em>The Fix</em>: Never read a full SIMD width if you are within 32/64 bytes of a page boundary (4KB). Use a safe scalar fallback for the very end of the string.</li>\n</ul>\n</li>\n<li><strong>False Positives in Substrings</strong>: If you are looking for &quot;CAT&quot;, and you find a &#39;C&#39; at the very end of your SIMD register, the &#39;A&#39; and &#39;T&#39; might be in the <em>next</em> register load.<ul>\n<li><em>The Fix</em>: Use &quot;Sliding Window&quot; logic or specialized instructions like <code>_mm256_mpsadbw_epu8</code> for multi-byte sequences.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"code-scaffold-avx2-character-search\">Code Scaffold: AVX2 Character Search</h3>\n<p>This is a high-performance &quot;Find First Of&quot; implementation.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">cpp</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;immintrin.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cstdint></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Find the first occurrence of 'target' in 'data'</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Returns the index, or 'size' if not found.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> FindFirstChar_AVX2</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#FFAB70\"> target</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Create the \"Magic Stencil\" (Broadcast target to all 32 lanes)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __m256i needle </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_set1_epi8</span><span style=\"color:#E1E4E8\">(target);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Process in 32-byte chunks</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (; i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 31</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#E1E4E8\"> size; i </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 32</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Load 32 bytes from the haystack</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        __m256i haystack </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_loadu_si256</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">reinterpret_cast&#x3C;const</span><span style=\"color:#E1E4E8\"> __m256i</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(data </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> i));</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Compare haystack to needle (Result is a mask of 0xFF or 0x00)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        __m256i comparison </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_cmpeq_epi8</span><span style=\"color:#E1E4E8\">(haystack, needle);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Convert the 256-bit mask into a 32-bit integer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        int</span><span style=\"color:#E1E4E8\"> mask </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_movemask_epi8</span><span style=\"color:#E1E4E8\">(comparison);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (mask </span><span style=\"color:#F97583\">!=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // 3. Use the \"Bit Scan\" to find the exact index of the first '1' bit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            // __builtin_ctz = Count Trailing Zeros</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">+</span><span style=\"color:#B392F0\"> __builtin_ctz</span><span style=\"color:#E1E4E8\">(mask);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. The \"Tail\": Process remaining bytes (&#x3C; 32) one by one</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> size; </span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">i) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (data[i] </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> target) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\"> i;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> size;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Quick Breakdown: _mm256_loadu_si256</strong>\nThe <code>u</code> in <code>loadu</code> stands for <strong>Unaligned</strong>. This tells the CPU &quot;I don&#39;t guarantee this string starts on a perfect 32-byte boundary, please handle the memory fetch carefully.&quot; It is slightly slower than an aligned load but prevents crashes on arbitrary strings.</p>\n</blockquote>\n<p><a href=\"#satellite-map\">↑ Back to System Map</a></p>\n<div id=\"ms-memcpy-opt\"></div>\n\n<h1 id=\"optimized-memory-transfer-the-firemans-chute\">Optimized Memory Transfer: The Fireman’s Chute</h1>\n<p>Imagine you are moving 1,000 boxes of books into a new library. </p>\n<p>A <strong>Standard Memcpy</strong> is like carrying each box through the library’s main reading room (the <strong>CPU Cache</strong>). It’s fine for a few boxes, but if you move 1,000, you’ll crowd the reading room, kick out the people studying there, and clutter the space. </p>\n<p>An <strong>Optimized Memcpy with Non-Temporal Stores</strong> is like installing a temporary &quot;Fireman’s Chute&quot; on the side of the building. The boxes slide directly from the truck to the shelf, bypassing the reading room entirely. The students (other active data) stay undisturbed in the cache, and the transfer happens at the maximum speed the &quot;chute&quot; (memory bus) can handle.</p>\n<blockquote>\n<p><strong>Quick Breakdown: Non-Temporal Store</strong>\nNormally, when the CPU writes data to memory, it assumes you’ll want to read that data again soon, so it keeps a copy in the fast <strong>L1/L2 Cache</strong>. A &quot;Non-Temporal&quot; store tells the CPU: &quot;I’m writing this data, but I won&#39;t need it again for a while. Don&#39;t waste space in the cache; send it straight to the RAM.&quot;</p>\n</blockquote>\n<hr>\n<h3 id=\"technical-rationale-the-quotwhyquot\">Technical Rationale: The &quot;Why&quot;</h3>\n<p>Standard <code>memcpy</code> is a general-purpose tool. However, when dealing with &quot;Big Data&quot; (multi-megabyte buffers), it suffers from <strong>Cache Pollution</strong>. By forcing massive amounts of data through the cache, the CPU evicts the instructions and data your program actually needs to run, causing a massive slowdown immediately after the copy finishes.</p>\n<p>By using <strong>AVX-512</strong> registers, we can move 64 bytes in a single instruction. By using <strong>Streaming (Non-Temporal) instructions</strong>, we bypass the cache hierarchy, preserving performance for the rest of the application.</p>\n<hr>\n<h3 id=\"internal-mechanics-the-quothowquot\">Internal Mechanics: The &quot;How&quot;</h3>\n<p>The secret to this speed is the interaction between the <strong>ZMM Registers</strong> and the <strong>Write-Combining Buffers</strong>.</p>\n<h4 id=\"the-microscope-the-write-combining-buffer\">The Microscope: The Write-Combining Buffer</h4>\n<p>When you use a streaming store instruction like <code>_mm512_stream_si512</code>, the data doesn&#39;t go to the L1 Cache. Instead, it goes to a small, specialized piece of hardware called the <strong>Write-Combining (WC) Buffer</strong>.</p>\n<ol>\n<li>The CPU collects several 64-byte writes into the WC Buffer.</li>\n<li>Once the buffer is full, the CPU sends the entire &quot;burst&quot; across the memory bus to the RAM in one highly efficient transaction.</li>\n<li>This reduces the &quot;chatter&quot; on the memory bus and prevents the CPU from having to &quot;read-for-ownership&quot; (checking if other cores have the data) before writing.</li>\n</ol>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-09.svg\" alt=\"Memcpy Orchestrator\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-10.svg\" alt=\"AVX-512 Memcpy Path\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-11.svg\" alt=\"Non-Temporal Store Logic\"></p>\n<hr>\n<h3 id=\"the-debugging-lab-common-pitfalls\">The Debugging Lab: Common Pitfalls</h3>\n<ul>\n<li><strong>The &quot;Small Buffer&quot; Penalty</strong>: Non-temporal stores have a high &quot;startup cost.&quot; If you use them to copy a tiny 16-byte string, it will be significantly slower than a standard copy because the Write-Combining buffer won&#39;t fill up, and the CPU has to wait to flush it.<ul>\n<li><em>The Fix</em>: Only use the &quot;Streaming Path&quot; for buffers larger than the L2 or L3 cache (typically &gt; 1MB).</li>\n</ul>\n</li>\n<li><strong>Alignment Requirements</strong>: Most streaming instructions (like <code>VMOVNTDQ</code>) <strong>require</strong> the memory address to be perfectly aligned to the register width (e.g., 64-byte alignment for AVX-512). If the address is off by even one byte, the program will crash with a <code>General Protection Fault</code>.<ul>\n<li><em>The Fix</em>: Use the &quot;Peeling&quot; technique we learned in the Memory Alignment section to handle the unaligned start of the buffer.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"code-scaffold-the-high-throughput-copy\">Code Scaffold: The High-Throughput Copy</h3>\n<p>This scaffold demonstrates how to implement a &quot;Streaming&quot; copy that uses AVX-512 to blast data directly to RAM.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">cpp</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;immintrin.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cstddef></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Optimized Memcpy for LARGE buffers.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Requirements: 'dest' and 'src' should be 64-byte aligned for max speed.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> Memcpy_Streaming_AVX512</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">void*</span><span style=\"color:#FFAB70\"> dest</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> void*</span><span style=\"color:#FFAB70\"> src</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    char*</span><span style=\"color:#E1E4E8\"> d </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> static_cast&#x3C;char*></span><span style=\"color:#E1E4E8\">(dest);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#E1E4E8\"> s </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> static_cast&#x3C;const</span><span style=\"color:#F97583\"> char*></span><span style=\"color:#E1E4E8\">(src);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. The Main Heavy-Lifting Loop (64 bytes per iteration)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // We use __m512i to represent a 512-bit ZMM register</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (; i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 63</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#E1E4E8\"> size; i </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 64</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Load data from source into a ZMM register</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // _mm512_loadu_si512 = Load Unaligned (Safe)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        __m512i chunk </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm512_loadu_si512</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">reinterpret_cast&#x3C;const</span><span style=\"color:#E1E4E8\"> __m512i</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(s </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> i));</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // 2. The \"Fireman's Chute\": Non-Temporal Store</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // _mm512_stream_si512 = Write directly to RAM, bypassing cache.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // NOTE: This instruction REQUIRES 'dest' to be 64-byte aligned!</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        _mm512_stream_si512</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">reinterpret_cast&#x3C;</span><span style=\"color:#E1E4E8\">__m512i</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(d </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> i), chunk);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. The \"SFENCE\" (Store Fence)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Because streaming stores are \"weakly ordered,\" we must tell the CPU:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // \"Finish all those background writes before anyone else reads this memory!\"</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    _mm_sfence</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. The Tail: Handle remaining bytes with standard logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> size; </span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">i) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        d[i] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> s[i];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Quick Breakdown: SFENCE</strong>\nThink of <code>SFENCE</code> as a &quot;Save Game&quot; button. Because non-temporal stores happen in the background via the Write-Combining buffers, the rest of your program might try to read the memory before the &quot;chute&quot; has finished dropping the boxes. <code>SFENCE</code> forces the CPU to finish all pending stores before moving to the next line of code.</p>\n</blockquote>\n<p><a href=\"#satellite-map\">↑ Back to System Map</a></p>\n<div id=\"ms-checksum-simd\"></div>\n\n<h1 id=\"simd-checksum-amp-hashing-the-multi-lane-toll-booth\">SIMD Checksum &amp; Hashing: The Multi-Lane Toll Booth</h1>\n<p>Imagine you are a toll booth operator on a massive highway. Thousands of cars are passing through, and your job is to count exactly how many passengers are in every car to ensure the &quot;Total Passenger Count&quot; (the <strong>Checksum</strong>) matches the manifest.</p>\n<p>A <strong>Scalar</strong> approach is like having a single toll lane. You stop one car, count the people, add it to your clipboard, and move to the next. If the highway is packed, the traffic backs up for miles.</p>\n<p>A <strong>SIMD Checksum</strong> is like opening 8 or 16 lanes simultaneously. You have a camera over the highway that snaps a picture of 8 cars at once. You count all the passengers in those 8 cars in a single &quot;blink&quot; and add that sub-total to your master list. You aren&#39;t just working faster; you are processing the entire width of the highway in parallel.</p>\n<blockquote>\n<p><strong>Quick Breakdown: Checksum</strong>\nA checksum is a small datum derived from a block of digital data for the purpose of detecting errors that may have been introduced during its transmission or storage. Think of it like a &quot;digital fingerprint&quot; of a file.</p>\n</blockquote>\n<hr>\n<h3 id=\"technical-rationale-the-quotwhyquot\">Technical Rationale: The &quot;Why&quot;</h3>\n<p>Calculating a checksum (like CRC32) or a hash (like MurmurHash or HighwayHash) is often the final bottleneck in data pipelines. Whether you are verifying a download or indexing a database, you have to touch every single byte.</p>\n<p>In a serial world, CRC32 is &quot;recursive&quot;—the calculation for the next byte depends on the result of the previous byte. This is a nightmare for performance. However, modern CPUs provide specialized instructions (like <code>PCLMULQDQ</code> for Carry-less Multiplication) that allow us to break the data into independent chunks, calculate &quot;partial&quot; checksums in parallel lanes, and then fold them together at the end.</p>\n<hr>\n<h3 id=\"internal-mechanics-the-quothowquot\">Internal Mechanics: The &quot;How&quot;</h3>\n<p>To parallelize a checksum, we use a technique called <strong>Multi-Stream Processing</strong>.</p>\n<h4 id=\"1-the-parallel-lanes\">1. The Parallel Lanes</h4>\n<p>Instead of one rolling total, we maintain multiple independent totals. If we use AVX2, we can treat a 256-bit register as eight 32-bit &quot;lanes.&quot;</p>\n<ul>\n<li>Lane 1 processes bytes 0, 8, 16...</li>\n<li>Lane 2 processes bytes 1, 9, 17...</li>\n<li>...and so on.</li>\n</ul>\n<h4 id=\"2-the-hardware-accelerator-_mm_crc32_u64\">2. The Hardware Accelerator (<code>_mm_crc32_u64</code>)</h4>\n<p>Intel and AMD CPUs have a dedicated circuit just for CRC32. It’s not a general-purpose math unit; it’s a hard-wired &quot;CRC machine.&quot; By using the <code>_mm_crc32_u64</code> intrinsic, we can process 8 bytes at a time with near-zero latency.</p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-12.svg\" alt=\"Checksum Pipeline\"></p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-13.svg\" alt=\"CRC32 Hardware Acceleration\"></p>\n<h4 id=\"3-the-quotfoldquot-galois-field-math\">3. The &quot;Fold&quot; (Galois Field Math)</h4>\n<p>Once we reach the end of the data, we have 8 different partial checksums. We can&#39;t just add them together (math doesn&#39;t work that way for CRC). We use a &quot;Fold&quot; operation, which uses specialized SIMD math to combine these 8 fingerprints into one final, authoritative 32-bit CRC.</p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-14.svg\" alt=\"AVX2 Parallel Hashing\"></p>\n<hr>\n<h3 id=\"the-microscope-the-xor-operation\">The Microscope: The XOR Operation</h3>\n<p>At the heart of almost every checksum and hash is the <strong>XOR (Exclusive OR)</strong> operation. \nIn binary:</p>\n<ul>\n<li><code>0 XOR 0 = 0</code></li>\n<li><code>1 XOR 1 = 0</code></li>\n<li><code>1 XOR 0 = 1</code></li>\n</ul>\n<p>Why XOR? Because it’s &quot;reversible&quot; and doesn&#39;t &quot;carry&quot; like addition does. In SIMD, <code>_mm256_xor_si256</code> is one of the fastest instructions in existence, often executing in 0.5 cycles. It is the &quot;glue&quot; that binds parallel hashing together.</p>\n<hr>\n<h3 id=\"the-debugging-lab-common-pitfalls\">The Debugging Lab: Common Pitfalls</h3>\n<ul>\n<li><strong>The Endianness Trap</strong>: If you calculate a SIMD checksum on a Little-Endian machine (Intel) and compare it to a result from a Big-Endian machine (older PowerPC), the bytes in your registers will be swapped, and the checksums won&#39;t match.<ul>\n<li><em>The Fix</em>: Always use <code>_mm_shuffle_epi8</code> to normalize byte order if your protocol requires a specific &quot;Network Byte Order.&quot;</li>\n</ul>\n</li>\n<li><strong>The Final XOR</strong>: Many CRC algorithms (like CRC32-IEEE) require you to XOR the final result with <code>0xFFFFFFFF</code> at the very end. If you forget this &quot;final flip,&quot; your checksum will be perfectly calculated but technically &quot;wrong&quot; according to the standard.</li>\n<li><strong>The Seed Value</strong>: If you start your parallel lanes with a seed of <code>0</code>, but the standard expects <code>0xFFFFFFFF</code>, your lanes will diverge immediately.</li>\n</ul>\n<hr>\n<h3 id=\"code-scaffold-parallel-additive-checksum\">Code Scaffold: Parallel Additive Checksum</h3>\n<p>While a full CRC32 is complex, this scaffold shows the &quot;Mental Model&quot; of a vectorized additive checksum (summing 32-bit integers in parallel).</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">cpp</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;immintrin.h></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cstdint></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * Calculates a simple 32-bit additive checksum using AVX2.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * This processes 8 integers (32 bytes) per cycle.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">uint32_t</span><span style=\"color:#B392F0\"> CalculateChecksum_AVX2</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> uint32_t*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> count</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 1. Initialize a register of 8 zeros (our 8 parallel \"toll lanes\")</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __m256i v_sum </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_setzero_si256</span><span style=\"color:#E1E4E8\">();</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">;</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 2. Process 8 integers at a time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (; i </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 7</span><span style=\"color:#F97583\"> &#x3C;</span><span style=\"color:#E1E4E8\"> count; i </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 8</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Load 8 integers into a YMM register</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        __m256i v_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_loadu_si256</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">reinterpret_cast&#x3C;const</span><span style=\"color:#E1E4E8\"> __m256i</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">&#x26;</span><span style=\"color:#E1E4E8\">data[i]));</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        // Add the 8 integers to our 8 running totals in parallel</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        v_sum </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_add_epi32</span><span style=\"color:#E1E4E8\">(v_sum, v_data);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 3. The \"Horizontal Fold\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // We have 8 partial sums in one register. We need to add them together.</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // We extract the two 128-bit halves and add them.</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __m128i v_low </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_castsi256_si128</span><span style=\"color:#E1E4E8\">(v_sum);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __m128i v_high </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm256_extracti128_si256</span><span style=\"color:#E1E4E8\">(v_sum, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __m128i v_final128 </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> _mm_add_epi32</span><span style=\"color:#E1E4E8\">(v_low, v_high);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // Further reduce 128-bit (4 ints) to 1 int</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> results[</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    _mm_storeu_si128</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">reinterpret_cast&#x3C;</span><span style=\"color:#E1E4E8\">__m128i</span><span style=\"color:#F97583\">*></span><span style=\"color:#E1E4E8\">(results), v_final128);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    uint32_t</span><span style=\"color:#E1E4E8\"> final_checksum </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> results[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> results[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> results[</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> results[</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">];</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    // 4. Handle the Tail (remaining elements &#x3C; 8)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> count; </span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">i) {</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        final_checksum </span><span style=\"color:#F97583\">+=</span><span style=\"color:#E1E4E8\"> data[i];</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> final_checksum;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Quick Breakdown: Horizontal Fold</strong>\nSIMD is great at &quot;Vertical&quot; math (Lane A + Lane A). It is naturally bad at &quot;Horizontal&quot; math (Lane A + Lane B). To get a single total, we have to &quot;fold&quot; the register in half repeatedly until only one value remains.</p>\n</blockquote>\n<p><a href=\"#satellite-map\">↑ Back to System Map</a></p>\n<div id=\"ms-bench-validation\"></div>\n\n<h1 id=\"validation-amp-benchmarking-the-master-blueprint-amp-the-stopwatch\">Validation &amp; Benchmarking: The Master Blueprint &amp; The Stopwatch</h1>\n<p>Imagine you’ve just built a high-speed experimental jet engine (your <strong>SIMD Kernel</strong>). It’s theoretically capable of Mach 5, but how do you prove it?</p>\n<p>First, you need a <strong>Master Blueprint</strong>. You take a standard, reliable propeller plane (your <strong>Scalar Reference</strong>) and fly it to a destination. You record exactly what the landscape looks like. Then, you fly your jet. If the jet arrives at a place that looks different from the blueprint, your engine is broken—it doesn&#39;t matter how fast it got there. This is <strong>Validation</strong>.</p>\n<p>Second, you need a <strong>Precision Stopwatch</strong>. You can&#39;t just look at a wall clock; you need to measure the exact moment the fuel ignites. You also need to account for the wind and the weight of the fuel. This is <strong>Benchmarking</strong>.</p>\n<blockquote>\n<p><strong>Quick Breakdown: Scalar Reference</strong>\nA &quot;Scalar&quot; version of your code is the simplest, most readable C++ version (usually a basic <code>for</code> loop). Because it&#39;s simple, it&#39;s unlikely to have bugs. We use it as the &quot;Ground Truth&quot; to ensure our complex SIMD code produces the exact same results.</p>\n</blockquote>\n<hr>\n<h3 id=\"technical-rationale-the-quotwhyquot\">Technical Rationale: The &quot;Why&quot;</h3>\n<p>SIMD programming is notoriously &quot;brittle.&quot; A single off-by-one error in your tail-handling logic or a misunderstood bit-shift can result in &quot;Silent Data Corruption&quot;—where the program runs perfectly fine but the output is slightly wrong.</p>\n<p>Furthermore, &quot;Fast&quot; is a relative term. On some CPUs, AVX-512 might actually be <em>slower</em> than AVX2 because the CPU lowers its clock speed (throttling) to handle the massive power draw of 512-bit instructions. Without a rigorous benchmarking suite, you are just guessing.</p>\n<hr>\n<h3 id=\"internal-mechanics-the-quothowquot\">Internal Mechanics: The &quot;How&quot;</h3>\n<h4 id=\"1-differential-testing-the-ground-truth\">1. Differential Testing (The Ground Truth)</h4>\n<p>We run the same data through two pipes:</p>\n<ol>\n<li><code>Result_A = Scalar_Implementation(input)</code></li>\n<li><code>Result_B = SIMD_Implementation(input)</code></li>\n<li><code>Assert(Result_A == Result_B)</code></li>\n</ol>\n<p>We do this across &quot;Edge Cases&quot;: empty buffers, buffers with 1 byte, buffers that are exactly 31 bytes (just under an AVX2 window), and buffers that cross memory page boundaries.</p>\n<h4 id=\"2-the-high-resolution-timer-rdtsc\">2. The High-Resolution Timer (<code>RDTSC</code>)</h4>\n<p>Standard timers like <code>std::chrono</code> are often too &quot;blunt&quot; for SIMD. To measure a kernel that takes only 200 nanoseconds, we use the <strong>RDTSC (Read Time-Stamp Counter)</strong> instruction. This returns the exact number of CPU cycles that have passed since the processor started.</p>\n<p><img src=\"/api/project/simd-library/architecture-doc/asset?path=diagrams%2Fdiag-17.svg\" alt=\"Benchmarking Framework\"></p>\n<h4 id=\"3-throughput-vs-latency\">3. Throughput vs. Latency</h4>\n<ul>\n<li><strong>Latency</strong>: How long does it take for <em>one</em> operation to finish? (Important for real-time audio).</li>\n<li><strong>Throughput</strong>: How many operations can we finish per second? (Important for database scanning).\nSIMD is designed to maximize <strong>Throughput</strong>.</li>\n</ul>\n<hr>\n<h3 id=\"the-microscope-the-quotwarm-upquot-and-quotcache-statequot\">The Microscope: The &quot;Warm-up&quot; and &quot;Cache State&quot;</h3>\n<p>When you benchmark, the first run is always the slowest. Why?</p>\n<ol>\n<li><strong>Instruction Cache</strong>: The CPU has to fetch your SIMD code from RAM into the fast L1 instruction cache.</li>\n<li><strong>Data Cache</strong>: The data you are processing isn&#39;t in the cache yet (<strong>Cold Cache</strong>).</li>\n<li><strong>Branch Predictor</strong>: The CPU hasn&#39;t &quot;learned&quot; the pattern of your loops yet.</li>\n</ol>\n<p>To get a &quot;Deep Technical Truth,&quot; we run a <strong>Warm-up Loop</strong> (executing the code 1,000 times without recording) before we start the actual measurement.</p>\n<hr>\n<h3 id=\"the-debugging-lab-common-pitfalls\">The Debugging Lab: Common Pitfalls</h3>\n<ul>\n<li><strong>The Optimizer&#39;s Vanishing Act</strong>: If you write a benchmark that calculates a result but never <em>uses</em> that result, the C++ compiler will notice. It will say, &quot;This code does nothing,&quot; and delete your entire SIMD loop. Your benchmark will report <code>0.000ns</code>.<ul>\n<li><em>The Fix</em>: Use <code>benchmark::DoNotOptimize()</code> (in Google Benchmark) or a <code>volatile</code> pointer to force the compiler to keep the code.</li>\n</ul>\n</li>\n<li><strong>Frequency Scaling (Turbo Boost)</strong>: Modern CPUs change their speed constantly. If your laptop is unplugged, it might run at 1.2GHz. If it&#39;s plugged in and &quot;cold,&quot; it might hit 4.8GHz.<ul>\n<li><em>The Fix</em>: Pin the CPU frequency during benchmarks or measure in <strong>Cycles</strong> instead of <strong>Seconds</strong>.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"code-scaffold-the-validation-harness\">Code Scaffold: The Validation Harness</h3>\n<p>This scaffold provides a template for comparing a SIMD search against a standard C++ search.</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">cpp</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;iostream></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;vector></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;cassert></span></span>\n<span class=\"line\"><span style=\"color:#F97583\">#include</span><span style=\"color:#9ECBFF\"> &#x3C;chrono></span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// 1. The \"Ground Truth\" (Scalar)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">size_t</span><span style=\"color:#B392F0\"> ScalarSearch</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#FFAB70\"> target</span><span style=\"color:#E1E4E8\">) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">; i </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#E1E4E8\"> size; </span><span style=\"color:#F97583\">++</span><span style=\"color:#E1E4E8\">i) {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (data[i] </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> target) </span><span style=\"color:#F97583\">return</span><span style=\"color:#E1E4E8\"> i;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> size;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">// 2. The \"Experimental Engine\" (SIMD - Placeholder)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">extern</span><span style=\"color:#F97583\"> size_t</span><span style=\"color:#B392F0\"> FindFirstChar_AVX2</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">const</span><span style=\"color:#F97583\"> char*</span><span style=\"color:#FFAB70\"> data</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">size_t</span><span style=\"color:#FFAB70\"> size</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">char</span><span style=\"color:#FFAB70\"> target</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">void</span><span style=\"color:#B392F0\"> RunValidationSuite</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    std</span><span style=\"color:#E1E4E8\">::vector</span><span style=\"color:#F97583\">&#x3C;size_t></span><span style=\"color:#E1E4E8\"> test_sizes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">15</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">16</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">31</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">32</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">65</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">1024</span><span style=\"color:#E1E4E8\">};</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#F97583\">size_t</span><span style=\"color:#E1E4E8\"> size : test_sizes) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">        std</span><span style=\"color:#E1E4E8\">::vector</span><span style=\"color:#F97583\">&#x3C;char></span><span style=\"color:#B392F0\"> buffer</span><span style=\"color:#E1E4E8\">(size, </span><span style=\"color:#9ECBFF\">'A'</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (size </span><span style=\"color:#F97583\">></span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">) buffer[size </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'Z'</span><span style=\"color:#E1E4E8\">;</span><span style=\"color:#6A737D\"> // Put target at the very end</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        size_t</span><span style=\"color:#E1E4E8\"> expected </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> ScalarSearch</span><span style=\"color:#E1E4E8\">(buffer.</span><span style=\"color:#B392F0\">data</span><span style=\"color:#E1E4E8\">(), buffer.</span><span style=\"color:#B392F0\">size</span><span style=\"color:#E1E4E8\">(), </span><span style=\"color:#9ECBFF\">'Z'</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        size_t</span><span style=\"color:#E1E4E8\"> actual </span><span style=\"color:#F97583\">=</span><span style=\"color:#B392F0\"> FindFirstChar_AVX2</span><span style=\"color:#E1E4E8\">(buffer.</span><span style=\"color:#B392F0\">data</span><span style=\"color:#E1E4E8\">(), buffer.</span><span style=\"color:#B392F0\">size</span><span style=\"color:#E1E4E8\">(), </span><span style=\"color:#9ECBFF\">'Z'</span><span style=\"color:#E1E4E8\">);</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> (expected </span><span style=\"color:#F97583\">!=</span><span style=\"color:#E1E4E8\"> actual) {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            std</span><span style=\"color:#E1E4E8\">::</span><span style=\"color:#B392F0\">printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"FAILED: Size </span><span style=\"color:#79B8FF\">%zu</span><span style=\"color:#9ECBFF\"> | Expected </span><span style=\"color:#79B8FF\">%zu</span><span style=\"color:#9ECBFF\">, Got </span><span style=\"color:#79B8FF\">%zu\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, size, expected, actual);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        } </span><span style=\"color:#F97583\">else</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">            std</span><span style=\"color:#E1E4E8\">::</span><span style=\"color:#B392F0\">printf</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"PASSED: Size </span><span style=\"color:#79B8FF\">%zu\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, size);</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\">/**</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> * A simple cycle-counting wrapper</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"> */</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">static</span><span style=\"color:#F97583\"> inline</span><span style=\"color:#F97583\"> uint64_t</span><span style=\"color:#B392F0\"> rdtsc</span><span style=\"color:#E1E4E8\">() {</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    unsigned</span><span style=\"color:#F97583\"> int</span><span style=\"color:#E1E4E8\"> lo, hi;</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    __asm__</span><span style=\"color:#E1E4E8\"> _</span><span style=\"color:#B392F0\">_volatile__</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#9ECBFF\">\"rdtsc\"</span><span style=\"color:#E1E4E8\"> : </span><span style=\"color:#9ECBFF\">\"=a\"</span><span style=\"color:#E1E4E8\"> (lo), </span><span style=\"color:#9ECBFF\">\"=d\"</span><span style=\"color:#E1E4E8\"> (hi));</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> ((</span><span style=\"color:#F97583\">uint64_t</span><span style=\"color:#E1E4E8\">)hi </span><span style=\"color:#F97583\">&#x3C;&#x3C;</span><span style=\"color:#79B8FF\"> 32</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">|</span><span style=\"color:#E1E4E8\"> lo;</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<blockquote>\n<p><strong>Quick Breakdown: <strong>asm</strong> <strong>volatile</strong></strong>\nThis is &quot;Inline Assembly.&quot; It tells the compiler: &quot;Stop! Don&#39;t try to optimize this. Just insert the raw <code>rdtsc</code> CPU instruction exactly where I put it.&quot; The <code>volatile</code> keyword ensures the compiler doesn&#39;t move this instruction around, which would ruin our timing.</p>\n</blockquote>\n<p><a href=\"#satellite-map\">↑ Back to System Map</a></p>\n","toc":[{"level":1,"text":"SIMD Optimization Library Atlas","id":"simd-optimization-library-atlas"},{"level":1,"text":"Dynamic CPU Feature Dispatching: The Universal Translator","id":"dynamic-cpu-feature-dispatching-the-universal-translator"},{"level":3,"text":"Technical Rationale: The &quot;Why&quot;","id":"technical-rationale-the-quotwhyquot"},{"level":3,"text":"Internal Mechanics: The &quot;How&quot;","id":"internal-mechanics-the-quothowquot"},{"level":4,"text":"The Microscope: Bit-Level Detection","id":"the-microscope-bit-level-detection"},{"level":3,"text":"The Debugging Lab: Common Pitfalls","id":"the-debugging-lab-common-pitfalls"},{"level":3,"text":"Code Scaffold: The Dispatcher","id":"code-scaffold-the-dispatcher"},{"level":1,"text":"Memory Alignment &amp; Buffer Management: The Tile Floor Principle","id":"memory-alignment-amp-buffer-management-the-tile-floor-principle"},{"level":3,"text":"Technical Rationale: The &quot;Why&quot;","id":"technical-rationale-the-quotwhyquot"},{"level":3,"text":"Internal Mechanics: The &quot;How&quot;","id":"internal-mechanics-the-quothowquot"},{"level":4,"text":"The Microscope: The Math of the Mask","id":"the-microscope-the-math-of-the-mask"},{"level":4,"text":"Handling the &quot;Head&quot; and &quot;Tail&quot;","id":"handling-the-quotheadquot-and-quottailquot"},{"level":3,"text":"The Debugging Lab: Common Pitfalls","id":"the-debugging-lab-common-pitfalls"},{"level":3,"text":"Code Scaffold: The Aligned Buffer","id":"code-scaffold-the-aligned-buffer"},{"level":1,"text":"Vectorized String Search: The Magic Stencil","id":"vectorized-string-search-the-magic-stencil"},{"level":3,"text":"Technical Rationale: The &quot;Why&quot;","id":"technical-rationale-the-quotwhyquot"},{"level":3,"text":"Internal Mechanics: The &quot;How&quot;","id":"internal-mechanics-the-quothowquot"},{"level":4,"text":"1. The AVX2 Masking Strategy","id":"1-the-avx2-masking-strategy"},{"level":4,"text":"2. The SSE4.2 &quot;String Specialist&quot; (PCMPESTRI)","id":"2-the-sse42-quotstring-specialistquot-pcmpestri"},{"level":3,"text":"The Microscope: From Bits to Indices","id":"the-microscope-from-bits-to-indices"},{"level":3,"text":"The Debugging Lab: Common Pitfalls","id":"the-debugging-lab-common-pitfalls"},{"level":3,"text":"Code Scaffold: AVX2 Character Search","id":"code-scaffold-avx2-character-search"},{"level":1,"text":"Optimized Memory Transfer: The Fireman’s Chute","id":"optimized-memory-transfer-the-firemans-chute"},{"level":3,"text":"Technical Rationale: The &quot;Why&quot;","id":"technical-rationale-the-quotwhyquot"},{"level":3,"text":"Internal Mechanics: The &quot;How&quot;","id":"internal-mechanics-the-quothowquot"},{"level":4,"text":"The Microscope: The Write-Combining Buffer","id":"the-microscope-the-write-combining-buffer"},{"level":3,"text":"The Debugging Lab: Common Pitfalls","id":"the-debugging-lab-common-pitfalls"},{"level":3,"text":"Code Scaffold: The High-Throughput Copy","id":"code-scaffold-the-high-throughput-copy"},{"level":1,"text":"SIMD Checksum &amp; Hashing: The Multi-Lane Toll Booth","id":"simd-checksum-amp-hashing-the-multi-lane-toll-booth"},{"level":3,"text":"Technical Rationale: The &quot;Why&quot;","id":"technical-rationale-the-quotwhyquot"},{"level":3,"text":"Internal Mechanics: The &quot;How&quot;","id":"internal-mechanics-the-quothowquot"},{"level":4,"text":"1. The Parallel Lanes","id":"1-the-parallel-lanes"},{"level":4,"text":"2. The Hardware Accelerator (_mm_crc32_u64)","id":"2-the-hardware-accelerator-_mm_crc32_u64"},{"level":4,"text":"3. The &quot;Fold&quot; (Galois Field Math)","id":"3-the-quotfoldquot-galois-field-math"},{"level":3,"text":"The Microscope: The XOR Operation","id":"the-microscope-the-xor-operation"},{"level":3,"text":"The Debugging Lab: Common Pitfalls","id":"the-debugging-lab-common-pitfalls"},{"level":3,"text":"Code Scaffold: Parallel Additive Checksum","id":"code-scaffold-parallel-additive-checksum"},{"level":1,"text":"Validation &amp; Benchmarking: The Master Blueprint &amp; The Stopwatch","id":"validation-amp-benchmarking-the-master-blueprint-amp-the-stopwatch"},{"level":3,"text":"Technical Rationale: The &quot;Why&quot;","id":"technical-rationale-the-quotwhyquot"},{"level":3,"text":"Internal Mechanics: The &quot;How&quot;","id":"internal-mechanics-the-quothowquot"},{"level":4,"text":"1. Differential Testing (The Ground Truth)","id":"1-differential-testing-the-ground-truth"},{"level":4,"text":"2. The High-Resolution Timer (RDTSC)","id":"2-the-high-resolution-timer-rdtsc"},{"level":4,"text":"3. Throughput vs. Latency","id":"3-throughput-vs-latency"},{"level":3,"text":"The Microscope: The &quot;Warm-up&quot; and &quot;Cache State&quot;","id":"the-microscope-the-quotwarm-upquot-and-quotcache-statequot"},{"level":3,"text":"The Debugging Lab: Common Pitfalls","id":"the-debugging-lab-common-pitfalls"},{"level":3,"text":"Code Scaffold: The Validation Harness","id":"code-scaffold-the-validation-harness"}],"title":"SIMD Optimization Library Atlas","markdown":"# SIMD Optimization Library Atlas\n\nA comprehensive blueprint for a high-performance SIMD library utilizing SSE, AVX2, and AVX-512 intrinsics to accelerate string search, memory operations, and checksum calculations through hardware-level parallelism.\n\n\n\n<div id=\"ms-cpu-dispatch\"></div>\n\n# Dynamic CPU Feature Dispatching: The Universal Translator\n\nImagine you are a world-class chef traveling to different kitchens. In a basic kitchen, you only have a hand-knife (Scalar code). In a modern kitchen, you might find a food processor (SSE). In a professional industrial kitchen, you have a high-speed industrial slicer (AVX-512). \n\nIf you try to plug your industrial slicer into a basic kitchen's outlet, you’ll blow a fuse (the program crashes with an `Illegal Instruction` error). **Dynamic Dispatching** is the process of walking into the kitchen, checking the equipment first, and then deciding which \"recipe\" (function implementation) to use for the rest of the night.\n\n### Technical Rationale: The \"Why\"\nWe write SIMD code to squeeze every drop of performance out of the hardware. However, hardware is fragmented. A user on a 2012 laptop has SSE4.2, while a user on a 2023 workstation has AVX-512. \n\nIf we compile our program specifically for AVX-512, it won't run on 90% of computers. If we compile only for the \"lowest common denominator\" (Scalar), we waste the power of modern CPUs. Dynamic Dispatching allows us to ship **one binary** that detects the CPU at runtime and \"patches\" itself to use the fastest available instructions.\n\n> **Quick Breakdown: Function Pointer**\n> Think of a standard function as a fixed path on a map. A **Function Pointer** is a signpost that you can turn. Initially, it points to a \"Detection\" function. Once the detection is done, you turn the signpost to point directly to the \"SSE\" or \"AVX\" version of the logic.\n\n---\n\n### Internal Mechanics: The \"How\"\nThe heart of this system is the `CPUID` instruction. This is a special CPU opcode that doesn't perform math; instead, it returns a \"map\" of the processor's soul into four general-purpose registers: `EAX`, `EBX`, `ECX`, and `EDX`.\n\n#### The Microscope: Bit-Level Detection\nTo detect AVX2 support, we don't just ask the CPU \"Are you fast?\" We perform a surgical bit-check:\n1. We call `CPUID` with `EAX` set to `7` (the \"leaf\" for extended features).\n2. The CPU fills `EBX` with a series of flags.\n3. We check **Bit 5** of the `EBX` register. If it's `1`, AVX2 is supported.\n\nHowever, there is a catch! Even if the CPU supports AVX, the Operating System (Windows/Linux) must also support saving the massive YMM/ZMM registers during context switches. We must check the **XCR0 (Extended Control Register)** to ensure the OS is \"SIMD-aware.\"\n\n\n![CPU Dispatcher Flow](./diagrams/diag-02.svg)\n\n\n![CPUID Leaf Analysis](./diagrams/diag-03.svg)\n\n\n---\n\n### The Debugging Lab: Common Pitfalls\n*   **The \"Illegal Instruction\" Crash**: This usually happens because you detected the CPU feature (e.g., AVX) but forgot to check if the OS supports it. The CPU says \"I can do it,\" but the OS says \"I don't know how to store those big registers,\" and kills the process.\n*   **The Dispatch Overhead**: If you check the CPU features *inside* a loop that runs a million times, you'll destroy your performance.\n    *   *The Fix*: Use a **Static Initializer** or a **Function Pointer Patch**. Check once at startup, set the pointer, and never check again.\n\n---\n\n### Code Scaffold: The Dispatcher\nBelow is the blueprint for your dispatcher. It uses a \"Lazy Initialization\" pattern to ensure we only check the CPU once.\n\n```cpp\n#include <iostream>\n#include <cpuid.h> // GCC/Clang header for __get_cpuid\n\n// 1. Define the function signature (The \"Recipe\")\ntypedef void (*ProcessingFunc)(const float* input, float* output, size_t count);\n\n// 2. The \"Slow & Safe\" Scalar Implementation\nvoid Process_Scalar(const float* input, float* output, size_t count) {\n    for (size_t i = 0; i < count; ++i) output[i] = input[i] * 2.0f;\n}\n\n// 3. The \"High-Speed\" AVX Implementation\nvoid Process_AVX(const float* input, float* output, size_t count) {\n    // Imagine __m256 registers and _mm256_add_ps intrinsics here\n    std::cout << \"[System] Using AVX Optimized Path\\n\";\n}\n\n// 4. The Dispatcher Logic\nclass Processor {\npublic:\n    static void Execute(const float* input, float* output, size_t count) {\n        // This function pointer is the \"Signpost\"\n        static ProcessingFunc best_func = ResolveImplementation();\n        best_func(input, output, count);\n    }\n\nprivate:\n    static ProcessingFunc ResolveImplementation() {\n        unsigned int eax, ebx, ecx, edx;\n        \n        // Call CPUID Leaf 7, Subleaf 0\n        if (__get_cpuid_count(7, 0, &eax, &ebx, &ecx, &edx)) {\n            // Check Bit 5 of EBX for AVX2\n            if (ebx & (1 << 5)) {\n                return Process_AVX;\n            }\n        }\n        \n        return Process_Scalar; // Fallback\n    }\n};\n```\n\n> **Quick Breakdown: Intrinsics**\n> These are C++ functions (like `_mm256_add_ps`) that look like normal code but are actually direct commands to the CPU hardware. They allow you to write assembly-level logic without leaving C++.\n\n[↑ Back to System Map](#satellite-map)\n\n\n<div id=\"ms-mem-align\"></div>\n\n# Memory Alignment & Buffer Management: The Tile Floor Principle\n\nImagine you are laying down large, heavy marble tiles that are exactly 32 inches wide. The floor has pre-etched grooves every 32 inches. If you place a tile perfectly within the grooves, it drops into place instantly. \n\nHowever, if you try to place a tile so that it overlaps a groove—covering 16 inches of one section and 16 inches of the next—the floor's support structure can't handle it. In the world of high-performance computing, the CPU either has to do double the work to \"stitch\" those two sections together, or it simply gives up and crashes your program. This is **Memory Alignment**.\n\n### Technical Rationale: The \"Why\"\nCPUs do not read memory one byte at a time. They read in \"chunks\" called **Cache Lines** (usually 64 bytes). \n\nWhen you use SIMD instructions, you are moving massive amounts of data (128, 256, or 512 bits) at once. \n1.  **Performance**: If a 256-bit AVX register loads data that straddles two different cache lines, the CPU must perform two memory fetches instead of one. This \"split load\" can cut your throughput in half.\n2.  **Correctness**: Many optimized SIMD instructions (like `MOVDQA` — Move Double Quadword **Aligned**) are hard-wired to expect addresses that are multiples of 16, 32, or 64. If you give them an \"odd\" address, the CPU triggers a **General Protection Fault**, and your application segfaults immediately.\n\n> **Quick Breakdown: GP Fault (General Protection Fault)**\n> This is the CPU's way of saying \"You broke the rules of the architecture.\" It’s a hardware-level emergency stop that happens when you try to execute an instruction on data that isn't prepared correctly (like unaligned memory).\n\n---\n\n### Internal Mechanics: The \"How\"\nTo achieve alignment, we use two primary strategies: **Aligned Allocation** and **Buffer Peeling**.\n\n#### The Microscope: The Math of the Mask\nHow do we know if an address is aligned? We look at the pointer's binary representation. For a 64-byte alignment, the last 6 bits of the memory address must be zero ($2^6 = 64$).\n\nTo align an arbitrary pointer `p` to a boundary `a`, we use this bitwise trick:\n`aligned_p = (p + (a - 1)) & ~(a - 1)`\n\n1.  **Add `a-1`**: This pushes the pointer forward just enough to cross the next alignment boundary.\n2.  **NOT `a-1`**: This creates a \"mask\" (e.g., for 64, it creates a mask where the last 6 bits are `0` and all others are `1`).\n3.  **AND `&`**: This \"chops off\" the extra bits, rounding the address down to the nearest perfect boundary.\n\n\n![Memory Alignment Strategy](./diagrams/diag-04.svg)\n\n\n![Cache Line Alignment Visualization](./diagrams/diag-22.svg)\n\n\n#### Handling the \"Head\" and \"Tail\"\nMost data buffers don't start or end perfectly on a 64-byte boundary. \n*   **The Peel**: We process the first few \"unaligned\" bytes using slow, scalar code until we hit the first aligned boundary.\n*   **The Main Loop**: We blast through the bulk of the data using high-speed, aligned SIMD instructions.\n*   **The Remainder**: We process the final leftover bytes (the \"tail\") that don't fill a whole SIMD register.\n\n\n![Unaligned Access Micro-Logic](./diagrams/diag-05.svg)\n\n\n![Buffer Padding & Tail Handling](./diagrams/diag-15.svg)\n\n\n---\n\n### The Debugging Lab: Common Pitfalls\n*   **The \"Off-By-One\" Alignment**: You allocated 1024 bytes, but your alignment padding pushed the start pointer forward by 32 bytes. If you try to write 1024 bytes starting from that new pointer, you will overflow the buffer.\n    *   *The Fix*: Always allocate `Size + Alignment` bytes to ensure there is enough \"runway\" for the padding.\n*   **Stack vs. Heap**: Standard `malloc` usually only guarantees 8 or 16-byte alignment. If you need 64-byte alignment for AVX-512, `malloc` will eventually fail you.\n    *   *The Fix*: Use specialized allocators like `_aligned_malloc` (Windows) or `posix_memalign` (Linux).\n\n---\n\n### Code Scaffold: The Aligned Buffer\nThis scaffold demonstrates how to create a wrapper that ensures memory is always ready for AVX-512 (64-byte alignment).\n\n```cpp\n#include <cstdlib>\n#include <cstdint>\n#include <stdexcept>\n\ntemplate <typename T>\nclass AlignedBuffer {\n    T* raw_ptr = nullptr;\n    T* aligned_data = nullptr;\n    size_t element_count;\n\npublic:\n    // We target 64-byte alignment to satisfy AVX-512 and Cache Line requirements\n    static constexpr size_t ALIGNMENT = 64;\n\n    AlignedBuffer(size_t count) : element_count(count) {\n        // 1. Allocate extra space to allow for shifting the pointer\n        size_t total_bytes = (count * sizeof(T)) + ALIGNMENT;\n        raw_ptr = static_cast<T*>(std::malloc(total_bytes));\n\n        if (!raw_ptr) throw std::bad_alloc();\n\n        // 2. Perform the Bitwise Alignment Math\n        uintptr_t address = reinterpret_cast<uintptr_t>(raw_ptr);\n        uintptr_t aligned_address = (address + (ALIGNMENT - 1)) & ~(ALIGNMENT - 1);\n        aligned_data = reinterpret_cast<T*>(aligned_address);\n    }\n\n    ~AlignedBuffer() {\n        // Always free the ORIGINAL pointer, not the aligned one!\n        std::free(raw_ptr);\n    }\n\n    T& operator[](size_t index) { return aligned_data[index]; }\n    T* data() { return aligned_data; }\n};\n```\n\n> **Quick Breakdown: uintptr_t**\n> You cannot perform bitwise math (like `&` or `~`) directly on a pointer. `uintptr_t` is an unsigned integer type that is guaranteed to be the same size as a pointer, allowing us to treat a memory address like a regular number for calculations.\n\n[↑ Back to System Map](#satellite-map)\n\n\n<div id=\"ms-string-simd\"></div>\n\n# Vectorized String Search: The Magic Stencil\n\nImagine you are looking for a specific letter 'Z' in a massive book. A **Scalar** approach is like reading every single letter one by one with a magnifying glass. It works, but it’s exhausting.\n\nNow, imagine you have a **Magic Stencil**. This stencil is 32 letters wide. You slap it down on a line of text, and it instantly highlights every 'Z' in that entire block. You don't \"read\" the block; you \"see\" the results all at once. **Vectorized String Search** is the art of using the CPU's SIMD registers as these magic stencils to find patterns in data at speeds exceeding 10GB/s.\n\n### Technical Rationale: The \"Why\"\nIn standard C++, `std::string::find` or `strstr` typically compares characters one at a time. While highly optimized, they are fundamentally limited by the \"one-at-a-time\" bottleneck. \n\nModern CPUs have 256-bit (AVX2) or 512-bit (AVX-512) registers. A single AVX2 register can hold **32 characters** (8-bit bytes) simultaneously. By loading a chunk of the haystack into a register and comparing it against a \"broadcasted\" version of our needle, we can perform 32 comparisons in a single CPU cycle.\n\n> **Quick Breakdown: Broadcast**\n> To \"Broadcast\" means to take a single value (like the character 'A') and copy it into every slot of a SIMD register. If you broadcast 'A' into a 256-bit register, you get a register containing 32 'A's.\n\n---\n\n### Internal Mechanics: The \"How\"\nWe use two primary hardware \"superpowers\" for this:\n\n#### 1. The AVX2 Masking Strategy\nThis is the most common modern approach. \n1.  **Load**: We load 32 bytes of the \"Haystack\" into a YMM register.\n2.  **Compare**: We use `_mm256_cmpeq_epi8` to compare our Haystack register against a register full of our \"Needle\" character.\n3.  **The Mask**: The CPU returns a \"Mask\"—a register where slots that matched are filled with `0xFF` (all ones) and slots that didn't are `0x00`.\n4.  **Compress**: We use `_mm256_movemask_epi8` to turn that massive 256-bit register into a simple 32-bit integer. Each bit in this integer represents one character. If bit 5 is `1`, the 5th character was a match!\n\n\n![String Search Pipeline](./diagrams/diag-06.svg)\n\n\n![AVX2 Mask Generation](./diagrams/diag-08.svg)\n\n\n#### 2. The SSE4.2 \"String Specialist\" (`PCMPESTRI`)\nIntel introduced a specific instruction just for strings: `PCMPESTRI`. It is a \"CISC\" (Complex Instruction Set) powerhouse. In one instruction, it can perform \"Equal Each,\" \"Equal Any,\" or \"Equal Ordered\" comparisons. It is incredibly powerful for finding substrings but is limited to 128-bit (16-byte) chunks.\n\n\n![SSE4.2 PCMPESTRI Internals](./diagrams/diag-07.svg)\n\n\n---\n\n### The Microscope: From Bits to Indices\nOnce we have our 32-bit integer mask from the AVX2 comparison, how do we know *where* the match is? We use a specialized CPU instruction called **Trailing Zero Count (TZCNT)** or **Bit Scan Forward (BSF)**.\n\nIf our mask is `00001000`, the CPU counts the zeros from the right. It sees 3 zeros, meaning the first match is at index 3. This allows us to jump directly to the match without ever looping through the bits.\n\n\n![Bitmask Bit-Scan (BSF/BSR)](./diagrams/diag-21.svg)\n\n\n---\n\n### The Debugging Lab: Common Pitfalls\n*   **The Page Boundary Segfault**: This is the \"Final Boss\" of SIMD. If you try to read 32 bytes from a string that only has 5 bytes left, and those extra 27 bytes happen to cross over into a \"forbidden\" memory page, the CPU will crash your program—even if you intended to ignore those extra bytes!\n    *   *The Fix*: Never read a full SIMD width if you are within 32/64 bytes of a page boundary (4KB). Use a safe scalar fallback for the very end of the string.\n*   **False Positives in Substrings**: If you are looking for \"CAT\", and you find a 'C' at the very end of your SIMD register, the 'A' and 'T' might be in the *next* register load.\n    *   *The Fix*: Use \"Sliding Window\" logic or specialized instructions like `_mm256_mpsadbw_epu8` for multi-byte sequences.\n\n---\n\n### Code Scaffold: AVX2 Character Search\nThis is a high-performance \"Find First Of\" implementation.\n\n```cpp\n#include <immintrin.h>\n#include <cstdint>\n\n/**\n * Find the first occurrence of 'target' in 'data'\n * Returns the index, or 'size' if not found.\n */\nsize_t FindFirstChar_AVX2(const char* data, size_t size, char target) {\n    size_t i = 0;\n\n    // 1. Create the \"Magic Stencil\" (Broadcast target to all 32 lanes)\n    __m256i needle = _mm256_set1_epi8(target);\n\n    // 2. Process in 32-byte chunks\n    for (; i + 31 < size; i += 32) {\n        // Load 32 bytes from the haystack\n        __m256i haystack = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(data + i));\n\n        // Compare haystack to needle (Result is a mask of 0xFF or 0x00)\n        __m256i comparison = _mm256_cmpeq_epi8(haystack, needle);\n\n        // Convert the 256-bit mask into a 32-bit integer\n        int mask = _mm256_movemask_epi8(comparison);\n\n        if (mask != 0) {\n            // 3. Use the \"Bit Scan\" to find the exact index of the first '1' bit\n            // __builtin_ctz = Count Trailing Zeros\n            return i + __builtin_ctz(mask);\n        }\n    }\n\n    // 4. The \"Tail\": Process remaining bytes (< 32) one by one\n    for (; i < size; ++i) {\n        if (data[i] == target) return i;\n    }\n\n    return size;\n}\n```\n\n> **Quick Breakdown: _mm256_loadu_si256**\n> The `u` in `loadu` stands for **Unaligned**. This tells the CPU \"I don't guarantee this string starts on a perfect 32-byte boundary, please handle the memory fetch carefully.\" It is slightly slower than an aligned load but prevents crashes on arbitrary strings.\n\n[↑ Back to System Map](#satellite-map)\n\n\n<div id=\"ms-memcpy-opt\"></div>\n\n# Optimized Memory Transfer: The Fireman’s Chute\n\nImagine you are moving 1,000 boxes of books into a new library. \n\nA **Standard Memcpy** is like carrying each box through the library’s main reading room (the **CPU Cache**). It’s fine for a few boxes, but if you move 1,000, you’ll crowd the reading room, kick out the people studying there, and clutter the space. \n\nAn **Optimized Memcpy with Non-Temporal Stores** is like installing a temporary \"Fireman’s Chute\" on the side of the building. The boxes slide directly from the truck to the shelf, bypassing the reading room entirely. The students (other active data) stay undisturbed in the cache, and the transfer happens at the maximum speed the \"chute\" (memory bus) can handle.\n\n> **Quick Breakdown: Non-Temporal Store**\n> Normally, when the CPU writes data to memory, it assumes you’ll want to read that data again soon, so it keeps a copy in the fast **L1/L2 Cache**. A \"Non-Temporal\" store tells the CPU: \"I’m writing this data, but I won't need it again for a while. Don't waste space in the cache; send it straight to the RAM.\"\n\n---\n\n### Technical Rationale: The \"Why\"\nStandard `memcpy` is a general-purpose tool. However, when dealing with \"Big Data\" (multi-megabyte buffers), it suffers from **Cache Pollution**. By forcing massive amounts of data through the cache, the CPU evicts the instructions and data your program actually needs to run, causing a massive slowdown immediately after the copy finishes.\n\nBy using **AVX-512** registers, we can move 64 bytes in a single instruction. By using **Streaming (Non-Temporal) instructions**, we bypass the cache hierarchy, preserving performance for the rest of the application.\n\n---\n\n### Internal Mechanics: The \"How\"\nThe secret to this speed is the interaction between the **ZMM Registers** and the **Write-Combining Buffers**.\n\n#### The Microscope: The Write-Combining Buffer\nWhen you use a streaming store instruction like `_mm512_stream_si512`, the data doesn't go to the L1 Cache. Instead, it goes to a small, specialized piece of hardware called the **Write-Combining (WC) Buffer**.\n1. The CPU collects several 64-byte writes into the WC Buffer.\n2. Once the buffer is full, the CPU sends the entire \"burst\" across the memory bus to the RAM in one highly efficient transaction.\n3. This reduces the \"chatter\" on the memory bus and prevents the CPU from having to \"read-for-ownership\" (checking if other cores have the data) before writing.\n\n\n![Memcpy Orchestrator](./diagrams/diag-09.svg)\n\n\n![AVX-512 Memcpy Path](./diagrams/diag-10.svg)\n\n\n![Non-Temporal Store Logic](./diagrams/diag-11.svg)\n\n\n---\n\n### The Debugging Lab: Common Pitfalls\n*   **The \"Small Buffer\" Penalty**: Non-temporal stores have a high \"startup cost.\" If you use them to copy a tiny 16-byte string, it will be significantly slower than a standard copy because the Write-Combining buffer won't fill up, and the CPU has to wait to flush it.\n    *   *The Fix*: Only use the \"Streaming Path\" for buffers larger than the L2 or L3 cache (typically > 1MB).\n*   **Alignment Requirements**: Most streaming instructions (like `VMOVNTDQ`) **require** the memory address to be perfectly aligned to the register width (e.g., 64-byte alignment for AVX-512). If the address is off by even one byte, the program will crash with a `General Protection Fault`.\n    *   *The Fix*: Use the \"Peeling\" technique we learned in the Memory Alignment section to handle the unaligned start of the buffer.\n\n---\n\n### Code Scaffold: The High-Throughput Copy\nThis scaffold demonstrates how to implement a \"Streaming\" copy that uses AVX-512 to blast data directly to RAM.\n\n```cpp\n#include <immintrin.h>\n#include <cstddef>\n\n/**\n * Optimized Memcpy for LARGE buffers.\n * Requirements: 'dest' and 'src' should be 64-byte aligned for max speed.\n */\nvoid Memcpy_Streaming_AVX512(void* dest, const void* src, size_t size) {\n    char* d = static_cast<char*>(dest);\n    const char* s = static_cast<const char*>(src);\n    \n    size_t i = 0;\n\n    // 1. The Main Heavy-Lifting Loop (64 bytes per iteration)\n    // We use __m512i to represent a 512-bit ZMM register\n    for (; i + 63 < size; i += 64) {\n        // Load data from source into a ZMM register\n        // _mm512_loadu_si512 = Load Unaligned (Safe)\n        __m512i chunk = _mm512_loadu_si512(reinterpret_cast<const __m512i*>(s + i));\n\n        // 2. The \"Fireman's Chute\": Non-Temporal Store\n        // _mm512_stream_si512 = Write directly to RAM, bypassing cache.\n        // NOTE: This instruction REQUIRES 'dest' to be 64-byte aligned!\n        _mm512_stream_si512(reinterpret_cast<__m512i*>(d + i), chunk);\n    }\n\n    // 3. The \"SFENCE\" (Store Fence)\n    // Because streaming stores are \"weakly ordered,\" we must tell the CPU:\n    // \"Finish all those background writes before anyone else reads this memory!\"\n    _mm_sfence();\n\n    // 4. The Tail: Handle remaining bytes with standard logic\n    for (; i < size; ++i) {\n        d[i] = s[i];\n    }\n}\n```\n\n> **Quick Breakdown: SFENCE**\n> Think of `SFENCE` as a \"Save Game\" button. Because non-temporal stores happen in the background via the Write-Combining buffers, the rest of your program might try to read the memory before the \"chute\" has finished dropping the boxes. `SFENCE` forces the CPU to finish all pending stores before moving to the next line of code.\n\n[↑ Back to System Map](#satellite-map)\n\n\n<div id=\"ms-checksum-simd\"></div>\n\n# SIMD Checksum & Hashing: The Multi-Lane Toll Booth\n\nImagine you are a toll booth operator on a massive highway. Thousands of cars are passing through, and your job is to count exactly how many passengers are in every car to ensure the \"Total Passenger Count\" (the **Checksum**) matches the manifest.\n\nA **Scalar** approach is like having a single toll lane. You stop one car, count the people, add it to your clipboard, and move to the next. If the highway is packed, the traffic backs up for miles.\n\nA **SIMD Checksum** is like opening 8 or 16 lanes simultaneously. You have a camera over the highway that snaps a picture of 8 cars at once. You count all the passengers in those 8 cars in a single \"blink\" and add that sub-total to your master list. You aren't just working faster; you are processing the entire width of the highway in parallel.\n\n> **Quick Breakdown: Checksum**\n> A checksum is a small datum derived from a block of digital data for the purpose of detecting errors that may have been introduced during its transmission or storage. Think of it like a \"digital fingerprint\" of a file.\n\n---\n\n### Technical Rationale: The \"Why\"\nCalculating a checksum (like CRC32) or a hash (like MurmurHash or HighwayHash) is often the final bottleneck in data pipelines. Whether you are verifying a download or indexing a database, you have to touch every single byte.\n\nIn a serial world, CRC32 is \"recursive\"—the calculation for the next byte depends on the result of the previous byte. This is a nightmare for performance. However, modern CPUs provide specialized instructions (like `PCLMULQDQ` for Carry-less Multiplication) that allow us to break the data into independent chunks, calculate \"partial\" checksums in parallel lanes, and then fold them together at the end.\n\n---\n\n### Internal Mechanics: The \"How\"\nTo parallelize a checksum, we use a technique called **Multi-Stream Processing**.\n\n#### 1. The Parallel Lanes\nInstead of one rolling total, we maintain multiple independent totals. If we use AVX2, we can treat a 256-bit register as eight 32-bit \"lanes.\"\n*   Lane 1 processes bytes 0, 8, 16...\n*   Lane 2 processes bytes 1, 9, 17...\n*   ...and so on.\n\n#### 2. The Hardware Accelerator (`_mm_crc32_u64`)\nIntel and AMD CPUs have a dedicated circuit just for CRC32. It’s not a general-purpose math unit; it’s a hard-wired \"CRC machine.\" By using the `_mm_crc32_u64` intrinsic, we can process 8 bytes at a time with near-zero latency.\n\n\n![Checksum Pipeline](./diagrams/diag-12.svg)\n\n\n![CRC32 Hardware Acceleration](./diagrams/diag-13.svg)\n\n\n#### 3. The \"Fold\" (Galois Field Math)\nOnce we reach the end of the data, we have 8 different partial checksums. We can't just add them together (math doesn't work that way for CRC). We use a \"Fold\" operation, which uses specialized SIMD math to combine these 8 fingerprints into one final, authoritative 32-bit CRC.\n\n\n![AVX2 Parallel Hashing](./diagrams/diag-14.svg)\n\n\n---\n\n### The Microscope: The XOR Operation\nAt the heart of almost every checksum and hash is the **XOR (Exclusive OR)** operation. \nIn binary:\n*   `0 XOR 0 = 0`\n*   `1 XOR 1 = 0`\n*   `1 XOR 0 = 1`\n\nWhy XOR? Because it’s \"reversible\" and doesn't \"carry\" like addition does. In SIMD, `_mm256_xor_si256` is one of the fastest instructions in existence, often executing in 0.5 cycles. It is the \"glue\" that binds parallel hashing together.\n\n---\n\n### The Debugging Lab: Common Pitfalls\n*   **The Endianness Trap**: If you calculate a SIMD checksum on a Little-Endian machine (Intel) and compare it to a result from a Big-Endian machine (older PowerPC), the bytes in your registers will be swapped, and the checksums won't match.\n    *   *The Fix*: Always use `_mm_shuffle_epi8` to normalize byte order if your protocol requires a specific \"Network Byte Order.\"\n*   **The Final XOR**: Many CRC algorithms (like CRC32-IEEE) require you to XOR the final result with `0xFFFFFFFF` at the very end. If you forget this \"final flip,\" your checksum will be perfectly calculated but technically \"wrong\" according to the standard.\n*   **The Seed Value**: If you start your parallel lanes with a seed of `0`, but the standard expects `0xFFFFFFFF`, your lanes will diverge immediately.\n\n---\n\n### Code Scaffold: Parallel Additive Checksum\nWhile a full CRC32 is complex, this scaffold shows the \"Mental Model\" of a vectorized additive checksum (summing 32-bit integers in parallel).\n\n```cpp\n#include <immintrin.h>\n#include <cstdint>\n\n/**\n * Calculates a simple 32-bit additive checksum using AVX2.\n * This processes 8 integers (32 bytes) per cycle.\n */\nuint32_t CalculateChecksum_AVX2(const uint32_t* data, size_t count) {\n    // 1. Initialize a register of 8 zeros (our 8 parallel \"toll lanes\")\n    __m256i v_sum = _mm256_setzero_si256();\n\n    size_t i = 0;\n    // 2. Process 8 integers at a time\n    for (; i + 7 < count; i += 8) {\n        // Load 8 integers into a YMM register\n        __m256i v_data = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(&data[i]));\n        \n        // Add the 8 integers to our 8 running totals in parallel\n        v_sum = _mm256_add_epi32(v_sum, v_data);\n    }\n\n    // 3. The \"Horizontal Fold\"\n    // We have 8 partial sums in one register. We need to add them together.\n    // We extract the two 128-bit halves and add them.\n    __m128i v_low = _mm256_castsi256_si128(v_sum);\n    __m128i v_high = _mm256_extracti128_si256(v_sum, 1);\n    __m128i v_final128 = _mm_add_epi32(v_low, v_high);\n\n    // Further reduce 128-bit (4 ints) to 1 int\n    uint32_t results[4];\n    _mm_storeu_si128(reinterpret_cast<__m128i*>(results), v_final128);\n\n    uint32_t final_checksum = results[0] + results[1] + results[2] + results[3];\n\n    // 4. Handle the Tail (remaining elements < 8)\n    for (; i < count; ++i) {\n        final_checksum += data[i];\n    }\n\n    return final_checksum;\n}\n```\n\n> **Quick Breakdown: Horizontal Fold**\n> SIMD is great at \"Vertical\" math (Lane A + Lane A). It is naturally bad at \"Horizontal\" math (Lane A + Lane B). To get a single total, we have to \"fold\" the register in half repeatedly until only one value remains.\n\n[↑ Back to System Map](#satellite-map)\n\n\n<div id=\"ms-bench-validation\"></div>\n\n# Validation & Benchmarking: The Master Blueprint & The Stopwatch\n\nImagine you’ve just built a high-speed experimental jet engine (your **SIMD Kernel**). It’s theoretically capable of Mach 5, but how do you prove it?\n\nFirst, you need a **Master Blueprint**. You take a standard, reliable propeller plane (your **Scalar Reference**) and fly it to a destination. You record exactly what the landscape looks like. Then, you fly your jet. If the jet arrives at a place that looks different from the blueprint, your engine is broken—it doesn't matter how fast it got there. This is **Validation**.\n\nSecond, you need a **Precision Stopwatch**. You can't just look at a wall clock; you need to measure the exact moment the fuel ignites. You also need to account for the wind and the weight of the fuel. This is **Benchmarking**.\n\n> **Quick Breakdown: Scalar Reference**\n> A \"Scalar\" version of your code is the simplest, most readable C++ version (usually a basic `for` loop). Because it's simple, it's unlikely to have bugs. We use it as the \"Ground Truth\" to ensure our complex SIMD code produces the exact same results.\n\n---\n\n### Technical Rationale: The \"Why\"\nSIMD programming is notoriously \"brittle.\" A single off-by-one error in your tail-handling logic or a misunderstood bit-shift can result in \"Silent Data Corruption\"—where the program runs perfectly fine but the output is slightly wrong.\n\nFurthermore, \"Fast\" is a relative term. On some CPUs, AVX-512 might actually be *slower* than AVX2 because the CPU lowers its clock speed (throttling) to handle the massive power draw of 512-bit instructions. Without a rigorous benchmarking suite, you are just guessing.\n\n---\n\n### Internal Mechanics: The \"How\"\n\n#### 1. Differential Testing (The Ground Truth)\nWe run the same data through two pipes:\n1.  `Result_A = Scalar_Implementation(input)`\n2.  `Result_B = SIMD_Implementation(input)`\n3.  `Assert(Result_A == Result_B)`\n\nWe do this across \"Edge Cases\": empty buffers, buffers with 1 byte, buffers that are exactly 31 bytes (just under an AVX2 window), and buffers that cross memory page boundaries.\n\n#### 2. The High-Resolution Timer (`RDTSC`)\nStandard timers like `std::chrono` are often too \"blunt\" for SIMD. To measure a kernel that takes only 200 nanoseconds, we use the **RDTSC (Read Time-Stamp Counter)** instruction. This returns the exact number of CPU cycles that have passed since the processor started.\n\n\n![Benchmarking Framework](./diagrams/diag-17.svg)\n\n\n#### 3. Throughput vs. Latency\n*   **Latency**: How long does it take for *one* operation to finish? (Important for real-time audio).\n*   **Throughput**: How many operations can we finish per second? (Important for database scanning).\nSIMD is designed to maximize **Throughput**.\n\n---\n\n### The Microscope: The \"Warm-up\" and \"Cache State\"\nWhen you benchmark, the first run is always the slowest. Why?\n1.  **Instruction Cache**: The CPU has to fetch your SIMD code from RAM into the fast L1 instruction cache.\n2.  **Data Cache**: The data you are processing isn't in the cache yet (**Cold Cache**).\n3.  **Branch Predictor**: The CPU hasn't \"learned\" the pattern of your loops yet.\n\nTo get a \"Deep Technical Truth,\" we run a **Warm-up Loop** (executing the code 1,000 times without recording) before we start the actual measurement.\n\n---\n\n### The Debugging Lab: Common Pitfalls\n*   **The Optimizer's Vanishing Act**: If you write a benchmark that calculates a result but never *uses* that result, the C++ compiler will notice. It will say, \"This code does nothing,\" and delete your entire SIMD loop. Your benchmark will report `0.000ns`.\n    *   *The Fix*: Use `benchmark::DoNotOptimize()` (in Google Benchmark) or a `volatile` pointer to force the compiler to keep the code.\n*   **Frequency Scaling (Turbo Boost)**: Modern CPUs change their speed constantly. If your laptop is unplugged, it might run at 1.2GHz. If it's plugged in and \"cold,\" it might hit 4.8GHz.\n    *   *The Fix*: Pin the CPU frequency during benchmarks or measure in **Cycles** instead of **Seconds**.\n\n---\n\n### Code Scaffold: The Validation Harness\nThis scaffold provides a template for comparing a SIMD search against a standard C++ search.\n\n```cpp\n#include <iostream>\n#include <vector>\n#include <cassert>\n#include <chrono>\n\n// 1. The \"Ground Truth\" (Scalar)\nsize_t ScalarSearch(const char* data, size_t size, char target) {\n    for (size_t i = 0; i < size; ++i) {\n        if (data[i] == target) return i;\n    }\n    return size;\n}\n\n// 2. The \"Experimental Engine\" (SIMD - Placeholder)\nextern size_t FindFirstChar_AVX2(const char* data, size_t size, char target);\n\nvoid RunValidationSuite() {\n    std::vector<size_t> test_sizes = {0, 1, 15, 16, 31, 32, 65, 1024};\n    \n    for (size_t size : test_sizes) {\n        std::vector<char> buffer(size, 'A');\n        if (size > 0) buffer[size - 1] = 'Z'; // Put target at the very end\n\n        size_t expected = ScalarSearch(buffer.data(), buffer.size(), 'Z');\n        size_t actual = FindFirstChar_AVX2(buffer.data(), buffer.size(), 'Z');\n\n        if (expected != actual) {\n            std::printf(\"FAILED: Size %zu | Expected %zu, Got %zu\\n\", size, expected, actual);\n        } else {\n            std::printf(\"PASSED: Size %zu\\n\", size);\n        }\n    }\n}\n\n/**\n * A simple cycle-counting wrapper\n */\nstatic inline uint64_t rdtsc() {\n    unsigned int lo, hi;\n    __asm__ __volatile__ (\"rdtsc\" : \"=a\" (lo), \"=d\" (hi));\n    return ((uint64_t)hi << 32) | lo;\n}\n```\n\n> **Quick Breakdown: __asm__ __volatile__**\n> This is \"Inline Assembly.\" It tells the compiler: \"Stop! Don't try to optimize this. Just insert the raw `rdtsc` CPU instruction exactly where I put it.\" The `volatile` keyword ensures the compiler doesn't move this instruction around, which would ruin our timing.\n\n[↑ Back to System Map](#satellite-map)\n"}