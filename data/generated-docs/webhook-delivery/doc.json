{"html":"<h1 id=\"webhook-delivery-system-design-document\">Webhook Delivery System: Design Document</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>A reliable webhook delivery system that provides guaranteed event delivery to HTTP endpoints with security, fault tolerance, and observability. The key architectural challenge is building resilience against network failures, endpoint downtime, and security threats while maintaining ordered delivery and preventing data loss.</p>\n<p><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fsystem-overview.svg\" alt=\"System Overview\"></p>\n<blockquote>\n<p>This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.</p>\n</blockquote>\n<h2 id=\"context-and-problem-statement\">Context and Problem Statement</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones - establishes core webhook delivery challenges addressed throughout the project</p>\n</blockquote>\n<h3 id=\"mental-model-the-digital-postal-service\">Mental Model: The Digital Postal Service</h3>\n<p>Think of webhooks as a <strong>digital postal service</strong> for the internet. When something important happens in your application—a payment is processed, an order is placed, or a user signs up—you need to notify other systems about this event. Just like how you might send a letter through the postal service, webhooks deliver event notifications to registered &quot;addresses&quot; (HTTP endpoints) across the web.</p>\n<p>In this analogy, our webhook delivery system acts as the <strong>postal infrastructure</strong>. When an event occurs (someone wants to send a letter), we need to:</p>\n<ol>\n<li><p><strong>Verify the destination address</strong> - Ensure the recipient endpoint actually exists and wants to receive mail from us, similar to how postal services validate addresses and require recipients to register for certain types of mail delivery.</p>\n</li>\n<li><p><strong>Package and sign the message</strong> - Wrap the event data in a secure envelope with tamper-proof sealing (cryptographic signatures), just like how important documents are sent with authentication seals and tracking numbers.</p>\n</li>\n<li><p><strong>Handle delivery failures gracefully</strong> - If the recipient isn&#39;t home (endpoint is down), we don&#39;t just throw the mail away. We try again later, maybe multiple times, with increasing delays between attempts. Eventually, if delivery consistently fails, we might mark the address as undeliverable and alert the sender.</p>\n</li>\n<li><p><strong>Maintain delivery order</strong> - Critical mail to the same recipient should arrive in the order it was sent. If you mail a check and then a deposit slip to your bank, the bank needs to process them in the correct sequence.</p>\n</li>\n<li><p><strong>Protect against fraud</strong> - We need to prevent malicious actors from sending fake mail claiming to be from legitimate senders, and we must avoid delivering mail to dangerous addresses that might be traps.</p>\n</li>\n<li><p><strong>Provide tracking and receipts</strong> - Just like package tracking, we need to log every delivery attempt, record when messages were successfully delivered, and provide detailed status information for debugging failed deliveries.</p>\n</li>\n</ol>\n<p>The key insight is that <strong>reliability trumps speed</strong> in webhook delivery. It&#39;s better to deliver an event notification 30 seconds late than to lose it entirely. Unlike real-time API calls where users are waiting for immediate responses, webhooks are asynchronous notifications where consistency and guarantees matter more than low latency.</p>\n<p>However, this postal service operates at internet scale with additional complexities that physical mail doesn&#39;t face: endpoints can go down and recover within seconds, network connections can fail mid-delivery, and malicious actors can easily create fake addresses or overwhelm recipients with spam. Our system must be resilient against all these failure modes while maintaining the delivery guarantees that make webhooks reliable for business-critical integrations.</p>\n<h3 id=\"reliability-challenges\">Reliability Challenges</h3>\n<p>The fundamental challenge in webhook delivery lies in bridging the gap between <strong>at-least-once delivery guarantees</strong> and the unreliable nature of HTTP network communication. Unlike database transactions or message queues that operate within controlled environments, webhooks must traverse the public internet to reach endpoints controlled by external parties who may implement unreliable services, experience downtime, or even disappear entirely.</p>\n<h4 id=\"network-and-transport-failures\">Network and Transport Failures</h4>\n<p>Network communication introduces multiple failure vectors that don&#39;t exist in local system operations. <strong>DNS resolution can fail</strong> when endpoint domains become temporarily unreachable or permanently invalid. <strong>TCP connection establishment can time out</strong> due to network congestion, firewall rules, or endpoint server overload. <strong>HTTP requests can hang indefinitely</strong> if recipient services accept connections but fail to process requests, creating resource leaks in our delivery workers.</p>\n<p>The challenge deepens when we consider <strong>partial failures during transmission</strong>. A webhook payload might be successfully sent, but the response indicating successful processing might be lost due to network interruption. This creates an uncertainty window where we don&#39;t know if the recipient processed the event. Naive retry logic could lead to duplicate processing, while conservative approaches might lose events entirely.</p>\n<p><strong>Connection pooling and keep-alive</strong> present additional complexity. While reusing connections improves performance, long-lived connections can become stale or encounter proxy timeouts. Our delivery system must detect and recover from these scenarios without losing in-flight events.</p>\n<h4 id=\"endpoint-reliability-and-downtime\">Endpoint Reliability and Downtime</h4>\n<p>External webhook endpoints exhibit far more diverse failure patterns than internal services. <strong>Recipient services may experience deployment downtime</strong> lasting minutes to hours, during which all delivery attempts will fail. <strong>Capacity limits</strong> at recipient endpoints can cause intermittent failures when our delivery rate exceeds their processing capability. <strong>Code bugs in recipient handlers</strong> might cause consistent failures for specific event types while allowing others to succeed.</p>\n<p>More challenging are <strong>partial failure scenarios</strong> where endpoints return successful HTTP status codes but fail to process events correctly due to internal errors. Our system cannot detect these failures without additional feedback mechanisms, yet we must provide debugging tools to help webhook consumers identify and resolve processing issues.</p>\n<p><strong>Endpoint migration and URL changes</strong> create another reliability challenge. Long-running webhook subscriptions may outlive the original endpoint URLs. Our system needs graceful handling of permanent redirects while protecting against malicious redirect attacks.</p>\n<h4 id=\"security-and-trust-boundaries\">Security and Trust Boundaries</h4>\n<p>Webhook delivery crosses organizational trust boundaries, creating unique security challenges not present in internal system communication. <strong>Payload integrity</strong> must be maintained across the public internet, requiring cryptographic signatures that recipients can verify. <strong>Authentication</strong> mechanisms must prevent spoofed webhook deliveries while remaining simple enough for diverse recipient implementations.</p>\n<p><strong>Server-Side Request Forgery (SSRF) attacks</strong> pose a critical threat where malicious actors register internal IP addresses as webhook endpoints, potentially allowing them to probe or attack internal infrastructure through our delivery system. <strong>Timing attacks</strong> against signature verification could leak signing keys. <strong>Replay attacks</strong> might allow malicious actors to resend captured webhook payloads at inappropriate times.</p>\n<p>The security model must also handle <strong>secret rotation</strong> seamlessly. Signing keys need periodic updates for security hygiene, but rotation cannot break in-flight deliveries or require precise coordination between our system and all webhook consumers.</p>\n<h4 id=\"ordering-and-consistency-guarantees\">Ordering and Consistency Guarantees</h4>\n<p>Many webhook use cases require <strong>strict ordering guarantees per endpoint</strong>. Financial systems processing payment notifications, inventory systems tracking stock changes, and audit systems recording user actions all depend on receiving events in the order they occurred. However, implementing ordering at scale creates significant architectural constraints.</p>\n<p><strong>Parallel processing</strong> conflicts with ordering requirements. While we could process all webhooks sequentially, this approach cannot scale to handle high event volumes. The solution requires <strong>per-endpoint ordering</strong> while allowing parallelization across different endpoints.</p>\n<p><strong>Failure recovery complicates ordering</strong> significantly. If event N fails delivery but event N+1 succeeds, we must decide whether to block future events until N succeeds (risking head-of-line blocking) or allow out-of-order delivery with eventual consistency. Different use cases require different trade-offs, making this a configurable system behavior rather than a fixed architectural decision.</p>\n<p><strong>Replay scenarios</strong> after system failures must maintain ordering consistency. If our delivery system crashes and restarts, queued events must resume processing in their original order, even if some events were partially processed before the failure.</p>\n<h4 id=\"scale-and-performance-constraints\">Scale and Performance Constraints</h4>\n<p>High-volume webhook delivery systems must handle <strong>thousands of events per second</strong> while maintaining per-endpoint delivery guarantees. This scale requirement conflicts with many reliability patterns that work well for smaller systems.</p>\n<p><strong>Exponential backoff retry logic</strong> can create exponentially growing queues during widespread endpoint downtime. If 100 endpoints go offline for an hour, and events are generated every second, the retry queue could grow to hundreds of thousands of entries. Our system must bound retry queue growth while preserving ordering and delivery guarantees.</p>\n<p><strong>Circuit breaker patterns</strong> help protect failing endpoints but introduce state management complexity. Per-endpoint circuit breaker state must persist across system restarts and be shared across multiple delivery worker processes. <strong>Rate limiting</strong> adds another layer of per-endpoint state that must be coordinated system-wide.</p>\n<p><strong>Database contention</strong> becomes a bottleneck when thousands of delivery workers update event status concurrently. Traditional RDBMS row locking doesn&#39;t scale to this level of concurrent updates on shared tables.</p>\n<h3 id=\"existing-approaches-comparison\">Existing Approaches Comparison</h3>\n<p>Understanding the landscape of webhook delivery approaches helps illuminate why a queue-based system with circuit breakers represents the optimal balance for most use cases. Each approach makes different trade-offs between simplicity, reliability, performance, and operational complexity.</p>\n<blockquote>\n<p><strong>Decision: Queue-Based Delivery Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook delivery systems must balance reliability, performance, and operational complexity while handling diverse failure scenarios at scale</li>\n<li><strong>Options Considered</strong>: Direct HTTP delivery, queue-based delivery with retry logic, event streaming with consumer groups</li>\n<li><strong>Decision</strong>: Queue-based delivery with per-endpoint ordering and circuit breaker protection</li>\n<li><strong>Rationale</strong>: Provides at-least-once delivery guarantees with bounded failure impact while maintaining implementable complexity for most organizations</li>\n<li><strong>Consequences</strong>: Requires message queue infrastructure and adds delivery latency, but enables reliable delivery with comprehensive failure handling</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Reliability</th>\n<th>Performance</th>\n<th>Complexity</th>\n<th>Operational Overhead</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Direct HTTP</td>\n<td>Low - no retry or failure handling</td>\n<td>High - minimal latency</td>\n<td>Low - simple implementation</td>\n<td>Low - stateless operation</td>\n</tr>\n<tr>\n<td>Queue-Based</td>\n<td>High - comprehensive retry and DLQ</td>\n<td>Medium - adds queue latency</td>\n<td>Medium - requires queue infrastructure</td>\n<td>Medium - queue monitoring needed</td>\n</tr>\n<tr>\n<td>Event Streaming</td>\n<td>Very High - durable log with replay</td>\n<td>High - parallel processing</td>\n<td>High - complex consumer coordination</td>\n<td>High - requires streaming platform</td>\n</tr>\n</tbody></table>\n<h4 id=\"direct-http-delivery-approach\">Direct HTTP Delivery Approach</h4>\n<p>The simplest webhook delivery approach involves <strong>immediate HTTP POST requests</strong> when events occur. This synchronous model treats webhook delivery like a regular API call: serialize the event payload, generate a signature, make an HTTP request to each registered endpoint, and return success or failure to the event producer.</p>\n<p><strong>Advantages of direct delivery</strong> include minimal infrastructure requirements (no message queues), low latency (immediate delivery), and simple debugging (direct correlation between events and HTTP requests). The implementation complexity stays low because there&#39;s no separate delivery worker process or persistent queue state to manage.</p>\n<p>However, <strong>direct delivery fails catastrophically under common failure scenarios</strong>. When recipient endpoints experience downtime, events are simply lost unless the event producer implements its own retry logic. <strong>Slow endpoints block event producers</strong> because the producer must wait for HTTP responses before continuing. <strong>Cascading failures</strong> occur when endpoint downtime causes event producer slowdown, potentially affecting user-facing operations.</p>\n<p><strong>Partial failure handling</strong> becomes the responsibility of event producers, who typically aren&#39;t equipped to implement exponential backoff, circuit breakers, and dead letter queues. This leads to inconsistent reliability behavior across different event types and makes system-wide webhook reliability impossible to guarantee.</p>\n<p>Direct delivery works acceptably for <strong>non-critical notifications</strong> where occasional event loss is tolerable, such as optional email notifications or analytics events. However, it&#39;s unsuitable for business-critical integrations like payment notifications or inventory updates where reliability requirements are strict.</p>\n<h4 id=\"queue-based-delivery-with-retry-logic\">Queue-Based Delivery with Retry Logic</h4>\n<p>Queue-based delivery <strong>decouples event production from delivery</strong> using a persistent message queue as an intermediate buffer. When events occur, they&#39;re immediately written to a durable queue and acknowledged to the producer. Separate delivery workers consume from the queue, perform HTTP delivery, and implement retry logic for failures.</p>\n<p>This approach provides <strong>at-least-once delivery guarantees</strong> because events persist in the queue until successful delivery. <strong>Event producers remain fast</strong> because queue writes are typically much faster than HTTP requests across the internet. <strong>Comprehensive retry logic</strong> can be implemented in delivery workers without affecting event producers.</p>\n<p><strong>Failure isolation</strong> improves significantly because endpoint downtime only affects the delivery workers, not event production. <strong>Per-endpoint circuit breakers</strong> can disable failing endpoints without impacting deliveries to healthy endpoints. <strong>Dead letter queues</strong> capture permanently failed events for manual intervention while allowing the system to continue processing new events.</p>\n<p>The <strong>ordering challenge</strong> requires careful queue design. Simple FIFO queues provide global ordering but create head-of-line blocking when any endpoint fails. <strong>Per-endpoint queues</strong> enable parallel processing while maintaining ordering per destination, but require more complex queue management and worker coordination.</p>\n<p><strong>Operational complexity</strong> increases because the system now requires queue infrastructure (Redis, RabbitMQ, or cloud queues), queue monitoring, and worker process management. <strong>Delivery latency</strong> increases due to queue buffering, though this latency is typically acceptable for asynchronous webhook use cases.</p>\n<p>Queue-based delivery represents the <strong>sweet spot for most webhook systems</strong> because it provides strong reliability guarantees without requiring the operational complexity of full event streaming platforms.</p>\n<h4 id=\"event-streaming-with-consumer-groups\">Event Streaming with Consumer Groups</h4>\n<p>Event streaming platforms like Apache Kafka treat webhook events as entries in a <strong>durable, ordered log</strong>. Events are written to topic partitions and consumed by delivery workers organized into consumer groups. This approach provides the strongest durability and replay guarantees at the cost of significant operational complexity.</p>\n<p><strong>Streaming advantages</strong> include <strong>perfect event replay</strong> capability (reprocess events from any point in time), <strong>horizontal scalability</strong> through partition parallelism, and <strong>exactly-once processing</strong> semantics when combined with idempotent delivery logic. <strong>Consumer group rebalancing</strong> automatically distributes work when delivery workers are added or removed.</p>\n<p><strong>Partition-based ordering</strong> allows parallel processing while maintaining ordering within partitions. By partitioning events by endpoint URL, each endpoint&#39;s events maintain strict ordering while allowing parallel delivery across endpoints.</p>\n<p>However, <strong>operational overhead</strong> becomes substantial. Streaming platforms require cluster management, partition rebalancing monitoring, offset management, and complex failure recovery procedures. <strong>Development complexity</strong> increases because delivery workers must implement streaming consumer protocols and handle partition rebalancing gracefully.</p>\n<p><strong>Resource overhead</strong> is significant because streaming platforms maintain durable logs for extended periods. A high-volume webhook system might generate terabytes of event data monthly, requiring substantial storage and network resources for log replication.</p>\n<p><strong>Delivery latency</strong> can increase due to batching optimizations in streaming platforms, though this is often tunable through consumer configuration.</p>\n<p>Event streaming excels for <strong>very high-volume systems</strong> (millions of events per day) or scenarios requiring <strong>comprehensive audit trails</strong> with replay capability. However, the operational complexity makes it overkill for most webhook delivery use cases where queue-based delivery provides sufficient reliability guarantees with much lower operational overhead.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong></p>\n<p>The choice between these approaches fundamentally comes down to your organization&#39;s tolerance for operational complexity versus reliability requirements. Direct delivery optimizes for simplicity but sacrifices reliability. Event streaming maximizes reliability and auditability but requires significant operational investment. Queue-based delivery provides the optimal balance for most organizations by delivering strong reliability guarantees with manageable operational overhead.</p>\n</blockquote>\n<h3 id=\"common-anti-patterns-and-design-pitfalls\">Common Anti-Patterns and Design Pitfalls</h3>\n<p>Understanding how webhook delivery systems fail helps inform better architectural decisions and avoid common implementation mistakes that lead to reliability issues in production.</p>\n<h4 id=\"-pitfall-synchronous-delivery-from-critical-path\">⚠️ <strong>Pitfall: Synchronous Delivery from Critical Path</strong></h4>\n<p>Many systems start by implementing webhook delivery directly in request handlers for user-facing operations. When a user completes a purchase, the payment handler immediately sends webhook notifications before responding to the user. This creates a <strong>critical path dependency</strong> where webhook delivery failures can impact user experience.</p>\n<p><strong>Why this fails</strong>: Slow or failing webhook endpoints cause user requests to time out. Users experience degraded performance due to external service issues completely outside your control. During webhook endpoint outages, user operations may fail entirely.</p>\n<p><strong>How to fix</strong>: Always decouple webhook delivery from user-facing operations using asynchronous queues. User requests should complete successfully regardless of webhook delivery status.</p>\n<h4 id=\"-pitfall-inadequate-failure-classification\">⚠️ <strong>Pitfall: Inadequate Failure Classification</strong></h4>\n<p>Naive retry logic treats all HTTP failures equally, retrying 4xx client errors that will never succeed while giving up too quickly on 5xx server errors that might recover.</p>\n<p><strong>Why this fails</strong>: Retrying 400 Bad Request or 404 Not Found responses wastes resources and creates unnecessary load. Meanwhile, giving up on 503 Service Unavailable responses discards events that might succeed after brief downtime.</p>\n<p><strong>How to fix</strong>: Implement status code classification where 4xx errors (except 429) skip retries, 5xx errors and network failures trigger exponential backoff, and 429 Rate Limited responses respect Retry-After headers.</p>\n<h4 id=\"-pitfall-missing-signature-verification\">⚠️ <strong>Pitfall: Missing Signature Verification</strong></h4>\n<p>Some webhook systems skip cryptographic signature generation or implement it incorrectly, making it impossible for recipients to verify payload authenticity.</p>\n<p><strong>Why this fails</strong>: Recipients cannot distinguish legitimate webhooks from spoofed attacks. Debugging becomes impossible because recipients can&#39;t trust payload integrity. Compliance requirements may mandate signature verification for audit trails.</p>\n<p><strong>How to fix</strong>: Always implement HMAC-SHA256 signature verification with timestamp-based replay protection. Include signatures in standard headers and document verification procedures for recipients.</p>\n<h4 id=\"-pitfall-unbounded-retry-queues\">⚠️ <strong>Pitfall: Unbounded Retry Queues</strong></h4>\n<p>Without proper queue management, failed webhook deliveries can accumulate indefinitely, eventually consuming all available memory and storage.</p>\n<p><strong>Why this fails</strong>: During widespread endpoint outages, retry queues grow exponentially. System performance degrades as workers spend all their time processing retries for dead endpoints. Eventually, the system runs out of resources and crashes.</p>\n<p><strong>How to fix</strong>: Implement dead letter queues with maximum retry limits. Use circuit breakers to disable failing endpoints. Monitor queue depth and alert when growth exceeds normal bounds.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Building a reliable webhook delivery system requires careful technology selection and project structure to handle the complexity of asynchronous processing, cryptographic operations, and external HTTP communication.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Message Queue</td>\n<td>Redis with <code>celery</code> for task queuing</td>\n<td>RabbitMQ with <code>pika</code> for AMQP messaging</td>\n</tr>\n<tr>\n<td>HTTP Client</td>\n<td><code>requests</code> library with connection pooling</td>\n<td><code>httpx</code> with async support and HTTP/2</td>\n</tr>\n<tr>\n<td>Database</td>\n<td>PostgreSQL with <code>psycopg2</code> for reliability</td>\n<td>PostgreSQL with async <code>asyncpg</code> for performance</td>\n</tr>\n<tr>\n<td>Cryptography</td>\n<td><code>hmac</code> and <code>hashlib</code> from standard library</td>\n<td><code>cryptography</code> library for advanced features</td>\n</tr>\n<tr>\n<td>Web Framework</td>\n<td>Flask with <code>Flask-RESTful</code> for simplicity</td>\n<td>FastAPI for async support and OpenAPI docs</td>\n</tr>\n<tr>\n<td>Background Workers</td>\n<td>Celery for task processing</td>\n<td>Custom async workers with <code>asyncio</code></td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Python <code>logging</code> with structured output</td>\n<td>Prometheus metrics with <code>prometheus_client</code></td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-project-structure\">Recommended Project Structure</h4>\n<p>The webhook delivery system requires clear separation between API endpoints, background processing, and data models to maintain testability and enable horizontal scaling.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-delivery-system/\n├── app/\n│   ├── __init__.py\n│   ├── models/                    # Data models and database schemas\n│   │   ├── __init__.py\n│   │   ├── webhook.py             # Webhook registration model\n│   │   ├── event.py               # Event and delivery attempt models\n│   │   └── circuit_breaker.py     # Circuit breaker state model\n│   ├── api/                       # REST API endpoints\n│   │   ├── __init__.py\n│   │   ├── webhooks.py            # Webhook registration API\n│   │   ├── events.py              # Event submission and replay API\n│   │   └── monitoring.py          # Status and health endpoints\n│   ├── delivery/                  # Core delivery engine\n│   │   ├── __init__.py\n│   │   ├── queue_manager.py       # Queue operations and ordering\n│   │   ├── delivery_worker.py     # HTTP delivery and retry logic\n│   │   ├── circuit_breaker.py     # Circuit breaker implementation\n│   │   └── signature.py           # HMAC signature generation\n│   ├── storage/                   # Data persistence layer\n│   │   ├── __init__.py\n│   │   ├── webhook_store.py       # Webhook registration storage\n│   │   ├── event_store.py         # Event and attempt logging\n│   │   └── migrations/            # Database schema migrations\n│   └── config/                    # Configuration management\n│       ├── __init__.py\n│       ├── settings.py            # Environment-based configuration\n│       └── logging.py             # Logging configuration\n├── tests/                         # Test suite organization\n│   ├── unit/                      # Component unit tests\n│   ├── integration/               # Cross-component tests\n│   └── fixtures/                  # Test data and mocks\n├── scripts/                       # Operational scripts\n│   ├── migrate.py                 # Database migration runner\n│   ├── worker.py                  # Background worker startup\n│   └── health_check.py            # System health validation\n├── docker/                        # Container configuration\n│   ├── Dockerfile\n│   ├── docker-compose.yml\n│   └── nginx.conf                 # Reverse proxy configuration\n└── docs/                          # Documentation\n    ├── api.md                     # API documentation\n    ├── deployment.md              # Operations guide\n    └── troubleshooting.md         # Common issues and solutions</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Database Connection Management</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># app/storage/__init__.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> psycopg2</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> psycopg2.pool </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ThreadedConnectionPool</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> psycopg2.extras </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> RealDictCursor</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DatabaseManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages PostgreSQL connection pooling for webhook storage.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, database_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, min_conn: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">, max_conn: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.database_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> database_url</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.pool </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ThreadedConnectionPool(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            min_conn, max_conn, database_url,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            cursor_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">RealDictCursor</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database pool initialized with </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">min_conn</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">-</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">max_conn</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> connections\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_connection</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager for database connections with automatic cleanup.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            conn </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.pool.getconn()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span><span style=\"color:#E1E4E8\"> conn</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> conn:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                conn.rollback()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database operation failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> conn:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.pool.putconn(conn)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> execute_query</span><span style=\"color:#E1E4E8\">(self, query: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, params: </span><span style=\"color:#79B8FF\">tuple</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute query and return results.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.get_connection() </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> conn:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#E1E4E8\"> conn.cursor() </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> cursor:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                cursor.execute(query, params)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> query.strip().upper().startswith(</span><span style=\"color:#9ECBFF\">'SELECT'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> cursor.fetchall()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                conn.commit()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> cursor.rowcount</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Initialize global database manager</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">db_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DatabaseManager(os.getenv(</span><span style=\"color:#9ECBFF\">'DATABASE_URL'</span><span style=\"color:#E1E4E8\">))</span></span></code></pre></div>\n\n<p><strong>HTTP Client with Connection Pooling</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># app/delivery/http_client.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> urllib3.util.retry </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Retry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> requests.adapters </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> HTTPAdapter</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookHTTPClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"HTTP client optimized for webhook delivery with proper connection management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">, max_retries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timeout</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> requests.Session()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Configure connection pooling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        adapter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> HTTPAdapter(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_connections</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_retries</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_retries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.mount(</span><span style=\"color:#9ECBFF\">'http://'</span><span style=\"color:#E1E4E8\">, adapter)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.mount(</span><span style=\"color:#9ECBFF\">'https://'</span><span style=\"color:#E1E4E8\">, adapter)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set default headers</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.headers.update({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'User-Agent'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'WebhookDeliverySystem/1.0'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'Content-Type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'application/json'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deliver_webhook</span><span style=\"color:#E1E4E8\">(self, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       signature: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                       headers: Optional[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Deliver webhook payload to endpoint.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Tuple of (status_code, response_text, response_time_seconds)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        delivery_headers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'X-Webhook-Signature-256'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'sha256=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">signature</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'X-Webhook-Timestamp'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(time.time())),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'X-Webhook-Delivery-ID'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(uuid.uuid4())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> headers:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            delivery_headers.update(headers)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.session.post(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                url, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                data</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">payload,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">delivery_headers,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.timeout,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                allow_redirects</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#6A737D\">  # Prevent redirect attacks</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger.info(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Webhook delivered: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> -> </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">response.status_code</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> in </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">response_time</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> response.status_code, response.text[:</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">], response_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.Timeout:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger.warning(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Webhook timeout: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> after </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">response_time</span><span style=\"color:#F97583\">:.3f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 408</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"Request timeout\"</span><span style=\"color:#E1E4E8\">, response_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.ConnectionError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger.warning(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Webhook connection failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 503</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Connection error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)[:</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, response_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Webhook delivery error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> - </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> 500</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Delivery error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)[:</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">]</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, response_time</span></span></code></pre></div>\n\n<p><strong>Configuration Management</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># app/config/settings.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration settings for webhook delivery system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Database settings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    database_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> os.getenv(</span><span style=\"color:#9ECBFF\">'DATABASE_URL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'postgresql://localhost/webhooks'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Queue settings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    redis_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> os.getenv(</span><span style=\"color:#9ECBFF\">'REDIS_URL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'redis://localhost:6379/0'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> os.getenv(</span><span style=\"color:#9ECBFF\">'QUEUE_NAME'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'webhook_delivery'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Delivery settings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delivery_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'DELIVERY_TIMEOUT'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'30'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_retry_attempts: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'MAX_RETRY_ATTEMPTS'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'5'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    retry_base_delay: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'RETRY_BASE_DELAY'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'60'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Circuit breaker settings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_breaker_failure_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'CB_FAILURE_THRESHOLD'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'5'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_breaker_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'CB_TIMEOUT'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'300'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Rate limiting settings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_requests_per_minute: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'RATE_LIMIT_RPM'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'60'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Security settings</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signature_algorithm: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'sha256'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_signature_header: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> 'X-Webhook-Signature-256'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp_tolerance: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'TIMESTAMP_TOLERANCE'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'300'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate configuration settings.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.max_retry_attempts </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"max_retry_attempts must be at least 1\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.delivery_timeout </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"delivery_timeout must be at least 1 second\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.circuit_breaker_failure_threshold </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"circuit_breaker_failure_threshold must be at least 1\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global configuration instance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> WebhookConfig()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">config.validate()</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton\">Core Logic Skeleton</h4>\n<p><strong>Webhook Registration Handler</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># app/api/webhooks.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> flask </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Flask, request, jsonify</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> app.models.webhook </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookRegistration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> app.delivery.signature </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> generate_webhook_secret</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> register_webhook</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Register a new webhook endpoint with ownership verification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Expected JSON payload:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"url\": \"https://example.com/webhook\",</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"events\": [\"payment.completed\", \"user.created\"],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"description\": \"Payment processing webhooks\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    }</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate request JSON contains required fields (url, events)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate URL format and ensure HTTPS only</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check URL against SSRF blacklist (private IPs, localhost, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate cryptographically secure signing secret</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Store webhook registration in database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Send ownership verification challenge to endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return webhook ID and secret to client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use urllib.parse to validate URL format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use ipaddress module to check for private IP ranges</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> verify_webhook_ownership</span><span style=\"color:#E1E4E8\">(webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Verify webhook endpoint ownership via challenge-response.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Sends a GET request with a challenge parameter and expects</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    the same challenge value in the response body.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve webhook registration from database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate random challenge string (UUID)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Send GET request to webhook URL with ?challenge=&#x3C;value></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify response contains the challenge value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update webhook status to 'verified' in database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Log verification success/failure for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Use uuid.uuid4() for challenge generation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Hint: Set short timeout for verification requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Event Delivery Worker</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># app/delivery/delivery_worker.py</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> app.models.event </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DeliveryAttempt</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> app.delivery.http_client </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookHTTPClient</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> app.delivery.signature </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> generate_hmac_signature</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DeliveryWorker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Processes webhook delivery queue with retry logic and circuit breakers.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, http_client: WebhookHTTPClient):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.http_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> http_client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_delivery</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Attempt delivery of webhook event with full error handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if delivery succeeded, False if it should be retried.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load webhook registration and verify it's not disabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check circuit breaker state - skip if open</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply rate limiting - delay if necessary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate HMAC signature for payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Perform HTTP delivery using http_client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Classify response status code (success/retry/permanent_failure)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Record delivery attempt in database with full details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Update circuit breaker state based on result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Schedule retry if needed with exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 10: Move to dead letter queue if max retries exceeded</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Status codes 2xx = success, 5xx = retry, 4xx = permanent failure (except 429)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use time.time() for attempt timestamps</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_retry_delay</span><span style=\"color:#E1E4E8\">(self, attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, base_delay: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate exponential backoff delay with jitter.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns delay in seconds for the next retry attempt.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate exponential backoff: base_delay * (2 ^ attempt_number)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add random jitter to prevent thundering herd (±25%)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Cap maximum delay at reasonable limit (e.g., 1 hour)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return calculated delay in seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use random.uniform() for jitter calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: min(calculated_delay, max_delay) for capping</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Checkpoint: Webhook Registration</strong>\nAfter implementing the webhook registration system, you should be able to:</p>\n<ol>\n<li><p><strong>Test registration API</strong>: <code>curl -X POST http://localhost:5000/webhooks -H &quot;Content-Type: application/json&quot; -d &#39;{&quot;url&quot;: &quot;https://httpbin.org/post&quot;, &quot;events&quot;: [&quot;test.event&quot;]}&#39;</code></p>\n<ul>\n<li>Expected: JSON response with webhook ID and signing secret</li>\n<li>Verify: Check database for new webhook record with generated secret</li>\n</ul>\n</li>\n<li><p><strong>Test SSRF protection</strong>: Try registering <code>http://localhost:8080/webhook</code> or <code>http://192.168.1.1/webhook</code></p>\n<ul>\n<li>Expected: 400 Bad Request with error message about invalid URL</li>\n<li>Verify: Private IPs and localhost are rejected</li>\n</ul>\n</li>\n<li><p><strong>Test signature generation</strong>: Generate signature for test payload and verify it matches expected HMAC-SHA256 output</p>\n<ul>\n<li>Use online HMAC calculator to verify signature correctness</li>\n<li>Ensure timestamp is included in signed data</li>\n</ul>\n</li>\n<li><p><strong>Test ownership verification</strong>: Register webhook pointing to a test server you control</p>\n<ul>\n<li>Expected: GET request to your endpoint with challenge parameter</li>\n<li>Respond with challenge value to complete verification</li>\n</ul>\n</li>\n</ol>\n<p><strong>Milestone 2 Checkpoint: Delivery Queue</strong>\nAfter implementing the delivery system:</p>\n<ol>\n<li><p><strong>Test basic delivery</strong>: Submit test event and verify HTTP delivery</p>\n<ul>\n<li>Check delivery attempt records in database</li>\n<li>Verify HMAC signature in delivered request headers</li>\n</ul>\n</li>\n<li><p><strong>Test retry logic</strong>: Point webhook at non-existent domain and observe retries</p>\n<ul>\n<li>Expected: Exponential backoff delays between attempts</li>\n<li>Verify: Retry delays increase: 60s, 120s, 240s, etc.</li>\n</ul>\n</li>\n<li><p><strong>Test dead letter queue</strong>: Let webhook exhaust all retry attempts</p>\n<ul>\n<li>Expected: Event moved to dead letter queue after max retries</li>\n<li>Verify: No further delivery attempts scheduled</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"common-implementation-issues\">Common Implementation Issues</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Webhook registration returns 500 error</td>\n<td>Database connection failure</td>\n<td>Check database connectivity and credentials</td>\n<td>Verify DATABASE_URL and test connection</td>\n</tr>\n<tr>\n<td>Signature verification fails at recipient</td>\n<td>Incorrect HMAC calculation</td>\n<td>Compare generated signature with online calculator</td>\n<td>Ensure UTF-8 encoding and correct secret</td>\n</tr>\n<tr>\n<td>Deliveries never retry after failures</td>\n<td>Queue worker not running</td>\n<td>Check worker process logs</td>\n<td>Start background worker process</td>\n</tr>\n<tr>\n<td>High memory usage in workers</td>\n<td>Connection pool leaks</td>\n<td>Monitor connection count metrics</td>\n<td>Implement proper connection cleanup</td>\n</tr>\n<tr>\n<td>Slow delivery processing</td>\n<td>Database transaction locks</td>\n<td>Check for long-running queries</td>\n<td>Add database indexes and optimize queries</td>\n</tr>\n<tr>\n<td>Circuit breaker never opens</td>\n<td>Threshold too high</td>\n<td>Review failure count vs threshold</td>\n<td>Lower failure threshold for testing</td>\n</tr>\n</tbody></table>\n<h2 id=\"goals-and-non-goals\">Goals and Non-Goals</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones - establishes success criteria and scope boundaries that guide implementation decisions throughout the project</p>\n</blockquote>\n<p>The webhook delivery system aims to solve the fundamental challenge of reliable asynchronous communication between distributed services. Before diving into technical solutions, it&#39;s essential to clearly define what constitutes success and explicitly bound the scope of the system. This prevents feature creep while ensuring all stakeholders understand the system&#39;s intended capabilities and limitations.</p>\n<p><strong>Mental Model: The Service Level Agreement (SLA) Contract</strong></p>\n<p>Think of this goals section as writing a detailed service level agreement between your webhook system and its users. Just as a shipping company promises specific delivery times, tracking capabilities, and damage protection while explicitly excluding certain package types or destinations, our webhook system must clearly define its delivery guarantees, security protections, and operational capabilities while explicitly stating what it will not handle. This contract becomes the North Star for all implementation decisions - when faced with competing design choices, we always choose the option that best serves these stated goals.</p>\n<p>The goals fall into three categories: functional requirements that define core system behavior, non-functional requirements that establish quality attributes, and explicit non-goals that prevent scope creep. Each goal must be measurable and testable to ensure successful implementation.</p>\n<h3 id=\"functional-goals\">Functional Goals</h3>\n<p>The functional goals define the core business capabilities that make the webhook delivery system valuable to its users. These represent the fundamental features that must work correctly for the system to fulfill its purpose.</p>\n<p><strong>Reliable Event Delivery with Ordering Guarantees</strong></p>\n<p>The system must guarantee that webhook events are delivered to registered endpoints with strong consistency and ordering semantics. This means implementing at-least-once delivery semantics where every event will eventually be delivered successfully or moved to a dead letter queue for manual intervention. For each webhook endpoint, events must be delivered in the order they were originally generated to maintain causal consistency - if Event A was generated before Event B for the same resource, Event A must be delivered before Event B.</p>\n<table>\n<thead>\n<tr>\n<th>Delivery Guarantee</th>\n<th>Implementation Requirement</th>\n<th>Measurable Criteria</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>At-least-once delivery</td>\n<td>Persistent message queues with acknowledgments</td>\n<td>99.9% of events delivered within SLA timeframes</td>\n</tr>\n<tr>\n<td>Ordering per endpoint</td>\n<td>Sequential processing with per-endpoint queues</td>\n<td>Events arrive in chronological order of generation</td>\n</tr>\n<tr>\n<td>Failure isolation</td>\n<td>Dead letter queue for undeliverable messages</td>\n<td>Failed events don&#39;t block subsequent event delivery</td>\n</tr>\n<tr>\n<td>Delivery confirmation</td>\n<td>Track delivery attempts and final status</td>\n<td>Complete audit trail for every event processed</td>\n</tr>\n</tbody></table>\n<p><strong>Cryptographic Security with HMAC Signature Verification</strong></p>\n<p>Every webhook delivery must include a cryptographically secure HMAC-SHA256 signature that allows recipients to verify both the authenticity and integrity of the payload. The system must generate cryptographically random signing secrets for each webhook registration and include timestamps in the signature calculation to prevent replay attacks. Recipients can use the shared secret to recompute the signature and confirm that the event originated from the webhook system and hasn&#39;t been tampered with in transit.</p>\n<table>\n<thead>\n<tr>\n<th>Security Feature</th>\n<th>Implementation Details</th>\n<th>Verification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HMAC-SHA256 signatures</td>\n<td>Include timestamp and payload in signature</td>\n<td>Recipients recompute and compare signatures</td>\n</tr>\n<tr>\n<td>Replay attack prevention</td>\n<td>Timestamp tolerance window of 5 minutes</td>\n<td>Reject events with timestamps outside tolerance</td>\n</tr>\n<tr>\n<td>Secret rotation support</td>\n<td>Multiple active secrets during rotation period</td>\n<td>New secrets work while old ones remain valid</td>\n</tr>\n<tr>\n<td>HTTPS-only delivery</td>\n<td>Reject webhook URLs with HTTP scheme</td>\n<td>All delivery attempts use TLS encryption</td>\n</tr>\n</tbody></table>\n<p><strong>Comprehensive Retry Logic with Exponential Backoff</strong></p>\n<p>When webhook delivery fails due to network issues or temporary endpoint unavailability, the system must implement intelligent retry logic that balances quick recovery with avoiding overwhelming already-struggling endpoints. This includes exponential backoff with jitter to prevent thundering herd problems, appropriate retry decisions based on HTTP status codes, and circuit breaker protection to disable persistently failing endpoints.</p>\n<table>\n<thead>\n<tr>\n<th>Retry Feature</th>\n<th>Configuration Parameters</th>\n<th>Behavior Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Exponential backoff</td>\n<td>Base delay 1s, max delay 300s, 5 max attempts</td>\n<td>Delays: 1s, 2s, 4s, 8s, 16s with ±25% jitter</td>\n</tr>\n<tr>\n<td>Status code logic</td>\n<td>Retry 5xx and 429, don&#39;t retry most 4xx</td>\n<td>400/401/403/404 are permanent failures</td>\n</tr>\n<tr>\n<td>Circuit breaker</td>\n<td>5 consecutive failures trigger open circuit</td>\n<td>Endpoint disabled until manual reset or timeout</td>\n</tr>\n<tr>\n<td>Dead letter routing</td>\n<td>Events exhausting retries move to DLQ</td>\n<td>Manual review and replay capability required</td>\n</tr>\n</tbody></table>\n<p><strong>Event Ownership Verification and SSRF Protection</strong></p>\n<p>Before accepting webhook registrations, the system must verify that the registering party actually controls the destination endpoint to prevent abuse and server-side request forgery (SSRF) attacks. This involves sending a challenge request to the proposed endpoint and requiring a specific response that proves ownership. Additionally, all webhook URLs must be validated to ensure they don&#39;t target private network addresses or internal services.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Step</th>\n<th>Security Protection</th>\n<th>Implementation Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Challenge-response verification</td>\n<td>Prevents unauthorized webhook registration</td>\n<td>Generate random token, require echo back</td>\n</tr>\n<tr>\n<td>URL validation</td>\n<td>Blocks SSRF attacks on internal services</td>\n<td>Reject private IP ranges and localhost</td>\n</tr>\n<tr>\n<td>HTTPS enforcement</td>\n<td>Protects payload confidentiality in transit</td>\n<td>Only accept webhook URLs with HTTPS scheme</td>\n</tr>\n<tr>\n<td>Endpoint reachability</td>\n<td>Confirms URL is accessible for delivery</td>\n<td>Test delivery during registration process</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Design Principle: Security by Default</strong>\nEvery security feature must be enabled by default with no option to disable it. Organizations often struggle with webhook security because systems make it optional or easy to bypass. Our system forces secure practices by rejecting insecure configurations rather than warning about them.</p>\n</blockquote>\n<h3 id=\"non-functional-goals\">Non-Functional Goals</h3>\n<p>The non-functional goals establish quality attributes that define how well the system performs its functional capabilities. These requirements often drive architectural decisions more than functional requirements do.</p>\n<p><strong>Performance and Throughput Requirements</strong></p>\n<p>The webhook delivery system must handle substantial event volumes while maintaining low latency for delivery attempts. This requires careful attention to queue management, connection pooling, and concurrent processing capabilities. The system should gracefully handle traffic spikes without dropping events or significantly increasing delivery latency.</p>\n<table>\n<thead>\n<tr>\n<th>Performance Metric</th>\n<th>Target Value</th>\n<th>Measurement Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event ingestion rate</td>\n<td>10,000 events/second sustained</td>\n<td>Queue depth monitoring during peak load</td>\n</tr>\n<tr>\n<td>Delivery latency P99</td>\n<td>Under 5 seconds for healthy endpoints</td>\n<td>Time from event creation to first delivery attempt</td>\n</tr>\n<tr>\n<td>Concurrent deliveries</td>\n<td>1,000 simultaneous HTTP requests</td>\n<td>HTTP client connection pool utilization</td>\n</tr>\n<tr>\n<td>Queue processing lag</td>\n<td>Under 30 seconds during normal operation</td>\n<td>Difference between newest queued and processed event</td>\n</tr>\n</tbody></table>\n<p><strong>High Availability and Fault Tolerance</strong></p>\n<p>The system must continue operating correctly even when individual components fail or become temporarily unavailable. This includes surviving database outages, message queue failures, and individual worker process crashes without losing events or corrupting delivery state. Recovery from failures should be automatic whenever possible.</p>\n<table>\n<thead>\n<tr>\n<th>Availability Feature</th>\n<th>Failure Scenario</th>\n<th>Recovery Mechanism</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Message queue persistence</td>\n<td>Worker process crash during delivery</td>\n<td>Events remain queued until acknowledged</td>\n</tr>\n<tr>\n<td>Database connection handling</td>\n<td>Temporary database unavailability</td>\n<td>Connection pool retry with exponential backoff</td>\n</tr>\n<tr>\n<td>Worker process resilience</td>\n<td>Individual worker thread crashes</td>\n<td>Process supervisor restarts failed workers</td>\n</tr>\n<tr>\n<td>Event durability</td>\n<td>System crash before event queuing</td>\n<td>Write-ahead log ensures events aren&#39;t lost</td>\n</tr>\n</tbody></table>\n<p><strong>Operational Observability and Debugging</strong></p>\n<p>Operating a webhook delivery system requires comprehensive visibility into event processing, delivery success rates, and failure modes. The system must provide detailed logging, metrics, and debugging capabilities that enable rapid diagnosis of delivery issues and performance problems.</p>\n<table>\n<thead>\n<tr>\n<th>Observability Component</th>\n<th>Information Provided</th>\n<th>Usage Scenario</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Delivery attempt logs</td>\n<td>HTTP status, response time, error details</td>\n<td>Debug specific endpoint delivery failures</td>\n</tr>\n<tr>\n<td>Endpoint health metrics</td>\n<td>Success rate, average latency, circuit breaker status</td>\n<td>Monitor overall webhook health across endpoints</td>\n</tr>\n<tr>\n<td>Queue depth monitoring</td>\n<td>Pending events per endpoint and globally</td>\n<td>Detect processing bottlenecks and traffic spikes</td>\n</tr>\n<tr>\n<td>Error rate dashboards</td>\n<td>Failed deliveries by error type and endpoint</td>\n<td>Identify systematic problems vs isolated failures</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Operational Excellence Principle</strong>\nThe system must be designed to make the most common operational tasks simple and the most dangerous operations difficult. Viewing delivery logs should be a single click, while replaying events should require deliberate confirmation steps to prevent accidental duplicate deliveries.</p>\n</blockquote>\n<p><strong>Horizontal Scalability Architecture</strong></p>\n<p>As webhook usage grows, the system must support horizontal scaling by adding more worker processes or machines without requiring fundamental architectural changes. This means avoiding single points of contention, designing for stateless processing where possible, and ensuring that work can be distributed across multiple processing units.</p>\n<table>\n<thead>\n<tr>\n<th>Scalability Dimension</th>\n<th>Scaling Approach</th>\n<th>Implementation Consideration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event processing workers</td>\n<td>Add worker processes or containers</td>\n<td>Stateless workers using shared message queue</td>\n</tr>\n<tr>\n<td>Database connections</td>\n<td>Connection pooling with configurable limits</td>\n<td>Read replicas for delivery history queries</td>\n</tr>\n<tr>\n<td>HTTP delivery capacity</td>\n<td>Concurrent connection limits per worker</td>\n<td>Connection pooling prevents resource exhaustion</td>\n</tr>\n<tr>\n<td>Queue throughput</td>\n<td>Partitioned queues by endpoint or hash</td>\n<td>Prevents single endpoint from blocking others</td>\n</tr>\n</tbody></table>\n<h3 id=\"explicit-non-goals\">Explicit Non-Goals</h3>\n<p>The explicit non-goals are equally important as the goals themselves because they define boundaries that prevent feature creep and maintain system focus. These exclusions help teams resist the temptation to solve adjacent problems that would complicate the core webhook delivery mission.</p>\n<p><strong>Real-Time Streaming and Sub-Second Latency</strong></p>\n<p>This webhook delivery system is explicitly not designed for real-time streaming use cases that require sub-second latency or complex event processing. While the system aims for reasonable delivery latency (under 5 seconds P99), it prioritizes reliability and ordering over ultra-low latency. Teams needing millisecond-latency event delivery should consider event streaming platforms rather than webhook systems.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Feature</th>\n<th>Why Not Included</th>\n<th>Recommended Alternative</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Sub-second delivery guarantees</td>\n<td>Conflicts with reliability and retry logic</td>\n<td>Apache Kafka or similar event streaming</td>\n</tr>\n<tr>\n<td>Complex event processing</td>\n<td>Outside webhook delivery scope</td>\n<td>Dedicated stream processing frameworks</td>\n</tr>\n<tr>\n<td>Real-time analytics</td>\n<td>Not core to webhook delivery mission</td>\n<td>Time-series databases and analytics platforms</td>\n</tr>\n<tr>\n<td>Event transformation</td>\n<td>Adds complexity and failure modes</td>\n<td>Implement transformations in receiving applications</td>\n</tr>\n</tbody></table>\n<p><strong>Advanced Payload Processing and Transformation</strong></p>\n<p>The system will not provide built-in payload transformation, filtering, or enrichment capabilities. Webhook events are delivered exactly as they were submitted, without modification. This decision maintains system simplicity and avoids the complexity of a general-purpose data processing pipeline. Organizations needing payload transformation should implement it in their event publishing or receiving applications.</p>\n<p><strong>Multi-Tenant Isolation and Access Control</strong></p>\n<p>While the system supports multiple webhook endpoints, it does not provide sophisticated multi-tenant isolation, user authentication, or fine-grained access control. The webhook registry is shared across all users, and there&#39;s no concept of user accounts or permissions. Organizations requiring multi-tenant operation should implement authentication and authorization in the application layer that uses the webhook system.</p>\n<table>\n<thead>\n<tr>\n<th>Excluded Capability</th>\n<th>Complexity Reason</th>\n<th>Workaround Approach</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>User authentication</td>\n<td>Requires identity provider integration</td>\n<td>Implement in application layer</td>\n</tr>\n<tr>\n<td>Tenant data isolation</td>\n<td>Complex database design and query patterns</td>\n<td>Use separate webhook system instances</td>\n</tr>\n<tr>\n<td>Permission management</td>\n<td>Extensive RBAC implementation needed</td>\n<td>Application-level access control</td>\n</tr>\n<tr>\n<td>Audit logging by user</td>\n<td>Requires user context throughout system</td>\n<td>Log user actions in calling application</td>\n</tr>\n</tbody></table>\n<p><strong>Geographic Distribution and Multi-Region Deployment</strong></p>\n<p>The initial system design assumes single-region deployment and does not address challenges of geographic distribution, cross-region replication, or compliance with data residency requirements. While the system can be deployed in multiple regions independently, it won&#39;t provide built-in cross-region event replication or failover capabilities.</p>\n<p><strong>Integration with External Monitoring and Alerting Systems</strong></p>\n<p>While the system provides comprehensive logging and metrics, it will not include built-in integration with specific monitoring platforms, alerting systems, or incident management tools. The system exposes metrics and logs in standard formats that can be consumed by external monitoring solutions, but teams must configure their own alerting and incident response workflows.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Type</th>\n<th>Why Excluded</th>\n<th>Standard Interface Provided</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Specific monitoring tools</td>\n<td>Too many platform variations</td>\n<td>Prometheus metrics endpoint</td>\n</tr>\n<tr>\n<td>Alerting systems</td>\n<td>Organization-specific requirements</td>\n<td>Structured JSON logs</td>\n</tr>\n<tr>\n<td>Incident management</td>\n<td>Workflow varies by organization</td>\n<td>HTTP webhook for system events</td>\n</tr>\n<tr>\n<td>Performance analytics</td>\n<td>Specialized tools handle this better</td>\n<td>Time-series metrics export</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Scope Discipline Principle</strong>\nEvery excluded feature represents a conscious decision to maintain system focus. Before adding any new capability, teams must explicitly consider whether it serves the core webhook delivery mission or could be better handled by specialized tools.</p>\n</blockquote>\n<p><strong>Event Schema Validation and Registry</strong></p>\n<p>The webhook delivery system treats all event payloads as opaque JSON or text data and does not perform schema validation, versioning, or registry management. This decision avoids the complexity of maintaining schema definitions and compatibility rules across different event types and versions. Applications publishing and consuming webhook events are responsible for their own payload format management.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The goals and non-goals established in this section directly influence every subsequent design decision throughout the webhook delivery system. Understanding these requirements helps guide technology choices, architectural patterns, and implementation priorities.</p>\n<p><strong>A. Goal Verification Strategy</strong></p>\n<table>\n<thead>\n<tr>\n<th>Requirement Category</th>\n<th>Verification Method</th>\n<th>Implementation Checkpoint</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Functional Goals</td>\n<td>Automated integration tests with mock endpoints</td>\n<td>Each milestone includes test scenarios validating specific goals</td>\n</tr>\n<tr>\n<td>Performance Goals</td>\n<td>Load testing with configurable traffic patterns</td>\n<td>Benchmark tests measuring throughput and latency under load</td>\n</tr>\n<tr>\n<td>Security Goals</td>\n<td>Penetration testing and security review</td>\n<td>Security-focused tests for SSRF, replay attacks, and signature bypass</td>\n</tr>\n<tr>\n<td>Operational Goals</td>\n<td>Monitoring dashboard and alerting validation</td>\n<td>Verify observability features help diagnose common failure scenarios</td>\n</tr>\n</tbody></table>\n<p><strong>B. Technology Selection Criteria</strong></p>\n<p>When choosing specific technologies for implementing the webhook delivery system, evaluate each option against these established goals:</p>\n<ul>\n<li><strong>Reliability First</strong>: Choose proven technologies with strong consistency guarantees over cutting-edge options with uncertain behavior</li>\n<li><strong>Security by Default</strong>: Prefer technologies that make secure configuration the default rather than requiring extensive security hardening</li>\n<li><strong>Operational Simplicity</strong>: Select technologies that provide good observability and debugging capabilities out of the box</li>\n<li><strong>Horizontal Scaling</strong>: Ensure chosen technologies support the scalability patterns defined in non-functional goals</li>\n</ul>\n<p><strong>C. Milestone Success Criteria</strong></p>\n<p>Each project milestone should be evaluated against these goals to ensure the implementation stays on track:</p>\n<table>\n<thead>\n<tr>\n<th>Milestone</th>\n<th>Primary Goals Validated</th>\n<th>Success Indicators</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Milestone 1: Registration &amp; Security</td>\n<td>HMAC signatures, SSRF protection, HTTPS enforcement</td>\n<td>All webhook registrations require valid HTTPS URLs and generate crypto-secure secrets</td>\n</tr>\n<tr>\n<td>Milestone 2: Delivery &amp; Retry</td>\n<td>At-least-once delivery, exponential backoff, ordering</td>\n<td>Events are delivered in order with appropriate retry logic for different failure types</td>\n</tr>\n<tr>\n<td>Milestone 3: Circuit Breaker &amp; Rate Limiting</td>\n<td>Fault tolerance, endpoint protection, performance</td>\n<td>Failing endpoints are automatically disabled and healthy endpoints maintain SLA performance</td>\n</tr>\n<tr>\n<td>Milestone 4: Event Log &amp; Replay</td>\n<td>Observability, debugging, operational excellence</td>\n<td>Complete audit trail enables rapid diagnosis and safe event replay</td>\n</tr>\n</tbody></table>\n<p><strong>D. Common Goal Conflicts and Resolutions</strong></p>\n<p>During implementation, certain goals may appear to conflict with each other. Here are common tensions and how to resolve them:</p>\n<p>⚠️ <strong>Goal Conflict: Security vs Performance</strong>\nThe requirement for HMAC signature generation and verification adds computational overhead that could impact delivery throughput. Resolution: Implement signature operations efficiently using optimized crypto libraries and consider signature caching for duplicate payloads. The security benefit outweighs the performance cost, and proper implementation minimizes the impact.</p>\n<p>⚠️ <strong>Goal Conflict: Reliability vs Latency</strong>\nEnsuring at-least-once delivery requires persistent queuing and acknowledgment mechanisms that increase delivery latency. Resolution: This trade-off is intentional per our non-goals - we explicitly chose reliability over ultra-low latency. Teams needing sub-second delivery should use event streaming platforms instead.</p>\n<p>⚠️ <strong>Goal Conflict: Observability vs Privacy</strong>\nComprehensive logging for debugging might include sensitive payload data that should not be stored long-term. Resolution: Implement configurable log retention with automatic payload redaction. Store delivery metadata indefinitely but configure payload logging with short retention periods.</p>\n<p><strong>E. Metrics and SLA Monitoring</strong></p>\n<p>Implement these specific metrics to validate that the system meets its goals in production:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code># Functional Goal Metrics\nwebhook_delivery_success_rate_percent{endpoint_id}\nwebhook_delivery_latency_seconds{percentile}\nwebhook_events_out_of_order_total{endpoint_id}\nwebhook_signature_verification_failures_total\n\n# Non-Functional Goal Metrics  \nwebhook_events_ingested_per_second\nwebhook_queue_depth_total{endpoint_id}\nwebhook_worker_concurrent_deliveries\nwebhook_circuit_breaker_open_total{endpoint_id}\n\n# Operational Goal Metrics\nwebhook_delivery_attempts_total{status_code, endpoint_id}\nwebhook_dead_letter_queue_depth\nwebhook_endpoint_health_score{endpoint_id}\nwebhook_retry_attempts_total{attempt_number}</code></pre></div>\n\n<p>These metrics provide quantitative validation that the implemented system meets the goals established in this section. Regular review of these metrics helps identify when system behavior deviates from intended goals and guides optimization efforts.</p>\n<h2 id=\"high-level-architecture\">High-Level Architecture</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones - architectural decisions here impact webhook registration (Milestone 1), delivery processing (Milestone 2), circuit breaker implementation (Milestone 3), and event logging systems (Milestone 4)</p>\n</blockquote>\n<p>The webhook delivery system follows a multi-component architecture designed around the principle of <strong>separation of concerns</strong> and <strong>fault isolation</strong>. Think of this system like a modern mail processing facility: there&#39;s a registration desk that validates addresses and issues mailbox keys (webhook registry), a sorting and routing department that queues mail and handles delivery attempts (delivery engine), a quality control department that monitors delivery success and temporarily blocks problematic addresses (circuit breaker), and a record-keeping department that logs every piece of mail and delivery attempt for auditing purposes (event logging system).</p>\n<h3 id=\"component-responsibilities\">Component Responsibilities</h3>\n<p>The webhook delivery system consists of four primary components, each with clearly defined responsibilities and interfaces. This architectural separation ensures that failures in one component don&#39;t cascade to others, and each component can be developed, tested, and scaled independently.</p>\n<blockquote>\n<p><strong>Decision: Component-Based Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook delivery involves multiple distinct concerns: registration management, HTTP delivery processing, failure protection, and audit logging. These concerns have different scaling characteristics, failure modes, and operational requirements.</li>\n<li><strong>Options Considered</strong>: Monolithic service, microservices with separate databases, component-based monolith with shared database</li>\n<li><strong>Decision</strong>: Component-based monolith with shared database and clear internal boundaries</li>\n<li><strong>Rationale</strong>: Provides strong separation of concerns without operational complexity of distributed systems. Each component can be tested in isolation while maintaining ACID properties across the entire delivery workflow.</li>\n<li><strong>Consequences</strong>: Enables independent development and testing while avoiding distributed system complexities like eventual consistency and cross-service transaction coordination.</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Primary Responsibility</th>\n<th>Key Data Owned</th>\n<th>Failure Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Webhook Registry</td>\n<td>Endpoint registration and signature management</td>\n<td><code>WebhookRegistration</code> records, signing secrets</td>\n<td>New registrations fail, existing deliveries continue</td>\n</tr>\n<tr>\n<td>Delivery Engine</td>\n<td>Queue processing and HTTP delivery attempts</td>\n<td><code>DeliveryAttempt</code> records, retry scheduling</td>\n<td>New deliveries queue up, no data loss</td>\n</tr>\n<tr>\n<td>Circuit Breaker</td>\n<td>Endpoint health monitoring and failure protection</td>\n<td>Circuit state, failure counters, health metrics</td>\n<td>Failing endpoints may receive extra attempts</td>\n</tr>\n<tr>\n<td>Event Logger</td>\n<td>Delivery audit trail and replay functionality</td>\n<td>Complete delivery history, debugging data</td>\n<td>Debugging capability lost, deliveries continue</td>\n</tr>\n</tbody></table>\n<p>The <strong>Webhook Registry</strong> component acts as the system&#39;s front desk, handling all interactions related to webhook endpoint management. When a client wants to register a new webhook endpoint, this component validates the URL for security concerns (preventing SSRF attacks by blocking private IP ranges), generates cryptographically secure signing secrets using <code>generate_webhook_secret()</code>, and performs ownership verification through a challenge-response mechanism via <code>verify_webhook_ownership()</code>. The registry maintains the authoritative record of all registered webhooks, including their subscription preferences, active signing secrets, and verification status. This component also handles the complex process of secret rotation, allowing multiple secrets to be active simultaneously during transition periods to prevent disruption of in-flight deliveries.</p>\n<p>The <strong>Delivery Engine</strong> serves as the system&#39;s workhorse, responsible for the reliable processing of webhook delivery requests. This component consumes events from the delivery queue, performs the actual HTTP POST requests to registered endpoints using <code>deliver_webhook()</code>, and manages the sophisticated retry logic through <code>calculate_retry_delay()</code> with exponential backoff and jitter. The delivery engine maintains strict ordering guarantees per endpoint while allowing parallel processing across different endpoints. When delivery attempts fail, this component makes intelligent decisions about whether to retry based on HTTP status codes (retrying 5xx errors and 429 rate limiting, but not 4xx client errors), and eventually routes persistently failing messages to the dead letter queue for manual intervention.</p>\n<blockquote>\n<p>The delivery engine&#39;s ordering guarantee is critical for webhooks representing state changes. Consider an e-commerce system sending &quot;order_created&quot; followed by &quot;order_shipped&quot; events - these must arrive in the correct sequence to prevent the receiving system from processing a shipment notification before knowing the order exists.</p>\n</blockquote>\n<p>The <strong>Circuit Breaker</strong> component implements the circuit breaker pattern to protect both the webhook delivery system and the receiving endpoints from cascade failures. This component continuously monitors the success rate of deliveries to each registered endpoint, maintaining counters for recent successes and failures. When an endpoint&#39;s failure rate exceeds the configured threshold (<code>CIRCUIT_BREAKER_FAILURE_THRESHOLD</code>), the circuit breaker transitions from the closed state to the open state, temporarily halting all delivery attempts to that endpoint. The component implements a sophisticated state machine with three states: closed (normal operation), open (deliveries blocked), and half-open (limited test deliveries). During the half-open state, the circuit breaker allows a small number of test requests to determine if the endpoint has recovered, either transitioning back to closed on success or returning to open on continued failures.</p>\n<p>The <strong>Event Logger</strong> component provides comprehensive observability and debugging capabilities for the entire webhook delivery system. This component maintains a complete audit trail of every delivery attempt, including request payloads, response codes, timing information, and error messages. The event logger implements efficient time-series storage optimized for the high-volume, append-only nature of delivery logs. Beyond passive logging, this component supports active replay functionality, allowing operators to re-queue specific events for delivery while maintaining proper deduplication through unique delivery identifiers. The logger also implements intelligent retention policies, archiving older delivery records to cold storage while maintaining fast access to recent delivery history for debugging and operational monitoring.</p>\n<table>\n<thead>\n<tr>\n<th>Component Interface</th>\n<th>Methods</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>WebhookRegistry</code></td>\n<td><code>register_webhook() -&gt; dict</code></td>\n<td>Validates URL, generates secret, initiates ownership verification</td>\n</tr>\n<tr>\n<td><code>WebhookRegistry</code></td>\n<td><code>verify_webhook_ownership(webhook_id) -&gt; bool</code></td>\n<td>Sends challenge request and validates response</td>\n</tr>\n<tr>\n<td><code>WebhookRegistry</code></td>\n<td><code>generate_webhook_secret() -&gt; str</code></td>\n<td>Creates cryptographically secure signing key</td>\n</tr>\n<tr>\n<td><code>WebhookRegistry</code></td>\n<td><code>generate_hmac_signature(payload, secret) -&gt; str</code></td>\n<td>Computes HMAC-SHA256 for payload authentication</td>\n</tr>\n<tr>\n<td><code>DeliveryEngine</code></td>\n<td><code>process_delivery(event_id, webhook_id, payload) -&gt; bool</code></td>\n<td>Orchestrates complete delivery attempt with error handling</td>\n</tr>\n<tr>\n<td><code>DeliveryEngine</code></td>\n<td><code>deliver_webhook(url, payload, signature) -&gt; tuple</code></td>\n<td>Executes HTTP POST with proper headers and timeout</td>\n</tr>\n<tr>\n<td><code>DeliveryEngine</code></td>\n<td><code>calculate_retry_delay(attempt_number, base_delay) -&gt; int</code></td>\n<td>Computes exponential backoff with jitter</td>\n</tr>\n<tr>\n<td><code>CircuitBreaker</code></td>\n<td><code>check_endpoint_health(webhook_id) -&gt; bool</code></td>\n<td>Determines if endpoint is available for delivery</td>\n</tr>\n<tr>\n<td><code>CircuitBreaker</code></td>\n<td><code>record_delivery_result(webhook_id, success) -&gt; None</code></td>\n<td>Updates failure counters and state transitions</td>\n</tr>\n<tr>\n<td><code>EventLogger</code></td>\n<td><code>log_delivery_attempt(attempt) -&gt; None</code></td>\n<td>Persists delivery attempt with full context</td>\n</tr>\n<tr>\n<td><code>EventLogger</code></td>\n<td><code>replay_event(event_id) -&gt; bool</code></td>\n<td>Re-queues event with deduplication handling</td>\n</tr>\n</tbody></table>\n<h3 id=\"data-flow-overview\">Data Flow Overview</h3>\n<p>The webhook delivery system processes events through a carefully orchestrated pipeline that ensures reliability, ordering, and observability at every stage. Understanding this data flow is crucial because it reveals how the system maintains delivery guarantees even in the face of component failures, network issues, and endpoint unavailability.</p>\n<p>The <strong>event ingestion flow</strong> begins when an external system publishes an event that needs to be delivered via webhooks. The event first arrives at the delivery engine, which immediately performs webhook resolution by querying the registry component to identify all endpoints subscribed to that specific event type. For each matching webhook registration, the delivery engine retrieves the current signing secret and uses <code>generate_hmac_signature()</code> to create an authentication signature for the payload. The signed delivery request is then placed onto the persistent delivery queue with a unique delivery identifier, ensuring that even if the system crashes at this point, no delivery requests are lost.</p>\n<blockquote>\n<p><strong>Critical Design Insight</strong>: The system commits the delivery request to the persistent queue BEFORE attempting any HTTP delivery. This ensures at-least-once delivery semantics - events may be delivered multiple times if failures occur, but they will never be lost entirely.</p>\n</blockquote>\n<p>The <strong>queue processing flow</strong> operates as an independent process that continuously consumes delivery requests from the persistent queue. Before attempting delivery, the queue processor checks with the circuit breaker component to verify that the target endpoint is currently accepting traffic. If the circuit breaker indicates the endpoint is healthy (circuit closed), the delivery engine retrieves the full webhook registration details and constructs an HTTP POST request containing the signed payload. The <code>deliver_webhook()</code> method handles the actual HTTP delivery with appropriate timeout settings (<code>DELIVERY_TIMEOUT</code>), connection pooling, and error handling. The response from the target endpoint, including status code, response time, and any error messages, is immediately logged by the event logger component for debugging and compliance purposes.</p>\n<p>The <strong>retry scheduling flow</strong> activates when delivery attempts fail with retryable conditions. The delivery engine analyzes the HTTP response code to determine whether the failure warrants a retry attempt - 5xx server errors and 429 rate limiting responses trigger retry logic, while 4xx client errors (except 429) are considered permanent failures that should not be retried. For retryable failures, the system calculates the next delivery attempt time using <code>calculate_retry_delay()</code> with exponential backoff and jitter. The delivery request is updated with the new attempt timestamp and returned to the delivery queue for future processing. This continues until either the delivery succeeds, the maximum retry limit (<code>MAX_RETRY_ATTEMPTS</code>) is reached, or the circuit breaker opens due to repeated failures.</p>\n<table>\n<thead>\n<tr>\n<th>Flow Stage</th>\n<th>Input</th>\n<th>Processing</th>\n<th>Output</th>\n<th>Persistence</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Ingestion</td>\n<td>External event + metadata</td>\n<td>Webhook lookup, signature generation</td>\n<td>Signed delivery requests</td>\n<td>Queue entries created</td>\n</tr>\n<tr>\n<td>Queue Processing</td>\n<td>Delivery request from queue</td>\n<td>Circuit breaker check, HTTP delivery</td>\n<td>Delivery result + timing</td>\n<td>Attempt logged</td>\n</tr>\n<tr>\n<td>Retry Scheduling</td>\n<td>Failed delivery result</td>\n<td>Status code analysis, backoff calculation</td>\n<td>Rescheduled delivery request</td>\n<td>Queue entry updated</td>\n</tr>\n<tr>\n<td>Circuit Breaker Update</td>\n<td>Delivery success/failure</td>\n<td>Failure counter update, state evaluation</td>\n<td>Circuit state change</td>\n<td>Circuit state persisted</td>\n</tr>\n<tr>\n<td>Dead Letter Routing</td>\n<td>Exhausted retry attempts</td>\n<td>Final failure classification</td>\n<td>Dead letter entry</td>\n<td>Manual review queue</td>\n</tr>\n</tbody></table>\n<p>The <strong>failure handling flow</strong> ensures that delivery failures are properly classified and routed for appropriate handling. When a delivery attempt fails, the circuit breaker component records the failure against the target endpoint and evaluates whether the failure rate has exceeded the configured threshold. If so, the circuit breaker transitions to the open state, temporarily halting all deliveries to that endpoint and triggering alerting to notify the webhook owner of the service degradation. Meanwhile, the specific failed delivery request continues through the retry logic until it either succeeds, exhausts all retry attempts, or is blocked by the circuit breaker. Delivery requests that exhaust all retry attempts are routed to the dead letter queue, where they remain available for manual inspection and potential replay once the underlying issues are resolved.</p>\n<p>The <strong>monitoring and alerting flow</strong> operates continuously in the background, providing observability into system health and delivery performance. The event logger component aggregates delivery metrics, tracking success rates, response times, and error patterns across all registered endpoints. When circuit breakers open or delivery queues begin backing up, the system generates alerts to notify operators of potential issues. The comprehensive logging also enables debugging of delivery failures, providing operators with complete visibility into request payloads, response headers, and timing information for every delivery attempt.</p>\n<blockquote>\n<p><strong>Ordering Guarantee Implementation</strong>: The system maintains per-endpoint ordering by using a separate queue partition for each registered webhook endpoint. This allows parallel processing across different endpoints while ensuring that events for a specific endpoint are processed in the order they were received.</p>\n</blockquote>\n<h3 id=\"deployment-architecture\">Deployment Architecture</h3>\n<p>The webhook delivery system is designed as a scalable, cloud-native application that can be deployed across various environments while maintaining consistent behavior and reliability guarantees. The deployment architecture emphasizes operational simplicity while providing the flexibility to scale individual components based on traffic patterns and performance requirements.</p>\n<blockquote>\n<p><strong>Decision: Single-Process Multi-Component Deployment</strong></p>\n<ul>\n<li><strong>Context</strong>: The system needs to balance operational complexity with scalability requirements. Options include microservices (high operational overhead), serverless functions (limited control over retry timing), or component-based monolith.</li>\n<li><strong>Options Considered</strong>: Kubernetes microservices, AWS Lambda + SQS, single process with worker threads</li>\n<li><strong>Decision</strong>: Single process with worker threads and horizontal scaling</li>\n<li><strong>Rationale</strong>: Minimizes operational complexity while providing good performance and scalability. Components share database connections and memory efficiently. Circuit breaker state remains consistent within each process instance.</li>\n<li><strong>Consequences</strong>: Simplified deployment and debugging at the cost of fine-grained component scaling. All components scale together rather than independently.</li>\n</ul>\n</blockquote>\n<p>The <strong>application tier</strong> consists of one or more instances of the webhook delivery service, each running as a single process containing all four system components. Each service instance operates multiple worker threads: registration handlers for processing webhook registration requests, delivery workers for consuming from the delivery queue, and monitoring threads for circuit breaker evaluation and health checking. The application processes are stateless, storing all persistent data in the shared database and queue infrastructure. This design enables horizontal scaling by simply adding more service instances when delivery volume increases, with load balancing handled automatically through the shared queue mechanism.</p>\n<table>\n<thead>\n<tr>\n<th>Service Component</th>\n<th>Resource Requirements</th>\n<th>Scaling Characteristics</th>\n<th>Failure Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Registration Handler</td>\n<td>Low CPU, moderate memory</td>\n<td>Scales with registration requests</td>\n<td>New registrations rejected, existing unaffected</td>\n</tr>\n<tr>\n<td>Delivery Workers</td>\n<td>Moderate CPU, low memory</td>\n<td>Scales with delivery volume</td>\n<td>Delivery queue backs up, no data loss</td>\n</tr>\n<tr>\n<td>Circuit Breaker Monitor</td>\n<td>Low CPU, low memory</td>\n<td>Constant regardless of volume</td>\n<td>Failure protection disabled temporarily</td>\n</tr>\n<tr>\n<td>Event Logger</td>\n<td>Low CPU, high I/O</td>\n<td>Scales with delivery attempts</td>\n<td>Debugging capability reduced</td>\n</tr>\n</tbody></table>\n<p>The <strong>data tier</strong> provides persistent storage for all system state through a combination of a relational database and message queue infrastructure. The primary database stores webhook registrations, delivery attempt history, and circuit breaker state using a schema optimized for the access patterns of each component. The <code>WebhookRegistration</code> table includes indexes on URL and event type for efficient webhook lookups during event ingestion. The <code>DeliveryAttempt</code> table is partitioned by timestamp to support efficient time-range queries for debugging while maintaining write performance for high-volume delivery logging. The message queue infrastructure handles the delivery queue with persistence guarantees, ensuring that queued delivery requests survive system restarts and process failures.</p>\n<p>The <strong>infrastructure tier</strong> includes supporting services required for production operation: monitoring and alerting systems that track delivery success rates and queue depths, log aggregation systems that collect application logs for debugging and compliance, and secrets management systems that handle the rotation of webhook signing keys. The deployment also includes HTTP load balancers for distributing registration requests across service instances, and database connection pooling to efficiently manage database connections across multiple worker threads and service instances.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Production Deployment Layout:\n\n┌─────────────────────────────┐\n│     Load Balancer           │\n│  (Registration API)         │\n└──────────┬──────────────────┘\n           │\n    ┌──────▼──────┐    ┌─────────────┐    ┌─────────────┐\n    │   Instance  │    │  Instance   │    │  Instance   │\n    │     #1      │    │     #2      │    │     #3      │\n    │ ┌─────────┐ │    │ ┌─────────┐ │    │ ┌─────────┐ │\n    │ │Registry │ │    │ │Registry │ │    │ │Registry │ │\n    │ │Delivery │ │    │ │Delivery │ │    │ │Delivery │ │\n    │ │Circuit  │ │    │ │Circuit  │ │    │ │Circuit  │ │\n    │ │Logger   │ │    │ │Logger   │ │    │ │Logger   │ │\n    │ └─────────┘ │    │ └─────────┘ │    │ └─────────┘ │\n    └──────┬──────┘    └──────┬──────┘    └──────┬──────┘\n           │                  │                  │\n           └──────────────────┼──────────────────┘\n                              │\n    ┌─────────────────────────▼─────────────────────────┐\n    │              Shared Data Layer                    │\n    │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐  │\n    │ │  Database   │ │ Message     │ │   Redis     │  │\n    │ │(PostgreSQL) │ │ Queue       │ │ (Circuit    │  │\n    │ │             │ │ (RabbitMQ)  │ │  State)     │  │\n    │ └─────────────┘ └─────────────┘ └─────────────┘  │\n    └───────────────────────────────────────────────────┘</code></pre></div>\n\n<p>The <strong>configuration management</strong> approach uses environment-based configuration with sensible defaults for all timing and threshold parameters. The <code>WebhookConfig</code> dataclass encapsulates all configurable parameters including database connection strings, retry parameters (<code>MAX_RETRY_ATTEMPTS</code>, base delay values), circuit breaker thresholds (<code>CIRCUIT_BREAKER_FAILURE_THRESHOLD</code>), and timeout values (<code>DELIVERY_TIMEOUT</code>). This configuration approach enables the same application binary to be deployed across development, staging, and production environments with environment-specific parameter tuning.</p>\n<table>\n<thead>\n<tr>\n<th>Environment</th>\n<th>Database</th>\n<th>Queue</th>\n<th>Instance Count</th>\n<th>Special Configuration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Development</td>\n<td>SQLite</td>\n<td>In-memory</td>\n<td>1</td>\n<td>Reduced timeouts, verbose logging</td>\n</tr>\n<tr>\n<td>Staging</td>\n<td>PostgreSQL</td>\n<td>RabbitMQ</td>\n<td>2</td>\n<td>Production timeouts, integration test endpoints</td>\n</tr>\n<tr>\n<td>Production</td>\n<td>PostgreSQL (HA)</td>\n<td>RabbitMQ (Cluster)</td>\n<td>3-10</td>\n<td>Security hardening, monitoring integration</td>\n</tr>\n</tbody></table>\n<p>The <strong>monitoring and observability</strong> deployment includes comprehensive metrics collection and alerting configured to track the health of each system component. Key metrics include delivery success rates per endpoint, queue depths for early detection of processing bottlenecks, circuit breaker state changes to identify problematic endpoints, and end-to-end delivery latency to monitor system performance. The deployment integrates with standard observability tools, exposing metrics in Prometheus format and structured logs compatible with centralized logging systems.</p>\n<blockquote>\n<p><strong>Scalability Considerations</strong>: The system&#39;s bottleneck is typically HTTP delivery throughput rather than queue processing or database operations. Each service instance can handle approximately 100-200 concurrent HTTP deliveries, with actual throughput depending on target endpoint response times. Scaling decisions should be based on delivery queue depth and worker thread utilization rather than CPU or memory usage.</p>\n</blockquote>\n<p>The <strong>security hardening</strong> for production deployment includes network-level protections against SSRF attacks through firewall rules that prevent webhook deliveries to private IP ranges, secure secrets management for webhook signing keys with automatic rotation capabilities, and comprehensive audit logging of all registration and delivery activities. The deployment also includes rate limiting at the load balancer level to protect against registration abuse and DDoS attacks against the registration API.</p>\n<h3 id=\"common-architecture-pitfalls\">Common Architecture Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Shared Circuit Breaker State Across Instances</strong>\nWhen deploying multiple service instances, a common mistake is failing to synchronize circuit breaker state across instances. This leads to inconsistent behavior where some instances block deliveries to a failing endpoint while others continue attempting delivery. The circuit breaker state must be stored in a shared location (Redis or database) with proper locking to ensure all instances see consistent endpoint health status. Implement circuit breaker state as a shared resource with atomic updates and cache invalidation to maintain consistency.</p>\n<p>⚠️ <strong>Pitfall: Database Connection Exhaustion Under Load</strong>\nEach delivery worker thread requires database connections for logging delivery attempts and updating circuit breaker state. Without proper connection pooling, high delivery volumes can exhaust the database connection limit, causing new delivery attempts to fail. The <code>DatabaseManager</code> must implement connection pooling with appropriate sizing based on the number of worker threads across all instances. Size the connection pool to handle peak load plus a safety margin, and implement connection retry logic for transient connection failures.</p>\n<p>⚠️ <strong>Pitfall: Queue Message Loss During Process Restarts</strong>\nIf delivery workers don&#39;t properly acknowledge message consumption, queued delivery requests can be lost during process restarts or crashes. This violates the at-least-once delivery guarantee. Implement proper message acknowledgment patterns where messages are only acknowledged after successful delivery or after being placed in the dead letter queue. Use manual acknowledgment mode in the message queue configuration rather than auto-acknowledgment.</p>\n<p>⚠️ <strong>Pitfall: Unbounded Queue Growth from Circuit Breaker Backlog</strong>\nWhen circuit breakers open for popular endpoints, delivery requests continue to accumulate in the queue without being processed. This can lead to memory exhaustion or disk space issues if the queue grows unboundedly. Implement queue depth monitoring with alerting, and consider implementing backpressure mechanisms that temporarily halt event ingestion when queue depths exceed safe thresholds. The dead letter queue also needs size limits and retention policies.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Timing Between Development and Production</strong>\nDevelopment environments often use shorter timeout values and retry intervals for faster testing, but forgetting to adjust these values for production can lead to premature delivery failures or excessive retry attempts. The <code>WebhookConfig</code> must include environment-specific defaults, and deployment automation should validate that production configurations use appropriate values for <code>DELIVERY_TIMEOUT</code>, retry intervals, and circuit breaker thresholds.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The webhook delivery system implementation requires careful attention to concurrent programming patterns, reliable message processing, and robust error handling. This section provides practical guidance for building each architectural component with production-ready reliability and performance characteristics.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n<th>Production Considerations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Database</td>\n<td>SQLite with WAL mode</td>\n<td>PostgreSQL with connection pooling</td>\n<td>PostgreSQL required for multi-instance deployment</td>\n</tr>\n<tr>\n<td>Message Queue</td>\n<td>Redis Lists with blocking pop</td>\n<td>RabbitMQ with persistent queues</td>\n<td>RabbitMQ provides better ordering guarantees</td>\n</tr>\n<tr>\n<td>HTTP Client</td>\n<td><code>requests</code> with session pooling</td>\n<td><code>httpx</code> with async support</td>\n<td>Connection pooling essential for performance</td>\n</tr>\n<tr>\n<td>Configuration</td>\n<td>Environment variables</td>\n<td><code>pydantic</code> settings with validation</td>\n<td>Validation prevents runtime configuration errors</td>\n</tr>\n<tr>\n<td>Logging</td>\n<td>Python <code>logging</code> module</td>\n<td>Structured logging with <code>structlog</code></td>\n<td>Structured logs essential for debugging</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Simple metrics collection</td>\n<td>Prometheus metrics with alerting</td>\n<td>Required for production observability</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-delivery-system/\n├── main.py                          ← Application entry point\n├── config.py                        ← WebhookConfig and environment handling\n├── models/                          ← Data models and database schemas\n│   ├── __init__.py\n│   ├── webhook.py                   ← WebhookRegistration model\n│   └── delivery.py                  ← DeliveryAttempt model\n├── components/                      ← Core system components\n│   ├── __init__.py\n│   ├── registry.py                  ← Webhook registration and verification\n│   ├── delivery_engine.py           ← Queue processing and HTTP delivery\n│   ├── circuit_breaker.py           ← Endpoint health monitoring\n│   └── event_logger.py              ← Delivery audit and replay\n├── infrastructure/                  ← Supporting infrastructure\n│   ├── __init__.py\n│   ├── database.py                  ← DatabaseManager and connection pooling\n│   ├── queue.py                     ← Message queue abstraction\n│   └── http_client.py               ← WebhookHTTPClient with connection pooling\n├── tests/                          ← Test suite\n│   ├── test_registry.py\n│   ├── test_delivery_engine.py\n│   ├── test_circuit_breaker.py\n│   └── integration/\n└── scripts/                        ← Operational scripts\n    ├── migrate_db.py\n    └── replay_events.py</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p>The following infrastructure components provide the foundation for the webhook delivery system. These are complete, production-ready implementations that handle connection pooling, error recovery, and resource management.</p>\n<p><strong>Database Connection Manager (<code>infrastructure/database.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> psycopg2</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> psycopg2 </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pool</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Generator</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DatabaseConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    host: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    port: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    database: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    username: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    password: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_connections: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_connections: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DatabaseManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Thread-safe database connection pool manager.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: DatabaseConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._pool </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> threading.Lock()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._initialize_pool()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _initialize_pool</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize the connection pool with retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._pool </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> psycopg2.pool.ThreadedConnectionPool(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                minconn</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.min_connections,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                maxconn</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.max_connections,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                host</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.host,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                port</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.port,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                database</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.database,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                user</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.username,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                password</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.password,</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Connection pool configuration for reliability</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                cursor_factory</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">psycopg2.extras.RealDictCursor,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                connect_timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                application_name</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"webhook-delivery-system\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logging.info(</span><span style=\"color:#9ECBFF\">\"Database connection pool initialized\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Failed to initialize database pool: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_connection</span><span style=\"color:#E1E4E8\">(self) -> Generator[psycopg2.extensions.connection, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get a database connection from the pool with automatic cleanup.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        connection </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                connection </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._pool.getconn()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span><span style=\"color:#E1E4E8\"> connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> connection:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                connection.rollback()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> connection:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._lock:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">._pool.putconn(connection)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> health_check</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Verify database connectivity for health monitoring.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.get_connection() </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> conn:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                with</span><span style=\"color:#E1E4E8\"> conn.cursor() </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> cursor:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    cursor.execute(</span><span style=\"color:#9ECBFF\">\"SELECT 1\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database health check failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<p><strong>HTTP Client with Connection Pooling (<code>infrastructure/http_client.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> urllib.parse </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> urlparse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HTTPResponse</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status_code: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    headers: Optional[</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookHTTPClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"HTTP client optimized for webhook delivery with connection pooling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">, max_retries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timeout</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> requests.Session()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Configure connection pooling for better performance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        adapter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> requests.adapters.HTTPAdapter(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_connections</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Number of connection pools to cache</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,     </span><span style=\"color:#6A737D\"># Maximum connections per pool</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_retries</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">max_retries</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.mount(</span><span style=\"color:#9ECBFF\">'http://'</span><span style=\"color:#E1E4E8\">, adapter)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.mount(</span><span style=\"color:#9ECBFF\">'https://'</span><span style=\"color:#E1E4E8\">, adapter)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Set default headers for webhook deliveries</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.headers.update({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'Content-Type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'application/json'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'User-Agent'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'WebhookDeliverySystem/1.0'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deliver_webhook</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, signature: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> HTTPResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Deliver webhook payload with signature authentication.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        headers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'X-Webhook-Signature-256'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">'sha256=</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">signature</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'X-Webhook-Timestamp'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(time.time())),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'X-Webhook-Delivery-ID'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">._generate_delivery_id()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.session.post(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                url, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                data</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">payload.encode(</span><span style=\"color:#9ECBFF\">'utf-8'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">headers,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.timeout,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                allow_redirects</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#6A737D\">  # Security: don't follow redirects</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response.status_code,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(response.headers)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.Timeout:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Special code for timeout</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Request timeout\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.ConnectionError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Special code for connection error</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Connection error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unexpected error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _generate_delivery_id</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate unique delivery ID for tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(uuid.uuid4())</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_url</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate webhook URL for security (SSRF protection).\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            parsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urlparse(url)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Must use HTTPS in production</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> parsed.scheme </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> 'https'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Block private IP ranges to prevent SSRF</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            import</span><span style=\"color:#E1E4E8\"> ipaddress</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                ip </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ipaddress.ip_address(parsed.hostname)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> ip.is_private </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> ip.is_loopback:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> ValueError</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Hostname is not an IP address, DNS resolution will be handled by requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<h4 id=\"core-component-skeletons\">Core Component Skeletons</h4>\n<p><strong>Webhook Registry Component (<code>components/registry.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Optional, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> secrets</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hmac</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookRegistry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages webhook endpoint registration and signature verification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, db_manager, http_client):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> db_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.http_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> http_client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_webhook</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, events: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], owner_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register a new webhook endpoint with ownership verification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            dict: Registration result with webhook_id and verification status</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate the webhook URL using http_client.validate_url()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate a cryptographically secure webhook secret using generate_webhook_secret()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store WebhookRegistration record in database with verified=False</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Initiate ownership verification process</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return registration response with webhook_id and next steps</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use uuid.uuid4() for webhook_id generation</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> verify_webhook_ownership</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Send challenge request to verify endpoint ownership.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            webhook_id: UUID of the webhook to verify</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            bool: True if verification succeeds, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve webhook registration from database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate verification challenge token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Send HTTP GET request with challenge parameter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate the response contains expected challenge echo</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update webhook registration with verified=True on success</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Challenge should be in query parameters: ?webhook_challenge=TOKEN</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_webhook_secret</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate cryptographically secure signing key for webhook authentication.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use secrets.token_urlsafe() to generate 32 bytes of randomness</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Ensure the secret is suitable for HMAC-SHA256 operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: 32 bytes provides 256 bits of entropy, same as SHA256 output</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_hmac_signature</span><span style=\"color:#E1E4E8\">(self, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, secret: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Compute HMAC-SHA256 signature for payload authentication.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            payload: JSON string to be signed</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            secret: Webhook signing secret</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            str: Hex-encoded HMAC signature</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create HMAC instance with SHA256 hash function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Update HMAC with payload bytes (ensure UTF-8 encoding)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return hexadecimal digest of the signature</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use hmac.new(secret.encode(), payload.encode(), hashlib.sha256)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Delivery Engine Component (<code>components/delivery_engine.py</code>):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DeliveryEngine</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles queued delivery processing with exponential backoff retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, db_manager, http_client, registry, circuit_breaker, logger):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> db_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.http_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> http_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> registry</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.circuit_breaker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> circuit_breaker</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.event_logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_delivery</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process a single webhook delivery with complete error handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            event_id: Unique identifier for the event being delivered</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            webhook_id: Target webhook endpoint identifier</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            payload: JSON payload to deliver</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            bool: True if delivery succeeded, False if failed/should retry</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check circuit breaker status for the target endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Retrieve webhook registration details (URL, secret, verification status)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate HMAC signature for the payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Attempt HTTP delivery using http_client.deliver_webhook()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Log the delivery attempt with event_logger</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update circuit breaker with success/failure result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return success status for retry decision logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Only attempt delivery if circuit breaker allows and webhook is verified</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deliver_webhook</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, signature: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute HTTP webhook delivery with timeout and error handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            url: Target endpoint URL</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            payload: JSON payload string</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            signature: HMAC signature for authentication</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Tuple of (status_code, response_time_seconds, error_message)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Use http_client to perform the POST request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle timeout and connection errors appropriately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return structured response information for retry logic</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: This method delegates to WebhookHTTPClient but adds delivery-specific logic</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_retry_delay</span><span style=\"color:#E1E4E8\">(self, attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, base_delay: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate exponential backoff delay with jitter for retry scheduling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            attempt_number: Current retry attempt (1-based)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            base_delay: Base delay in seconds for first retry</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            int: Delay in seconds before next retry attempt</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate exponential backoff: base_delay * (2 ** (attempt_number - 1))</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add random jitter to prevent thundering herd (±25% of calculated delay)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Cap maximum delay at reasonable value (e.g., 1 hour = 3600 seconds)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return final delay value</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use random.uniform() for jitter: delay * random.uniform(0.75, 1.25)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> should_retry_delivery</span><span style=\"color:#E1E4E8\">(self, status_code: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Determine if delivery failure should trigger retry based on response.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            status_code: HTTP response status code from delivery attempt</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            attempt_number: Current attempt number</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            bool: True if delivery should be retried, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if maximum retry attempts have been exceeded</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Classify status codes: 5xx and 429 are retryable, 4xx are not</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle special case of status_code=0 (network/timeout errors)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return retry decision</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Don't retry 4xx errors except 429 (Too Many Requests)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Checkpoint - Webhook Registration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test webhook registration API</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_registry.py::test_webhook_registration</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification steps:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 1. Start the application: python main.py</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 2. Register a webhook: curl -X POST localhost:8000/webhooks -d '{\"url\":\"https://example.com/webhook\",\"events\":[\"user.created\"]}'</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 3. Verify the response includes webhook_id and verification challenge instructions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 4. Check database for WebhookRegistration record with verified=False</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 5. Simulate ownership verification and verify the record updates to verified=True</span></span></code></pre></div>\n\n<p>Expected behavior: Registration creates database record, generates secure secret, initiates ownership verification process. HMAC signature generation produces consistent signatures for the same payload and secret.</p>\n<p><strong>Milestone 2 Checkpoint - Delivery Processing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test delivery engine with mock endpoints</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_delivery_engine.py::test_exponential_backoff</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_delivery_engine.py::test_retry_logic</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification with test server:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 1. Start test webhook endpoint: python scripts/test_webhook_server.py</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 2. Register webhook pointing to test server</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 3. Send test event and verify delivery appears in test server logs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 4. Stop test server and verify retry attempts with exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># 5. Restart test server and verify eventual successful delivery</span></span></code></pre></div>\n\n<p>Expected behavior: Delivery attempts follow exponential backoff pattern, failed deliveries are retried based on status codes, successful deliveries are logged and removed from retry queue.</p>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Webhooks not being delivered</td>\n<td>Circuit breaker opened</td>\n<td>Check circuit breaker state in Redis/database</td>\n<td>Manually reset circuit breaker or fix endpoint</td>\n</tr>\n<tr>\n<td>Exponential backoff not working</td>\n<td>Jitter calculation error</td>\n<td>Log actual delay values vs expected</td>\n<td>Verify jitter calculation uses proper bounds</td>\n</tr>\n<tr>\n<td>Database connection exhausted</td>\n<td>Too many concurrent workers</td>\n<td>Monitor connection pool usage</td>\n<td>Increase pool size or reduce worker threads</td>\n</tr>\n<tr>\n<td>HMAC signature verification fails</td>\n<td>Timestamp/payload mismatch</td>\n<td>Log exact payload and timestamp used</td>\n<td>Ensure consistent payload serialization</td>\n</tr>\n<tr>\n<td>Queue backing up under load</td>\n<td>Slow HTTP deliveries</td>\n<td>Monitor delivery response times</td>\n<td>Increase timeout or worker concurrency</td>\n</tr>\n</tbody></table>\n<h2 id=\"data-model\">Data Model</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Foundation for all milestones - data entities established here are used in webhook registration (Milestone 1), delivery tracking (Milestone 2), circuit breaker state (Milestone 3), and event logging (Milestone 4)</p>\n</blockquote>\n<h3 id=\"mental-model-the-digital-postal-service-database\">Mental Model: The Digital Postal Service Database</h3>\n<p>Think of the webhook delivery system&#39;s data model as the filing system for a sophisticated digital postal service. Just as a postal service maintains customer registrations (addresses, preferences, delivery instructions), delivery logs (tracking numbers, attempts, status updates), and operational state (route health, capacity limits), our webhook system needs structured data to track three core entities: registered webhook endpoints, events awaiting or completing delivery, and the detailed history of every delivery attempt.</p>\n<p>The data model serves as the authoritative record for the entire system&#39;s state. Unlike a traditional postal service that might lose a package or delivery record, our digital system maintains complete audit trails and guarantees no data loss through persistent storage and careful relationship modeling.</p>\n<p><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fdata-model.svg\" alt=\"Data Model Relationships\"></p>\n<p>The data model consists of three primary entity types that capture the complete lifecycle of webhook delivery. The <code>WebhookRegistration</code> entity represents customer-registered endpoints with their security credentials and event preferences. The <code>WebhookEvent</code> entity represents individual messages that need delivery, containing payloads and targeting information. The <code>DeliveryAttempt</code> entity provides the detailed audit trail of every delivery attempt, successful or failed, creating an immutable history for debugging and compliance.</p>\n<blockquote>\n<p><strong>Decision: Normalized Relational Design vs Denormalized Event Store</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook systems need to balance query performance, data consistency, and audit requirements while handling high-volume delivery operations</li>\n<li><strong>Options Considered</strong>: Normalized relational tables, denormalized event sourcing, hybrid approach with separate OLTP/OLAP stores</li>\n<li><strong>Decision</strong>: Normalized relational design with immutable delivery attempt records</li>\n<li><strong>Rationale</strong>: Provides strong consistency for webhook configuration, efficient querying for delivery status, and complete audit trails without data duplication. Event sourcing would complicate simple operations like &quot;show all webhooks for this customer&quot;</li>\n<li><strong>Consequences</strong>: Excellent data integrity and debugging capability, slightly more complex queries for analytics, straightforward implementation with standard SQL databases</li>\n</ul>\n</blockquote>\n<p>The relationship design enforces data integrity while supporting the system&#39;s operational needs. Each webhook registration can receive multiple events, and each event generates multiple delivery attempts over time. This one-to-many relationship structure naturally supports the retry logic and audit requirements while preventing orphaned records that could lead to data inconsistencies.</p>\n<h3 id=\"webhook-registration-model\">Webhook Registration Model</h3>\n<p>The webhook registration model captures everything needed to securely and reliably deliver events to customer endpoints. This model serves as the foundation for endpoint security, event filtering, and delivery targeting throughout the system&#39;s operation.</p>\n<p><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fregistration-sequence.svg\" alt=\"Registration Sequence\"></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>id</td>\n<td>str</td>\n<td>UUID primary key uniquely identifying this webhook registration</td>\n</tr>\n<tr>\n<td>url</td>\n<td>str</td>\n<td>HTTPS endpoint URL where events will be delivered via HTTP POST</td>\n</tr>\n<tr>\n<td>secret</td>\n<td>str</td>\n<td>Cryptographically secure signing key for HMAC-SHA256 payload signatures</td>\n</tr>\n<tr>\n<td>events</td>\n<td>list[str]</td>\n<td>Event type subscriptions determining which events this endpoint receives</td>\n</tr>\n<tr>\n<td>verified</td>\n<td>bool</td>\n<td>Ownership verification status indicating endpoint control confirmation</td>\n</tr>\n<tr>\n<td>created_at</td>\n<td>datetime</td>\n<td>Registration timestamp for audit trails and debugging</td>\n</tr>\n<tr>\n<td>updated_at</td>\n<td>datetime</td>\n<td>Last modification timestamp tracking configuration changes</td>\n</tr>\n<tr>\n<td>active</td>\n<td>bool</td>\n<td>Operational status allowing temporary endpoint disabling</td>\n</tr>\n<tr>\n<td>failure_count</td>\n<td>int</td>\n<td>Consecutive failure counter for circuit breaker state tracking</td>\n</tr>\n<tr>\n<td>circuit_state</td>\n<td>str</td>\n<td>Current circuit breaker state: &quot;closed&quot;, &quot;open&quot;, or &quot;half-open&quot;</td>\n</tr>\n<tr>\n<td>last_success_at</td>\n<td>datetime</td>\n<td>Most recent successful delivery timestamp for health monitoring</td>\n</tr>\n<tr>\n<td>rate_limit_rpm</td>\n<td>int</td>\n<td>Delivery rate limit in requests per minute for this endpoint</td>\n</tr>\n<tr>\n<td>metadata</td>\n<td>json</td>\n<td>Extensible key-value pairs for customer-specific configuration</td>\n</tr>\n</tbody></table>\n<p>The <code>WebhookRegistration</code> model balances security requirements with operational flexibility. The <code>secret</code> field contains a cryptographically random 32-byte key encoded as a hex string, providing sufficient entropy for HMAC signature security. The <code>events</code> field uses a simple string array rather than a complex subscription model, making event filtering straightforward while remaining extensible for future event type additions.</p>\n<blockquote>\n<p><strong>Decision: Embedded Circuit Breaker State vs Separate State Table</strong></p>\n<ul>\n<li><strong>Context</strong>: Circuit breaker functionality requires persistent state tracking per webhook endpoint</li>\n<li><strong>Options Considered</strong>: Store circuit state in webhook table, separate circuit_breaker_state table, in-memory state only</li>\n<li><strong>Decision</strong>: Embed circuit breaker fields directly in webhook registration table</li>\n<li><strong>Rationale</strong>: Circuit breaker state is tightly coupled to webhook identity, embedded approach reduces join complexity and ensures state persistence across service restarts</li>\n<li><strong>Consequences</strong>: Simpler queries and stronger consistency, slightly denormalized design, circuit state survives service restarts automatically</li>\n</ul>\n</blockquote>\n<p>The verification mechanism uses the <code>verified</code> boolean to track ownership confirmation through challenge-response validation. Unverified webhooks remain in the database but cannot receive event deliveries, preventing unauthorized endpoint registration while allowing customers to complete the verification process at their convenience.</p>\n<p><strong>URL Validation and SSRF Protection</strong></p>\n<p>The webhook URL undergoes strict validation to prevent server-side request forgery (SSRF) attacks and ensure delivery reliability. The validation process checks that URLs use HTTPS protocol exclusively, resolve to public IP addresses, and respond appropriately to challenge requests during ownership verification.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Rule</th>\n<th>Purpose</th>\n<th>Implementation</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTPS Only</td>\n<td>Prevents credential interception</td>\n<td>Reject any URL not starting with <code>https://</code></td>\n</tr>\n<tr>\n<td>Public IP Only</td>\n<td>SSRF attack prevention</td>\n<td>Resolve hostname and block private/internal IP ranges</td>\n</tr>\n<tr>\n<td>Valid Hostname</td>\n<td>DNS security</td>\n<td>Validate hostname format and successful resolution</td>\n</tr>\n<tr>\n<td>Reachable Endpoint</td>\n<td>Delivery viability</td>\n<td>Test HTTP connectivity during registration</td>\n</tr>\n<tr>\n<td>Challenge Response</td>\n<td>Ownership proof</td>\n<td>Send unique token and verify correct response</td>\n</tr>\n</tbody></table>\n<p>The SSRF protection specifically blocks delivery to private IP ranges (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16), localhost (127.0.0.0/8), and other reserved ranges to prevent internal network access through webhook delivery requests.</p>\n<h3 id=\"event-model\">Event Model</h3>\n<p>The event model represents individual messages queued for webhook delivery, capturing both the payload data and the delivery orchestration metadata required for reliable processing.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>id</td>\n<td>str</td>\n<td>UUID primary key uniquely identifying this event across the system</td>\n</tr>\n<tr>\n<td>event_type</td>\n<td>str</td>\n<td>Event classification used for webhook subscription filtering</td>\n</tr>\n<tr>\n<td>payload</td>\n<td>json</td>\n<td>Event data payload delivered to matching webhook endpoints</td>\n</tr>\n<tr>\n<td>source</td>\n<td>str</td>\n<td>Originating system or service that generated this event</td>\n</tr>\n<tr>\n<td>created_at</td>\n<td>datetime</td>\n<td>Event creation timestamp for ordering and audit purposes</td>\n</tr>\n<tr>\n<td>webhook_id</td>\n<td>str</td>\n<td>Foreign key referencing the target webhook registration</td>\n</tr>\n<tr>\n<td>delivery_status</td>\n<td>str</td>\n<td>Current status: &quot;pending&quot;, &quot;delivered&quot;, &quot;failed&quot;, &quot;dead_letter&quot;</td>\n</tr>\n<tr>\n<td>scheduled_at</td>\n<td>datetime</td>\n<td>Next delivery attempt timestamp for retry scheduling</td>\n</tr>\n<tr>\n<td>attempt_count</td>\n<td>int</td>\n<td>Number of delivery attempts made for this event</td>\n</tr>\n<tr>\n<td>signature</td>\n<td>str</td>\n<td>Pre-computed HMAC-SHA256 signature for delivery authentication</td>\n</tr>\n<tr>\n<td>idempotency_key</td>\n<td>str</td>\n<td>Unique identifier enabling safe event replay and deduplication</td>\n</tr>\n<tr>\n<td>priority</td>\n<td>int</td>\n<td>Delivery priority level for queue processing order (1=highest, 5=lowest)</td>\n</tr>\n<tr>\n<td>expires_at</td>\n<td>datetime</td>\n<td>Event expiration timestamp after which delivery stops</td>\n</tr>\n<tr>\n<td>metadata</td>\n<td>json</td>\n<td>Additional event context and customer-specific fields</td>\n</tr>\n</tbody></table>\n<p>The event model supports the complete delivery lifecycle from initial queuing through final disposition. The <code>delivery_status</code> field provides clear state tracking, while <code>scheduled_at</code> enables precise retry timing control using exponential backoff calculations.</p>\n<blockquote>\n<p><strong>Decision: Pre-computed Signatures vs Dynamic Generation</strong></p>\n<ul>\n<li><strong>Context</strong>: HMAC signatures must be calculated for every delivery attempt, potentially creating computational overhead</li>\n<li><strong>Options Considered</strong>: Calculate signatures on-demand during delivery, pre-compute and store signatures, hybrid caching approach</li>\n<li><strong>Decision</strong>: Pre-compute signatures during event creation and store in event record</li>\n<li><strong>Rationale</strong>: Reduces delivery latency by eliminating signature calculation from the critical path, simplifies delivery worker logic, signatures rarely change after event creation</li>\n<li><strong>Consequences</strong>: Slightly increased storage requirements, faster delivery processing, simpler worker implementation, signatures survive service restarts</li>\n</ul>\n</blockquote>\n<p>The <code>idempotency_key</code> serves dual purposes: enabling safe event replay for debugging and providing downstream endpoints with deduplication capabilities. When events are replayed through the system, they receive new event IDs but retain the same idempotency key, allowing receiving systems to detect and ignore duplicate deliveries.</p>\n<p><strong>Event Lifecycle States</strong></p>\n<p>Events transition through a well-defined state machine that governs delivery processing and error handling:</p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Trigger Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>pending</td>\n<td>delivery_attempted</td>\n<td>pending</td>\n<td>Increment attempt_count, update scheduled_at with backoff delay</td>\n</tr>\n<tr>\n<td>pending</td>\n<td>delivery_succeeded</td>\n<td>delivered</td>\n<td>Set final status, record success timestamp</td>\n</tr>\n<tr>\n<td>pending</td>\n<td>max_attempts_reached</td>\n<td>failed</td>\n<td>Move to dead letter queue, alert operations</td>\n</tr>\n<tr>\n<td>pending</td>\n<td>circuit_breaker_open</td>\n<td>pending</td>\n<td>Delay scheduling until circuit recovers</td>\n</tr>\n<tr>\n<td>failed</td>\n<td>manual_replay</td>\n<td>pending</td>\n<td>Reset attempt_count, generate new delivery_id</td>\n</tr>\n<tr>\n<td>delivered</td>\n<td>manual_replay</td>\n<td>pending</td>\n<td>Create new event instance with same idempotency_key</td>\n</tr>\n</tbody></table>\n<p>The state transitions ensure events never become lost or forgotten within the system. Failed events remain queryable for debugging, while delivered events provide an audit trail of successful operations.</p>\n<h3 id=\"delivery-tracking-model\">Delivery Tracking Model</h3>\n<p>The delivery tracking model provides comprehensive audit trails and debugging information for every webhook delivery attempt, creating an immutable record of system behavior that supports troubleshooting and compliance requirements.</p>\n<p><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fdelivery-sequence.svg\" alt=\"Delivery Sequence\"></p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>id</td>\n<td>str</td>\n<td>UUID primary key uniquely identifying this delivery attempt</td>\n</tr>\n<tr>\n<td>event_id</td>\n<td>str</td>\n<td>Foreign key linking to the webhook event being delivered</td>\n</tr>\n<tr>\n<td>webhook_id</td>\n<td>str</td>\n<td>Foreign key referencing the target webhook registration</td>\n</tr>\n<tr>\n<td>attempt_number</td>\n<td>int</td>\n<td>Sequential attempt counter starting from 1 for each event</td>\n</tr>\n<tr>\n<td>status_code</td>\n<td>int</td>\n<td>HTTP response status code returned by the webhook endpoint</td>\n</tr>\n<tr>\n<td>response_time</td>\n<td>float</td>\n<td>Request duration in seconds from send to response completion</td>\n</tr>\n<tr>\n<td>response_headers</td>\n<td>json</td>\n<td>HTTP response headers returned by the endpoint</td>\n</tr>\n<tr>\n<td>response_body</td>\n<td>str</td>\n<td>Response payload body for debugging failed deliveries</td>\n</tr>\n<tr>\n<td>error_message</td>\n<td>str</td>\n<td>Error description for failed attempts (timeouts, connection errors)</td>\n</tr>\n<tr>\n<td>attempted_at</td>\n<td>datetime</td>\n<td>Precise timestamp when this delivery attempt was initiated</td>\n</tr>\n<tr>\n<td>completed_at</td>\n<td>datetime</td>\n<td>Timestamp when response was received or error occurred</td>\n</tr>\n<tr>\n<td>request_headers</td>\n<td>json</td>\n<td>Complete HTTP headers sent with the delivery request</td>\n</tr>\n<tr>\n<td>request_payload</td>\n<td>str</td>\n<td>Exact payload delivered to the endpoint for audit purposes</td>\n</tr>\n<tr>\n<td>delivery_duration</td>\n<td>int</td>\n<td>Total processing time including queue delays and retries</td>\n</tr>\n<tr>\n<td>worker_instance</td>\n<td>str</td>\n<td>Identifier of the worker process handling this delivery</td>\n</tr>\n<tr>\n<td>circuit_breaker_triggered</td>\n<td>bool</td>\n<td>Whether this attempt triggered circuit breaker activation</td>\n</tr>\n</tbody></table>\n<p>The <code>DeliveryAttempt</code> model captures every detail necessary for comprehensive debugging and system monitoring. Unlike the mutable event model, delivery attempt records remain immutable after creation, providing a trustworthy audit trail that supports both automated monitoring and manual investigation.</p>\n<blockquote>\n<p><strong>Decision: Immutable Attempt Records vs Mutable Status Updates</strong></p>\n<ul>\n<li><strong>Context</strong>: Delivery attempts need detailed logging for debugging while supporting efficient status queries</li>\n<li><strong>Options Considered</strong>: Update single delivery record with latest status, create immutable attempt record per delivery, hybrid with summary + detail tables</li>\n<li><strong>Decision</strong>: Create immutable delivery attempt record for every delivery try</li>\n<li><strong>Rationale</strong>: Provides complete audit trail for compliance and debugging, prevents accidental data loss, supports detailed analytics on delivery patterns</li>\n<li><strong>Consequences</strong>: Higher storage requirements, complete debugging capability, slight complexity in &quot;current status&quot; queries</li>\n</ul>\n</blockquote>\n<p>The delivery tracking model supports advanced debugging scenarios by preserving complete request and response information. When webhook deliveries fail due to endpoint issues, developers can examine the exact headers, payload, and response to identify integration problems without reproducing the original event.</p>\n<p><strong>Response Classification and Retry Logic</strong></p>\n<p>The delivery tracking model supports sophisticated retry logic through detailed response classification:</p>\n<table>\n<thead>\n<tr>\n<th>Status Code Range</th>\n<th>Classification</th>\n<th>Retry Behavior</th>\n<th>Circuit Breaker Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>200-299</td>\n<td>Success</td>\n<td>No retry needed</td>\n<td>Reset failure counter</td>\n</tr>\n<tr>\n<td>300-399</td>\n<td>Redirect</td>\n<td>Follow redirect, then apply success/failure rules</td>\n<td>Neutral</td>\n</tr>\n<tr>\n<td>400-499 (except 429)</td>\n<td>Client Error</td>\n<td>No retry (permanent failure)</td>\n<td>No impact on circuit</td>\n</tr>\n<tr>\n<td>429</td>\n<td>Rate Limited</td>\n<td>Retry with Retry-After header respect</td>\n<td>Neutral</td>\n</tr>\n<tr>\n<td>500-599</td>\n<td>Server Error</td>\n<td>Retry with exponential backoff</td>\n<td>Increment failure counter</td>\n</tr>\n<tr>\n<td>Timeout/Connection</td>\n<td>Network Error</td>\n<td>Retry with exponential backoff</td>\n<td>Increment failure counter</td>\n</tr>\n</tbody></table>\n<p>The classification logic prevents inappropriate retries for client errors while ensuring transient server failures receive proper retry treatment. The <code>circuit_breaker_triggered</code> field tracks which delivery attempts contributed to circuit breaker state changes, enabling debugging of protection mechanism activation.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Storing Webhook Secrets in Plain Text</strong></p>\n<p>Many implementations store webhook signing secrets as plain text in the database, creating a significant security vulnerability. If the database is compromised, attackers can forge webhook signatures for any registered endpoint.</p>\n<p><strong>Why it&#39;s wrong</strong>: Plain text secrets provide no protection against database breaches and make secret rotation unnecessarily complex since there&#39;s no way to distinguish between different secret versions.</p>\n<p><strong>Fix</strong>: Hash webhook secrets using a strong key derivation function (PBKDF2, scrypt, or Argon2) before database storage. Store both the hashed secret and a salt value, then use the same derivation process to generate signatures during delivery.</p>\n<p>⚠️ <strong>Pitfall: Missing Foreign Key Constraints</strong></p>\n<p>Implementing the data model without proper foreign key constraints allows orphaned records that break data integrity. Events without corresponding webhooks or delivery attempts without parent events create debugging nightmares.</p>\n<p><strong>Why it&#39;s wrong</strong>: Without foreign key constraints, application bugs can create invalid data states that crash delivery workers or produce confusing audit trails with missing context.</p>\n<p><strong>Fix</strong>: Implement foreign key constraints with appropriate cascade behaviors. Use <code>ON DELETE CASCADE</code> for delivery attempts when events are deleted, but <code>ON DELETE RESTRICT</code> for webhook deletions to prevent accidental data loss.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Indexing for Query Performance</strong></p>\n<p>The webhook delivery system generates high-volume time-series data, but many implementations neglect proper indexing, leading to slow queries that impact delivery performance and user experience.</p>\n<p><strong>Why it&#39;s wrong</strong>: Without proper indexes, queries for delivery status, retry scheduling, and dashboard displays become prohibitively slow as data volume grows, eventually making the system unusable.</p>\n<p><strong>Fix</strong>: Create composite indexes on frequently queried combinations: <code>(webhook_id, created_at)</code> for delivery history, <code>(delivery_status, scheduled_at)</code> for retry processing, and <code>(event_type, created_at)</code> for event filtering.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The data model implementation requires careful attention to database schema design, relationship integrity, and query performance. The following guidance provides practical implementation strategies using Python with SQLAlchemy ORM.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Database</td>\n<td>PostgreSQL with SQLAlchemy</td>\n<td>PostgreSQL with custom connection pooling</td>\n</tr>\n<tr>\n<td>Schema Migration</td>\n<td>Alembic migration scripts</td>\n<td>Custom migration framework with rollback</td>\n</tr>\n<tr>\n<td>Connection Management</td>\n<td>SQLAlchemy Session</td>\n<td>AsyncPG with connection pooling</td>\n</tr>\n<tr>\n<td>Serialization</td>\n<td>JSON columns with validation</td>\n<td>Protocol Buffers with schema evolution</td>\n</tr>\n</tbody></table>\n<p><strong>File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-system/\n├── models/\n│   ├── __init__.py\n│   ├── base.py              ← SQLAlchemy base configuration\n│   ├── webhook.py           ← WebhookRegistration model\n│   ├── event.py             ← WebhookEvent model  \n│   └── delivery.py          ← DeliveryAttempt model\n├── database/\n│   ├── __init__.py\n│   ├── connection.py        ← DatabaseManager implementation\n│   └── migrations/          ← Alembic migration files\n└── schemas/\n    ├── __init__.py\n    └── validation.py        ← Pydantic schemas for API validation</code></pre></div>\n\n<p><strong>Database Configuration and Connection Management:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># models/base.py - Complete SQLAlchemy configuration</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> create_engine, MetaData</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.ext.declarative </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> declarative_base</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.orm </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sessionmaker</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># SQLAlchemy base configuration with naming conventions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">metadata </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> MetaData(</span><span style=\"color:#FFAB70\">naming_convention</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"ix\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"ix_</span><span style=\"color:#79B8FF\">%(column_0_label)s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"uq\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"uq_</span><span style=\"color:#79B8FF\">%(table_name)s</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">%(column_0_name)s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"ck\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"ck_</span><span style=\"color:#79B8FF\">%(table_name)s</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">%(constraint_name)s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"fk\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"fk_</span><span style=\"color:#79B8FF\">%(table_name)s</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">%(column_0_name)s</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">%(referred_table_name)s</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"pk\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"pk_</span><span style=\"color:#79B8FF\">%(table_name)s</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">})</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Base </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> declarative_base(</span><span style=\"color:#FFAB70\">metadata</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">metadata)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DatabaseManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Connection pool manager with get_connection context manager\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, database_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.engine </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> create_engine(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            database_url,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_overflow</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">30</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_pre_ping</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Verify connections before use</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_recycle</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3600</span><span style=\"color:#E1E4E8\">,   </span><span style=\"color:#6A737D\"># Recycle connections hourly</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            echo</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#6A737D\">           # Set True for SQL debugging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.SessionLocal </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sessionmaker(</span><span style=\"color:#FFAB70\">bind</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.engine)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_connection</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager for database connections with automatic cleanup\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        session </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.SessionLocal()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span><span style=\"color:#E1E4E8\"> session</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            session.commit()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            session.rollback()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            raise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            session.close()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_tables</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create all tables defined by SQLAlchemy models\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        Base.metadata.create_all(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.engine)</span></span></code></pre></div>\n\n<p><strong>Webhook Registration Model Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># models/webhook.py - Complete WebhookRegistration model</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Column, String, Boolean, DateTime, Integer, </span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, Text</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.dialects.postgresql </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> UUID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.orm </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> relationship</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Base</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookRegistration</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Base</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Webhook endpoint registration with security and circuit breaker state\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __tablename__ </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'webhook_registrations'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Core identification and endpoint configuration  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    id</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Column(UUID(</span><span style=\"color:#FFAB70\">as_uuid</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">primary_key</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">uuid.uuid4)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">2048</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Support long URLs</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    secret </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">128</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Hex-encoded signing key</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">list</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Event type subscriptions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Ownership and operational status</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    verified </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Boolean, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    active </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Boolean, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Circuit breaker state tracking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failure_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'closed'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_success_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Rate limiting and operational configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_rpm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Audit timestamps</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    updated_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                       onupdate</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Relationships to related entities</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    events_relationship </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relationship(</span><span style=\"color:#9ECBFF\">\"WebhookEvent\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">back_populates</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"webhook\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delivery_attempts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relationship(</span><span style=\"color:#9ECBFF\">\"DeliveryAttempt\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">back_populates</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"webhook\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __repr__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;WebhookRegistration(id=</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, url=</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">, verified=</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.verified</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">)>\"</span></span></code></pre></div>\n\n<p><strong>Event and Delivery Tracking Models:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># models/event.py - WebhookEvent model with delivery tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Column, String, DateTime, Integer, </span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, Text, ForeignKey</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.dialects.postgresql </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> UUID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.orm </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> relationship</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Base</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookEvent</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Base</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Individual webhook event awaiting or completing delivery\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __tablename__ </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'webhook_events'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Event identification and content</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    id</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Column(UUID(</span><span style=\"color:#FFAB70\">as_uuid</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">primary_key</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">uuid.uuid4)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">index</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    payload </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    source </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Delivery targeting and scheduling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(UUID(</span><span style=\"color:#FFAB70\">as_uuid</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">), ForeignKey(</span><span style=\"color:#9ECBFF\">'webhook_registrations.id'</span><span style=\"color:#E1E4E8\">), </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                       nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delivery_status </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'pending'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">index</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    scheduled_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow, </span><span style=\"color:#FFAB70\">index</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Delivery attempt tracking  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attempt_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    signature </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">128</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Pre-computed HMAC</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Deduplication and lifecycle management</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    idempotency_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">128</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">unique</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    priority </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># 1=highest, 5=lowest</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expires_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                       default</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: datetime.utcnow() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> timedelta(</span><span style=\"color:#FFAB70\">days</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Extensible metadata and audit trail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow, </span><span style=\"color:#FFAB70\">index</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Relationships</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relationship(</span><span style=\"color:#9ECBFF\">\"WebhookRegistration\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">back_populates</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"events_relationship\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delivery_attempts </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relationship(</span><span style=\"color:#9ECBFF\">\"DeliveryAttempt\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">back_populates</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"event\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># models/delivery.py - DeliveryAttempt immutable audit records  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Column, String, DateTime, Integer, </span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, Text, Boolean, Float, ForeignKey</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.dialects.postgresql </span><span style=\"color:#F97583\">import</span><span style=\"color:#79B8FF\"> UUID</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.orm </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> relationship</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .base </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Base</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DeliveryAttempt</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Base</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Immutable record of individual webhook delivery attempt\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __tablename__ </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'delivery_attempts'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Attempt identification and relationships</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    id</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Column(UUID(</span><span style=\"color:#FFAB70\">as_uuid</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">primary_key</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">uuid.uuid4)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(UUID(</span><span style=\"color:#FFAB70\">as_uuid</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">), ForeignKey(</span><span style=\"color:#9ECBFF\">'webhook_events.id'</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(UUID(</span><span style=\"color:#FFAB70\">as_uuid</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">), ForeignKey(</span><span style=\"color:#9ECBFF\">'webhook_registrations.id'</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attempt_number </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # HTTP delivery results</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status_code </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># None for connection errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Float, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Text, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Complete request/response audit trail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_headers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_body </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Text, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Truncated for large responses</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request_headers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    request_payload </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Text, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Timing and processing metadata</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attempted_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow, </span><span style=\"color:#FFAB70\">index</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    completed_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delivery_duration </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Milliseconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    worker_instance </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String(</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">), </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Circuit breaker impact tracking</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_breaker_triggered </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Boolean, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Relationships</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relationship(</span><span style=\"color:#9ECBFF\">\"WebhookEvent\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">back_populates</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"delivery_attempts\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> relationship(</span><span style=\"color:#9ECBFF\">\"WebhookRegistration\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">back_populates</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"delivery_attempts\"</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>Essential Database Indexes:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Add to models after class definitions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Index</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Composite indexes for common query patterns</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Index(</span><span style=\"color:#9ECBFF\">'ix_events_webhook_created'</span><span style=\"color:#E1E4E8\">, WebhookEvent.webhook_id, WebhookEvent.created_at)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Index(</span><span style=\"color:#9ECBFF\">'ix_events_status_scheduled'</span><span style=\"color:#E1E4E8\">, WebhookEvent.delivery_status, WebhookEvent.scheduled_at)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Index(</span><span style=\"color:#9ECBFF\">'ix_attempts_event_attempt'</span><span style=\"color:#E1E4E8\">, DeliveryAttempt.event_id, DeliveryAttempt.attempt_number)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Index(</span><span style=\"color:#9ECBFF\">'ix_attempts_webhook_attempted'</span><span style=\"color:#E1E4E8\">, DeliveryAttempt.webhook_id, DeliveryAttempt.attempted_at)</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint:</strong></p>\n<p>After implementing the data model:</p>\n<ol>\n<li><strong>Database Creation</strong>: Run <code>python -m models.base</code> to create all tables with proper indexes and constraints</li>\n<li><strong>Model Validation</strong>: Create test webhook registration - verify foreign key relationships work correctly</li>\n<li><strong>Query Performance</strong>: Insert 1000 test events and verify delivery status queries complete under 100ms</li>\n<li><strong>Data Integrity</strong>: Attempt to create orphaned records - foreign key constraints should prevent creation</li>\n</ol>\n<p>Expected behavior: All CRUD operations should work smoothly, complex queries should perform well, and the database should enforce referential integrity automatically.</p>\n<h2 id=\"webhook-registry-component\">Webhook Registry Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 1 (Webhook Registration &amp; Security) - implements endpoint registration, signature verification, and ownership validation that forms the security foundation for all webhook deliveries</p>\n</blockquote>\n<h3 id=\"mental-model-the-secure-post-office-registration-system\">Mental Model: The Secure Post Office Registration System</h3>\n<p>Think of the webhook registry as a post office that manages delivery addresses, but with strict security requirements. Just as you can&#39;t simply claim ownership of someone else&#39;s postal address, webhook endpoints must prove they control their URL before receiving deliveries. The registry acts like a postal clerk who:</p>\n<ol>\n<li><strong>Verifies address ownership</strong> - sends a verification letter to confirm you actually receive mail at that address</li>\n<li><strong>Issues secure delivery certificates</strong> - provides cryptographic &quot;stamps&quot; (HMAC signatures) that prove packages came from the legitimate postal service</li>\n<li><strong>Maintains address books</strong> - tracks which addresses want which types of mail (event subscriptions)</li>\n<li><strong>Rotates security credentials</strong> - periodically updates the cryptographic stamps while ensuring packages in transit remain valid</li>\n</ol>\n<p>This mental model captures the core challenge: balancing security (preventing unauthorized deliveries and spoofing) with usability (making registration straightforward for legitimate users).</p>\n<p>The webhook registry component serves as the secure foundation for the entire delivery system. Before any webhook can receive events, it must successfully register with ownership verification. This component generates the cryptographic signatures that authenticate every delivery attempt, manages secret rotation to maintain long-term security, and protects against common attack vectors like Server-Side Request Forgery (SSRF).</p>\n<h3 id=\"registration-and-ownership-verification\">Registration and Ownership Verification</h3>\n<p>The registration process establishes a trusted relationship between the webhook delivery system and endpoint owners through a multi-step verification protocol. This process prevents unauthorized webhook registrations that could be used for attacks or data exfiltration.</p>\n<h4 id=\"registration-protocol-design\">Registration Protocol Design</h4>\n<p>The registration protocol follows a challenge-response pattern that ensures only users who control an endpoint can register it for webhook deliveries. This prevents attackers from registering endpoints they don&#39;t own and intercepting sensitive webhook data intended for legitimate applications.</p>\n<blockquote>\n<p><strong>Decision: Challenge-Response Ownership Verification</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to verify that registration requests come from users who actually control the endpoint URL</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>No verification (trust registration requests)</li>\n<li>DNS-based verification (verify DNS ownership)</li>\n<li>Challenge-response verification (send test request to endpoint)</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Challenge-response verification with cryptographic challenges</li>\n<li><strong>Rationale</strong>: DNS verification doesn&#39;t prove HTTP endpoint control; no verification enables trivial attacks; challenge-response directly verifies HTTP endpoint control with minimal complexity</li>\n<li><strong>Consequences</strong>: Adds registration latency but provides strong security guarantees; requires endpoints to implement challenge handling</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Registration Step</th>\n<th>Action</th>\n<th>Purpose</th>\n<th>Security Consideration</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1. Initial Request</td>\n<td>Validate URL format and accessibility</td>\n<td>Prevent obviously invalid endpoints</td>\n<td>Block private IP ranges to prevent SSRF</td>\n</tr>\n<tr>\n<td>2. Challenge Generation</td>\n<td>Create cryptographically random challenge token</td>\n<td>Ensure unpredictable verification</td>\n<td>Use secure random number generator</td>\n</tr>\n<tr>\n<td>3. Challenge Delivery</td>\n<td>Send HTTP POST with challenge to endpoint</td>\n<td>Verify endpoint receives requests</td>\n<td>Set short timeout to prevent hanging</td>\n</tr>\n<tr>\n<td>4. Response Validation</td>\n<td>Verify correct challenge response format</td>\n<td>Confirm endpoint understands protocol</td>\n<td>Validate response within time window</td>\n</tr>\n<tr>\n<td>5. Registration Completion</td>\n<td>Store verified endpoint with generated secret</td>\n<td>Enable future webhook deliveries</td>\n<td>Mark endpoint as verified and active</td>\n</tr>\n</tbody></table>\n<p>The registration request validation performs comprehensive URL analysis to prevent Server-Side Request Forgery attacks. The system blocks requests to private IP address ranges, localhost, and other internal network resources that could be exploited to access internal services.</p>\n<h4 id=\"url-validation-and-ssrf-protection\">URL Validation and SSRF Protection</h4>\n<p>SSRF protection represents a critical security boundary that prevents attackers from using the webhook system to probe internal networks or access restricted services. The validation logic must be comprehensive while avoiding overly restrictive policies that block legitimate use cases.</p>\n<p>The URL validation process begins with parsing the provided endpoint URL using a strict parser that rejects malformed URLs, unsupported schemes, and suspicious components. Only HTTPS URLs are accepted, ensuring all webhook deliveries occur over encrypted connections.</p>\n<blockquote>\n<p>⚠️ <strong>Pitfall: Insufficient SSRF Protection</strong>\nMany developers focus only on blocking obvious private IPs like 127.0.0.1 and 192.168.x.x, but attackers can use DNS rebinding, URL redirects, and IPv6 addresses to bypass simple IP filtering. Comprehensive protection requires DNS resolution validation, redirect following limits, and IPv6 private range blocking.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>SSRF Protection Layer</th>\n<th>Implementation</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>URL Scheme Validation</td>\n<td>Accept only HTTPS schemes</td>\n<td>Prevent file://, ftp://, and other protocol abuse</td>\n</tr>\n<tr>\n<td>IP Address Filtering</td>\n<td>Block RFC 1918 private ranges</td>\n<td>Prevent internal network access</td>\n</tr>\n<tr>\n<td>DNS Resolution Check</td>\n<td>Resolve hostname before allowing registration</td>\n<td>Detect DNS rebinding attacks</td>\n</tr>\n<tr>\n<td>Port Restriction</td>\n<td>Allow only standard HTTPS ports (443, 8443)</td>\n<td>Prevent port scanning of internal services</td>\n</tr>\n<tr>\n<td>Redirect Following</td>\n<td>Limit redirect chains to 3 hops</td>\n<td>Prevent redirect-based SSRF bypass</td>\n</tr>\n<tr>\n<td>IPv6 Protection</td>\n<td>Block IPv6 private ranges (fc00::/7)</td>\n<td>Comprehensive private network protection</td>\n</tr>\n</tbody></table>\n<p>The challenge-response mechanism uses a time-limited cryptographic token that the endpoint must echo back in a specific format. This proves the endpoint can receive HTTP POST requests and parse JSON payloads, validating it can handle actual webhook deliveries.</p>\n<h4 id=\"challenge-response-implementation\">Challenge-Response Implementation</h4>\n<p>The challenge mechanism generates a cryptographically secure random token and sends it to the candidate endpoint via HTTP POST request. The endpoint must respond within a configured time window (typically 60 seconds) with the challenge token in the expected format.</p>\n<p>The challenge request includes metadata about the webhook system, the event types being subscribed to, and instructions for completing verification. This helps endpoint developers understand the registration process and implement appropriate response handlers.</p>\n<table>\n<thead>\n<tr>\n<th>Challenge Field</th>\n<th>Type</th>\n<th>Purpose</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>challenge_token</td>\n<td>string</td>\n<td>Cryptographic proof token</td>\n<td>&quot;chg_7f3e8d9a2b1c4e6f&quot;</td>\n</tr>\n<tr>\n<td>webhook_url</td>\n<td>string</td>\n<td>Callback URL being verified</td>\n<td>&quot;<a href=\"https://api.example.com/webhooks\">https://api.example.com/webhooks</a>&quot;</td>\n</tr>\n<tr>\n<td>event_types</td>\n<td>array</td>\n<td>Subscribed event types</td>\n<td>[&quot;user.created&quot;, &quot;order.completed&quot;]</td>\n</tr>\n<tr>\n<td>expires_at</td>\n<td>timestamp</td>\n<td>Challenge expiration time</td>\n<td>&quot;2024-01-15T14:30:00Z&quot;</td>\n</tr>\n<tr>\n<td>verification_url</td>\n<td>string</td>\n<td>URL to complete registration</td>\n<td>&quot;<a href=\"https://webhooks.service.com/verify/abc123\">https://webhooks.service.com/verify/abc123</a>&quot;</td>\n</tr>\n</tbody></table>\n<p>The endpoint must respond with a JSON payload containing the challenge token and additional confirmation data. This response format validation ensures the endpoint can handle structured webhook payloads and isn&#39;t simply echoing requests without parsing.</p>\n<p>The verification process includes timestamp validation to prevent replay attacks where an attacker captures a legitimate challenge response and reuses it later. Challenge tokens are single-use and expire quickly to minimize the attack window.</p>\n<h3 id=\"hmac-signature-generation\">HMAC Signature Generation</h3>\n<p>HMAC (Hash-based Message Authentication Code) signature generation provides cryptographic proof that webhook payloads originate from the legitimate delivery system and haven&#39;t been tampered with during transmission. This signature mechanism forms the core of webhook payload authentication.</p>\n<h4 id=\"cryptographic-design-foundation\">Cryptographic Design Foundation</h4>\n<p>The HMAC signature system uses SHA-256 as the underlying hash function, providing strong cryptographic properties and wide compatibility across programming languages and platforms. The signature covers both the payload content and metadata to prevent replay attacks and payload tampering.</p>\n<blockquote>\n<p><strong>Decision: HMAC-SHA256 with Timestamp Protection</strong></p>\n<ul>\n<li><strong>Context</strong>: Need cryptographic authentication for webhook payloads with replay attack protection</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>JWT signatures (RS256 or HS256)</li>\n<li>Simple hash signatures (MD5 or SHA-256)</li>\n<li>HMAC-SHA256 with timestamp validation</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: HMAC-SHA256 with timestamp validation and structured signing</li>\n<li><strong>Rationale</strong>: HMAC provides mutual authentication without key distribution complexity; SHA-256 offers strong security; timestamp validation prevents replay attacks; simpler than JWT with equivalent security</li>\n<li><strong>Consequences</strong>: Requires clock synchronization between systems; slightly more complex than simple hashing but much more secure</li>\n</ul>\n</blockquote>\n<p>The signature generation process creates a canonical representation of the webhook payload and metadata, ensuring consistent signature calculation across different implementations and preventing subtle variations that could break verification.</p>\n<table>\n<thead>\n<tr>\n<th>Signature Component</th>\n<th>Purpose</th>\n<th>Format</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Timestamp</td>\n<td>Replay attack prevention</td>\n<td>Unix timestamp (seconds)</td>\n<td>1642265400</td>\n</tr>\n<tr>\n<td>Payload Hash</td>\n<td>Content integrity</td>\n<td>SHA-256 hex digest</td>\n<td>&quot;a3f5d...&quot;</td>\n</tr>\n<tr>\n<td>Webhook ID</td>\n<td>Delivery authentication</td>\n<td>UUID string</td>\n<td>&quot;wh_7f3e8d9a2b1c4e6f&quot;</td>\n</tr>\n<tr>\n<td>Event Type</td>\n<td>Context validation</td>\n<td>Dot-separated string</td>\n<td>&quot;user.created&quot;</td>\n</tr>\n<tr>\n<td>Delivery ID</td>\n<td>Request uniqueness</td>\n<td>UUID string</td>\n<td>&quot;del_9a2b1c4e6f8d3e7a&quot;</td>\n</tr>\n</tbody></table>\n<p>The signing process concatenates these components in a specific order, separated by newline characters, creating a canonical string that gets processed through HMAC-SHA256 with the webhook&#39;s secret key. This structure ensures that any modification to the payload, metadata, or timestamp results in signature verification failure.</p>\n<h4 id=\"signature-calculation-process\">Signature Calculation Process</h4>\n<p>The signature calculation follows a deterministic process that creates identical signatures for identical inputs, enabling reliable verification at the receiving endpoint. The process must handle edge cases like empty payloads, special characters, and large payload sizes consistently.</p>\n<p>The canonical signing string construction follows this precise format:</p>\n<ol>\n<li>Start with the Unix timestamp as a string</li>\n<li>Add newline character (\\n)</li>\n<li>Add the webhook ID</li>\n<li>Add newline character (\\n)</li>\n<li>Add the delivery ID</li>\n<li>Add newline character (\\n)</li>\n<li>Add the event type</li>\n<li>Add newline character (\\n)</li>\n<li>Add the complete JSON payload (without additional formatting)</li>\n</ol>\n<p>This canonical string gets processed through HMAC-SHA256 using the webhook&#39;s secret key, producing a 256-bit hash value that gets encoded as a hexadecimal string for HTTP header transmission.</p>\n<blockquote>\n<p>The critical insight here is that signature verification must be timing-attack resistant. Naive string comparison of signatures can leak information about correct signature bytes through timing differences, potentially enabling signature forgery. Use constant-time comparison functions provided by cryptographic libraries.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Signature Header</th>\n<th>Format</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>X-Webhook-Timestamp</td>\n<td>Unix timestamp</td>\n<td>1642265400</td>\n</tr>\n<tr>\n<td>X-Webhook-Signature-256</td>\n<td>sha256=<hex_digest></td>\n<td>sha256=a3f5d9e7c2b8f1a4...</td>\n</tr>\n<tr>\n<td>X-Webhook-ID</td>\n<td>Webhook registration ID</td>\n<td>wh_7f3e8d9a2b1c4e6f</td>\n</tr>\n<tr>\n<td>X-Webhook-Delivery</td>\n<td>Unique delivery attempt ID</td>\n<td>del_9a2b1c4e6f8d3e7a</td>\n</tr>\n</tbody></table>\n<h4 id=\"timestamp-based-replay-protection\">Timestamp-Based Replay Protection</h4>\n<p>Timestamp validation prevents replay attacks where attackers capture valid webhook requests and retransmit them later. The validation window must balance security (narrow window) with operational flexibility (allowing for network delays and clock skew).</p>\n<p>The replay protection mechanism compares the timestamp in the webhook headers against the current time, rejecting requests outside the acceptable window. The default tolerance of 5 minutes (<code>TIMESTAMP_TOLERANCE = 300</code> seconds) accommodates normal network delays and minor clock differences while preventing old requests from being replayed.</p>\n<p>Clock skew handling recognizes that distributed systems rarely have perfectly synchronized clocks. The tolerance window allows for reasonable clock differences between the webhook delivery system and receiving endpoints without compromising security significantly.</p>\n<table>\n<thead>\n<tr>\n<th>Timestamp Validation Check</th>\n<th>Condition</th>\n<th>Action</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Missing Timestamp</td>\n<td>No X-Webhook-Timestamp header</td>\n<td>Reject request</td>\n<td>Cannot validate replay protection</td>\n</tr>\n<tr>\n<td>Invalid Format</td>\n<td>Non-numeric or malformed timestamp</td>\n<td>Reject request</td>\n<td>Prevents parsing errors and bypasses</td>\n</tr>\n<tr>\n<td>Future Timestamp</td>\n<td>Timestamp &gt; current_time + tolerance</td>\n<td>Reject request</td>\n<td>Prevents time-based attacks</td>\n</tr>\n<tr>\n<td>Expired Timestamp</td>\n<td>Timestamp &lt; current_time - tolerance</td>\n<td>Reject request</td>\n<td>Prevents replay attacks</td>\n</tr>\n<tr>\n<td>Valid Window</td>\n<td>Within tolerance range</td>\n<td>Accept for signature verification</td>\n<td>Normal operation</td>\n</tr>\n</tbody></table>\n<p>The timestamp validation occurs before signature verification to avoid unnecessary cryptographic computation for obviously invalid requests. However, the timestamp itself is included in the signature to prevent timestamp tampering attacks.</p>\n<h3 id=\"secret-rotation-strategy\">Secret Rotation Strategy</h3>\n<p>Secret rotation maintains long-term security by periodically updating the cryptographic keys used for signature generation while ensuring seamless operation during the transition period. The rotation strategy must handle in-flight deliveries and allow gradual migration without service disruption.</p>\n<h4 id=\"overlapping-validity-periods\">Overlapping Validity Periods</h4>\n<p>The secret rotation mechanism uses overlapping validity periods where both old and new secrets remain valid during a transition window. This approach prevents delivery failures when webhook events signed with the old secret are still being processed or retried.</p>\n<blockquote>\n<p><strong>Decision: Overlapping Secret Validity with Graceful Migration</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to rotate secrets regularly for security while maintaining delivery reliability</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Immediate secret replacement (old secret invalid immediately)</li>\n<li>Overlapping validity periods with gradual migration</li>\n<li>Secret versioning with explicit version negotiation</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Overlapping validity periods with configurable transition windows</li>\n<li><strong>Rationale</strong>: Immediate replacement breaks in-flight deliveries; version negotiation adds complexity; overlapping periods provide security and reliability</li>\n<li><strong>Consequences</strong>: Requires tracking multiple active secrets per webhook; slightly more complex verification logic but prevents delivery failures</li>\n</ul>\n</blockquote>\n<p>The rotation schedule uses a configurable interval (typically 30-90 days) with automatic secret generation and gradual migration. During the transition period, new deliveries use the new secret while the system continues accepting verification attempts with either secret.</p>\n<table>\n<thead>\n<tr>\n<th>Rotation Phase</th>\n<th>Duration</th>\n<th>New Deliveries</th>\n<th>Verification Accepts</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Pre-rotation</td>\n<td>Normal operation</td>\n<td>Current secret</td>\n<td>Current secret only</td>\n<td>Stable state</td>\n</tr>\n<tr>\n<td>Rotation Start</td>\n<td>Immediate</td>\n<td>New secret</td>\n<td>Both secrets</td>\n<td>Begin transition</td>\n</tr>\n<tr>\n<td>Transition Period</td>\n<td>7-14 days</td>\n<td>New secret</td>\n<td>Both secrets</td>\n<td>Allow in-flight completion</td>\n</tr>\n<tr>\n<td>Post-rotation</td>\n<td>Ongoing</td>\n<td>New secret</td>\n<td>New secret only</td>\n<td>Complete migration</td>\n</tr>\n</tbody></table>\n<p>The transition period length depends on the maximum retry window for webhook deliveries. Since failed deliveries may retry for several days with exponential backoff, the secret overlap must accommodate the longest possible retry scenario.</p>\n<h4 id=\"secret-generation-and-storage\">Secret Generation and Storage</h4>\n<p>Secret generation uses cryptographically secure random number generation to produce unpredictable keys resistant to brute-force attacks. The secret length (256 bits) provides sufficient entropy to prevent practical key guessing attacks while remaining manageable for storage and transmission.</p>\n<p>The secret storage mechanism protects keys at rest using envelope encryption, where secrets are encrypted with a master key that&#39;s managed separately from the application database. This approach provides defense in depth if the application database is compromised.</p>\n<table>\n<thead>\n<tr>\n<th>Secret Attribute</th>\n<th>Specification</th>\n<th>Purpose</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Length</td>\n<td>256 bits (32 bytes)</td>\n<td>Cryptographic strength against brute force</td>\n</tr>\n<tr>\n<td>Encoding</td>\n<td>Base64 URL-safe</td>\n<td>Safe transmission and storage</td>\n</tr>\n<tr>\n<td>Generation</td>\n<td>Cryptographic PRNG</td>\n<td>Unpredictable key material</td>\n</tr>\n<tr>\n<td>Storage</td>\n<td>Envelope encryption</td>\n<td>Protection at rest</td>\n</tr>\n<tr>\n<td>Rotation Frequency</td>\n<td>30-90 days</td>\n<td>Balance security and operational overhead</td>\n</tr>\n</tbody></table>\n<p>Secret versioning tracks multiple active secrets per webhook registration, enabling gradual migration and emergency rollback scenarios. The version metadata includes creation timestamp, activation timestamp, and planned expiration to support automated rotation management.</p>\n<p>The secret distribution mechanism ensures that all delivery workers have access to current secrets for signature generation. This typically involves a secure configuration service or encrypted configuration files that workers can access with appropriate authentication.</p>\n<h4 id=\"emergency-rotation-procedures\">Emergency Rotation Procedures</h4>\n<p>Emergency secret rotation handles compromise scenarios where secrets may have been exposed and require immediate replacement. The emergency procedure bypasses normal transition periods while maintaining delivery reliability for uncompromised endpoints.</p>\n<p>Emergency rotation triggers include suspected key exposure, security breach notifications, compliance requirements, or proactive security measures. The procedure generates new secrets immediately and notifies endpoint owners about the required configuration updates.</p>\n<table>\n<thead>\n<tr>\n<th>Emergency Scenario</th>\n<th>Trigger Condition</th>\n<th>Response Time</th>\n<th>Notification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Suspected Compromise</td>\n<td>Security incident report</td>\n<td>1 hour</td>\n<td>Immediate email + webhook</td>\n</tr>\n<tr>\n<td>Compliance Requirement</td>\n<td>Audit finding or policy change</td>\n<td>24 hours</td>\n<td>Email notification</td>\n</tr>\n<tr>\n<td>Proactive Rotation</td>\n<td>Scheduled security maintenance</td>\n<td>1 week</td>\n<td>Advance email notice</td>\n</tr>\n<tr>\n<td>Bulk Compromise</td>\n<td>System-wide security event</td>\n<td>30 minutes</td>\n<td>All notification channels</td>\n</tr>\n</tbody></table>\n<p>The emergency notification includes the new secret, implementation timeline, and verification instructions. Endpoint owners receive sample code for updating their signature verification logic and testing connectivity with the new credentials.</p>\n<h3 id=\"common-registry-pitfalls\">Common Registry Pitfalls</h3>\n<p>The webhook registry component involves complex security considerations that frequently lead to implementation mistakes. These pitfalls can create serious vulnerabilities or operational problems that affect the entire delivery system.</p>\n<h4 id=\"ssrf-attack-vectors\">SSRF Attack Vectors</h4>\n<p>⚠️ <strong>Pitfall: Incomplete Private IP Filtering</strong></p>\n<p>Many developers implement basic SSRF protection by blocking obvious private IP ranges like 127.0.0.1 and 192.168.x.x, but miss IPv6 private ranges, DNS rebinding attacks, and cloud metadata endpoints. Attackers can exploit these gaps to access internal services, cloud credentials, or other sensitive resources.</p>\n<p>The vulnerability occurs when URL validation only checks the initial hostname without following DNS resolution or considering all private address formats. For example, an attacker might register a webhook pointing to a domain that resolves to an internal IP address, bypassing hostname-based filtering.</p>\n<p><strong>How to prevent</strong>: Implement comprehensive IP filtering that includes all RFC 1918 IPv4 ranges, IPv6 private ranges (fc00::/7), loopback addresses, link-local addresses, and cloud metadata endpoints (169.254.169.254). Perform DNS resolution during validation and block any URLs that resolve to private addresses.</p>\n<p>⚠️ <strong>Pitfall: DNS Rebinding Bypass</strong></p>\n<p>Attackers can use DNS rebinding attacks where a domain initially resolves to a public IP address (passing validation) but later resolves to a private IP address (enabling internal network access). This time-of-check-time-of-use vulnerability bypasses validation that only occurs during registration.</p>\n<p><strong>How to prevent</strong>: Implement DNS resolution validation at delivery time, not just registration time. Use DNS caching with reasonable TTLs and re-validate IP addresses if DNS responses change unexpectedly. Consider using DNS-over-HTTPS or other secure DNS mechanisms to prevent DNS manipulation.</p>\n<p>⚠️ <strong>Pitfall: URL Redirect Chain Exploitation</strong></p>\n<p>HTTP redirects can bypass SSRF protection when the initial URL points to a public endpoint that redirects to a private address. Attackers register webhooks pointing to their controlled servers, which then redirect webhook requests to internal services.</p>\n<p><strong>How to prevent</strong>: Limit redirect following to a maximum of 3 hops and validate each destination in the redirect chain against SSRF filters. Consider disabling redirect following entirely for webhook deliveries if redirects aren&#39;t required for legitimate use cases.</p>\n<h4 id=\"weak-secret-generation\">Weak Secret Generation</h4>\n<p>⚠️ <strong>Pitfall: Predictable Secret Generation</strong></p>\n<p>Using weak random number generators or deterministic seed values creates predictable secrets that attackers can guess or reproduce. This completely undermines the security provided by HMAC signatures, allowing attackers to forge valid webhook signatures.</p>\n<p>Common mistakes include using time-based seeds, process IDs, or programming language default random number generators that aren&#39;t cryptographically secure. Predictable secrets enable signature forgery attacks where attackers can generate valid signatures for malicious payloads.</p>\n<p><strong>How to prevent</strong>: Use cryptographically secure random number generators provided by the operating system or cryptographic libraries. In Python, use <code>secrets.token_bytes()</code> or <code>os.urandom()</code>. Ensure sufficient entropy (256 bits minimum) and avoid any deterministic components in secret generation.</p>\n<p>⚠️ <strong>Pitfall: Secret Exposure in Logs</strong></p>\n<p>Webhook secrets may accidentally appear in application logs, error messages, or debug output, especially during development or troubleshooting. Secret exposure through logs creates a persistent security vulnerability that may not be detected for extended periods.</p>\n<p><strong>How to prevent</strong>: Implement secret redaction in logging systems that automatically masks or removes secret values from log output. Use structured logging that can identify and redact sensitive fields. Regularly audit logs for accidental secret exposure and implement log retention policies that limit exposure windows.</p>\n<h4 id=\"signature-verification-bypasses\">Signature Verification Bypasses</h4>\n<p>⚠️ <strong>Pitfall: Timing Attack Vulnerabilities</strong></p>\n<p>Naive string comparison for signature verification can leak information about correct signature bytes through timing differences, potentially enabling signature forgery through timing attacks. Standard string comparison functions return immediately upon finding the first differing character, creating measurable timing differences.</p>\n<p><strong>How to prevent</strong>: Use constant-time comparison functions provided by cryptographic libraries that always take the same amount of time regardless of input differences. In Python, use <code>hmac.compare_digest()</code>. Never use standard string comparison operators (==) for cryptographic verification.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Timestamp Validation</strong></p>\n<p>Weak timestamp validation enables replay attacks where captured webhook requests can be retransmitted outside the intended time window. Common mistakes include accepting timestamps too far in the future, using overly generous tolerance windows, or failing to validate timestamp format.</p>\n<p><strong>How to prevent</strong>: Implement strict timestamp validation with reasonable tolerance windows (5-15 minutes maximum). Reject requests with timestamps in the future beyond a small tolerance for clock skew. Validate timestamp format and reject malformed or non-numeric values. Include timestamps in signature calculation to prevent timestamp tampering.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Database</td>\n<td>SQLite with SQLAlchemy ORM</td>\n<td>PostgreSQL with connection pooling</td>\n</tr>\n<tr>\n<td>HTTP Client</td>\n<td>Python <code>requests</code> library</td>\n<td><code>httpx</code> with async support</td>\n</tr>\n<tr>\n<td>Cryptography</td>\n<td>Python <code>hmac</code> and <code>hashlib</code> standard library</td>\n<td><code>cryptography</code> library with hardware acceleration</td>\n</tr>\n<tr>\n<td>Secret Storage</td>\n<td>Environment variables</td>\n<td>HashiCorp Vault or AWS Secrets Manager</td>\n</tr>\n<tr>\n<td>URL Validation</td>\n<td><code>urllib.parse</code> with custom validation</td>\n<td><code>validators</code> library with comprehensive checks</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n├── src/\n│   ├── webhook_registry/\n│   │   ├── __init__.py\n│   │   ├── registry.py              ← Main registration logic\n│   │   ├── verification.py          ← Challenge-response verification\n│   │   ├── signature.py             ← HMAC signature generation\n│   │   ├── validation.py            ← URL and SSRF validation\n│   │   └── models.py                ← Database models\n│   ├── common/\n│   │   ├── database.py              ← Database connection management\n│   │   ├── http_client.py           ← HTTP client utilities\n│   │   └── security.py              ← Cryptographic utilities\n│   └── config/\n│       └── webhook_config.py        ← Configuration management\n├── tests/\n│   ├── test_registry.py\n│   ├── test_verification.py\n│   └── test_signature.py\n└── requirements.txt</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Database Models (complete implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Column, String, Boolean, DateTime, Integer, </span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, Text</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.ext.declarative </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> declarative_base</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sqlalchemy.sql </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> func</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">Base </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> declarative_base()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookRegistration</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Base</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Webhook endpoint registration with signature verification and circuit breaker state.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __tablename__ </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'webhook_registrations'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    id</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Column(String, </span><span style=\"color:#FFAB70\">primary_key</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"wh_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">uuid.uuid4().hex</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    secret </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Base64-encoded signing secret</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)    </span><span style=\"color:#6A737D\"># List of subscribed event types</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    verified </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Boolean, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    updated_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow, </span><span style=\"color:#FFAB70\">onupdate</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    active </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Boolean, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failure_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'closed'</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># closed, open, half-open</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_success_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_rpm </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(</span><span style=\"color:#79B8FF\">JSON</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __repr__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"&#x3C;WebhookRegistration(id='</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">', url='</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.url</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">', verified=</span><span style=\"color:#79B8FF\">{self</span><span style=\"color:#E1E4E8\">.verified</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">)>\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookSecret</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Base</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Stores multiple active secrets per webhook for rotation support.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    __tablename__ </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> 'webhook_secrets'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    id</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> Column(String, </span><span style=\"color:#FFAB70\">primary_key</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=lambda</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"secret_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">uuid.uuid4().hex</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(String, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    secret_value </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Text, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Encrypted secret</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    created_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">datetime.utcnow)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    activated_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expires_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(DateTime)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    is_active </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Boolean, </span><span style=\"color:#FFAB70\">default</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    version </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Column(Integer, </span><span style=\"color:#FFAB70\">nullable</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n<p><strong>HTTP Client Utilities (complete implementation):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> httpx</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ssl</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> urllib.parse </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> urlparse</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ipaddress</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> socket</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HTTPResponse</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"HTTP response with timing and error information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status_code: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    headers: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    body: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookHTTPClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"HTTP client with SSRF protection and timeout handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timeout</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> httpx.Client(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">httpx.Timeout(timeout),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            follow_redirects</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_redirects</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">3</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            verify</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#6A737D\">  # Enforce SSL verification</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __enter__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __exit__</span><span style=\"color:#E1E4E8\">(self, exc_type, exc_val, exc_tb):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.close()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_url_security</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate URL against SSRF attacks and security policies.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            parsed </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> urlparse(url)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Only allow HTTPS</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> parsed.scheme </span><span style=\"color:#F97583\">!=</span><span style=\"color:#9ECBFF\"> 'https'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Only allow standard HTTPS ports</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#E1E4E8\"> parsed.port </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> parsed.port </span><span style=\"color:#F97583\">not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">443</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">8443</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Resolve hostname and check IP</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            hostname </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> parsed.hostname</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> hostname:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Get IP addresses for hostname</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                addrs </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> socket.getaddrinfo(hostname, parsed.port </span><span style=\"color:#F97583\">or</span><span style=\"color:#79B8FF\"> 443</span><span style=\"color:#E1E4E8\">, socket.</span><span style=\"color:#79B8FF\">AF_UNSPEC</span><span style=\"color:#E1E4E8\">, socket.</span><span style=\"color:#79B8FF\">SOCK_STREAM</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> addr </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> addrs:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    ip </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ipaddress.ip_address(addr[</span><span style=\"color:#79B8FF\">4</span><span style=\"color:#E1E4E8\">][</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#E1E4E8\"> ip.is_private </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> ip.is_loopback </span><span style=\"color:#F97583\">or</span><span style=\"color:#E1E4E8\"> ip.is_link_local:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                    # Block cloud metadata endpoints</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    if</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(ip) </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> '169.254.169.254'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#E1E4E8\"> (socket.gaierror, </span><span style=\"color:#79B8FF\">ValueError</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> post_json</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: Dict, headers: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> HTTPResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Send JSON POST request with comprehensive error handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate_url_security(url):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"URL failed security validation\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Implementation continues with actual HTTP request...</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Complete implementation based on requirements</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton\">Core Logic Skeleton</h4>\n<p><strong>Webhook Registration (main implementation target):</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hmac</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> secrets</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for webhook system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    database_url: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    redis_url: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    delivery_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_retry_attempts: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_breaker_failure_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_rpm: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp_tolerance: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 300</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookRegistry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages webhook endpoint registration and verification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: WebhookConfig, db_manager, http_client):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> db_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.http </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> http_client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> register_webhook</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, events: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], metadata: Optional[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Register a new webhook endpoint with ownership verification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Dict with registration_id, challenge_token, and verification_url</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate URL format and basic security checks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if webhook URL is already registered</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate cryptographically secure secret using generate_webhook_secret()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create webhook registration record in database (unverified state)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate challenge token for ownership verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Send challenge request to webhook URL using verify_webhook_ownership()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return registration details with verification instructions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Set verified=False initially, only mark True after challenge success</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> verify_webhook_ownership</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Send challenge request to verify endpoint ownership.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            bool indicating if ownership verification succeeded</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve webhook registration from database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate time-limited challenge token (60 second expiry)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Create challenge payload with token, webhook_url, event_types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Send HTTP POST to webhook URL with challenge payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate response contains correct challenge token within time limit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update webhook registration to verified=True if challenge succeeds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return verification success/failure status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Challenge should include timestamp to prevent replay</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_webhook_secret</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate cryptographically secure signing secret.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Base64-encoded secret suitable for HMAC signing</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate 32 bytes of cryptographically secure random data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Encode as URL-safe base64 string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return encoded secret for storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use secrets.token_bytes() for cryptographic randomness</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_hmac_signature</span><span style=\"color:#E1E4E8\">(self, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, secret: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, timestamp: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                              webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, delivery_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, event_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate HMAC-SHA256 signature for webhook payload.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Args:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            payload: JSON string of webhook payload</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            secret: Base64-encoded webhook secret</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            timestamp: Unix timestamp for replay protection</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            webhook_id: Webhook registration identifier</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            delivery_id: Unique delivery attempt identifier</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            event_type: Event type string (e.g., 'user.created')</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Hex-encoded HMAC signature for X-Webhook-Signature-256 header</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Decode base64 secret to bytes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create canonical signing string with format:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #         {timestamp}\\n{webhook_id}\\n{delivery_id}\\n{event_type}\\n{payload}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compute HMAC-SHA256 of canonical string using decoded secret</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return hex-encoded signature</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use hmac.new() with hashlib.sha256 and consistent string encoding</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> rotate_webhook_secret</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Rotate webhook secret with overlapping validity period.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            Dict with new_secret, old_secret_expiry, and transition details</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve current webhook registration and active secret</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate new secret using generate_webhook_secret()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store new secret with current timestamp as activated_at</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Set expiry for old secret (7-14 days from now)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update webhook registration with new primary secret</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return rotation details for endpoint owner notification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Keep old secret valid during transition to handle in-flight deliveries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Constants referenced in implementation</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">DELIVERY_TIMEOUT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">MAX_RETRY_ATTEMPTS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">CIRCUIT_BREAKER_FAILURE_THRESHOLD</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">RATE_LIMIT_RPM</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">TIMESTAMP_TOLERANCE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 300</span></span></code></pre></div>\n\n<h4 id=\"language-specific-hints\">Language-Specific Hints</h4>\n<p><strong>Python Security Best Practices:</strong></p>\n<ul>\n<li>Use <code>secrets.token_bytes(32)</code> for generating webhook secrets, never <code>random</code></li>\n<li>Use <code>hmac.compare_digest()</code> for signature verification to prevent timing attacks</li>\n<li>Use <code>base64.urlsafe_b64encode()</code> for secret encoding to avoid URL encoding issues</li>\n<li>Validate all inputs with type hints and runtime validation (consider <code>pydantic</code>)</li>\n<li>Use <code>sqlalchemy.text()</code> for raw SQL to prevent injection attacks in complex queries</li>\n</ul>\n<p><strong>Database Connection Management:</strong></p>\n<ul>\n<li>Use SQLAlchemy connection pooling with <code>pool_pre_ping=True</code> for connection health</li>\n<li>Implement database transactions for multi-step operations (register + verify)</li>\n<li>Use <code>session.merge()</code> for upsert operations during secret rotation</li>\n<li>Set reasonable connection timeouts (<code>pool_timeout=30</code>)</li>\n</ul>\n<p><strong>HTTP Client Configuration:</strong></p>\n<ul>\n<li>Set <code>verify=True</code> for SSL certificate verification - never disable in production</li>\n<li>Use connection pooling with <code>httpx.Client()</code> for better performance</li>\n<li>Implement request timeout that&#39;s shorter than overall delivery timeout</li>\n<li>Configure retry logic only for network errors, not HTTP status errors</li>\n</ul>\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing the webhook registry component, verify functionality:</p>\n<p><strong>Registration Test:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> http://localhost:8000/webhooks/register</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{\"url\": \"https://myapp.example.com/webhooks\", \"events\": [\"user.created\"]}'</span></span></code></pre></div>\n\n<p><strong>Expected Response:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">json</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#E1E4E8\">{</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"webhook_id\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"wh_7f3e8d9a2b1c4e6f\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"challenge_token\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"chg_a1b2c3d4e5f6\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"verification_url\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"https://webhook-service.com/verify/wh_7f3e8d9a2b1c4e6f\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  \"status\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"pending_verification\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">}</span></span></code></pre></div>\n\n<p><strong>Verification Indicators:</strong></p>\n<ul>\n<li>Challenge request sent to webhook URL within 5 seconds</li>\n<li>Challenge payload includes correct token and metadata</li>\n<li>Database record created with <code>verified=False</code> initially</li>\n<li>Secret generated with proper entropy (32 bytes, base64 encoded)</li>\n<li>URL validation rejects private IPs and non-HTTPS schemes</li>\n</ul>\n<p><strong>Common Issues:</strong></p>\n<ul>\n<li><strong>No challenge request sent</strong>: Check URL validation logic and HTTP client configuration</li>\n<li><strong>Challenge request fails</strong>: Verify SSRF protection isn&#39;t blocking legitimate URLs</li>\n<li><strong>Database errors</strong>: Ensure proper connection pooling and transaction handling</li>\n<li><strong>Weak secret generation</strong>: Confirm using <code>secrets</code> module, not <code>random</code></li>\n</ul>\n<h2 id=\"delivery-engine-component\">Delivery Engine Component</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 2 (Delivery Queue &amp; Retry Logic) - implements reliable webhook delivery with exponential backoff, timeout handling, and dead letter queue management</p>\n</blockquote>\n<h3 id=\"mental-model-the-smart-package-delivery-service\">Mental Model: The Smart Package Delivery Service</h3>\n<p>Think of the <strong>delivery engine</strong> as a sophisticated package delivery service that never gives up on deliveries. When a package (webhook event) arrives at the sorting facility, it gets labeled with a destination address (webhook endpoint) and placed in the appropriate delivery truck queue. If the first delivery attempt fails because nobody&#39;s home (endpoint is down), the delivery driver doesn&#39;t just abandon the package. Instead, they follow a systematic retry schedule: try again in 2 minutes, then 4 minutes, then 8 minutes, with each delay getting progressively longer to avoid overwhelming the recipient.</p>\n<p>The delivery service has smart routing logic - if a package can&#39;t be delivered because the address is wrong (4xx HTTP error), they don&#39;t keep trying. But if the recipient&#39;s mailbox is full (5xx error), they know this is temporary and worth retrying. After exhausting all retry attempts, packages that still can&#39;t be delivered go to a special &quot;undeliverable mail&quot; facility (dead letter queue) where postal workers can manually investigate what went wrong.</p>\n<p>Just like a real postal service maintains delivery records, our engine tracks every delivery attempt, recording when it was tried, what response was received, and how long it took. This audit trail becomes invaluable for debugging delivery issues and understanding endpoint reliability patterns.</p>\n<h3 id=\"queue-management-and-ordering\">Queue Management and Ordering</h3>\n<p>The <strong>queue management system</strong> serves as the backbone of reliable webhook delivery, ensuring that events reach their destinations in the correct order while providing persistence guarantees against system failures. Unlike simple in-memory queues that lose data during crashes, our queue system uses persistent message queues that survive restarts and maintain delivery contracts.</p>\n<p>The fundamental principle behind our queue architecture is <strong>per-endpoint ordering guarantees</strong>. This means that all events destined for a specific webhook endpoint are processed sequentially, preventing race conditions where a &quot;user deleted&quot; event might be delivered before the preceding &quot;user created&quot; event. However, events for different endpoints can be processed in parallel, maximizing throughput while preserving semantic ordering where it matters.</p>\n<blockquote>\n<p><strong>Decision: Per-Endpoint Queue Partitioning</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook events must maintain causal ordering per endpoint while maximizing parallel processing across different endpoints</li>\n<li><strong>Options Considered</strong>: Single global queue, per-event-type queues, per-endpoint queues</li>\n<li><strong>Decision</strong>: Implement per-endpoint queue partitioning with parallel workers</li>\n<li><strong>Rationale</strong>: Prevents ordering violations within endpoint event streams while enabling horizontal scaling across endpoints</li>\n<li><strong>Consequences</strong>: Requires queue routing logic but guarantees semantic consistency and enables independent endpoint processing rates</li>\n</ul>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Queue Architecture Option</th>\n<th>Pros</th>\n<th>Cons</th>\n<th>Chosen?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Single Global FIFO Queue</td>\n<td>Simple implementation, guaranteed global ordering</td>\n<td>Head-of-line blocking, no parallelization</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Per-Event-Type Queues</td>\n<td>Parallel processing by event type, simple routing</td>\n<td>No ordering guarantees per endpoint</td>\n<td>❌</td>\n</tr>\n<tr>\n<td>Per-Endpoint Queues</td>\n<td>Ordering per endpoint, parallel processing, endpoint-specific backpressure</td>\n<td>Complex routing, queue proliferation</td>\n<td>✅</td>\n</tr>\n</tbody></table>\n<p>The queue implementation leverages <strong>Redis Streams</strong> for persistence and ordering, with each webhook endpoint getting its own stream identified by <code>webhook:{webhook_id}:events</code>. This design provides several critical capabilities:</p>\n<ol>\n<li><strong>Persistent Storage</strong>: Events survive system restarts and worker crashes</li>\n<li><strong>Consumer Groups</strong>: Multiple worker instances can process different endpoints simultaneously</li>\n<li><strong>Acknowledgment Tracking</strong>: Events remain in the queue until successfully processed</li>\n<li><strong>Failure Recovery</strong>: Unacknowledged events can be reclaimed and retried</li>\n</ol>\n<p>The queue entry format captures all information needed for delivery attempts and retry logic:</p>\n<table>\n<thead>\n<tr>\n<th>Queue Entry Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>event_id</code></td>\n<td>string</td>\n<td>Unique identifier linking to stored event</td>\n</tr>\n<tr>\n<td><code>webhook_id</code></td>\n<td>string</td>\n<td>Target endpoint identifier</td>\n</tr>\n<tr>\n<td><code>attempt_count</code></td>\n<td>integer</td>\n<td>Number of delivery attempts made</td>\n</tr>\n<tr>\n<td><code>next_attempt_at</code></td>\n<td>timestamp</td>\n<td>Scheduled time for next delivery attempt</td>\n</tr>\n<tr>\n<td><code>payload_hash</code></td>\n<td>string</td>\n<td>SHA-256 hash for integrity verification</td>\n</tr>\n<tr>\n<td><code>priority</code></td>\n<td>integer</td>\n<td>Delivery priority (0=highest, 9=lowest)</td>\n</tr>\n<tr>\n<td><code>expires_at</code></td>\n<td>timestamp</td>\n<td>Event expiration time after which delivery stops</td>\n</tr>\n<tr>\n<td><code>metadata</code></td>\n<td>json</td>\n<td>Additional context for debugging and routing</td>\n</tr>\n</tbody></table>\n<p><strong>Queue consumption</strong> follows a pull-based model where worker processes continuously poll their assigned queues for ready events. The polling mechanism implements exponential backoff when queues are empty to reduce Redis load while maintaining low latency for new events:</p>\n<ol>\n<li>Worker queries Redis Stream for events with <code>next_attempt_at &lt;= current_time</code></li>\n<li>If events are found, worker claims them using Redis consumer groups</li>\n<li>For each claimed event, worker retrieves full event details from primary storage</li>\n<li>Worker attempts delivery and updates attempt tracking</li>\n<li>On success, worker acknowledges the message, removing it from the queue</li>\n<li>On failure, worker reschedules the event with calculated backoff delay</li>\n</ol>\n<p>The queue management system handles <strong>backpressure</strong> gracefully when downstream endpoints become overwhelmed. Rather than dropping events or crashing workers, the system implements several pressure relief mechanisms:</p>\n<ul>\n<li><strong>Queue Length Monitoring</strong>: When per-endpoint queues exceed configurable thresholds, the system triggers alerts and may pause new event ingestion for that endpoint</li>\n<li><strong>Worker Rate Limiting</strong>: Each worker respects per-endpoint rate limits, slowing consumption when delivery rates exceed configured maximums</li>\n<li><strong>Circuit Breaker Integration</strong>: When circuit breakers open for failing endpoints, their queues pause consumption until the breaker transitions to half-open state</li>\n</ul>\n<blockquote>\n<p>The queue management system&#39;s most critical responsibility is maintaining the durability contract. Once an event enters a queue, the system guarantees it will either be successfully delivered or explicitly moved to a dead letter queue after exhausting all retry attempts. This guarantee holds even across system restarts, worker crashes, and Redis failovers.</p>\n</blockquote>\n<h3 id=\"exponential-backoff-retry-logic\">Exponential Backoff Retry Logic</h3>\n<p>The <strong>exponential backoff retry system</strong> implements intelligent retry scheduling that balances rapid recovery for transient failures with respectful backing off for persistent issues. Unlike naive retry approaches that hammer failing endpoints with repeated requests, exponential backoff progressively increases delays between attempts, giving downstream systems time to recover while preventing thundering herd scenarios.</p>\n<p>The mathematical foundation of exponential backoff follows the formula: <code>delay = base_delay * (2 ^ attempt_number) + jitter</code>, where jitter introduces randomization to prevent synchronized retry storms when multiple events fail simultaneously. Our implementation uses a base delay of 30 seconds and caps maximum delays at 1 hour to prevent indefinite postponement of retry attempts.</p>\n<table>\n<thead>\n<tr>\n<th>Attempt Number</th>\n<th>Base Delay (seconds)</th>\n<th>Max Delay (seconds)</th>\n<th>Jitter Range (seconds)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>30</td>\n<td>30</td>\n<td>0-15</td>\n</tr>\n<tr>\n<td>2</td>\n<td>60</td>\n<td>60</td>\n<td>0-30</td>\n</tr>\n<tr>\n<td>3</td>\n<td>120</td>\n<td>120</td>\n<td>0-60</td>\n</tr>\n<tr>\n<td>4</td>\n<td>240</td>\n<td>240</td>\n<td>0-120</td>\n</tr>\n<tr>\n<td>5</td>\n<td>480</td>\n<td>480</td>\n<td>0-240</td>\n</tr>\n<tr>\n<td>6+</td>\n<td>3600</td>\n<td>3600</td>\n<td>0-1800</td>\n</tr>\n</tbody></table>\n<p>The retry decision logic incorporates <strong>HTTP status code analysis</strong> to distinguish between retryable and non-retryable failures. This classification prevents wasted retry attempts on permanent failures while ensuring transient issues get appropriate retry treatment:</p>\n<table>\n<thead>\n<tr>\n<th>Status Code Range</th>\n<th>Retry Decision</th>\n<th>Rationale</th>\n<th>Examples</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2xx</td>\n<td>Success - No Retry</td>\n<td>Request succeeded</td>\n<td>200 OK, 201 Created</td>\n</tr>\n<tr>\n<td>3xx</td>\n<td>No Retry</td>\n<td>Redirect handling should be automatic</td>\n<td>301, 302, 307</td>\n</tr>\n<tr>\n<td>4xx (except 429)</td>\n<td>No Retry</td>\n<td>Client error - request is malformed</td>\n<td>400 Bad Request, 401 Unauthorized, 404 Not Found</td>\n</tr>\n<tr>\n<td>429</td>\n<td>Retry with Rate Limit</td>\n<td>Rate limited - respect Retry-After header</td>\n<td>429 Too Many Requests</td>\n</tr>\n<tr>\n<td>5xx</td>\n<td>Retry</td>\n<td>Server error - likely transient</td>\n<td>500 Internal Server Error, 502 Bad Gateway</td>\n</tr>\n<tr>\n<td>Timeout/Network</td>\n<td>Retry</td>\n<td>Infrastructure issue - likely transient</td>\n<td>Connection timeout, DNS failure</td>\n</tr>\n</tbody></table>\n<p>The retry logic integrates closely with the circuit breaker system to prevent futile retry attempts against consistently failing endpoints. When a circuit breaker opens for an endpoint, pending retries for that endpoint are either paused (if the circuit might recover soon) or moved directly to the dead letter queue (if the failure pattern suggests permanent issues).</p>\n<blockquote>\n<p><strong>Decision: Status-Based Retry Classification</strong></p>\n<ul>\n<li><strong>Context</strong>: Not all HTTP failures should trigger retry attempts - some indicate permanent client errors</li>\n<li><strong>Options Considered</strong>: Retry all failures, retry only 5xx errors, configurable retry status codes</li>\n<li><strong>Decision</strong>: Built-in classification with special handling for 429 rate limiting</li>\n<li><strong>Rationale</strong>: Prevents wasted resources on non-retryable errors while handling rate limiting gracefully</li>\n<li><strong>Consequences</strong>: Reduces load on failing endpoints but requires careful status code interpretation</li>\n</ul>\n</blockquote>\n<p><strong>Jitter implementation</strong> uses cryptographically secure random number generation to ensure even distribution across the jitter range. The specific jitter algorithm is <code>uniform_random(0, delay / 2)</code>, which provides sufficient randomization without excessively delaying retries. This approach prevents the thundering herd problem where many failed webhook deliveries might all retry at exactly the same time after a downstream service recovers.</p>\n<p>The retry scheduling process follows these detailed steps:</p>\n<ol>\n<li><strong>Failure Detection</strong>: Delivery attempt completes with non-2xx status or network error</li>\n<li><strong>Status Code Analysis</strong>: Classify failure as retryable or non-retryable using status code rules</li>\n<li><strong>Attempt Count Check</strong>: Verify current attempt count is below <code>MAX_RETRY_ATTEMPTS</code> threshold</li>\n<li><strong>Circuit Breaker Check</strong>: Confirm endpoint circuit breaker is not in open state</li>\n<li><strong>Delay Calculation</strong>: Compute exponential backoff delay with jitter for next attempt</li>\n<li><strong>Queue Rescheduling</strong>: Update queue entry with new <code>next_attempt_at</code> timestamp</li>\n<li><strong>Attempt Logging</strong>: Record failure details and calculated retry delay in delivery log</li>\n</ol>\n<p><strong>Retry-After header handling</strong> provides special logic for 429 rate limiting responses. When an endpoint returns 429 with a Retry-After header, our system respects the server&#39;s guidance rather than using exponential backoff. The retry delay becomes <code>max(retry_after_seconds, exponential_backoff_delay)</code> to ensure we never retry more aggressively than the server requests.</p>\n<p>The retry system maintains <strong>attempt state persistence</strong> across worker restarts and system failures. All retry scheduling information is stored in Redis alongside the queue entries, ensuring that partially-processed events resume with correct attempt counts and delay calculations after system recovery.</p>\n<h3 id=\"dead-letter-queue-handling\">Dead Letter Queue Handling</h3>\n<p>The <strong>dead letter queue (DLQ)</strong> serves as the final repository for webhook events that cannot be delivered despite exhaustive retry attempts. Unlike simply discarding failed events, the DLQ preserves them for manual investigation, debugging, and potential replay once underlying issues are resolved. This design maintains the system&#39;s durability guarantees while preventing infinite retry loops that could exhaust system resources.</p>\n<p>Events transition to the dead letter queue under several specific conditions, each indicating a different type of permanent delivery failure:</p>\n<table>\n<thead>\n<tr>\n<th>DLQ Trigger Condition</th>\n<th>Description</th>\n<th>Next Steps</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Max Retry Attempts Exceeded</td>\n<td>Event failed delivery after <code>MAX_RETRY_ATTEMPTS</code> attempts</td>\n<td>Manual investigation, potential replay</td>\n</tr>\n<tr>\n<td>Circuit Breaker Permanent Failure</td>\n<td>Endpoint circuit breaker indicates permanent failure</td>\n<td>Endpoint owner notification, webhook disabling</td>\n</tr>\n<tr>\n<td>Event Expiration</td>\n<td>Event exceeded <code>expires_at</code> timestamp</td>\n<td>Event discarded, no recovery possible</td>\n</tr>\n<tr>\n<td>Malformed Event Data</td>\n<td>Event payload corruption or signature mismatch</td>\n<td>Data integrity investigation</td>\n</tr>\n<tr>\n<td>Webhook Deletion</td>\n<td>Target webhook was deleted during retry processing</td>\n<td>Event discarded, cleanup required</td>\n</tr>\n</tbody></table>\n<p>The dead letter queue implementation uses a separate Redis Stream (<code>dlq:events</code>) with enhanced metadata to support manual intervention workflows. Each DLQ entry preserves the complete event history along with diagnostic information:</p>\n<table>\n<thead>\n<tr>\n<th>DLQ Entry Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>original_event_id</code></td>\n<td>string</td>\n<td>Reference to original webhook event</td>\n</tr>\n<tr>\n<td><code>webhook_id</code></td>\n<td>string</td>\n<td>Target endpoint (may no longer exist)</td>\n</tr>\n<tr>\n<td><code>failure_reason</code></td>\n<td>string</td>\n<td>Enumerated reason for DLQ placement</td>\n</tr>\n<tr>\n<td><code>attempt_history</code></td>\n<td>json</td>\n<td>Complete list of all delivery attempts</td>\n</tr>\n<tr>\n<td><code>final_error</code></td>\n<td>string</td>\n<td>Last error message from final delivery attempt</td>\n</tr>\n<tr>\n<td><code>dlq_timestamp</code></td>\n<td>timestamp</td>\n<td>When event was moved to DLQ</td>\n</tr>\n<tr>\n<td><code>investigation_status</code></td>\n<td>string</td>\n<td>Manual review status (pending, investigating, resolved)</td>\n</tr>\n<tr>\n<td><code>replay_eligible</code></td>\n<td>boolean</td>\n<td>Whether event can be safely replayed</td>\n</tr>\n</tbody></table>\n<p><strong>DLQ monitoring and alerting</strong> systems continuously track dead letter queue growth patterns and trigger notifications when intervention is needed. The monitoring system distinguishes between expected DLQ activity (occasional failed events from flaky endpoints) and concerning patterns (sudden spikes indicating systemic issues):</p>\n<ol>\n<li><strong>Volume Alerts</strong>: Trigger when DLQ receives more than X events per hour for any single webhook</li>\n<li><strong>Pattern Alerts</strong>: Detect when multiple webhooks start failing simultaneously (indicating infrastructure issues)</li>\n<li><strong>Staleness Alerts</strong>: Flag DLQ events that remain in &quot;pending investigation&quot; status beyond configured thresholds</li>\n<li><strong>Capacity Alerts</strong>: Warn when DLQ storage approaches configured retention limits</li>\n</ol>\n<p>The dead letter queue supports several <strong>manual intervention workflows</strong> to handle different types of delivery failures:</p>\n<p><strong>Replay Workflow</strong>: For events that failed due to temporary endpoint issues, operators can trigger replay once the underlying problem is resolved. The replay process creates new delivery attempts with fresh attempt counters while preserving original event timestamps and signatures.</p>\n<p><strong>Batch Analysis Workflow</strong>: When multiple events fail with similar error patterns, operators can export DLQ entries for batch analysis. This workflow helps identify common failure causes like endpoint URL changes, authentication issues, or payload format problems.</p>\n<p><strong>Webhook Health Assessment</strong>: The DLQ serves as a data source for evaluating webhook endpoint reliability. Endpoints with high DLQ rates may need owner notification, rate limiting adjustments, or removal from the system.</p>\n<blockquote>\n<p><strong>Decision: Structured DLQ with Manual Intervention Support</strong></p>\n<ul>\n<li><strong>Context</strong>: Failed webhook events need preservation for debugging while preventing infinite retry resource consumption</li>\n<li><strong>Options Considered</strong>: Simple discard after max retries, basic DLQ storage, structured DLQ with workflows</li>\n<li><strong>Decision</strong>: Implement structured dead letter queue with manual intervention and replay capabilities</li>\n<li><strong>Rationale</strong>: Maintains durability guarantees while providing operational tools for failure resolution</li>\n<li><strong>Consequences</strong>: Requires additional storage and operational procedures but prevents data loss and enables failure analysis</li>\n</ul>\n</blockquote>\n<p><strong>DLQ retention policies</strong> balance storage costs with debugging needs. Events remain in the DLQ for 30 days by default, with automatic archival to cold storage for compliance requirements. During the retention period, all DLQ entries remain available for analysis and replay.</p>\n<p>The DLQ cleanup process runs daily to remove expired entries and archive events marked as &quot;resolved&quot; by operators. This process maintains DLQ performance while preserving audit trails for compliance and debugging purposes.</p>\n<p><strong>Replay safety mechanisms</strong> prevent duplicate deliveries when events are replayed from the DLQ. Each replay creates a new <code>delivery_id</code> while preserving the original <code>event_id</code> and <code>idempotency_key</code>. Receiving endpoints can use these identifiers to detect and safely ignore duplicate deliveries from replay operations.</p>\n<h3 id=\"common-delivery-pitfalls\">Common Delivery Pitfalls</h3>\n<p>Understanding and avoiding common delivery implementation mistakes is crucial for building a reliable webhook system. These pitfalls represent real-world issues that can lead to poor endpoint relationships, resource exhaustion, and data loss.</p>\n<p>⚠️ <strong>Pitfall: Thundering Herd on Endpoint Recovery</strong></p>\n<p>When a popular endpoint goes down and many webhook events start failing, naive retry implementations will schedule all retry attempts for the exact same time using simple exponential backoff. When the endpoint recovers, it gets hit with hundreds or thousands of simultaneous retry requests, immediately overwhelming it again.</p>\n<p><strong>Why it&#39;s wrong</strong>: Synchronized retries create artificial load spikes that can crash recovered endpoints, creating a cycle of failure and recovery that never stabilizes.</p>\n<p><strong>How to fix</strong>: Implement jitter in retry delays by adding random variation (<code>delay + random(0, delay/2)</code>). This spreads retry attempts across a time window, giving recovered endpoints a chance to handle the retry load gradually.</p>\n<p>⚠️ <strong>Pitfall: Retrying Non-Retryable Errors</strong></p>\n<p>A common mistake is implementing blanket retry logic that attempts to redeliver events regardless of the HTTP status code received. This leads to wasted resources trying to retry 400 Bad Request or 404 Not Found errors that will never succeed.</p>\n<p><strong>Why it&#39;s wrong</strong>: Retrying permanent client errors (4xx codes) wastes system resources and creates unnecessary load on endpoints that are correctly rejecting malformed requests.</p>\n<p><strong>How to fix</strong>: Implement status code classification that only retries 5xx server errors, network timeouts, and 429 rate limiting responses. Treat 4xx errors (except 429) as permanent failures that should go directly to the dead letter queue.</p>\n<p>⚠️ <strong>Pitfall: Unbounded Queue Growth</strong></p>\n<p>Without proper backpressure handling, delivery queues can grow indefinitely when endpoint failures outpace retry processing. This eventually leads to memory exhaustion and system crashes, ironically making delivery problems worse.</p>\n<p><strong>Why it&#39;s wrong</strong>: Unbounded queues hide delivery problems until system resources are exhausted, creating catastrophic failures that affect all endpoints, not just the failing ones.</p>\n<p><strong>How to fix</strong>: Implement queue length monitoring with configurable limits. When queues exceed thresholds, trigger alerts, pause new event ingestion for that endpoint, and consider emergency DLQ promotion for oldest events.</p>\n<p>⚠️ <strong>Pitfall: Losing Event Ordering During Parallel Retries</strong></p>\n<p>When implementing parallel processing for better performance, it&#39;s tempting to allow multiple workers to process events for the same endpoint simultaneously. This breaks ordering guarantees and can lead to events being delivered out of sequence.</p>\n<p><strong>Why it&#39;s wrong</strong>: Out-of-order delivery violates the semantic contracts that webhook consumers depend on, potentially causing data corruption in downstream systems.</p>\n<p><strong>How to fix</strong>: Implement per-endpoint queue partitioning where each endpoint&#39;s events are processed by exactly one worker at a time. Use Redis consumer groups or similar mechanisms to ensure exclusive processing per endpoint.</p>\n<p>⚠️ <strong>Pitfall: Ignoring Retry-After Headers</strong></p>\n<p>When endpoints return 429 rate limiting responses with Retry-After headers, naive implementations ignore this guidance and continue using exponential backoff delays, often retrying much more aggressively than the endpoint can handle.</p>\n<p><strong>Why it&#39;s wrong</strong>: Ignoring explicit rate limiting guidance from endpoints demonstrates poor API citizenship and can lead to endpoint operators blocking webhook deliveries entirely.</p>\n<p><strong>How to fix</strong>: Always respect Retry-After headers when present, using <code>max(retry_after_seconds, exponential_backoff_delay)</code> to ensure you never retry more aggressively than the endpoint requests.</p>\n<p>⚠️ <strong>Pitfall: Circuit Breaker State Race Conditions</strong></p>\n<p>In multi-worker environments, race conditions in circuit breaker state updates can lead to inconsistent behavior where some workers continue attempting deliveries to endpoints that other workers have marked as failed.</p>\n<p><strong>Why it&#39;s wrong</strong>: Inconsistent circuit breaker state defeats the protection mechanism, allowing continued load on failing endpoints and wasting retry attempts.</p>\n<p><strong>How to fix</strong>: Use atomic operations for circuit breaker state transitions and ensure all workers check current circuit breaker state before attempting deliveries. Consider using Redis for shared circuit breaker state across worker instances.</p>\n<p>⚠️ <strong>Pitfall: Event Payload Mutations During Retries</strong></p>\n<p>When retry logic reconstructs HTTP requests from stored event data, timestamp headers or signature calculations might be regenerated, creating different payloads for retry attempts than the original delivery.</p>\n<p><strong>Why it&#39;s wrong</strong>: Changing event payloads between delivery attempts violates idempotency expectations and can confuse endpoint validation logic that expects consistent payloads.</p>\n<p><strong>How to fix</strong>: Store complete HTTP request details (headers, payload, signature) with each event and replay them identically for all delivery attempts. Only update attempt-specific metadata like delivery attempt counts.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides practical implementation patterns and starter code for building the delivery engine component. The implementation uses Python with Celery for task processing, Redis for queuing, and comprehensive error handling.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Task Queue</td>\n<td>Celery with Redis backend</td>\n<td>Apache Kafka with consumer groups</td>\n</tr>\n<tr>\n<td>HTTP Client</td>\n<td><code>requests</code> with timeout configuration</td>\n<td><code>aiohttp</code> with connection pooling</td>\n</tr>\n<tr>\n<td>Retry Logic</td>\n<td>Built-in exponential backoff with jitter</td>\n<td>Custom retry with circuit breaker integration</td>\n</tr>\n<tr>\n<td>Dead Letter Storage</td>\n<td>Redis Lists with TTL</td>\n<td>Dedicated database table with indexes</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Basic logging with structured messages</td>\n<td>Prometheus metrics with Grafana dashboards</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook_system/\n├── delivery_engine/\n│   ├── __init__.py\n│   ├── queue_manager.py           # Queue operations and partitioning\n│   ├── delivery_worker.py         # Core delivery logic\n│   ├── retry_handler.py           # Exponential backoff and retry decisions\n│   ├── dead_letter_handler.py     # DLQ management and replay\n│   ├── http_client.py             # Webhook HTTP delivery client\n│   └── models.py                  # DeliveryAttempt and related models\n├── config/\n│   └── delivery_config.py         # Configuration constants and settings\n└── tests/\n    └── test_delivery_engine.py    # Comprehensive delivery tests</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Queue Manager Implementation</strong> (Complete, ready to use):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timezone</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, asdict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueueEntry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    attempt_count: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    next_attempt_at: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    payload_hash: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    priority: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expires_at: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Dict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueueManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages per-endpoint webhook delivery queues with Redis Streams.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_client: redis.Redis, config: </span><span style=\"color:#9ECBFF\">'WebhookConfig'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.consumer_group </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"delivery_workers\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> enqueue_event</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     priority: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">, expires_at: Optional[datetime] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add event to webhook-specific delivery queue.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stream_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"webhook:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">:events\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Calculate expiration (default 7 days from now)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> expires_at </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            expires_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.now(timezone.utc).timestamp() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">7</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 24</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 3600</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            expires_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> expires_at.timestamp()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        queue_entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueueEntry(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            event_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">event_id,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            webhook_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">webhook_id,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            attempt_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            next_attempt_at</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time(),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            payload_hash</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># Will be calculated by delivery worker</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            priority</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">priority,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            expires_at</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">expires_at,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            metadata</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">\"enqueued_at\"</span><span style=\"color:#E1E4E8\">: time.time()}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Add to Redis Stream</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        message_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.xadd(stream_key, asdict(queue_entry))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Create consumer group if it doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.redis.xgroup_create(stream_key, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.consumer_group, </span><span style=\"color:#FFAB70\">id</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">'0'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">mkstream</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> redis.ResponseError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#9ECBFF\"> \"BUSYGROUP\"</span><span style=\"color:#F97583\"> not</span><span style=\"color:#F97583\"> in</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(e):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                raise</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> message_id </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> claim_ready_events</span><span style=\"color:#E1E4E8\">(self, consumer_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, batch_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Dict]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Claim events ready for delivery across all webhook streams.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ready_events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Get list of all webhook streams</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        webhook_streams </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.keys(</span><span style=\"color:#9ECBFF\">\"webhook:*:events\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> stream_key </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> webhook_streams:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Read pending messages for this consumer</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                pending </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.xreadgroup(</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.consumer_group, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    consumer_name, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    {stream_key: </span><span style=\"color:#9ECBFF\">'>'</span><span style=\"color:#E1E4E8\">}, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    count</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">batch_size, </span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    block</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1000</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                for</span><span style=\"color:#E1E4E8\"> stream, messages </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> pending:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    for</span><span style=\"color:#E1E4E8\"> message_id, fields </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> messages:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueueEntry(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">fields)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                        # Check if event is ready for delivery</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                        if</span><span style=\"color:#E1E4E8\"> entry.next_attempt_at </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> current_time </span><span style=\"color:#F97583\">and</span><span style=\"color:#E1E4E8\"> entry.expires_at </span><span style=\"color:#F97583\">></span><span style=\"color:#E1E4E8\"> current_time:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            ready_events.append((message_id.decode(), asdict(entry)))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#E1E4E8\"> redis.ResponseError:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Stream might not exist or have no pending messages</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                continue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> ready_events[:batch_size]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> reschedule_event</span><span style=\"color:#E1E4E8\">(self, stream_key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, message_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        delay_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, attempt_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Reschedule failed event for later retry.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Acknowledge the current message</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.redis.xack(stream_key, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.consumer_group, message_id)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Get original message data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.xrange(stream_key, message_id, message_id)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> messages:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            _, original_fields </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> messages[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueueEntry(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">original_fields)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Update for retry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            entry.attempt_count </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> attempt_count</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            entry.next_attempt_at </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> delay_seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            entry.metadata.update({</span><span style=\"color:#9ECBFF\">\"last_retry_scheduled\"</span><span style=\"color:#E1E4E8\">: time.time()})</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Re-add to stream</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            new_message_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.xadd(stream_key, asdict(entry))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> new_message_id </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Failed to reschedule event </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">message_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> move_to_dlq</span><span style=\"color:#E1E4E8\">(self, stream_key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, message_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                   failure_reason: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, attempt_history: List[Dict]) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Move failed event to dead letter queue.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        dlq_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"dlq:events\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Get original event data</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            messages </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.xrange(stream_key, message_id, message_id)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#E1E4E8\"> messages:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            _, original_fields </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> messages[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueueEntry(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">original_fields)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Create DLQ entry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            dlq_entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"original_event_id\"</span><span style=\"color:#E1E4E8\">: entry.event_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"webhook_id\"</span><span style=\"color:#E1E4E8\">: entry.webhook_id,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"failure_reason\"</span><span style=\"color:#E1E4E8\">: failure_reason,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"attempt_history\"</span><span style=\"color:#E1E4E8\">: json.dumps(attempt_history),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"final_error\"</span><span style=\"color:#E1E4E8\">: attempt_history[</span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">].get(</span><span style=\"color:#9ECBFF\">\"error_message\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">) </span><span style=\"color:#F97583\">if</span><span style=\"color:#E1E4E8\"> attempt_history </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> \"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"dlq_timestamp\"</span><span style=\"color:#E1E4E8\">: time.time(),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"investigation_status\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"pending\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">                \"replay_eligible\"</span><span style=\"color:#E1E4E8\">: failure_reason </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#9ECBFF\">\"max_retries_exceeded\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"circuit_breaker_timeout\"</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Add to DLQ</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            dlq_message_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.xadd(dlq_key, dlq_entry)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Acknowledge original message</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.redis.xack(stream_key, </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.consumer_group, message_id)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> dlq_message_id </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Failed to move event </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">message_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> to DLQ: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<p><strong>HTTP Client with Retry Logic</strong> (Complete, ready to use):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hmac</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HTTPResponse</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status_code: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    headers: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    body: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookHTTPClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"HTTP client for webhook deliveries with timeout and retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: </span><span style=\"color:#9ECBFF\">'WebhookConfig'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> requests.Session()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config.delivery_timeout</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Configure connection pooling</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        adapter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> requests.adapters.HTTPAdapter(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_connections</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            pool_maxsize</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            max_retries</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#6A737D\">  # We handle retries ourselves</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.mount(</span><span style=\"color:#9ECBFF\">'http://'</span><span style=\"color:#E1E4E8\">, adapter)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.mount(</span><span style=\"color:#9ECBFF\">'https://'</span><span style=\"color:#E1E4E8\">, adapter)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> post_json</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, headers: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> HTTPResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Send JSON POST request with comprehensive error handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.session.post(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                url,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                data</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">payload,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">headers,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.delivery_timeout,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                allow_redirects</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">False</span><span style=\"color:#6A737D\">  # Don't follow redirects for security</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response.status_code,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(response.headers),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response.text[:</span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">]  </span><span style=\"color:#6A737D\"># Truncate large responses</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.Timeout:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Request timeout\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.ConnectionError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Connection error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.RequestException </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Request error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> should_retry_delivery</span><span style=\"color:#E1E4E8\">(self, status_code: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Determine if delivery attempt should be retried based on response.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> attempt_number </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.max_retry_attempts:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Retry server errors and timeouts</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#F97583\"> or</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">>=</span><span style=\"color:#79B8FF\"> 500</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Retry rate limiting</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">==</span><span style=\"color:#79B8FF\"> 429</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Don't retry client errors (except rate limiting)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> 400</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 500</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Don't retry successful responses</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> 200</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 300</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Don't retry redirects (security policy)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> 300</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> status_code </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> 400</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_retry_delay</span><span style=\"color:#E1E4E8\">(self, attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, base_delay: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate exponential backoff delay with jitter.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Exponential backoff: base_delay * (2 ^ attempt_number)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        exponential_delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_delay </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\"> **</span><span style=\"color:#E1E4E8\"> attempt_number)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Cap maximum delay at 1 hour</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        capped_delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> min</span><span style=\"color:#E1E4E8\">(exponential_delay, </span><span style=\"color:#79B8FF\">3600</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Add jitter: random value between 0 and delay/2</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        jitter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> random.randint(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, capped_delay </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 2</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> capped_delay </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> jitter</span></span></code></pre></div>\n\n<h4 id=\"core-delivery-logic-skeleton\">Core Delivery Logic Skeleton</h4>\n<p><strong>DeliveryWorker Class</strong> (Signatures with detailed TODOs):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timezone</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DeliveryWorker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Processes webhook deliveries with retry logic and circuit breaker integration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, queue_manager: QueueManager, http_client: WebhookHTTPClient,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 registry: </span><span style=\"color:#9ECBFF\">'WebhookRegistry'</span><span style=\"color:#E1E4E8\">, config: </span><span style=\"color:#9ECBFF\">'WebhookConfig'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.queue_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.http_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> http_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> registry</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.worker_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"worker_</span><span style=\"color:#79B8FF\">{int</span><span style=\"color:#E1E4E8\">(time.time())</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_delivery</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Attempt webhook delivery with comprehensive error handling and retry logic.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if delivery succeeded, False if it should be retried or moved to DLQ.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Retrieve webhook registration details from registry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Get webhook URL, secret, and current circuit breaker state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Return False if webhook doesn't exist or is disabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Check if circuit breaker is open - if so, move to DLQ with reason</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Generate HMAC signature for payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Use webhook secret to sign payload with current timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Include event_id and webhook_id in signature calculation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Format signature as \"sha256=&#x3C;hex_digest>\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Construct HTTP request headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Content-Type: application/json</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - X-Webhook-Signature: &#x3C;generated_signature></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - X-Webhook-Event-ID: &#x3C;event_id></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - X-Webhook-Timestamp: &#x3C;current_unix_timestamp></span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - User-Agent: WebhookSystem/1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Attempt HTTP delivery using webhook HTTP client</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Call http_client.post_json() with URL, payload, and headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Record attempt start time and end time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Handle any exceptions from HTTP client</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create DeliveryAttempt record</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Store attempt details including status code, response time, headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Include request details for debugging purposes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Save to database for audit trail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Analyze response and determine next action</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - If 2xx status: mark as successful, return True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - If should_retry_delivery() returns False: move to DLQ</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - If should retry: calculate delay and reschedule in queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Update circuit breaker state based on success/failure</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Handle circuit breaker state transitions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - On success: reset failure count, close circuit if in half-open</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - On failure: increment failure count, open circuit if threshold exceeded</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Update webhook registration with new circuit breaker state</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Replace with implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> deliver_webhook</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, signature: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, HTTPResponse]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Send webhook HTTP request and return success status with response details.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        This method handles the actual HTTP delivery mechanics.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate URL format and security constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Ensure URL uses HTTPS (never HTTP for security)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Check against SSRF protection rules (no private IPs)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Validate URL structure and reachability</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Prepare headers for webhook delivery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Content-Type: application/json</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - X-Webhook-Signature: signature parameter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - X-Webhook-Timestamp: current timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Include any custom headers from webhook configuration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Execute HTTP POST request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Use http_client.post_json() with timeout handling</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Capture full response details including headers and timing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Handle network errors gracefully without crashing</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Analyze response for success determination</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Success: 2xx status codes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Consider 3xx as delivery failure (don't follow redirects)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Log response details for debugging and compliance</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return structured results</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Boolean success indicator</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Complete HTTPResponse object with all details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Ensure no sensitive data leaks in error messages</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Replace with implementation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_worker_loop</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Main worker loop that continuously processes events from delivery queues.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        This method implements the worker's primary event processing cycle.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Initialize worker state and register with system</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Set worker ID and start timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Register worker in Redis for monitoring purposes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Initialize performance counters and health metrics</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Implement continuous event polling loop</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Claim ready events from queue_manager</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Handle empty queue gracefully with backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Respect shutdown signals for clean worker termination</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Process each claimed event</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Extract event details from queue entry</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Load full event payload from database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Call process_delivery() for actual delivery attempt</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle delivery results appropriately</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Success: acknowledge message and remove from queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Retry needed: reschedule with calculated backoff delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Permanent failure: move to dead letter queue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update worker health metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Track delivery success/failure rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Monitor processing latency and queue depths</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Report worker status to monitoring system</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle worker shutdown gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Complete current deliveries before stopping</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Release any claimed but unprocessed messages</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        #   - Update worker registry to show offline status</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span><span style=\"color:#6A737D\">  # Replace with implementation</span></span></code></pre></div>\n\n<h4 id=\"language-specific-implementation-hints\">Language-Specific Implementation Hints</h4>\n<p><strong>Redis Operations</strong>:</p>\n<ul>\n<li>Use <code>redis-py</code> library with connection pooling: <code>redis.ConnectionPool(max_connections=20)</code></li>\n<li>For atomic operations, use Redis pipelines: <code>pipe = redis_client.pipeline()</code> followed by <code>pipe.execute()</code></li>\n<li>Redis Streams operations: <code>XADD</code> for enqueueing, <code>XREADGROUP</code> for claiming, <code>XACK</code> for acknowledgment</li>\n</ul>\n<p><strong>HTTP Client Configuration</strong>:</p>\n<ul>\n<li>Set reasonable timeouts: <code>requests.Session(timeout=(5, 30))</code> for 5s connect, 30s read</li>\n<li>Disable redirects for security: <code>allow_redirects=False</code> in all requests</li>\n<li>Use connection pooling: <code>HTTPAdapter(pool_connections=10, pool_maxsize=20)</code></li>\n</ul>\n<p><strong>Error Handling Patterns</strong>:</p>\n<ul>\n<li>Always catch specific exceptions: <code>requests.exceptions.Timeout</code>, <code>requests.exceptions.ConnectionError</code></li>\n<li>Use structured logging: <code>logging.getLogger(__name__).error(&quot;Delivery failed&quot;, extra={&quot;webhook_id&quot;: webhook_id})</code></li>\n<li>Never let worker crashes lose events - wrap main processing in try/except with event rescheduling</li>\n</ul>\n<p><strong>Database Operations</strong>:</p>\n<ul>\n<li>Use SQLAlchemy sessions with proper cleanup: <code>with session_scope() as session:</code></li>\n<li>For high-throughput inserts, use batch operations: <code>session.bulk_insert_mappings()</code></li>\n<li>Index frequently queried fields: <code>webhook_id</code>, <code>event_id</code>, <code>attempted_at</code></li>\n</ul>\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Checkpoint 1: Basic Queue Operations</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start Redis server</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">redis-server</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Run basic queue test</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_queue_manager.py::test_enqueue_and_claim</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected behavior: Events enqueued to webhook-specific streams can be claimed by workers and acknowledged successfully.</p>\n<p><strong>Checkpoint 2: HTTP Delivery with Retries</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start mock webhook endpoint</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> tests/mock_webhook_server.py</span><span style=\"color:#79B8FF\"> --port</span><span style=\"color:#79B8FF\"> 8080</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Run delivery test</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_delivery_worker.py::test_successful_delivery</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected behavior: Webhook events are delivered via HTTP POST with proper signatures and retry logic handles failures.</p>\n<p><strong>Checkpoint 3: Dead Letter Queue Processing</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run DLQ test with failing endpoint</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_delivery_worker.py::test_dlq_processing</span><span style=\"color:#79B8FF\"> -v</span></span></code></pre></div>\n<p>Expected behavior: Events that exceed retry limits are moved to dead letter queue with complete attempt history.</p>\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Events stuck in queue</td>\n<td>Worker crash or infinite loop</td>\n<td>Check Redis streams: <code>XPENDING webhook:123:events delivery_workers</code></td>\n<td>Restart workers, check for unhandled exceptions</td>\n</tr>\n<tr>\n<td>Duplicate deliveries</td>\n<td>Message not acknowledged after processing</td>\n<td>Check XACK calls in delivery logic</td>\n<td>Ensure acknowledgment happens after successful processing</td>\n</tr>\n<tr>\n<td>High retry rates</td>\n<td>Endpoint returning 5xx errors or timing out</td>\n<td>Check delivery attempt logs for status codes</td>\n<td>Review endpoint health, adjust timeout settings</td>\n</tr>\n<tr>\n<td>Circuit breaker not opening</td>\n<td>Failure threshold too high or state not persisted</td>\n<td>Check webhook registration failure_count field</td>\n<td>Lower threshold, verify state updates are atomic</td>\n</tr>\n<tr>\n<td>Memory usage growing</td>\n<td>Dead letter queue or delivery logs growing unbounded</td>\n<td>Check DLQ size: <code>XLEN dlq:events</code></td>\n<td>Implement retention policies, archive old entries</td>\n</tr>\n</tbody></table>\n<h2 id=\"circuit-breaker-and-rate-limiting\">Circuit Breaker and Rate Limiting</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 3 (Circuit Breaker &amp; Rate Limiting) - implements protection mechanisms that prevent failing endpoints from overwhelming the delivery system while supporting automatic recovery</p>\n</blockquote>\n<h3 id=\"mental-model-the-overworked-postal-worker\">Mental Model: The Overworked Postal Worker</h3>\n<p>Think of the circuit breaker pattern like a postal worker who becomes selective about delivery routes. When the postal worker repeatedly encounters a house where no one answers the door (failing webhook endpoint), they don&#39;t keep wasting time and energy making delivery attempts. Instead, they mark that address as &quot;temporarily undeliverable&quot; and skip it for a while, allowing them to focus on successful deliveries to other addresses.</p>\n<p>After some time passes, the postal worker gives that problematic address another chance with a single test delivery (half-open state). If someone finally answers, great - normal delivery resumes. If not, the address goes back on the &quot;skip&quot; list for an even longer period. This prevents one problematic address from blocking deliveries to everyone else.</p>\n<p>Rate limiting works like the postal service&#39;s capacity management. Even for addresses that work perfectly, the postal worker can only handle so many deliveries per hour. If they try to deliver too fast, they make mistakes, drop packages, or burn out. So they maintain a steady, sustainable pace that ensures quality delivery to all customers.</p>\n<p><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fcircuit-breaker-states.svg\" alt=\"Circuit Breaker State Machine\"></p>\n<p>The webhook delivery system faces identical challenges. Some endpoints will inevitably fail - servers go down, networks have issues, or applications crash. Without protection mechanisms, these failing endpoints can consume all available delivery workers, create massive retry queues, and degrade service for healthy endpoints. Circuit breakers and rate limiting provide the essential protection that keeps the entire system healthy.</p>\n<h3 id=\"circuit-breaker-state-machine\">Circuit Breaker State Machine</h3>\n<p>The circuit breaker operates as a finite state machine with three distinct states that protect failing endpoints while enabling automatic recovery. Each webhook registration maintains its own independent circuit breaker, allowing fine-grained failure isolation without affecting delivery to healthy endpoints.</p>\n<blockquote>\n<p><strong>Decision: Per-Endpoint Circuit Breaker Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to protect against failing endpoints without impacting healthy ones, while handling different failure patterns across diverse webhook consumers</li>\n<li><strong>Options Considered</strong>: Global circuit breaker for all endpoints, per-endpoint circuit breakers, endpoint groups with shared circuit breakers</li>\n<li><strong>Decision</strong>: Independent circuit breaker per webhook endpoint</li>\n<li><strong>Rationale</strong>: Different endpoints have vastly different reliability characteristics, scaling patterns, and operational schedules. A social media platform might have planned maintenance windows, while a payment processor requires 24/7 availability. Global circuit breakers create inappropriate coupling between unrelated services.</li>\n<li><strong>Consequences</strong>: Higher memory overhead for circuit breaker state storage, more complex monitoring across many breakers, but provides precise failure isolation and recovery control</li>\n</ul>\n</blockquote>\n<h4 id=\"circuit-breaker-states-and-transitions\">Circuit Breaker States and Transitions</h4>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Triggering Event</th>\n<th>Next State</th>\n<th>Actions Taken</th>\n<th>Conditions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Closed</strong></td>\n<td>Successful delivery</td>\n<td>Closed</td>\n<td>Reset failure count, update <code>last_success_at</code></td>\n<td>Normal operation state</td>\n</tr>\n<tr>\n<td><strong>Closed</strong></td>\n<td>Failed delivery</td>\n<td>Closed</td>\n<td>Increment failure count</td>\n<td><code>failure_count &lt; CIRCUIT_BREAKER_FAILURE_THRESHOLD</code></td>\n</tr>\n<tr>\n<td><strong>Closed</strong></td>\n<td>Failed delivery</td>\n<td>Open</td>\n<td>Set <code>circuit_state = &#39;open&#39;</code>, schedule recovery attempt</td>\n<td><code>failure_count &gt;= CIRCUIT_BREAKER_FAILURE_THRESHOLD</code></td>\n</tr>\n<tr>\n<td><strong>Open</strong></td>\n<td>Delivery attempt</td>\n<td>Open</td>\n<td>Reject delivery immediately, return circuit breaker error</td>\n<td>Before recovery timeout expires</td>\n</tr>\n<tr>\n<td><strong>Open</strong></td>\n<td>Recovery timeout</td>\n<td>Half-Open</td>\n<td>Set <code>circuit_state = &#39;half_open&#39;</code>, allow limited test traffic</td>\n<td>After configurable open duration</td>\n</tr>\n<tr>\n<td><strong>Half-Open</strong></td>\n<td>Successful test delivery</td>\n<td>Closed</td>\n<td>Reset failure count, set <code>circuit_state = &#39;closed&#39;</code></td>\n<td>Test delivery succeeds</td>\n</tr>\n<tr>\n<td><strong>Half-Open</strong></td>\n<td>Failed test delivery</td>\n<td>Open</td>\n<td>Increment open duration, set <code>circuit_state = &#39;open&#39;</code></td>\n<td>Test delivery fails</td>\n</tr>\n</tbody></table>\n<p>The <strong>closed state</strong> represents normal operation where all delivery attempts are allowed to proceed. The system tracks consecutive failures for each endpoint, incrementing the <code>failure_count</code> field in the <code>WebhookRegistration</code> record after each failed delivery attempt. When this count reaches the <code>CIRCUIT_BREAKER_FAILURE_THRESHOLD</code> (typically 5 consecutive failures), the circuit breaker transitions to the open state.</p>\n<p>In the <strong>open state</strong>, the circuit breaker immediately rejects all delivery attempts without making HTTP requests to the failing endpoint. This prevents resource waste on requests that are likely to fail and allows the delivery system to focus on healthy endpoints. The system sets a recovery timer (starting at 60 seconds, with exponential backoff for repeated openings) that eventually transitions the breaker to half-open state.</p>\n<p>The <strong>half-open state</strong> serves as a cautious testing phase where the system allows a single delivery attempt to probe whether the endpoint has recovered. If this test delivery succeeds, the endpoint is considered healthy and the circuit returns to closed state with reset failure counters. If the test fails, the circuit returns to open state with an increased recovery timeout (doubled from the previous duration, capped at 30 minutes).</p>\n<h4 id=\"circuit-breaker-implementation-strategy\">Circuit Breaker Implementation Strategy</h4>\n<blockquote>\n<p><strong>Decision: Failure Count vs Time Window Approach</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to determine how to measure endpoint failures for circuit breaker activation</li>\n<li><strong>Options Considered</strong>: Consecutive failure count, sliding window failure rate, exponential decay scoring</li>\n<li><strong>Decision</strong>: Consecutive failure count with success-based reset</li>\n<li><strong>Rationale</strong>: Consecutive failures indicate persistent endpoint issues requiring immediate protection. Rate-based approaches can miss sustained outages if occasional successes reset the window. Exponential decay adds complexity without clear reliability benefits for webhook delivery patterns.</li>\n<li><strong>Consequences</strong>: May open circuits for temporary network blips, but provides fast protection against sustained failures. Simple to implement and reason about during debugging.</li>\n</ul>\n</blockquote>\n<p>The circuit breaker state is persisted in the <code>WebhookRegistration</code> record to survive system restarts and enable coordination across multiple delivery workers. The key fields for circuit breaker operation include:</p>\n<table>\n<thead>\n<tr>\n<th>Field Name</th>\n<th>Type</th>\n<th>Description</th>\n<th>Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>failure_count</code></td>\n<td>int</td>\n<td>Consecutive delivery failures</td>\n<td>Compared against threshold for state transitions</td>\n</tr>\n<tr>\n<td><code>circuit_state</code></td>\n<td>str</td>\n<td>Current breaker state (&#39;closed&#39;, &#39;open&#39;, &#39;half_open&#39;)</td>\n<td>Controls delivery attempt behavior</td>\n</tr>\n<tr>\n<td><code>last_success_at</code></td>\n<td>datetime</td>\n<td>Timestamp of most recent successful delivery</td>\n<td>Used for health monitoring and recovery decisions</td>\n</tr>\n<tr>\n<td><code>circuit_opened_at</code></td>\n<td>datetime</td>\n<td>When circuit last opened</td>\n<td>Calculates recovery timeout expiration</td>\n</tr>\n<tr>\n<td><code>circuit_recovery_timeout</code></td>\n<td>int</td>\n<td>Seconds until next recovery attempt</td>\n<td>Exponentially increased after repeated failures</td>\n</tr>\n</tbody></table>\n<p>The delivery worker checks circuit breaker state before attempting any webhook delivery. For closed circuits, delivery proceeds normally. For open circuits, the worker immediately marks the attempt as failed with <code>circuit_breaker_triggered = true</code> in the <code>DeliveryAttempt</code> record and schedules the event for retry after the circuit recovery timeout expires.</p>\n<p>During half-open state, only a single delivery worker should attempt the test delivery to prevent thundering herd conditions. This is coordinated using Redis atomic operations:</p>\n<ol>\n<li>Worker checks if circuit is half-open and no test is in progress</li>\n<li>Worker attempts to set a Redis key <code>circuit_test:{webhook_id}</code> with short TTL (10 seconds)</li>\n<li>If successful, worker proceeds with test delivery; if key exists, worker backs off</li>\n<li>After test completion, worker updates circuit state and clears the test coordination key</li>\n</ol>\n<h4 id=\"adaptive-recovery-timing\">Adaptive Recovery Timing</h4>\n<p>The circuit breaker implements adaptive recovery timing that increases open duration after repeated failures, preventing rapid cycling between open and half-open states for persistently failing endpoints.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Cycle</th>\n<th>Recovery Timeout</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>First opening</td>\n<td>60 seconds</td>\n<td>Quick recovery for temporary issues</td>\n</tr>\n<tr>\n<td>Second opening</td>\n<td>120 seconds</td>\n<td>Longer grace period for service restarts</td>\n</tr>\n<tr>\n<td>Third opening</td>\n<td>300 seconds</td>\n<td>Extended timeout for maintenance windows</td>\n</tr>\n<tr>\n<td>Fourth+ opening</td>\n<td>600 seconds (10 minutes)</td>\n<td>Maximum timeout for persistent failures</td>\n</tr>\n</tbody></table>\n<p>This exponential backoff approach balances quick recovery for transient issues with system protection against long-term failures. The recovery timeout resets to 60 seconds after any successful delivery, allowing endpoints that recover to immediately return to normal operation cadence.</p>\n<p><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fretry-flowchart.svg\" alt=\"Retry Decision Flowchart\"></p>\n<h3 id=\"rate-limiting-strategy\">Rate Limiting Strategy</h3>\n<p>Rate limiting prevents webhook delivery systems from overwhelming downstream endpoints, even when those endpoints are healthy and responding successfully. Unlike circuit breakers that respond to failures, rate limiting provides proactive protection by controlling the delivery pace regardless of endpoint health status.</p>\n<blockquote>\n<p><strong>Decision: Token Bucket vs Sliding Window Rate Limiting</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to control delivery rate per endpoint while allowing reasonable burst capacity and respecting endpoint preferences</li>\n<li><strong>Options Considered</strong>: Token bucket algorithm, sliding window rate limiting, leaky bucket algorithm</li>\n<li><strong>Decision</strong>: Token bucket with configurable refill rate and burst capacity</li>\n<li><strong>Rationale</strong>: Token bucket naturally handles burst traffic by accumulating tokens during idle periods, matches common webhook consumer expectations, and integrates well with HTTP Retry-After header responses. Sliding windows require more complex time-based calculations and don&#39;t support bursting.</li>\n<li><strong>Consequences</strong>: Allows temporary bursts above steady-state rate, requires token state persistence for multi-worker coordination, simpler to tune and monitor than sliding window approaches</li>\n</ul>\n</blockquote>\n<h4 id=\"token-bucket-implementation\">Token Bucket Implementation</h4>\n<p>The token bucket algorithm maintains a bucket of tokens for each webhook endpoint, with tokens representing permission to make delivery attempts. The bucket refills at a configured rate (default 60 tokens per minute, or 1 request per second) and has a maximum capacity that allows brief bursts above the sustained rate.</p>\n<table>\n<thead>\n<tr>\n<th>Token Bucket Parameter</th>\n<th>Default Value</th>\n<th>Configuration Field</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Refill Rate</strong></td>\n<td>60 tokens/minute</td>\n<td><code>rate_limit_rpm</code></td>\n<td>Sustained delivery rate per endpoint</td>\n</tr>\n<tr>\n<td><strong>Bucket Capacity</strong></td>\n<td>10 tokens</td>\n<td><code>rate_limit_burst</code></td>\n<td>Maximum burst size above sustained rate</td>\n</tr>\n<tr>\n<td><strong>Token Refill Interval</strong></td>\n<td>1 second</td>\n<td><code>rate_limit_refill_interval</code></td>\n<td>How frequently to add tokens</td>\n</tr>\n<tr>\n<td><strong>Minimum Delivery Interval</strong></td>\n<td>1000ms</td>\n<td><code>min_delivery_interval_ms</code></td>\n<td>Absolute minimum time between requests</td>\n</tr>\n</tbody></table>\n<p>Before attempting any webhook delivery, the delivery worker must acquire a token from the endpoint&#39;s bucket. If no tokens are available, the delivery attempt is delayed until the next refill cycle. This ensures that even healthy endpoints receive deliveries at a sustainable pace.</p>\n<p>The token bucket state is maintained in Redis using atomic operations to coordinate across multiple delivery workers:</p>\n<table>\n<thead>\n<tr>\n<th>Redis Key Pattern</th>\n<th>Value Type</th>\n<th>Description</th>\n<th>TTL</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>rate_limit:{webhook_id}:tokens</code></td>\n<td>Integer</td>\n<td>Current token count</td>\n<td>3600 seconds</td>\n</tr>\n<tr>\n<td><code>rate_limit:{webhook_id}:last_refill</code></td>\n<td>Unix timestamp</td>\n<td>Last refill time</td>\n<td>3600 seconds</td>\n</tr>\n<tr>\n<td><code>rate_limit:{webhook_id}:locked_until</code></td>\n<td>Unix timestamp</td>\n<td>Delay until next allowed request</td>\n<td>Variable</td>\n</tr>\n</tbody></table>\n<h4 id=\"retry-after-header-handling\">Retry-After Header Handling</h4>\n<p>When webhook endpoints return HTTP 429 (Too Many Requests) responses, they often include a <code>Retry-After</code> header specifying how long the client should wait before making another request. The rate limiting system respects these headers and temporarily reduces the delivery rate beyond the configured token bucket limits.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>HTTP/1.1 429 Too Many Requests\nRetry-After: 300\nContent-Type: application/json\n\n{&quot;error&quot;: &quot;Rate limit exceeded&quot;, &quot;reset_time&quot;: &quot;2024-01-15T10:35:00Z&quot;}</code></pre></div>\n\n<p>When a 429 response includes a <code>Retry-After</code> header, the system:</p>\n<ol>\n<li>Parses the header value (supports both delta-seconds and HTTP-date formats)</li>\n<li>Sets the <code>rate_limit:{webhook_id}:locked_until</code> Redis key to the calculated retry time</li>\n<li>Suspends all delivery attempts to that endpoint until the lock expires</li>\n<li>Resumes normal token bucket operation after the lock period</li>\n</ol>\n<p>This mechanism allows webhook consumers to dynamically control their incoming rate during high load periods, maintenance windows, or capacity constraints.</p>\n<h4 id=\"dynamic-rate-limit-adjustment\">Dynamic Rate Limit Adjustment</h4>\n<p>The system supports dynamic rate limit adjustment based on endpoint response patterns and explicit consumer preferences. This enables automatic adaptation to endpoint capacity changes without requiring manual configuration updates.</p>\n<table>\n<thead>\n<tr>\n<th>Adjustment Trigger</th>\n<th>Action Taken</th>\n<th>Duration</th>\n<th>Rationale</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Successful delivery &lt; 100ms</strong></td>\n<td>Increase rate limit by 10%</td>\n<td>Until next failure</td>\n<td>Endpoint has spare capacity</td>\n</tr>\n<tr>\n<td><strong>Successful delivery &gt; 2000ms</strong></td>\n<td>Decrease rate limit by 20%</td>\n<td>300 seconds</td>\n<td>Endpoint showing stress signs</td>\n</tr>\n<tr>\n<td><strong>HTTP 429 response</strong></td>\n<td>Set rate to 50% of current</td>\n<td>Until Retry-After expires</td>\n<td>Explicit endpoint feedback</td>\n</tr>\n<tr>\n<td><strong>Consecutive timeouts</strong></td>\n<td>Decrease rate limit by 50%</td>\n<td>600 seconds</td>\n<td>Endpoint overload indication</td>\n</tr>\n</tbody></table>\n<p>Rate limit adjustments are bounded by configured minimum and maximum values to prevent runaway increases or decreases. The base rate limit from the webhook registration serves as the default value that the system returns to after adjustment periods expire.</p>\n<h3 id=\"endpoint-health-monitoring\">Endpoint Health Monitoring</h3>\n<p>Continuous health monitoring provides the observability foundation that enables circuit breakers and rate limiting to make informed decisions about endpoint status and capacity. The monitoring system tracks multiple health dimensions simultaneously to build a comprehensive view of each endpoint&#39;s operational status.</p>\n<h4 id=\"health-metrics-collection\">Health Metrics Collection</h4>\n<p>The system collects detailed metrics for every delivery attempt, building a real-time picture of endpoint health across multiple dimensions. These metrics feed into both circuit breaker state decisions and rate limiting adjustments.</p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Specific Metrics</th>\n<th>Collection Method</th>\n<th>Retention Period</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Response Time</strong></td>\n<td>p50, p90, p95, p99 latency</td>\n<td>Histogram in Redis</td>\n<td>24 hours</td>\n</tr>\n<tr>\n<td><strong>Success Rate</strong></td>\n<td>2xx responses vs total attempts</td>\n<td>Counter with time buckets</td>\n<td>7 days</td>\n</tr>\n<tr>\n<td><strong>Error Distribution</strong></td>\n<td>Count by HTTP status code</td>\n<td>Hash map per endpoint</td>\n<td>24 hours</td>\n</tr>\n<tr>\n<td><strong>Availability</strong></td>\n<td>Uptime percentage over rolling window</td>\n<td>Sliding window calculation</td>\n<td>24 hours</td>\n</tr>\n<tr>\n<td><strong>Throughput</strong></td>\n<td>Successful deliveries per minute</td>\n<td>Time-series data</td>\n<td>24 hours</td>\n</tr>\n</tbody></table>\n<p>Response time tracking focuses on total delivery duration from HTTP request start to complete response processing. This includes DNS resolution, connection establishment, request transmission, server processing, and response download. High latencies often precede outright failures and can trigger preemptive rate limiting adjustments.</p>\n<p>Success rate calculation considers any HTTP response in the 2xx range as successful, with special handling for specific codes:</p>\n<table>\n<thead>\n<tr>\n<th>HTTP Status Range</th>\n<th>Classification</th>\n<th>Circuit Breaker Impact</th>\n<th>Retry Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>2xx Success</strong></td>\n<td>Healthy</td>\n<td>Reset failure count</td>\n<td>No retry needed</td>\n</tr>\n<tr>\n<td><strong>3xx Redirect</strong></td>\n<td>Healthy</td>\n<td>Reset failure count</td>\n<td>Follow redirect if allowed</td>\n</tr>\n<tr>\n<td><strong>4xx Client Error</strong></td>\n<td>Healthy (bad request)</td>\n<td>Reset failure count</td>\n<td>No retry (except 429)</td>\n</tr>\n<tr>\n<td><strong>429 Rate Limited</strong></td>\n<td>Healthy (capacity limit)</td>\n<td>Reset failure count</td>\n<td>Retry after delay</td>\n</tr>\n<tr>\n<td><strong>5xx Server Error</strong></td>\n<td>Unhealthy</td>\n<td>Increment failure count</td>\n<td>Retry with backoff</td>\n</tr>\n<tr>\n<td><strong>Timeout/Network</strong></td>\n<td>Unhealthy</td>\n<td>Increment failure count</td>\n<td>Retry with backoff</td>\n</tr>\n</tbody></table>\n<p>This classification scheme distinguishes between endpoint failures (5xx, timeouts) and request problems (4xx) that indicate healthy endpoints receiving invalid requests.</p>\n<h4 id=\"health-score-calculation\">Health Score Calculation</h4>\n<p>The system calculates a composite health score for each endpoint that combines multiple metrics into a single value between 0 (completely unhealthy) and 100 (perfectly healthy). This score drives circuit breaker state transitions and rate limiting adjustments.</p>\n<blockquote>\n<p><strong>Decision: Composite Health Score vs Individual Thresholds</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to make circuit breaker and rate limiting decisions based on multiple health indicators</li>\n<li><strong>Options Considered</strong>: Individual thresholds per metric, weighted composite score, machine learning-based health prediction</li>\n<li><strong>Decision</strong>: Weighted composite health score with configurable weights</li>\n<li><strong>Rationale</strong>: Individual thresholds create complex decision matrices and can conflict with each other. Composite scores provide a single decision point while preserving the ability to weight different aspects based on endpoint characteristics. ML approaches add significant complexity without clear accuracy benefits for webhook delivery patterns.</li>\n<li><strong>Consequences</strong>: Requires tuning of weight values, may mask specific failure modes, but provides consistent decision-making framework across all endpoints</li>\n</ul>\n</blockquote>\n<p>The health score combines five weighted components:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Weight</th>\n<th>Calculation Method</th>\n<th>Score Range</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Success Rate</strong></td>\n<td>40%</td>\n<td>(Successful requests / Total requests) × 100</td>\n<td>0-100</td>\n</tr>\n<tr>\n<td><strong>Response Time</strong></td>\n<td>25%</td>\n<td>max(0, 100 - (p95_latency_ms / 50))</td>\n<td>0-100</td>\n</tr>\n<tr>\n<td><strong>Error Rate</strong></td>\n<td>20%</td>\n<td>max(0, 100 - (5xx_count / total_count × 100))</td>\n<td>0-100</td>\n</tr>\n<tr>\n<td><strong>Availability</strong></td>\n<td>10%</td>\n<td>(Non-timeout requests / Total requests) × 100</td>\n<td>0-100</td>\n</tr>\n<tr>\n<td><strong>Consistency</strong></td>\n<td>5%</td>\n<td>100 - (response_time_stddev / mean_response_time × 100)</td>\n<td>0-100</td>\n</tr>\n</tbody></table>\n<p>The overall health score is calculated as: <code>health_score = (success_rate × 0.4) + (response_time_score × 0.25) + (error_rate_score × 0.2) + (availability_score × 0.1) + (consistency_score × 0.05)</code></p>\n<p>Health scores are recalculated every 30 seconds using a sliding 10-minute window of delivery attempts. Circuit breaker thresholds are based on both consecutive failures and sustained low health scores:</p>\n<ul>\n<li>Circuit opens when health score drops below 30 for more than 5 minutes</li>\n<li>Circuit closes when health score exceeds 80 for more than 2 minutes in half-open state</li>\n<li>Rate limits decrease when health score drops below 60</li>\n<li>Rate limits increase when health score exceeds 90</li>\n</ul>\n<h4 id=\"alerting-and-notification\">Alerting and Notification</h4>\n<p>The health monitoring system generates alerts when endpoints show signs of degradation, enabling proactive intervention before complete failures occur. Alerts are configured with escalation levels that match the severity of detected issues.</p>\n<table>\n<thead>\n<tr>\n<th>Alert Level</th>\n<th>Trigger Conditions</th>\n<th>Recipients</th>\n<th>Response Time SLA</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Info</strong></td>\n<td>Health score 60-70 for 10 minutes</td>\n<td>Endpoint owner (email)</td>\n<td>No SLA - informational</td>\n</tr>\n<tr>\n<td><strong>Warning</strong></td>\n<td>Health score 40-60 for 5 minutes</td>\n<td>Endpoint owner (email + Slack)</td>\n<td>4 hours</td>\n</tr>\n<tr>\n<td><strong>Critical</strong></td>\n<td>Health score &lt; 40 or circuit breaker opens</td>\n<td>Endpoint owner + webhook admin (PagerDuty)</td>\n<td>30 minutes</td>\n</tr>\n<tr>\n<td><strong>Emergency</strong></td>\n<td>Multiple endpoints failing in same organization</td>\n<td>All stakeholders (phone + PagerDuty)</td>\n<td>15 minutes</td>\n</tr>\n</tbody></table>\n<p>Alert notifications include actionable context that helps endpoint owners diagnose and resolve issues:</p>\n<ul>\n<li>Recent error distribution with example error messages</li>\n<li>Response time trends over the past hour</li>\n<li>Comparison with typical performance baselines</li>\n<li>Suggested remediation steps based on observed failure patterns</li>\n<li>Direct links to delivery logs and debugging tools</li>\n</ul>\n<p>The system implements alert fatigue prevention by grouping related alerts and suppressing duplicate notifications during known issue periods. When an endpoint&#39;s circuit breaker opens, subsequent health alerts are suppressed until the circuit returns to closed state.</p>\n<h3 id=\"common-protection-pitfalls\">Common Protection Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Premature Circuit Opening on Cold Starts</strong></p>\n<p>Many developers configure circuit breaker failure thresholds too aggressively, causing circuits to open during normal cold start periods when applications are initializing and may respond slowly or return temporary errors.</p>\n<p><strong>Why It&#39;s Wrong</strong>: Applications often need 30-60 seconds to fully initialize after deployment or scaling events. A circuit breaker with a 3-failure threshold can open within seconds of a deployment, preventing the application from receiving the traffic it needs to finish warming up.</p>\n<p><strong>How to Fix</strong>: Use minimum failure counts of 5-7 for most applications, implement cold start detection by tracking deployment events, and consider longer response timeouts (30+ seconds) during the first few minutes after circuit closure.</p>\n<p>⚠️ <strong>Pitfall: Ignoring HTTP 4xx Responses in Circuit Breaker Logic</strong></p>\n<p>A common mistake is treating all HTTP error responses as endpoint failures, including 4xx client errors that indicate problems with the webhook payload rather than endpoint health.</p>\n<p><strong>Why It&#39;s Wrong</strong>: When webhook payloads become malformed due to upstream bugs, treating 400 Bad Request responses as endpoint failures can open circuit breakers for perfectly healthy endpoints. This prevents delivery of valid webhook events that would succeed.</p>\n<p><strong>How to Fix</strong>: Only count 5xx responses, timeouts, and connection failures as endpoint failures. Reset failure counts on 4xx responses since they indicate the endpoint is healthy enough to process and reject bad requests.</p>\n<p>⚠️ <strong>Pitfall: Token Bucket Implementation Without Burst Capacity</strong></p>\n<p>Implementing rate limiting with strict per-second limits prevents endpoints from handling natural traffic bursts, even when they have available capacity.</p>\n<p><strong>Why It&#39;s Wrong</strong>: Webhook traffic often comes in bursts - a social media post might generate 50 webhook events simultaneously, but the endpoint can handle this burst fine as long as sustained rate remains reasonable. Rejecting burst traffic creates artificial delays.</p>\n<p><strong>How to Fix</strong>: Always implement token bucket capacity that&#39;s 3-5x the per-second rate limit. For a 10 RPS limit, allow a bucket capacity of 30-50 tokens so that bursts can be handled immediately while maintaining sustainable average rates.</p>\n<p>⚠️ <strong>Pitfall: Circuit Breaker State Races in Multi-Worker Systems</strong></p>\n<p>In distributed systems with multiple delivery workers, race conditions during circuit state transitions can cause inconsistent behavior where some workers think a circuit is open while others attempt deliveries.</p>\n<p><strong>Why It&#39;s Wrong</strong>: Without proper coordination, multiple workers might simultaneously detect that a circuit should open, or worse, multiple workers might attempt &quot;test&quot; deliveries during half-open state, creating thundering herd conditions.</p>\n<p><strong>How to Fix</strong>: Use atomic Redis operations for all circuit state changes, implement test delivery coordination with Redis locks during half-open state, and include circuit state timestamps to detect stale reads.</p>\n<p>⚠️ <strong>Pitfall: Rate Limiting Without Retry-After Header Support</strong></p>\n<p>Many implementations ignore the <code>Retry-After</code> header in HTTP 429 responses, continuing to send requests at the configured rate limit even when endpoints explicitly request slower delivery.</p>\n<p><strong>Why It&#39;s Wrong</strong>: Endpoints include <code>Retry-After</code> headers during maintenance windows, scaling events, or capacity issues. Ignoring these headers can cause unnecessary circuit breaker activations when the endpoint just needs temporary delivery pauses.</p>\n<p><strong>How to Fix</strong>: Always parse and respect <code>Retry-After</code> headers from 429 responses. Suspend delivery attempts until the specified time, and consider this a successful interaction (don&#39;t increment failure counters) since the endpoint is communicating properly.</p>\n<p>⚠️ <strong>Pitfall: Health Score Calculation Based on Insufficient Data</strong></p>\n<p>Computing health scores and making circuit breaker decisions based on small sample sizes leads to erratic behavior where single failed requests cause circuit openings.</p>\n<p><strong>Why It&#39;s Wrong</strong>: An endpoint that receives 2 requests per hour shouldn&#39;t have its circuit opened because both requests in a 10-minute window failed. The sample size is too small to determine actual endpoint health.</p>\n<p><strong>How to Fix</strong>: Require minimum request counts (10-20 requests) before computing health scores, extend observation windows for low-traffic endpoints, and use different thresholds based on request volume patterns.</p>\n<p>⚠️ <strong>Pitfall: Circuit Breaker Recovery Without Exponential Backoff</strong></p>\n<p>Implementing fixed recovery timeouts causes repeated rapid cycling between open and half-open states for endpoints with sustained issues.</p>\n<p><strong>Why It&#39;s Wrong</strong>: If an endpoint is down for maintenance, a 60-second recovery timeout will cause the circuit breaker to test every minute, generating unnecessary load and creating noise in monitoring systems.</p>\n<p><strong>How to Fix</strong>: Implement exponential backoff for recovery timeouts, starting at 60 seconds and doubling on each failure up to a maximum of 10-15 minutes. Reset to base timeout only after successful deliveries.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The circuit breaker and rate limiting components require careful coordination between multiple system layers. The following technology choices provide a robust foundation for implementing these protection mechanisms at scale.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Circuit Breaker State Storage</strong></td>\n<td>Redis with atomic operations</td>\n<td>Redis Cluster with consistent hashing</td>\n</tr>\n<tr>\n<td><strong>Rate Limiting Backend</strong></td>\n<td>Redis token bucket implementation</td>\n<td>Redis with Lua scripts for atomicity</td>\n</tr>\n<tr>\n<td><strong>Health Metrics Collection</strong></td>\n<td>Redis time-series with TTL</td>\n<td>InfluxDB or TimescaleDB</td>\n</tr>\n<tr>\n<td><strong>Alerting System</strong></td>\n<td>SMTP email + Slack webhooks</td>\n<td>PagerDuty + OpsGenie integration</td>\n</tr>\n<tr>\n<td><strong>Configuration Management</strong></td>\n<td>Environment variables + database</td>\n<td>Consul/etcd with dynamic reloading</td>\n</tr>\n</tbody></table>\n<h4 id=\"file-structure\">File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  src/\n    webhook_delivery/\n      protection/                    ← Circuit breaker and rate limiting\n        __init__.py\n        circuit_breaker.py          ← Circuit breaker state machine\n        rate_limiter.py             ← Token bucket rate limiting\n        health_monitor.py           ← Endpoint health tracking\n        protection_middleware.py     ← Integration with delivery pipeline\n        redis_backend.py            ← Redis operations for state storage\n      delivery/\n        worker.py                   ← Modified to integrate protection\n        queue_manager.py            ← Modified for circuit-aware queueing\n      models/\n        webhook.py                  ← Extended WebhookRegistration model\n        delivery.py                 ← Extended DeliveryAttempt model\n    config/\n      protection_config.py          ← Configuration constants and validation\n    tests/\n      protection/\n        test_circuit_breaker.py\n        test_rate_limiter.py\n        test_integration.py</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Redis Backend Operations</strong> (<code>protection/redis_backend.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RedisBackend</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Redis operations for circuit breaker and rate limiting state management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis.from_url(redis_url, </span><span style=\"color:#FFAB70\">decode_responses</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_circuit_state</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current circuit breaker state for webhook endpoint.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pipe </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.pipeline()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pipe.hgetall(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"circuit:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        pipe.get(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"circuit_test_lock:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        result </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> pipe.execute()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        state_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> result[</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        test_lock </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> result[</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'state'</span><span style=\"color:#E1E4E8\">: state_data.get(</span><span style=\"color:#9ECBFF\">'state'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'closed'</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'failure_count'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(state_data.get(</span><span style=\"color:#9ECBFF\">'failure_count'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'opened_at'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(state_data.get(</span><span style=\"color:#9ECBFF\">'opened_at'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'recovery_timeout'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(state_data.get(</span><span style=\"color:#9ECBFF\">'recovery_timeout'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'test_in_progress'</span><span style=\"color:#E1E4E8\">: test_lock </span><span style=\"color:#F97583\">is</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> update_circuit_state</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, state: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, failure_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">, recovery_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Atomically update circuit breaker state.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        state_data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'state'</span><span style=\"color:#E1E4E8\">: state,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'failure_count'</span><span style=\"color:#E1E4E8\">: failure_count,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'recovery_timeout'</span><span style=\"color:#E1E4E8\">: recovery_timeout</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> state </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'open'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            state_data[</span><span style=\"color:#9ECBFF\">'opened_at'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.hset(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"circuit:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">mapping</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">state_data)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> acquire_test_lock</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, ttl_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Acquire exclusive lock for circuit breaker test delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.set(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"circuit_test_lock:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"locked\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">nx</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">ex</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">ttl_seconds)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> release_test_lock</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Release circuit breaker test lock.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis.delete(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"circuit_test_lock:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_rate_limit_tokens</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, rate_limit_rpm: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get current token count for rate limiting bucket.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Lua script for atomic token bucket operations</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lua_script </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local bucket_key = KEYS[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local refill_key = KEYS[2]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local current_time = tonumber(ARGV[1])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local rate_limit_rpm = tonumber(ARGV[2])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local max_tokens = tonumber(ARGV[3])</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local current_tokens = tonumber(redis.call('GET', bucket_key) or max_tokens)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local last_refill = tonumber(redis.call('GET', refill_key) or current_time)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        -- Calculate tokens to add based on elapsed time</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local elapsed_seconds = current_time - last_refill</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local tokens_to_add = math.floor(elapsed_seconds * rate_limit_rpm / 60)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        if tokens_to_add > 0 then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            current_tokens = math.min(max_tokens, current_tokens + tokens_to_add)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            redis.call('SET', bucket_key, current_tokens, 'EX', 3600)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            redis.call('SET', refill_key, current_time, 'EX', 3600)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        end</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        return current_tokens</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        max_tokens </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> max</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">, rate_limit_rpm </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 6</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># 10-second burst capacity</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.redis.eval(</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            lua_script,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            2</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"rate_limit:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">:tokens\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            f</span><span style=\"color:#9ECBFF\">\"rate_limit:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">:last_refill\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            current_time,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            rate_limit_rpm,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            max_tokens</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> consume_rate_limit_token</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Attempt to consume a rate limiting token.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        lua_script </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local bucket_key = KEYS[1]</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        local current_tokens = tonumber(redis.call('GET', bucket_key) or 0)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        if current_tokens > 0 then</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            redis.call('DECR', bucket_key)</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            return 1</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        else</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            return 0</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        end</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> bool</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.redis.eval(lua_script, </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"rate_limit:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">:tokens\"</span><span style=\"color:#E1E4E8\">))</span></span></code></pre></div>\n\n<p><strong>Protection Configuration</strong> (<code>config/protection_config.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> os</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreakerConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Circuit breaker configuration parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    failure_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recovery_timeout_base: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    recovery_timeout_max: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 600</span><span style=\"color:#6A737D\">  # 10 minutes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    health_score_threshold: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    half_open_test_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RateLimitConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Rate limiting configuration parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    default_rpm: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    burst_multiplier: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 2.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    refill_interval: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    retry_after_max: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3600</span><span style=\"color:#6A737D\">  # 1 hour maximum delay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    dynamic_adjustment: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HealthMonitorConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Health monitoring configuration parameters.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics_window: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 600</span><span style=\"color:#6A737D\">  # 10 minutes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metrics_retention: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 86400</span><span style=\"color:#6A737D\">  # 24 hours</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    health_check_interval: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_requests_for_score: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_protection_config</span><span style=\"color:#E1E4E8\">() -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load protection configuration from environment and defaults.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'circuit_breaker'</span><span style=\"color:#E1E4E8\">: CircuitBreakerConfig(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            failure_threshold</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'CIRCUIT_BREAKER_FAILURE_THRESHOLD'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            recovery_timeout_base</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'CIRCUIT_RECOVERY_TIMEOUT_BASE'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            recovery_timeout_max</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'CIRCUIT_RECOVERY_TIMEOUT_MAX'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">600</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'rate_limit'</span><span style=\"color:#E1E4E8\">: RateLimitConfig(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            default_rpm</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'RATE_LIMIT_DEFAULT_RPM'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            burst_multiplier</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'RATE_LIMIT_BURST_MULTIPLIER'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            dynamic_adjustment</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">os.getenv(</span><span style=\"color:#9ECBFF\">'RATE_LIMIT_DYNAMIC'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'true'</span><span style=\"color:#E1E4E8\">).lower() </span><span style=\"color:#F97583\">==</span><span style=\"color:#9ECBFF\"> 'true'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        'health_monitor'</span><span style=\"color:#E1E4E8\">: HealthMonitorConfig(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            metrics_window</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'HEALTH_METRICS_WINDOW'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">600</span><span style=\"color:#E1E4E8\">)),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            health_check_interval</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(os.getenv(</span><span style=\"color:#9ECBFF\">'HEALTH_CHECK_INTERVAL'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">30</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    }</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton-code\">Core Logic Skeleton Code</h4>\n<p><strong>Circuit Breaker State Machine</strong> (<code>protection/circuit_breaker.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitState</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CLOSED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"closed\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    OPEN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"open\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    HALF_OPEN</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"half_open\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreaker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Per-endpoint circuit breaker with state persistence.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_backend, config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_backend</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config[</span><span style=\"color:#9ECBFF\">'circuit_breaker'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> should_allow_delivery</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if delivery should be attempted based on circuit state.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get current circuit state from Redis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If state is CLOSED, return True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If state is OPEN, check if recovery timeout has passed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If recovery timeout passed, transition to HALF_OPEN and return True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: If state is HALF_OPEN, check if test lock can be acquired</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return True only if test lock acquired, False otherwise</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_success</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record successful delivery and update circuit state.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get current circuit state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If state is HALF_OPEN, transition to CLOSED</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Reset failure count to 0</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update last_success_at timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Release any active test locks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use atomic Redis operations for state changes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> record_failure</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, error_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record delivery failure and update circuit state.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get current circuit state and failure count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Increment failure count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If state is HALF_OPEN, transition to OPEN with increased timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If state is CLOSED and failure count exceeds threshold, transition to OPEN</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate next recovery timeout with exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Log circuit state changes for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_recovery_timeout</span><span style=\"color:#E1E4E8\">(self, current_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, failure_cycle: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate next recovery timeout with exponential backoff.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Start with base timeout from config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Apply exponential backoff: timeout = base * (2 ** (failure_cycle - 1))</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Cap at maximum timeout from config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return calculated timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: failure_cycle represents how many times circuit has opened</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Token Bucket Rate Limiter</strong> (<code>protection/rate_limiter.py</code>):</p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RateLimiter</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Token bucket rate limiter with Redis backend.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_backend, config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_backend</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config[</span><span style=\"color:#9ECBFF\">'rate_limit'</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> can_proceed</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, rate_limit_rpm: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, Optional[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if delivery can proceed and return delay if rate limited.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for active Retry-After lock from previous 429 responses</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If locked, return False and remaining lock time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Get current token count using redis_backend.get_rate_limit_tokens()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: If tokens available, consume one token and return True</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: If no tokens, calculate delay until next token refill</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return False with calculated delay</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_retry_after_response</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, retry_after_seconds: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle HTTP 429 response with Retry-After header.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate retry_after_seconds against maximum allowed delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Set Redis lock key with expiration matching retry_after</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Log rate limiting activation for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Optionally adjust base rate limit if dynamic adjustment enabled</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use Redis SETEX for atomic lock creation with TTL</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> adjust_rate_limit</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, response_time_ms: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, success: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Dynamically adjust rate limits based on endpoint performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if dynamic adjustment is enabled in config</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If response time &#x3C; 100ms and success, consider rate increase</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If response time > 2000ms, consider rate decrease  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate new rate limit within configured bounds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update rate limit in webhook registration if significantly changed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Log rate limit changes for monitoring</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_next_token_time</span><span style=\"color:#E1E4E8\">(self, rate_limit_rpm: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Calculate when next token will be available.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Convert RPM to tokens per second</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate seconds per token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return current time + seconds per token</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: tokens_per_second = rate_limit_rpm / 60.0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint\">Milestone Checkpoint</h4>\n<p>After implementing circuit breaker and rate limiting protection:</p>\n<ol>\n<li><strong>Start the webhook delivery system with Redis backend</strong></li>\n<li><strong>Register a test webhook endpoint that can simulate failures</strong></li>\n<li><strong>Send 10 webhook events to trigger circuit breaker</strong>:</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#B392F0\">   curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> http://localhost:8080/webhooks/test/events</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">     -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">     -d</span><span style=\"color:#9ECBFF\"> '{\"event\": \"test\", \"data\": {\"message\": \"Circuit breaker test\"}}'</span></span></code></pre></div>\n\n<ol start=\"4\">\n<li><p><strong>Expected behavior</strong>:</p>\n<ul>\n<li>First 5 delivery attempts should reach the endpoint</li>\n<li>Circuit should open after 5th consecutive failure</li>\n<li>Subsequent attempts should be rejected immediately without HTTP requests</li>\n<li>After 60 seconds, circuit should transition to half-open</li>\n<li>Single test delivery should be attempted in half-open state</li>\n</ul>\n</li>\n<li><p><strong>Verification commands</strong>:</p>\n</li>\n</ol>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\">   # Check circuit breaker state</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">   redis-cli</span><span style=\"color:#9ECBFF\"> HGETALL</span><span style=\"color:#9ECBFF\"> circuit:webhook_test_id</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # Check rate limiting tokens</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">   redis-cli</span><span style=\"color:#9ECBFF\"> GET</span><span style=\"color:#9ECBFF\"> rate_limit:webhook_test_id:tokens</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">   </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">   # View delivery attempt logs</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">   curl</span><span style=\"color:#9ECBFF\"> http://localhost:8080/webhooks/test/delivery-log</span></span></code></pre></div>\n\n<ol start=\"6\">\n<li><strong>Signs of correct implementation</strong>:<ul>\n<li>Circuit state transitions logged in application logs</li>\n<li>Rate limiting respects token bucket refill timing</li>\n<li>Health metrics update after each delivery attempt</li>\n<li>No delivery attempts during circuit open state</li>\n<li>Test delivery coordination prevents multiple simultaneous attempts</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"event-logging-and-replay\">Event Logging and Replay</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Milestone 4 (Event Log &amp; Replay) - implements comprehensive delivery audit trail with replay capability for debugging, compliance, and recovery from delivery failures</p>\n</blockquote>\n<h3 id=\"mental-model-the-digital-postal-service-archive\">Mental Model: The Digital Postal Service Archive</h3>\n<p>Think of event logging as a comprehensive postal service archive that maintains detailed records of every letter sent, every delivery attempt made, and every response received. Just as a postal service might keep detailed logs of package tracking information, delivery attempts, and customer signatures for accountability and service improvement, our webhook delivery system maintains an exhaustive audit trail of every event processed.</p>\n<p>The replay mechanism functions like a postal service&#39;s ability to resend a lost package or retry a failed delivery. When a customer calls to report a missing package, the postal service can look up the original shipment details, verify what happened, and initiate a new delivery using the same contents but with a fresh tracking number. Similarly, webhook event replay allows operators to re-deliver specific events while maintaining proper tracking and avoiding confusion with the original delivery attempts.</p>\n<p>The archive system must balance completeness with storage efficiency - a postal service cannot keep every piece of mail forever but must retain records long enough to handle disputes and provide service accountability. Our event logging system faces the same challenge: maintaining comprehensive delivery history while managing storage costs through intelligent retention and archival policies.</p>\n<h3 id=\"delivery-audit-trail-complete-event-sourcing-for-debugging-and-compliance\">Delivery Audit Trail: Complete Event Sourcing for Debugging and Compliance</h3>\n<p>The delivery audit trail serves as the system&#39;s memory, capturing every significant action and decision throughout the webhook delivery lifecycle. This comprehensive logging enables debugging complex delivery failures, provides compliance documentation for audit requirements, and supports operational analytics for system optimization.</p>\n<p><strong>Event Sourcing Architecture</strong></p>\n<p>The audit trail implements event sourcing principles where every state change is captured as an immutable event record. Unlike traditional database updates that overwrite previous values, event sourcing appends new records that describe what happened, when it happened, and what the system state was at that moment. This approach provides several critical benefits for webhook delivery systems.</p>\n<p>First, it enables complete reconstruction of any delivery&#39;s history. When debugging a complex delivery failure that involved multiple retry attempts, circuit breaker activations, and rate limiting delays, operators can replay the exact sequence of events to understand what went wrong. Second, it provides audit compliance by maintaining an immutable record of all delivery attempts, making it impossible to lose or accidentally modify historical delivery data.</p>\n<p>The event sourcing model captures multiple event types throughout the delivery lifecycle. These include delivery attempts with their HTTP responses, circuit breaker state transitions, rate limiting decisions, queue operations, and system-level events like worker crashes or configuration changes. Each event contains sufficient context to understand the system state at that moment without requiring external lookups.</p>\n<table>\n<thead>\n<tr>\n<th>Event Type</th>\n<th>Captured Data</th>\n<th>Storage Frequency</th>\n<th>Retention Period</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>delivery_attempted</code></td>\n<td>Request payload, headers, response status, timing</td>\n<td>Every HTTP attempt</td>\n<td>90 days hot, 1 year cold</td>\n</tr>\n<tr>\n<td><code>delivery_succeeded</code></td>\n<td>Final response, total attempts, duration</td>\n<td>Successful completions</td>\n<td>30 days hot, 6 months cold</td>\n</tr>\n<tr>\n<td><code>delivery_failed_permanent</code></td>\n<td>Final error, attempt history, DLQ placement</td>\n<td>Permanent failures</td>\n<td>1 year hot, 3 years cold</td>\n</tr>\n<tr>\n<td><code>circuit_breaker_opened</code></td>\n<td>Failure count, endpoint health, trigger reason</td>\n<td>State transitions</td>\n<td>6 months hot, 2 years cold</td>\n</tr>\n<tr>\n<td><code>rate_limit_applied</code></td>\n<td>Current rate, delay imposed, token bucket state</td>\n<td>Rate limiting events</td>\n<td>7 days hot, 30 days cold</td>\n</tr>\n<tr>\n<td><code>event_replayed</code></td>\n<td>Original event ID, replay reason, new delivery ID</td>\n<td>Manual replays</td>\n<td>1 year hot, permanent cold</td>\n</tr>\n<tr>\n<td><code>secret_rotated</code></td>\n<td>Webhook ID, old/new secret IDs, rotation reason</td>\n<td>Security operations</td>\n<td>2 years hot, permanent cold</td>\n</tr>\n<tr>\n<td><code>worker_crashed</code></td>\n<td>Worker instance, active deliveries, crash reason</td>\n<td>System failures</td>\n<td>30 days hot, 1 year cold</td>\n</tr>\n</tbody></table>\n<p><strong>Delivery Attempt Logging Schema</strong></p>\n<p>The <code>DeliveryAttempt</code> records form the core of the audit trail, capturing comprehensive information about each HTTP delivery attempt. These records enable detailed analysis of delivery patterns, endpoint behavior, and system performance.</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>id</code></td>\n<td>str</td>\n<td>Unique identifier for this delivery attempt</td>\n</tr>\n<tr>\n<td><code>event_id</code></td>\n<td>str</td>\n<td>Reference to the original webhook event</td>\n</tr>\n<tr>\n<td><code>webhook_id</code></td>\n<td>str</td>\n<td>Target webhook endpoint identifier</td>\n</tr>\n<tr>\n<td><code>attempt_number</code></td>\n<td>int</td>\n<td>Sequential attempt number (1-based) within this delivery</td>\n</tr>\n<tr>\n<td><code>status_code</code></td>\n<td>int</td>\n<td>HTTP response status code (null if network failure)</td>\n</tr>\n<tr>\n<td><code>response_time</code></td>\n<td>float</td>\n<td>Total request duration in milliseconds</td>\n</tr>\n<tr>\n<td><code>error_message</code></td>\n<td>str</td>\n<td>Detailed error description for failed attempts</td>\n</tr>\n<tr>\n<td><code>response_headers</code></td>\n<td>json</td>\n<td>Complete HTTP response headers for analysis</td>\n</tr>\n<tr>\n<td><code>response_body</code></td>\n<td>str</td>\n<td>Response body (truncated if exceeds size limit)</td>\n</tr>\n<tr>\n<td><code>request_headers</code></td>\n<td>json</td>\n<td>HTTP request headers sent to endpoint</td>\n</tr>\n<tr>\n<td><code>request_payload</code></td>\n<td>str</td>\n<td>Complete request payload (may be compressed)</td>\n</tr>\n<tr>\n<td><code>attempted_at</code></td>\n<td>datetime</td>\n<td>When the HTTP request was initiated</td>\n</tr>\n<tr>\n<td><code>completed_at</code></td>\n<td>datetime</td>\n<td>When the response was received or timeout occurred</td>\n</tr>\n<tr>\n<td><code>delivery_duration</code></td>\n<td>int</td>\n<td>Time from queue claim to attempt completion</td>\n</tr>\n<tr>\n<td><code>worker_instance</code></td>\n<td>str</td>\n<td>Identifier of worker that processed this attempt</td>\n</tr>\n<tr>\n<td><code>circuit_breaker_triggered</code></td>\n<td>bool</td>\n<td>Whether circuit breaker prevented this attempt</td>\n</tr>\n</tbody></table>\n<p>The schema design balances comprehensive logging with storage efficiency. Response bodies are truncated at 10KB to prevent storage explosion from verbose API responses, while still capturing enough information for debugging. Request payloads are stored with compression to reduce storage costs for large webhook events.</p>\n<p><strong>Time-Series Optimization Strategy</strong></p>\n<p>Webhook delivery logs exhibit strong time-series characteristics where recent data is accessed frequently for debugging and monitoring, while historical data serves primarily archival and compliance purposes. The logging system optimizes for this access pattern through a multi-tiered storage approach.</p>\n<p>Hot storage maintains the most recent 30-90 days of delivery data in high-performance databases optimized for analytical queries. This tier uses time-series databases like InfluxDB or time-partitioned PostgreSQL tables that enable fast range queries and aggregations. The hot tier supports real-time debugging, monitoring dashboards, and operational analytics.</p>\n<p>Warm storage archives data from 30 days to 1-3 years in compressed formats optimized for occasional access. This tier typically uses object storage like S3 with intelligent tiering to automatically migrate less-accessed data to cheaper storage classes. Warm storage supports compliance audits, historical analysis, and replay operations that reference older events.</p>\n<p>Cold storage provides long-term archival for data older than 1-3 years using the most cost-effective storage available. This tier may use glacier storage or tape backup systems with retrieval times measured in hours rather than seconds. Cold storage primarily serves legal compliance and forensic analysis requirements.</p>\n<blockquote>\n<p><strong>Decision: Time-Series Partitioning Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook delivery logs grow continuously and exhibit clear time-based access patterns where recent data is accessed frequently while historical data serves primarily compliance purposes</li>\n<li><strong>Options Considered</strong>: Single table with indexes, hash partitioning by webhook ID, time-based partitioning by delivery date</li>\n<li><strong>Decision</strong>: Time-based partitioning with monthly partitions and automated migration between storage tiers</li>\n<li><strong>Rationale</strong>: Time-based partitioning aligns with natural access patterns, enables efficient data lifecycle management, supports fast queries on recent data while maintaining cost-effective long-term storage</li>\n<li><strong>Consequences</strong>: Requires partition management automation, enables predictable storage cost scaling, simplifies backup and archival processes, may complicate cross-partition queries</li>\n</ul>\n</blockquote>\n<h3 id=\"event-replay-mechanism-safe-re-delivery-with-deduplication-and-rate-limit-respect\">Event Replay Mechanism: Safe Re-delivery with Deduplication and Rate Limit Respect</h3>\n<p>Event replay provides operators with the ability to re-deliver specific webhook events after resolving delivery failures or endpoint issues. The replay mechanism must handle this operation safely without overwhelming recovered endpoints, creating duplicate deliveries, or bypassing established security and rate limiting controls.</p>\n<p><strong>Replay Safety and Deduplication</strong></p>\n<p>Safe event replay requires careful handling of idempotency to prevent duplicate processing by webhook endpoints. When an event is replayed, the receiving endpoint must be able to distinguish between the original delivery attempt and the replay, even if both requests contain identical payloads.</p>\n<p>The system generates a new delivery identifier for each replay operation while maintaining references to the original event. This approach provides clear audit trails showing the relationship between original and replayed deliveries while giving endpoints the information needed to implement proper deduplication.</p>\n<p>The HMAC signature generation for replayed events includes additional metadata to ensure uniqueness while maintaining security. The signature calculation incorporates the original event ID, the new delivery ID, and a replay timestamp to create a signature that is cryptographically distinct from the original delivery.</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Replay Signature Components:\n- Original event payload (unchanged)\n- Original event ID and timestamp\n- New delivery ID and replay timestamp\n- Replay reason and operator identification\n- Webhook secret (current active secret, not original)</code></pre></div>\n\n<p>Headers sent with replayed events include explicit replay indicators that help endpoints implement appropriate handling. The <code>X-Webhook-Replay</code> header contains the original event ID and delivery timestamp, while <code>X-Webhook-Delivery-Id</code> contains the new delivery identifier for this replay attempt.</p>\n<p><strong>Replay Rate Limiting and Endpoint Protection</strong></p>\n<p>Replay operations must respect the same rate limiting and circuit breaker protections applied to normal webhook deliveries. This prevents operators from accidentally overwhelming endpoints through bulk replay operations and maintains the system&#39;s protective mechanisms.</p>\n<p>When multiple events are selected for replay, the system schedules them through the normal delivery queues rather than attempting immediate delivery. This approach ensures that replayed events compete fairly with new events for delivery capacity and respect per-endpoint rate limits.</p>\n<table>\n<thead>\n<tr>\n<th>Replay Scenario</th>\n<th>Rate Limiting Behavior</th>\n<th>Circuit Breaker Behavior</th>\n<th>Scheduling Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Single event replay</td>\n<td>Uses current endpoint rate limit</td>\n<td>Respects current circuit state</td>\n<td>Immediate queue placement</td>\n</tr>\n<tr>\n<td>Bulk replay (&lt; 100 events)</td>\n<td>Spreads over 1-hour window</td>\n<td>Halts if circuit opens during replay</td>\n<td>Gradual queue placement</td>\n</tr>\n<tr>\n<td>Bulk replay (&gt; 100 events)</td>\n<td>Spreads over 24-hour window</td>\n<td>Requires manual circuit override</td>\n<td>Background batch processing</td>\n</tr>\n<tr>\n<td>Historical replay (&gt; 30 days old)</td>\n<td>Reduced rate limit (50% of normal)</td>\n<td>Requires operator acknowledgment</td>\n<td>Low priority queue</td>\n</tr>\n</tbody></table>\n<p>The replay system includes safeguards against replay storms where operators accidentally trigger massive replay operations. Bulk replay requests require explicit confirmation and are processed in the background with progress reporting. If an endpoint&#39;s circuit breaker opens during a bulk replay operation, the system pauses the replay and alerts the operator rather than continuing to attempt deliveries to a known-failing endpoint.</p>\n<p><strong>Replay Audit and Metadata Tracking</strong></p>\n<p>Every replay operation creates comprehensive audit records that capture the replay decision, execution, and results. This audit trail helps operators understand the impact of replay operations and provides accountability for manual system interventions.</p>\n<table>\n<thead>\n<tr>\n<th>Replay Audit Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>replay_id</code></td>\n<td>str</td>\n<td>Unique identifier for this replay operation</td>\n</tr>\n<tr>\n<td><code>operator_id</code></td>\n<td>str</td>\n<td>Identity of operator who initiated replay</td>\n</tr>\n<tr>\n<td><code>original_event_ids</code></td>\n<td>list</td>\n<td>Events selected for replay</td>\n</tr>\n<tr>\n<td><code>replay_reason</code></td>\n<td>str</td>\n<td>Operator-provided justification for replay</td>\n</tr>\n<tr>\n<td><code>replay_requested_at</code></td>\n<td>datetime</td>\n<td>When replay was requested</td>\n</tr>\n<tr>\n<td><code>replay_completed_at</code></td>\n<td>datetime</td>\n<td>When all replay deliveries finished</td>\n</tr>\n<tr>\n<td><code>events_replayed</code></td>\n<td>int</td>\n<td>Number of events successfully replayed</td>\n</tr>\n<tr>\n<td><code>events_failed_replay</code></td>\n<td>int</td>\n<td>Number of events that failed during replay</td>\n</tr>\n<tr>\n<td><code>endpoints_affected</code></td>\n<td>list</td>\n<td>Webhook endpoints that received replayed events</td>\n</tr>\n<tr>\n<td><code>delivery_ids_generated</code></td>\n<td>list</td>\n<td>New delivery IDs created for replay attempts</td>\n</tr>\n</tbody></table>\n<p>The replay metadata enables operators to track the effectiveness of replay operations and understand their impact on system performance. This information supports decision-making about future replay strategies and helps identify patterns in delivery failures that might require systemic fixes rather than individual event replay.</p>\n<blockquote>\n<p><strong>Decision: Replay Deduplication Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Replayed events must be distinguishable from original deliveries to prevent duplicate processing while maintaining security through proper signature validation</li>\n<li><strong>Options Considered</strong>: Same delivery ID with replay flag, new delivery ID with original reference, separate replay-specific endpoints</li>\n<li><strong>Decision</strong>: New delivery ID for each replay with original event metadata in headers and signature</li>\n<li><strong>Rationale</strong>: Provides clear audit separation between original and replayed deliveries, enables endpoint deduplication through delivery ID tracking, maintains signature security while indicating replay context</li>\n<li><strong>Consequences</strong>: Requires endpoint updates to handle replay headers, creates additional audit complexity, enables precise replay tracking and prevents accidental duplicate processing</li>\n</ul>\n</blockquote>\n<h3 id=\"log-retention-and-archival-time-series-optimization-with-cold-storage-migration\">Log Retention and Archival: Time-Series Optimization with Cold Storage Migration</h3>\n<p>Webhook delivery logs accumulate rapidly in high-volume systems, requiring sophisticated retention and archival strategies to balance operational needs with storage costs. The system must maintain immediate access to recent delivery data while providing cost-effective long-term storage for compliance and forensic analysis.</p>\n<p><strong>Hierarchical Storage Management</strong></p>\n<p>The log retention system implements hierarchical storage management (HSM) that automatically migrates data between storage tiers based on age and access patterns. This approach optimizes costs while maintaining appropriate access performance for different use cases.</p>\n<p>The hot storage tier maintains 30-90 days of delivery logs in high-performance databases optimized for analytical queries and real-time access. This tier uses SSD storage with aggressive caching and supports the real-time monitoring, debugging, and alerting operations that require immediate data access.</p>\n<p>Hot tier storage uses time-partitioned tables that enable efficient pruning and migration operations. Daily partitions allow granular control over data movement while maintaining query performance through partition elimination. The partitioning strategy aligns with natural query patterns where most operational queries focus on recent time windows.</p>\n<table>\n<thead>\n<tr>\n<th>Storage Tier</th>\n<th>Duration</th>\n<th>Access Time</th>\n<th>Storage Cost</th>\n<th>Query Performance</th>\n<th>Use Cases</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hot (SSD)</td>\n<td>30-90 days</td>\n<td>&lt; 100ms</td>\n<td>High ($0.10/GB/month)</td>\n<td>Excellent</td>\n<td>Real-time debugging, monitoring dashboards</td>\n</tr>\n<tr>\n<td>Warm (Standard)</td>\n<td>90 days - 1 year</td>\n<td>&lt; 1 second</td>\n<td>Medium ($0.05/GB/month)</td>\n<td>Good</td>\n<td>Historical analysis, replay operations</td>\n</tr>\n<tr>\n<td>Cold (Archive)</td>\n<td>1-3 years</td>\n<td>&lt; 1 minute</td>\n<td>Low ($0.01/GB/month)</td>\n<td>Fair</td>\n<td>Compliance audits, forensic analysis</td>\n</tr>\n<tr>\n<td>Glacier (Deep Archive)</td>\n<td>&gt; 3 years</td>\n<td>&lt; 4 hours</td>\n<td>Very Low ($0.002/GB/month)</td>\n<td>Restore required</td>\n<td>Legal compliance, long-term forensics</td>\n</tr>\n</tbody></table>\n<p><strong>Automated Migration Pipelines</strong></p>\n<p>Data migration between storage tiers operates through automated pipelines that run continuously to maintain appropriate data distribution. These pipelines handle compression, format optimization, and metadata preservation during migration operations.</p>\n<p>The migration process preserves data integrity through checksums and validation steps at each tier transition. Before removing data from a higher-performance tier, the system verifies successful migration and validates that the archived data can be retrieved and decompressed correctly.</p>\n<p>Migration operations run during low-traffic periods to minimize impact on operational performance. The system monitors query patterns and adjusts migration timing to avoid moving frequently accessed data during peak usage periods.</p>\n<p>Data compression strategies vary by storage tier to optimize for access patterns and cost requirements. Hot storage uses minimal compression to maintain query performance, warm storage applies medium compression for balanced access and cost, while cold storage uses aggressive compression to minimize storage costs.</p>\n<table>\n<thead>\n<tr>\n<th>Migration Trigger</th>\n<th>Source Tier</th>\n<th>Target Tier</th>\n<th>Compression Ratio</th>\n<th>Validation Process</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Age &gt; 30 days</td>\n<td>Hot</td>\n<td>Warm</td>\n<td>2:1</td>\n<td>Checksum validation, sample query test</td>\n</tr>\n<tr>\n<td>Age &gt; 1 year</td>\n<td>Warm</td>\n<td>Cold</td>\n<td>5:1</td>\n<td>Full data integrity check, restore test</td>\n</tr>\n<tr>\n<td>Age &gt; 3 years</td>\n<td>Cold</td>\n<td>Glacier</td>\n<td>8:1</td>\n<td>Cryptographic hash validation</td>\n</tr>\n<tr>\n<td>Access &lt; 1/month</td>\n<td>Any</td>\n<td>Lower tier</td>\n<td>Varies</td>\n<td>Access pattern analysis</td>\n</tr>\n</tbody></table>\n<p><strong>Retention Policy Configuration</strong></p>\n<p>Retention policies provide flexible control over data lifecycle management while ensuring compliance with legal and business requirements. The system supports multiple retention schedules that can be configured per webhook, event type, or organizational policy.</p>\n<p>Default retention policies balance operational needs with storage costs, but organizations can customize retention based on specific compliance requirements or business needs. Some industries require longer retention periods for audit purposes, while others prioritize cost optimization through aggressive data lifecycle management.</p>\n<p>The retention configuration supports both time-based and size-based policies. Time-based policies automatically archive or delete data after specific durations, while size-based policies manage storage consumption by archiving oldest data when storage limits are approached.</p>\n<p>Retention policies include legal hold capabilities that prevent automatic deletion of data involved in legal proceedings or compliance investigations. When a legal hold is placed, the system suspends normal retention processing for affected data until the hold is released.</p>\n<table>\n<thead>\n<tr>\n<th>Policy Type</th>\n<th>Configuration Options</th>\n<th>Enforcement Method</th>\n<th>Override Capabilities</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Time-based</td>\n<td>Hot (30-180 days), Warm (1-5 years), Cold (3-10 years)</td>\n<td>Automated daily processing</td>\n<td>Legal hold suspension</td>\n</tr>\n<tr>\n<td>Size-based</td>\n<td>Per-webhook limits, total system limits</td>\n<td>Triggered by storage monitoring</td>\n<td>Emergency retention extension</td>\n</tr>\n<tr>\n<td>Compliance-based</td>\n<td>Industry-specific requirements (PCI, HIPAA, SOX)</td>\n<td>Regulatory compliance engine</td>\n<td>Audit-approved modifications only</td>\n</tr>\n<tr>\n<td>Event-specific</td>\n<td>Critical vs normal event classification</td>\n<td>Event metadata-driven</td>\n<td>Manual operator override</td>\n</tr>\n</tbody></table>\n<h3 id=\"common-logging-pitfalls\">Common Logging Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Unbounded Log Growth Leading to Storage Explosion</strong></p>\n<p>Many webhook delivery implementations start with simple logging that captures every delivery attempt without considering long-term storage implications. In high-volume systems processing millions of webhooks daily, this approach quickly leads to storage costs that exceed the entire infrastructure budget and query performance degradation that makes the logs unusable for debugging.</p>\n<p>The root cause is treating webhook logs like traditional application logs with simple append-only behavior. Unlike application logs that are primarily used for debugging during development, webhook delivery logs serve operational, compliance, and business intelligence purposes that require different retention and access strategies.</p>\n<p>To prevent storage explosion, implement tiered storage from the beginning rather than attempting to retrofit it after storage costs become problematic. Design log schemas to support compression by avoiding highly variable fields that compress poorly, and implement automated retention policies that enforce data lifecycle management without manual intervention.</p>\n<p>Establish storage budgets and monitoring alerts that trigger when log storage grows beyond expected patterns. This early warning system prevents surprise storage costs and enables proactive capacity planning for log infrastructure.</p>\n<p>⚠️ <strong>Pitfall: Replay Storms Overwhelming Recovered Endpoints</strong></p>\n<p>Operators often attempt to resolve delivery failures through bulk event replay without considering the cumulative load this places on recovered endpoints. When an endpoint experiences downtime and accumulates hundreds of failed deliveries, replaying all events simultaneously can overwhelm the recovered endpoint and cause it to fail again.</p>\n<p>This problem is particularly common when operators bypass normal rate limiting and circuit breaker protections during replay operations, believing that these protective mechanisms are unnecessary for retry operations. The result is often a cycle where replay operations trigger new failures that require additional replay operations.</p>\n<p>Implement replay throttling that spreads replayed events over time windows appropriate to the endpoint&#39;s normal capacity. Use the same rate limiting infrastructure for replay operations that protects normal webhook deliveries, and consider implementing reduced rate limits for bulk replay operations to provide additional safety margin.</p>\n<p>Design replay interfaces that encourage operators to start with small batches and verify endpoint behavior before proceeding with larger replay operations. Provide clear feedback about replay progress and endpoint health during bulk operations to help operators make informed decisions about continuing or pausing replay processes.</p>\n<p>⚠️ <strong>Pitfall: Inadequate Retention Policy Leading to Compliance Violations</strong></p>\n<p>Organizations often implement webhook logging without consulting legal and compliance teams about data retention requirements. This oversight can lead to either premature data deletion that violates regulatory requirements or excessive data retention that increases privacy risks and storage costs.</p>\n<p>Different types of webhook events may have different retention requirements based on the data they contain and the business processes they support. Payment webhooks might require longer retention for financial auditing, while user activity webhooks might need shorter retention to comply with privacy regulations.</p>\n<p>Establish retention policies through collaboration between engineering, legal, and compliance teams before implementing the logging system. Document the business and legal justification for each retention period to support future audits and policy reviews.</p>\n<p>Implement retention policy enforcement that is auditable and reversible. Avoid hard deletion in favor of archival strategies that can restore data if retention policies change or legal holds are imposed on historical data.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Replay Deduplication Causing Business Logic Errors</strong></p>\n<p>Webhook endpoints that do not properly implement idempotency checking can experience significant business logic errors when events are replayed. For example, replaying payment confirmation webhooks might trigger duplicate payment processing, or replaying user registration webhooks might create multiple user accounts.</p>\n<p>The problem is compounded when the webhook delivery system does not provide sufficient metadata for endpoints to implement proper deduplication. Without delivery IDs, replay indicators, or original event timestamps, endpoints cannot reliably distinguish between legitimate duplicate events and replayed events.</p>\n<p>Design replay mechanisms to include comprehensive metadata that enables endpoint deduplication. Include original event IDs, delivery IDs, replay flags, and original delivery timestamps in replay requests to give endpoints all information needed for proper duplicate detection.</p>\n<p>Provide clear documentation and examples showing how endpoints should implement idempotency checking using the replay metadata. Consider offering client libraries that handle deduplication automatically to reduce the implementation burden on webhook consumers.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The event logging and replay system requires careful balance between comprehensive data capture and system performance. This implementation provides production-ready logging infrastructure with efficient storage management and safe replay capabilities.</p>\n<p><strong>Technology Recommendations</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Time-Series Database</td>\n<td>PostgreSQL with time partitions</td>\n<td>InfluxDB or TimescaleDB</td>\n</tr>\n<tr>\n<td>Object Storage</td>\n<td>Local filesystem with rotation</td>\n<td>AWS S3 with Intelligent Tiering</td>\n</tr>\n<tr>\n<td>Data Pipeline</td>\n<td>Celery background tasks</td>\n<td>Apache Kafka with Kafka Streams</td>\n</tr>\n<tr>\n<td>Compression</td>\n<td>gzip built-in compression</td>\n<td>Parquet with Snappy compression</td>\n</tr>\n<tr>\n<td>Query Interface</td>\n<td>SQL queries with indexes</td>\n<td>Grafana with pre-built dashboards</td>\n</tr>\n</tbody></table>\n<p><strong>File Structure</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-system/\n├── internal/\n│   ├── logging/\n│   │   ├── audit_logger.py           ← Main logging interface\n│   │   ├── storage_manager.py        ← Tiered storage management\n│   │   ├── replay_engine.py          ← Event replay functionality\n│   │   └── retention_policy.py       ← Data lifecycle management\n│   ├── storage/\n│   │   ├── time_series_db.py         ← Time-series database interface\n│   │   └── object_store.py           ← Object storage interface\n│   └── models/\n│       ├── delivery_attempt.py       ← Delivery attempt data model\n│       └── replay_request.py         ← Replay request data model\n├── scripts/\n│   ├── migrate_logs.py               ← Storage tier migration\n│   └── cleanup_expired_logs.py       ← Retention policy enforcement\n└── tests/\n    ├── test_audit_logging.py\n    ├── test_replay_engine.py\n    └── test_storage_migration.py</code></pre></div>\n\n<p><strong>Audit Logger Infrastructure (Complete Implementation)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Any</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass, asdict</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> gzip</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..storage.time_series_db </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> TimeSeriesDB</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..storage.object_store </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ObjectStore</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models.delivery_attempt </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DeliveryAttempt</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..config </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookConfig</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AuditEvent</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Base class for all audit events in the webhook system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_type: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    timestamp: datetime</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> to_json</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Serialize audit event to JSON string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> asdict(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        data[</span><span style=\"color:#9ECBFF\">'timestamp'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.timestamp.isoformat()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> json.dumps(data, </span><span style=\"color:#FFAB70\">separators</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">','</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">':'</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @</span><span style=\"color:#79B8FF\">classmethod</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> from_json</span><span style=\"color:#E1E4E8\">(cls, json_str: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#9ECBFF\">'AuditEvent'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Deserialize audit event from JSON string.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        data </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> json.loads(json_str)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        data[</span><span style=\"color:#9ECBFF\">'timestamp'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.fromisoformat(data[</span><span style=\"color:#9ECBFF\">'timestamp'</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> cls</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">**</span><span style=\"color:#E1E4E8\">data)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> AuditLogger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Comprehensive audit logging for webhook delivery system.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Captures all significant events in the webhook delivery lifecycle</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    including delivery attempts, circuit breaker changes, replay operations,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    and system-level events. Implements tiered storage with automatic</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    migration and retention policy enforcement.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: WebhookConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.time_series_db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TimeSeriesDB(config.database_url)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ObjectStore(config.storage_config)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Storage tier thresholds</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.hot_retention_days </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.warm_retention_days </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 365</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.cold_retention_days </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1095</span><span style=\"color:#6A737D\">  # 3 years</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log_delivery_attempt</span><span style=\"color:#E1E4E8\">(self, attempt: DeliveryAttempt) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Log a complete delivery attempt with all request/response details.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Captures comprehensive delivery information for debugging and audit</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        purposes. Compresses large payloads and truncates response bodies</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        to prevent storage explosion while maintaining debugging utility.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate attempt data and ensure required fields are present</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Compress large payloads and truncate response bodies > 10KB</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Calculate payload hash for deduplication and integrity checking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Insert attempt record into hot storage time-series database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Create audit event for delivery attempt and queue for processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update delivery statistics and health metrics asynchronously</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use gzip for payload compression, SHA-256 for payload hashing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log_circuit_breaker_event</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, event_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  previous_state: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, new_state: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                  failure_count: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, metadata: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log circuit breaker state transitions with context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create circuit breaker audit event with state transition details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Include failure count, error patterns, and trigger conditions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Record timing information for circuit breaker analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store event in hot storage for immediate monitoring access</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Include error type distribution in metadata for pattern analysis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> log_replay_operation</span><span style=\"color:#E1E4E8\">(self, replay_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, operator_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           event_ids: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">], reason: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log event replay operations with full audit context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create replay audit event with operator identification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Record all event IDs selected for replay with selection criteria</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store replay justification and approval workflow information</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate unique tracking ID for monitoring replay progress</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Include original failure reasons for replayed events in metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> delivery_timing_context</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Context manager for timing delivery operations.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> datetime.utcnow()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            yield</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            duration </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.perf_counter() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">._log_timing_event(event_id, webhook_id, start_timestamp, duration)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _log_timing_event</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         start_time: datetime, duration: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Log delivery timing information for performance analysis.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create timing audit event with precise duration measurements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Include queue wait time, processing time, and network time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store timing data in time-series format for trend analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Update performance metrics and SLA tracking</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> StorageManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Manages tiered storage and automated data migration for audit logs.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Implements hierarchical storage management with automatic migration</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    between hot, warm, and cold storage tiers based on age and access</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    patterns. Includes retention policy enforcement and cost optimization.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: WebhookConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.time_series_db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TimeSeriesDB(config.database_url)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.object_store </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> ObjectStore(config.storage_config)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> migrate_to_warm_storage</span><span style=\"color:#E1E4E8\">(self, cutoff_date: datetime) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Migrate delivery logs older than cutoff_date to warm storage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns number of records migrated.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Query hot storage for delivery attempts older than cutoff_date</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Batch process records for efficient migration (1000 records/batch)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compress and serialize records for warm storage format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Upload compressed batches to object storage with metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify successful upload before removing from hot storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update migration tracking and storage usage statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use parquet format for efficient analytical queries on warm data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> migrate_to_cold_storage</span><span style=\"color:#E1E4E8\">(self, cutoff_date: datetime) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Migrate logs from warm to cold storage with maximum compression.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Identify warm storage files eligible for cold migration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Apply maximum compression (gzip level 9 or better)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Generate cryptographic checksums for integrity verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Transfer to cold storage with appropriate metadata tags</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify cold storage integrity before removing warm copies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Consider using columnar compression for better ratios</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> enforce_retention_policy</span><span style=\"color:#E1E4E8\">(self, policy_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Enforce retention policies across all storage tiers.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns statistics about data processed and deleted.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check for legal holds that prevent normal retention processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify data eligible for deletion based on retention policies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Archive data requiring longer retention to appropriate tiers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Permanently delete data past maximum retention periods</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate retention compliance report with deletion statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Update storage usage metrics and cost tracking</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Always create backup snapshots before permanent deletion</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Event Replay Engine (Core Logic Skeleton)</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models.webhook_event </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookEvent</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..models.delivery_attempt </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DeliveryAttempt</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..delivery.queue_manager </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueueManager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> ..security.signature </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> generate_hmac_signature</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> .audit_logger </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> AuditLogger</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ReplayRequest</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a request to replay specific webhook events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    replay_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    operator_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    event_ids: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    reason: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    requested_at: datetime</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_override: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_breaker_override: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ReplayEngine</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Safe event replay with deduplication and rate limiting.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Handles manual replay of webhook events while maintaining all</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    protective mechanisms including rate limiting, circuit breakers,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    and proper audit trails. Provides safeguards against replay storms</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    and ensures endpoint deduplication support.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, queue_manager: QueueManager, audit_logger: AuditLogger):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.queue_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.audit_logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> audit_logger</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> replay_events</span><span style=\"color:#E1E4E8\">(self, replay_request: ReplayRequest) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Replay specified events with full safety checks and audit logging.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns replay operation results with success/failure statistics.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate replay request and check operator permissions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Retrieve original events and verify they exist and are replayable</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check endpoint circuit breaker states unless override specified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Generate new delivery IDs while preserving original event references</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate replay-specific HMAC signatures with replay metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Schedule replayed events through normal delivery queues with rate limiting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Create comprehensive audit records for replay operation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Return replay tracking information for monitoring progress</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Include original delivery failure reasons in replay audit metadata</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_replay_safety</span><span style=\"color:#E1E4E8\">(self, event_ids: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Tuple[</span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Validate that events are safe to replay.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns (is_safe, list_of_issues) where issues explain any problems.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if events still exist and haven't been archived to cold storage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify target webhooks are still active and not deleted</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check for recent successful deliveries that might indicate duplicates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Validate that payload sizes won't overwhelm endpoints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Ensure replay won't violate daily/hourly rate limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Check for any legal holds or compliance restrictions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Consider implementing cooling-off periods between replays</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_replay_headers</span><span style=\"color:#E1E4E8\">(self, original_event: WebhookEvent, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               replay_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, delivery_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate HTTP headers for replayed webhook delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Include standard webhook headers (delivery ID, timestamp, signature)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add replay-specific headers identifying original event and delivery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Include replay reason and timestamp for endpoint deduplication</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Add replay tracking information for debugging purposes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Ensure headers provide all information needed for endpoint idempotency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use X-Webhook-Replay header to clearly mark replayed events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> schedule_bulk_replay</span><span style=\"color:#E1E4E8\">(self, replay_request: ReplayRequest, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           batch_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Schedule bulk replay operation with progress tracking.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Divide replay request into manageable batches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create background task for processing replay batches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Implement progress tracking and operator notification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Schedule batches with appropriate delays to respect rate limits</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle partial failures and provide retry options for failed batches</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Generate final report with complete replay statistics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use exponential backoff between batches if circuit breakers activate</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoint</strong></p>\n<p>After implementing the event logging and replay system, verify correct operation:</p>\n<p><strong>Testing Event Logging:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Generate test webhook deliveries with various outcomes</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_audit_logging.py::test_delivery_attempt_logging</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: All delivery attempts logged with complete metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify: Check time-series database for delivery_attempt records</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify: Confirm payload compression and response truncation working</span></span></code></pre></div>\n\n<p><strong>Testing Storage Migration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Trigger storage tier migration</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> scripts/migrate_logs.py</span><span style=\"color:#79B8FF\"> --dry-run</span><span style=\"color:#79B8FF\"> --cutoff-days</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: Migration plan showing records to move and storage savings</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify: Confirm migration preserves data integrity through checksums</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify: Validate compressed data can be queried and restored</span></span></code></pre></div>\n\n<p><strong>Testing Event Replay:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Replay failed webhook events</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> http://localhost:8080/api/v1/replay</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"event_ids\": [\"event-123\", \"event-456\"],</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"reason\": \"Endpoint recovered after maintenance\",</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"operator_id\": \"ops-team\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">  }'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected output: Replay tracking ID and operation status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify: Replayed events have new delivery IDs and replay headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Verify: Original rate limits and circuit breakers respected</span></span></code></pre></div>\n\n<p><strong>Debugging Tips</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Log storage growing too fast</td>\n<td>Missing compression or retention</td>\n<td>Check storage growth rate vs delivery volume</td>\n<td>Implement tiered storage migration</td>\n</tr>\n<tr>\n<td>Replay events not delivered</td>\n<td>Circuit breaker blocking replay</td>\n<td>Check circuit breaker states for target webhooks</td>\n<td>Reset circuit breaker or use override flag</td>\n</tr>\n<tr>\n<td>Cannot query historical logs</td>\n<td>Data migrated to slow storage</td>\n<td>Check storage tier of requested time range</td>\n<td>Restore from archive or use async query</td>\n</tr>\n<tr>\n<td>Duplicate events after replay</td>\n<td>Missing replay deduplication</td>\n<td>Check endpoint logs for delivery ID handling</td>\n<td>Update endpoint to check X-Webhook-Replay header</td>\n</tr>\n</tbody></table>\n<h2 id=\"component-interactions-and-data-flow\">Component Interactions and Data Flow</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) - this section describes how components from webhook registration through event logging interact to provide end-to-end reliable webhook delivery</p>\n</blockquote>\n<h3 id=\"mental-model-the-orchestrated-assembly-line\">Mental Model: The Orchestrated Assembly Line</h3>\n<p>Think of the webhook delivery system as a sophisticated assembly line in a high-tech manufacturing plant. The <strong>event ingestion flow</strong> is like the receiving dock where raw materials (webhook events) arrive and get sorted, labeled, and prepared for processing. Each event gets a work order with delivery instructions and security credentials. The <strong>delivery processing flow</strong> is the main assembly line where workers (delivery workers) pick up prepared events, perform the actual delivery work, and handle quality control checks. The <strong>failure recovery flow</strong> is like the quality assurance and maintenance department - when something goes wrong on the assembly line, they step in to diagnose problems, reroute work, and get production back on track.</p>\n<p>Just as an assembly line has conveyor belts, quality checkpoints, and feedback loops, our webhook system has message queues, circuit breakers, and retry mechanisms. The key insight is that each component has a specific role, but they must work together in precise coordination to ensure no event gets lost and every delivery attempt is tracked and recoverable.</p>\n<h3 id=\"event-ingestion-flow-webhook-lookup-signature-generation-and-queue-placement\">Event Ingestion Flow: Webhook lookup, signature generation, and queue placement</h3>\n<p>The event ingestion flow represents the entry point where external events enter the webhook delivery system and get transformed into deliverable webhook notifications. This flow bridges the gap between the event source (your application) and the delivery infrastructure, ensuring that every event is properly authenticated, routed, and queued for reliable delivery.</p>\n<h4 id=\"event-reception-and-validation\">Event Reception and Validation</h4>\n<p>When an event enters the webhook delivery system, the ingestion process begins with fundamental validation and preparation steps. The system receives an event payload along with metadata indicating the event type and source information. Think of this as a post office receiving a letter - before it can be delivered, the postal service needs to verify the destination address exists and prepare the envelope with proper postage and routing information.</p>\n<p>The ingestion flow starts by looking up all webhook registrations that have subscribed to the specific event type. This lookup process queries the <code>WebhookRegistry</code> to find active webhook endpoints where the <code>events</code> field contains the incoming event type and the <code>active</code> field is true. The system must handle the case where no webhooks are subscribed to an event type - this is not an error condition, but rather a normal scenario that requires logging for observability.</p>\n<table>\n<thead>\n<tr>\n<th>Validation Step</th>\n<th>Purpose</th>\n<th>Failure Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event type validation</td>\n<td>Ensure event type is recognized by system</td>\n<td>Log warning, continue processing</td>\n</tr>\n<tr>\n<td>Payload size check</td>\n<td>Prevent oversized payloads from overwhelming endpoints</td>\n<td>Reject event, return error to source</td>\n</tr>\n<tr>\n<td>Content type validation</td>\n<td>Verify payload can be serialized as JSON</td>\n<td>Reject event, return error to source</td>\n</tr>\n<tr>\n<td>Required metadata validation</td>\n<td>Ensure source, timestamp, and idempotency key present</td>\n<td>Auto-generate missing non-critical fields</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Event Deduplication Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Events may be submitted multiple times due to retries from the event source</li>\n<li><strong>Options Considered</strong>: 1) No deduplication, 2) Idempotency keys with time windows, 3) Content-based hashing</li>\n<li><strong>Decision</strong>: Idempotency keys with 24-hour time windows</li>\n<li><strong>Rationale</strong>: Provides protection against duplicate submissions while allowing intentional re-delivery of identical content after reasonable time periods</li>\n<li><strong>Consequences</strong>: Requires storing idempotency keys in fast-access storage (Redis), but prevents duplicate webhook deliveries during normal retry scenarios</li>\n</ul>\n</blockquote>\n<h4 id=\"webhook-event-creation\">Webhook Event Creation</h4>\n<p>Once validation passes, the system creates a <code>WebhookEvent</code> record for each webhook registration that should receive the event. This step transforms a single incoming event into multiple deliverable webhook events, each customized for its target endpoint. The event creation process generates unique identifiers, calculates delivery priorities, and sets expiration times based on webhook configuration.</p>\n<p>The <code>WebhookEvent</code> creation process follows these steps:</p>\n<ol>\n<li>Generate a unique <code>event_id</code> using a UUID4 to ensure global uniqueness across the distributed system</li>\n<li>Copy the event payload and metadata, ensuring the payload remains immutable during processing</li>\n<li>Set the initial <code>delivery_status</code> to &quot;pending&quot; to indicate the event awaits processing</li>\n<li>Calculate the <code>scheduled_at</code> timestamp based on the webhook&#39;s delivery preferences and current system load</li>\n<li>Set the <code>expires_at</code> timestamp using the webhook&#39;s configured expiration policy or system default</li>\n<li>Generate an <code>idempotency_key</code> combining the source event&#39;s idempotency key with the webhook ID</li>\n<li>Assign a <code>priority</code> value based on the event type, webhook tier, and business rules</li>\n<li>Initialize <code>attempt_count</code> to zero since no delivery attempts have been made yet</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>WebhookEvent Field</th>\n<th>Population Logic</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>id</td>\n<td>UUID4 generation</td>\n<td>&quot;550e8400-e29b-41d4-a716-446655440000&quot;</td>\n</tr>\n<tr>\n<td>event_type</td>\n<td>Copy from source event</td>\n<td>&quot;user.created&quot;</td>\n</tr>\n<tr>\n<td>payload</td>\n<td>JSON serialization of event data</td>\n<td>{&quot;user_id&quot;: 12345, &quot;email&quot;: &quot;<a href=\"mailto:user@example.com\">user@example.com</a>&quot;}</td>\n</tr>\n<tr>\n<td>webhook_id</td>\n<td>Target webhook registration ID</td>\n<td>&quot;webhook_789&quot;</td>\n</tr>\n<tr>\n<td>delivery_status</td>\n<td>Always starts as &quot;pending&quot;</td>\n<td>&quot;pending&quot;</td>\n</tr>\n<tr>\n<td>scheduled_at</td>\n<td>Current time + any configured delay</td>\n<td>&quot;2024-01-15T10:30:00Z&quot;</td>\n</tr>\n<tr>\n<td>attempt_count</td>\n<td>Always starts at 0</td>\n<td>0</td>\n</tr>\n<tr>\n<td>idempotency_key</td>\n<td>source_key + &quot;_&quot; + webhook_id</td>\n<td>&quot;event123_webhook_789&quot;</td>\n</tr>\n<tr>\n<td>priority</td>\n<td>Based on event type and webhook tier</td>\n<td>5 (1=highest, 10=lowest)</td>\n</tr>\n<tr>\n<td>expires_at</td>\n<td>scheduled_at + retention period</td>\n<td>&quot;2024-01-22T10:30:00Z&quot;</td>\n</tr>\n</tbody></table>\n<h4 id=\"hmac-signature-generation\">HMAC Signature Generation</h4>\n<p>Before a webhook event can be queued for delivery, the system must generate the cryptographic signature that will authenticate the webhook payload at the receiving endpoint. This signature generation process is critical for webhook security and must be performed during ingestion to ensure consistency and prevent timing attacks during delivery.</p>\n<p>The signature generation process retrieves the current active secret for the target webhook using the <code>WebhookSecret</code> model. The system constructs a canonical signing string that includes the event payload, timestamp, webhook ID, delivery ID, and event type. This comprehensive signing approach prevents various attack vectors including replay attacks, signature reuse, and payload tampering.</p>\n<p>The canonical signing string format follows this structure:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>timestamp.webhook_id.delivery_id.event_type.payload_hash</code></pre></div>\n\n<p>Where each component serves a specific security purpose:</p>\n<ul>\n<li><code>timestamp</code>: Prevents replay attacks by including the current Unix timestamp</li>\n<li><code>webhook_id</code>: Binds the signature to a specific webhook endpoint</li>\n<li><code>delivery_id</code>: Ensures each delivery attempt has a unique signature</li>\n<li><code>event_type</code>: Prevents event type confusion attacks</li>\n<li><code>payload_hash</code>: SHA-256 hash of the JSON payload for integrity verification</li>\n</ul>\n<blockquote>\n<p>The canonical signing string approach provides defense in depth against signature-based attacks. By including multiple contextual elements, we prevent attackers from reusing signatures across different webhooks, event types, or time periods even if they intercept valid webhook deliveries.</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>Signature Component</th>\n<th>Security Purpose</th>\n<th>Attack Prevention</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Timestamp</td>\n<td>Temporal binding</td>\n<td>Replay attacks, signature aging</td>\n</tr>\n<tr>\n<td>Webhook ID</td>\n<td>Endpoint binding</td>\n<td>Cross-webhook signature reuse</td>\n</tr>\n<tr>\n<td>Delivery ID</td>\n<td>Uniqueness guarantee</td>\n<td>Duplicate delivery confusion</td>\n</tr>\n<tr>\n<td>Event Type</td>\n<td>Content binding</td>\n<td>Event type confusion attacks</td>\n</tr>\n<tr>\n<td>Payload Hash</td>\n<td>Integrity protection</td>\n<td>Payload tampering detection</td>\n</tr>\n</tbody></table>\n<h4 id=\"queue-placement-and-routing\">Queue Placement and Routing</h4>\n<p>The final step in the event ingestion flow places the prepared webhook events into the appropriate delivery queues. The queue placement process must ensure that events are routed to the correct per-webhook queues while maintaining ordering guarantees and handling queue overflow scenarios.</p>\n<p>The <code>QueueManager</code> handles the queue placement process using Redis streams to provide per-webhook ordering guarantees. Each webhook endpoint has a dedicated Redis stream identified by the webhook ID, ensuring that events for a specific endpoint are processed in first-in-first-out order. This ordering guarantee is critical for maintaining data consistency at the receiving endpoint.</p>\n<p>The queue entry creation process transforms the <code>WebhookEvent</code> into a <code>QueueEntry</code> with additional routing metadata:</p>\n<ol>\n<li>Calculate the <code>next_attempt_at</code> timestamp based on the scheduled delivery time and any rate limiting delays</li>\n<li>Generate a <code>payload_hash</code> for deduplication and integrity checking during delivery</li>\n<li>Set the queue <code>priority</code> to enable priority-based processing within the webhook stream</li>\n<li>Copy expiration and metadata for queue-level processing decisions</li>\n<li>Serialize the queue entry and add it to the webhook&#39;s Redis stream using <code>XADD</code></li>\n</ol>\n<blockquote>\n<p><strong>Decision: Per-Webhook Queue Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to maintain ordering guarantees while enabling parallel processing across different webhook endpoints</li>\n<li><strong>Options Considered</strong>: 1) Single global queue, 2) Per-webhook queues, 3) Event-type-based queues</li>\n<li><strong>Decision</strong>: Per-webhook Redis streams with parallel processing across webhooks</li>\n<li><strong>Rationale</strong>: Provides ordering guarantees per endpoint while maximizing parallelism, prevents slow endpoints from blocking others</li>\n<li><strong>Consequences</strong>: Requires more complex queue management but enables better isolation and performance characteristics</li>\n</ul>\n</blockquote>\n<h4 id=\"error-handling-and-rollback\">Error Handling and Rollback</h4>\n<p>The event ingestion flow must handle various failure scenarios gracefully, ensuring that events are not lost and system state remains consistent even when individual steps fail. The error handling strategy uses database transactions to ensure atomicity of the ingestion process.</p>\n<p>When errors occur during ingestion, the system follows a rollback strategy:</p>\n<ol>\n<li><strong>Validation Failures</strong>: Return error immediately to event source without persisting any state</li>\n<li><strong>Database Failures</strong>: Roll back the transaction and retry with exponential backoff</li>\n<li><strong>Queue Failures</strong>: Mark events as &quot;queuing_failed&quot; for later retry and alert operations</li>\n<li><strong>Partial Failures</strong>: Complete successful webhook events and retry failed ones individually</li>\n</ol>\n<p>The ingestion process tracks these error metrics for monitoring and alerting:</p>\n<table>\n<thead>\n<tr>\n<th>Error Type</th>\n<th>Metric</th>\n<th>Alert Threshold</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid payload</td>\n<td>ingestion.validation_errors</td>\n<td>&gt;5% of events</td>\n<td>Review event source integration</td>\n</tr>\n<tr>\n<td>Database timeout</td>\n<td>ingestion.db_timeouts</td>\n<td>&gt;1% of events</td>\n<td>Scale database resources</td>\n</tr>\n<tr>\n<td>Queue unavailable</td>\n<td>ingestion.queue_errors</td>\n<td>Any occurrence</td>\n<td>Immediate escalation</td>\n</tr>\n<tr>\n<td>Signature generation failure</td>\n<td>ingestion.crypto_errors</td>\n<td>Any occurrence</td>\n<td>Check secret rotation status</td>\n</tr>\n</tbody></table>\n<h3 id=\"delivery-processing-flow-queue-consumption-http-delivery-and-response-handling\">Delivery Processing Flow: Queue consumption, HTTP delivery, and response handling</h3>\n<p>The delivery processing flow represents the core operational component of the webhook delivery system, where queued events are consumed, transformed into HTTP requests, and delivered to registered endpoint URLs. This flow must handle the complexity of distributed HTTP delivery while maintaining reliability guarantees and providing comprehensive observability.</p>\n<h4 id=\"queue-consumption-and-event-claiming\">Queue Consumption and Event Claiming</h4>\n<p>The delivery processing begins with <code>DeliveryWorker</code> instances claiming ready events from the Redis streams managed by the <code>QueueManager</code>. The worker processes run continuously, polling for events that are ready for delivery based on their <code>next_attempt_at</code> timestamps. This polling mechanism must balance responsiveness with system efficiency, avoiding both excessive polling overhead and delivery delays.</p>\n<p>The event claiming process uses Redis stream consumer groups to provide at-least-once delivery guarantees with automatic failure handling. Each <code>DeliveryWorker</code> instance joins a consumer group and claims events using the <code>XREADGROUP</code> command with a configured batch size. The claiming process prioritizes events based on their scheduled delivery time and priority levels.</p>\n<p>The worker&#39;s event claiming algorithm follows these steps:</p>\n<ol>\n<li>Connect to Redis and join the appropriate consumer group for webhook streams</li>\n<li>Execute <code>XREADGROUP</code> with a batch size limit to claim ready events across multiple webhook streams</li>\n<li>Filter claimed events based on the current timestamp and <code>next_attempt_at</code> values</li>\n<li>Sort events by priority and scheduled time to determine processing order</li>\n<li>Acknowledge successfully claimed events to prevent duplicate processing by other workers</li>\n<li>Return the batch of claimed events for delivery processing</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Consumer Group Parameter</th>\n<th>Purpose</th>\n<th>Typical Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Group Name</td>\n<td>Identifies worker pool</td>\n<td>&quot;webhook_delivery_workers&quot;</td>\n</tr>\n<tr>\n<td>Consumer Name</td>\n<td>Unique worker identifier</td>\n<td>&quot;{hostname}<em>{pid}</em>{thread_id}&quot;</td>\n</tr>\n<tr>\n<td>Batch Size</td>\n<td>Events claimed per poll</td>\n<td>10-50 events</td>\n</tr>\n<tr>\n<td>Block Timeout</td>\n<td>Maximum wait time for new events</td>\n<td>5000ms</td>\n</tr>\n<tr>\n<td>Message ID</td>\n<td>Starting point for consumption</td>\n<td>&quot;&gt;&quot; (new messages only)</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>The consumer group pattern ensures that if a worker crashes after claiming events but before completing delivery, those events become available for other workers to process after a configured timeout period. This provides automatic failure recovery without requiring external coordination.</p>\n</blockquote>\n<h4 id=\"circuit-breaker-and-rate-limit-checks\">Circuit Breaker and Rate Limit Checks</h4>\n<p>Before attempting HTTP delivery, each event must pass through circuit breaker and rate limiting checks to ensure the target endpoint is healthy and not overwhelmed. The <code>CircuitBreakerManager</code> and rate limiting components work together to protect both the webhook system and the receiving endpoints from overload conditions.</p>\n<p>The circuit breaker check examines the current state for the target webhook endpoint. If the circuit breaker is in the <code>OPEN</code> state due to previous failures, the delivery attempt is immediately failed and the event is rescheduled for retry after the circuit recovery timeout. For endpoints in the <code>HALF_OPEN</code> state, only a limited number of test deliveries are allowed to proceed.</p>\n<p>The rate limiting check uses a token bucket algorithm implemented in Redis to enforce per-endpoint delivery rate limits. The rate limiter respects both the default system limits and any endpoint-specific rate limits configured in the <code>WebhookRegistration</code>. When rate limits are exceeded, the event is rescheduled rather than failed, preserving the delivery guarantee.</p>\n<table>\n<thead>\n<tr>\n<th>Check Type</th>\n<th>Pass Condition</th>\n<th>Fail Action</th>\n<th>Scheduling Delay</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Circuit Closed</td>\n<td>Normal operation</td>\n<td>Proceed to delivery</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Circuit Half-Open</td>\n<td>Test slot available</td>\n<td>Proceed with monitoring</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Circuit Open</td>\n<td>Never passes</td>\n<td>Reschedule event</td>\n<td>Circuit recovery timeout</td>\n</tr>\n<tr>\n<td>Rate Limit OK</td>\n<td>Tokens available</td>\n<td>Proceed and consume token</td>\n<td>None</td>\n</tr>\n<tr>\n<td>Rate Limit Exceeded</td>\n<td>No tokens</td>\n<td>Reschedule event</td>\n<td>Token refill time</td>\n</tr>\n<tr>\n<td>HTTP 429 Response</td>\n<td>Retry-After header</td>\n<td>Reschedule event</td>\n<td>Retry-After duration</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Pre-Delivery Protection Checks</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance delivery guarantees with endpoint protection and system stability</li>\n<li><strong>Options Considered</strong>: 1) Deliver all events immediately, 2) Circuit breaker only, 3) Comprehensive pre-delivery checks</li>\n<li><strong>Decision</strong>: Combined circuit breaker and rate limiting checks before each delivery attempt</li>\n<li><strong>Rationale</strong>: Prevents cascading failures while maintaining delivery guarantees through rescheduling rather than dropping events</li>\n<li><strong>Consequences</strong>: Adds latency to delivery process but significantly improves system resilience and endpoint protection</li>\n</ul>\n</blockquote>\n<h4 id=\"http-request-construction-and-delivery\">HTTP Request Construction and Delivery</h4>\n<p>When an event passes the protection checks, the delivery worker constructs an HTTP POST request with the properly signed payload and headers. The HTTP request construction process must handle authentication, content formatting, and security headers while maintaining compatibility with webhook standards.</p>\n<p>The HTTP request construction follows the webhook specification standards:</p>\n<ol>\n<li>Set the HTTP method to POST for all webhook deliveries</li>\n<li>Set the <code>Content-Type</code> header to <code>application/json</code> for JSON payloads</li>\n<li>Include the HMAC signature in the <code>X-Webhook-Signature-256</code> header using the format <code>sha256={signature}</code></li>\n<li>Add a <code>X-Webhook-Timestamp</code> header with the Unix timestamp used in signature generation</li>\n<li>Include a <code>X-Webhook-ID</code> header with the webhook registration ID for recipient identification</li>\n<li>Add a unique <code>X-Delivery-ID</code> header for deduplication and debugging purposes</li>\n<li>Set appropriate timeout headers and User-Agent identification</li>\n</ol>\n<p>The payload delivery process uses the <code>WebhookHTTPClient</code> which provides SSRF protection, timeout handling, and comprehensive error capture. The HTTP client is configured with conservative timeout values and retry-safe settings to prevent resource exhaustion.</p>\n<table>\n<thead>\n<tr>\n<th>HTTP Header</th>\n<th>Purpose</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Content-Type</td>\n<td>Payload format specification</td>\n<td>&quot;application/json&quot;</td>\n</tr>\n<tr>\n<td>X-Webhook-Signature-256</td>\n<td>HMAC signature for authentication</td>\n<td>&quot;sha256=a0b1c2d3...&quot;</td>\n</tr>\n<tr>\n<td>X-Webhook-Timestamp</td>\n<td>Signature timestamp for replay protection</td>\n<td>&quot;1642248600&quot;</td>\n</tr>\n<tr>\n<td>X-Webhook-ID</td>\n<td>Webhook registration identifier</td>\n<td>&quot;wh_1234567890&quot;</td>\n</tr>\n<tr>\n<td>X-Delivery-ID</td>\n<td>Unique delivery attempt identifier</td>\n<td>&quot;del_abcd1234efgh5678&quot;</td>\n</tr>\n<tr>\n<td>User-Agent</td>\n<td>System identification</td>\n<td>&quot;WebhookDeliverySystem/1.0&quot;</td>\n</tr>\n</tbody></table>\n<h4 id=\"response-handling-and-status-classification\">Response Handling and Status Classification</h4>\n<p>The HTTP response handling process must interpret the webhook endpoint&#39;s response to determine whether the delivery was successful and how to handle any failures. The response classification logic follows HTTP semantics while accounting for webhook-specific behaviors and common endpoint implementation patterns.</p>\n<p>The response handling process captures comprehensive delivery metrics:</p>\n<ol>\n<li>Record the HTTP status code and response time for performance monitoring</li>\n<li>Capture response headers, particularly <code>Retry-After</code> for rate limiting coordination  </li>\n<li>Store a truncated version of the response body for debugging purposes</li>\n<li>Classify the response as success, temporary failure, or permanent failure</li>\n<li>Update circuit breaker statistics based on the response classification</li>\n<li>Generate a <code>DeliveryAttempt</code> record with complete delivery metadata</li>\n</ol>\n<p>The status code classification determines the next action for the webhook event:</p>\n<table>\n<thead>\n<tr>\n<th>Status Code Range</th>\n<th>Classification</th>\n<th>Next Action</th>\n<th>Circuit Breaker Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>200-299</td>\n<td>Success</td>\n<td>Mark delivered, remove from queue</td>\n<td>Record success, potentially close circuit</td>\n</tr>\n<tr>\n<td>400-499 (except 429)</td>\n<td>Permanent failure</td>\n<td>Move to dead letter queue</td>\n<td>Record failure</td>\n</tr>\n<tr>\n<td>429</td>\n<td>Rate limited</td>\n<td>Reschedule with Retry-After delay</td>\n<td>No impact on circuit breaker</td>\n</tr>\n<tr>\n<td>500-599</td>\n<td>Temporary failure</td>\n<td>Schedule retry with backoff</td>\n<td>Record failure</td>\n</tr>\n<tr>\n<td>Timeout/Connection Error</td>\n<td>Temporary failure</td>\n<td>Schedule retry with backoff</td>\n<td>Record failure</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>HTTP 4xx errors (except 429) indicate permanent failures because they represent client errors where retrying the same request will not succeed. The webhook payload or configuration has a fundamental problem that requires manual intervention to resolve.</p>\n</blockquote>\n<h4 id=\"delivery-attempt-recording\">Delivery Attempt Recording</h4>\n<p>Every delivery attempt, successful or failed, must be recorded in the delivery audit trail for debugging, compliance, and retry decision making. The <code>DeliveryAttempt</code> creation process captures comprehensive metadata while managing storage efficiency through response body truncation and header filtering.</p>\n<p>The delivery attempt recording process creates a complete audit record:</p>\n<ol>\n<li>Generate a unique <code>attempt_id</code> for tracking and correlation purposes</li>\n<li>Record all request details including headers, payload hash, and delivery timestamp  </li>\n<li>Capture response metadata with truncation for large bodies (limit: 10KB)</li>\n<li>Calculate and store the total delivery duration including network time</li>\n<li>Identify the worker instance that performed the delivery for debugging</li>\n<li>Note any circuit breaker state changes triggered by this delivery attempt</li>\n<li>Persist the complete record to the delivery audit database</li>\n</ol>\n<p>The audit record enables comprehensive debugging and analysis:</p>\n<table>\n<thead>\n<tr>\n<th>Audit Field</th>\n<th>Purpose</th>\n<th>Retention</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Request headers</td>\n<td>Debug signature and formatting issues</td>\n<td>30 days hot storage</td>\n</tr>\n<tr>\n<td>Response status/headers</td>\n<td>Understand endpoint behavior</td>\n<td>365 days warm storage</td>\n</tr>\n<tr>\n<td>Response body (truncated)</td>\n<td>Debug endpoint errors</td>\n<td>30 days hot storage</td>\n</tr>\n<tr>\n<td>Timing metrics</td>\n<td>Performance analysis and SLA monitoring</td>\n<td>1095 days cold storage</td>\n</tr>\n<tr>\n<td>Worker identification</td>\n<td>Debug system-side delivery issues</td>\n<td>30 days hot storage</td>\n</tr>\n<tr>\n<td>Circuit breaker events</td>\n<td>Understand endpoint health patterns</td>\n<td>365 days warm storage</td>\n</tr>\n</tbody></table>\n<h3 id=\"failure-recovery-flow-retry-scheduling-circuit-breaker-activation-and-alerting\">Failure Recovery Flow: Retry scheduling, circuit breaker activation, and alerting</h3>\n<p>The failure recovery flow handles the complex scenarios where webhook deliveries fail and the system must make intelligent decisions about retry scheduling, endpoint health management, and escalation to human operators. This flow is critical for maintaining the system&#39;s reliability guarantees while preventing cascading failures.</p>\n<h4 id=\"retry-scheduling-and-exponential-backoff\">Retry Scheduling and Exponential Backoff</h4>\n<p>When a webhook delivery fails with a temporary error condition, the retry scheduling system must calculate an appropriate delay before the next attempt. The exponential backoff algorithm balances quick recovery from transient issues with respect for overwhelmed endpoints that need time to recover.</p>\n<p>The retry scheduling algorithm implements exponential backoff with jitter:</p>\n<ol>\n<li>Determine if the failure is retryable based on HTTP status code and error type</li>\n<li>Check if the maximum retry attempts limit has been exceeded for this event</li>\n<li>Calculate the base delay using exponential backoff: <code>base_delay * (2 ^ attempt_number)</code></li>\n<li>Add jitter by randomizing the delay within ±25% of the calculated value</li>\n<li>Respect any <code>Retry-After</code> header from the endpoint by using the larger of calculated delay or header value</li>\n<li>Cap the delay at a maximum value (typically 1 hour) to prevent indefinite delays</li>\n<li>Update the event&#39;s <code>next_attempt_at</code> timestamp and increment the <code>attempt_count</code></li>\n<li>Reschedule the event in the appropriate webhook stream for future processing</li>\n</ol>\n<p>The jitter calculation prevents the thundering herd problem where multiple failed endpoints all retry simultaneously when they recover. The randomization spreads retry attempts over time, reducing load spikes on recovering endpoints.</p>\n<table>\n<thead>\n<tr>\n<th>Attempt Number</th>\n<th>Base Delay</th>\n<th>With Jitter Range</th>\n<th>Maximum Effective Delay</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>30 seconds</td>\n<td>22.5 - 37.5 seconds</td>\n<td>37.5 seconds</td>\n</tr>\n<tr>\n<td>2</td>\n<td>60 seconds</td>\n<td>45 - 75 seconds</td>\n<td>75 seconds</td>\n</tr>\n<tr>\n<td>3</td>\n<td>2 minutes</td>\n<td>1.5 - 2.5 minutes</td>\n<td>2.5 minutes</td>\n</tr>\n<tr>\n<td>4</td>\n<td>4 minutes</td>\n<td>3 - 5 minutes</td>\n<td>5 minutes</td>\n</tr>\n<tr>\n<td>5</td>\n<td>8 minutes</td>\n<td>6 - 10 minutes</td>\n<td>10 minutes</td>\n</tr>\n<tr>\n<td>6+</td>\n<td>16+ minutes</td>\n<td>Capped at 1 hour</td>\n<td>1 hour maximum</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Exponential Backoff with Jitter and Caps</strong></p>\n<ul>\n<li><strong>Context</strong>: Need to balance quick recovery from transient failures with protection of overwhelmed endpoints</li>\n<li><strong>Options Considered</strong>: 1) Linear backoff, 2) Pure exponential backoff, 3) Exponential with jitter and caps</li>\n<li><strong>Decision</strong>: Exponential backoff with ±25% jitter and 1-hour maximum delay</li>\n<li><strong>Rationale</strong>: Exponential growth handles systematic problems, jitter prevents thundering herd, caps prevent indefinite delays</li>\n<li><strong>Consequences</strong>: More complex scheduling logic but significantly better behavior under load and during recovery</li>\n</ul>\n</blockquote>\n<h4 id=\"circuit-breaker-state-management\">Circuit Breaker State Management</h4>\n<p>The circuit breaker system monitors endpoint health and automatically disables delivery to consistently failing endpoints to prevent resource waste and allow endpoints time to recover. The circuit breaker state management must track failure patterns, manage state transitions, and coordinate recovery testing.</p>\n<p>The circuit breaker operates as a state machine with three primary states:</p>\n<p><strong>CLOSED State</strong>: Normal operation where all delivery attempts are allowed. The circuit breaker monitors failure rates and response times to detect developing problems. When the failure threshold is exceeded within the monitoring window, the circuit transitions to OPEN.</p>\n<p><strong>OPEN State</strong>: All delivery attempts are blocked and immediately failed without making HTTP requests. Events are rescheduled with increasingly longer delays to allow the endpoint time to recover. After a recovery timeout period, the circuit transitions to HALF_OPEN for testing.</p>\n<p><strong>HALF_OPEN State</strong>: Limited testing mode where only a small number of delivery attempts are allowed to probe endpoint health. If test deliveries succeed, the circuit returns to CLOSED. If test deliveries fail, the circuit returns to OPEN with a longer recovery timeout.</p>\n<p>The circuit breaker maintains per-endpoint state in Redis with atomic updates:</p>\n<table>\n<thead>\n<tr>\n<th>Circuit State Field</th>\n<th>Purpose</th>\n<th>Example Value</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>state</td>\n<td>Current circuit breaker state</td>\n<td>&quot;OPEN&quot;</td>\n</tr>\n<tr>\n<td>failure_count</td>\n<td>Consecutive failures in current window</td>\n<td>7</td>\n</tr>\n<tr>\n<td>last_failure_at</td>\n<td>Timestamp of most recent failure</td>\n<td>1642248600</td>\n</tr>\n<tr>\n<td>recovery_timeout</td>\n<td>Seconds until next HALF_OPEN attempt</td>\n<td>300</td>\n</tr>\n<tr>\n<td>test_delivery_count</td>\n<td>Number of test deliveries in HALF_OPEN</td>\n<td>2</td>\n</tr>\n<tr>\n<td>success_count</td>\n<td>Consecutive successes (for closing circuit)</td>\n<td>0</td>\n</tr>\n<tr>\n<td>window_start</td>\n<td>Start of current monitoring window</td>\n<td>1642248300</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p>The circuit breaker&#39;s recovery timeout increases with each failed recovery attempt: initial timeout of 5 minutes, doubling up to a maximum of 1 hour. This progressive backoff prevents rapid oscillation between states when endpoints have intermittent issues.</p>\n</blockquote>\n<h4 id=\"dead-letter-queue-management\">Dead Letter Queue Management</h4>\n<p>When webhook events exhaust all retry attempts or encounter permanent failure conditions, they must be moved to a dead letter queue for manual review and potential replay. The dead letter queue system provides a safety net that prevents event loss while enabling human intervention for complex failure scenarios.</p>\n<p>The dead letter queue process handles multiple failure scenarios:</p>\n<ol>\n<li><strong>Retry Exhaustion</strong>: Events that have exceeded the maximum retry attempt limit</li>\n<li><strong>Permanent Failures</strong>: HTTP 4xx responses (except 429) that indicate client errors</li>\n<li><strong>Expired Events</strong>: Events that have passed their expiration timestamp without successful delivery  </li>\n<li><strong>Configuration Errors</strong>: Events targeting deleted or misconfigured webhook endpoints</li>\n</ol>\n<p>The dead letter queue entry captures comprehensive failure context:</p>\n<ol>\n<li>Copy the complete original event payload and metadata for potential replay</li>\n<li>Record the complete delivery attempt history with all response details</li>\n<li>Categorize the failure reason for operational triage and automated handling</li>\n<li>Calculate failure statistics for trend analysis and system improvement</li>\n<li>Generate operational alerts based on failure volume and patterns</li>\n<li>Create replay preparation metadata for streamlined manual recovery</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Dead Letter Field</th>\n<th>Purpose</th>\n<th>Alert Trigger</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>failure_reason</td>\n<td>Categorized root cause</td>\n<td>High-frequency reason types</td>\n</tr>\n<tr>\n<td>attempt_history</td>\n<td>Complete delivery timeline</td>\n<td>Patterns indicating system issues</td>\n</tr>\n<tr>\n<td>original_payload</td>\n<td>Event data for replay</td>\n<td>None</td>\n</tr>\n<tr>\n<td>failure_timestamp</td>\n<td>When event was moved to DLQ</td>\n<td>Volume thresholds</td>\n</tr>\n<tr>\n<td>webhook_metadata</td>\n<td>Endpoint configuration at failure time</td>\n<td>Configuration drift detection</td>\n</tr>\n<tr>\n<td>replay_metadata</td>\n<td>Pre-computed replay parameters</td>\n<td>None</td>\n</tr>\n</tbody></table>\n<h4 id=\"alerting-and-escalation\">Alerting and Escalation</h4>\n<p>The failure recovery system must detect patterns that require human intervention and generate appropriate alerts for different stakeholder groups. The alerting system balances comprehensive coverage with alert fatigue, using intelligent grouping and escalation rules.</p>\n<p>The alerting system monitors multiple failure dimensions:</p>\n<p><strong>Endpoint-Level Alerts</strong>: Generated when individual webhook endpoints experience problems that may require customer support or endpoint owner intervention. These alerts include circuit breaker activations, consistent delivery failures, and configuration issues.</p>\n<p><strong>System-Level Alerts</strong>: Generated when failure patterns indicate broader system problems such as queue backlogs, database performance issues, or infrastructure failures. These alerts target the operations team and trigger automated scaling or failover procedures.</p>\n<p><strong>Security Alerts</strong>: Generated when failure patterns suggest potential security issues such as SSRF attempts, signature verification bypasses, or unusual traffic patterns. These alerts require immediate security team response.</p>\n<p>The alert escalation process follows defined severity levels:</p>\n<table>\n<thead>\n<tr>\n<th>Severity Level</th>\n<th>Trigger Conditions</th>\n<th>Initial Notification</th>\n<th>Escalation Timeline</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>INFO</td>\n<td>Circuit breaker transitions, retry patterns</td>\n<td>Email to endpoint owner</td>\n<td>No escalation</td>\n</tr>\n<tr>\n<td>WARN</td>\n<td>Dead letter queue growth, rate limit violations</td>\n<td>Email + dashboard alert</td>\n<td>2 hours to operations</td>\n</tr>\n<tr>\n<td>ERROR</td>\n<td>System queue backlogs, database timeouts</td>\n<td>Immediate slack + email</td>\n<td>30 minutes to on-call</td>\n</tr>\n<tr>\n<td>CRITICAL</td>\n<td>Security violations, data integrity issues</td>\n<td>Phone + slack + email</td>\n<td>Immediate escalation</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Decision: Multi-Dimensional Alerting Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Different failure types require different response teams and urgency levels</li>\n<li><strong>Options Considered</strong>: 1) Simple threshold alerts, 2) Pattern-based alerts, 3) Multi-dimensional alerting with escalation</li>\n<li><strong>Decision</strong>: Layered alerting system with endpoint, system, and security dimensions</li>\n<li><strong>Rationale</strong>: Enables appropriate response matching failure impact, reduces alert fatigue through intelligent grouping</li>\n<li><strong>Consequences</strong>: More complex alerting logic but significantly better operational outcomes and customer satisfaction</li>\n</ul>\n</blockquote>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Event Loss During Ingestion Failures</strong>\nWhen database transactions fail during event ingestion, developers often implement retry logic that can cause duplicate events or lose events entirely. The correct approach requires idempotent ingestion with proper transaction boundaries. Use database transactions that include both event creation and queue placement, with idempotency keys to handle duplicate submissions safely.</p>\n<p>⚠️ <strong>Pitfall: Signature Generation Timing Attacks</strong>\nGenerating HMAC signatures during delivery processing rather than ingestion can create timing-based security vulnerabilities and consistency issues. Signatures should be generated once during ingestion with a fixed timestamp, not recalculated for each retry attempt. This ensures consistent authentication and prevents timing attack vectors.</p>\n<p>⚠️ <strong>Pitfall: Circuit Breaker Oscillation</strong>\nImplementing circuit breakers without proper recovery testing mechanisms causes rapid oscillation between OPEN and CLOSED states when endpoints are intermittently failing. The HALF_OPEN state must limit test deliveries and require multiple consecutive successes before fully closing the circuit. Use exponentially increasing recovery timeouts to prevent rapid state changes.</p>\n<p>⚠️ <strong>Pitfall: Queue Ordering Violations</strong>\nUsing a single global queue with multiple workers can violate per-endpoint ordering guarantees when workers process events concurrently. Implement per-webhook queues using Redis streams to ensure that events for a specific endpoint are processed sequentially while maintaining parallelism across different endpoints.</p>\n<p>⚠️ <strong>Pitfall: Rate Limiting Bypass During Retries</strong>\nFailed delivery attempts that are retried without rate limit checks can overwhelm recovered endpoints and trigger new failures. All delivery attempts, including retries, must pass through rate limiting validation. Respect Retry-After headers from endpoints and implement exponential backoff to prevent retry storms.</p>\n<p>⚠️ <strong>Pitfall: Dead Letter Queue Monitoring Gaps</strong>\nMoving events to dead letter queues without proper alerting and review processes results in silent event loss from the customer perspective. Implement automated alerts for dead letter queue growth, categorize failure reasons for triage, and provide operational tools for event replay and customer notification.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides concrete implementation patterns and starter code for building the component interaction flows. The code focuses on Python with Redis for queue management and PostgreSQL for persistent storage.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Message Queues</td>\n<td>Redis Streams with python redis-py</td>\n<td>Apache Kafka with kafka-python</td>\n</tr>\n<tr>\n<td>HTTP Client</td>\n<td>requests library with retry decorators</td>\n<td>aiohttp with circuit breaker integration</td>\n</tr>\n<tr>\n<td>Background Workers</td>\n<td>Celery with Redis broker</td>\n<td>Custom asyncio workers with proper shutdown</td>\n</tr>\n<tr>\n<td>Database Operations</td>\n<td>SQLAlchemy ORM with connection pooling</td>\n<td>Async SQLAlchemy with connection management</td>\n</tr>\n<tr>\n<td>Circuit Breaker</td>\n<td>Simple Redis-based state machine</td>\n<td>py-breaker library with custom extensions</td>\n</tr>\n<tr>\n<td>Monitoring</td>\n<td>Python logging with structured output</td>\n<td>Prometheus metrics with custom collectors</td>\n</tr>\n</tbody></table>\n<h4 id=\"file-structure\">File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook_system/\n├── core/\n│   ├── __init__.py\n│   ├── models.py              ← SQLAlchemy models\n│   └── config.py              ← Configuration management\n├── ingestion/\n│   ├── __init__.py\n│   ├── event_processor.py     ← Event ingestion flow\n│   └── signature_service.py   ← HMAC signature generation\n├── delivery/\n│   ├── __init__.py\n│   ├── queue_manager.py       ← Redis stream management\n│   ├── delivery_worker.py     ← Core delivery processing\n│   └── http_client.py         ← Webhook HTTP delivery\n├── protection/\n│   ├── __init__.py\n│   ├── circuit_breaker.py     ← Circuit breaker state management\n│   └── rate_limiter.py        ← Token bucket rate limiting\n├── recovery/\n│   ├── __init__.py\n│   ├── retry_scheduler.py     ← Exponential backoff logic\n│   └── dead_letter_handler.py ← DLQ management\n└── monitoring/\n    ├── __init__.py\n    └── alerting.py            ← Alert generation and escalation</code></pre></div>\n\n<h4 id=\"infrastructure-starter-code\">Infrastructure Starter Code</h4>\n<p><strong>Queue Manager with Redis Streams:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asdict</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueueManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages per-webhook delivery queues using Redis streams.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, consumer_group: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"webhook_workers\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis.from_url(redis_url, </span><span style=\"color:#FFAB70\">decode_responses</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.consumer_group </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> consumer_group</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._ensure_consumer_groups()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _ensure_consumer_groups</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create consumer groups for all webhook streams.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Consumer group creation is handled per webhook stream</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> enqueue_event</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                     priority: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, expires_at: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Add event to webhook-specific delivery queue.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        stream_key </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"webhook_queue:</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">webhook_id</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        queue_entry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> QueueEntry(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            event_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">event_id,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            webhook_id</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">webhook_id,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            attempt_count</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            next_attempt_at</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time(),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            payload_hash</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#6A737D\"># Calculate from payload</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            priority</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">priority,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            expires_at</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">expires_at,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            metadata</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create consumer group if it doesn't exist</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add event to Redis stream with XADD</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle stream length limits and cleanup</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return success/failure status</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> redis.RedisError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Log error and return False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> claim_ready_events</span><span style=\"color:#E1E4E8\">(self, consumer_name: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                          batch_size: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 10</span><span style=\"color:#E1E4E8\">) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Dict]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Claim events ready for delivery across webhook streams.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        claimed_events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get list of active webhook streams</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Use XREADGROUP to claim events from multiple streams</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Filter events by next_attempt_at timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Sort by priority and scheduled time</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return list of (stream_key, event_data) tuples</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> redis.RedisError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Log error and return empty list</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> []</span></span></code></pre></div>\n\n<p><strong>HTTP Client with Protection Integration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> urllib.parse </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> urlparse</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookHTTPClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"HTTP client with SSRF protection and webhook-specific features.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: WebhookConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> requests.Session()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session.headers.update({</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'User-Agent'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'WebhookDeliverySystem/1.0'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'Content-Type'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'application/json'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        })</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> post_json</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">, headers: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">) -> HTTPResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Send JSON POST request with comprehensive error handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate URL for SSRF protection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Merge custom headers with default headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Make HTTP POST request with timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle various exception types (timeout, connection, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate response time and create HTTPResponse object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Truncate response body if too large</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> requests.exceptions.Timeout:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Request timeout\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span></code></pre></div>\n\n<h4 id=\"core-logic-skeleton\">Core Logic Skeleton</h4>\n<p><strong>Event Ingestion Processor:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> uuid</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EventIngestionProcessor</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Handles the complete event ingestion flow from validation to queue placement.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, webhook_registry: WebhookRegistry, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 queue_manager: QueueManager,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 signature_service: SignatureService):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.webhook_registry </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> webhook_registry</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.queue_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.signature_service </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> signature_service</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_incoming_event</span><span style=\"color:#E1E4E8\">(self, event_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                              source: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, idempotency_key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">any</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Process incoming event through complete ingestion flow.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate event payload size and format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check for duplicate events using idempotency key</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Look up webhook registrations subscribed to event_type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: For each matching webhook, create WebhookEvent record</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate HMAC signature for each webhook event</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Enqueue events in webhook-specific queues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return success response with event IDs and webhook count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Use database transaction to ensure atomicity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Handle case where no webhooks subscribe to event_type</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log error and return failure response</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Ensure no partial state is persisted</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> create_webhook_event</span><span style=\"color:#E1E4E8\">(self, webhook_reg: WebhookRegistration,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           event_type: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           source: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, idempotency_key: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> WebhookEvent:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Create WebhookEvent record for specific webhook endpoint.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate unique event ID using UUID4</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate priority based on event type and webhook tier</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Set expiration time based on webhook configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create idempotency key combining source key and webhook ID</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Initialize delivery status and attempt count</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return populated WebhookEvent object</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use current timestamp for created_at and scheduled_at</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Delivery Worker with Circuit Breaker Integration:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DeliveryWorker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Processes webhook deliveries with retry logic and protection mechanisms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, queue_manager: QueueManager,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 http_client: WebhookHTTPClient,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 circuit_breaker: CircuitBreakerManager,</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                 rate_limiter: RateLimitManager):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.queue_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> queue_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.http_client </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> http_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.circuit_breaker </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> circuit_breaker</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rate_limiter </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> rate_limiter</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.worker_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">socket.gethostname()</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">os.getpid()</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_worker_loop</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Continuously process events from delivery queues.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.running </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.running:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Claim batch of ready events from queue manager</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: For each event, load webhook registration and event details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check circuit breaker and rate limiting before delivery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Perform HTTP delivery if checks pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle delivery response and update circuit breaker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Schedule retries for failed deliveries or move to DLQ</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Acknowledge processed events in queue</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Sleep briefly if no events available</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Hint: Use process_delivery method for individual deliveries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                logging.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Worker loop error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                time.sleep(</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Back off on errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> process_delivery</span><span style=\"color:#E1E4E8\">(self, event_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                        payload: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Attempt webhook delivery with error handling and retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load webhook registration and verify it's active</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check circuit breaker state - return False if OPEN</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Check rate limiting - reschedule if rate limited</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Load webhook secret and generate request headers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Make HTTP delivery request using webhook HTTP client  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Create DeliveryAttempt record with response details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Update circuit breaker based on response status</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 8: Schedule retry for failures or mark success</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 9: Return True for success, False for failure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Hint: Use should_retry_delivery to classify response codes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log error, create failed delivery attempt record</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Schedule retry or move to DLQ based on attempt count</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints\">Milestone Checkpoints</h4>\n<p><strong>Milestone 1 Checkpoint - Event Ingestion:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run ingestion tests</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_event_ingestion.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected behavior:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Events create multiple WebhookEvent records for subscribed endpoints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - HMAC signatures generated correctly for each webhook</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Events queued in correct per-webhook Redis streams</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Idempotency protection prevents duplicate processing</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Checkpoint - Delivery Processing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Start delivery worker</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> webhook_system.delivery.worker</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Send test event</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> http://localhost:8080/events</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{\"event_type\": \"test.event\", \"payload\": {\"test\": true}}'</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected behavior:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Worker claims events from Redis streams</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - HTTP requests sent to registered webhook endpoints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Delivery attempts recorded with response details</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Failed deliveries scheduled for retry with exponential backoff</span></span></code></pre></div>\n\n<p><strong>Milestone 3 Checkpoint - Protection Mechanisms:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test circuit breaker</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> scripts/test_circuit_breaker.py</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected behavior:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Circuit opens after configured failure threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Deliveries blocked when circuit is OPEN</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Circuit transitions to HALF_OPEN for recovery testing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># - Rate limiting enforces per-endpoint delivery limits</span></span></code></pre></div>\n\n<h4 id=\"debugging-tips\">Debugging Tips</h4>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>How to Diagnose</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Events not being delivered</td>\n<td>Worker not claiming events</td>\n<td>Check Redis consumer group status</td>\n<td>Restart worker, verify consumer group creation</td>\n</tr>\n<tr>\n<td>Signatures failing validation</td>\n<td>Clock skew or incorrect secret</td>\n<td>Compare timestamps and verify secret rotation</td>\n<td>Sync clocks, check active secret versions</td>\n</tr>\n<tr>\n<td>Circuit breaker not opening</td>\n<td>Failure threshold too high</td>\n<td>Review failure counts in Redis</td>\n<td>Adjust threshold or verify failure recording</td>\n</tr>\n<tr>\n<td>Memory usage growing</td>\n<td>Large response bodies not truncated</td>\n<td>Monitor delivery attempt record sizes</td>\n<td>Implement response body truncation</td>\n</tr>\n<tr>\n<td>Queue backlog growing</td>\n<td>Workers slower than ingestion rate</td>\n<td>Compare ingestion vs processing rates</td>\n<td>Scale worker instances or optimize delivery code</td>\n</tr>\n</tbody></table>\n<h2 id=\"error-handling-and-edge-cases\">Error Handling and Edge Cases</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) - error handling patterns established here apply to webhook registration failures (Milestone 1), delivery and retry failures (Milestone 2), circuit breaker edge cases (Milestone 3), and event logging failures (Milestone 4)</p>\n</blockquote>\n<h3 id=\"mental-model-the-resilient-communication-network\">Mental Model: The Resilient Communication Network</h3>\n<p>Think of our webhook delivery system as a resilient communication network, similar to how postal services handle mail during natural disasters or infrastructure failures. Just as the postal service has established protocols for handling undeliverable mail, routing around damaged infrastructure, and recovering from facility outages, our webhook system must gracefully handle network partitions, endpoint failures, and system crashes.</p>\n<p>The postal service doesn&#39;t simply give up when a delivery truck breaks down - it has backup vehicles, alternative routes, and procedures for handling mail that can&#39;t be delivered immediately. Similarly, our webhook delivery system implements comprehensive error handling that categorizes failures by their nature and recoverability, applies appropriate recovery strategies, and maintains system consistency even during cascading failures.</p>\n<p>Consider how a postal service handles different types of delivery problems: temporary road closures (network timeouts) get retried later with alternative routes, incorrect addresses (4xx errors) are returned to sender without retry, and damaged packages (system failures) are handled through insurance and replacement processes. Our webhook system applies similar classification and handling strategies to ensure reliable delivery despite the inevitable failures in distributed systems.</p>\n<h3 id=\"network-and-timeout-handling\">Network and Timeout Handling</h3>\n<p>Network and timeout handling forms the foundation of resilient webhook delivery, as network failures represent the most common category of transient errors in distributed systems. The delivery engine must distinguish between different types of network failures to apply appropriate recovery strategies while avoiding resource exhaustion and cascading failures.</p>\n<p><strong>Connection Establishment Failures</strong> occur when the HTTP client cannot establish a TCP connection to the target endpoint. These failures manifest as DNS resolution failures, connection timeouts, or connection refused errors. Each type requires different handling strategies based on the underlying cause and likelihood of recovery.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Type</th>\n<th>Typical Causes</th>\n<th>Detection Method</th>\n<th>Recovery Strategy</th>\n<th>Retry Classification</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>DNS Resolution</td>\n<td>Invalid hostname, DNS server down</td>\n<td>DNS lookup exception</td>\n<td>Exponential backoff, alternative DNS</td>\n<td>Retriable with backoff</td>\n</tr>\n<tr>\n<td>Connection Timeout</td>\n<td>Network congestion, endpoint overload</td>\n<td>Socket timeout exception</td>\n<td>Longer timeout, circuit breaker</td>\n<td>Retriable, counts toward failures</td>\n</tr>\n<tr>\n<td>Connection Refused</td>\n<td>Service down, port closed</td>\n<td>Connection refused error</td>\n<td>Immediate retry contraindicated</td>\n<td>Retriable with longer backoff</td>\n</tr>\n<tr>\n<td>Network Unreachable</td>\n<td>Routing issues, network partition</td>\n<td>Network unreachable error</td>\n<td>Wait for network recovery</td>\n<td>Retriable with extended backoff</td>\n</tr>\n</tbody></table>\n<p>DNS resolution failures require special handling because they can indicate either temporary DNS server issues or permanent hostname errors. The system implements a tiered DNS resolution strategy where initial failures trigger retries with alternative DNS servers before classifying the hostname as permanently invalid.</p>\n<p><strong>Read and Write Timeout Handling</strong> manages partial connection establishment where the TCP handshake succeeds but HTTP request processing encounters delays. Write timeouts occur when the client cannot send the request payload within the configured timeout period, while read timeouts happen when the server doesn&#39;t respond within the expected timeframe.</p>\n<p>The <code>WebhookHTTPClient</code> implements sophisticated timeout handling that distinguishes between connection timeouts, request transmission timeouts, and response timeout scenarios:</p>\n<table>\n<thead>\n<tr>\n<th>Timeout Stage</th>\n<th>Configuration</th>\n<th>Failure Implications</th>\n<th>Retry Decision</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Connection Timeout</td>\n<td><code>DELIVERY_TIMEOUT</code> / 3</td>\n<td>Network or endpoint issues</td>\n<td>Retry with exponential backoff</td>\n</tr>\n<tr>\n<td>Request Write Timeout</td>\n<td><code>DELIVERY_TIMEOUT</code> / 3</td>\n<td>Large payload or slow upload</td>\n<td>Retry once, then circuit breaker</td>\n</tr>\n<tr>\n<td>Response Read Timeout</td>\n<td><code>DELIVERY_TIMEOUT</code></td>\n<td>Server processing delay</td>\n<td>Retry with jitter</td>\n</tr>\n<tr>\n<td>Total Request Timeout</td>\n<td><code>DELIVERY_TIMEOUT</code></td>\n<td>Overall request duration</td>\n<td>No retry, mark as failed</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Key Design Insight</strong>: Timeout handling must account for the fact that a request timeout doesn&#39;t guarantee the server didn&#39;t process the request. The webhook payload might have been successfully received and processed even if the response was lost due to timeout.</p>\n</blockquote>\n<p><strong>Partial Response Handling</strong> addresses scenarios where the HTTP response is partially received before the connection is interrupted. This creates ambiguity about whether the webhook was successfully delivered, requiring careful handling to prevent both data loss and duplicate processing.</p>\n<p>When a partial response is detected, the system records the attempt with a special status indicating uncertainty about delivery success. The <code>DeliveryAttempt</code> record includes sufficient information for manual investigation:</p>\n<table>\n<thead>\n<tr>\n<th>Response State</th>\n<th>Status Code Received</th>\n<th>Headers Received</th>\n<th>Body Received</th>\n<th>Classification</th>\n<th>Next Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Complete Response</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Definitive</td>\n<td>Apply normal retry logic</td>\n</tr>\n<tr>\n<td>Partial Headers</td>\n<td>Yes</td>\n<td>Partial</td>\n<td>No</td>\n<td>Uncertain Success</td>\n<td>Short retry delay</td>\n</tr>\n<tr>\n<td>Partial Body</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Partial</td>\n<td>Likely Success</td>\n<td>Extended retry delay</td>\n</tr>\n<tr>\n<td>Connection Lost</td>\n<td>No</td>\n<td>No</td>\n<td>No</td>\n<td>Likely Failure</td>\n<td>Normal retry logic</td>\n</tr>\n<tr>\n<td>Timeout During Body</td>\n<td>Yes</td>\n<td>Yes</td>\n<td>Timeout</td>\n<td>Uncertain Success</td>\n<td>Manual investigation flag</td>\n</tr>\n</tbody></table>\n<p><strong>Network Partition Recovery</strong> handles scenarios where the webhook delivery system loses connectivity to external endpoints due to network infrastructure failures. During network partitions, the system must avoid accumulating excessive retry load while maintaining delivery ordering guarantees.</p>\n<p>The network partition detection mechanism monitors global delivery failure rates and connection establishment success rates across all webhook endpoints. When partition conditions are detected, the system enters a degraded mode with modified retry behavior:</p>\n<ol>\n<li>Suspend normal retry schedules for connection-level failures</li>\n<li>Increase circuit breaker sensitivity to prevent queue buildup</li>\n<li>Implement partition-aware exponential backoff with extended maximum delays  </li>\n<li>Enable priority-based processing to handle critical webhooks first</li>\n<li>Alert operators about system-wide connectivity issues</li>\n</ol>\n<blockquote>\n<p><strong>Decision: Network Partition Detection Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: During network partitions, individual endpoint failures can overwhelm retry queues and delay recovery</li>\n<li><strong>Options Considered</strong>: Per-endpoint detection, global failure rate monitoring, external health check services</li>\n<li><strong>Decision</strong>: Implement global failure rate monitoring with per-endpoint override capabilities</li>\n<li><strong>Rationale</strong>: Balances automated detection with endpoint-specific network conditions while preventing false positives</li>\n<li><strong>Consequences</strong>: Enables faster recovery from partitions but requires careful tuning of detection thresholds</li>\n</ul>\n</blockquote>\n<h3 id=\"endpoint-error-classification\">Endpoint Error Classification</h3>\n<p>Endpoint error classification determines retry eligibility and failure handling based on HTTP response codes, response content, and error patterns. Proper classification prevents wasteful retries of permanent failures while ensuring transient errors receive appropriate retry treatment.</p>\n<p><strong>HTTP Status Code Classification</strong> follows RFC specifications but includes webhook-specific interpretations based on common endpoint implementation patterns. The classification directly drives retry decisions and circuit breaker state transitions.</p>\n<table>\n<thead>\n<tr>\n<th>Status Code Range</th>\n<th>Classification</th>\n<th>Retry Behavior</th>\n<th>Circuit Breaker Impact</th>\n<th>Common Webhook Causes</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>200-299</td>\n<td>Success</td>\n<td>No retry needed</td>\n<td>Reset failure count</td>\n<td>Successful delivery</td>\n</tr>\n<tr>\n<td>300-399</td>\n<td>Client Error</td>\n<td>No retry, log redirect</td>\n<td>No impact</td>\n<td>Endpoint URL changed</td>\n</tr>\n<tr>\n<td>400</td>\n<td>Bad Request</td>\n<td>No retry</td>\n<td>No impact</td>\n<td>Malformed payload or headers</td>\n</tr>\n<tr>\n<td>401</td>\n<td>Unauthorized</td>\n<td>No retry, alert</td>\n<td>No impact</td>\n<td>Invalid signature or auth</td>\n</tr>\n<tr>\n<td>403</td>\n<td>Forbidden</td>\n<td>No retry</td>\n<td>No impact</td>\n<td>Endpoint rejects webhook source</td>\n</tr>\n<tr>\n<td>404</td>\n<td>Not Found</td>\n<td>No retry</td>\n<td>No impact</td>\n<td>Endpoint URL no longer valid</td>\n</tr>\n<tr>\n<td>408</td>\n<td>Request Timeout</td>\n<td>Retry with backoff</td>\n<td>Count as failure</td>\n<td>Server-side timeout</td>\n</tr>\n<tr>\n<td>409</td>\n<td>Conflict</td>\n<td>No retry</td>\n<td>No impact</td>\n<td>Duplicate delivery detected</td>\n</tr>\n<tr>\n<td>410</td>\n<td>Gone</td>\n<td>No retry, deactivate</td>\n<td>No impact</td>\n<td>Endpoint permanently removed</td>\n</tr>\n<tr>\n<td>413</td>\n<td>Payload Too Large</td>\n<td>No retry</td>\n<td>No impact</td>\n<td>Webhook payload exceeds limits</td>\n</tr>\n<tr>\n<td>422</td>\n<td>Unprocessable Entity</td>\n<td>No retry</td>\n<td>No impact</td>\n<td>Valid format, invalid content</td>\n</tr>\n<tr>\n<td>429</td>\n<td>Rate Limited</td>\n<td>Retry with delay</td>\n<td>Special handling</td>\n<td>Endpoint rate limiting</td>\n</tr>\n<tr>\n<td>500-502</td>\n<td>Server Error</td>\n<td>Retry with backoff</td>\n<td>Count as failure</td>\n<td>Temporary server issues</td>\n</tr>\n<tr>\n<td>503</td>\n<td>Service Unavailable</td>\n<td>Retry with longer delay</td>\n<td>Count as failure</td>\n<td>Server overload or maintenance</td>\n</tr>\n<tr>\n<td>504</td>\n<td>Gateway Timeout</td>\n<td>Retry with backoff</td>\n<td>Count as failure</td>\n<td>Upstream timeout</td>\n</tr>\n</tbody></table>\n<p>The <code>should_retry_delivery</code> function implements this classification with additional logic for webhook-specific scenarios:</p>\n<p><strong>Rate Limiting Response Handling</strong> provides special treatment for HTTP 429 responses because they indicate temporary capacity constraints rather than permanent failures. The system examines the <code>Retry-After</code> header to determine appropriate retry scheduling.</p>\n<table>\n<thead>\n<tr>\n<th>Retry-After Header</th>\n<th>Value Type</th>\n<th>Interpretation</th>\n<th>Retry Scheduling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Present</td>\n<td>Seconds (integer)</td>\n<td>Exact delay requested</td>\n<td>Schedule retry at specified time</td>\n</tr>\n<tr>\n<td>Present</td>\n<td>HTTP-date</td>\n<td>Absolute time</td>\n<td>Schedule retry at specified timestamp</td>\n</tr>\n<tr>\n<td>Missing</td>\n<td>N/A</td>\n<td>Standard rate limiting</td>\n<td>Apply default rate limit backoff</td>\n</tr>\n<tr>\n<td>Invalid</td>\n<td>Malformed</td>\n<td>Parse error</td>\n<td>Log warning, use default backoff</td>\n</tr>\n</tbody></table>\n<p>When processing 429 responses, the system updates the endpoint&#39;s rate limiting state through the <code>handle_retry_after_response</code> method, which temporarily reduces the delivery rate below the requested threshold. This prevents immediate re-triggering of rate limiting while respecting the endpoint&#39;s capacity constraints.</p>\n<p><strong>Authentication and Authorization Failures</strong> (401/403 responses) indicate configuration issues rather than transient failures. These responses trigger immediate alerting to the webhook owner and temporarily suspend delivery attempts to prevent continued authentication failures.</p>\n<p>The system maintains an authentication failure tracking mechanism that distinguishes between signature verification failures (likely system clock skew or secret rotation issues) and authorization failures (endpoint policy changes or webhook subscription cancellation):</p>\n<table>\n<thead>\n<tr>\n<th>Error Pattern</th>\n<th>Detection Method</th>\n<th>Alert Priority</th>\n<th>Remediation Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Signature Rejection</td>\n<td>401 with signature error message</td>\n<td>High</td>\n<td>Check secret rotation status</td>\n</tr>\n<tr>\n<td>Expired Timestamp</td>\n<td>401 with timestamp error</td>\n<td>Medium</td>\n<td>Verify system clock synchronization</td>\n</tr>\n<tr>\n<td>Source Rejection</td>\n<td>403 with source policy message</td>\n<td>Low</td>\n<td>Contact endpoint owner</td>\n</tr>\n<tr>\n<td>Subscription Cancelled</td>\n<td>403 with subscription message</td>\n<td>High</td>\n<td>Update webhook registration status</td>\n</tr>\n</tbody></table>\n<p><strong>Malformed Response Handling</strong> addresses scenarios where endpoints return structurally invalid HTTP responses or responses that violate HTTP specifications. These failures require careful classification because they might indicate endpoint implementation issues rather than temporary failures.</p>\n<p>The <code>HTTPResponse</code> object captures response parsing failures and categorizes them based on the type of malformation:</p>\n<table>\n<thead>\n<tr>\n<th>Malformation Type</th>\n<th>Detection</th>\n<th>Classification</th>\n<th>Retry Decision</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Invalid Status Line</td>\n<td>HTTP parsing exception</td>\n<td>Server Error</td>\n<td>Retry with backoff</td>\n</tr>\n<tr>\n<td>Malformed Headers</td>\n<td>Header parsing failure</td>\n<td>Server Error</td>\n<td>Retry with backoff</td>\n</tr>\n<tr>\n<td>Invalid Content-Length</td>\n<td>Length mismatch</td>\n<td>Server Error</td>\n<td>Single retry attempt</td>\n</tr>\n<tr>\n<td>Encoding Errors</td>\n<td>Character encoding issues</td>\n<td>Server Error</td>\n<td>No retry, log for investigation</td>\n</tr>\n<tr>\n<td>Truncated Response</td>\n<td>Incomplete response</td>\n<td>Network Error</td>\n<td>Retry with normal backoff</td>\n</tr>\n</tbody></table>\n<h3 id=\"system-level-failure-recovery\">System-Level Failure Recovery</h3>\n<p>System-level failure recovery ensures webhook delivery system consistency and availability during infrastructure failures, worker process crashes, and database connectivity issues. The recovery mechanisms must handle both graceful shutdowns and unexpected failures while preserving delivery ordering and preventing data loss.</p>\n<p><strong>Worker Process Crash Recovery</strong> handles scenarios where <code>DeliveryWorker</code> processes terminate unexpectedly during webhook delivery processing. The system implements a combination of message acknowledgment, worker heartbeats, and orphaned task recovery to ensure no deliveries are lost during worker failures.</p>\n<p>Each <code>DeliveryWorker</code> maintains a heartbeat record in Redis that includes the worker&#39;s current processing state and the events it has claimed for delivery. The heartbeat mechanism enables rapid detection of worker failures and prevents indefinite message locks:</p>\n<table>\n<thead>\n<tr>\n<th>Worker State</th>\n<th>Heartbeat Interval</th>\n<th>Timeout Threshold</th>\n<th>Recovery Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Idle</td>\n<td>30 seconds</td>\n<td>90 seconds</td>\n<td>Mark worker as available</td>\n</tr>\n<tr>\n<td>Processing Event</td>\n<td>10 seconds</td>\n<td>45 seconds</td>\n<td>Reclaim orphaned event</td>\n</tr>\n<tr>\n<td>Delivering Webhook</td>\n<td>5 seconds</td>\n<td>20 seconds</td>\n<td>Retry delivery from checkpoint</td>\n</tr>\n<tr>\n<td>Circuit Breaker Wait</td>\n<td>60 seconds</td>\n<td>180 seconds</td>\n<td>Resume normal processing</td>\n</tr>\n</tbody></table>\n<p>The orphaned task recovery process runs as a separate background service that periodically scans for events claimed by workers that have exceeded their heartbeat timeout. When orphaned events are detected, the recovery service releases the message locks and re-queues the events for processing by healthy workers.</p>\n<p><strong>Database Connection Failure Recovery</strong> implements connection pool management with automatic retry and circuit breaking to handle database connectivity issues gracefully. The <code>DatabaseManager</code> maintains multiple connection pools with different priorities for different types of operations.</p>\n<table>\n<thead>\n<tr>\n<th>Operation Type</th>\n<th>Connection Pool</th>\n<th>Retry Strategy</th>\n<th>Failure Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Queuing</td>\n<td>Primary Pool</td>\n<td>3 retries with backoff</td>\n<td>Switch to secondary pool</td>\n</tr>\n<tr>\n<td>Delivery Logging</td>\n<td>Secondary Pool</td>\n<td>2 retries</td>\n<td>Buffer to local storage</td>\n</tr>\n<tr>\n<td>Configuration Queries</td>\n<td>Read-Only Pool</td>\n<td>5 retries</td>\n<td>Use cached configuration</td>\n</tr>\n<tr>\n<td>Health Checks</td>\n<td>Dedicated Pool</td>\n<td>No retries</td>\n<td>Mark database unhealthy</td>\n</tr>\n</tbody></table>\n<p>The connection failure recovery implements a tiered fallback strategy where less critical operations gracefully degrade while preserving core delivery functionality. Event queuing operations receive the highest priority, followed by delivery attempt logging, with configuration and analytics queries receiving lower priority during resource constraints.</p>\n<blockquote>\n<p><strong>Decision: Database Failure Handling Strategy</strong>  </p>\n<ul>\n<li><strong>Context</strong>: Database connectivity issues can cause webhook delivery system outages if not handled gracefully</li>\n<li><strong>Options Considered</strong>: Immediate failure, local buffering, secondary database, full degraded mode</li>\n<li><strong>Decision</strong>: Implement tiered fallback with local buffering and connection pool management</li>\n<li><strong>Rationale</strong>: Balances delivery reliability with system complexity while maintaining data consistency</li>\n<li><strong>Consequences</strong>: Enables continued operation during database issues but requires local storage management and eventual consistency handling</li>\n</ul>\n</blockquote>\n<p><strong>Message Queue Persistence and Recovery</strong> ensures that webhook events are not lost during Redis failures or restarts. The system implements a dual-persistence strategy using Redis Streams for primary queuing and PostgreSQL for durable backup storage.</p>\n<p>The queue persistence mechanism maintains synchronized state between Redis and PostgreSQL, with Redis serving as the high-performance primary queue and PostgreSQL providing durability guarantees:</p>\n<table>\n<thead>\n<tr>\n<th>Queue Operation</th>\n<th>Redis Action</th>\n<th>PostgreSQL Action</th>\n<th>Consistency Guarantee</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event Enqueue</td>\n<td>XADD to stream</td>\n<td>INSERT to events table</td>\n<td>At-least-once delivery</td>\n</tr>\n<tr>\n<td>Event Claim</td>\n<td>XREADGROUP</td>\n<td>UPDATE claim timestamp</td>\n<td>Exactly-once claim</td>\n</tr>\n<tr>\n<td>Delivery Success</td>\n<td>XACK message</td>\n<td>UPDATE delivery status</td>\n<td>Eventually consistent</td>\n</tr>\n<tr>\n<td>Delivery Failure</td>\n<td>Update retry count</td>\n<td>INSERT attempt record</td>\n<td>Eventually consistent</td>\n</tr>\n<tr>\n<td>Dead Letter</td>\n<td>XADD to DLQ stream</td>\n<td>UPDATE to failed status</td>\n<td>At-least-once DLQ</td>\n</tr>\n</tbody></table>\n<p>During Redis recovery, the system rebuilds the in-memory queue state by scanning PostgreSQL for events that were not successfully delivered, ensuring no events are lost during infrastructure failures.</p>\n<p><strong>Configuration Hot Reloading</strong> enables webhook system configuration updates without service restarts, which is critical for production systems that must maintain high availability. The configuration system monitors for changes to webhook registrations, rate limiting settings, and circuit breaker thresholds.</p>\n<p>The hot reload mechanism uses Redis pub/sub notifications to coordinate configuration changes across multiple worker processes:</p>\n<table>\n<thead>\n<tr>\n<th>Configuration Type</th>\n<th>Change Detection</th>\n<th>Distribution Method</th>\n<th>Application Timing</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Webhook Registration</td>\n<td>Database trigger</td>\n<td>Redis pub/sub</td>\n<td>Immediate</td>\n</tr>\n<tr>\n<td>Rate Limit Updates</td>\n<td>Admin API</td>\n<td>Redis pub/sub</td>\n<td>Next request</td>\n</tr>\n<tr>\n<td>Circuit Breaker Thresholds</td>\n<td>Configuration file</td>\n<td>File system watcher</td>\n<td>Next health check</td>\n</tr>\n<tr>\n<td>Security Settings</td>\n<td>Environment variables</td>\n<td>Process signal</td>\n<td>Next request batch</td>\n</tr>\n</tbody></table>\n<p>Configuration changes that affect security (such as signature validation settings) are applied with additional validation to prevent configuration errors from compromising webhook security.</p>\n<p><strong>Split-Brain Prevention</strong> addresses scenarios where multiple instances of the webhook delivery system become isolated from each other but continue processing events. This can lead to duplicate deliveries or inconsistent state if not properly handled.</p>\n<p>The system implements distributed coordination using Redis-based distributed locks with lease expiration to ensure only one instance processes events for each webhook endpoint at any given time:</p>\n<table>\n<thead>\n<tr>\n<th>Coordination Mechanism</th>\n<th>Implementation</th>\n<th>Lease Duration</th>\n<th>Failure Handling</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Endpoint Processing Lock</td>\n<td>Redis SETNX with TTL</td>\n<td>60 seconds</td>\n<td>Automatic release on timeout</td>\n</tr>\n<tr>\n<td>Circuit Breaker State</td>\n<td>Redis hash with TTL</td>\n<td>120 seconds</td>\n<td>Conservative state assumption</td>\n</tr>\n<tr>\n<td>Rate Limit Buckets</td>\n<td>Redis sorted set</td>\n<td>300 seconds</td>\n<td>Reset to safe defaults</td>\n</tr>\n<tr>\n<td>Dead Letter Processing</td>\n<td>Redis queue with timeout</td>\n<td>180 seconds</td>\n<td>Manual intervention required</td>\n</tr>\n</tbody></table>\n<p>The distributed coordination prevents split-brain scenarios while allowing for rapid failover when primary instances become unavailable.</p>\n<h3 id=\"\"><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Fretry-flowchart.svg\" alt=\"Retry Decision Flowchart\"></h3>\n<p>The retry decision flowchart illustrates the comprehensive decision tree used by the <code>should_retry_delivery</code> function to determine appropriate handling for each delivery attempt. The flowchart shows how HTTP status codes, attempt counts, circuit breaker states, and rate limiting constraints combine to determine whether an event should be retried, rescheduled, or moved to the dead letter queue.</p>\n<h3 id=\"\"><img src=\"/api/project/webhook-delivery/architecture-doc/asset?path=diagrams%2Ffailure-recovery.svg\" alt=\"Failure Recovery Architecture\"></h3>\n<p>The failure recovery architecture diagram shows the interaction between system components during failure scenarios, including worker crash recovery, database failover, and split-brain prevention mechanisms. The diagram illustrates how different types of failures trigger different recovery pathways while maintaining system consistency.</p>\n<h3 id=\"common-pitfalls\">Common Pitfalls</h3>\n<p>⚠️ <strong>Pitfall: Retry Amplification During Recovery</strong></p>\n<p>A common mistake is implementing retry logic that creates exponentially increasing load during system recovery. When many webhook endpoints fail simultaneously (such as during network partitions), naive retry implementations can create a &quot;thundering herd&quot; effect where all retries execute simultaneously when connectivity is restored.</p>\n<p><strong>Why this is problematic</strong>: Recovery periods are when system resources are most constrained. Simultaneous retry attempts can overwhelm recovered endpoints, extend outage duration, and trigger cascading failures in downstream systems.</p>\n<p><strong>How to avoid</strong>: Implement retry jitter and staggered recovery scheduling. Add randomization to retry delays and implement global rate limiting during recovery periods to spread retry load over time.</p>\n<p>⚠️ <strong>Pitfall: Incorrect Timeout Cascade Classification</strong></p>\n<p>Many implementations incorrectly classify all timeout errors as retriable failures, leading to persistent retry attempts against endpoints that are permanently overloaded or misconfigured.</p>\n<p><strong>Why this is problematic</strong>: Continuous retry attempts against timing-out endpoints can prevent proper circuit breaker activation and waste system resources on deliveries that will never succeed.</p>\n<p><strong>How to avoid</strong>: Implement timeout pattern analysis that distinguishes between network-level timeouts (retriable) and application-level timeouts (potential circuit breaker trigger). Track timeout duration patterns to identify chronically slow endpoints.</p>\n<p>⚠️ <strong>Pitfall: Database Connection Leak During Failures</strong></p>\n<p>Connection pool management often fails during database connectivity issues, leading to connection exhaustion and preventing system recovery even after database connectivity is restored.</p>\n<p><strong>Why this is problematic</strong>: Connection leaks during failure scenarios create resource exhaustion that persists beyond the original failure, extending outage duration and requiring manual intervention.</p>\n<p><strong>How to avoid</strong>: Implement aggressive connection timeouts during failure detection and connection pool reset mechanisms that forcibly close potentially stale connections during recovery procedures.</p>\n<p>⚠️ <strong>Pitfall: Inconsistent Error Classification Across Workers</strong></p>\n<p>Different worker processes applying different error classification logic leads to inconsistent retry behavior and circuit breaker state divergence across the distributed system.</p>\n<p><strong>Why this is problematic</strong>: Inconsistent error handling creates unpredictable webhook delivery behavior and makes debugging difficult. Circuit breaker states can become inconsistent across workers, leading to delivery confusion.</p>\n<p><strong>How to avoid</strong>: Centralize error classification logic in shared libraries and implement configuration distribution mechanisms that ensure all workers apply identical error handling rules.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>This section provides comprehensive implementation support for robust error handling across all webhook delivery system components. The error handling patterns established here apply to webhook registration failures, delivery processing errors, circuit breaker edge cases, and event logging failures.</p>\n<p><strong>Technology Recommendations:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP Client</td>\n<td><code>requests</code> with timeout configuration</td>\n<td><code>aiohttp</code> with connection pooling and circuit breakers</td>\n</tr>\n<tr>\n<td>Error Tracking</td>\n<td>Python logging with structured output</td>\n<td><code>sentry-sdk</code> with error aggregation and alerting</td>\n</tr>\n<tr>\n<td>Retry Logic</td>\n<td>Simple exponential backoff</td>\n<td><code>tenacity</code> library with advanced retry strategies</td>\n</tr>\n<tr>\n<td>Health Monitoring</td>\n<td>Basic success rate tracking</td>\n<td><code>prometheus-client</code> with detailed metrics</td>\n</tr>\n<tr>\n<td>Database Resilience</td>\n<td>Connection retry with backoff</td>\n<td><code>SQLAlchemy</code> with connection pooling and failover</td>\n</tr>\n</tbody></table>\n<p><strong>Recommended File Structure:</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-system/\n├── src/\n│   ├── error_handling/\n│   │   ├── __init__.py                 ← error handling exports\n│   │   ├── network_errors.py           ← network and timeout handling\n│   │   ├── endpoint_classification.py  ← HTTP status code classification  \n│   │   ├── system_recovery.py          ← worker and database failure recovery\n│   │   ├── retry_strategies.py         ← retry logic and backoff algorithms\n│   │   └── failure_detection.py        ← failure pattern detection\n│   ├── delivery/\n│   │   ├── http_client.py              ← enhanced HTTP client with error handling\n│   │   └── worker_recovery.py          ← worker crash detection and recovery\n│   ├── infrastructure/\n│   │   ├── database_manager.py         ← connection pool management\n│   │   ├── queue_recovery.py           ← message queue persistence recovery\n│   │   └── health_monitoring.py        ← system health and alerting\n│   └── tests/\n│       ├── test_error_scenarios.py     ← comprehensive error testing\n│       └── test_recovery_procedures.py ← failure recovery validation</code></pre></div>\n\n<p><strong>Infrastructure Starter Code - Enhanced HTTP Client:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> aiohttp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Optional, Dict, Any, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> NetworkErrorType</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    DNS_RESOLUTION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"dns_resolution\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CONNECTION_TIMEOUT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"connection_timeout\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CONNECTION_REFUSED</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"connection_refused\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    READ_TIMEOUT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"read_timeout\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WRITE_TIMEOUT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"write_timeout\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    NETWORK_UNREACHABLE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"network_unreachable\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HTTPResponse</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status_code: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_time: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    error_message: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    headers: </span><span style=\"color:#79B8FF\">dict</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    body: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    network_error_type: Optional[NetworkErrorType] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookHTTPClient</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Enhanced HTTP client with comprehensive error handling and timeout management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: </span><span style=\"color:#9ECBFF\">'WebhookConfig'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#79B8FF\"> __aenter__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timeout </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> aiohttp.ClientTimeout(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            total</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.delivery_timeout,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            connect</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.delivery_timeout </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            sock_read</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.delivery_timeout </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 3</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            sock_connect</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.delivery_timeout </span><span style=\"color:#F97583\">//</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        connector </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> aiohttp.TCPConnector(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            limit</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            limit_per_host</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            ttl_dns_cache</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">300</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            use_dns_cache</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            keepalive_timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">30</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.session </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> aiohttp.ClientSession(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">timeout,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            connector</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">connector,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">            headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{</span><span style=\"color:#9ECBFF\">'User-Agent'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">'WebhookDeliverySystem/1.0'</span><span style=\"color:#E1E4E8\">}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        )</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> self</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#79B8FF\"> __aexit__</span><span style=\"color:#E1E4E8\">(self, exc_type, exc_val, exc_tb):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.session:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            await</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.session.close()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> post_json</span><span style=\"color:#E1E4E8\">(self, url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, payload: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">, headers: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">) -> HTTPResponse:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Send JSON POST request with comprehensive error handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Handles all categories of network errors, timeouts, and malformed responses</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        with appropriate classification for retry decision making.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        start_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            async</span><span style=\"color:#F97583\"> with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.session.post(url, </span><span style=\"color:#FFAB70\">json</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">payload, </span><span style=\"color:#FFAB70\">headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">headers) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> response:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    body </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> await</span><span style=\"color:#E1E4E8\"> response.text()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                except</span><span style=\"color:#E1E4E8\"> asyncio.TimeoutError:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Response body read timeout\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                        network_error_type</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">NetworkErrorType.</span><span style=\"color:#79B8FF\">READ_TIMEOUT</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                    )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response.status,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">(response.headers),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    body</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">body</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> asyncio.TimeoutError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Request timeout after </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">response_time</span><span style=\"color:#F97583\">:.2f</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">s\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                network_error_type</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">NetworkErrorType.</span><span style=\"color:#79B8FF\">CONNECTION_TIMEOUT</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#E1E4E8\"> aiohttp.ClientConnectorError </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            error_type </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._classify_connection_error(e)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">(e),</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                network_error_type</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">error_type</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            response_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time() </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> start_time</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unexpected HTTP client error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> HTTPResponse(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                status_code</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                response_time</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">response_time,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                error_message</span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Unexpected error: </span><span style=\"color:#79B8FF\">{str</span><span style=\"color:#E1E4E8\">(e)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                headers</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">{},</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                body</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> _classify_connection_error</span><span style=\"color:#E1E4E8\">(self, error: aiohttp.ClientConnectorError) -> NetworkErrorType:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Classify connection errors for appropriate retry handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        error_str </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> str</span><span style=\"color:#E1E4E8\">(error).lower()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#9ECBFF\"> \"name or service not known\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> error_str </span><span style=\"color:#F97583\">or</span><span style=\"color:#9ECBFF\"> \"nodename nor servname provided\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> error_str:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> NetworkErrorType.</span><span style=\"color:#79B8FF\">DNS_RESOLUTION</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#9ECBFF\"> \"connection refused\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> error_str:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> NetworkErrorType.</span><span style=\"color:#79B8FF\">CONNECTION_REFUSED</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        elif</span><span style=\"color:#9ECBFF\"> \"network is unreachable\"</span><span style=\"color:#F97583\"> in</span><span style=\"color:#E1E4E8\"> error_str:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> NetworkErrorType.</span><span style=\"color:#79B8FF\">NETWORK_UNREACHABLE</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span><span style=\"color:#E1E4E8\"> NetworkErrorType.</span><span style=\"color:#79B8FF\">CONNECTION_TIMEOUT</span></span></code></pre></div>\n\n<p><strong>Infrastructure Starter Code - Database Connection Manager:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncpg</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> logging</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asynccontextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> AsyncGenerator, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DatabaseConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    host: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    port: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    database: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    username: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    password: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    min_connections: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_connections: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 20</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    command_timeout: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    max_retries: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 3</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    retry_delay: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1.0</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DatabaseManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Database connection manager with automatic failure recovery and connection pooling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, config: DatabaseConfig):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.primary_pool: Optional[asyncpg.Pool] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.last_health_check </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.health_check_interval </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> initialize</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize the database connection pool with retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> attempt </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.max_retries):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.primary_pool </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> await</span><span style=\"color:#E1E4E8\"> asyncpg.create_pool(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    host</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.host,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    port</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.port,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    database</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.database,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    user</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.username,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    password</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.password,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    min_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.min_connections,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    max_size</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.max_connections,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">                    command_timeout</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.command_timeout</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                )</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # Test connection</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                async</span><span style=\"color:#F97583\"> with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.primary_pool.acquire() </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> conn:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    await</span><span style=\"color:#E1E4E8\"> conn.execute(</span><span style=\"color:#9ECBFF\">\"SELECT 1\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.logger.info(</span><span style=\"color:#9ECBFF\">\"Database connection pool initialized successfully\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database connection attempt </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">attempt </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1}</span><span style=\"color:#9ECBFF\"> failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> attempt </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.max_retries </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    await</span><span style=\"color:#E1E4E8\"> asyncio.sleep(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.retry_delay </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\"> **</span><span style=\"color:#E1E4E8\"> attempt))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    raise</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @asynccontextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> get_connection</span><span style=\"color:#E1E4E8\">(self) -> AsyncGenerator[asyncpg.Connection, </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Get database connection with automatic retry and health checking.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Implements connection-level retry with exponential backoff and automatic</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        pool recreation during extended outages.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.is_healthy </span><span style=\"color:#F97583\">or</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.primary_pool:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            await</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._attempt_recovery()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> attempt </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.max_retries):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                async</span><span style=\"color:#F97583\"> with</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.primary_pool.acquire() </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> conn:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    yield</span><span style=\"color:#E1E4E8\"> conn</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.logger.warning(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database connection attempt </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">attempt </span><span style=\"color:#F97583\">+</span><span style=\"color:#79B8FF\"> 1}</span><span style=\"color:#9ECBFF\"> failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                if</span><span style=\"color:#E1E4E8\"> attempt </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.config.max_retries </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    await</span><span style=\"color:#E1E4E8\"> asyncio.sleep(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.config.retry_delay </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\"> **</span><span style=\"color:#E1E4E8\"> attempt))</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                else</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                    self</span><span style=\"color:#E1E4E8\">.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                    raise</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> _attempt_recovery</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Attempt to recover database connectivity with pool recreation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        current_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> time.time()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> current_time </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.last_health_check </span><span style=\"color:#F97583\">&#x3C;</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.health_check_interval:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            return</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.last_health_check </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> current_time</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger.info(</span><span style=\"color:#9ECBFF\">\"Attempting database connection recovery\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.primary_pool:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                await</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.primary_pool.close()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            await</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.initialize()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database recovery failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.is_healthy </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton - Error Classification:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Tuple, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> RetryDecision</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    RETRY_IMMEDIATELY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"retry_immediately\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    RETRY_WITH_BACKOFF</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"retry_with_backoff\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    RETRY_WITH_DELAY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"retry_with_delay\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    NO_RETRY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"no_retry\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    MOVE_TO_DLQ</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"move_to_dlq\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> should_retry_delivery</span><span style=\"color:#E1E4E8\">(status_code: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, response_headers: </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, error_type: Optional[NetworkErrorType] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Tuple[RetryDecision, Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Determine retry eligibility based on response characteristics and attempt history.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns tuple of (retry_decision, delay_seconds) where delay_seconds is None</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    for immediate retry or no retry scenarios.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if maximum retry attempts exceeded - return MOVE_TO_DLQ if so</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Handle network-level errors (status_code == 0) based on error_type</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - DNS_RESOLUTION: RETRY_WITH_BACKOFF with exponential delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - CONNECTION_TIMEOUT: RETRY_WITH_BACKOFF, count toward circuit breaker</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - CONNECTION_REFUSED: RETRY_WITH_DELAY with longer delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - READ_TIMEOUT: RETRY_WITH_BACKOFF with normal exponential backoff</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Handle success responses (200-299) - return NO_RETRY</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle client errors (400-499):</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - 408 (Request Timeout): RETRY_WITH_BACKOFF</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - 429 (Rate Limited): RETRY_WITH_DELAY, extract delay from Retry-After header</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - All other 4xx: NO_RETRY (permanent client errors)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle server errors (500-599): RETRY_WITH_BACKOFF for all</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Calculate appropriate delay based on attempt_number and retry decision</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - Use exponential backoff: base_delay * (2 ** attempt_number) with jitter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #         - Cap maximum delay at 300 seconds (5 minutes)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Return tuple of (decision, delay_seconds)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> calculate_retry_delay</span><span style=\"color:#E1E4E8\">(attempt_number: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">, base_delay: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 5</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Calculate exponential backoff delay with jitter to prevent thundering herd.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Base delay doubles with each attempt, adds randomization to spread retry load.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate exponential backoff: base_delay * (2 ** attempt_number)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add jitter: random value between 0.5x and 1.5x the calculated delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply maximum delay cap of 300 seconds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Ensure minimum delay of 1 second</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return integer delay in seconds</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> extract_retry_after_delay</span><span style=\"color:#E1E4E8\">(retry_after_header: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Extract delay from HTTP Retry-After header supporting both seconds and HTTP-date formats.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Returns delay in seconds, or None if header is malformed.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if header value is integer (delay-seconds format)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If integer, validate range (1-86400 seconds) and return</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If not integer, try parsing as HTTP-date format</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Calculate seconds until specified timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return None for malformed headers or past timestamps</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Cap maximum delay at 3600 seconds (1 hour) for security</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Core Logic Skeleton - System Recovery:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Dict, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WorkerHeartbeat</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    worker_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_heartbeat: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    current_event_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_state: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    claimed_events: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SystemRecoveryManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Manages system-level failure recovery including worker crashes and database failures.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, database_manager: DatabaseManager, redis_client, config: </span><span style=\"color:#9ECBFF\">'WebhookConfig'</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> database_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> config</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.logger </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> logging.getLogger(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.worker_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#F97583\"> f</span><span style=\"color:#9ECBFF\">\"worker_</span><span style=\"color:#79B8FF\">{int</span><span style=\"color:#E1E4E8\">(time.time())</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">_</span><span style=\"color:#79B8FF\">{id</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">)</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> run_worker_recovery_monitor</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Continuously monitor for failed workers and recover orphaned events.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Scans worker heartbeats to detect crashes and reclaims orphaned delivery events.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#79B8FF\"> True</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Scan all worker heartbeat keys in Redis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify workers that haven't updated heartbeat within timeout threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: For each failed worker, retrieve its claimed_events list</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Release message locks for orphaned events using XDEL or XCLAIM</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Re-queue orphaned events for processing by healthy workers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Clean up stale worker heartbeat records</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 7: Sleep for monitoring interval before next scan</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                await</span><span style=\"color:#E1E4E8\"> asyncio.sleep(</span><span style=\"color:#79B8FF\">30</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Monitor every 30 seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Worker recovery monitor error: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                await</span><span style=\"color:#E1E4E8\"> asyncio.sleep(</span><span style=\"color:#79B8FF\">60</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Extended delay on errors</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> update_worker_heartbeat</span><span style=\"color:#E1E4E8\">(self, current_event_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">, processing_state: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"idle\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Update worker heartbeat with current processing state.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Heartbeat includes worker health and current processing context for recovery.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create WorkerHeartbeat object with current timestamp and state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Serialize heartbeat data to JSON</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Store in Redis with expiration slightly longer than monitor interval</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle Redis connection errors gracefully (log but don't fail)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update claimed_events list if currently processing events</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> recover_database_connections</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Recover from database connectivity issues with progressive backoff.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Implements tiered recovery strategy based on failure duration and severity.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        recovery_attempts </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        while</span><span style=\"color:#F97583\"> not</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.db.is_healthy:</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Attempt database connection test query</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If successful, mark database as healthy and reset attempt counter</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: If failed, increment recovery_attempts and calculate backoff delay</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Implement progressive backoff: longer delays for repeated failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Log recovery attempts with appropriate severity levels</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">                # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Consider switching to degraded mode after extended failures</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                recovery_attempts </span><span style=\"color:#F97583\">+=</span><span style=\"color:#79B8FF\"> 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                await</span><span style=\"color:#E1E4E8\"> asyncio.sleep(</span><span style=\"color:#79B8FF\">min</span><span style=\"color:#E1E4E8\">(recovery_attempts </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">300</span><span style=\"color:#E1E4E8\">))  </span><span style=\"color:#6A737D\"># Cap at 5 minutes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            except</span><span style=\"color:#79B8FF\"> Exception</span><span style=\"color:#F97583\"> as</span><span style=\"color:#E1E4E8\"> e:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                self</span><span style=\"color:#E1E4E8\">.logger.error(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"Database recovery attempt </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">recovery_attempts</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\"> failed: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">e</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> handle_queue_persistence_failure</span><span style=\"color:#E1E4E8\">(self, event_data: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], error: </span><span style=\"color:#79B8FF\">Exception</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Handle Redis queue failures by falling back to database persistence.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Ensures event delivery guarantees even during message queue outages.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Log the original queue failure with full context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt to persist event to PostgreSQL as fallback</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Mark event with special flag indicating queue failure recovery</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Implement eventual consistency sync when Redis recovers</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Alert operations team about queue persistence issues</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return success/failure status for upstream error handling</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Milestone Checkpoints:</strong></p>\n<p><strong>Error Classification Checkpoint:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test error classification behavior</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_error_scenarios.py</span><span style=\"color:#79B8FF\"> -v</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: All HTTP status codes classified correctly with appropriate retry decisions</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Manual verification:</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">curl</span><span style=\"color:#79B8FF\"> -X</span><span style=\"color:#9ECBFF\"> POST</span><span style=\"color:#9ECBFF\"> localhost:8080/webhooks/test-endpoint/simulate-error</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -H</span><span style=\"color:#9ECBFF\"> \"Content-Type: application/json\"</span><span style=\"color:#79B8FF\"> \\</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">  -d</span><span style=\"color:#9ECBFF\"> '{\"error_type\": \"500\", \"delay\": 30}'</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Retry with exponential backoff, circuit breaker activation after threshold</span></span></code></pre></div>\n\n<p><strong>System Recovery Checkpoint:</strong>  </p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Test worker crash recovery</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#9ECBFF\"> scripts/test_worker_crash.py</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Orphaned events reclaimed within 60 seconds, no delivery loss</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Test database failover</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">docker</span><span style=\"color:#9ECBFF\"> stop</span><span style=\"color:#9ECBFF\"> webhook-postgres</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -c</span><span style=\"color:#9ECBFF\"> \"import src.delivery.worker; worker.process_single_event()\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: Graceful degradation, local buffering, recovery when DB returns</span></span></code></pre></div>\n\n<p><strong>Integration Test Checkpoint:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># End-to-end error handling test</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> pytest</span><span style=\"color:#9ECBFF\"> tests/test_integration_errors.py::test_comprehensive_failure_scenarios</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Expected: System maintains delivery guarantees through cascading failures</span></span></code></pre></div>\n\n<p><strong>Debugging Tips:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnosis Steps</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Events stuck in retry loop</td>\n<td>Incorrect error classification</td>\n<td>Check <code>should_retry_delivery</code> logic for status code</td>\n<td>Fix classification rules, implement circuit breaker</td>\n</tr>\n<tr>\n<td>Worker processes crash silently</td>\n<td>Unhandled exceptions in delivery loop</td>\n<td>Review worker logs, add exception handlers</td>\n<td>Wrap delivery logic in try/catch, implement graceful shutdown</td>\n</tr>\n<tr>\n<td>Database connection exhaustion</td>\n<td>Connection leaks during errors</td>\n<td>Monitor connection pool metrics</td>\n<td>Add connection timeouts, implement aggressive cleanup</td>\n</tr>\n<tr>\n<td>Memory growth during failures</td>\n<td>Event accumulation without processing</td>\n<td>Check dead letter queue size, worker processing rates</td>\n<td>Implement backpressure, increase worker count</td>\n</tr>\n<tr>\n<td>Delivery duplicates after recovery</td>\n<td>Improper message acknowledgment</td>\n<td>Verify XACK calls after successful delivery</td>\n<td>Fix message acknowledgment timing</td>\n</tr>\n</tbody></table>\n<h2 id=\"testing-strategy-and-milestone-checkpoints\">Testing Strategy and Milestone Checkpoints</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) - comprehensive testing strategy covering webhook registration validation (Milestone 1), delivery queue and retry testing (Milestone 2), circuit breaker and rate limiting verification (Milestone 3), and event logging and replay testing (Milestone 4)</p>\n</blockquote>\n<h3 id=\"mental-model-the-quality-assurance-inspection-system\">Mental Model: The Quality Assurance Inspection System</h3>\n<p>Think of testing a webhook delivery system like inspecting a sophisticated mail sorting and delivery operation. Just as a postal service must verify address accuracy, test delivery routes under various conditions, and ensure packages reach their destinations reliably, webhook delivery testing requires systematic validation of registration security, delivery resilience, and failure recovery mechanisms.</p>\n<p>The testing strategy resembles a multi-stage quality control process. First, we inspect incoming mail (webhook registration) to ensure addresses are valid and customers can receive packages. Next, we test the sorting machinery (delivery queues) under normal and peak loads. Then we verify safety systems (circuit breakers) prevent damage when delivery routes fail. Finally, we audit the complete paper trail (event logging) and test our ability to resend lost packages (replay functionality).</p>\n<p>This comprehensive approach ensures our webhook delivery system maintains reliability guarantees even when facing network failures, endpoint downtime, malicious attacks, and system overload conditions.</p>\n<h3 id=\"milestone-verification-checkpoints\">Milestone Verification Checkpoints</h3>\n<p>The milestone verification strategy employs progressive validation, where each checkpoint builds upon the previous milestone&#39;s foundation while introducing new complexity. Each milestone includes specific acceptance tests, behavioral validation, and integration checkpoints that verify the system meets its reliability and security requirements.</p>\n<h4 id=\"milestone-1-webhook-registration-amp-security-testing\">Milestone 1: Webhook Registration &amp; Security Testing</h4>\n<p>The first milestone testing focuses on security validation, SSRF protection, and ownership verification. These tests ensure that webhook endpoints are properly registered, signatures are correctly generated, and malicious registration attempts are blocked.</p>\n<p><strong>Registration Security Validation:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Case</th>\n<th>Expected Behavior</th>\n<th>Verification Method</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Valid HTTPS endpoint registration</td>\n<td>Registration succeeds with generated secret</td>\n<td>POST to <code>/webhooks</code> returns 201 with webhook_id</td>\n</tr>\n<tr>\n<td>HTTP endpoint rejection</td>\n<td>Registration fails with security error</td>\n<td>POST returns 400 with &quot;HTTPS required&quot; message</td>\n</tr>\n<tr>\n<td>Private IP SSRF attempt</td>\n<td>Registration blocked with SSRF protection error</td>\n<td>localhost/192.168.x.x/10.x.x.x URLs return 403</td>\n</tr>\n<tr>\n<td>Challenge-response verification</td>\n<td>Endpoint ownership confirmed via challenge</td>\n<td>Mock endpoint receives GET with challenge token</td>\n</tr>\n<tr>\n<td>Duplicate endpoint registration</td>\n<td>Second registration updates existing webhook</td>\n<td>Same URL returns existing webhook_id</td>\n</tr>\n<tr>\n<td>Invalid URL format</td>\n<td>Registration fails with validation error</td>\n<td>Malformed URLs return 400 with specific error</td>\n</tr>\n</tbody></table>\n<p><strong>Signature Generation Testing:</strong></p>\n<p>The signature verification testing validates HMAC-SHA256 computation, timestamp inclusion, and replay protection mechanisms. These tests ensure webhook signatures provide cryptographic authentication and prevent replay attacks.</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Test Scenario</th>\n<th>Expected Result</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>generate_hmac_signature()</code></td>\n<td>Payload + secret + timestamp</td>\n<td>Deterministic HMAC-SHA256 hex string</td>\n</tr>\n<tr>\n<td>Signature validation</td>\n<td>Valid signature within tolerance</td>\n<td><code>verify_signature()</code> returns True</td>\n</tr>\n<tr>\n<td>Timestamp replay protection</td>\n<td>Signature older than <code>TIMESTAMP_TOLERANCE</code></td>\n<td>Verification fails with replay error</td>\n</tr>\n<tr>\n<td>Secret rotation overlap</td>\n<td>Both old and new secrets valid</td>\n<td>Either signature validates during transition</td>\n</tr>\n<tr>\n<td>Signature header format</td>\n<td>Complete X-Webhook-Signature header</td>\n<td>Format: &quot;t=timestamp,v1=signature&quot;</td>\n</tr>\n</tbody></table>\n<p><strong>Ownership Verification Process:</strong></p>\n<p>The ownership verification testing ensures legitimate endpoint control while preventing unauthorized webhook registration. This process validates challenge-response protocols and timeout handling.</p>\n<ol>\n<li><strong>Challenge Generation</strong>: System generates unique challenge token with 5-minute expiration</li>\n<li><strong>Challenge Delivery</strong>: GET request sent to webhook URL with <code>?webhook_challenge=TOKEN</code> parameter</li>\n<li><strong>Response Validation</strong>: Endpoint must return challenge token in response body within 30 seconds</li>\n<li><strong>Verification Recording</strong>: Successful verification marks <code>WebhookRegistration.verified = True</code></li>\n<li><strong>Retry Logic</strong>: Failed verification attempts retry 3 times with exponential backoff</li>\n<li><strong>Timeout Handling</strong>: Verification failure after retries marks webhook as unverified</li>\n</ol>\n<blockquote>\n<p><strong>Critical Testing Insight:</strong> Ownership verification tests must use real HTTP endpoints (not mocks) to validate network connectivity, DNS resolution, and certificate validation behavior.</p>\n</blockquote>\n<p><strong>Common Registration Pitfalls Testing:</strong></p>\n<p>⚠️ <strong>Pitfall: SSRF Bypass Attempts</strong>\nTest malicious URLs that attempt to bypass SSRF protection through URL encoding, redirects, or DNS rebinding attacks. Validation must catch <code>http://localhost</code>, <code>https://169.254.169.254/</code>, and redirect chains to private IPs.</p>\n<p>⚠️ <strong>Pitfall: Weak Secret Generation</strong>\nVerify webhook secrets use cryptographically secure random generation with sufficient entropy (minimum 256 bits). Secrets should never be predictable or reused across webhooks.</p>\n<p>⚠️ <strong>Pitfall: Timestamp Tolerance Edge Cases</strong>\nTest signature validation with timestamps exactly at tolerance boundaries, accounting for clock skew and network delays. Both past and future timestamp limits must be validated.</p>\n<h4 id=\"milestone-2-delivery-queue-amp-retry-logic-testing\">Milestone 2: Delivery Queue &amp; Retry Logic Testing</h4>\n<p>The second milestone testing validates delivery reliability, retry behavior, and dead letter queue processing. These tests ensure webhook events reach their destinations despite network failures and endpoint downtime.</p>\n<p><strong>Queue Management Testing:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Queue Operation</th>\n<th>Test Scenario</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Event ingestion</td>\n<td>High-volume event creation</td>\n<td>Events queued without loss, ordered by webhook</td>\n</tr>\n<tr>\n<td>Per-endpoint ordering</td>\n<td>Multiple events to same webhook</td>\n<td>FIFO delivery order maintained per endpoint</td>\n</tr>\n<tr>\n<td>Priority handling</td>\n<td>Mix of normal and high priority events</td>\n<td>High priority events delivered first</td>\n</tr>\n<tr>\n<td>Queue persistence</td>\n<td>System restart during processing</td>\n<td>Queued events survive restart and resume processing</td>\n</tr>\n<tr>\n<td>Batch consumption</td>\n<td>Worker claims multiple events</td>\n<td><code>claim_ready_events()</code> returns batch with locks</td>\n</tr>\n</tbody></table>\n<p><strong>Exponential Backoff Validation:</strong></p>\n<p>The retry testing validates exponential backoff behavior, jitter application, and status code-based retry decisions. These tests ensure failed deliveries are retried appropriately without overwhelming recovered endpoints.</p>\n<table>\n<thead>\n<tr>\n<th>Attempt Number</th>\n<th>Base Delay</th>\n<th>Expected Range (with jitter)</th>\n<th>Status Codes to Retry</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>2 seconds</td>\n<td>1.5 - 2.5 seconds</td>\n<td>5xx, 429, timeout, connection error</td>\n</tr>\n<tr>\n<td>2</td>\n<td>4 seconds</td>\n<td>3.0 - 5.0 seconds</td>\n<td>Same as above</td>\n</tr>\n<tr>\n<td>3</td>\n<td>8 seconds</td>\n<td>6.0 - 10.0 seconds</td>\n<td>Same as above</td>\n</tr>\n<tr>\n<td>4</td>\n<td>16 seconds</td>\n<td>12.0 - 20.0 seconds</td>\n<td>Same as above</td>\n</tr>\n<tr>\n<td>5</td>\n<td>32 seconds</td>\n<td>24.0 - 40.0 seconds</td>\n<td>Same as above</td>\n</tr>\n</tbody></table>\n<p><strong>Dead Letter Queue Processing:</strong></p>\n<p>The dead letter queue testing validates that permanently failed events are captured for manual intervention while maintaining complete delivery history for debugging.</p>\n<ol>\n<li><strong>Failure Classification</strong>: Events failing all retry attempts move to DLQ with failure reason</li>\n<li><strong>Attempt History Preservation</strong>: Complete <code>DeliveryAttempt</code> records maintained for debugging</li>\n<li><strong>Manual Inspection Interface</strong>: DLQ provides filtering and search capabilities for operators</li>\n<li><strong>Bulk Replay Support</strong>: Selected DLQ events can be replayed after endpoint recovery</li>\n<li><strong>Alerting Integration</strong>: DLQ growth triggers alerts for immediate operator attention</li>\n</ol>\n<p><strong>HTTP Delivery Client Testing:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Test Case</th>\n<th>Mock Response</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Successful delivery</td>\n<td>200 OK with response body</td>\n<td>Mark delivery successful, no retry</td>\n</tr>\n<tr>\n<td>Temporary server error</td>\n<td>503 Service Unavailable</td>\n<td>Schedule exponential backoff retry</td>\n</tr>\n<tr>\n<td>Rate limiting response</td>\n<td>429 with Retry-After: 60</td>\n<td>Respect Retry-After header, bypass normal backoff</td>\n</tr>\n<tr>\n<td>Client error response</td>\n<td>400 Bad Request</td>\n<td>Do not retry, log as permanent failure</td>\n</tr>\n<tr>\n<td>Connection timeout</td>\n<td>No response within <code>DELIVERY_TIMEOUT</code></td>\n<td>Treat as temporary failure, retry</td>\n</tr>\n<tr>\n<td>DNS resolution failure</td>\n<td>Network error</td>\n<td>Treat as temporary failure, retry</td>\n</tr>\n</tbody></table>\n<blockquote>\n<p><strong>Testing Architecture Decision:</strong> Use real HTTP servers for integration tests rather than mocking HTTP responses. This validates timeout handling, connection pooling, and certificate validation behavior that mocks cannot replicate.</p>\n</blockquote>\n<p><strong>Delivery Worker Testing:</strong></p>\n<p>The delivery worker testing validates concurrent processing, graceful shutdown, and worker recovery mechanisms. These tests ensure the delivery engine scales reliably under production loads.</p>\n<p>Worker behavior validation includes:</p>\n<ul>\n<li><strong>Concurrent Processing</strong>: Multiple workers process different webhook queues simultaneously</li>\n<li><strong>Graceful Shutdown</strong>: Workers complete in-flight deliveries before terminating</li>\n<li><strong>Worker Health Monitoring</strong>: Heartbeat mechanism detects crashed workers</li>\n<li><strong>Load Balancing</strong>: Event distribution spreads work across available workers</li>\n<li><strong>Resource Limits</strong>: Workers respect memory and connection pool limits</li>\n</ul>\n<h4 id=\"milestone-3-circuit-breaker-amp-rate-limiting-testing\">Milestone 3: Circuit Breaker &amp; Rate Limiting Testing</h4>\n<p>The third milestone testing validates endpoint protection mechanisms, ensuring failing endpoints don&#39;t overwhelm the system while rate limiting prevents abuse.</p>\n<p><strong>Circuit Breaker State Machine Testing:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Current State</th>\n<th>Failure Count</th>\n<th>Action</th>\n<th>Next State</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CLOSED</td>\n<td>0-4 failures</td>\n<td>Delivery attempt</td>\n<td>CLOSED</td>\n<td>Normal delivery processing</td>\n</tr>\n<tr>\n<td>CLOSED</td>\n<td>5 failures</td>\n<td>Delivery failure</td>\n<td>OPEN</td>\n<td>Block all deliveries, start recovery timer</td>\n</tr>\n<tr>\n<td>OPEN</td>\n<td>Any</td>\n<td>Delivery attempt</td>\n<td>OPEN</td>\n<td>Reject immediately, no HTTP call</td>\n</tr>\n<tr>\n<td>OPEN</td>\n<td>Timer expires</td>\n<td>Recovery check</td>\n<td>HALF_OPEN</td>\n<td>Allow single test delivery</td>\n</tr>\n<tr>\n<td>HALF_OPEN</td>\n<td>1 success</td>\n<td>Test delivery succeeds</td>\n<td>CLOSED</td>\n<td>Resume normal processing</td>\n</tr>\n<tr>\n<td>HALF_OPEN</td>\n<td>1 failure</td>\n<td>Test delivery fails</td>\n<td>OPEN</td>\n<td>Extend recovery timeout</td>\n</tr>\n</tbody></table>\n<p><strong>Rate Limiting Validation:</strong></p>\n<p>The rate limiting testing validates token bucket behavior, burst capacity handling, and Retry-After header respect. These tests ensure endpoints aren&#39;t overwhelmed while maintaining delivery throughput.</p>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Request Rate</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Normal operation</td>\n<td>50 RPM (under 60 limit)</td>\n<td>All deliveries proceed immediately</td>\n</tr>\n<tr>\n<td>Rate limit hit</td>\n<td>70 RPM (over 60 limit)</td>\n<td>Excess requests delayed to maintain 60 RPM</td>\n</tr>\n<tr>\n<td>Burst handling</td>\n<td>120 requests in 30 seconds</td>\n<td>First 60 proceed, remainder spaced over next minute</td>\n</tr>\n<tr>\n<td>Retry-After respect</td>\n<td>429 with Retry-After: 300</td>\n<td>Wait 300 seconds before next attempt</td>\n</tr>\n<tr>\n<td>Rate limit recovery</td>\n<td>Return to normal rate</td>\n<td>Resume immediate processing</td>\n</tr>\n</tbody></table>\n<p><strong>Circuit Breaker Configuration Testing:</strong></p>\n<p>The circuit breaker configuration testing validates different failure thresholds and recovery timeouts for various endpoint reliability profiles.</p>\n<table>\n<thead>\n<tr>\n<th>Endpoint Type</th>\n<th>Failure Threshold</th>\n<th>Base Recovery Timeout</th>\n<th>Max Recovery Timeout</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Critical production</td>\n<td>3 failures</td>\n<td>30 seconds</td>\n<td>300 seconds</td>\n</tr>\n<tr>\n<td>Standard endpoint</td>\n<td>5 failures</td>\n<td>60 seconds</td>\n<td>600 seconds</td>\n</tr>\n<tr>\n<td>Development/test</td>\n<td>10 failures</td>\n<td>10 seconds</td>\n<td>120 seconds</td>\n</tr>\n</tbody></table>\n<p><strong>Health Monitoring Integration:</strong></p>\n<p>The health monitoring testing validates success rate tracking, latency measurement, and automated recovery detection for circuit breaker decision making.</p>\n<p>Health metrics tracked include:</p>\n<ul>\n<li><strong>Success Rate</strong>: Percentage of successful deliveries over sliding time window</li>\n<li><strong>Response Latency</strong>: P50, P95, P99 response times for endpoint performance</li>\n<li><strong>Error Distribution</strong>: Classification of 4xx vs 5xx vs network errors</li>\n<li><strong>Recovery Signals</strong>: Sustained success after circuit breaker opens</li>\n</ul>\n<h4 id=\"milestone-4-event-logging-amp-replay-testing\">Milestone 4: Event Logging &amp; Replay Testing</h4>\n<p>The fourth milestone testing validates comprehensive audit trails, replay functionality, and log retention management for compliance and debugging requirements.</p>\n<p><strong>Event Logging Comprehensive Testing:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Log Component</th>\n<th>Data Captured</th>\n<th>Storage Requirements</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Delivery attempts</td>\n<td>Full HTTP request/response, timing, worker ID</td>\n<td>Hot storage 30 days</td>\n</tr>\n<tr>\n<td>Replay operations</td>\n<td>Operator ID, reason, event list, rate overrides</td>\n<td>Permanent retention</td>\n</tr>\n<tr>\n<td>Circuit breaker events</td>\n<td>State changes, failure reasons, recovery timing</td>\n<td>Warm storage 1 year</td>\n</tr>\n<tr>\n<td>Security events</td>\n<td>Registration attempts, SSRF blocks, signature failures</td>\n<td>Cold storage 3 years</td>\n</tr>\n</tbody></table>\n<p><strong>Event Replay Safety Testing:</strong></p>\n<p>The replay testing validates safe re-delivery with deduplication support, rate limiting respect, and circuit breaker integration.</p>\n<p>Replay safety validations include:</p>\n<ol>\n<li><strong>Deduplication Headers</strong>: Replayed events include <code>X-Webhook-Replay-Id</code> and <code>X-Webhook-Original-Delivery-Id</code></li>\n<li><strong>Rate Limit Respect</strong>: Replay operations honor current rate limits unless explicitly overridden</li>\n<li><strong>Circuit Breaker Integration</strong>: Replay attempts blocked if circuit breaker is open</li>\n<li><strong>Bulk Replay Protection</strong>: Large replay operations spread across time to prevent endpoint overwhelming</li>\n<li><strong>Operator Audit Trail</strong>: Complete logging of who initiated replay and why</li>\n</ol>\n<p><strong>Log Retention Policy Testing:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Storage Tier</th>\n<th>Retention Period</th>\n<th>Migration Trigger</th>\n<th>Compression</th>\n<th>Query Performance</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Hot</td>\n<td>30 days</td>\n<td>Age-based</td>\n<td>None</td>\n<td>Sub-second</td>\n</tr>\n<tr>\n<td>Warm</td>\n<td>365 days</td>\n<td>30 day age</td>\n<td>GZIP</td>\n<td>Seconds</td>\n</tr>\n<tr>\n<td>Cold</td>\n<td>1095 days</td>\n<td>365 day age</td>\n<td>LZMA</td>\n<td>Minutes</td>\n</tr>\n<tr>\n<td>Archive</td>\n<td>7 years</td>\n<td>3 year age</td>\n<td>Maximum</td>\n<td>Hours</td>\n</tr>\n</tbody></table>\n<p><strong>Replay Operation Testing:</strong></p>\n<p>The replay operation testing validates various replay scenarios including single event replay, bulk operations, and selective filtering.</p>\n<table>\n<thead>\n<tr>\n<th>Replay Type</th>\n<th>Test Scenario</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Single event</td>\n<td>Operator replays specific failed delivery</td>\n<td>Event re-queued with replay metadata</td>\n</tr>\n<tr>\n<td>Bulk replay</td>\n<td>Replay all events for endpoint in time range</td>\n<td>Events processed with rate limiting</td>\n</tr>\n<tr>\n<td>Filtered replay</td>\n<td>Replay only events matching event_type filter</td>\n<td>Correct subset identified and replayed</td>\n</tr>\n<tr>\n<td>Cross-endpoint replay</td>\n<td>Replay events across multiple webhooks</td>\n<td>Per-endpoint rate limits respected</td>\n</tr>\n</tbody></table>\n<h3 id=\"integration-testing-strategy\">Integration Testing Strategy</h3>\n<p>The integration testing strategy validates end-to-end workflows using realistic scenarios with mock webhook endpoints. These tests ensure component interactions work correctly under various network conditions and failure scenarios.</p>\n<h4 id=\"end-to-end-scenario-testing\">End-to-End Scenario Testing</h4>\n<p><strong>Complete Webhook Lifecycle Testing:</strong></p>\n<p>The end-to-end testing validates the complete webhook lifecycle from registration through successful delivery, including all intermediate states and error conditions.</p>\n<p>Integration test scenarios include:</p>\n<ol>\n<li><strong>Successful Flow</strong>: Register webhook → verify ownership → receive events → deliver successfully</li>\n<li><strong>Failure Recovery</strong>: Endpoint fails → retry with backoff → circuit breaker opens → endpoint recovers → circuit closes</li>\n<li><strong>Rate Limiting</strong>: High event volume → rate limiting activated → deliveries throttled → backlog processed</li>\n<li><strong>Replay Scenario</strong>: Delivery failures → events in DLQ → endpoint fixed → successful replay</li>\n</ol>\n<p><strong>Mock Endpoint Testing Infrastructure:</strong></p>\n<p>The mock endpoint infrastructure provides controlled webhook targets that simulate various endpoint behaviors for comprehensive testing coverage.</p>\n<table>\n<thead>\n<tr>\n<th>Mock Behavior</th>\n<th>Configuration</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Successful endpoint</td>\n<td>Always return 200 OK</td>\n<td>Happy path testing</td>\n</tr>\n<tr>\n<td>Intermittent failures</td>\n<td>Random 5xx responses</td>\n<td>Retry logic testing</td>\n</tr>\n<tr>\n<td>Rate limited endpoint</td>\n<td>Return 429 after N requests</td>\n<td>Rate limiting testing</td>\n</tr>\n<tr>\n<td>Slow endpoint</td>\n<td>Configurable response delay</td>\n<td>Timeout testing</td>\n</tr>\n<tr>\n<td>Malicious endpoint</td>\n<td>Redirect to private IPs</td>\n<td>SSRF protection testing</td>\n</tr>\n</tbody></table>\n<p><strong>Network Condition Simulation:</strong></p>\n<p>The network simulation testing validates webhook delivery behavior under various network conditions including latency, packet loss, and connectivity failures.</p>\n<p>Network simulation scenarios:</p>\n<ul>\n<li><strong>High Latency</strong>: 500ms+ response times to test timeout handling</li>\n<li><strong>Packet Loss</strong>: Intermittent connection failures to test retry behavior  </li>\n<li><strong>DNS Failures</strong>: Temporary name resolution failures</li>\n<li><strong>Connection Limits</strong>: Endpoint refusing connections to test backpressure</li>\n<li><strong>SSL Certificate Issues</strong>: Invalid certificates to test security validation</li>\n</ul>\n<blockquote>\n<p><strong>Integration Testing Architecture Decision:</strong> Use containerized test environments with network policy controls rather than live internet endpoints. This provides deterministic network conditions while preventing accidental external service calls during testing.</p>\n</blockquote>\n<h4 id=\"component-integration-validation\">Component Integration Validation</h4>\n<p><strong>Registry-Delivery Integration:</strong></p>\n<p>The registry-delivery integration testing validates data flow between webhook registration and event delivery systems.</p>\n<p>Integration validation points:</p>\n<ol>\n<li><strong>Webhook Lookup</strong>: Delivery engine correctly retrieves webhook configuration from registry</li>\n<li><strong>Secret Management</strong>: Signature generation uses current active secret from registry</li>\n<li><strong>Circuit Breaker State</strong>: Registry reflects current circuit breaker status from delivery engine</li>\n<li><strong>Configuration Updates</strong>: Changes to webhook configuration propagate to delivery workers</li>\n</ol>\n<p><strong>Queue-Worker Integration:</strong></p>\n<p>The queue-worker integration testing validates message processing, acknowledgment, and failure handling between queue management and delivery workers.</p>\n<table>\n<thead>\n<tr>\n<th>Integration Aspect</th>\n<th>Test Scenario</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Message acknowledgment</td>\n<td>Successful delivery</td>\n<td>Message removed from queue</td>\n</tr>\n<tr>\n<td>Failure handling</td>\n<td>Delivery fails, not exhausted</td>\n<td>Message rescheduled with backoff</td>\n</tr>\n<tr>\n<td>Dead letter routing</td>\n<td>All retries exhausted</td>\n<td>Message moved to DLQ</td>\n</tr>\n<tr>\n<td>Worker crash recovery</td>\n<td>Worker dies during processing</td>\n<td>Message returns to queue</td>\n</tr>\n<tr>\n<td>Queue persistence</td>\n<td>System restart</td>\n<td>Messages survive and resume processing</td>\n</tr>\n</tbody></table>\n<p><strong>Circuit Breaker-Rate Limiter Integration:</strong></p>\n<p>The circuit breaker and rate limiter integration testing validates protection mechanism coordination and proper prioritization of protection rules.</p>\n<p>Protection mechanism coordination:</p>\n<ul>\n<li><strong>Circuit Open</strong>: Rate limiter bypassed when circuit breaker blocks delivery</li>\n<li><strong>Rate Limited</strong>: Circuit breaker failure count not incremented for rate limited requests</li>\n<li><strong>Recovery Coordination</strong>: Both systems must agree endpoint is healthy for full recovery</li>\n<li><strong>Configuration Conflicts</strong>: Rate limits that would trigger circuit breaker thresholds</li>\n</ul>\n<h4 id=\"multi-component-failure-testing\">Multi-Component Failure Testing</h4>\n<p><strong>Cascading Failure Scenarios:</strong></p>\n<p>The cascading failure testing validates system behavior when multiple components fail simultaneously, ensuring graceful degradation rather than complete system failure.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Combination</th>\n<th>System Response</th>\n<th>Recovery Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Database + Queue failure</td>\n<td>Accept events in memory buffer</td>\n<td>Persist when connectivity returns</td>\n</tr>\n<tr>\n<td>Multiple worker failures</td>\n<td>Remaining workers handle load</td>\n<td>Auto-scale or alert operators</td>\n</tr>\n<tr>\n<td>Registry + Circuit breaker failure</td>\n<td>Use cached webhook configuration</td>\n<td>Refresh when registry recovers</td>\n</tr>\n<tr>\n<td>Rate limiter + Network partition</td>\n<td>Default to conservative rate limits</td>\n<td>Sync state when partition heals</td>\n</tr>\n</tbody></table>\n<p><strong>Resource Exhaustion Testing:</strong></p>\n<p>The resource exhaustion testing validates system behavior under memory, CPU, and network connection limits.</p>\n<p>Resource exhaustion scenarios:</p>\n<ul>\n<li><strong>Memory Pressure</strong>: Large event payloads consuming available memory</li>\n<li><strong>Connection Pool Exhaustion</strong>: More concurrent deliveries than HTTP connections</li>\n<li><strong>CPU Saturation</strong>: Signature generation overwhelming processing capacity  </li>\n<li><strong>Disk Space</strong>: Event logs filling available storage</li>\n<li><strong>Queue Depth</strong>: More events than queue system can efficiently handle</li>\n</ul>\n<h3 id=\"load-and-reliability-testing\">Load and Reliability Testing</h3>\n<p>The load and reliability testing validates system performance under production-scale traffic while maintaining delivery guarantees and protection mechanisms.</p>\n<h4 id=\"stress-testing-delivery-queues\">Stress Testing Delivery Queues</h4>\n<p><strong>High-Volume Event Processing:</strong></p>\n<p>The high-volume testing validates queue performance, worker scaling, and delivery throughput under realistic production loads.</p>\n<table>\n<thead>\n<tr>\n<th>Load Level</th>\n<th>Events/Second</th>\n<th>Webhooks</th>\n<th>Expected Throughput</th>\n<th>Queue Depth Limit</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Light</td>\n<td>100</td>\n<td>50</td>\n<td>&lt;1 second delivery</td>\n<td>&lt;1000 events</td>\n</tr>\n<tr>\n<td>Moderate</td>\n<td>1,000</td>\n<td>500</td>\n<td>&lt;5 second delivery</td>\n<td>&lt;10,000 events</td>\n</tr>\n<tr>\n<td>Heavy</td>\n<td>10,000</td>\n<td>2,000</td>\n<td>&lt;30 second delivery</td>\n<td>&lt;100,000 events</td>\n</tr>\n<tr>\n<td>Peak</td>\n<td>50,000</td>\n<td>5,000</td>\n<td>&lt;5 minute delivery</td>\n<td>&lt;500,000 events</td>\n</tr>\n</tbody></table>\n<p><strong>Queue Scaling Behavior:</strong></p>\n<p>The queue scaling testing validates horizontal and vertical scaling behavior as event volume increases.</p>\n<p>Queue scaling validations:</p>\n<ol>\n<li><strong>Worker Auto-scaling</strong>: Additional workers start when queue depth increases</li>\n<li><strong>Memory Management</strong>: Queue system handles large event backlogs without memory exhaustion</li>\n<li><strong>Persistence Performance</strong>: High write volumes don&#39;t degrade queue persistence</li>\n<li><strong>Query Performance</strong>: Event claiming performance remains stable under load</li>\n<li><strong>Graceful Degradation</strong>: System prioritizes critical events when overwhelmed</li>\n</ol>\n<h4 id=\"circuit-breaker-load-testing\">Circuit Breaker Load Testing</h4>\n<p><strong>Failure Threshold Validation:</strong></p>\n<p>The circuit breaker load testing validates protection mechanism behavior under high failure rates and recovery scenarios.</p>\n<table>\n<thead>\n<tr>\n<th>Failure Rate</th>\n<th>Circuit Response</th>\n<th>Recovery Time</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>10% failures</td>\n<td>Circuit remains closed</td>\n<td>N/A</td>\n<td>Normal retry processing</td>\n</tr>\n<tr>\n<td>50% failures</td>\n<td>Circuit opens quickly</td>\n<td>60 seconds</td>\n<td>Block further attempts</td>\n</tr>\n<tr>\n<td>90% failures</td>\n<td>Circuit opens immediately</td>\n<td>300 seconds</td>\n<td>Extended recovery timeout</td>\n</tr>\n<tr>\n<td>100% failures</td>\n<td>Circuit opens on threshold</td>\n<td>600 seconds</td>\n<td>Maximum recovery timeout</td>\n</tr>\n</tbody></table>\n<p><strong>Recovery Performance Testing:</strong></p>\n<p>The recovery performance testing validates circuit breaker behavior during endpoint recovery, ensuring prompt resumption of normal delivery without overwhelming recovering endpoints.</p>\n<p>Recovery validation scenarios:</p>\n<ul>\n<li><strong>Gradual Recovery</strong>: Endpoint success rate slowly improves over time</li>\n<li><strong>Immediate Recovery</strong>: Endpoint immediately returns to full functionality</li>\n<li><strong>False Recovery</strong>: Endpoint appears recovered but fails again quickly</li>\n<li><strong>Partial Recovery</strong>: Endpoint handles some request types but not others</li>\n</ul>\n<h4 id=\"rate-limiting-performance\">Rate Limiting Performance</h4>\n<p><strong>Token Bucket Algorithm Validation:</strong></p>\n<p>The token bucket performance testing validates rate limiting accuracy and fairness under various load patterns.</p>\n<table>\n<thead>\n<tr>\n<th>Load Pattern</th>\n<th>Request Distribution</th>\n<th>Expected Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Steady state</td>\n<td>Evenly distributed</td>\n<td>Smooth delivery rate</td>\n</tr>\n<tr>\n<td>Burst traffic</td>\n<td>High initial spike</td>\n<td>Burst allowed, then throttled</td>\n</tr>\n<tr>\n<td>Bursty workload</td>\n<td>Periodic spikes</td>\n<td>Each burst handled independently</td>\n</tr>\n<tr>\n<td>Sustained overload</td>\n<td>Continuous high rate</td>\n<td>Strict rate enforcement</td>\n</tr>\n</tbody></table>\n<p><strong>Rate Limiting Fairness:</strong></p>\n<p>The rate limiting fairness testing validates that webhook endpoints receive fair treatment and aren&#39;t starved by high-volume endpoints.</p>\n<p>Fairness validation includes:</p>\n<ul>\n<li><strong>Per-endpoint Isolation</strong>: High-volume webhook doesn&#39;t affect others</li>\n<li><strong>Priority Handling</strong>: Critical events bypass normal rate limits</li>\n<li><strong>Adaptive Limits</strong>: Rate limits adjust based on endpoint capacity</li>\n<li><strong>Burst Credit</strong>: Endpoints accumulate burst capacity during quiet periods</li>\n</ul>\n<h4 id=\"reliability-under-failure-conditions\">Reliability Under Failure Conditions</h4>\n<p><strong>Network Partition Resilience:</strong></p>\n<p>The network partition testing validates system behavior when components cannot communicate, ensuring data consistency and recovery when connectivity returns.</p>\n<table>\n<thead>\n<tr>\n<th>Partition Scenario</th>\n<th>System Response</th>\n<th>Data Consistency</th>\n<th>Recovery Behavior</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Worker-Queue partition</td>\n<td>Workers use local buffer</td>\n<td>At-least-once delivery</td>\n<td>Sync on reconnect</td>\n</tr>\n<tr>\n<td>Registry-Worker partition</td>\n<td>Use cached webhook config</td>\n<td>Eventual consistency</td>\n<td>Refresh on reconnect</td>\n</tr>\n<tr>\n<td>Database partition</td>\n<td>Read-only mode with alerts</td>\n<td>Read-only consistency</td>\n<td>Full sync on reconnect</td>\n</tr>\n</tbody></table>\n<p><strong>Component Crash Recovery:</strong></p>\n<p>The crash recovery testing validates data persistence and state recovery when individual components fail unexpectedly.</p>\n<p>Component crash scenarios:</p>\n<ul>\n<li><strong>Worker Process Crash</strong>: In-flight deliveries return to queue, processing resumes</li>\n<li><strong>Queue System Crash</strong>: Persistent events survive restart, temporary buffer lost</li>\n<li><strong>Database Crash</strong>: Transaction log enables full state recovery</li>\n<li><strong>Registry Crash</strong>: Webhook configuration cached by workers continues operation</li>\n</ul>\n<blockquote>\n<p><strong>Reliability Testing Architecture Decision:</strong> Use chaos engineering techniques with random component failures rather than scheduled maintenance windows. This validates recovery mechanisms under realistic failure timing and ensures production resilience.</p>\n</blockquote>\n<p><strong>Performance Degradation Testing:</strong></p>\n<p>The performance degradation testing validates graceful performance reduction rather than complete failure when system resources become constrained.</p>\n<p>Performance degradation scenarios:</p>\n<ul>\n<li><strong>Slow Database</strong>: Increased query latency affects event processing speed</li>\n<li><strong>Limited Memory</strong>: Reduced buffer sizes slow event ingestion</li>\n<li><strong>CPU Throttling</strong>: Signature generation becomes bottleneck</li>\n<li><strong>Network Congestion</strong>: Delivery attempts experience higher latency</li>\n</ul>\n<h4 id=\"load-testing-results-analysis\">Load Testing Results Analysis</h4>\n<p><strong>Performance Metrics Collection:</strong></p>\n<p>The load testing metrics provide comprehensive performance visibility for capacity planning and performance optimization.</p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Key Measurements</th>\n<th>Target Values</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Throughput</td>\n<td>Events processed/second</td>\n<td>10,000+ events/sec</td>\n</tr>\n<tr>\n<td>Latency</td>\n<td>End-to-end delivery time</td>\n<td>P95 &lt; 30 seconds</td>\n</tr>\n<tr>\n<td>Error Rates</td>\n<td>Failed deliveries/total</td>\n<td>&lt; 0.1% permanent failures</td>\n</tr>\n<tr>\n<td>Resource Usage</td>\n<td>CPU, memory, disk I/O</td>\n<td>&lt; 70% sustained usage</td>\n</tr>\n<tr>\n<td>Queue Metrics</td>\n<td>Queue depth, processing lag</td>\n<td>&lt; 60 second queue lag</td>\n</tr>\n</tbody></table>\n<p><strong>Capacity Planning Data:</strong></p>\n<p>The capacity planning analysis provides scaling recommendations based on load testing results and resource utilization patterns.</p>\n<p>Scaling recommendations include:</p>\n<ul>\n<li><strong>Worker Scaling</strong>: Events per second to worker count ratios</li>\n<li><strong>Database Scaling</strong>: Connection pool sizing for concurrent webhook management</li>\n<li><strong>Queue Scaling</strong>: Memory and disk requirements for various queue depths</li>\n<li><strong>Network Scaling</strong>: Bandwidth requirements for delivery throughput</li>\n<li><strong>Storage Scaling</strong>: Log storage growth rates and retention requirements</li>\n</ul>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The testing implementation provides comprehensive test infrastructure for validating webhook delivery system reliability across all milestones. This guidance includes complete test frameworks, mock infrastructure, and validation tools.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Test Framework</td>\n<td><code>pytest</code> with fixtures</td>\n<td><code>pytest</code> + <code>pytest-asyncio</code> + <code>pytest-xdist</code></td>\n</tr>\n<tr>\n<td>HTTP Mocking</td>\n<td><code>responses</code> library</td>\n<td>Custom HTTP server with <code>aiohttp</code></td>\n</tr>\n<tr>\n<td>Database Testing</td>\n<td>SQLite in-memory</td>\n<td>PostgreSQL test containers</td>\n</tr>\n<tr>\n<td>Queue Testing</td>\n<td>Redis test instance</td>\n<td>RabbitMQ test containers</td>\n</tr>\n<tr>\n<td>Load Testing</td>\n<td><code>locust</code> with Python</td>\n<td><code>k6</code> with JavaScript scenarios</td>\n</tr>\n<tr>\n<td>Mock Services</td>\n<td><code>Flask</code> test servers</td>\n<td><code>Docker Compose</code> test environment</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-system/\n  tests/\n    unit/\n      test_webhook_registry.py      ← Registry component tests\n      test_delivery_engine.py       ← Delivery and retry logic tests  \n      test_circuit_breaker.py       ← Circuit breaker state tests\n      test_event_logging.py         ← Logging and replay tests\n    integration/\n      test_end_to_end.py           ← Complete workflow tests\n      test_failure_scenarios.py    ← Error condition tests\n      test_component_integration.py ← Inter-component tests\n    load/\n      test_queue_performance.py     ← Queue scaling tests\n      test_delivery_throughput.py   ← Delivery performance tests\n      locustfile.py                ← Load testing scenarios\n    fixtures/\n      mock_endpoints.py            ← HTTP endpoint mocking\n      test_data.py                 ← Test data generation\n      database_setup.py            ← Test database management\n    conftest.py                    ← Pytest configuration and fixtures\n  scripts/\n    run_milestone_tests.py         ← Milestone validation runner\n    performance_analysis.py       ← Load test result analysis</code></pre></div>\n\n<h4 id=\"mock-infrastructure-implementation\">Mock Infrastructure Implementation</h4>\n<p><strong>Complete HTTP Endpoint Mocking:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/fixtures/mock_endpoints.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Comprehensive HTTP endpoint mocking for webhook delivery testing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides configurable endpoint behaviors for integration testing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Callable</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> flask </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Flask, request, jsonify, Response</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> threading</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> EndpointConfig</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configuration for mock webhook endpoint behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    success_rate: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 1.0</span><span style=\"color:#6A737D\">  # 0.0 to 1.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_delay: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0.0</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    status_codes: List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#6A737D\">  # Custom status code distribution</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_rpm: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    response_body: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"OK\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    custom_headers: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __post_init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.status_codes </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.status_codes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span><span style=\"color:#79B8FF\">200</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.custom_headers </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            self</span><span style=\"color:#E1E4E8\">.custom_headers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MockWebhookEndpoint</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Configurable mock webhook endpoint for testing delivery behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, port: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 0</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.app </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> Flask(</span><span style=\"color:#79B8FF\">__name__</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.port </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> port</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.server </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.thread </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.configs: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, EndpointConfig] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.request_history: List[Dict] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rate_limit_counters: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Setup Flask routes</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.app.add_url_rule(</span><span style=\"color:#9ECBFF\">'/webhook/&#x3C;endpoint_id>'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'webhook'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                             self</span><span style=\"color:#E1E4E8\">.handle_webhook, </span><span style=\"color:#FFAB70\">methods</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">'POST'</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.app.add_url_rule(</span><span style=\"color:#9ECBFF\">'/challenge/&#x3C;endpoint_id>'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">'challenge'</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">                             self</span><span style=\"color:#E1E4E8\">.handle_challenge, </span><span style=\"color:#FFAB70\">methods</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">'GET'</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> configure_endpoint</span><span style=\"color:#E1E4E8\">(self, endpoint_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, config: EndpointConfig):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Configure behavior for specific endpoint ID.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Store endpoint configuration in configs dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Initialize rate limiting counter for endpoint if specified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Validate configuration parameters (success_rate 0-1, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_webhook</span><span style=\"color:#E1E4E8\">(self, endpoint_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Response:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle webhook POST request with configured behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Record request details in request_history</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check rate limiting if configured for endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply response delay if configured</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Determine response status code based on success_rate</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return response with configured body and headers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> handle_challenge</span><span style=\"color:#E1E4E8\">(self, endpoint_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Response:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Handle ownership verification challenge.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract challenge token from query parameters</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Return challenge token in response body</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Log challenge attempt in request_history</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> check_rate_limit</span><span style=\"color:#E1E4E8\">(self, endpoint_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Check if request should be rate limited.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Get rate limit configuration for endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Clean old timestamps outside rate limit window  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Count requests in current window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Return True if under limit, False if rate limited</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_request_count</span><span style=\"color:#E1E4E8\">(self, endpoint_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Get total request count for endpoint.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> len</span><span style=\"color:#E1E4E8\">([r </span><span style=\"color:#F97583\">for</span><span style=\"color:#E1E4E8\"> r </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.request_history </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">                   if</span><span style=\"color:#E1E4E8\"> r[</span><span style=\"color:#9ECBFF\">'endpoint_id'</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">==</span><span style=\"color:#E1E4E8\"> endpoint_id])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> clear_history</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clear request history for fresh test.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.request_history.clear()</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.rate_limit_counters.clear()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> mock_webhook_server</span><span style=\"color:#E1E4E8\">(configs: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, EndpointConfig]):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Context manager for mock webhook server lifecycle.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    server </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> MockWebhookEndpoint()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Configure endpoints with provided configs</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Start server in background thread</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Yield server instance for test use</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Clean shutdown server and thread</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Database Test Infrastructure:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/fixtures/database_setup.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Test database infrastructure for webhook system testing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides isolated database instances for test execution.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> tempfile</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> contextlib </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_system.database </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DatabaseManager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_system.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Base</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestDatabaseManager</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Database manager for testing with cleanup capabilities.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, database_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        if</span><span style=\"color:#E1E4E8\"> database_url </span><span style=\"color:#F97583\">is</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # Use in-memory SQLite for unit tests</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            database_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"sqlite:///:memory:\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.database_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> database_url</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.db_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> DatabaseManager(database_url)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> setup_test_database</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize test database with schema.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create all tables using SQLAlchemy models</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Seed test data if specified in fixture</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Return database connection for test use</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> cleanup_test_database</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Clean up test database after test completion.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Close all active connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Drop all tables if using dedicated test database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Remove temporary files if using file-based SQLite</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_transaction</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Provide transactional test context with rollback.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Begin database transaction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Yield connection for test operations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Rollback transaction on exit (keeps database clean)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@contextmanager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_database_session</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Provide clean database session for each test.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    db_manager </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> TestDatabaseManager()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    try</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Setup test database schema</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Yield database manager for test use  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Cleanup database after test completion</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    finally</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Ensure cleanup even if test fails</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"core-test-implementation-skeletons\">Core Test Implementation Skeletons</h4>\n<p><strong>Milestone 1 Registration Testing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/unit/test_webhook_registry.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Comprehensive webhook registration and security testing.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Validates HMAC signatures, SSRF protection, and ownership verification.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> unittest.mock </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Mock, patch</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_system.registry </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookRegistry</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_system.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookRegistration, WebhookSecret</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestWebhookRegistration</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test webhook endpoint registration functionality.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> registry</span><span style=\"color:#E1E4E8\">(self, test_database):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> WebhookRegistry(test_database)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_valid_https_registration</span><span style=\"color:#E1E4E8\">(self, registry):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test successful webhook registration with valid HTTPS URL.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Call register_webhook with valid HTTPS URL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify webhook record created in database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify secret generated and stored</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify webhook marked as unverified initially</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify response contains webhook_id and secret</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_http_url_rejection</span><span style=\"color:#E1E4E8\">(self, registry):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test rejection of HTTP URLs for security.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Attempt registration with HTTP URL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify registration fails with security error</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify no database record created</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify error message mentions HTTPS requirement</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_ssrf_protection</span><span style=\"color:#E1E4E8\">(self, registry):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test SSRF protection against private IP addresses.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ssrf_urls </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"https://localhost/webhook\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"https://127.0.0.1/webhook\"</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"https://192.168.1.100/webhook\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"https://10.0.0.1/webhook\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"https://169.254.169.254/webhook\"</span><span style=\"color:#6A737D\">  # AWS metadata</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> url </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> ssrf_urls:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Attempt registration with SSRF URL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify registration blocked with SSRF error</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify no database record created</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestHMACSignatures</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test HMAC-SHA256 signature generation and validation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_signature_generation</span><span style=\"color:#E1E4E8\">(self, registry):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test deterministic HMAC signature generation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        payload </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> '{\"event\": \"test\", \"data\": {\"key\": \"value\"</span><span style=\"color:#79B8FF\">}}</span><span style=\"color:#9ECBFF\">'</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        secret </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"test_secret_key_12345\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 1640995200</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate signature using generate_hmac_signature</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify signature is consistent across multiple calls</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify signature format matches expected pattern</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify signature changes with different payload/secret/timestamp</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_signature_validation</span><span style=\"color:#E1E4E8\">(self, registry):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test signature validation with various scenarios.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate valid signature and verify it validates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Test signature validation with wrong secret</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test signature validation with modified payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test timestamp tolerance boundaries</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_replay_protection</span><span style=\"color:#E1E4E8\">(self, registry):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test timestamp-based replay attack prevention.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        old_timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(time.time()) </span><span style=\"color:#F97583\">-</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">TIMESTAMP_TOLERANCE</span><span style=\"color:#F97583\"> +</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        future_timestamp </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> int</span><span style=\"color:#E1E4E8\">(time.time()) </span><span style=\"color:#F97583\">+</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">TIMESTAMP_TOLERANCE</span><span style=\"color:#F97583\"> +</span><span style=\"color:#79B8FF\"> 100</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Test signature with timestamp too far in past</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Test signature with timestamp too far in future  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test signature with timestamp at exact tolerance boundary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify appropriate error messages for each case</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestOwnershipVerification</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test webhook endpoint ownership verification.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_successful_verification</span><span style=\"color:#E1E4E8\">(self, registry, mock_webhook_server):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test successful ownership verification flow.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        endpoint_config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EndpointConfig(</span><span style=\"color:#FFAB70\">success_rate</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1.0</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#E1E4E8\"> mock_webhook_server({</span><span style=\"color:#9ECBFF\">\"test\"</span><span style=\"color:#E1E4E8\">: endpoint_config}) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> server:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Register webhook with mock server URL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Trigger ownership verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify challenge request sent to endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify webhook marked as verified in database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify challenge token properly validated</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_verification_failure</span><span style=\"color:#E1E4E8\">(self, registry, mock_webhook_server):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test ownership verification with unresponsive endpoint.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        endpoint_config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EndpointConfig(</span><span style=\"color:#FFAB70\">success_rate</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">status_codes</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">404</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#E1E4E8\"> mock_webhook_server({</span><span style=\"color:#9ECBFF\">\"test\"</span><span style=\"color:#E1E4E8\">: endpoint_config}) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> server:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Register webhook with mock server URL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Trigger ownership verification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify verification fails after retries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify webhook remains unverified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify failure reason recorded</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Checkpoint validation for Milestone 1</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_milestone_1_checkpoint</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Verify Milestone 1 acceptance criteria.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Run: python -m pytest tests/unit/test_webhook_registry.py::test_milestone_1_checkpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Expected: All registration security tests pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Manual verification: </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   1. Start webhook system</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   2. POST https://your-server.com/webhooks {\"url\": \"https://httpbin.org/post\", \"events\": [\"user.created\"]}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   3. Should return {\"webhook_id\": \"...\", \"secret\": \"...\", \"verified\": false}</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   4. Check httpbin request logs for verification challenge</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<p><strong>Milestone 2 Delivery Testing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/unit/test_delivery_engine.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Comprehensive delivery engine testing including retry logic and DLQ.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Validates exponential backoff, queue management, and failure handling.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> pytest</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> unittest.mock </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> AsyncMock, patch</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_system.delivery </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> DeliveryEngine, QueueManager</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_system.models </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> WebhookEvent, DeliveryAttempt</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestDeliveryQueue</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test webhook delivery queue management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @pytest.fixture</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> queue_manager</span><span style=\"color:#E1E4E8\">(self, test_database, redis_connection):</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> QueueManager(redis_connection)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> test_event_queuing</span><span style=\"color:#E1E4E8\">(self, queue_manager):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test event queuing with ordering guarantees.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        webhook_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"webhook_123\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        events </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            {</span><span style=\"color:#9ECBFF\">\"event_id\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"event_</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">i</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"priority\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">} </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            for</span><span style=\"color:#E1E4E8\"> i </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Queue all events for same webhook</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify events queued in FIFO order</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify events isolated per webhook</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify priority events processed first</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> test_queue_persistence</span><span style=\"color:#E1E4E8\">(self, queue_manager):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test queue persistence across system restarts.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Queue several events  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Simulate system restart by creating new QueueManager</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify events still available for processing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify event order preserved after restart</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestRetryLogic</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test exponential backoff retry logic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_backoff_calculation</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test exponential backoff delay calculation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        base_delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 2.0</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> attempt </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> range</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">6</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            delay </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> calculate_retry_delay(attempt, base_delay)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            expected_base </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_delay </span><span style=\"color:#F97583\">*</span><span style=\"color:#E1E4E8\"> (</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#F97583\"> **</span><span style=\"color:#E1E4E8\"> (attempt </span><span style=\"color:#F97583\">-</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">))</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Verify delay is in expected range (with jitter)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify jitter prevents exact timing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify maximum delay cap enforced</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            assert</span><span style=\"color:#E1E4E8\"> expected_base </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 0.75</span><span style=\"color:#F97583\"> &#x3C;=</span><span style=\"color:#E1E4E8\"> delay </span><span style=\"color:#F97583\">&#x3C;=</span><span style=\"color:#E1E4E8\"> expected_base </span><span style=\"color:#F97583\">*</span><span style=\"color:#79B8FF\"> 1.25</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> test_retry_status_decisions</span><span style=\"color:#E1E4E8\">(self, delivery_engine):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test retry decisions based on HTTP status codes.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        retry_scenarios </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#79B8FF\">200</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">),  </span><span style=\"color:#6A737D\"># Success - no retry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#79B8FF\">404</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">False</span><span style=\"color:#E1E4E8\">),  </span><span style=\"color:#6A737D\"># Client error - no retry  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#79B8FF\">429</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">),   </span><span style=\"color:#6A737D\"># Rate limited - retry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">),   </span><span style=\"color:#6A737D\"># Server error - retry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#79B8FF\">503</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">),   </span><span style=\"color:#6A737D\"># Service unavailable - retry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            (</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">True</span><span style=\"color:#E1E4E8\">),     </span><span style=\"color:#6A737D\"># Connection error - retry</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        ]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> status_code, should_retry </span><span style=\"color:#F97583\">in</span><span style=\"color:#E1E4E8\"> retry_scenarios:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create mock delivery attempt with status code</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Call should_retry_delivery function</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify retry decision matches expected behavior</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test with different attempt numbers</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TestDeadLetterQueue</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Test dead letter queue processing.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> test_dlq_routing</span><span style=\"color:#E1E4E8\">(self, delivery_engine, mock_webhook_server):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test events moved to DLQ after max retries.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Configure endpoint to always fail</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        endpoint_config </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> EndpointConfig(</span><span style=\"color:#FFAB70\">success_rate</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">0.0</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#FFAB70\">status_codes</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#79B8FF\">500</span><span style=\"color:#E1E4E8\">])</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        with</span><span style=\"color:#E1E4E8\"> mock_webhook_server({</span><span style=\"color:#9ECBFF\">\"failing\"</span><span style=\"color:#E1E4E8\">: endpoint_config}) </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> server:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Queue event for failing endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Process through all retry attempts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify event moved to DLQ after max retries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Verify delivery history preserved</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">            # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Verify DLQ contains failure reason</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">            pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> test_dlq_inspection</span><span style=\"color:#E1E4E8\">(self, delivery_engine):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test DLQ provides filtering and search capabilities.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create events with various failure reasons</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Move events to DLQ with different timestamps</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Test filtering by webhook_id, failure reason, time range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Test pagination for large DLQ contents</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Checkpoint validation for Milestone 2  </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> test_milestone_2_checkpoint</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Verify Milestone 2 acceptance criteria.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Run: python -m pytest tests/unit/test_delivery_engine.py::test_milestone_2_checkpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Expected: All delivery and retry tests pass</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Manual verification:</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   1. Queue webhook event for unreachable endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   2. Observe retry attempts with increasing delays</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    #   3. Verify event moves to DLQ after MAX_RETRY_ATTEMPTS</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span></code></pre></div>\n\n<h4 id=\"load-testing-infrastructure\">Load Testing Infrastructure</h4>\n<p><strong>Complete Load Testing Implementation:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># tests/load/locustfile.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Comprehensive load testing scenarios for webhook delivery system.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Validates performance under realistic production traffic patterns.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> random</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> locust </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> HttpUser, task, between</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> locust.exception </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StopUser</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookSystemUser</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">HttpUser</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Simulated user generating webhook traffic.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wait_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> between(</span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">2.0</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Realistic event generation rate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> on_start</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Initialize test user with webhook registration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Register test webhook endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Store webhook_id for event generation</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Configure mock endpoint for delivery testing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @task</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">10</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> send_webhook_event</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate webhook event for delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        event_payload </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"event_type\"</span><span style=\"color:#E1E4E8\">: random.choice([</span><span style=\"color:#9ECBFF\">\"user.created\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"order.placed\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"payment.completed\"</span><span style=\"color:#E1E4E8\">]),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"timestamp\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">(time.time()),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"data\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.generate_test_payload()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: POST event to webhook system ingestion endpoint  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify event accepted (2xx response)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Track response time in Locust metrics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @task</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">2</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> query_delivery_status</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Query delivery status for generated events.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: GET delivery status for recent events</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify response contains expected delivery data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Track query performance</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_test_payload</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">dict</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate realistic test payload with size variation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Create payload with realistic field structure</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Vary payload size to simulate different event types</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Include nested objects and arrays</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"user_id\"</span><span style=\"color:#E1E4E8\">: random.randint(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">100000</span><span style=\"color:#E1E4E8\">),</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            \"metadata\"</span><span style=\"color:#E1E4E8\">: {</span><span style=\"color:#9ECBFF\">\"key\"</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#9ECBFF\">\"value\"</span><span style=\"color:#F97583\"> *</span><span style=\"color:#E1E4E8\"> random.randint(</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">100</span><span style=\"color:#E1E4E8\">)}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> HighVolumeUser</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">WebhookSystemUser</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"User simulating high-volume webhook producers.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    wait_time </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> between(</span><span style=\"color:#79B8FF\">0.01</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">0.1</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># Much higher event rate</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @task</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">20</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> burst_events</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate burst of events to test queue handling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Generate multiple events in rapid succession</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Vary event priority and expiration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Monitor queue depth and processing lag</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CircuitBreakerTestUser</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">WebhookSystemUser</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"User testing circuit breaker behavior.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> on_start</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        super</span><span style=\"color:#E1E4E8\">().on_start()</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Register webhook with failing mock endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Configure endpoint to fail after success threshold</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">    @task</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">5</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> trigger_circuit_breaker</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate events to trigger circuit breaker.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Send events that will cause delivery failures</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Monitor circuit breaker state transitions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify delivery attempts stop when circuit opens</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-validation\">Milestone Checkpoint Validation</h4>\n<p><strong>Automated Milestone Testing:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># scripts/run_milestone_tests.py</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Automated milestone validation runner.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides step-by-step verification of acceptance criteria.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> subprocess</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> sys</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> requests</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> MilestoneValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Automated validation of milestone acceptance criteria.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, base_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"http://localhost:8000\"</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.base_url </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> base_url</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_webhook_id: Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_results: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_1</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 1: Webhook Registration &#x26; Security.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"🔐 Validating Milestone 1: Webhook Registration &#x26; Security\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 1: Valid webhook registration</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_webhook_registration()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 2: SSRF protection</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_ssrf_protection()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 3: Signature generation</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_signature_generation()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 4: Ownership verification</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_ownership_verification()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_results[</span><span style=\"color:#9ECBFF\">\"milestone_1\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_webhook_registration</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test webhook endpoint registration functionality.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: POST valid webhook registration request</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Verify response contains webhook_id and secret</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify webhook stored in database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Store webhook_id for subsequent tests</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"  ✓ Webhook registration validation\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> test_ssrf_protection</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Test SSRF protection prevents private IP registration.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Attempt registration with localhost URL</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Attempt registration with private IP ranges</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Verify all attempts rejected with security error</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"  ✓ SSRF protection validation\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_2</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 2: Delivery Queue &#x26; Retry Logic.\"\"\"</span><span style=\"color:#E1E4E8\">  </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"🚀 Validating Milestone 2: Delivery Queue &#x26; Retry Logic\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 1: Event queuing and ordering</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_event_queuing()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 2: Retry logic with backoff</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_retry_logic()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 3: Dead letter queue</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_dead_letter_queue()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_results[</span><span style=\"color:#9ECBFF\">\"milestone_2\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_3</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 3: Circuit Breaker &#x26; Rate Limiting.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"🛡️ Validating Milestone 3: Circuit Breaker &#x26; Rate Limiting\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 1: Circuit breaker state transitions</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_circuit_breaker()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 2: Rate limiting behavior</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_rate_limiting()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 3: Health monitoring</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_health_monitoring()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_results[</span><span style=\"color:#9ECBFF\">\"milestone_3\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_milestone_4</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Validate Milestone 4: Event Log &#x26; Replay.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"📋 Validating Milestone 4: Event Log &#x26; Replay\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 1: Delivery logging</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_delivery_logging()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 2: Event replay</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_event_replay()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Test 3: Log retention</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_log_retention()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.test_results[</span><span style=\"color:#9ECBFF\">\"milestone_4\"</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> success</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> run_all_validations</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Run all milestone validations in sequence.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"🧪 Starting Comprehensive Milestone Validation</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        all_success </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> True</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        all_success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate_milestone_1()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        all_success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate_milestone_2()  </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        all_success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate_milestone_3()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        all_success </span><span style=\"color:#F97583\">&#x26;=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.validate_milestone_4()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.print_summary()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        return</span><span style=\"color:#E1E4E8\"> all_success</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> print_summary</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Print validation results summary.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">📊 Milestone Validation Summary\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">\"=\"</span><span style=\"color:#F97583\"> *</span><span style=\"color:#79B8FF\"> 40</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        for</span><span style=\"color:#E1E4E8\"> milestone, success </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">.test_results.items():</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">            status </span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\"> \"✅ PASS\"</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> success </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> \"❌ FAIL\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">            print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">milestone.replace(</span><span style=\"color:#9ECBFF\">'_'</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">' '</span><span style=\"color:#E1E4E8\">).title()</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#E1E4E8\">status</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        overall </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> all</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#79B8FF\">self</span><span style=\"color:#E1E4E8\">.test_results.values())</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        print</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#F97583\">f</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#79B8FF\">\\n</span><span style=\"color:#9ECBFF\">Overall Result: </span><span style=\"color:#79B8FF\">{</span><span style=\"color:#9ECBFF\">'✅ ALL PASS'</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> overall </span><span style=\"color:#F97583\">else</span><span style=\"color:#9ECBFF\"> '❌ SOME FAILURES'</span><span style=\"color:#79B8FF\">}</span><span style=\"color:#9ECBFF\">\"</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> __name__</span><span style=\"color:#F97583\"> ==</span><span style=\"color:#9ECBFF\"> \"__main__\"</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    validator </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> MilestoneValidator()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    success </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> validator.run_all_validations()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    sys.exit(</span><span style=\"color:#79B8FF\">0</span><span style=\"color:#F97583\"> if</span><span style=\"color:#E1E4E8\"> success </span><span style=\"color:#F97583\">else</span><span style=\"color:#79B8FF\"> 1</span><span style=\"color:#E1E4E8\">)</span></span></code></pre></div>\n\n\n<h2 id=\"debugging-guide\">Debugging Guide</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) - debugging techniques covering webhook registration issues (Milestone 1), delivery failures and retry loops (Milestone 2), circuit breaker and rate limiting problems (Milestone 3), and event logging and replay complications (Milestone 4)</p>\n</blockquote>\n<h3 id=\"mental-model-the-detective39s-toolkit\">Mental Model: The Detective&#39;s Toolkit</h3>\n<p>Think of debugging a webhook delivery system like being a detective investigating why packages aren&#39;t being delivered in a complex postal network. Just as a detective follows clues from the mailroom through sorting facilities to final delivery, debugging webhooks requires following the event trail through registration, queuing, delivery attempts, and logging. Each component leaves evidence - logs, metrics, state changes - that tell the story of what went wrong. The key is knowing where to look first, what symptoms indicate which root causes, and how to fix problems without disrupting the entire delivery network.</p>\n<p>Unlike debugging a simple web application where you can trace a single request-response cycle, webhook delivery systems involve asynchronous processing, distributed state, and complex retry logic. A single event might leave traces across multiple databases, queue systems, and log stores. The challenge is correlating these distributed traces to understand the complete failure story.</p>\n<h3 id=\"delivery-failure-debugging-diagnosing-stuck-queues-failed-deliveries-and-retry-loops\">Delivery Failure Debugging: Diagnosing Stuck Queues, Failed Deliveries, and Retry Loops</h3>\n<p><strong>Stuck Queue Analysis</strong></p>\n<p>The most common webhook delivery problem is events getting stuck in queues without being processed. This manifests as growing queue depths with no corresponding delivery attempts being logged. The detective work starts with identifying whether the problem is in event ingestion, queue consumption, or delivery processing.</p>\n<p>Queue stagnation typically occurs in three locations within the delivery pipeline. First, events may fail to enter the queue due to webhook registration lookup failures or signature generation errors. Second, events may accumulate in queues because <code>DeliveryWorker</code> instances have crashed or become unresponsive. Third, events may be dequeued but never complete processing due to hanging HTTP requests or database connection issues.</p>\n<p>The diagnostic approach begins with queue depth monitoring across all webhook endpoints. Each <code>WebhookRegistration</code> should have an associated Redis stream containing pending <code>QueueEntry</code> items. Sudden spikes in queue depth without corresponding increases in delivery attempt logs indicate worker consumption issues.</p>\n<table>\n<thead>\n<tr>\n<th>Symptom</th>\n<th>Likely Cause</th>\n<th>Diagnostic Command</th>\n<th>Fix</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Queue depth growing steadily</td>\n<td>Worker crashed or stuck</td>\n<td>Check <code>WorkerHeartbeat</code> timestamps</td>\n<td>Restart worker instances</td>\n</tr>\n<tr>\n<td>Queue depth steady but no deliveries</td>\n<td>Database connection failure</td>\n<td>Check delivery attempt table writes</td>\n<td>Restart database connections</td>\n</tr>\n<tr>\n<td>Events enter queue then disappear</td>\n<td>Dead letter queue activation</td>\n<td>Check DLQ depth and failure reasons</td>\n<td>Review circuit breaker thresholds</td>\n</tr>\n<tr>\n<td>Queue processes slowly</td>\n<td>Rate limiting active</td>\n<td>Check <code>RateLimitConfig</code> token consumption</td>\n<td>Adjust rate limits or add workers</td>\n</tr>\n</tbody></table>\n<p><strong>Failed Delivery Root Cause Analysis</strong></p>\n<p>When deliveries fail, the <code>DeliveryAttempt</code> records provide the primary evidence for diagnosis. However, interpreting HTTP status codes, response times, and error messages requires understanding the subtle differences between temporary network issues, endpoint configuration problems, and systematic failures.</p>\n<p>HTTP 5xx responses generally indicate temporary endpoint issues that warrant retry attempts, while 4xx responses suggest permanent configuration problems that should not be retried. However, HTTP 429 (rate limiting) and 408 (timeout) responses require special handling with respect to the endpoint&#39;s <code>Retry-After</code> headers and circuit breaker state.</p>\n<p>The investigation process starts with filtering <code>DeliveryAttempt</code> records by <code>webhook_id</code> and examining the progression of <code>status_code</code> values across attempts. Consistent 4xx responses indicate endpoint configuration issues, while intermittent 5xx responses suggest capacity or network problems. Timeout errors (indicated by null <code>status_code</code> and network error messages) point to connectivity or DNS resolution issues.</p>\n<blockquote>\n<p><strong>Critical Insight</strong>: Failed deliveries often follow patterns that reveal root causes. A sequence of successful deliveries followed by sudden 5xx failures suggests endpoint overload, while consistent DNS resolution errors indicate infrastructure changes.</p>\n</blockquote>\n<p><strong>Retry Loop Detection and Resolution</strong></p>\n<p>Retry loops occur when the exponential backoff logic becomes stuck in a pattern where events are continuously rescheduled but never successfully delivered or moved to the dead letter queue. This happens when circuit breaker thresholds are misconfigured, when the <code>MAX_RETRY_ATTEMPTS</code> limit is too high, or when system clock drift affects retry scheduling.</p>\n<p>The diagnostic signature of retry loops includes <code>DeliveryAttempt</code> records with <code>attempt_number</code> values that exceed reasonable thresholds, combined with <code>next_attempt_at</code> timestamps that show regular scheduling patterns without progression toward success or final failure.</p>\n<table>\n<thead>\n<tr>\n<th>Loop Pattern</th>\n<th>Root Cause</th>\n<th>Detection Method</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Exponential backoff plateau</td>\n<td>Max delay reached but endpoint still failing</td>\n<td><code>next_attempt_at</code> intervals stop growing</td>\n<td>Reduce max retry attempts or enable circuit breaker</td>\n</tr>\n<tr>\n<td>Clock drift retry acceleration</td>\n<td>System time inconsistency</td>\n<td>Negative or zero retry delays</td>\n<td>Synchronize system clocks across workers</td>\n</tr>\n<tr>\n<td>Circuit breaker flapping</td>\n<td>Threshold too sensitive</td>\n<td>Rapid OPEN/CLOSED state transitions</td>\n<td>Increase failure threshold or extend recovery timeout</td>\n</tr>\n<tr>\n<td>Rate limit retry storms</td>\n<td>Retry-After header ignored</td>\n<td>Bursts of attempts after rate limit responses</td>\n<td>Implement proper Retry-After header handling</td>\n</tr>\n</tbody></table>\n<p>The resolution approach depends on whether the loop is caused by configuration, infrastructure, or endpoint-specific issues. Configuration problems require updating <code>CircuitBreakerConfig</code> or <code>RateLimitConfig</code> parameters. Infrastructure issues may require worker restarts or system clock synchronization. Endpoint-specific problems might require manual intervention to update webhook URLs or temporarily disable problematic endpoints.</p>\n<h3 id=\"security-and-signature-debugging-hmac-verification-failures-and-timestamp-validation-issues\">Security and Signature Debugging: HMAC Verification Failures and Timestamp Validation Issues</h3>\n<p><strong>HMAC Signature Verification Failures</strong></p>\n<p>HMAC signature verification failures are among the most subtle and difficult debugging challenges in webhook systems because they involve cryptographic operations that fail silently, leaving minimal diagnostic traces. The verification process depends on exact byte-for-byte reproduction of the signed payload, making it sensitive to character encoding, JSON serialization order, and HTTP header manipulation.</p>\n<p>The signature verification process begins when webhook endpoints receive delivery requests and attempt to validate the <code>X-Webhook-Signature</code> header against their stored secret. Failures occur when the receiving endpoint cannot reproduce the same HMAC-SHA256 value that was generated during delivery. This mismatch can result from payload modification during transit, incorrect secret retrieval, or differences in the canonical signing string format.</p>\n<p>The debugging approach requires correlating delivery logs with endpoint-side verification attempts. The <code>DeliveryAttempt</code> records contain the <code>request_payload</code> and <code>request_headers</code> that were sent, while endpoint logs should show the signature verification inputs and results. The key insight is that HMAC verification requires bit-perfect reproduction of both the payload and the signing metadata.</p>\n<blockquote>\n<p><strong>Security Insight</strong>: HMAC verification failures often indicate either implementation bugs in the signing process or active tampering with webhook deliveries. Never ignore signature verification failures as mere configuration issues.</p>\n</blockquote>\n<p>Common signature verification failure modes include JSON canonicalization differences where the sending system serializes JSON with different key ordering or whitespace than the receiving system expects. Character encoding mismatches can occur when payload strings contain Unicode characters that are encoded differently during signing versus verification. HTTP proxy modifications may alter payload content or headers during transit, breaking signature verification.</p>\n<table>\n<thead>\n<tr>\n<th>Verification Failure Type</th>\n<th>Symptoms</th>\n<th>Debugging Steps</th>\n<th>Common Fixes</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>JSON serialization mismatch</td>\n<td>Consistent verification failures for JSON payloads</td>\n<td>Compare sent vs received JSON byte-for-byte</td>\n<td>Use deterministic JSON serialization</td>\n</tr>\n<tr>\n<td>Character encoding issues</td>\n<td>Failures only with Unicode content</td>\n<td>Check payload encoding in transit</td>\n<td>Ensure UTF-8 encoding throughout pipeline</td>\n</tr>\n<tr>\n<td>Header tampering</td>\n<td>Signature header present but invalid</td>\n<td>Compare delivered headers with generation logs</td>\n<td>Investigate proxy or load balancer configuration</td>\n</tr>\n<tr>\n<td>Clock skew impacts</td>\n<td>Intermittent failures related to time</td>\n<td>Check timestamp differences between systems</td>\n<td>Increase <code>TIMESTAMP_TOLERANCE</code> or sync clocks</td>\n</tr>\n</tbody></table>\n<p><strong>Timestamp Validation and Replay Protection</strong></p>\n<p>Timestamp validation failures occur when the difference between the signature generation time and verification time exceeds the configured <code>TIMESTAMP_TOLERANCE</code> window. This protection mechanism prevents replay attacks but can cause legitimate delivery failures when system clocks are not synchronized or when network delays cause extended delivery times.</p>\n<p>The timestamp validation process embeds the current Unix timestamp into the HMAC signing string, ensuring that signature validation fails if attempted outside the acceptable time window. However, this creates operational complexity when webhook deliveries experience delays due to retry logic, rate limiting, or network congestion.</p>\n<p>Timestamp-related failures manifest as successful signature generation followed by verification failures at the receiving endpoint. The <code>DeliveryAttempt</code> records will show successful HTTP delivery (2xx status codes) but endpoint logs will indicate timestamp validation failures. This pattern distinguishes timestamp issues from HMAC computation problems.</p>\n<p>The diagnostic process involves comparing the <code>attempted_at</code> timestamp in <code>DeliveryAttempt</code> records with the embedded signature timestamp and the endpoint&#39;s verification timestamp. Delays longer than <code>TIMESTAMP_TOLERANCE</code> (default 300 seconds) will cause validation failures even with correct HMAC computation.</p>\n<p><strong>Secret Rotation Debugging</strong></p>\n<p>Secret rotation introduces additional complexity because multiple <code>WebhookSecret</code> entries may be valid simultaneously during rotation periods. The receiving endpoint must attempt verification with all active secrets, but implementation bugs can cause verification to fail with older secrets even when they should remain valid.</p>\n<p>The rotation process creates overlapping validity periods where both old and new secrets remain active. The <code>WebhookSecret</code> model tracks <code>activated_at</code> and <code>expires_at</code> timestamps to manage this overlap, but endpoint implementations must correctly handle multiple secret validation attempts.</p>\n<table>\n<thead>\n<tr>\n<th>Rotation Issue</th>\n<th>Symptom Pattern</th>\n<th>Root Cause</th>\n<th>Resolution</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Immediate post-rotation failures</td>\n<td>All deliveries fail after rotation</td>\n<td>Endpoint using only newest secret</td>\n<td>Implement multi-secret validation</td>\n</tr>\n<tr>\n<td>Gradual rotation failures</td>\n<td>Increasing failure rate during overlap period</td>\n<td>Inconsistent secret selection in delivery</td>\n<td>Fix secret selection algorithm</td>\n</tr>\n<tr>\n<td>Expired secret usage</td>\n<td>Sudden failures after rotation completion</td>\n<td>Cached expired secrets in delivery workers</td>\n<td>Clear secret caches after rotation</td>\n</tr>\n<tr>\n<td>Clock synchronization issues</td>\n<td>Random verification failures</td>\n<td>System clock differences during rotation</td>\n<td>Synchronize clocks or extend overlap periods</td>\n</tr>\n</tbody></table>\n<h3 id=\"performance-and-scaling-issues-queue-backlog-rate-limiting-bottlenecks-and-resource-exhaustion\">Performance and Scaling Issues: Queue Backlog, Rate Limiting Bottlenecks, and Resource Exhaustion</h3>\n<p><strong>Queue Backlog Analysis and Resolution</strong></p>\n<p>Queue backlogs develop when event ingestion rates consistently exceed delivery processing capacity. This imbalance can occur due to insufficient worker instances, slow endpoint response times, or resource contention in the delivery pipeline. Unlike temporary queue spikes from traffic bursts, sustained backlogs indicate systematic capacity problems that require architectural solutions.</p>\n<p>The backlog formation process begins when the <code>enqueue_event</code> operation adds events faster than <code>DeliveryWorker</code> instances can process them. Each webhook endpoint maintains its own Redis stream, so backlogs can be per-endpoint (indicating endpoint-specific issues) or system-wide (indicating infrastructure capacity limits).</p>\n<p>Queue backlog diagnosis requires analyzing both depth trends and processing velocity across webhook endpoints. The <code>QueueManager</code> provides metrics for queue depth, event age, and processing rates that reveal whether backlogs are growing, stable, or shrinking. Correlation with endpoint response times and circuit breaker states helps identify root causes.</p>\n<blockquote>\n<p><strong>Scalability Insight</strong>: Queue backlogs are symptoms, not causes. The root cause is always an imbalance between event ingestion and delivery capacity. Focus on identifying and removing the delivery bottlenecks rather than just adding more queue capacity.</p>\n</blockquote>\n<p><strong>Rate Limiting Bottleneck Identification</strong></p>\n<p>Rate limiting bottlenecks occur when the configured delivery rates are too conservative for the endpoint&#39;s actual capacity, causing artificial delays that contribute to queue growth. The <code>RateLimitConfig</code> parameters may be set too low, or the token bucket implementation may not properly handle burst traffic patterns.</p>\n<p>The bottleneck manifests as consistent delays in the <code>can_proceed</code> method calls, with delivery attempts being postponed despite endpoint availability. The <code>DeliveryAttempt</code> records show successful deliveries but with longer than necessary delays between attempts. This pattern differs from endpoint-imposed rate limiting (HTTP 429 responses) which comes from the receiving side.</p>\n<p>Diagnosis involves analyzing the relationship between configured rate limits, actual endpoint capacity, and delivery timing patterns. If endpoints consistently respond successfully within acceptable timeframes but deliveries are artificially delayed by rate limiting, the configuration needs adjustment.</p>\n<table>\n<thead>\n<tr>\n<th>Bottleneck Type</th>\n<th>Performance Impact</th>\n<th>Detection Method</th>\n<th>Optimization Strategy</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Conservative rate limits</td>\n<td>Artificial delivery delays</td>\n<td>Compare endpoint response capacity with configured limits</td>\n<td>Increase RPM limits based on endpoint testing</td>\n</tr>\n<tr>\n<td>Token bucket starvation</td>\n<td>Burst traffic cannot be processed</td>\n<td>Queue spikes during traffic bursts</td>\n<td>Increase burst multiplier in <code>RateLimitConfig</code></td>\n</tr>\n<tr>\n<td>Global rate limiting</td>\n<td>Single endpoint limits affect others</td>\n<td>Cross-endpoint delivery correlation</td>\n<td>Implement per-endpoint rate limiting isolation</td>\n</tr>\n<tr>\n<td>Retry-After mishandling</td>\n<td>Rate limit responses cause excessive delays</td>\n<td>Extended delays after HTTP 429 responses</td>\n<td>Implement proper Retry-After header parsing</td>\n</tr>\n</tbody></table>\n<p><strong>Resource Exhaustion Diagnosis</strong></p>\n<p>Resource exhaustion occurs when system components run out of database connections, memory, file handles, or network sockets. This typically manifests as intermittent failures that worsen under load, rather than consistent failure patterns. The webhook delivery system is particularly susceptible because it maintains persistent connections to message queues, databases, and HTTP endpoints.</p>\n<p>Database connection exhaustion is the most common resource issue, occurring when the connection pool in <code>DatabaseManager</code> becomes depleted due to long-running queries, connection leaks, or insufficient pool sizing. The symptoms include database timeout errors in <code>DeliveryAttempt</code> records and growing connection counts in database monitoring tools.</p>\n<p>Memory exhaustion can occur when large webhook payloads accumulate in worker memory, especially during retry processing. The <code>WebhookEvent</code> model stores full payload content, and workers processing many large events simultaneously can exceed available memory. This leads to worker crashes and restart cycles that appear as intermittent processing failures.</p>\n<p>Network socket exhaustion affects HTTP delivery when workers attempt to establish more concurrent connections than the system allows. This is particularly problematic when endpoints have slow response times, causing connections to remain open longer and depleting the available socket pool.</p>\n<table>\n<thead>\n<tr>\n<th>Resource Type</th>\n<th>Exhaustion Symptoms</th>\n<th>Monitoring Approach</th>\n<th>Mitigation Strategies</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Database connections</td>\n<td>Query timeouts and connection failures</td>\n<td>Monitor active connection counts vs pool limits</td>\n<td>Increase pool size or optimize query performance</td>\n</tr>\n<tr>\n<td>Memory</td>\n<td>Worker crashes and OOM errors</td>\n<td>Track worker memory usage and payload sizes</td>\n<td>Implement payload size limits and memory-efficient processing</td>\n</tr>\n<tr>\n<td>File handles</td>\n<td>File operation failures</td>\n<td>Monitor open file descriptor counts</td>\n<td>Ensure proper file closure and increase system limits</td>\n</tr>\n<tr>\n<td>Network sockets</td>\n<td>HTTP connection failures</td>\n<td>Track concurrent connection counts</td>\n<td>Implement connection pooling and timeout optimization</td>\n</tr>\n</tbody></table>\n<p><strong>Scaling Bottleneck Resolution Strategies</strong></p>\n<p>Scaling bottlenecks require systematic analysis of component throughput limits and resource utilization patterns. The webhook delivery system has multiple potential bottlenecks: webhook registration database queries, event queuing operations, delivery processing throughput, and logging write performance.</p>\n<p>The identification process involves load testing individual components to determine their maximum sustainable throughput. Database operations can be bottlenecked by query performance, connection pool limits, or storage I/O capacity. Queue operations may be limited by Redis memory, network bandwidth, or persistence configuration. HTTP delivery throughput depends on endpoint response times, worker concurrency, and network capacity.</p>\n<p>Resolution strategies range from configuration tuning (increasing connection pools, adjusting rate limits) to architectural changes (horizontal scaling, read replicas, queue sharding). The choice depends on where bottlenecks are identified and the cost-benefit trade-offs of different approaches.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p><strong>Technology Stack for Debugging</strong></p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Logging Framework</td>\n<td>Python <code>logging</code> with JSON formatter</td>\n<td>Structured logging with ELK stack</td>\n</tr>\n<tr>\n<td>Metrics Collection</td>\n<td>Basic counters and gauges</td>\n<td>Prometheus with Grafana dashboards</td>\n</tr>\n<tr>\n<td>Tracing</td>\n<td>Custom correlation IDs</td>\n<td>OpenTelemetry distributed tracing</td>\n</tr>\n<tr>\n<td>Database Monitoring</td>\n<td>SQL query logging</td>\n<td>Performance insights with slow query analysis</td>\n</tr>\n<tr>\n<td>Queue Monitoring</td>\n<td>Redis INFO command</td>\n<td>Redis monitoring with alerting</td>\n</tr>\n</tbody></table>\n<p><strong>Project Structure for Debugging Tools</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-system/\n├── src/webhook_delivery/\n│   ├── debugging/\n│   │   ├── __init__.py\n│   │   ├── queue_analyzer.py          ← Queue backlog analysis tools\n│   │   ├── delivery_tracer.py         ← Delivery attempt correlation\n│   │   ├── signature_validator.py     ← HMAC verification testing\n│   │   └── performance_profiler.py    ← Resource usage analysis\n│   ├── monitoring/\n│   │   ├── metrics_collector.py       ← System health metrics\n│   │   ├── alerting.py                ← Threshold-based alerts\n│   │   └── dashboard_data.py          ← Metrics aggregation for dashboards\n│   └── tools/\n│       ├── debug_cli.py               ← Command-line debugging interface\n│       ├── replay_analyzer.py         ← Event replay debugging\n│       └── config_validator.py        ← Configuration validation</code></pre></div>\n\n<p><strong>Queue Analyzer Infrastructure</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueueHealth</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    webhook_id: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    queue_depth: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    oldest_event_age: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    processing_rate: </span><span style=\"color:#79B8FF\">float</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_successful_delivery: Optional[datetime]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    circuit_state: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    rate_limit_tokens: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> QueueAnalyzer</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Comprehensive queue health analysis and bottleneck detection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_client: redis.Redis, db_manager):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> db_manager</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.analysis_window </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> timedelta(</span><span style=\"color:#FFAB70\">hours</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> analyze_queue_health</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> QueueHealth:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze queue health for a specific webhook endpoint.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get queue depth from Redis stream length</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Find oldest pending event timestamp</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate processing rate from recent delivery attempts</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get last successful delivery from DeliveryAttempt table</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check current circuit breaker state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get available rate limit tokens</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_stuck_queues</span><span style=\"color:#E1E4E8\">(self) -> List[Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect queues with events but no processing activity.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Scan all webhook streams in Redis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Compare queue depths with recent delivery activity</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify queues with events older than threshold</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of (webhook_id, reason) tuples</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> diagnose_delivery_failures</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, hours: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 24</span><span style=\"color:#E1E4E8\">) -> Dict:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze delivery failure patterns for debugging.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Query DeliveryAttempt records for time window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Group failures by status code and error message</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify retry loop patterns</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate failure progression rates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return diagnostic summary with recommendations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Signature Verification Testing Tools</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hmac</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, Any, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> SignatureDebugger</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Tools for debugging HMAC signature verification issues.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.timestamp_tolerance </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 300</span><span style=\"color:#6A737D\">  # 5 minutes</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_test_signature</span><span style=\"color:#E1E4E8\">(self, payload: Dict[Any, Any], secret: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                              timestamp: Optional[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Generate HMAC signature with debugging information.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Convert payload to canonical JSON string</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Create signing string with timestamp and metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Generate HMAC-SHA256 signature</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return signature and canonical payload for comparison</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> verify_signature_step_by_step</span><span style=\"color:#E1E4E8\">(self, payload: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, signature: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                    secret: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, timestamp: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Step-by-step signature verification with detailed diagnostics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse signature components (timestamp, hash)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate timestamp against tolerance window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Reproduce signing string exactly</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate expected HMAC and compare</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return detailed verification report</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> diagnose_verification_failure</span><span style=\"color:#E1E4E8\">(self, delivery_attempt_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Analyze why signature verification might have failed.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Retrieve delivery attempt details from database</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get webhook secret that was used for signing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Reproduce signature generation process</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify potential mismatch sources</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return diagnostic report with recommendations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Performance Monitoring Core Logic</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> psutil</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> time</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> collections </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> deque</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PerformanceProfiler</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"System resource monitoring and bottleneck detection.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, sample_interval: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.sample_interval </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> sample_interval</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.metrics_history </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> deque(</span><span style=\"color:#FFAB70\">maxlen</span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\">1440</span><span style=\"color:#E1E4E8\">)  </span><span style=\"color:#6A737D\"># 24 hours of samples</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.alert_thresholds </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'cpu_percent'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">80</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'memory_percent'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">85</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'db_connections'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">80</span><span style=\"color:#E1E4E8\">,  </span><span style=\"color:#6A737D\"># % of pool</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'queue_depth'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">1000</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">            'delivery_latency'</span><span style=\"color:#E1E4E8\">: </span><span style=\"color:#79B8FF\">30.0</span><span style=\"color:#6A737D\">  # seconds</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        }</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> collect_system_metrics</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Collect comprehensive system performance metrics.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get CPU usage percentage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Get memory usage percentage  </span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Count active database connections</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Sum queue depths across all webhooks</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate average delivery latency</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return metrics dictionary</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_resource_exhaustion</span><span style=\"color:#E1E4E8\">(self) -> List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Detect resource exhaustion patterns and bottlenecks.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Analyze metrics trends over time window</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify metrics exceeding alert thresholds</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Correlate resource usage with delivery performance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of detected issues with severity</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> diagnose_scaling_bottlenecks</span><span style=\"color:#E1E4E8\">(self) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Identify system components limiting throughput scaling.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Analyze component throughput vs resource utilization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify components with highest resource consumption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Calculate theoretical maximum throughput per component</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return bottleneck analysis with scaling recommendations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<p><strong>Debugging Command Line Interface</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> click</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_delivery.debugging.queue_analyzer </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> QueueAnalyzer</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_delivery.debugging.signature_validator </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> SignatureDebugger</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> webhook_delivery.debugging.performance_profiler </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> PerformanceProfiler</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@click.group</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> debug_cli</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Webhook delivery system debugging tools.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@debug_cli.command</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@click.argument</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">'webhook_id'</span><span style=\"color:#E1E4E8\">)</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> analyze_queue</span><span style=\"color:#E1E4E8\">(webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Analyze queue health for a specific webhook.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize QueueAnalyzer with Redis connection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Run queue health analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Display formatted results with recommendations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@debug_cli.command</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@click.argument</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#9ECBFF\">'delivery_attempt_id'</span><span style=\"color:#E1E4E8\">) </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> debug_signature</span><span style=\"color:#E1E4E8\">(delivery_attempt_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Debug HMAC signature verification failure.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize SignatureDebugger</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Run verification failure diagnosis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Display step-by-step verification process</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@debug_cli.command</span><span style=\"color:#E1E4E8\">()</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> system_health</span><span style=\"color:#E1E4E8\">():</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Check overall system health and performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Initialize PerformanceProfiler</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Collect current metrics</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Run bottleneck detection</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Display health summary with alerts</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">if</span><span style=\"color:#79B8FF\"> __name__</span><span style=\"color:#F97583\"> ==</span><span style=\"color:#9ECBFF\"> '__main__'</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    debug_cli()</span></span></code></pre></div>\n\n<p><strong>Language-Specific Implementation Notes</strong></p>\n<p>For Python webhook delivery debugging:</p>\n<ul>\n<li>Use <code>logging.getLogger(__name__)</code> with structured JSON formatters for consistent log correlation</li>\n<li>Leverage <code>redis-py</code> XINFO and XPENDING commands for detailed queue analysis</li>\n<li>Use <code>psutil</code> library for comprehensive system resource monitoring</li>\n<li>Implement custom exception classes for different failure modes to enable specific error handling</li>\n<li>Use <code>dataclasses</code> for structured debugging output that&#39;s easy to serialize and analyze</li>\n</ul>\n<p><strong>Milestone Debugging Checkpoints</strong></p>\n<p>After implementing each milestone, use these debugging validation steps:</p>\n<p><strong>Milestone 1 Debugging Checkpoint:</strong></p>\n<ul>\n<li>Generate test webhook with known secret and verify signature creation matches expected HMAC</li>\n<li>Test signature verification failure by modifying payload and confirm proper error reporting</li>\n<li>Validate URL security checks by attempting registration with private IP addresses</li>\n<li>Verify challenge-response ownership validation handles network timeouts gracefully</li>\n</ul>\n<p><strong>Milestone 2 Debugging Checkpoint:</strong>  </p>\n<ul>\n<li>Simulate network failures during delivery and verify exponential backoff timing</li>\n<li>Test queue processing by monitoring Redis streams during worker startup and shutdown</li>\n<li>Validate dead letter queue behavior by exhausting retry attempts on unreachable endpoint</li>\n<li>Confirm retry loop prevention by checking attempt limits are respected</li>\n</ul>\n<p><strong>Milestone 3 Debugging Checkpoint:</strong></p>\n<ul>\n<li>Trigger circuit breaker by simulating consecutive endpoint failures and verify state transitions</li>\n<li>Test rate limiting by sending bursts above configured limits and measuring actual delivery rates  </li>\n<li>Validate Retry-After header handling by returning HTTP 429 responses with delay instructions</li>\n<li>Confirm circuit recovery by fixing failing endpoint and observing automatic state restoration</li>\n</ul>\n<p><strong>Milestone 4 Debugging Checkpoint:</strong></p>\n<ul>\n<li>Verify delivery logs capture complete request/response data for failed deliveries</li>\n<li>Test event replay functionality with deduplication headers to prevent duplicate processing</li>\n<li>Validate log retention policies by checking automatic archival of old delivery records</li>\n<li>Confirm debugging tools can correlate events across multiple system components</li>\n</ul>\n<p>⚠️ <strong>Common Debugging Pitfalls</strong></p>\n<p>⚠️ <strong>Pitfall: Correlation ID Missing</strong>\nMany debugging sessions fail because events cannot be correlated across system components. Each webhook event should have a unique correlation ID that appears in queue messages, delivery attempts, and log entries. Without this, debugging distributed failures becomes nearly impossible.</p>\n<p>⚠️ <strong>Pitfall: Insufficient Error Context</strong><br>Generic error messages like &quot;delivery failed&quot; provide no debugging value. Each failure should capture the complete context: endpoint URL, HTTP status code, response headers, response body, network timing, and retry attempt number. This context is essential for root cause analysis.</p>\n<p>⚠️ <strong>Pitfall: Clock Synchronization Ignored</strong>\nTimestamp-based debugging assumes synchronized system clocks across components. Clock drift can make retry timing appear incorrect, signature verification seem random, and event ordering look corrupted. Always verify system clock synchronization before debugging timing-related issues.</p>\n<p>⚠️ <strong>Pitfall: Production Debugging Without Safety</strong>\nRunning debugging tools in production can impact performance or expose sensitive data. Always implement rate limiting, data sanitization, and read-only access controls in debugging interfaces. Never run performance profiling tools continuously in production without proper resource limits.</p>\n<h2 id=\"future-extensions-and-scalability\">Future Extensions and Scalability</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> Post-delivery advanced features - builds upon all completed milestones (1-4) to provide enterprise-grade capabilities including conditional delivery, comprehensive analytics, and horizontal scaling architecture</p>\n</blockquote>\n<p>The webhook delivery system we&#39;ve designed through the four core milestones provides a solid foundation for reliable event delivery with security, fault tolerance, and observability. However, as organizations scale their webhook infrastructure and adopt more sophisticated integration patterns, additional capabilities become essential. This section explores advanced features and architectural evolution paths that transform our system from a reliable webhook delivery service into a comprehensive event distribution platform.</p>\n<p>Think of this evolution like transforming a neighborhood postal service into a global logistics network. While the fundamental concepts of addressing, delivery, and tracking remain the same, the scale and sophistication of operations require new capabilities: conditional routing based on package contents, real-time visibility into delivery performance across regions, predictive analytics to prevent service disruptions, and distributed coordination mechanisms to handle traffic volumes that would overwhelm a single processing center.</p>\n<p>The extensions we&#39;ll explore fall into three categories: advanced delivery features that add intelligence and geographic distribution to our delivery logic, enhanced monitoring and analytics that provide deep visibility into system behavior and customer experience, and horizontal scaling considerations that enable the system to handle enterprise-scale traffic across multiple geographic regions. Each category builds upon the foundational components we&#39;ve established while introducing new architectural patterns and operational complexities.</p>\n<h3 id=\"advanced-delivery-features\">Advanced Delivery Features</h3>\n<p>Modern webhook consumers often require more sophisticated delivery semantics than simple fire-and-forget HTTP requests. Organizations need conditional delivery based on event content, payload transformation to match diverse consumer formats, and multi-region deployment for reduced latency and compliance with data sovereignty requirements. These features transform our delivery engine from a simple HTTP dispatcher into an intelligent event router and transformer.</p>\n<h4 id=\"conditional-delivery-logic\">Conditional Delivery Logic</h4>\n<p><strong>Mental Model: Smart Mail Filtering</strong>\nImagine a postal service where mail carriers can read package labels and apply complex routing rules: &quot;If this package is marked &#39;urgent&#39; and the recipient is in the downtown district, deliver immediately. If it&#39;s a routine document for a residential address, batch it with other deliveries for efficiency.&quot; Conditional delivery applies similar intelligence to webhook events, allowing fine-grained control over when and how events reach their destinations.</p>\n<p>Traditional webhook systems deliver every subscribed event to every registered endpoint, leaving filtering and relevance decisions to the consumer. This creates unnecessary network traffic, processing overhead, and potential security exposure when sensitive events are delivered to endpoints that shouldn&#39;t receive them. Conditional delivery moves this intelligence into the delivery system itself.</p>\n<blockquote>\n<p><strong>Decision: Event Filtering Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Organizations need to filter webhook deliveries based on event content, recipient characteristics, or external conditions without modifying every consuming application</li>\n<li><strong>Options Considered</strong>: <ol>\n<li>Consumer-side filtering (current approach)</li>\n<li>Static subscription filters at registration time  </li>\n<li>Dynamic filtering with expression evaluation engine</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement dynamic filtering with expression evaluation engine</li>\n<li><strong>Rationale</strong>: Provides maximum flexibility while reducing network overhead and improving security by preventing delivery of irrelevant or sensitive events</li>\n<li><strong>Consequences</strong>: Adds complexity to delivery pipeline but enables sophisticated routing patterns and reduces downstream processing burden</li>\n</ul>\n</blockquote>\n<p>The conditional delivery system extends our <code>WebhookRegistration</code> model with filter expressions that are evaluated against each event before delivery decisions:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>filter_expression</code></td>\n<td><code>str</code></td>\n<td>JSONPath or CEL expression defining delivery conditions</td>\n</tr>\n<tr>\n<td><code>filter_version</code></td>\n<td><code>int</code></td>\n<td>Schema version for backward compatibility during filter evolution</td>\n</tr>\n<tr>\n<td><code>filter_variables</code></td>\n<td><code>json</code></td>\n<td>External variables available during filter evaluation</td>\n</tr>\n<tr>\n<td><code>delivery_conditions</code></td>\n<td><code>json</code></td>\n<td>Complex conditions including time windows, rate limits per filter match</td>\n</tr>\n<tr>\n<td><code>content_requirements</code></td>\n<td><code>json</code></td>\n<td>Required fields or patterns in event payload for delivery eligibility</td>\n</tr>\n</tbody></table>\n<p>The filter evaluation process integrates into our delivery queue logic before events are scheduled for HTTP delivery:</p>\n<ol>\n<li><strong>Event Ingestion Enhancement</strong>: When events are queued for delivery, the <code>QueueManager</code> evaluates filter expressions for each subscribed webhook endpoint</li>\n<li><strong>Expression Evaluation</strong>: The system supports JSONPath expressions for simple field matching and Common Expression Language (CEL) for complex logical conditions</li>\n<li><strong>Context Enrichment</strong>: Filter expressions have access to event payload, metadata, webhook configuration, and external context variables</li>\n<li><strong>Performance Optimization</strong>: Frequently evaluated filters are cached in Redis with invalidation on webhook configuration changes</li>\n<li><strong>Audit Logging</strong>: All filter evaluations are logged to support debugging and compliance requirements</li>\n</ol>\n<p>Consider a financial services platform that sends transaction events to multiple downstream systems. The fraud detection system only needs high-value transactions, while the analytics platform wants all transactions but only during business hours. The loyalty program service needs transactions from retail merchants but excludes internal transfers:</p>\n<ul>\n<li><strong>Fraud Detection Filter</strong>: <code>event.transaction.amount &gt; 10000 || event.transaction.risk_score &gt; 0.7</code></li>\n<li><strong>Analytics Filter</strong>: <code>hour(now()) &gt;= 9 &amp;&amp; hour(now()) &lt;= 17 &amp;&amp; weekday(now()) &lt;= 5</code></li>\n<li><strong>Loyalty Program Filter</strong>: <code>event.merchant.category == &#39;retail&#39; &amp;&amp; !event.transaction.internal</code></li>\n</ul>\n<h4 id=\"payload-transformation-pipeline\">Payload Transformation Pipeline</h4>\n<p><strong>Mental Model: Universal Package Converter</strong>\nThink of payload transformation like a package conversion center at an international shipping hub. Packages arrive in various sizes and formats, but each destination country has specific requirements: different labeling standards, customs declarations, packaging materials. The conversion center automatically reformats packages to match destination requirements while preserving the original contents.</p>\n<p>Modern organizations often need to integrate systems with different data formats, field naming conventions, or payload structures. Rather than requiring each webhook consumer to implement transformation logic, the delivery system can handle these conversions centrally, reducing integration complexity and ensuring consistent data formats.</p>\n<blockquote>\n<p><strong>Decision: Transformation Engine Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook consumers often require different payload formats, field mappings, or data enrichment from the original event structure</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Consumer-side transformation (current approach)</li>\n<li>Static field mapping configuration</li>\n<li>Template-based transformation with scripting support</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement template-based transformation with scripting support using JSONata or JavaScript expressions</li>\n<li><strong>Rationale</strong>: Balances flexibility with performance and security, enabling complex transformations while maintaining deterministic behavior</li>\n<li><strong>Consequences</strong>: Requires transformation engine infrastructure but dramatically reduces consumer-side integration complexity</li>\n</ul>\n</blockquote>\n<p>The transformation system extends webhook configurations with transformation templates and enrichment rules:</p>\n<table>\n<thead>\n<tr>\n<th>Field</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>transformation_template</code></td>\n<td><code>str</code></td>\n<td>JSONata template or JavaScript function for payload transformation</td>\n</tr>\n<tr>\n<td><code>enrichment_sources</code></td>\n<td><code>json</code></td>\n<td>External data sources for payload enrichment during transformation</td>\n</tr>\n<tr>\n<td><code>field_mappings</code></td>\n<td><code>json</code></td>\n<td>Simple field rename and type conversion rules</td>\n</tr>\n<tr>\n<td><code>output_format</code></td>\n<td><code>str</code></td>\n<td>Target format: JSON, XML, form-encoded, or custom</td>\n</tr>\n<tr>\n<td><code>transformation_version</code></td>\n<td><code>int</code></td>\n<td>Template version for A/B testing and gradual rollout</td>\n</tr>\n</tbody></table>\n<p>The transformation pipeline operates between filter evaluation and HTTP delivery:</p>\n<ol>\n<li><strong>Template Compilation</strong>: Transformation templates are compiled and cached on webhook registration or update</li>\n<li><strong>Context Preparation</strong>: The original event payload, metadata, and enrichment data are prepared for template execution</li>\n<li><strong>Safe Execution</strong>: Templates execute in sandboxed environments with resource limits and timeout protection</li>\n<li><strong>Format Conversion</strong>: Transformed data is serialized to the target format specified in webhook configuration</li>\n<li><strong>Validation</strong>: Transformed payloads are validated against optional JSON schemas before delivery</li>\n<li><strong>Fallback Handling</strong>: If transformation fails, the system can deliver the original payload or skip delivery based on webhook configuration</li>\n</ol>\n<p>Example transformations demonstrate the system&#39;s flexibility:</p>\n<p><strong>Legacy System Integration</strong>: A legacy CRM system expects customer data in XML format with specific field names:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Original Event: {&quot;customer&quot;: {&quot;id&quot;: 123, &quot;email&quot;: &quot;user@example.com&quot;, &quot;created_at&quot;: &quot;2023-10-15T10:30:00Z&quot;}}\n\nTransformation Template:\n{\n  &quot;CustomerRecord&quot;: {\n    &quot;ID&quot;: customer.id,\n    &quot;EmailAddress&quot;: customer.email,\n    &quot;RegistrationDate&quot;: $formatDate(customer.created_at, &quot;MM/DD/YYYY&quot;)\n  }\n}\n\nOutput Format: XML</code></pre></div>\n\n<p><strong>Data Enrichment</strong>: An analytics system needs customer events enriched with account tier and geographic information:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Enrichment Sources: \n- customer_service: /api/customers/{customer.id}/details\n- geo_service: /api/lookup/country/{customer.ip_address}\n\nTemplate:\nevent ~&gt; |$| { \n  &quot;customer_tier&quot;: $lookup(&quot;customer_service&quot;).tier,\n  &quot;country&quot;: $lookup(&quot;geo_service&quot;).country_code,\n  &quot;enriched_at&quot;: $now()\n}|</code></pre></div>\n\n<h4 id=\"multi-region-deployment-architecture\">Multi-Region Deployment Architecture</h4>\n<p><strong>Mental Model: Global Distribution Network</strong>\nConsider how global shipping companies operate: they maintain regional distribution centers connected by coordinated logistics networks. A package shipped from New York to Tokyo doesn&#39;t travel directly - it moves through regional hubs that handle local delivery while maintaining global tracking and coordination. Multi-region webhook deployment follows similar principles.</p>\n<p>Organizations with global operations need webhook delivery systems that can handle events and deliver to endpoints across multiple geographic regions while maintaining consistency, compliance with data sovereignty requirements, and optimal performance through reduced latency.</p>\n<blockquote>\n<p><strong>Decision: Multi-Region Architecture Pattern</strong></p>\n<ul>\n<li><strong>Context</strong>: Global organizations need webhook delivery with regional compliance, reduced latency, and disaster recovery capabilities</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Single global deployment with geographic load balancing</li>\n<li>Independent regional deployments with manual coordination</li>\n<li>Federated architecture with regional autonomy and global coordination</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement federated architecture with regional webhook delivery clusters and global state coordination</li>\n<li><strong>Rationale</strong>: Balances performance, compliance, and operational complexity while enabling true disaster recovery and data sovereignty compliance</li>\n<li><strong>Consequences</strong>: Requires sophisticated coordination mechanisms but provides best-in-class performance and compliance capabilities</li>\n</ul>\n</blockquote>\n<p>The multi-region architecture introduces several new components and extends existing ones for global operation:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Regional Responsibility</th>\n<th>Global Responsibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>RegionalDeliveryCluster</code></td>\n<td>Event delivery within region, circuit breaker state, rate limiting</td>\n<td>Global webhook registration, cross-region event routing</td>\n</tr>\n<tr>\n<td><code>GlobalWebhookRegistry</code></td>\n<td>Regional webhook cache, ownership verification</td>\n<td>Master webhook configuration, secret rotation coordination</td>\n</tr>\n<tr>\n<td><code>EventRouter</code></td>\n<td>Regional event processing, local delivery queues</td>\n<td>Cross-region event routing, compliance rule enforcement</td>\n</tr>\n<tr>\n<td><code>ConsensusManager</code></td>\n<td>Regional coordinator node, health reporting</td>\n<td>Global configuration consensus, leader election across regions</td>\n</tr>\n<tr>\n<td><code>ComplianceEngine</code></td>\n<td>Regional data residency enforcement</td>\n<td>Global compliance policy management, audit trail consolidation</td>\n</tr>\n</tbody></table>\n<p>The federated deployment model operates through coordinated regional clusters:</p>\n<ol>\n<li><strong>Regional Cluster Architecture</strong>: Each geographic region operates a complete webhook delivery system with its own delivery queues, circuit breakers, and event logs</li>\n<li><strong>Global State Synchronization</strong>: Webhook registrations, configurations, and policy updates are synchronized across regions using distributed consensus protocols</li>\n<li><strong>Event Routing Intelligence</strong>: Events are routed to the appropriate regional cluster based on webhook endpoint location, compliance requirements, and performance optimization</li>\n<li><strong>Cross-Region Failover</strong>: If a regional cluster becomes unavailable, events can be rerouted to secondary regions with appropriate compliance validation</li>\n<li><strong>Consolidated Monitoring</strong>: Global dashboards provide unified visibility into delivery performance and system health across all regions</li>\n</ol>\n<p><strong>Data Sovereignty and Compliance Handling</strong>\nThe multi-region system enforces data sovereignty requirements through policy-based event routing:</p>\n<table>\n<thead>\n<tr>\n<th>Policy Type</th>\n<th>Description</th>\n<th>Enforcement Mechanism</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>data_residency</code></td>\n<td>Events containing personal data must be processed in specific regions</td>\n<td>Geographic event routing with payload analysis</td>\n</tr>\n<tr>\n<td><code>cross_border_restrictions</code></td>\n<td>Certain event types cannot cross national boundaries</td>\n<td>Compliance tags on events with routing validation</td>\n</tr>\n<tr>\n<td><code>encryption_requirements</code></td>\n<td>Events in specific regions require enhanced encryption</td>\n<td>Regional encryption key management and payload protection</td>\n</tr>\n<tr>\n<td><code>audit_retention</code></td>\n<td>Different regions have varying audit log retention requirements</td>\n<td>Regional audit policy enforcement with legal hold support</td>\n</tr>\n</tbody></table>\n<h3 id=\"enhanced-monitoring-and-analytics\">Enhanced Monitoring and Analytics</h3>\n<p>As webhook delivery systems mature from basic operational tools to critical business infrastructure, organizations require sophisticated monitoring and analytics capabilities that go beyond simple delivery success rates. Enhanced monitoring provides deep visibility into system behavior, customer experience, and business impact through comprehensive metrics, predictive analytics, and intelligent alerting.</p>\n<h4 id=\"comprehensive-metrics-dashboard\">Comprehensive Metrics Dashboard</h4>\n<p><strong>Mental Model: Air Traffic Control Center</strong>\nThink of enhanced monitoring like an air traffic control center managing a busy metropolitan airport. Controllers need real-time visibility into every aircraft&#39;s position, speed, and destination, but they also need predictive analytics to anticipate congestion, weather impact analysis, and historical pattern recognition to optimize flight scheduling. Similarly, webhook monitoring requires both real-time operational metrics and analytical insights that enable proactive system management.</p>\n<p>Traditional webhook monitoring focuses on basic delivery metrics: success rates, error counts, and response times. Enhanced monitoring expands this to provide comprehensive visibility into system performance, customer experience, and business impact through multidimensional metrics collection and analysis.</p>\n<p>The enhanced metrics system extends our existing monitoring infrastructure with comprehensive data collection and analysis capabilities:</p>\n<table>\n<thead>\n<tr>\n<th>Metric Category</th>\n<th>Key Metrics</th>\n<th>Analysis Dimensions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>delivery_performance</code></td>\n<td>Success rate, P50/P95/P99 latency, throughput per endpoint</td>\n<td>Time windows, geographic region, event type, endpoint characteristics</td>\n</tr>\n<tr>\n<td><code>customer_experience</code></td>\n<td>End-to-end delivery time, retry frequency, circuit breaker activations</td>\n<td>Customer segments, integration patterns, business criticality</td>\n</tr>\n<tr>\n<td><code>system_health</code></td>\n<td>Queue depth, worker utilization, database performance, memory usage</td>\n<td>Component-level detail, resource allocation, scaling efficiency</td>\n</tr>\n<tr>\n<td><code>business_impact</code></td>\n<td>Revenue-critical event delivery, SLA compliance, customer satisfaction</td>\n<td>Business unit correlation, cost attribution, ROI analysis</td>\n</tr>\n<tr>\n<td><code>security_metrics</code></td>\n<td>Authentication failures, SSRF attempts, rate limiting activations</td>\n<td>Attack pattern analysis, geographic threat distribution</td>\n</tr>\n</tbody></table>\n<p><strong>Real-Time Dashboard Architecture</strong>\nThe metrics dashboard provides multiple views optimized for different stakeholders and operational scenarios:</p>\n<ol>\n<li><strong>Operations Dashboard</strong>: Real-time system health with immediate alerting for operational issues</li>\n<li><strong>Customer Success Dashboard</strong>: Customer-facing delivery performance metrics with SLA tracking</li>\n<li><strong>Engineering Dashboard</strong>: Deep technical metrics for system optimization and capacity planning</li>\n<li><strong>Business Dashboard</strong>: Business impact metrics connecting webhook performance to revenue and customer satisfaction</li>\n<li><strong>Security Dashboard</strong>: Security event monitoring with threat detection and response coordination</li>\n</ol>\n<p>The dashboard implementation leverages time-series databases optimized for high-volume metrics ingestion and real-time querying:</p>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Technology Choice</th>\n<th>Responsibility</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MetricsCollector</code></td>\n<td>StatsD with Prometheus exposition</td>\n<td>High-frequency metric collection from all system components</td>\n</tr>\n<tr>\n<td><code>TimeSeriesDatabase</code></td>\n<td>InfluxDB or Prometheus with long-term storage</td>\n<td>Efficient storage and querying of metric time series</td>\n</tr>\n<tr>\n<td><code>DashboardEngine</code></td>\n<td>Grafana with custom panels</td>\n<td>Real-time visualization and alerting based on metric thresholds</td>\n</tr>\n<tr>\n<td><code>AnalyticsProcessor</code></td>\n<td>Apache Spark for batch processing</td>\n<td>Complex analytical queries and trend analysis</td>\n</tr>\n</tbody></table>\n<h4 id=\"sla-tracking-and-customer-health-scoring\">SLA Tracking and Customer Health Scoring</h4>\n<p><strong>Mental Model: Customer Health Monitoring</strong>\nConsider how a healthcare monitoring system tracks patient vital signs: it doesn&#39;t just record individual measurements, but analyzes patterns, trends, and correlations to provide an overall health score. It can predict potential issues before they become critical and alert medical staff when intervention is needed. SLA tracking and customer health scoring applies similar principles to webhook delivery performance.</p>\n<p>Organizations using webhook delivery systems need to monitor not just technical performance metrics, but the overall health of their customer integrations. This includes SLA compliance tracking, customer experience scoring, and predictive analytics that identify potential integration issues before they impact business operations.</p>\n<p>The SLA tracking system extends our monitoring infrastructure with customer-centric health metrics:</p>\n<table>\n<thead>\n<tr>\n<th>Health Metric</th>\n<th>Calculation Method</th>\n<th>Business Impact</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>integration_health_score</code></td>\n<td>Weighted average of delivery success, latency, and error patterns</td>\n<td>Overall integration reliability from customer perspective</td>\n</tr>\n<tr>\n<td><code>sla_compliance_percentage</code></td>\n<td>Percentage of events delivered within SLA commitments</td>\n<td>Direct customer satisfaction and contract compliance measurement</td>\n</tr>\n<tr>\n<td><code>customer_experience_index</code></td>\n<td>Complex score incorporating retry frequency, circuit breaker activations, support tickets</td>\n<td>Predictive indicator of customer satisfaction and churn risk</td>\n</tr>\n<tr>\n<td><code>business_criticality_factor</code></td>\n<td>Revenue-weighted delivery performance for high-value events</td>\n<td>Business impact prioritization for operational decision making</td>\n</tr>\n</tbody></table>\n<p><strong>Predictive Health Analytics</strong>\nThe system employs machine learning models to predict customer health trends and proactively identify integration issues:</p>\n<ol>\n<li><strong>Delivery Pattern Analysis</strong>: Identifies unusual patterns in delivery timing, frequency, or success rates that may indicate integration problems</li>\n<li><strong>Endpoint Health Prediction</strong>: Uses historical data to predict when endpoints are likely to experience issues, enabling proactive support</li>\n<li><strong>Resource Utilization Forecasting</strong>: Predicts system resource requirements based on customer growth patterns and event volume trends</li>\n<li><strong>Churn Risk Assessment</strong>: Correlates delivery performance with customer satisfaction metrics to identify at-risk customer integrations</li>\n</ol>\n<p>Consider how the health scoring system operates for a typical enterprise customer:</p>\n<p><strong>Customer: E-commerce Platform</strong></p>\n<ul>\n<li><p><strong>Integration Health Score</strong>: 94/100 (Excellent)</p>\n<ul>\n<li>Delivery Success Rate: 99.8% (weight: 40%)</li>\n<li>Average Delivery Latency: 150ms (weight: 30%)</li>\n<li>Circuit Breaker Activations: 1 in last 30 days (weight: 20%)</li>\n<li>Error Pattern Consistency: Low variance (weight: 10%)</li>\n</ul>\n</li>\n<li><p><strong>SLA Compliance</strong>: 98.5% (Target: 99.0%)</p>\n<ul>\n<li>Events delivered within 500ms: 98.2%</li>\n<li>Events delivered within 5 seconds: 99.9%</li>\n<li>Monthly downtime: 23 minutes (Target: 14.4 minutes)</li>\n</ul>\n</li>\n<li><p><strong>Predictive Alerts</strong>: </p>\n<ul>\n<li>Warning: Endpoint response time trending upward (investigate)</li>\n<li>Info: Traffic volume 15% above historical average (capacity planning)</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"predictive-analytics-and-alerting\">Predictive Analytics and Alerting</h4>\n<p><strong>Mental Model: Weather Forecasting System</strong>\nThink of predictive analytics like an advanced weather forecasting system that doesn&#39;t just report current conditions, but uses atmospheric models, historical patterns, and real-time sensor data to predict storms, temperature changes, and severe weather events days in advance. This enables people to prepare and take preventive action rather than simply reacting to problems as they occur.</p>\n<p>Traditional monitoring systems are reactive - they alert when problems have already occurred. Predictive analytics transforms this into proactive system management by identifying trends, patterns, and early warning signals that indicate potential issues before they impact service delivery.</p>\n<blockquote>\n<p><strong>Decision: Predictive Analytics Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Traditional reactive monitoring cannot prevent service disruptions or optimize system performance proactively</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Rule-based threshold alerting (current approach)</li>\n<li>Statistical anomaly detection with fixed baselines</li>\n<li>Machine learning-based predictive analytics with dynamic baselines</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement ML-based predictive analytics with multiple prediction models and ensemble methods</li>\n<li><strong>Rationale</strong>: Provides most accurate predictions and adapts to changing system behavior patterns over time</li>\n<li><strong>Consequences</strong>: Requires ML infrastructure and expertise but enables proactive system management and improved reliability</li>\n</ul>\n</blockquote>\n<p>The predictive analytics system operates through multiple specialized prediction models:</p>\n<table>\n<thead>\n<tr>\n<th>Prediction Model</th>\n<th>Purpose</th>\n<th>Input Data</th>\n<th>Prediction Horizon</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>DeliveryFailurePrediction</code></td>\n<td>Predict endpoint failures before they occur</td>\n<td>Response times, error rates, external monitoring</td>\n<td>15 minutes to 4 hours</td>\n</tr>\n<tr>\n<td><code>CapacityDemandForecasting</code></td>\n<td>Predict resource requirements for scaling decisions</td>\n<td>Event volume, customer growth, seasonal patterns</td>\n<td>1 hour to 30 days</td>\n</tr>\n<tr>\n<td><code>SecurityThreatDetection</code></td>\n<td>Identify potential security attacks or abuse</td>\n<td>Request patterns, IP geolocation, payload analysis</td>\n<td>Real-time to 24 hours</td>\n</tr>\n<tr>\n<td><code>CustomerChurnRiskAssessment</code></td>\n<td>Predict customer integration health and satisfaction</td>\n<td>Delivery performance, support interactions, usage patterns</td>\n<td>7 to 90 days</td>\n</tr>\n</tbody></table>\n<p><strong>Intelligent Alerting System</strong>\nThe alerting system uses predictive insights to generate actionable alerts with context and recommended actions:</p>\n<ol>\n<li><strong>Anomaly Detection</strong>: Statistical models identify unusual patterns in system metrics that may indicate emerging issues</li>\n<li><strong>Trend Analysis</strong>: Long-term trend analysis identifies gradual degradation that might not trigger threshold-based alerts</li>\n<li><strong>Correlation Analysis</strong>: Multi-dimensional correlation analysis identifies relationships between seemingly unrelated metrics</li>\n<li><strong>Impact Assessment</strong>: Alerts include predicted business impact and recommended response priority</li>\n<li><strong>Action Recommendations</strong>: Alerts include specific recommended actions based on historical resolution patterns</li>\n</ol>\n<p><strong>Example Predictive Alert Scenarios:</strong></p>\n<p><strong>Scenario 1: Endpoint Degradation Prediction</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Alert: Predicted Endpoint Failure\nSeverity: Warning\nWebhook: customer-orders.retailco.com\nPrediction: 78% probability of circuit breaker activation within 2 hours\nEvidence: \n- Response time increased 40% over last 30 minutes\n- Error rate trending from 0.1% to 1.2%\n- Similar pattern preceded last outage on 2023-09-15\nRecommended Actions:\n1. Contact customer technical team\n2. Prepare traffic rerouting to backup endpoint\n3. Monitor customer infrastructure status page\nBusiness Impact: $12,000 revenue exposure if prediction accurate</code></pre></div>\n\n<p><strong>Scenario 2: Capacity Scaling Prediction</strong></p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>Alert: Capacity Planning Required\nSeverity: Info\nComponent: Delivery Workers (US-East-1)\nPrediction: 90% worker utilization expected within 6 hours\nEvidence:\n- Event volume up 25% week-over-week\n- Current utilization at 68% with growing queue depth\n- Historical pattern matches Black Friday traffic surge\nRecommended Actions:\n1. Scale worker pool from 10 to 15 instances\n2. Pre-warm additional Redis connection pools\n3. Notify on-call team of expected traffic surge\nCost Impact: $48/hour additional infrastructure cost</code></pre></div>\n\n<h3 id=\"horizontal-scaling-considerations\">Horizontal Scaling Considerations</h3>\n<p>As webhook delivery systems grow from handling thousands of events per day to millions of events per hour, the architectural patterns that worked for single-instance deployments become bottlenecks. Horizontal scaling requires fundamental changes to how we think about state management, work coordination, and system boundaries. This involves transforming our component-based architecture into a distributed system with multiple coordinating instances.</p>\n<h4 id=\"sharding-strategies-for-event-distribution\">Sharding Strategies for Event Distribution</h4>\n<p><strong>Mental Model: Postal Service Hub System</strong>\nThink of horizontal scaling like transforming a single post office into a network of regional distribution hubs. Mail cannot be processed randomly by any hub - specific routing rules determine which hub handles mail for which geographic areas or postal codes. However, all hubs must coordinate to ensure mail tracking works globally and packages can be rerouted if one hub becomes unavailable.</p>\n<p>Traditional webhook delivery systems process all events through a single queue or processing pipeline. Horizontal scaling requires partitioning the event space across multiple processing instances while maintaining consistency guarantees and enabling coordination for cross-partition operations.</p>\n<blockquote>\n<p><strong>Decision: Event Sharding Strategy</strong></p>\n<ul>\n<li><strong>Context</strong>: Single-instance processing cannot handle enterprise-scale event volumes or provide geographic distribution</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Random distribution across workers (no sharding)</li>\n<li>Webhook endpoint-based sharding for processing locality</li>\n<li>Hybrid sharding with event type and customer-based partitioning</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement webhook endpoint-based sharding with customer affinity and failover capability</li>\n<li><strong>Rationale</strong>: Provides processing locality, maintains ordering guarantees per endpoint, and enables customer-specific scaling while supporting automatic failover</li>\n<li><strong>Consequences</strong>: Requires partition rebalancing logic but provides optimal performance and consistency characteristics</li>\n</ul>\n</blockquote>\n<p>The sharding system divides the webhook delivery workload across multiple processing instances while maintaining strong consistency guarantees:</p>\n<table>\n<thead>\n<tr>\n<th>Sharding Dimension</th>\n<th>Strategy</th>\n<th>Benefits</th>\n<th>Challenges</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>webhook_endpoint</code></td>\n<td>Hash-based partitioning on webhook URL</td>\n<td>Processing locality, ordering guarantees</td>\n<td>Uneven distribution if customer sizes vary</td>\n</tr>\n<tr>\n<td><code>customer_tenant</code></td>\n<td>Customer-based partition assignment</td>\n<td>Resource isolation, billing accuracy</td>\n<td>Complex rebalancing when customers grow</td>\n</tr>\n<tr>\n<td><code>geographic_region</code></td>\n<td>Event source location-based routing</td>\n<td>Compliance, latency optimization</td>\n<td>Cross-region coordination complexity</td>\n</tr>\n<tr>\n<td><code>event_priority</code></td>\n<td>High/normal priority separate processing</td>\n<td>SLA differentiation, resource allocation</td>\n<td>Additional infrastructure complexity</td>\n</tr>\n</tbody></table>\n<p><strong>Partition Assignment and Rebalancing</strong>\nThe sharding system uses consistent hashing with virtual nodes to distribute webhook endpoints across processing instances:</p>\n<ol>\n<li><strong>Hash Ring Construction</strong>: Webhook endpoints are assigned to partitions using SHA-256 hash of the URL, creating uniform distribution</li>\n<li><strong>Virtual Node Mapping</strong>: Each physical processing instance handles multiple virtual partitions, enabling fine-grained rebalancing</li>\n<li><strong>Partition Assignment</strong>: New instances claim partitions from the hash ring, while failing instances trigger automatic reassignment</li>\n<li><strong>Rebalancing Algorithm</strong>: Gradual partition migration maintains system availability during topology changes</li>\n<li><strong>Consistency Maintenance</strong>: Partition ownership is managed through distributed consensus to prevent split-brain scenarios</li>\n</ol>\n<p>Consider how partition assignment works for a system with 1000 webhook endpoints distributed across 5 processing instances:</p>\n<p><strong>Initial Distribution:</strong></p>\n<ul>\n<li>Instance 1: Partitions 0-199 (webhooks with hash values 0x0000-0x3333)</li>\n<li>Instance 2: Partitions 200-399 (webhooks with hash values 0x3334-0x6666)</li>\n<li>Instance 3: Partitions 400-599 (webhooks with hash values 0x6667-0x9999)</li>\n<li>Instance 4: Partitions 600-799 (webhooks with hash values 0x999A-0xCCCC)</li>\n<li>Instance 5: Partitions 800-999 (webhooks with hash values 0xCCCD-0xFFFF)</li>\n</ul>\n<p><strong>After Instance 6 Joins:</strong>\nThe system gradually reassigns partitions to achieve uniform distribution across 6 instances, with each instance handling approximately 167 partitions.</p>\n<h4 id=\"distributed-circuit-breaker-coordination\">Distributed Circuit Breaker Coordination</h4>\n<p><strong>Mental Model: Traffic Control Network</strong>\nImagine a city-wide traffic management system where multiple traffic control centers manage different districts, but they must coordinate to handle major incidents. If a highway bridge fails, all control centers need to know immediately so they can reroute traffic appropriately. However, day-to-day traffic decisions can be made locally without consulting other centers.</p>\n<p>In a distributed webhook delivery system, circuit breaker decisions must be coordinated across instances while avoiding the performance bottlenecks and single points of failure that would result from centralized state management.</p>\n<p>Traditional circuit breakers maintain state in local memory within a single process instance. Distributed systems require circuit breaker state that can be shared across instances while providing fast local decision-making and coordinated failure detection.</p>\n<blockquote>\n<p><strong>Decision: Distributed Circuit Breaker Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Circuit breaker decisions must be coordinated across multiple processing instances to prevent overwhelming failing endpoints</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Centralized circuit breaker state in shared database</li>\n<li>Eventually consistent circuit breaker state with local caching</li>\n<li>Hybrid approach with local decisions and global coordination</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement hybrid architecture with local circuit breakers and global state synchronization</li>\n<li><strong>Rationale</strong>: Provides fast local decisions while ensuring global coordination, balancing performance with consistency</li>\n<li><strong>Consequences</strong>: Requires sophisticated state synchronization but provides optimal performance and reliability characteristics</li>\n</ul>\n</blockquote>\n<p>The distributed circuit breaker system maintains both local and global state for optimal decision-making:</p>\n<table>\n<thead>\n<tr>\n<th>State Layer</th>\n<th>Responsibility</th>\n<th>Update Frequency</th>\n<th>Consistency Model</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>LocalCircuitState</code></td>\n<td>Fast delivery decisions, immediate failure recording</td>\n<td>Every delivery attempt</td>\n<td>Strongly consistent within instance</td>\n</tr>\n<tr>\n<td><code>GlobalCircuitState</code></td>\n<td>Cross-instance coordination, authoritative failure counts</td>\n<td>Every 10-30 seconds</td>\n<td>Eventually consistent across instances</td>\n</tr>\n<tr>\n<td><code>CircuitEventLog</code></td>\n<td>Audit trail, coordination events, manual overrides</td>\n<td>Every state transition</td>\n<td>Strong consistency via distributed log</td>\n</tr>\n</tbody></table>\n<p><strong>Coordination Protocol</strong>\nThe distributed circuit breaker operates through a hierarchical coordination protocol:</p>\n<ol>\n<li><strong>Local Decision Making</strong>: Each processing instance maintains local circuit breaker state for fast delivery decisions</li>\n<li><strong>Failure Aggregation</strong>: Local failures are aggregated and periodically synchronized to global state storage</li>\n<li><strong>Global State Propagation</strong>: Circuit breaker state changes are propagated to all instances through pub/sub messaging</li>\n<li><strong>Coordination Events</strong>: Major state transitions (circuit opening/closing) trigger immediate coordination events</li>\n<li><strong>Conflict Resolution</strong>: Conflicting circuit breaker states are resolved using timestamp-based last-writer-wins with manual override capability</li>\n</ol>\n<p>Consider how the distributed circuit breaker handles a webhook endpoint failure scenario:</p>\n<p><strong>Initial State</strong>: All instances show webhook endpoint <code>api.customer.com</code> in CLOSED state with 2/5 failure count</p>\n<p><strong>Failure Cascade</strong>:</p>\n<ol>\n<li><strong>T+0</strong>: Instance 3 experiences 3 consecutive failures, local count reaches 5/5, circuit opens locally</li>\n<li><strong>T+5s</strong>: Instance 3 publishes circuit state change to global coordination channel</li>\n<li><strong>T+7s</strong>: Instances 1, 2, 4, 5 receive state update and open their local circuit breakers</li>\n<li><strong>T+30s</strong>: Global state storage is updated with authoritative circuit state</li>\n<li><strong>T+5m</strong>: Recovery timer expires, Instance 3 transitions to HALF_OPEN and attempts test delivery</li>\n<li><strong>T+5m+2s</strong>: Test delivery succeeds, circuit closes and success event is propagated globally</li>\n</ol>\n<h4 id=\"global-state-management-and-consensus\">Global State Management and Consensus</h4>\n<p><strong>Mental Model: United Nations Security Council</strong>\nThink of global state management like the United Nations Security Council coordinating international decisions. Member nations maintain their sovereignty and make most decisions independently, but certain critical decisions require global consensus. The UN provides mechanisms for proposal, discussion, voting, and enforcement while ensuring that temporary communication failures don&#39;t paralyze the entire system.</p>\n<p>Distributed webhook delivery systems require coordination of global state such as webhook registrations, configuration changes, and system-wide policies while maintaining high availability and partition tolerance. This requires sophisticated consensus protocols that can handle network partitions, instance failures, and conflicting updates.</p>\n<blockquote>\n<p><strong>Decision: Global State Management Architecture</strong></p>\n<ul>\n<li><strong>Context</strong>: Webhook registrations, secrets, and system configuration must be consistent across all processing instances while maintaining availability during network partitions</li>\n<li><strong>Options Considered</strong>:<ol>\n<li>Master-slave replication with single authoritative instance</li>\n<li>Multi-master replication with conflict resolution</li>\n<li>Consensus-based coordination using Raft or similar protocols</li>\n</ol>\n</li>\n<li><strong>Decision</strong>: Implement Raft consensus for critical state with eventual consistency for metrics and logs</li>\n<li><strong>Rationale</strong>: Provides strong consistency for configuration data while maintaining availability and partition tolerance</li>\n<li><strong>Consequences</strong>: Requires consensus protocol implementation but provides optimal consistency and availability characteristics</li>\n</ul>\n</blockquote>\n<p>The global state management system partitions different types of state based on consistency requirements:</p>\n<table>\n<thead>\n<tr>\n<th>State Category</th>\n<th>Consistency Model</th>\n<th>Storage Mechanism</th>\n<th>Update Protocol</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>webhook_registrations</code></td>\n<td>Strong consistency</td>\n<td>Raft consensus cluster</td>\n<td>Majority quorum for writes</td>\n</tr>\n<tr>\n<td><code>system_configuration</code></td>\n<td>Strong consistency</td>\n<td>Raft consensus cluster</td>\n<td>Two-phase commit for complex changes</td>\n</tr>\n<tr>\n<td><code>delivery_metrics</code></td>\n<td>Eventual consistency</td>\n<td>Distributed time-series database</td>\n<td>Best-effort propagation with reconciliation</td>\n</tr>\n<tr>\n<td><code>audit_logs</code></td>\n<td>Strong consistency</td>\n<td>Replicated append-only log</td>\n<td>Write-ahead logging with replication</td>\n</tr>\n<tr>\n<td><code>circuit_breaker_state</code></td>\n<td>Bounded inconsistency</td>\n<td>Local state with global synchronization</td>\n<td>Periodic sync with conflict resolution</td>\n</tr>\n</tbody></table>\n<p><strong>Consensus Protocol Implementation</strong>\nThe system implements Raft consensus for managing critical global state:</p>\n<ol>\n<li><strong>Leader Election</strong>: Processing instances participate in leader election for global state coordination</li>\n<li><strong>Log Replication</strong>: Configuration changes are replicated through Raft log consensus before taking effect</li>\n<li><strong>Membership Changes</strong>: Instance joining and leaving events are handled through Raft membership change protocols</li>\n<li><strong>Partition Handling</strong>: Network partitions are handled by maintaining majority quorum requirements for global state changes</li>\n<li><strong>Recovery Protocol</strong>: Failed instances can rejoin the cluster and catch up through log replay</li>\n</ol>\n<p><strong>State Synchronization Patterns</strong>\nDifferent types of state require different synchronization patterns optimized for their specific consistency and performance requirements:</p>\n<p><strong>Webhook Registration Synchronization</strong>:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>1. New webhook registration submitted to leader instance\n2. Leader validates registration and generates unique webhook ID\n3. Leader proposes registration entry to Raft cluster\n4. Majority of instances accept proposal and commit to local state\n5. Leader acknowledges successful registration to client\n6. Configuration change is propagated to all follower instances\n7. Background process validates endpoint ownership across all instances</code></pre></div>\n\n<p><strong>Metrics Aggregation Synchronization</strong>:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>1. Each instance maintains local metrics counters for performance\n2. Every 60 seconds, instances publish metrics snapshots to time-series database\n3. Global metrics dashboard aggregates data from all instances\n4. Inconsistencies are resolved through timestamp-based conflict resolution\n5. Missing data is backfilled through instance heartbeat recovery</code></pre></div>\n\n<p>The horizontal scaling architecture enables the webhook delivery system to handle enterprise-scale workloads while maintaining the reliability, security, and observability characteristics established in our core milestone design. By carefully partitioning state and coordinating global decisions through consensus protocols, the system can scale to handle millions of webhook deliveries per hour across multiple geographic regions while preserving strong consistency guarantees where required.</p>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>The advanced features and scaling capabilities described above represent sophisticated extensions that build upon the solid foundation established in the core four milestones. The implementation approach should be incremental, starting with advanced delivery features before moving to comprehensive analytics and horizontal scaling.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Conditional Delivery</strong></td>\n<td>JSONPath with Redis caching</td>\n<td>Common Expression Language (CEL) with compiled expression cache</td>\n</tr>\n<tr>\n<td><strong>Payload Transformation</strong></td>\n<td>JSONata template engine</td>\n<td>JavaScript V8 sandbox with TypeScript support</td>\n</tr>\n<tr>\n<td><strong>Multi-Region Coordination</strong></td>\n<td>Redis Cluster with geographic replication</td>\n<td>Consul with WAN federation for global state</td>\n</tr>\n<tr>\n<td><strong>Metrics and Analytics</strong></td>\n<td>Prometheus with Grafana</td>\n<td>InfluxDB + Apache Spark with custom dashboards</td>\n</tr>\n<tr>\n<td><strong>Predictive Analytics</strong></td>\n<td>scikit-learn with periodic model updates</td>\n<td>TensorFlow Serving with real-time model deployment</td>\n</tr>\n<tr>\n<td><strong>Distributed Consensus</strong></td>\n<td>etcd cluster for critical state</td>\n<td>Custom Raft implementation optimized for webhook workloads</td>\n</tr>\n<tr>\n<td><strong>Event Sharding</strong></td>\n<td>Consistent hash ring with Redis coordination</td>\n<td>Apache Kafka with custom partitioning strategy</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-architecture-evolution\">Recommended Architecture Evolution</h4>\n<p>The scaling implementation should follow a phased approach that maintains system stability while adding advanced capabilities:</p>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>webhook-system/\n├── cmd/\n│   ├── webhook-server/           ← Core delivery system from milestones 1-4\n│   ├── analytics-processor/      ← Advanced analytics and metrics processing\n│   ├── transformation-engine/    ← Payload transformation service\n│   └── global-coordinator/       ← Multi-region state coordination\n├── internal/\n│   ├── delivery/                 ← Enhanced delivery engine with sharding\n│   │   ├── sharding.go          ← Consistent hashing and partition management\n│   │   ├── coordinator.go       ← Distributed coordination protocols\n│   │   └── filters.go           ← Conditional delivery and filtering\n│   ├── transformation/          ← Payload transformation pipeline\n│   │   ├── engine.go            ← Template execution and caching\n│   │   ├── jsonata.go           ← JSONata template processor\n│   │   └── security.go          ← Sandbox and resource limits\n│   ├── analytics/               ← Advanced monitoring and predictions\n│   │   ├── collector.go         ← High-frequency metrics collection\n│   │   ├── predictor.go         ← ML-based predictive models\n│   │   └── health.go            ← Customer health scoring\n│   ├── consensus/               ← Distributed state management\n│   │   ├── raft.go              ← Raft consensus implementation\n│   │   ├── state.go             ← Global state management\n│   │   └── coordination.go      ← Cross-region coordination\n│   └── scaling/                 ← Horizontal scaling infrastructure\n│       ├── partitioner.go       ← Event partitioning and rebalancing\n│       ├── circuit_distributed.go ← Distributed circuit breakers\n│       └── discovery.go         ← Service discovery and health checking\n├── deployments/\n│   ├── kubernetes/              ← K8s manifests for multi-region deployment\n│   ├── terraform/               ← Infrastructure as code for cloud resources\n│   └── monitoring/              ← Advanced monitoring and alerting configuration\n└── ml-models/                   ← Machine learning models for predictions\n    ├── failure-prediction/      ← Endpoint failure prediction model\n    ├── capacity-forecasting/    ← Resource demand forecasting model\n    └── churn-analysis/          ← Customer health and churn prediction</code></pre></div>\n\n<h4 id=\"advanced-filtering-engine\">Advanced Filtering Engine</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Any, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timezone</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> FilterExpression</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Represents a compiled filter expression for webhook delivery decisions.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    expression: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    compiled_form: Any</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    version: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    variables: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConditionalDeliveryEngine</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Advanced filtering engine for conditional webhook delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_client: redis.Redis):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.expression_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> evaluate_delivery_conditions</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, event: </span><span style=\"color:#9ECBFF\">'WebhookEvent'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   webhook_config: </span><span style=\"color:#9ECBFF\">'WebhookRegistration'</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Determine if event should be delivered to webhook based on filter conditions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if event matches all delivery conditions, False otherwise.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check if webhook has filter expressions configured</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Load or compile filter expression from cache</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Prepare evaluation context with event data, metadata, and variables</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Execute filter expression in safe environment with timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Log filter evaluation result for debugging and audit</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return boolean delivery decision</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Cache compiled expressions to avoid recompilation overhead</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> compile_filter_expression</span><span style=\"color:#E1E4E8\">(self, expression: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, variables: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> FilterExpression:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Compile filter expression into optimized executable form.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Supports JSONPath for simple field access and CEL for complex conditions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Parse expression to determine type (JSONPath vs CEL)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Validate expression syntax and security constraints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Compile expression into executable form with optimization</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Create FilterExpression object with metadata</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Cache compiled expression for reuse</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use expression hash as cache key for efficient lookup</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> prepare_evaluation_context</span><span style=\"color:#E1E4E8\">(self, event: </span><span style=\"color:#9ECBFF\">'WebhookEvent'</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                 webhook_config: </span><span style=\"color:#9ECBFF\">'WebhookRegistration'</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Prepare context variables available during filter expression evaluation.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract event payload and metadata into context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Add webhook configuration fields to context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Include system variables (current time, region, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Merge custom variables from webhook filter configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate context size and complexity limits</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PayloadTransformationEngine</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Template-based payload transformation for webhook delivery.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.template_cache </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.enrichment_clients </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> transform_payload</span><span style=\"color:#E1E4E8\">(self, original_payload: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                         transformation_config: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Transform webhook payload according to template configuration.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Supports JSONata templates, field mapping, and data enrichment.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Load transformation template from configuration</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Prepare transformation context with payload and enrichment data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Execute template transformation in secure sandbox</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply field mappings and format conversions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Validate transformed payload against schema if configured</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Handle transformation errors with fallback strategies</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Implement resource limits and timeout protection for template execution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> enrich_payload_data</span><span style=\"color:#E1E4E8\">(self, payload: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any], </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                           enrichment_sources: List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Fetch additional data from external sources for payload enrichment.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Iterate through configured enrichment sources</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract lookup keys from original payload</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Make parallel requests to enrichment APIs with timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Merge enrichment data into payload context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Handle enrichment failures gracefully with partial data</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Cache enrichment results to reduce external API calls</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"predictive-analytics-infrastructure\">Predictive Analytics Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> numpy </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> np</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.ensemble </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> IsolationForest, RandomForestClassifier</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> sklearn.preprocessing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> StandardScaler</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> joblib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> List, Tuple, Dict, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> datetime </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> datetime, timedelta</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookPredictiveAnalytics</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Machine learning-based predictive analytics for webhook delivery system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, metrics_database):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.metrics_db </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> metrics_database</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.models </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.scalers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> predict_endpoint_failure</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                               prediction_horizon_minutes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 60</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">, Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Predict probability of webhook endpoint failure within specified time horizon.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns probability score (0.0-1.0) and evidence dictionary.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Fetch recent delivery metrics for webhook endpoint</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract feature vector from metrics (response time, error rate, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Load or train endpoint failure prediction model</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply feature scaling and generate prediction</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Calculate confidence intervals and evidence summary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return prediction with supporting evidence for alerting</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use sliding time windows for feature extraction</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> forecast_capacity_requirements</span><span style=\"color:#E1E4E8\">(self, region: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                     forecast_horizon_hours: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 24</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Forecast resource requirements for webhook delivery capacity planning.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Predicts worker instances, queue capacity, and infrastructure needs.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Analyze historical event volume patterns by time and region</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Extract seasonal, trend, and cyclical components</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply time series forecasting model (ARIMA or Prophet)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Convert event volume forecast to resource requirements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Include confidence intervals and scenario analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Generate scaling recommendations with cost estimates</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> detect_security_anomalies</span><span style=\"color:#E1E4E8\">(self, request_patterns: List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]) -> List[Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Identify potential security threats or abuse patterns in webhook requests.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Extract features from request patterns (IP, timing, payload size, etc.)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Apply anomaly detection model (Isolation Forest or similar)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Score requests for anomaly likelihood</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Cluster similar anomalous patterns for threat classification</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate security alerts with threat analysis</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Update anomaly detection baseline regularly to adapt to normal patterns</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> CustomerHealthScoring</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Advanced customer health scoring based on webhook delivery performance.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> calculate_integration_health_score</span><span style=\"color:#E1E4E8\">(self, customer_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                         time_window_days: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 30</span><span style=\"color:#E1E4E8\">) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Calculate comprehensive health score for customer webhook integration.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns health score (0-100) with component breakdown and trends.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Fetch delivery metrics for all customer webhook endpoints</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Calculate component scores (success rate, latency, reliability)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply weighted scoring based on business criticality</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Analyze trends and velocity of health changes</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Generate actionable insights and recommendations</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return comprehensive health assessment with drill-down data</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"distributed-scaling-infrastructure\">Distributed Scaling Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> hashlib</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> asyncio</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Set, Optional, Tuple</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> redis.asyncio </span><span style=\"color:#F97583\">as</span><span style=\"color:#E1E4E8\"> redis</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> json</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ShardingStrategy</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    WEBHOOK_ENDPOINT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"webhook_endpoint\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CUSTOMER_TENANT</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"customer_tenant\"</span><span style=\"color:#E1E4E8\"> </span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    GEOGRAPHIC_REGION</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"geographic_region\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> PartitionInfo</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    partition_id: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    start_hash: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    end_hash: </span><span style=\"color:#79B8FF\">int</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    assigned_instance: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    last_rebalanced: datetime</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> ConsistentHashSharding</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Consistent hashing implementation for webhook delivery load distribution.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_client: redis.Redis, virtual_nodes: </span><span style=\"color:#79B8FF\">int</span><span style=\"color:#F97583\"> =</span><span style=\"color:#79B8FF\"> 150</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.virtual_nodes </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> virtual_nodes</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.hash_ring </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.instance_partitions </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> assign_webhook_to_partition</span><span style=\"color:#E1E4E8\">(self, webhook_url: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Determine which processing instance should handle deliveries for webhook URL.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns instance identifier responsible for this webhook endpoint.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate hash value for webhook URL using SHA-256</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Find appropriate position on consistent hash ring</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Locate assigned processing instance for this hash range</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle partition reassignment during rebalancing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Cache partition assignment for performance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return instance identifier for delivery routing</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Use virtual nodes to ensure uniform distribution</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> rebalance_partitions</span><span style=\"color:#E1E4E8\">(self, available_instances: Set[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]) -> Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, List[</span><span style=\"color:#79B8FF\">int</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Rebalance webhook partitions across available processing instances.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Minimizes partition movement while achieving uniform distribution.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Calculate target partition count per instance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Identify over-loaded and under-loaded instances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Plan partition migrations to achieve balance</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Execute gradual migration to avoid service disruption</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Update hash ring and routing tables atomically</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return new partition assignment mapping</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> DistributedCircuitBreaker</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Distributed circuit breaker with global state coordination.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, redis_client: redis.Redis, instance_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.redis </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> redis_client</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.instance_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> instance_id</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.local_state </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> should_allow_delivery</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Tuple[</span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, Optional[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Check if delivery should be attempted considering distributed circuit state.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns (allow_delivery, reason) tuple for delivery decision.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Check local circuit breaker state for fast decision</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: If local state is uncertain, consult global state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Apply circuit breaker logic (CLOSED/OPEN/HALF_OPEN)</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle race conditions during state transitions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Return delivery decision with reasoning for debugging</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Prioritize local decisions for performance, global for accuracy</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> record_delivery_result</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, success: </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                   response_time: </span><span style=\"color:#79B8FF\">float</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Record delivery result and update circuit breaker state accordingly.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Update local circuit breaker state with delivery result</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Check if local state change triggers global coordination</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Publish state change events to other instances if needed</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle consensus conflicts during concurrent updates</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Log state transitions for debugging and audit</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> coordinate_global_state</span><span style=\"color:#E1E4E8\">(self, webhook_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">                                    local_state: </span><span style=\"color:#9ECBFF\">'CircuitState'</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Coordinate circuit breaker state changes across all processing instances.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Aggregate failure counts from all processing instances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Determine authoritative circuit breaker state</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Publish state changes to coordination channel</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Handle network partitions and instance failures gracefully</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Ensure all instances converge to consistent state</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GlobalStateCoordination</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Raft-based consensus for global webhook system state management.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, instance_id: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, peer_instances: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.instance_id </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> instance_id</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.peers </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> peer_instances</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.is_leader </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> False</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.current_term </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> 0</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.log </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> []</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> propose_configuration_change</span><span style=\"color:#E1E4E8\">(self, change: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, Any]) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Propose global configuration change through Raft consensus protocol.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        </span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns True if change was accepted by majority quorum.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Validate that current instance is elected leader</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Create log entry for proposed configuration change</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Replicate log entry to majority of peer instances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Apply configuration change once consensus is reached</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Notify all instances of successful configuration update</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Return success status for client acknowledgment</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # Hint: Implement proper Raft leader election and log replication</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    async</span><span style=\"color:#F97583\"> def</span><span style=\"color:#B392F0\"> handle_leader_election</span><span style=\"color:#E1E4E8\">(self) -> </span><span style=\"color:#79B8FF\">bool</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"Execute Raft leader election protocol when current leader is unavailable.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 1: Increment current term and vote for self</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 2: Send vote requests to all peer instances</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 3: Collect vote responses within election timeout</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 4: Become leader if majority votes received</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 5: Send heartbeats to maintain leadership authority</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\"> 6: Step down if higher term discovered or split vote</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoints-for-advanced-features\">Milestone Checkpoints for Advanced Features</h4>\n<p><strong>Advanced Delivery Features Validation:</strong></p>\n<ul>\n<li>Conditional delivery: Configure filter expressions and verify only matching events are delivered</li>\n<li>Payload transformation: Create transformation templates and validate output format correctness</li>\n<li>Multi-region deployment: Deploy to multiple regions and verify cross-region state synchronization</li>\n</ul>\n<p><strong>Enhanced Monitoring Validation:</strong></p>\n<ul>\n<li>Comprehensive metrics: Validate all metric categories are collected and displayed in dashboards</li>\n<li>Predictive analytics: Generate predictions and verify alert accuracy through controlled failure scenarios</li>\n<li>Customer health scoring: Calculate health scores and validate correlation with actual customer satisfaction</li>\n</ul>\n<p><strong>Horizontal Scaling Validation:</strong></p>\n<ul>\n<li>Sharding functionality: Add/remove processing instances and verify automatic partition rebalancing</li>\n<li>Distributed coordination: Create network partitions and verify system maintains consistency and availability</li>\n<li>Global state management: Perform concurrent configuration changes and verify consensus behavior</li>\n</ul>\n<p>The advanced features and scaling capabilities described in this section transform the webhook delivery system from a reliable single-instance service into a comprehensive enterprise-grade event distribution platform. The implementation approach emphasizes incremental development, operational excellence, and maintainability while providing the sophisticated capabilities required for modern cloud-native architectures.</p>\n<h2 id=\"glossary\">Glossary</h2>\n<blockquote>\n<p><strong>Milestone(s):</strong> All milestones (1-4) - technical terms and domain-specific vocabulary used throughout the webhook delivery system design and implementation</p>\n</blockquote>\n<p>Understanding a webhook delivery system requires familiarity with terminology spanning distributed systems, cryptography, HTTP protocols, and reliability engineering. This glossary provides precise definitions of technical terms used throughout the design document, organized to build understanding from basic concepts to advanced patterns.</p>\n<h3 id=\"mental-model-the-technical-dictionary\">Mental Model: The Technical Dictionary</h3>\n<p>Think of this glossary as a technical dictionary specifically tailored to webhook delivery systems. Just as a medical dictionary defines terms differently than a general dictionary (where &quot;culture&quot; means bacterial growth, not art), this glossary defines common terms within the specific context of reliable webhook delivery. Many terms like &quot;circuit breaker&quot; or &quot;exponential backoff&quot; have precise meanings in distributed systems that differ from their everyday usage.</p>\n<p>The glossary serves as a reference for junior developers learning the domain, ensuring consistent terminology across teams, and providing the precise technical definitions needed for implementation. Each entry includes not just the definition but the context in which the term is used within webhook delivery systems.</p>\n<h3 id=\"core-webhook-concepts\">Core Webhook Concepts</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>webhook delivery</strong></td>\n<td>Asynchronous HTTP notification system that sends event data to registered HTTP endpoints when specific events occur in the source system</td>\n<td>Primary system function - the core service being built</td>\n<td>endpoint, event, payload</td>\n</tr>\n<tr>\n<td><strong>webhook endpoint</strong></td>\n<td>HTTP URL that receives webhook notifications via POST requests with event payload data</td>\n<td>Destination for all delivery attempts - registered and verified by customers</td>\n<td>callback URL, destination URL</td>\n</tr>\n<tr>\n<td><strong>event payload</strong></td>\n<td>JSON data structure containing the actual event information being delivered to webhook endpoints</td>\n<td>Core data being transmitted - contains business event details</td>\n<td>event data, message body</td>\n</tr>\n<tr>\n<td><strong>webhook signature</strong></td>\n<td>Cryptographic authentication token included in HTTP headers that allows endpoints to verify the authenticity and integrity of webhook deliveries</td>\n<td>Security mechanism preventing spoofing and tampering</td>\n<td>HMAC signature, authentication</td>\n</tr>\n<tr>\n<td><strong>endpoint registration</strong></td>\n<td>Process of adding a new webhook endpoint to the system, including URL validation, ownership verification, and secret generation</td>\n<td>Initial setup required before any deliveries can occur</td>\n<td>webhook onboarding, subscription</td>\n</tr>\n<tr>\n<td><strong>event subscription</strong></td>\n<td>Configuration specifying which event types a webhook endpoint wants to receive notifications for</td>\n<td>Filtering mechanism that determines delivery targets</td>\n<td>event filtering, subscription rules</td>\n</tr>\n<tr>\n<td><strong>delivery attempt</strong></td>\n<td>Single HTTP POST request sent to a webhook endpoint with signed event payload data</td>\n<td>Individual unit of work in the delivery process</td>\n<td>webhook request, delivery try</td>\n</tr>\n<tr>\n<td><strong>delivery guarantee</strong></td>\n<td>System promise about webhook delivery reliability, typically &quot;at-least-once&quot; meaning events will not be lost but may be delivered multiple times</td>\n<td>Reliability contract with customers using the webhook service</td>\n<td>delivery semantics, reliability SLA</td>\n</tr>\n</tbody></table>\n<h3 id=\"reliability-and-fault-tolerance\">Reliability and Fault Tolerance</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>circuit breaker</strong></td>\n<td>Failure protection pattern that disables failing endpoints after consecutive failures, preventing wasted resources on known-bad destinations</td>\n<td>Protection mechanism preventing resource waste on failing endpoints</td>\n<td>fault isolation, failure protection</td>\n</tr>\n<tr>\n<td><strong>exponential backoff</strong></td>\n<td>Retry strategy where delay between attempts increases exponentially (e.g., 1s, 2s, 4s, 8s) to avoid overwhelming recovering services</td>\n<td>Retry timing strategy that balances fast recovery with system protection</td>\n<td>retry delay, backoff strategy</td>\n</tr>\n<tr>\n<td><strong>jitter</strong></td>\n<td>Random variation added to retry delays to prevent multiple failed requests from retrying simultaneously and overwhelming a recovering endpoint</td>\n<td>Prevents thundering herd when many webhooks fail at the same time</td>\n<td>randomization, staggered retry</td>\n</tr>\n<tr>\n<td><strong>dead letter queue</strong></td>\n<td>Storage location for webhook events that have exhausted all retry attempts and cannot be delivered successfully</td>\n<td>Final destination for permanently failed deliveries requiring manual intervention</td>\n<td>DLQ, failed message storage</td>\n</tr>\n<tr>\n<td><strong>at-least-once delivery</strong></td>\n<td>Guarantee that webhook events will be delivered successfully at least one time, though duplicate deliveries are possible during failure recovery</td>\n<td>Core reliability promise - no events are lost due to system failures</td>\n<td>delivery guarantee, reliability SLA</td>\n</tr>\n<tr>\n<td><strong>thundering herd</strong></td>\n<td>Problem where many clients simultaneously retry failed requests when a service recovers, potentially overwhelming it again</td>\n<td>Failure pattern prevented by jitter and circuit breakers</td>\n<td>retry storm, recovery overload</td>\n</tr>\n<tr>\n<td><strong>circuit breaker failure threshold</strong></td>\n<td>Number of consecutive delivery failures that will trigger the circuit breaker to open and stop delivery attempts</td>\n<td>Configuration parameter controlling circuit breaker sensitivity</td>\n<td>failure limit, trip threshold</td>\n</tr>\n<tr>\n<td><strong>circuit breaker recovery timeout</strong></td>\n<td>Duration the circuit breaker waits in open state before attempting test deliveries to check if the endpoint has recovered</td>\n<td>Time-based recovery mechanism allowing endpoints to heal</td>\n<td>recovery period, healing time</td>\n</tr>\n</tbody></table>\n<h3 id=\"circuit-breaker-states\">Circuit Breaker States</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>closed circuit state</strong></td>\n<td>Normal operating state where delivery attempts are allowed and the endpoint is considered healthy</td>\n<td>Default state when endpoint is working correctly</td>\n<td>normal operation, healthy state</td>\n</tr>\n<tr>\n<td><strong>open circuit state</strong></td>\n<td>Protective state where delivery attempts are blocked after repeated failures, preventing resource waste on known-bad endpoints</td>\n<td>Failure state protecting system resources from bad endpoints</td>\n<td>blocked state, failure protection</td>\n</tr>\n<tr>\n<td><strong>half-open circuit state</strong></td>\n<td>Testing state where limited probe requests are sent to check if a failed endpoint has recovered and can handle normal traffic</td>\n<td>Recovery testing phase between failure and normal operation</td>\n<td>recovery testing, probe state</td>\n</tr>\n<tr>\n<td><strong>circuit breaker flapping</strong></td>\n<td>Rapid oscillation between open and closed states, typically caused by an endpoint that intermittently fails under load</td>\n<td>Unstable behavior indicating endpoint capacity or reliability issues</td>\n<td>state oscillation, unstable circuit</td>\n</tr>\n</tbody></table>\n<h3 id=\"security-and-authentication\">Security and Authentication</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>HMAC signature</strong></td>\n<td>Hash-based Message Authentication Code computed using SHA-256 over the webhook payload with a shared secret key</td>\n<td>Primary authentication mechanism preventing webhook spoofing</td>\n<td>cryptographic signature, payload authentication</td>\n</tr>\n<tr>\n<td><strong>canonical signing string</strong></td>\n<td>Standardized format combining webhook payload, timestamp, webhook ID, and delivery ID used as input for HMAC signature calculation</td>\n<td>Ensures consistent signature generation and verification</td>\n<td>signature input, signing format</td>\n</tr>\n<tr>\n<td><strong>webhook secret</strong></td>\n<td>Cryptographically random shared key used for HMAC signature generation and verification between the webhook service and endpoint</td>\n<td>Shared authentication credential enabling signature verification</td>\n<td>signing key, shared secret</td>\n</tr>\n<tr>\n<td><strong>secret rotation</strong></td>\n<td>Process of generating new webhook secrets while maintaining overlapping validity periods to ensure seamless key updates</td>\n<td>Security practice preventing long-lived key compromise</td>\n<td>key rotation, credential refresh</td>\n</tr>\n<tr>\n<td><strong>ownership verification</strong></td>\n<td>Challenge-response protocol where endpoints must prove they control the registered URL by responding to a verification request</td>\n<td>Prevents unauthorized webhook registration to endpoints not owned by the requester</td>\n<td>endpoint verification, challenge-response</td>\n</tr>\n<tr>\n<td><strong>replay protection</strong></td>\n<td>Mechanism using timestamps and nonces to prevent reuse of captured webhook requests for malicious purposes</td>\n<td>Prevents replay attacks using recorded webhook deliveries</td>\n<td>anti-replay, request freshness</td>\n</tr>\n<tr>\n<td><strong>SSRF protection</strong></td>\n<td>Security measures preventing webhook registration to internal network addresses that could be exploited for server-side request forgery attacks</td>\n<td>Prevents attackers from using webhook system to probe internal networks</td>\n<td>request forgery prevention, network security</td>\n</tr>\n<tr>\n<td><strong>timing attack</strong></td>\n<td>Cryptographic attack that exploits differences in signature verification execution time to infer information about the secret key</td>\n<td>Security vulnerability prevented by constant-time signature comparison</td>\n<td>side-channel attack, cryptographic timing</td>\n</tr>\n<tr>\n<td><strong>envelope encryption</strong></td>\n<td>Technique where webhook secrets are encrypted with a separate master key rather than stored in plaintext</td>\n<td>Additional security layer protecting secrets from database compromise</td>\n<td>key encryption, layered security</td>\n</tr>\n</tbody></table>\n<h3 id=\"queue-management-and-processing\">Queue Management and Processing</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>delivery queue</strong></td>\n<td>Persistent message queue storing webhook events waiting to be delivered to their target endpoints</td>\n<td>Core infrastructure ensuring reliable event storage and processing</td>\n<td>message queue, event queue</td>\n</tr>\n<tr>\n<td><strong>queue ordering</strong></td>\n<td>Guarantee that webhook events for a specific endpoint are processed in the order they were received</td>\n<td>Ensures event sequence integrity for stateful webhook consumers</td>\n<td>FIFO processing, event ordering</td>\n</tr>\n<tr>\n<td><strong>queue backlog</strong></td>\n<td>Accumulation of unprocessed webhook events in delivery queues, typically indicating processing capacity issues</td>\n<td>Performance metric indicating system stress or endpoint problems</td>\n<td>message backlog, processing lag</td>\n</tr>\n<tr>\n<td><strong>message persistence</strong></td>\n<td>Storage of queued webhook events in durable storage to survive system restarts and failures</td>\n<td>Ensures events are not lost due to system crashes or restarts</td>\n<td>durable storage, queue durability</td>\n</tr>\n<tr>\n<td><strong>queue partitioning</strong></td>\n<td>Division of webhook events across multiple queue partitions to enable parallel processing and horizontal scaling</td>\n<td>Scaling technique allowing multiple workers to process events concurrently</td>\n<td>queue sharding, parallel processing</td>\n</tr>\n<tr>\n<td><strong>consumer group</strong></td>\n<td>Set of worker processes that cooperatively consume events from delivery queues with load balancing and failure recovery</td>\n<td>Worker coordination pattern ensuring events are processed exactly once</td>\n<td>worker pool, consumer coordination</td>\n</tr>\n<tr>\n<td><strong>queue health</strong></td>\n<td>Metrics indicating the operational status of delivery queues, including depth, processing rate, and error rates</td>\n<td>Monitoring data used for capacity planning and problem detection</td>\n<td>queue metrics, operational health</td>\n</tr>\n</tbody></table>\n<h3 id=\"rate-limiting-and-flow-control\">Rate Limiting and Flow Control</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>rate limiting</strong></td>\n<td>Mechanism that controls the maximum number of webhook delivery attempts per endpoint within a specific time window</td>\n<td>Protects endpoints from being overwhelmed by high delivery rates</td>\n<td>throttling, flow control</td>\n</tr>\n<tr>\n<td><strong>token bucket</strong></td>\n<td>Rate limiting algorithm that allows burst traffic up to a capacity limit while maintaining average rate limits over time</td>\n<td>Implementation technique providing flexible rate control with burst handling</td>\n<td>burst capacity, rate control</td>\n</tr>\n<tr>\n<td><strong>Retry-After header</strong></td>\n<td>HTTP response header indicating how long clients should wait before making another request to a rate-limited endpoint</td>\n<td>Standard mechanism for endpoints to communicate their preferred retry timing</td>\n<td>backpressure signal, rate limit communication</td>\n</tr>\n<tr>\n<td><strong>burst capacity</strong></td>\n<td>Maximum number of requests that can be sent in rapid succession before rate limiting takes effect</td>\n<td>Allows short traffic spikes while maintaining overall rate limits</td>\n<td>burst allowance, traffic spike handling</td>\n</tr>\n<tr>\n<td><strong>rate limit bypass</strong></td>\n<td>Configuration option allowing certain high-priority events or trusted customers to exceed normal rate limits</td>\n<td>Emergency mechanism for critical business events</td>\n<td>priority delivery, limit override</td>\n</tr>\n<tr>\n<td><strong>backpressure</strong></td>\n<td>System response to downstream capacity limits by slowing or stopping upstream processing to prevent overload</td>\n<td>Flow control mechanism protecting the entire delivery pipeline</td>\n<td>flow control, congestion control</td>\n</tr>\n</tbody></table>\n<h3 id=\"monitoring-and-health\">Monitoring and Health</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>endpoint health monitoring</strong></td>\n<td>Continuous tracking of delivery success rates, response times, and error patterns for webhook endpoints</td>\n<td>Operational intelligence for detecting problems and managing circuit breakers</td>\n<td>health tracking, endpoint monitoring</td>\n</tr>\n<tr>\n<td><strong>health score</strong></td>\n<td>Composite metric combining delivery success rate, response time, and availability to assess overall endpoint reliability</td>\n<td>Single number summarizing endpoint operational quality</td>\n<td>reliability metric, endpoint score</td>\n</tr>\n<tr>\n<td><strong>delivery latency</strong></td>\n<td>Time elapsed between when an event is generated and when it is successfully delivered to the webhook endpoint</td>\n<td>Performance metric indicating system responsiveness</td>\n<td>response time, delivery delay</td>\n</tr>\n<tr>\n<td><strong>success rate</strong></td>\n<td>Percentage of webhook delivery attempts that result in successful HTTP responses (2xx status codes)</td>\n<td>Primary reliability metric for endpoints and overall system health</td>\n<td>delivery success, reliability percentage</td>\n</tr>\n<tr>\n<td><strong>error rate</strong></td>\n<td>Percentage of webhook delivery attempts that result in HTTP errors, timeouts, or other failure conditions</td>\n<td>Failure metric used for alerting and circuit breaker decisions</td>\n<td>failure rate, delivery failures</td>\n</tr>\n<tr>\n<td><strong>endpoint availability</strong></td>\n<td>Percentage of time that a webhook endpoint is responsive and accepting delivery attempts successfully</td>\n<td>Uptime metric indicating endpoint operational status</td>\n<td>uptime percentage, service availability</td>\n</tr>\n</tbody></table>\n<h3 id=\"event-sourcing-and-audit\">Event Sourcing and Audit</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>event sourcing</strong></td>\n<td>Pattern of capturing all state changes as immutable event records, providing complete audit trail and replay capability</td>\n<td>Architectural approach enabling comprehensive delivery logging and replay</td>\n<td>audit trail, immutable log</td>\n</tr>\n<tr>\n<td><strong>delivery audit trail</strong></td>\n<td>Complete historical record of every webhook delivery attempt including payloads, responses, timing, and error information</td>\n<td>Compliance and debugging capability tracking all delivery activity</td>\n<td>audit log, delivery history</td>\n</tr>\n<tr>\n<td><strong>event replay</strong></td>\n<td>Capability to re-send previously delivered webhook events, typically used for recovery from endpoint outages or debugging</td>\n<td>Recovery mechanism allowing reprocessing of historical events</td>\n<td>message replay, event redelivery</td>\n</tr>\n<tr>\n<td><strong>replay deduplication</strong></td>\n<td>Mechanism to identify and handle duplicate webhook deliveries during event replay operations</td>\n<td>Prevents duplicate processing when events are replayed multiple times</td>\n<td>duplicate detection, idempotency</td>\n</tr>\n<tr>\n<td><strong>idempotency key</strong></td>\n<td>Unique identifier included in webhook headers that allows endpoints to detect and safely ignore duplicate deliveries</td>\n<td>Enables safe retry and replay operations without side effects</td>\n<td>duplicate detection, safe retry</td>\n</tr>\n<tr>\n<td><strong>delivery correlation</strong></td>\n<td>Ability to trace related webhook deliveries and system events using correlation IDs and request tracking</td>\n<td>Debugging capability linking events across system components</td>\n<td>request tracing, event correlation</td>\n</tr>\n</tbody></table>\n<h3 id=\"storage-and-data-management\">Storage and Data Management</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>hierarchical storage management</strong></td>\n<td>Automated data lifecycle management that moves older audit logs through multiple storage tiers based on age and access patterns</td>\n<td>Cost optimization strategy for long-term audit log retention</td>\n<td>data lifecycle, tiered storage</td>\n</tr>\n<tr>\n<td><strong>hot storage</strong></td>\n<td>High-performance storage tier for recent delivery logs that require fast query response times</td>\n<td>Recent audit data requiring immediate access for debugging</td>\n<td>active storage, high-performance tier</td>\n</tr>\n<tr>\n<td><strong>warm storage</strong></td>\n<td>Medium-performance storage tier for older delivery logs that are occasionally accessed for compliance or investigation</td>\n<td>Intermediate storage for less frequently accessed audit data</td>\n<td>standard storage, intermediate tier</td>\n</tr>\n<tr>\n<td><strong>cold storage</strong></td>\n<td>Low-cost archive storage tier for old delivery logs that are rarely accessed but must be retained for compliance</td>\n<td>Long-term retention for compliance and legal requirements</td>\n<td>archive storage, compliance retention</td>\n</tr>\n<tr>\n<td><strong>storage explosion</strong></td>\n<td>Uncontrolled growth in audit log storage leading to excessive costs and performance degradation</td>\n<td>Operational problem requiring retention policies and data lifecycle management</td>\n<td>log growth, storage bloat</td>\n</tr>\n<tr>\n<td><strong>time-series optimization</strong></td>\n<td>Database schema and query optimization techniques designed for time-based audit log data</td>\n<td>Performance optimization for chronological delivery log queries</td>\n<td>temporal optimization, log performance</td>\n</tr>\n<tr>\n<td><strong>data retention policy</strong></td>\n<td>Rules governing how long different types of delivery data are kept before automatic deletion or archival</td>\n<td>Compliance and cost management framework for audit data</td>\n<td>retention rules, data lifecycle</td>\n</tr>\n</tbody></table>\n<h3 id=\"failure-recovery-and-resilience\">Failure Recovery and Resilience</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>graceful degradation</strong></td>\n<td>System behavior that maintains partial functionality when some components fail rather than complete system failure</td>\n<td>Resilience pattern allowing continued operation during partial failures</td>\n<td>partial failure handling, service degradation</td>\n</tr>\n<tr>\n<td><strong>failure isolation</strong></td>\n<td>Design principle that prevents failures in one component from cascading to other system components</td>\n<td>Architectural pattern limiting blast radius of component failures</td>\n<td>fault containment, failure boundaries</td>\n</tr>\n<tr>\n<td><strong>auto-recovery</strong></td>\n<td>Capability for system components to automatically detect and recover from certain types of failures without manual intervention</td>\n<td>Operational efficiency feature reducing manual intervention requirements</td>\n<td>self-healing, automatic recovery</td>\n</tr>\n<tr>\n<td><strong>manual intervention</strong></td>\n<td>Human operational action required to resolve system problems that cannot be automatically recovered</td>\n<td>Escalation path for problems exceeding automatic recovery capabilities</td>\n<td>manual recovery, operational escalation</td>\n</tr>\n<tr>\n<td><strong>failure cascade</strong></td>\n<td>Pattern where initial component failure triggers failures in dependent components, potentially causing system-wide outage</td>\n<td>Dangerous failure pattern prevented by circuit breakers and isolation</td>\n<td>cascading failure, failure propagation</td>\n</tr>\n<tr>\n<td><strong>recovery window</strong></td>\n<td>Time period during which a failed component is expected to recover normal operation</td>\n<td>Planning parameter for circuit breaker timeouts and alerting</td>\n<td>healing time, restoration period</td>\n</tr>\n</tbody></table>\n<h3 id=\"testing-and-validation\">Testing and Validation</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>milestone verification</strong></td>\n<td>Systematic validation that implementation meets acceptance criteria defined for each development milestone</td>\n<td>Quality assurance process ensuring project progress and functionality</td>\n<td>acceptance testing, milestone validation</td>\n</tr>\n<tr>\n<td><strong>integration testing</strong></td>\n<td>Testing approach that validates complete workflows across multiple system components</td>\n<td>End-to-end validation ensuring component interactions work correctly</td>\n<td>system testing, workflow validation</td>\n</tr>\n<tr>\n<td><strong>load testing</strong></td>\n<td>Performance validation using production-scale traffic to identify bottlenecks and capacity limits</td>\n<td>Performance assurance ensuring system handles expected traffic volumes</td>\n<td>stress testing, capacity validation</td>\n</tr>\n<tr>\n<td><strong>mock endpoint</strong></td>\n<td>Configurable test webhook endpoint that simulates various response behaviors for testing delivery logic</td>\n<td>Testing infrastructure enabling validation of delivery and error handling</td>\n<td>test endpoint, simulated receiver</td>\n</tr>\n<tr>\n<td><strong>test fixtures</strong></td>\n<td>Reusable test setup and teardown code that creates consistent testing environments</td>\n<td>Testing infrastructure ensuring reproducible test conditions</td>\n<td>test harness, testing framework</td>\n</tr>\n<tr>\n<td><strong>chaos engineering</strong></td>\n<td>Testing approach that deliberately introduces failures to validate system resilience and recovery capabilities</td>\n<td>Resilience validation through controlled failure injection</td>\n<td>failure testing, resilience engineering</td>\n</tr>\n</tbody></table>\n<h3 id=\"performance-and-scaling\">Performance and Scaling</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>horizontal scaling</strong></td>\n<td>Increasing system capacity by adding more processing instances rather than upgrading existing hardware</td>\n<td>Scaling strategy enabling linear capacity growth with demand</td>\n<td>scale-out, distributed scaling</td>\n</tr>\n<tr>\n<td><strong>vertical scaling</strong></td>\n<td>Increasing system capacity by upgrading hardware resources (CPU, memory, storage) on existing instances</td>\n<td>Alternative scaling approach with hardware-imposed limits</td>\n<td>scale-up, hardware scaling</td>\n</tr>\n<tr>\n<td><strong>sharding strategy</strong></td>\n<td>Method for partitioning webhook workload across multiple processing instances to enable horizontal scaling</td>\n<td>Distribution technique enabling parallel processing across instances</td>\n<td>data partitioning, workload distribution</td>\n</tr>\n<tr>\n<td><strong>consistent hashing</strong></td>\n<td>Algorithm that distributes webhook endpoints uniformly across processing instances with minimal redistribution during scaling events</td>\n<td>Load balancing technique minimizing disruption during scaling</td>\n<td>hash-based distribution, load balancing</td>\n</tr>\n<tr>\n<td><strong>delivery bottleneck</strong></td>\n<td>System component or resource that limits overall webhook delivery throughput</td>\n<td>Performance constraint requiring optimization or scaling</td>\n<td>throughput limit, capacity constraint</td>\n</tr>\n<tr>\n<td><strong>resource exhaustion</strong></td>\n<td>Condition where system components run out of critical resources like connections, memory, or file descriptors</td>\n<td>Operational problem requiring monitoring and resource management</td>\n<td>capacity limit, resource depletion</td>\n</tr>\n</tbody></table>\n<h3 id=\"advanced-features\">Advanced Features</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>conditional delivery</strong></td>\n<td>Advanced filtering capability that delivers webhook events only when specific content or recipient criteria are met</td>\n<td>Intelligent filtering reducing unnecessary webhook traffic</td>\n<td>smart filtering, content-based routing</td>\n</tr>\n<tr>\n<td><strong>payload transformation</strong></td>\n<td>Automatic modification of webhook event data to match the format expectations of different endpoint consumers</td>\n<td>Data adaptation enabling compatibility with diverse endpoint requirements</td>\n<td>data mapping, format conversion</td>\n</tr>\n<tr>\n<td><strong>multi-region deployment</strong></td>\n<td>Geographic distribution of webhook delivery infrastructure across multiple data centers for performance and reliability</td>\n<td>Scaling pattern improving latency and providing disaster recovery</td>\n<td>geographic distribution, global deployment</td>\n</tr>\n<tr>\n<td><strong>predictive analytics</strong></td>\n<td>Machine learning techniques applied to webhook delivery data to forecast failures, capacity needs, and performance trends</td>\n<td>Advanced monitoring enabling proactive system management</td>\n<td>ML monitoring, failure prediction</td>\n</tr>\n<tr>\n<td><strong>customer health scoring</strong></td>\n<td>Comprehensive metrics combining technical delivery performance with business impact assessment for customer success management</td>\n<td>Business intelligence combining technical and business metrics</td>\n<td>integration health, customer success metrics</td>\n</tr>\n</tbody></table>\n<h3 id=\"distributed-systems-concepts\">Distributed Systems Concepts</h3>\n<table>\n<thead>\n<tr>\n<th>Term</th>\n<th>Definition</th>\n<th>Context</th>\n<th>Related Terms</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>distributed circuit breaker</strong></td>\n<td>Circuit breaker implementation that coordinates state across multiple processing instances for consistent failure protection</td>\n<td>Advanced fault tolerance requiring cross-instance coordination</td>\n<td>global circuit breaker, distributed fault protection</td>\n</tr>\n<tr>\n<td><strong>global state management</strong></td>\n<td>Coordination of configuration and operational state across multiple distributed system instances</td>\n<td>Consistency requirement for distributed webhook processing</td>\n<td>distributed coordination, state synchronization</td>\n</tr>\n<tr>\n<td><strong>consensus protocol</strong></td>\n<td>Distributed algorithm enabling multiple system instances to agree on configuration changes and operational decisions</td>\n<td>Coordination mechanism for distributed system management</td>\n<td>distributed consensus, agreement protocol</td>\n</tr>\n<tr>\n<td><strong>network partition</strong></td>\n<td>Loss of network connectivity between system components, potentially causing operational inconsistencies</td>\n<td>Failure scenario requiring careful handling in distributed systems</td>\n<td>split-brain, network isolation</td>\n</tr>\n<tr>\n<td><strong>split-brain scenario</strong></td>\n<td>Condition where network partitions cause isolated system instances to operate independently with potentially conflicting state</td>\n<td>Dangerous distributed systems failure mode requiring prevention</td>\n<td>partition handling, consistency conflict</td>\n</tr>\n<tr>\n<td><strong>leader election</strong></td>\n<td>Protocol for selecting a single coordinator instance among multiple candidates in a distributed system</td>\n<td>Coordination pattern ensuring single point of control for global decisions</td>\n<td>coordinator selection, distributed leadership</td>\n</tr>\n</tbody></table>\n<h3 id=\"implementation-guidance\">Implementation Guidance</h3>\n<p>Building a webhook delivery system requires understanding terminology from multiple technical domains. The implementation should establish a consistent vocabulary across all code, documentation, and operational procedures.</p>\n<h4 id=\"technology-recommendations\">Technology Recommendations</h4>\n<table>\n<thead>\n<tr>\n<th>Component</th>\n<th>Simple Option</th>\n<th>Advanced Option</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Documentation</td>\n<td>Markdown with inline glossary</td>\n<td>Searchable documentation portal with cross-references</td>\n</tr>\n<tr>\n<td>Code Comments</td>\n<td>Inline definitions for domain terms</td>\n<td>Automated glossary generation from code annotations</td>\n</tr>\n<tr>\n<td>API Documentation</td>\n<td>OpenAPI with term definitions</td>\n<td>Interactive API docs with contextual glossary</td>\n</tr>\n<tr>\n<td>Monitoring Dashboards</td>\n<td>Basic metric labels</td>\n<td>Tooltip definitions for technical terms</td>\n</tr>\n</tbody></table>\n<h4 id=\"recommended-file-structure\">Recommended File Structure</h4>\n<div class=\"code-block-wrapper\"><pre class=\"arch-pre shiki-highlighted\"><code>project-root/\n  docs/\n    design-document.md        ← main design document\n    glossary.md              ← standalone glossary reference\n    api-reference.md         ← API documentation with term usage\n  src/webhook_delivery/\n    models/\n      __init__.py            ← domain model definitions\n      glossary.py            ← code-embedded term definitions\n    components/\n      registry.py            ← webhook registration with term usage\n      delivery.py            ← delivery engine with consistent terminology\n    utils/\n      documentation.py       ← documentation generation utilities\n  tests/\n    test_terminology.py      ← validate consistent term usage</code></pre></div>\n\n<h4 id=\"glossary-management-infrastructure\">Glossary Management Infrastructure</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Embedded glossary system for maintaining consistent terminology.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Provides runtime access to technical definitions and validates term usage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Dict, List, Optional</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> dataclasses </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> enum </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Enum</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#B392F0\">@dataclass</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> GlossaryEntry</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Single glossary term with definition and usage context.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    term: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    definition: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    context: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    related_terms: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    aliases: List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    category: </span><span style=\"color:#79B8FF\">str</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TermCategory</span><span style=\"color:#E1E4E8\">(</span><span style=\"color:#B392F0\">Enum</span><span style=\"color:#E1E4E8\">):</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Categories for organizing glossary terms.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    CORE_CONCEPTS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"core_concepts\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    RELIABILITY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"reliability\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    SECURITY</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"security\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    PERFORMANCE</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"performance\"</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">    OPERATIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#9ECBFF\"> \"operations\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> WebhookGlossary</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Central glossary system for webhook delivery terminology.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Provides programmatic access to definitions and validates term usage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._entries: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, GlossaryEntry] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._aliases: Dict[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">] </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> {}</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">._load_core_definitions()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> define_term</span><span style=\"color:#E1E4E8\">(self, entry: GlossaryEntry) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Add a term definition to the glossary.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Validates for conflicts and maintains alias mappings.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate term doesn't conflict with existing definitions</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add term to main entries dictionary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Register all aliases pointing to canonical term</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate related terms exist in glossary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log term registration for auditing</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> get_definition</span><span style=\"color:#E1E4E8\">(self, term: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> Optional[GlossaryEntry]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Retrieve definition for a term or its alias.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns None if term is not found in glossary.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if term exists directly in entries</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check if term is an alias and resolve to canonical form</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return GlossaryEntry if found, None otherwise</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Log definition access for usage analytics</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_term_usage</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Analyze text for inconsistent terminology usage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns list of potential terminology issues found.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Scan text for technical terms and aliases</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for mixed usage of terms and aliases</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Identify undefined terms that should be in glossary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Flag deprecated terms or inconsistent naming</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of issues with suggestions for fixes</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> generate_documentation</span><span style=\"color:#E1E4E8\">(self, category: Optional[TermCategory] </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> None</span><span style=\"color:#E1E4E8\">) -> </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Generate formatted glossary documentation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Optionally filter by term category.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Filter entries by category if specified</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Sort terms alphabetically within categories</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Format as markdown table with columns for term, definition, context</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Include cross-references to related terms</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Add category headers and organization</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Global glossary instance for consistent term access</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">webhook_glossary </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> WebhookGlossary()</span></span></code></pre></div>\n\n<h4 id=\"core-term-definitions\">Core Term Definitions</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Core webhook delivery system terminology definitions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Loaded into the glossary system for consistent usage validation.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">CORE_DEFINITIONS</span><span style=\"color:#F97583\"> =</span><span style=\"color:#E1E4E8\"> [</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    GlossaryEntry(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        term</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"webhook delivery\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        definition</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Asynchronous HTTP notification system that sends event data to registered HTTP endpoints when specific events occur in the source system\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        context</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Primary system function - the core service being built\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        related_terms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"endpoint\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"event\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"payload\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        aliases</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"webhook notification\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"event delivery\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        category</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">TermCategory.</span><span style=\"color:#79B8FF\">CORE_CONCEPTS</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    GlossaryEntry(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        term</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"circuit breaker\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        definition</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Failure protection pattern that disables failing endpoints after consecutive failures, preventing wasted resources on known-bad destinations\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        context</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Protection mechanism preventing resource waste on failing endpoints\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        related_terms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"fault isolation\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"failure protection\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"exponential backoff\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        aliases</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"fault breaker\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"endpoint protection\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        category</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">TermCategory.</span><span style=\"color:#79B8FF\">RELIABILITY</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ),</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    GlossaryEntry(</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        term</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"HMAC signature\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        definition</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Hash-based Message Authentication Code computed using SHA-256 over the webhook payload with a shared secret key\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        context</span><span style=\"color:#F97583\">=</span><span style=\"color:#9ECBFF\">\"Primary authentication mechanism preventing webhook spoofing\"</span><span style=\"color:#E1E4E8\">,</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        related_terms</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"webhook secret\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"payload authentication\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"canonical signing string\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        aliases</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">[</span><span style=\"color:#9ECBFF\">\"webhook signature\"</span><span style=\"color:#E1E4E8\">, </span><span style=\"color:#9ECBFF\">\"cryptographic signature\"</span><span style=\"color:#E1E4E8\">],</span></span>\n<span class=\"line\"><span style=\"color:#FFAB70\">        category</span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\">TermCategory.</span><span style=\"color:#79B8FF\">SECURITY</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    ),</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">    # Additional core definitions would be included here</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">]</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">def</span><span style=\"color:#B392F0\"> load_core_definitions</span><span style=\"color:#E1E4E8\">(glossary: WebhookGlossary) -> </span><span style=\"color:#79B8FF\">None</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"Load core webhook delivery terminology into glossary system.\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    for</span><span style=\"color:#E1E4E8\"> definition </span><span style=\"color:#F97583\">in</span><span style=\"color:#79B8FF\"> CORE_DEFINITIONS</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">        glossary.define_term(definition)</span></span></code></pre></div>\n\n<h4 id=\"terminology-validation-tools\">Terminology Validation Tools</h4>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">python</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Tools for validating consistent terminology usage across codebase.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">Integrates with development workflow to catch terminology issues early.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">\"\"\"</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> ast</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> re</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">from</span><span style=\"color:#E1E4E8\"> typing </span><span style=\"color:#F97583\">import</span><span style=\"color:#E1E4E8\"> Set, List, Tuple</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#F97583\">class</span><span style=\"color:#B392F0\"> TerminologyValidator</span><span style=\"color:#E1E4E8\">:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Static analysis tool for validating terminology consistency.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    Scans code and documentation for terminology usage issues.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#79B8FF\"> __init__</span><span style=\"color:#E1E4E8\">(self, glossary: WebhookGlossary):</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.glossary </span><span style=\"color:#F97583\">=</span><span style=\"color:#E1E4E8\"> glossary</span></span>\n<span class=\"line\"><span style=\"color:#79B8FF\">        self</span><span style=\"color:#E1E4E8\">.known_terms </span><span style=\"color:#F97583\">=</span><span style=\"color:#79B8FF\"> self</span><span style=\"color:#E1E4E8\">._extract_known_terms()</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_code_file</span><span style=\"color:#E1E4E8\">(self, filepath: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Scan Python file for terminology usage issues.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Returns list of issues found with line numbers and suggestions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Parse Python AST to extract strings and comments</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check class names, method names, and variable names against glossary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate docstring terminology usage</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Flag inconsistent term usage within same file</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return detailed issues with line numbers and fix suggestions</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> validate_documentation</span><span style=\"color:#E1E4E8\">(self, filepath: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Scan markdown documentation for terminology consistency.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Checks for proper term usage and missing definitions.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract technical terms from markdown content</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Check for undefined terms that should be in glossary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Validate consistent usage of terms vs aliases</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Flag potential terminology improvements</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of documentation issues with recommendations</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span>\n<span class=\"line\"><span style=\"color:#E1E4E8\">    </span></span>\n<span class=\"line\"><span style=\"color:#F97583\">    def</span><span style=\"color:#B392F0\"> suggest_missing_definitions</span><span style=\"color:#E1E4E8\">(self, text: </span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">) -> List[</span><span style=\"color:#79B8FF\">str</span><span style=\"color:#E1E4E8\">]:</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Analyze text to identify technical terms missing from glossary.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        Helps maintain comprehensive terminology coverage.</span></span>\n<span class=\"line\"><span style=\"color:#9ECBFF\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Extract potential technical terms using pattern matching</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Filter out terms already defined in glossary</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Rank suggestions by frequency and technical likelihood</span></span>\n<span class=\"line\"><span style=\"color:#6A737D\">        # </span><span style=\"color:#F97583\">TODO</span><span style=\"color:#6A737D\">: Return list of suggested terms for glossary addition</span></span>\n<span class=\"line\"><span style=\"color:#F97583\">        pass</span></span></code></pre></div>\n\n<h4 id=\"milestone-checkpoint-terminology-consistency\">Milestone Checkpoint: Terminology Consistency</h4>\n<p>After implementing the glossary system, validate terminology consistency across the project:</p>\n<p><strong>Expected Behavior:</strong></p>\n<ul>\n<li>All technical terms used consistently across code and documentation</li>\n<li>Glossary provides programmatic access to term definitions</li>\n<li>Validation tools catch terminology inconsistencies in development workflow</li>\n<li>Documentation generation produces comprehensive reference material</li>\n</ul>\n<p><strong>Validation Commands:</strong></p>\n<div class=\"code-block-wrapper\"><span class=\"code-lang\">bash</span><pre class=\"arch-pre shiki-highlighted\"><code><span class=\"line\"><span style=\"color:#6A737D\"># Run terminology validation across codebase</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> tests.test_terminology</span><span style=\"color:#79B8FF\"> --validate-all</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Generate glossary documentation</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> src.webhook_delivery.utils.documentation</span><span style=\"color:#79B8FF\"> --generate-glossary</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#6A737D\"># Check specific file for terminology issues</span></span>\n<span class=\"line\"><span style=\"color:#B392F0\">python</span><span style=\"color:#79B8FF\"> -m</span><span style=\"color:#9ECBFF\"> src.webhook_delivery.utils.terminology</span><span style=\"color:#79B8FF\"> --validate</span><span style=\"color:#9ECBFF\"> docs/design-document.md</span></span></code></pre></div>\n\n<p><strong>Success Indicators:</strong></p>\n<ul>\n<li>Zero terminology validation failures in CI pipeline</li>\n<li>Consistent technical vocabulary across all documentation</li>\n<li>Developer IDE integration provides term definitions on hover</li>\n<li>Glossary covers all technical concepts used in implementation</li>\n</ul>\n<p><strong>Common Issues:</strong></p>\n<ul>\n<li><p><strong>Inconsistent Term Usage</strong>: Different parts of codebase using different names for same concept</p>\n<ul>\n<li><em>Symptom</em>: Validation tools report mixed usage of &quot;webhook delivery&quot; vs &quot;event notification&quot;</li>\n<li><em>Cause</em>: Multiple developers using different terminology preferences</li>\n<li><em>Fix</em>: Establish canonical terms in glossary and update all usage to match</li>\n</ul>\n</li>\n<li><p><strong>Missing Definitions</strong>: Technical terms used without glossary entries</p>\n<ul>\n<li><em>Symptom</em>: Documentation references undefined terms</li>\n<li><em>Cause</em>: New concepts introduced without updating glossary</li>\n<li><em>Fix</em>: Add comprehensive definitions for all technical concepts</li>\n</ul>\n</li>\n<li><p><strong>Overloaded Terms</strong>: Same word used with different meanings in different contexts</p>\n<ul>\n<li><em>Symptom</em>: Confusion about what &quot;retry&quot; means in different components</li>\n<li><em>Cause</em>: Generic terms lacking specific context definitions</li>\n<li><em>Fix</em>: Create context-specific definitions (e.g., &quot;retry attempt&quot;, &quot;retry policy&quot;, &quot;retry delay&quot;)</li>\n</ul>\n</li>\n</ul>\n","toc":[{"level":1,"text":"Webhook Delivery System: Design Document","id":"webhook-delivery-system-design-document"},{"level":2,"text":"Overview","id":"overview"},{"level":2,"text":"Context and Problem Statement","id":"context-and-problem-statement"},{"level":3,"text":"Mental Model: The Digital Postal Service","id":"mental-model-the-digital-postal-service"},{"level":3,"text":"Reliability Challenges","id":"reliability-challenges"},{"level":4,"text":"Network and Transport Failures","id":"network-and-transport-failures"},{"level":4,"text":"Endpoint Reliability and Downtime","id":"endpoint-reliability-and-downtime"},{"level":4,"text":"Security and Trust Boundaries","id":"security-and-trust-boundaries"},{"level":4,"text":"Ordering and Consistency Guarantees","id":"ordering-and-consistency-guarantees"},{"level":4,"text":"Scale and Performance Constraints","id":"scale-and-performance-constraints"},{"level":3,"text":"Existing Approaches Comparison","id":"existing-approaches-comparison"},{"level":4,"text":"Direct HTTP Delivery Approach","id":"direct-http-delivery-approach"},{"level":4,"text":"Queue-Based Delivery with Retry Logic","id":"queue-based-delivery-with-retry-logic"},{"level":4,"text":"Event Streaming with Consumer Groups","id":"event-streaming-with-consumer-groups"},{"level":3,"text":"Common Anti-Patterns and Design Pitfalls","id":"common-anti-patterns-and-design-pitfalls"},{"level":4,"text":"⚠️ Pitfall: Synchronous Delivery from Critical Path","id":"-pitfall-synchronous-delivery-from-critical-path"},{"level":4,"text":"⚠️ Pitfall: Inadequate Failure Classification","id":"-pitfall-inadequate-failure-classification"},{"level":4,"text":"⚠️ Pitfall: Missing Signature Verification","id":"-pitfall-missing-signature-verification"},{"level":4,"text":"⚠️ Pitfall: Unbounded Retry Queues","id":"-pitfall-unbounded-retry-queues"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Project Structure","id":"recommended-project-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton","id":"core-logic-skeleton"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Common Implementation Issues","id":"common-implementation-issues"},{"level":2,"text":"Goals and Non-Goals","id":"goals-and-non-goals"},{"level":3,"text":"Functional Goals","id":"functional-goals"},{"level":3,"text":"Non-Functional Goals","id":"non-functional-goals"},{"level":3,"text":"Explicit Non-Goals","id":"explicit-non-goals"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"High-Level Architecture","id":"high-level-architecture"},{"level":3,"text":"Component Responsibilities","id":"component-responsibilities"},{"level":3,"text":"Data Flow Overview","id":"data-flow-overview"},{"level":3,"text":"Deployment Architecture","id":"deployment-architecture"},{"level":3,"text":"Common Architecture Pitfalls","id":"common-architecture-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Component Skeletons","id":"core-component-skeletons"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Data Model","id":"data-model"},{"level":3,"text":"Mental Model: The Digital Postal Service Database","id":"mental-model-the-digital-postal-service-database"},{"level":3,"text":"Webhook Registration Model","id":"webhook-registration-model"},{"level":3,"text":"Event Model","id":"event-model"},{"level":3,"text":"Delivery Tracking Model","id":"delivery-tracking-model"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Webhook Registry Component","id":"webhook-registry-component"},{"level":3,"text":"Mental Model: The Secure Post Office Registration System","id":"mental-model-the-secure-post-office-registration-system"},{"level":3,"text":"Registration and Ownership Verification","id":"registration-and-ownership-verification"},{"level":4,"text":"Registration Protocol Design","id":"registration-protocol-design"},{"level":4,"text":"URL Validation and SSRF Protection","id":"url-validation-and-ssrf-protection"},{"level":4,"text":"Challenge-Response Implementation","id":"challenge-response-implementation"},{"level":3,"text":"HMAC Signature Generation","id":"hmac-signature-generation"},{"level":4,"text":"Cryptographic Design Foundation","id":"cryptographic-design-foundation"},{"level":4,"text":"Signature Calculation Process","id":"signature-calculation-process"},{"level":4,"text":"Timestamp-Based Replay Protection","id":"timestamp-based-replay-protection"},{"level":3,"text":"Secret Rotation Strategy","id":"secret-rotation-strategy"},{"level":4,"text":"Overlapping Validity Periods","id":"overlapping-validity-periods"},{"level":4,"text":"Secret Generation and Storage","id":"secret-generation-and-storage"},{"level":4,"text":"Emergency Rotation Procedures","id":"emergency-rotation-procedures"},{"level":3,"text":"Common Registry Pitfalls","id":"common-registry-pitfalls"},{"level":4,"text":"SSRF Attack Vectors","id":"ssrf-attack-vectors"},{"level":4,"text":"Weak Secret Generation","id":"weak-secret-generation"},{"level":4,"text":"Signature Verification Bypasses","id":"signature-verification-bypasses"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton","id":"core-logic-skeleton"},{"level":4,"text":"Language-Specific Hints","id":"language-specific-hints"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Delivery Engine Component","id":"delivery-engine-component"},{"level":3,"text":"Mental Model: The Smart Package Delivery Service","id":"mental-model-the-smart-package-delivery-service"},{"level":3,"text":"Queue Management and Ordering","id":"queue-management-and-ordering"},{"level":3,"text":"Exponential Backoff Retry Logic","id":"exponential-backoff-retry-logic"},{"level":3,"text":"Dead Letter Queue Handling","id":"dead-letter-queue-handling"},{"level":3,"text":"Common Delivery Pitfalls","id":"common-delivery-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Delivery Logic Skeleton","id":"core-delivery-logic-skeleton"},{"level":4,"text":"Language-Specific Implementation Hints","id":"language-specific-implementation-hints"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Circuit Breaker and Rate Limiting","id":"circuit-breaker-and-rate-limiting"},{"level":3,"text":"Mental Model: The Overworked Postal Worker","id":"mental-model-the-overworked-postal-worker"},{"level":3,"text":"Circuit Breaker State Machine","id":"circuit-breaker-state-machine"},{"level":4,"text":"Circuit Breaker States and Transitions","id":"circuit-breaker-states-and-transitions"},{"level":4,"text":"Circuit Breaker Implementation Strategy","id":"circuit-breaker-implementation-strategy"},{"level":4,"text":"Adaptive Recovery Timing","id":"adaptive-recovery-timing"},{"level":3,"text":"Rate Limiting Strategy","id":"rate-limiting-strategy"},{"level":4,"text":"Token Bucket Implementation","id":"token-bucket-implementation"},{"level":4,"text":"Retry-After Header Handling","id":"retry-after-header-handling"},{"level":4,"text":"Dynamic Rate Limit Adjustment","id":"dynamic-rate-limit-adjustment"},{"level":3,"text":"Endpoint Health Monitoring","id":"endpoint-health-monitoring"},{"level":4,"text":"Health Metrics Collection","id":"health-metrics-collection"},{"level":4,"text":"Health Score Calculation","id":"health-score-calculation"},{"level":4,"text":"Alerting and Notification","id":"alerting-and-notification"},{"level":3,"text":"Common Protection Pitfalls","id":"common-protection-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"File Structure","id":"file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton Code","id":"core-logic-skeleton-code"},{"level":4,"text":"Milestone Checkpoint","id":"milestone-checkpoint"},{"level":2,"text":"Event Logging and Replay","id":"event-logging-and-replay"},{"level":3,"text":"Mental Model: The Digital Postal Service Archive","id":"mental-model-the-digital-postal-service-archive"},{"level":3,"text":"Delivery Audit Trail: Complete Event Sourcing for Debugging and Compliance","id":"delivery-audit-trail-complete-event-sourcing-for-debugging-and-compliance"},{"level":3,"text":"Event Replay Mechanism: Safe Re-delivery with Deduplication and Rate Limit Respect","id":"event-replay-mechanism-safe-re-delivery-with-deduplication-and-rate-limit-respect"},{"level":3,"text":"Log Retention and Archival: Time-Series Optimization with Cold Storage Migration","id":"log-retention-and-archival-time-series-optimization-with-cold-storage-migration"},{"level":3,"text":"Common Logging Pitfalls","id":"common-logging-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Component Interactions and Data Flow","id":"component-interactions-and-data-flow"},{"level":3,"text":"Mental Model: The Orchestrated Assembly Line","id":"mental-model-the-orchestrated-assembly-line"},{"level":3,"text":"Event Ingestion Flow: Webhook lookup, signature generation, and queue placement","id":"event-ingestion-flow-webhook-lookup-signature-generation-and-queue-placement"},{"level":4,"text":"Event Reception and Validation","id":"event-reception-and-validation"},{"level":4,"text":"Webhook Event Creation","id":"webhook-event-creation"},{"level":4,"text":"HMAC Signature Generation","id":"hmac-signature-generation"},{"level":4,"text":"Queue Placement and Routing","id":"queue-placement-and-routing"},{"level":4,"text":"Error Handling and Rollback","id":"error-handling-and-rollback"},{"level":3,"text":"Delivery Processing Flow: Queue consumption, HTTP delivery, and response handling","id":"delivery-processing-flow-queue-consumption-http-delivery-and-response-handling"},{"level":4,"text":"Queue Consumption and Event Claiming","id":"queue-consumption-and-event-claiming"},{"level":4,"text":"Circuit Breaker and Rate Limit Checks","id":"circuit-breaker-and-rate-limit-checks"},{"level":4,"text":"HTTP Request Construction and Delivery","id":"http-request-construction-and-delivery"},{"level":4,"text":"Response Handling and Status Classification","id":"response-handling-and-status-classification"},{"level":4,"text":"Delivery Attempt Recording","id":"delivery-attempt-recording"},{"level":3,"text":"Failure Recovery Flow: Retry scheduling, circuit breaker activation, and alerting","id":"failure-recovery-flow-retry-scheduling-circuit-breaker-activation-and-alerting"},{"level":4,"text":"Retry Scheduling and Exponential Backoff","id":"retry-scheduling-and-exponential-backoff"},{"level":4,"text":"Circuit Breaker State Management","id":"circuit-breaker-state-management"},{"level":4,"text":"Dead Letter Queue Management","id":"dead-letter-queue-management"},{"level":4,"text":"Alerting and Escalation","id":"alerting-and-escalation"},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"File Structure","id":"file-structure"},{"level":4,"text":"Infrastructure Starter Code","id":"infrastructure-starter-code"},{"level":4,"text":"Core Logic Skeleton","id":"core-logic-skeleton"},{"level":4,"text":"Milestone Checkpoints","id":"milestone-checkpoints"},{"level":4,"text":"Debugging Tips","id":"debugging-tips"},{"level":2,"text":"Error Handling and Edge Cases","id":"error-handling-and-edge-cases"},{"level":3,"text":"Mental Model: The Resilient Communication Network","id":"mental-model-the-resilient-communication-network"},{"level":3,"text":"Network and Timeout Handling","id":"network-and-timeout-handling"},{"level":3,"text":"Endpoint Error Classification","id":"endpoint-error-classification"},{"level":3,"text":"System-Level Failure Recovery","id":"system-level-failure-recovery"},{"level":3,"text":"","id":""},{"level":3,"text":"","id":""},{"level":3,"text":"Common Pitfalls","id":"common-pitfalls"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Testing Strategy and Milestone Checkpoints","id":"testing-strategy-and-milestone-checkpoints"},{"level":3,"text":"Mental Model: The Quality Assurance Inspection System","id":"mental-model-the-quality-assurance-inspection-system"},{"level":3,"text":"Milestone Verification Checkpoints","id":"milestone-verification-checkpoints"},{"level":4,"text":"Milestone 1: Webhook Registration &amp; Security Testing","id":"milestone-1-webhook-registration-amp-security-testing"},{"level":4,"text":"Milestone 2: Delivery Queue &amp; Retry Logic Testing","id":"milestone-2-delivery-queue-amp-retry-logic-testing"},{"level":4,"text":"Milestone 3: Circuit Breaker &amp; Rate Limiting Testing","id":"milestone-3-circuit-breaker-amp-rate-limiting-testing"},{"level":4,"text":"Milestone 4: Event Logging &amp; Replay Testing","id":"milestone-4-event-logging-amp-replay-testing"},{"level":3,"text":"Integration Testing Strategy","id":"integration-testing-strategy"},{"level":4,"text":"End-to-End Scenario Testing","id":"end-to-end-scenario-testing"},{"level":4,"text":"Component Integration Validation","id":"component-integration-validation"},{"level":4,"text":"Multi-Component Failure Testing","id":"multi-component-failure-testing"},{"level":3,"text":"Load and Reliability Testing","id":"load-and-reliability-testing"},{"level":4,"text":"Stress Testing Delivery Queues","id":"stress-testing-delivery-queues"},{"level":4,"text":"Circuit Breaker Load Testing","id":"circuit-breaker-load-testing"},{"level":4,"text":"Rate Limiting Performance","id":"rate-limiting-performance"},{"level":4,"text":"Reliability Under Failure Conditions","id":"reliability-under-failure-conditions"},{"level":4,"text":"Load Testing Results Analysis","id":"load-testing-results-analysis"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Mock Infrastructure Implementation","id":"mock-infrastructure-implementation"},{"level":4,"text":"Core Test Implementation Skeletons","id":"core-test-implementation-skeletons"},{"level":4,"text":"Load Testing Infrastructure","id":"load-testing-infrastructure"},{"level":4,"text":"Milestone Checkpoint Validation","id":"milestone-checkpoint-validation"},{"level":2,"text":"Debugging Guide","id":"debugging-guide"},{"level":3,"text":"Mental Model: The Detective&#39;s Toolkit","id":"mental-model-the-detective39s-toolkit"},{"level":3,"text":"Delivery Failure Debugging: Diagnosing Stuck Queues, Failed Deliveries, and Retry Loops","id":"delivery-failure-debugging-diagnosing-stuck-queues-failed-deliveries-and-retry-loops"},{"level":3,"text":"Security and Signature Debugging: HMAC Verification Failures and Timestamp Validation Issues","id":"security-and-signature-debugging-hmac-verification-failures-and-timestamp-validation-issues"},{"level":3,"text":"Performance and Scaling Issues: Queue Backlog, Rate Limiting Bottlenecks, and Resource Exhaustion","id":"performance-and-scaling-issues-queue-backlog-rate-limiting-bottlenecks-and-resource-exhaustion"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":2,"text":"Future Extensions and Scalability","id":"future-extensions-and-scalability"},{"level":3,"text":"Advanced Delivery Features","id":"advanced-delivery-features"},{"level":4,"text":"Conditional Delivery Logic","id":"conditional-delivery-logic"},{"level":4,"text":"Payload Transformation Pipeline","id":"payload-transformation-pipeline"},{"level":4,"text":"Multi-Region Deployment Architecture","id":"multi-region-deployment-architecture"},{"level":3,"text":"Enhanced Monitoring and Analytics","id":"enhanced-monitoring-and-analytics"},{"level":4,"text":"Comprehensive Metrics Dashboard","id":"comprehensive-metrics-dashboard"},{"level":4,"text":"SLA Tracking and Customer Health Scoring","id":"sla-tracking-and-customer-health-scoring"},{"level":4,"text":"Predictive Analytics and Alerting","id":"predictive-analytics-and-alerting"},{"level":3,"text":"Horizontal Scaling Considerations","id":"horizontal-scaling-considerations"},{"level":4,"text":"Sharding Strategies for Event Distribution","id":"sharding-strategies-for-event-distribution"},{"level":4,"text":"Distributed Circuit Breaker Coordination","id":"distributed-circuit-breaker-coordination"},{"level":4,"text":"Global State Management and Consensus","id":"global-state-management-and-consensus"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended Architecture Evolution","id":"recommended-architecture-evolution"},{"level":4,"text":"Advanced Filtering Engine","id":"advanced-filtering-engine"},{"level":4,"text":"Predictive Analytics Infrastructure","id":"predictive-analytics-infrastructure"},{"level":4,"text":"Distributed Scaling Infrastructure","id":"distributed-scaling-infrastructure"},{"level":4,"text":"Milestone Checkpoints for Advanced Features","id":"milestone-checkpoints-for-advanced-features"},{"level":2,"text":"Glossary","id":"glossary"},{"level":3,"text":"Mental Model: The Technical Dictionary","id":"mental-model-the-technical-dictionary"},{"level":3,"text":"Core Webhook Concepts","id":"core-webhook-concepts"},{"level":3,"text":"Reliability and Fault Tolerance","id":"reliability-and-fault-tolerance"},{"level":3,"text":"Circuit Breaker States","id":"circuit-breaker-states"},{"level":3,"text":"Security and Authentication","id":"security-and-authentication"},{"level":3,"text":"Queue Management and Processing","id":"queue-management-and-processing"},{"level":3,"text":"Rate Limiting and Flow Control","id":"rate-limiting-and-flow-control"},{"level":3,"text":"Monitoring and Health","id":"monitoring-and-health"},{"level":3,"text":"Event Sourcing and Audit","id":"event-sourcing-and-audit"},{"level":3,"text":"Storage and Data Management","id":"storage-and-data-management"},{"level":3,"text":"Failure Recovery and Resilience","id":"failure-recovery-and-resilience"},{"level":3,"text":"Testing and Validation","id":"testing-and-validation"},{"level":3,"text":"Performance and Scaling","id":"performance-and-scaling"},{"level":3,"text":"Advanced Features","id":"advanced-features"},{"level":3,"text":"Distributed Systems Concepts","id":"distributed-systems-concepts"},{"level":3,"text":"Implementation Guidance","id":"implementation-guidance"},{"level":4,"text":"Technology Recommendations","id":"technology-recommendations"},{"level":4,"text":"Recommended File Structure","id":"recommended-file-structure"},{"level":4,"text":"Glossary Management Infrastructure","id":"glossary-management-infrastructure"},{"level":4,"text":"Core Term Definitions","id":"core-term-definitions"},{"level":4,"text":"Terminology Validation Tools","id":"terminology-validation-tools"},{"level":4,"text":"Milestone Checkpoint: Terminology Consistency","id":"milestone-checkpoint-terminology-consistency"}],"title":"Webhook Delivery System: Design Document","markdown":"# Webhook Delivery System: Design Document\n\n\n## Overview\n\nA reliable webhook delivery system that provides guaranteed event delivery to HTTP endpoints with security, fault tolerance, and observability. The key architectural challenge is building resilience against network failures, endpoint downtime, and security threats while maintaining ordered delivery and preventing data loss.\n\n![System Overview](./diagrams/system-overview.svg)\n\n\n> This guide is meant to help you understand the big picture before diving into each milestone. Refer back to it whenever you need context on how components connect.\n\n\n## Context and Problem Statement\n\n> **Milestone(s):** Foundation for all milestones - establishes core webhook delivery challenges addressed throughout the project\n\n### Mental Model: The Digital Postal Service\n\nThink of webhooks as a **digital postal service** for the internet. When something important happens in your application—a payment is processed, an order is placed, or a user signs up—you need to notify other systems about this event. Just like how you might send a letter through the postal service, webhooks deliver event notifications to registered \"addresses\" (HTTP endpoints) across the web.\n\nIn this analogy, our webhook delivery system acts as the **postal infrastructure**. When an event occurs (someone wants to send a letter), we need to:\n\n1. **Verify the destination address** - Ensure the recipient endpoint actually exists and wants to receive mail from us, similar to how postal services validate addresses and require recipients to register for certain types of mail delivery.\n\n2. **Package and sign the message** - Wrap the event data in a secure envelope with tamper-proof sealing (cryptographic signatures), just like how important documents are sent with authentication seals and tracking numbers.\n\n3. **Handle delivery failures gracefully** - If the recipient isn't home (endpoint is down), we don't just throw the mail away. We try again later, maybe multiple times, with increasing delays between attempts. Eventually, if delivery consistently fails, we might mark the address as undeliverable and alert the sender.\n\n4. **Maintain delivery order** - Critical mail to the same recipient should arrive in the order it was sent. If you mail a check and then a deposit slip to your bank, the bank needs to process them in the correct sequence.\n\n5. **Protect against fraud** - We need to prevent malicious actors from sending fake mail claiming to be from legitimate senders, and we must avoid delivering mail to dangerous addresses that might be traps.\n\n6. **Provide tracking and receipts** - Just like package tracking, we need to log every delivery attempt, record when messages were successfully delivered, and provide detailed status information for debugging failed deliveries.\n\nThe key insight is that **reliability trumps speed** in webhook delivery. It's better to deliver an event notification 30 seconds late than to lose it entirely. Unlike real-time API calls where users are waiting for immediate responses, webhooks are asynchronous notifications where consistency and guarantees matter more than low latency.\n\nHowever, this postal service operates at internet scale with additional complexities that physical mail doesn't face: endpoints can go down and recover within seconds, network connections can fail mid-delivery, and malicious actors can easily create fake addresses or overwhelm recipients with spam. Our system must be resilient against all these failure modes while maintaining the delivery guarantees that make webhooks reliable for business-critical integrations.\n\n### Reliability Challenges\n\nThe fundamental challenge in webhook delivery lies in bridging the gap between **at-least-once delivery guarantees** and the unreliable nature of HTTP network communication. Unlike database transactions or message queues that operate within controlled environments, webhooks must traverse the public internet to reach endpoints controlled by external parties who may implement unreliable services, experience downtime, or even disappear entirely.\n\n#### Network and Transport Failures\n\nNetwork communication introduces multiple failure vectors that don't exist in local system operations. **DNS resolution can fail** when endpoint domains become temporarily unreachable or permanently invalid. **TCP connection establishment can time out** due to network congestion, firewall rules, or endpoint server overload. **HTTP requests can hang indefinitely** if recipient services accept connections but fail to process requests, creating resource leaks in our delivery workers.\n\nThe challenge deepens when we consider **partial failures during transmission**. A webhook payload might be successfully sent, but the response indicating successful processing might be lost due to network interruption. This creates an uncertainty window where we don't know if the recipient processed the event. Naive retry logic could lead to duplicate processing, while conservative approaches might lose events entirely.\n\n**Connection pooling and keep-alive** present additional complexity. While reusing connections improves performance, long-lived connections can become stale or encounter proxy timeouts. Our delivery system must detect and recover from these scenarios without losing in-flight events.\n\n#### Endpoint Reliability and Downtime\n\nExternal webhook endpoints exhibit far more diverse failure patterns than internal services. **Recipient services may experience deployment downtime** lasting minutes to hours, during which all delivery attempts will fail. **Capacity limits** at recipient endpoints can cause intermittent failures when our delivery rate exceeds their processing capability. **Code bugs in recipient handlers** might cause consistent failures for specific event types while allowing others to succeed.\n\nMore challenging are **partial failure scenarios** where endpoints return successful HTTP status codes but fail to process events correctly due to internal errors. Our system cannot detect these failures without additional feedback mechanisms, yet we must provide debugging tools to help webhook consumers identify and resolve processing issues.\n\n**Endpoint migration and URL changes** create another reliability challenge. Long-running webhook subscriptions may outlive the original endpoint URLs. Our system needs graceful handling of permanent redirects while protecting against malicious redirect attacks.\n\n#### Security and Trust Boundaries\n\nWebhook delivery crosses organizational trust boundaries, creating unique security challenges not present in internal system communication. **Payload integrity** must be maintained across the public internet, requiring cryptographic signatures that recipients can verify. **Authentication** mechanisms must prevent spoofed webhook deliveries while remaining simple enough for diverse recipient implementations.\n\n**Server-Side Request Forgery (SSRF) attacks** pose a critical threat where malicious actors register internal IP addresses as webhook endpoints, potentially allowing them to probe or attack internal infrastructure through our delivery system. **Timing attacks** against signature verification could leak signing keys. **Replay attacks** might allow malicious actors to resend captured webhook payloads at inappropriate times.\n\nThe security model must also handle **secret rotation** seamlessly. Signing keys need periodic updates for security hygiene, but rotation cannot break in-flight deliveries or require precise coordination between our system and all webhook consumers.\n\n#### Ordering and Consistency Guarantees\n\nMany webhook use cases require **strict ordering guarantees per endpoint**. Financial systems processing payment notifications, inventory systems tracking stock changes, and audit systems recording user actions all depend on receiving events in the order they occurred. However, implementing ordering at scale creates significant architectural constraints.\n\n**Parallel processing** conflicts with ordering requirements. While we could process all webhooks sequentially, this approach cannot scale to handle high event volumes. The solution requires **per-endpoint ordering** while allowing parallelization across different endpoints.\n\n**Failure recovery complicates ordering** significantly. If event N fails delivery but event N+1 succeeds, we must decide whether to block future events until N succeeds (risking head-of-line blocking) or allow out-of-order delivery with eventual consistency. Different use cases require different trade-offs, making this a configurable system behavior rather than a fixed architectural decision.\n\n**Replay scenarios** after system failures must maintain ordering consistency. If our delivery system crashes and restarts, queued events must resume processing in their original order, even if some events were partially processed before the failure.\n\n#### Scale and Performance Constraints\n\nHigh-volume webhook delivery systems must handle **thousands of events per second** while maintaining per-endpoint delivery guarantees. This scale requirement conflicts with many reliability patterns that work well for smaller systems.\n\n**Exponential backoff retry logic** can create exponentially growing queues during widespread endpoint downtime. If 100 endpoints go offline for an hour, and events are generated every second, the retry queue could grow to hundreds of thousands of entries. Our system must bound retry queue growth while preserving ordering and delivery guarantees.\n\n**Circuit breaker patterns** help protect failing endpoints but introduce state management complexity. Per-endpoint circuit breaker state must persist across system restarts and be shared across multiple delivery worker processes. **Rate limiting** adds another layer of per-endpoint state that must be coordinated system-wide.\n\n**Database contention** becomes a bottleneck when thousands of delivery workers update event status concurrently. Traditional RDBMS row locking doesn't scale to this level of concurrent updates on shared tables.\n\n### Existing Approaches Comparison\n\nUnderstanding the landscape of webhook delivery approaches helps illuminate why a queue-based system with circuit breakers represents the optimal balance for most use cases. Each approach makes different trade-offs between simplicity, reliability, performance, and operational complexity.\n\n> **Decision: Queue-Based Delivery Architecture**\n> - **Context**: Webhook delivery systems must balance reliability, performance, and operational complexity while handling diverse failure scenarios at scale\n> - **Options Considered**: Direct HTTP delivery, queue-based delivery with retry logic, event streaming with consumer groups\n> - **Decision**: Queue-based delivery with per-endpoint ordering and circuit breaker protection\n> - **Rationale**: Provides at-least-once delivery guarantees with bounded failure impact while maintaining implementable complexity for most organizations\n> - **Consequences**: Requires message queue infrastructure and adds delivery latency, but enables reliable delivery with comprehensive failure handling\n\n| Approach | Reliability | Performance | Complexity | Operational Overhead |\n|----------|-------------|-------------|------------|---------------------|\n| Direct HTTP | Low - no retry or failure handling | High - minimal latency | Low - simple implementation | Low - stateless operation |\n| Queue-Based | High - comprehensive retry and DLQ | Medium - adds queue latency | Medium - requires queue infrastructure | Medium - queue monitoring needed |\n| Event Streaming | Very High - durable log with replay | High - parallel processing | High - complex consumer coordination | High - requires streaming platform |\n\n#### Direct HTTP Delivery Approach\n\nThe simplest webhook delivery approach involves **immediate HTTP POST requests** when events occur. This synchronous model treats webhook delivery like a regular API call: serialize the event payload, generate a signature, make an HTTP request to each registered endpoint, and return success or failure to the event producer.\n\n**Advantages of direct delivery** include minimal infrastructure requirements (no message queues), low latency (immediate delivery), and simple debugging (direct correlation between events and HTTP requests). The implementation complexity stays low because there's no separate delivery worker process or persistent queue state to manage.\n\nHowever, **direct delivery fails catastrophically under common failure scenarios**. When recipient endpoints experience downtime, events are simply lost unless the event producer implements its own retry logic. **Slow endpoints block event producers** because the producer must wait for HTTP responses before continuing. **Cascading failures** occur when endpoint downtime causes event producer slowdown, potentially affecting user-facing operations.\n\n**Partial failure handling** becomes the responsibility of event producers, who typically aren't equipped to implement exponential backoff, circuit breakers, and dead letter queues. This leads to inconsistent reliability behavior across different event types and makes system-wide webhook reliability impossible to guarantee.\n\nDirect delivery works acceptably for **non-critical notifications** where occasional event loss is tolerable, such as optional email notifications or analytics events. However, it's unsuitable for business-critical integrations like payment notifications or inventory updates where reliability requirements are strict.\n\n#### Queue-Based Delivery with Retry Logic\n\nQueue-based delivery **decouples event production from delivery** using a persistent message queue as an intermediate buffer. When events occur, they're immediately written to a durable queue and acknowledged to the producer. Separate delivery workers consume from the queue, perform HTTP delivery, and implement retry logic for failures.\n\nThis approach provides **at-least-once delivery guarantees** because events persist in the queue until successful delivery. **Event producers remain fast** because queue writes are typically much faster than HTTP requests across the internet. **Comprehensive retry logic** can be implemented in delivery workers without affecting event producers.\n\n**Failure isolation** improves significantly because endpoint downtime only affects the delivery workers, not event production. **Per-endpoint circuit breakers** can disable failing endpoints without impacting deliveries to healthy endpoints. **Dead letter queues** capture permanently failed events for manual intervention while allowing the system to continue processing new events.\n\nThe **ordering challenge** requires careful queue design. Simple FIFO queues provide global ordering but create head-of-line blocking when any endpoint fails. **Per-endpoint queues** enable parallel processing while maintaining ordering per destination, but require more complex queue management and worker coordination.\n\n**Operational complexity** increases because the system now requires queue infrastructure (Redis, RabbitMQ, or cloud queues), queue monitoring, and worker process management. **Delivery latency** increases due to queue buffering, though this latency is typically acceptable for asynchronous webhook use cases.\n\nQueue-based delivery represents the **sweet spot for most webhook systems** because it provides strong reliability guarantees without requiring the operational complexity of full event streaming platforms.\n\n#### Event Streaming with Consumer Groups\n\nEvent streaming platforms like Apache Kafka treat webhook events as entries in a **durable, ordered log**. Events are written to topic partitions and consumed by delivery workers organized into consumer groups. This approach provides the strongest durability and replay guarantees at the cost of significant operational complexity.\n\n**Streaming advantages** include **perfect event replay** capability (reprocess events from any point in time), **horizontal scalability** through partition parallelism, and **exactly-once processing** semantics when combined with idempotent delivery logic. **Consumer group rebalancing** automatically distributes work when delivery workers are added or removed.\n\n**Partition-based ordering** allows parallel processing while maintaining ordering within partitions. By partitioning events by endpoint URL, each endpoint's events maintain strict ordering while allowing parallel delivery across endpoints.\n\nHowever, **operational overhead** becomes substantial. Streaming platforms require cluster management, partition rebalancing monitoring, offset management, and complex failure recovery procedures. **Development complexity** increases because delivery workers must implement streaming consumer protocols and handle partition rebalancing gracefully.\n\n**Resource overhead** is significant because streaming platforms maintain durable logs for extended periods. A high-volume webhook system might generate terabytes of event data monthly, requiring substantial storage and network resources for log replication.\n\n**Delivery latency** can increase due to batching optimizations in streaming platforms, though this is often tunable through consumer configuration.\n\nEvent streaming excels for **very high-volume systems** (millions of events per day) or scenarios requiring **comprehensive audit trails** with replay capability. However, the operational complexity makes it overkill for most webhook delivery use cases where queue-based delivery provides sufficient reliability guarantees with much lower operational overhead.\n\n> **Critical Design Insight**\n> \n> The choice between these approaches fundamentally comes down to your organization's tolerance for operational complexity versus reliability requirements. Direct delivery optimizes for simplicity but sacrifices reliability. Event streaming maximizes reliability and auditability but requires significant operational investment. Queue-based delivery provides the optimal balance for most organizations by delivering strong reliability guarantees with manageable operational overhead.\n\n### Common Anti-Patterns and Design Pitfalls\n\nUnderstanding how webhook delivery systems fail helps inform better architectural decisions and avoid common implementation mistakes that lead to reliability issues in production.\n\n#### ⚠️ **Pitfall: Synchronous Delivery from Critical Path**\n\nMany systems start by implementing webhook delivery directly in request handlers for user-facing operations. When a user completes a purchase, the payment handler immediately sends webhook notifications before responding to the user. This creates a **critical path dependency** where webhook delivery failures can impact user experience.\n\n**Why this fails**: Slow or failing webhook endpoints cause user requests to time out. Users experience degraded performance due to external service issues completely outside your control. During webhook endpoint outages, user operations may fail entirely.\n\n**How to fix**: Always decouple webhook delivery from user-facing operations using asynchronous queues. User requests should complete successfully regardless of webhook delivery status.\n\n#### ⚠️ **Pitfall: Inadequate Failure Classification**\n\nNaive retry logic treats all HTTP failures equally, retrying 4xx client errors that will never succeed while giving up too quickly on 5xx server errors that might recover.\n\n**Why this fails**: Retrying 400 Bad Request or 404 Not Found responses wastes resources and creates unnecessary load. Meanwhile, giving up on 503 Service Unavailable responses discards events that might succeed after brief downtime.\n\n**How to fix**: Implement status code classification where 4xx errors (except 429) skip retries, 5xx errors and network failures trigger exponential backoff, and 429 Rate Limited responses respect Retry-After headers.\n\n#### ⚠️ **Pitfall: Missing Signature Verification**\n\nSome webhook systems skip cryptographic signature generation or implement it incorrectly, making it impossible for recipients to verify payload authenticity.\n\n**Why this fails**: Recipients cannot distinguish legitimate webhooks from spoofed attacks. Debugging becomes impossible because recipients can't trust payload integrity. Compliance requirements may mandate signature verification for audit trails.\n\n**How to fix**: Always implement HMAC-SHA256 signature verification with timestamp-based replay protection. Include signatures in standard headers and document verification procedures for recipients.\n\n#### ⚠️ **Pitfall: Unbounded Retry Queues**\n\nWithout proper queue management, failed webhook deliveries can accumulate indefinitely, eventually consuming all available memory and storage.\n\n**Why this fails**: During widespread endpoint outages, retry queues grow exponentially. System performance degrades as workers spend all their time processing retries for dead endpoints. Eventually, the system runs out of resources and crashes.\n\n**How to fix**: Implement dead letter queues with maximum retry limits. Use circuit breakers to disable failing endpoints. Monitor queue depth and alert when growth exceeds normal bounds.\n\n### Implementation Guidance\n\nBuilding a reliable webhook delivery system requires careful technology selection and project structure to handle the complexity of asynchronous processing, cryptographic operations, and external HTTP communication.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Message Queue | Redis with `celery` for task queuing | RabbitMQ with `pika` for AMQP messaging |\n| HTTP Client | `requests` library with connection pooling | `httpx` with async support and HTTP/2 |\n| Database | PostgreSQL with `psycopg2` for reliability | PostgreSQL with async `asyncpg` for performance |\n| Cryptography | `hmac` and `hashlib` from standard library | `cryptography` library for advanced features |\n| Web Framework | Flask with `Flask-RESTful` for simplicity | FastAPI for async support and OpenAPI docs |\n| Background Workers | Celery for task processing | Custom async workers with `asyncio` |\n| Monitoring | Python `logging` with structured output | Prometheus metrics with `prometheus_client` |\n\n#### Recommended Project Structure\n\nThe webhook delivery system requires clear separation between API endpoints, background processing, and data models to maintain testability and enable horizontal scaling.\n\n```\nwebhook-delivery-system/\n├── app/\n│   ├── __init__.py\n│   ├── models/                    # Data models and database schemas\n│   │   ├── __init__.py\n│   │   ├── webhook.py             # Webhook registration model\n│   │   ├── event.py               # Event and delivery attempt models\n│   │   └── circuit_breaker.py     # Circuit breaker state model\n│   ├── api/                       # REST API endpoints\n│   │   ├── __init__.py\n│   │   ├── webhooks.py            # Webhook registration API\n│   │   ├── events.py              # Event submission and replay API\n│   │   └── monitoring.py          # Status and health endpoints\n│   ├── delivery/                  # Core delivery engine\n│   │   ├── __init__.py\n│   │   ├── queue_manager.py       # Queue operations and ordering\n│   │   ├── delivery_worker.py     # HTTP delivery and retry logic\n│   │   ├── circuit_breaker.py     # Circuit breaker implementation\n│   │   └── signature.py           # HMAC signature generation\n│   ├── storage/                   # Data persistence layer\n│   │   ├── __init__.py\n│   │   ├── webhook_store.py       # Webhook registration storage\n│   │   ├── event_store.py         # Event and attempt logging\n│   │   └── migrations/            # Database schema migrations\n│   └── config/                    # Configuration management\n│       ├── __init__.py\n│       ├── settings.py            # Environment-based configuration\n│       └── logging.py             # Logging configuration\n├── tests/                         # Test suite organization\n│   ├── unit/                      # Component unit tests\n│   ├── integration/               # Cross-component tests\n│   └── fixtures/                  # Test data and mocks\n├── scripts/                       # Operational scripts\n│   ├── migrate.py                 # Database migration runner\n│   ├── worker.py                  # Background worker startup\n│   └── health_check.py            # System health validation\n├── docker/                        # Container configuration\n│   ├── Dockerfile\n│   ├── docker-compose.yml\n│   └── nginx.conf                 # Reverse proxy configuration\n└── docs/                          # Documentation\n    ├── api.md                     # API documentation\n    ├── deployment.md              # Operations guide\n    └── troubleshooting.md         # Common issues and solutions\n```\n\n#### Infrastructure Starter Code\n\n**Database Connection Management**\n\n```python\n# app/storage/__init__.py\nimport os\nimport psycopg2\nfrom psycopg2.pool import ThreadedConnectionPool\nfrom psycopg2.extras import RealDictCursor\nfrom contextlib import contextmanager\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass DatabaseManager:\n    \"\"\"Manages PostgreSQL connection pooling for webhook storage.\"\"\"\n    \n    def __init__(self, database_url: str, min_conn: int = 1, max_conn: int = 20):\n        self.database_url = database_url\n        self.pool = ThreadedConnectionPool(\n            min_conn, max_conn, database_url,\n            cursor_factory=RealDictCursor\n        )\n        logger.info(f\"Database pool initialized with {min_conn}-{max_conn} connections\")\n    \n    @contextmanager\n    def get_connection(self):\n        \"\"\"Context manager for database connections with automatic cleanup.\"\"\"\n        conn = None\n        try:\n            conn = self.pool.getconn()\n            yield conn\n        except Exception as e:\n            if conn:\n                conn.rollback()\n            logger.error(f\"Database operation failed: {e}\")\n            raise\n        finally:\n            if conn:\n                self.pool.putconn(conn)\n    \n    def execute_query(self, query: str, params: tuple = None):\n        \"\"\"Execute query and return results.\"\"\"\n        with self.get_connection() as conn:\n            with conn.cursor() as cursor:\n                cursor.execute(query, params)\n                if query.strip().upper().startswith('SELECT'):\n                    return cursor.fetchall()\n                conn.commit()\n                return cursor.rowcount\n\n# Initialize global database manager\ndb_manager = DatabaseManager(os.getenv('DATABASE_URL'))\n```\n\n**HTTP Client with Connection Pooling**\n\n```python\n# app/delivery/http_client.py\nimport requests\nimport logging\nfrom typing import Dict, Optional, Tuple\nfrom urllib3.util.retry import Retry\nfrom requests.adapters import HTTPAdapter\n\nlogger = logging.getLogger(__name__)\n\nclass WebhookHTTPClient:\n    \"\"\"HTTP client optimized for webhook delivery with proper connection management.\"\"\"\n    \n    def __init__(self, timeout: int = 30, max_retries: int = 0):\n        self.timeout = timeout\n        self.session = requests.Session()\n        \n        # Configure connection pooling\n        adapter = HTTPAdapter(\n            pool_connections=100,\n            pool_maxsize=100,\n            max_retries=max_retries\n        )\n        \n        self.session.mount('http://', adapter)\n        self.session.mount('https://', adapter)\n        \n        # Set default headers\n        self.session.headers.update({\n            'User-Agent': 'WebhookDeliverySystem/1.0',\n            'Content-Type': 'application/json'\n        })\n    \n    def deliver_webhook(self, \n                       url: str, \n                       payload: str, \n                       signature: str,\n                       headers: Optional[Dict[str, str]] = None) -> Tuple[int, str, float]:\n        \"\"\"\n        Deliver webhook payload to endpoint.\n        \n        Returns:\n            Tuple of (status_code, response_text, response_time_seconds)\n        \"\"\"\n        delivery_headers = {\n            'X-Webhook-Signature-256': f'sha256={signature}',\n            'X-Webhook-Timestamp': str(int(time.time())),\n            'X-Webhook-Delivery-ID': str(uuid.uuid4())\n        }\n        \n        if headers:\n            delivery_headers.update(headers)\n        \n        start_time = time.time()\n        try:\n            response = self.session.post(\n                url, \n                data=payload,\n                headers=delivery_headers,\n                timeout=self.timeout,\n                allow_redirects=False  # Prevent redirect attacks\n            )\n            \n            response_time = time.time() - start_time\n            logger.info(f\"Webhook delivered: {url} -> {response.status_code} in {response_time:.3f}s\")\n            \n            return response.status_code, response.text[:1000], response_time\n            \n        except requests.exceptions.Timeout:\n            response_time = time.time() - start_time\n            logger.warning(f\"Webhook timeout: {url} after {response_time:.3f}s\")\n            return 408, \"Request timeout\", response_time\n            \n        except requests.exceptions.ConnectionError as e:\n            response_time = time.time() - start_time\n            logger.warning(f\"Webhook connection failed: {url} - {e}\")\n            return 503, f\"Connection error: {str(e)[:500]}\", response_time\n            \n        except Exception as e:\n            response_time = time.time() - start_time\n            logger.error(f\"Webhook delivery error: {url} - {e}\")\n            return 500, f\"Delivery error: {str(e)[:500]}\", response_time\n```\n\n**Configuration Management**\n\n```python\n# app/config/settings.py\nimport os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass WebhookConfig:\n    \"\"\"Configuration settings for webhook delivery system.\"\"\"\n    \n    # Database settings\n    database_url: str = os.getenv('DATABASE_URL', 'postgresql://localhost/webhooks')\n    \n    # Queue settings\n    redis_url: str = os.getenv('REDIS_URL', 'redis://localhost:6379/0')\n    queue_name: str = os.getenv('QUEUE_NAME', 'webhook_delivery')\n    \n    # Delivery settings\n    delivery_timeout: int = int(os.getenv('DELIVERY_TIMEOUT', '30'))\n    max_retry_attempts: int = int(os.getenv('MAX_RETRY_ATTEMPTS', '5'))\n    retry_base_delay: int = int(os.getenv('RETRY_BASE_DELAY', '60'))\n    \n    # Circuit breaker settings\n    circuit_breaker_failure_threshold: int = int(os.getenv('CB_FAILURE_THRESHOLD', '5'))\n    circuit_breaker_timeout: int = int(os.getenv('CB_TIMEOUT', '300'))\n    \n    # Rate limiting settings\n    rate_limit_requests_per_minute: int = int(os.getenv('RATE_LIMIT_RPM', '60'))\n    \n    # Security settings\n    signature_algorithm: str = 'sha256'\n    webhook_signature_header: str = 'X-Webhook-Signature-256'\n    timestamp_tolerance: int = int(os.getenv('TIMESTAMP_TOLERANCE', '300'))\n    \n    def validate(self) -> None:\n        \"\"\"Validate configuration settings.\"\"\"\n        if self.max_retry_attempts < 1:\n            raise ValueError(\"max_retry_attempts must be at least 1\")\n        if self.delivery_timeout < 1:\n            raise ValueError(\"delivery_timeout must be at least 1 second\")\n        if self.circuit_breaker_failure_threshold < 1:\n            raise ValueError(\"circuit_breaker_failure_threshold must be at least 1\")\n\n# Global configuration instance\nconfig = WebhookConfig()\nconfig.validate()\n```\n\n#### Core Logic Skeleton\n\n**Webhook Registration Handler**\n\n```python\n# app/api/webhooks.py\nfrom flask import Flask, request, jsonify\nfrom app.models.webhook import WebhookRegistration\nfrom app.delivery.signature import generate_webhook_secret\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef register_webhook():\n    \"\"\"\n    Register a new webhook endpoint with ownership verification.\n    \n    Expected JSON payload:\n    {\n        \"url\": \"https://example.com/webhook\",\n        \"events\": [\"payment.completed\", \"user.created\"],\n        \"description\": \"Payment processing webhooks\"\n    }\n    \"\"\"\n    # TODO 1: Validate request JSON contains required fields (url, events)\n    # TODO 2: Validate URL format and ensure HTTPS only\n    # TODO 3: Check URL against SSRF blacklist (private IPs, localhost, etc.)\n    # TODO 4: Generate cryptographically secure signing secret\n    # TODO 5: Store webhook registration in database\n    # TODO 6: Send ownership verification challenge to endpoint\n    # TODO 7: Return webhook ID and secret to client\n    # Hint: Use urllib.parse to validate URL format\n    # Hint: Use ipaddress module to check for private IP ranges\n    pass\n\ndef verify_webhook_ownership(webhook_id: str):\n    \"\"\"\n    Verify webhook endpoint ownership via challenge-response.\n    \n    Sends a GET request with a challenge parameter and expects\n    the same challenge value in the response body.\n    \"\"\"\n    # TODO 1: Retrieve webhook registration from database\n    # TODO 2: Generate random challenge string (UUID)\n    # TODO 3: Send GET request to webhook URL with ?challenge=<value>\n    # TODO 4: Verify response contains the challenge value\n    # TODO 5: Update webhook status to 'verified' in database\n    # TODO 6: Log verification success/failure for debugging\n    # Hint: Use uuid.uuid4() for challenge generation\n    # Hint: Set short timeout for verification requests\n    pass\n```\n\n**Event Delivery Worker**\n\n```python\n# app/delivery/delivery_worker.py\nfrom app.models.event import DeliveryAttempt\nfrom app.delivery.http_client import WebhookHTTPClient\nfrom app.delivery.signature import generate_hmac_signature\nimport time\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass DeliveryWorker:\n    \"\"\"Processes webhook delivery queue with retry logic and circuit breakers.\"\"\"\n    \n    def __init__(self, http_client: WebhookHTTPClient):\n        self.http_client = http_client\n    \n    def process_delivery(self, event_id: str, webhook_id: str, payload: str):\n        \"\"\"\n        Attempt delivery of webhook event with full error handling.\n        \n        Returns True if delivery succeeded, False if it should be retried.\n        \"\"\"\n        # TODO 1: Load webhook registration and verify it's not disabled\n        # TODO 2: Check circuit breaker state - skip if open\n        # TODO 3: Apply rate limiting - delay if necessary\n        # TODO 4: Generate HMAC signature for payload\n        # TODO 5: Perform HTTP delivery using http_client\n        # TODO 6: Classify response status code (success/retry/permanent_failure)\n        # TODO 7: Record delivery attempt in database with full details\n        # TODO 8: Update circuit breaker state based on result\n        # TODO 9: Schedule retry if needed with exponential backoff\n        # TODO 10: Move to dead letter queue if max retries exceeded\n        # Hint: Status codes 2xx = success, 5xx = retry, 4xx = permanent failure (except 429)\n        # Hint: Use time.time() for attempt timestamps\n        pass\n    \n    def calculate_retry_delay(self, attempt_number: int, base_delay: int = 60) -> int:\n        \"\"\"\n        Calculate exponential backoff delay with jitter.\n        \n        Returns delay in seconds for the next retry attempt.\n        \"\"\"\n        # TODO 1: Calculate exponential backoff: base_delay * (2 ^ attempt_number)\n        # TODO 2: Add random jitter to prevent thundering herd (±25%)\n        # TODO 3: Cap maximum delay at reasonable limit (e.g., 1 hour)\n        # TODO 4: Return calculated delay in seconds\n        # Hint: Use random.uniform() for jitter calculation\n        # Hint: min(calculated_delay, max_delay) for capping\n        pass\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Checkpoint: Webhook Registration**\nAfter implementing the webhook registration system, you should be able to:\n\n1. **Test registration API**: `curl -X POST http://localhost:5000/webhooks -H \"Content-Type: application/json\" -d '{\"url\": \"https://httpbin.org/post\", \"events\": [\"test.event\"]}'`\n   - Expected: JSON response with webhook ID and signing secret\n   - Verify: Check database for new webhook record with generated secret\n\n2. **Test SSRF protection**: Try registering `http://localhost:8080/webhook` or `http://192.168.1.1/webhook`\n   - Expected: 400 Bad Request with error message about invalid URL\n   - Verify: Private IPs and localhost are rejected\n\n3. **Test signature generation**: Generate signature for test payload and verify it matches expected HMAC-SHA256 output\n   - Use online HMAC calculator to verify signature correctness\n   - Ensure timestamp is included in signed data\n\n4. **Test ownership verification**: Register webhook pointing to a test server you control\n   - Expected: GET request to your endpoint with challenge parameter\n   - Respond with challenge value to complete verification\n\n**Milestone 2 Checkpoint: Delivery Queue**\nAfter implementing the delivery system:\n\n1. **Test basic delivery**: Submit test event and verify HTTP delivery\n   - Check delivery attempt records in database\n   - Verify HMAC signature in delivered request headers\n\n2. **Test retry logic**: Point webhook at non-existent domain and observe retries\n   - Expected: Exponential backoff delays between attempts\n   - Verify: Retry delays increase: 60s, 120s, 240s, etc.\n\n3. **Test dead letter queue**: Let webhook exhaust all retry attempts\n   - Expected: Event moved to dead letter queue after max retries\n   - Verify: No further delivery attempts scheduled\n\n#### Common Implementation Issues\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Webhook registration returns 500 error | Database connection failure | Check database connectivity and credentials | Verify DATABASE_URL and test connection |\n| Signature verification fails at recipient | Incorrect HMAC calculation | Compare generated signature with online calculator | Ensure UTF-8 encoding and correct secret |\n| Deliveries never retry after failures | Queue worker not running | Check worker process logs | Start background worker process |\n| High memory usage in workers | Connection pool leaks | Monitor connection count metrics | Implement proper connection cleanup |\n| Slow delivery processing | Database transaction locks | Check for long-running queries | Add database indexes and optimize queries |\n| Circuit breaker never opens | Threshold too high | Review failure count vs threshold | Lower failure threshold for testing |\n\n\n## Goals and Non-Goals\n\n> **Milestone(s):** Foundation for all milestones - establishes success criteria and scope boundaries that guide implementation decisions throughout the project\n\nThe webhook delivery system aims to solve the fundamental challenge of reliable asynchronous communication between distributed services. Before diving into technical solutions, it's essential to clearly define what constitutes success and explicitly bound the scope of the system. This prevents feature creep while ensuring all stakeholders understand the system's intended capabilities and limitations.\n\n**Mental Model: The Service Level Agreement (SLA) Contract**\n\nThink of this goals section as writing a detailed service level agreement between your webhook system and its users. Just as a shipping company promises specific delivery times, tracking capabilities, and damage protection while explicitly excluding certain package types or destinations, our webhook system must clearly define its delivery guarantees, security protections, and operational capabilities while explicitly stating what it will not handle. This contract becomes the North Star for all implementation decisions - when faced with competing design choices, we always choose the option that best serves these stated goals.\n\nThe goals fall into three categories: functional requirements that define core system behavior, non-functional requirements that establish quality attributes, and explicit non-goals that prevent scope creep. Each goal must be measurable and testable to ensure successful implementation.\n\n### Functional Goals\n\nThe functional goals define the core business capabilities that make the webhook delivery system valuable to its users. These represent the fundamental features that must work correctly for the system to fulfill its purpose.\n\n**Reliable Event Delivery with Ordering Guarantees**\n\nThe system must guarantee that webhook events are delivered to registered endpoints with strong consistency and ordering semantics. This means implementing at-least-once delivery semantics where every event will eventually be delivered successfully or moved to a dead letter queue for manual intervention. For each webhook endpoint, events must be delivered in the order they were originally generated to maintain causal consistency - if Event A was generated before Event B for the same resource, Event A must be delivered before Event B.\n\n| Delivery Guarantee | Implementation Requirement | Measurable Criteria |\n|-------------------|---------------------------|-------------------|\n| At-least-once delivery | Persistent message queues with acknowledgments | 99.9% of events delivered within SLA timeframes |\n| Ordering per endpoint | Sequential processing with per-endpoint queues | Events arrive in chronological order of generation |\n| Failure isolation | Dead letter queue for undeliverable messages | Failed events don't block subsequent event delivery |\n| Delivery confirmation | Track delivery attempts and final status | Complete audit trail for every event processed |\n\n**Cryptographic Security with HMAC Signature Verification**\n\nEvery webhook delivery must include a cryptographically secure HMAC-SHA256 signature that allows recipients to verify both the authenticity and integrity of the payload. The system must generate cryptographically random signing secrets for each webhook registration and include timestamps in the signature calculation to prevent replay attacks. Recipients can use the shared secret to recompute the signature and confirm that the event originated from the webhook system and hasn't been tampered with in transit.\n\n| Security Feature | Implementation Details | Verification Method |\n|------------------|----------------------|-------------------|\n| HMAC-SHA256 signatures | Include timestamp and payload in signature | Recipients recompute and compare signatures |\n| Replay attack prevention | Timestamp tolerance window of 5 minutes | Reject events with timestamps outside tolerance |\n| Secret rotation support | Multiple active secrets during rotation period | New secrets work while old ones remain valid |\n| HTTPS-only delivery | Reject webhook URLs with HTTP scheme | All delivery attempts use TLS encryption |\n\n**Comprehensive Retry Logic with Exponential Backoff**\n\nWhen webhook delivery fails due to network issues or temporary endpoint unavailability, the system must implement intelligent retry logic that balances quick recovery with avoiding overwhelming already-struggling endpoints. This includes exponential backoff with jitter to prevent thundering herd problems, appropriate retry decisions based on HTTP status codes, and circuit breaker protection to disable persistently failing endpoints.\n\n| Retry Feature | Configuration Parameters | Behavior Description |\n|---------------|-------------------------|-------------------|\n| Exponential backoff | Base delay 1s, max delay 300s, 5 max attempts | Delays: 1s, 2s, 4s, 8s, 16s with ±25% jitter |\n| Status code logic | Retry 5xx and 429, don't retry most 4xx | 400/401/403/404 are permanent failures |\n| Circuit breaker | 5 consecutive failures trigger open circuit | Endpoint disabled until manual reset or timeout |\n| Dead letter routing | Events exhausting retries move to DLQ | Manual review and replay capability required |\n\n**Event Ownership Verification and SSRF Protection**\n\nBefore accepting webhook registrations, the system must verify that the registering party actually controls the destination endpoint to prevent abuse and server-side request forgery (SSRF) attacks. This involves sending a challenge request to the proposed endpoint and requiring a specific response that proves ownership. Additionally, all webhook URLs must be validated to ensure they don't target private network addresses or internal services.\n\n| Verification Step | Security Protection | Implementation Approach |\n|-------------------|-------------------|----------------------|\n| Challenge-response verification | Prevents unauthorized webhook registration | Generate random token, require echo back |\n| URL validation | Blocks SSRF attacks on internal services | Reject private IP ranges and localhost |\n| HTTPS enforcement | Protects payload confidentiality in transit | Only accept webhook URLs with HTTPS scheme |\n| Endpoint reachability | Confirms URL is accessible for delivery | Test delivery during registration process |\n\n> **Design Principle: Security by Default**\n> Every security feature must be enabled by default with no option to disable it. Organizations often struggle with webhook security because systems make it optional or easy to bypass. Our system forces secure practices by rejecting insecure configurations rather than warning about them.\n\n### Non-Functional Goals\n\nThe non-functional goals establish quality attributes that define how well the system performs its functional capabilities. These requirements often drive architectural decisions more than functional requirements do.\n\n**Performance and Throughput Requirements**\n\nThe webhook delivery system must handle substantial event volumes while maintaining low latency for delivery attempts. This requires careful attention to queue management, connection pooling, and concurrent processing capabilities. The system should gracefully handle traffic spikes without dropping events or significantly increasing delivery latency.\n\n| Performance Metric | Target Value | Measurement Method |\n|-------------------|-------------|------------------|\n| Event ingestion rate | 10,000 events/second sustained | Queue depth monitoring during peak load |\n| Delivery latency P99 | Under 5 seconds for healthy endpoints | Time from event creation to first delivery attempt |\n| Concurrent deliveries | 1,000 simultaneous HTTP requests | HTTP client connection pool utilization |\n| Queue processing lag | Under 30 seconds during normal operation | Difference between newest queued and processed event |\n\n**High Availability and Fault Tolerance**\n\nThe system must continue operating correctly even when individual components fail or become temporarily unavailable. This includes surviving database outages, message queue failures, and individual worker process crashes without losing events or corrupting delivery state. Recovery from failures should be automatic whenever possible.\n\n| Availability Feature | Failure Scenario | Recovery Mechanism |\n|---------------------|------------------|-------------------|\n| Message queue persistence | Worker process crash during delivery | Events remain queued until acknowledged |\n| Database connection handling | Temporary database unavailability | Connection pool retry with exponential backoff |\n| Worker process resilience | Individual worker thread crashes | Process supervisor restarts failed workers |\n| Event durability | System crash before event queuing | Write-ahead log ensures events aren't lost |\n\n**Operational Observability and Debugging**\n\nOperating a webhook delivery system requires comprehensive visibility into event processing, delivery success rates, and failure modes. The system must provide detailed logging, metrics, and debugging capabilities that enable rapid diagnosis of delivery issues and performance problems.\n\n| Observability Component | Information Provided | Usage Scenario |\n|------------------------|-------------------|---------------|\n| Delivery attempt logs | HTTP status, response time, error details | Debug specific endpoint delivery failures |\n| Endpoint health metrics | Success rate, average latency, circuit breaker status | Monitor overall webhook health across endpoints |\n| Queue depth monitoring | Pending events per endpoint and globally | Detect processing bottlenecks and traffic spikes |\n| Error rate dashboards | Failed deliveries by error type and endpoint | Identify systematic problems vs isolated failures |\n\n> **Operational Excellence Principle**\n> The system must be designed to make the most common operational tasks simple and the most dangerous operations difficult. Viewing delivery logs should be a single click, while replaying events should require deliberate confirmation steps to prevent accidental duplicate deliveries.\n\n**Horizontal Scalability Architecture**\n\nAs webhook usage grows, the system must support horizontal scaling by adding more worker processes or machines without requiring fundamental architectural changes. This means avoiding single points of contention, designing for stateless processing where possible, and ensuring that work can be distributed across multiple processing units.\n\n| Scalability Dimension | Scaling Approach | Implementation Consideration |\n|----------------------|------------------|----------------------------|\n| Event processing workers | Add worker processes or containers | Stateless workers using shared message queue |\n| Database connections | Connection pooling with configurable limits | Read replicas for delivery history queries |\n| HTTP delivery capacity | Concurrent connection limits per worker | Connection pooling prevents resource exhaustion |\n| Queue throughput | Partitioned queues by endpoint or hash | Prevents single endpoint from blocking others |\n\n### Explicit Non-Goals\n\nThe explicit non-goals are equally important as the goals themselves because they define boundaries that prevent feature creep and maintain system focus. These exclusions help teams resist the temptation to solve adjacent problems that would complicate the core webhook delivery mission.\n\n**Real-Time Streaming and Sub-Second Latency**\n\nThis webhook delivery system is explicitly not designed for real-time streaming use cases that require sub-second latency or complex event processing. While the system aims for reasonable delivery latency (under 5 seconds P99), it prioritizes reliability and ordering over ultra-low latency. Teams needing millisecond-latency event delivery should consider event streaming platforms rather than webhook systems.\n\n| Excluded Feature | Why Not Included | Recommended Alternative |\n|------------------|------------------|----------------------|\n| Sub-second delivery guarantees | Conflicts with reliability and retry logic | Apache Kafka or similar event streaming |\n| Complex event processing | Outside webhook delivery scope | Dedicated stream processing frameworks |\n| Real-time analytics | Not core to webhook delivery mission | Time-series databases and analytics platforms |\n| Event transformation | Adds complexity and failure modes | Implement transformations in receiving applications |\n\n**Advanced Payload Processing and Transformation**\n\nThe system will not provide built-in payload transformation, filtering, or enrichment capabilities. Webhook events are delivered exactly as they were submitted, without modification. This decision maintains system simplicity and avoids the complexity of a general-purpose data processing pipeline. Organizations needing payload transformation should implement it in their event publishing or receiving applications.\n\n**Multi-Tenant Isolation and Access Control**\n\nWhile the system supports multiple webhook endpoints, it does not provide sophisticated multi-tenant isolation, user authentication, or fine-grained access control. The webhook registry is shared across all users, and there's no concept of user accounts or permissions. Organizations requiring multi-tenant operation should implement authentication and authorization in the application layer that uses the webhook system.\n\n| Excluded Capability | Complexity Reason | Workaround Approach |\n|--------------------|------------------|-------------------|\n| User authentication | Requires identity provider integration | Implement in application layer |\n| Tenant data isolation | Complex database design and query patterns | Use separate webhook system instances |\n| Permission management | Extensive RBAC implementation needed | Application-level access control |\n| Audit logging by user | Requires user context throughout system | Log user actions in calling application |\n\n**Geographic Distribution and Multi-Region Deployment**\n\nThe initial system design assumes single-region deployment and does not address challenges of geographic distribution, cross-region replication, or compliance with data residency requirements. While the system can be deployed in multiple regions independently, it won't provide built-in cross-region event replication or failover capabilities.\n\n**Integration with External Monitoring and Alerting Systems**\n\nWhile the system provides comprehensive logging and metrics, it will not include built-in integration with specific monitoring platforms, alerting systems, or incident management tools. The system exposes metrics and logs in standard formats that can be consumed by external monitoring solutions, but teams must configure their own alerting and incident response workflows.\n\n| Integration Type | Why Excluded | Standard Interface Provided |\n|------------------|-------------|----------------------------|\n| Specific monitoring tools | Too many platform variations | Prometheus metrics endpoint |\n| Alerting systems | Organization-specific requirements | Structured JSON logs |\n| Incident management | Workflow varies by organization | HTTP webhook for system events |\n| Performance analytics | Specialized tools handle this better | Time-series metrics export |\n\n> **Scope Discipline Principle**\n> Every excluded feature represents a conscious decision to maintain system focus. Before adding any new capability, teams must explicitly consider whether it serves the core webhook delivery mission or could be better handled by specialized tools.\n\n**Event Schema Validation and Registry**\n\nThe webhook delivery system treats all event payloads as opaque JSON or text data and does not perform schema validation, versioning, or registry management. This decision avoids the complexity of maintaining schema definitions and compatibility rules across different event types and versions. Applications publishing and consuming webhook events are responsible for their own payload format management.\n\n### Implementation Guidance\n\nThe goals and non-goals established in this section directly influence every subsequent design decision throughout the webhook delivery system. Understanding these requirements helps guide technology choices, architectural patterns, and implementation priorities.\n\n**A. Goal Verification Strategy**\n\n| Requirement Category | Verification Method | Implementation Checkpoint |\n|---------------------|-------------------|-------------------------|\n| Functional Goals | Automated integration tests with mock endpoints | Each milestone includes test scenarios validating specific goals |\n| Performance Goals | Load testing with configurable traffic patterns | Benchmark tests measuring throughput and latency under load |\n| Security Goals | Penetration testing and security review | Security-focused tests for SSRF, replay attacks, and signature bypass |\n| Operational Goals | Monitoring dashboard and alerting validation | Verify observability features help diagnose common failure scenarios |\n\n**B. Technology Selection Criteria**\n\nWhen choosing specific technologies for implementing the webhook delivery system, evaluate each option against these established goals:\n\n- **Reliability First**: Choose proven technologies with strong consistency guarantees over cutting-edge options with uncertain behavior\n- **Security by Default**: Prefer technologies that make secure configuration the default rather than requiring extensive security hardening\n- **Operational Simplicity**: Select technologies that provide good observability and debugging capabilities out of the box\n- **Horizontal Scaling**: Ensure chosen technologies support the scalability patterns defined in non-functional goals\n\n**C. Milestone Success Criteria**\n\nEach project milestone should be evaluated against these goals to ensure the implementation stays on track:\n\n| Milestone | Primary Goals Validated | Success Indicators |\n|-----------|------------------------|-------------------|\n| Milestone 1: Registration & Security | HMAC signatures, SSRF protection, HTTPS enforcement | All webhook registrations require valid HTTPS URLs and generate crypto-secure secrets |\n| Milestone 2: Delivery & Retry | At-least-once delivery, exponential backoff, ordering | Events are delivered in order with appropriate retry logic for different failure types |\n| Milestone 3: Circuit Breaker & Rate Limiting | Fault tolerance, endpoint protection, performance | Failing endpoints are automatically disabled and healthy endpoints maintain SLA performance |\n| Milestone 4: Event Log & Replay | Observability, debugging, operational excellence | Complete audit trail enables rapid diagnosis and safe event replay |\n\n**D. Common Goal Conflicts and Resolutions**\n\nDuring implementation, certain goals may appear to conflict with each other. Here are common tensions and how to resolve them:\n\n⚠️ **Goal Conflict: Security vs Performance**\nThe requirement for HMAC signature generation and verification adds computational overhead that could impact delivery throughput. Resolution: Implement signature operations efficiently using optimized crypto libraries and consider signature caching for duplicate payloads. The security benefit outweighs the performance cost, and proper implementation minimizes the impact.\n\n⚠️ **Goal Conflict: Reliability vs Latency**\nEnsuring at-least-once delivery requires persistent queuing and acknowledgment mechanisms that increase delivery latency. Resolution: This trade-off is intentional per our non-goals - we explicitly chose reliability over ultra-low latency. Teams needing sub-second delivery should use event streaming platforms instead.\n\n⚠️ **Goal Conflict: Observability vs Privacy**\nComprehensive logging for debugging might include sensitive payload data that should not be stored long-term. Resolution: Implement configurable log retention with automatic payload redaction. Store delivery metadata indefinitely but configure payload logging with short retention periods.\n\n**E. Metrics and SLA Monitoring**\n\nImplement these specific metrics to validate that the system meets its goals in production:\n\n```\n# Functional Goal Metrics\nwebhook_delivery_success_rate_percent{endpoint_id}\nwebhook_delivery_latency_seconds{percentile}\nwebhook_events_out_of_order_total{endpoint_id}\nwebhook_signature_verification_failures_total\n\n# Non-Functional Goal Metrics  \nwebhook_events_ingested_per_second\nwebhook_queue_depth_total{endpoint_id}\nwebhook_worker_concurrent_deliveries\nwebhook_circuit_breaker_open_total{endpoint_id}\n\n# Operational Goal Metrics\nwebhook_delivery_attempts_total{status_code, endpoint_id}\nwebhook_dead_letter_queue_depth\nwebhook_endpoint_health_score{endpoint_id}\nwebhook_retry_attempts_total{attempt_number}\n```\n\nThese metrics provide quantitative validation that the implemented system meets the goals established in this section. Regular review of these metrics helps identify when system behavior deviates from intended goals and guides optimization efforts.\n\n\n## High-Level Architecture\n\n> **Milestone(s):** Foundation for all milestones - architectural decisions here impact webhook registration (Milestone 1), delivery processing (Milestone 2), circuit breaker implementation (Milestone 3), and event logging systems (Milestone 4)\n\nThe webhook delivery system follows a multi-component architecture designed around the principle of **separation of concerns** and **fault isolation**. Think of this system like a modern mail processing facility: there's a registration desk that validates addresses and issues mailbox keys (webhook registry), a sorting and routing department that queues mail and handles delivery attempts (delivery engine), a quality control department that monitors delivery success and temporarily blocks problematic addresses (circuit breaker), and a record-keeping department that logs every piece of mail and delivery attempt for auditing purposes (event logging system).\n\n### Component Responsibilities\n\nThe webhook delivery system consists of four primary components, each with clearly defined responsibilities and interfaces. This architectural separation ensures that failures in one component don't cascade to others, and each component can be developed, tested, and scaled independently.\n\n> **Decision: Component-Based Architecture**\n> - **Context**: Webhook delivery involves multiple distinct concerns: registration management, HTTP delivery processing, failure protection, and audit logging. These concerns have different scaling characteristics, failure modes, and operational requirements.\n> - **Options Considered**: Monolithic service, microservices with separate databases, component-based monolith with shared database\n> - **Decision**: Component-based monolith with shared database and clear internal boundaries\n> - **Rationale**: Provides strong separation of concerns without operational complexity of distributed systems. Each component can be tested in isolation while maintaining ACID properties across the entire delivery workflow.\n> - **Consequences**: Enables independent development and testing while avoiding distributed system complexities like eventual consistency and cross-service transaction coordination.\n\n| Component | Primary Responsibility | Key Data Owned | Failure Impact |\n|-----------|----------------------|-----------------|----------------|\n| Webhook Registry | Endpoint registration and signature management | `WebhookRegistration` records, signing secrets | New registrations fail, existing deliveries continue |\n| Delivery Engine | Queue processing and HTTP delivery attempts | `DeliveryAttempt` records, retry scheduling | New deliveries queue up, no data loss |\n| Circuit Breaker | Endpoint health monitoring and failure protection | Circuit state, failure counters, health metrics | Failing endpoints may receive extra attempts |\n| Event Logger | Delivery audit trail and replay functionality | Complete delivery history, debugging data | Debugging capability lost, deliveries continue |\n\nThe **Webhook Registry** component acts as the system's front desk, handling all interactions related to webhook endpoint management. When a client wants to register a new webhook endpoint, this component validates the URL for security concerns (preventing SSRF attacks by blocking private IP ranges), generates cryptographically secure signing secrets using `generate_webhook_secret()`, and performs ownership verification through a challenge-response mechanism via `verify_webhook_ownership()`. The registry maintains the authoritative record of all registered webhooks, including their subscription preferences, active signing secrets, and verification status. This component also handles the complex process of secret rotation, allowing multiple secrets to be active simultaneously during transition periods to prevent disruption of in-flight deliveries.\n\nThe **Delivery Engine** serves as the system's workhorse, responsible for the reliable processing of webhook delivery requests. This component consumes events from the delivery queue, performs the actual HTTP POST requests to registered endpoints using `deliver_webhook()`, and manages the sophisticated retry logic through `calculate_retry_delay()` with exponential backoff and jitter. The delivery engine maintains strict ordering guarantees per endpoint while allowing parallel processing across different endpoints. When delivery attempts fail, this component makes intelligent decisions about whether to retry based on HTTP status codes (retrying 5xx errors and 429 rate limiting, but not 4xx client errors), and eventually routes persistently failing messages to the dead letter queue for manual intervention.\n\n> The delivery engine's ordering guarantee is critical for webhooks representing state changes. Consider an e-commerce system sending \"order_created\" followed by \"order_shipped\" events - these must arrive in the correct sequence to prevent the receiving system from processing a shipment notification before knowing the order exists.\n\nThe **Circuit Breaker** component implements the circuit breaker pattern to protect both the webhook delivery system and the receiving endpoints from cascade failures. This component continuously monitors the success rate of deliveries to each registered endpoint, maintaining counters for recent successes and failures. When an endpoint's failure rate exceeds the configured threshold (`CIRCUIT_BREAKER_FAILURE_THRESHOLD`), the circuit breaker transitions from the closed state to the open state, temporarily halting all delivery attempts to that endpoint. The component implements a sophisticated state machine with three states: closed (normal operation), open (deliveries blocked), and half-open (limited test deliveries). During the half-open state, the circuit breaker allows a small number of test requests to determine if the endpoint has recovered, either transitioning back to closed on success or returning to open on continued failures.\n\nThe **Event Logger** component provides comprehensive observability and debugging capabilities for the entire webhook delivery system. This component maintains a complete audit trail of every delivery attempt, including request payloads, response codes, timing information, and error messages. The event logger implements efficient time-series storage optimized for the high-volume, append-only nature of delivery logs. Beyond passive logging, this component supports active replay functionality, allowing operators to re-queue specific events for delivery while maintaining proper deduplication through unique delivery identifiers. The logger also implements intelligent retention policies, archiving older delivery records to cold storage while maintaining fast access to recent delivery history for debugging and operational monitoring.\n\n| Component Interface | Methods | Description |\n|-------------------|---------|-------------|\n| `WebhookRegistry` | `register_webhook() -> dict` | Validates URL, generates secret, initiates ownership verification |\n| `WebhookRegistry` | `verify_webhook_ownership(webhook_id) -> bool` | Sends challenge request and validates response |\n| `WebhookRegistry` | `generate_webhook_secret() -> str` | Creates cryptographically secure signing key |\n| `WebhookRegistry` | `generate_hmac_signature(payload, secret) -> str` | Computes HMAC-SHA256 for payload authentication |\n| `DeliveryEngine` | `process_delivery(event_id, webhook_id, payload) -> bool` | Orchestrates complete delivery attempt with error handling |\n| `DeliveryEngine` | `deliver_webhook(url, payload, signature) -> tuple` | Executes HTTP POST with proper headers and timeout |\n| `DeliveryEngine` | `calculate_retry_delay(attempt_number, base_delay) -> int` | Computes exponential backoff with jitter |\n| `CircuitBreaker` | `check_endpoint_health(webhook_id) -> bool` | Determines if endpoint is available for delivery |\n| `CircuitBreaker` | `record_delivery_result(webhook_id, success) -> None` | Updates failure counters and state transitions |\n| `EventLogger` | `log_delivery_attempt(attempt) -> None` | Persists delivery attempt with full context |\n| `EventLogger` | `replay_event(event_id) -> bool` | Re-queues event with deduplication handling |\n\n### Data Flow Overview\n\nThe webhook delivery system processes events through a carefully orchestrated pipeline that ensures reliability, ordering, and observability at every stage. Understanding this data flow is crucial because it reveals how the system maintains delivery guarantees even in the face of component failures, network issues, and endpoint unavailability.\n\nThe **event ingestion flow** begins when an external system publishes an event that needs to be delivered via webhooks. The event first arrives at the delivery engine, which immediately performs webhook resolution by querying the registry component to identify all endpoints subscribed to that specific event type. For each matching webhook registration, the delivery engine retrieves the current signing secret and uses `generate_hmac_signature()` to create an authentication signature for the payload. The signed delivery request is then placed onto the persistent delivery queue with a unique delivery identifier, ensuring that even if the system crashes at this point, no delivery requests are lost.\n\n> **Critical Design Insight**: The system commits the delivery request to the persistent queue BEFORE attempting any HTTP delivery. This ensures at-least-once delivery semantics - events may be delivered multiple times if failures occur, but they will never be lost entirely.\n\nThe **queue processing flow** operates as an independent process that continuously consumes delivery requests from the persistent queue. Before attempting delivery, the queue processor checks with the circuit breaker component to verify that the target endpoint is currently accepting traffic. If the circuit breaker indicates the endpoint is healthy (circuit closed), the delivery engine retrieves the full webhook registration details and constructs an HTTP POST request containing the signed payload. The `deliver_webhook()` method handles the actual HTTP delivery with appropriate timeout settings (`DELIVERY_TIMEOUT`), connection pooling, and error handling. The response from the target endpoint, including status code, response time, and any error messages, is immediately logged by the event logger component for debugging and compliance purposes.\n\nThe **retry scheduling flow** activates when delivery attempts fail with retryable conditions. The delivery engine analyzes the HTTP response code to determine whether the failure warrants a retry attempt - 5xx server errors and 429 rate limiting responses trigger retry logic, while 4xx client errors (except 429) are considered permanent failures that should not be retried. For retryable failures, the system calculates the next delivery attempt time using `calculate_retry_delay()` with exponential backoff and jitter. The delivery request is updated with the new attempt timestamp and returned to the delivery queue for future processing. This continues until either the delivery succeeds, the maximum retry limit (`MAX_RETRY_ATTEMPTS`) is reached, or the circuit breaker opens due to repeated failures.\n\n| Flow Stage | Input | Processing | Output | Persistence |\n|------------|-------|------------|--------|------------|\n| Event Ingestion | External event + metadata | Webhook lookup, signature generation | Signed delivery requests | Queue entries created |\n| Queue Processing | Delivery request from queue | Circuit breaker check, HTTP delivery | Delivery result + timing | Attempt logged |\n| Retry Scheduling | Failed delivery result | Status code analysis, backoff calculation | Rescheduled delivery request | Queue entry updated |\n| Circuit Breaker Update | Delivery success/failure | Failure counter update, state evaluation | Circuit state change | Circuit state persisted |\n| Dead Letter Routing | Exhausted retry attempts | Final failure classification | Dead letter entry | Manual review queue |\n\nThe **failure handling flow** ensures that delivery failures are properly classified and routed for appropriate handling. When a delivery attempt fails, the circuit breaker component records the failure against the target endpoint and evaluates whether the failure rate has exceeded the configured threshold. If so, the circuit breaker transitions to the open state, temporarily halting all deliveries to that endpoint and triggering alerting to notify the webhook owner of the service degradation. Meanwhile, the specific failed delivery request continues through the retry logic until it either succeeds, exhausts all retry attempts, or is blocked by the circuit breaker. Delivery requests that exhaust all retry attempts are routed to the dead letter queue, where they remain available for manual inspection and potential replay once the underlying issues are resolved.\n\nThe **monitoring and alerting flow** operates continuously in the background, providing observability into system health and delivery performance. The event logger component aggregates delivery metrics, tracking success rates, response times, and error patterns across all registered endpoints. When circuit breakers open or delivery queues begin backing up, the system generates alerts to notify operators of potential issues. The comprehensive logging also enables debugging of delivery failures, providing operators with complete visibility into request payloads, response headers, and timing information for every delivery attempt.\n\n> **Ordering Guarantee Implementation**: The system maintains per-endpoint ordering by using a separate queue partition for each registered webhook endpoint. This allows parallel processing across different endpoints while ensuring that events for a specific endpoint are processed in the order they were received.\n\n### Deployment Architecture\n\nThe webhook delivery system is designed as a scalable, cloud-native application that can be deployed across various environments while maintaining consistent behavior and reliability guarantees. The deployment architecture emphasizes operational simplicity while providing the flexibility to scale individual components based on traffic patterns and performance requirements.\n\n> **Decision: Single-Process Multi-Component Deployment**\n> - **Context**: The system needs to balance operational complexity with scalability requirements. Options include microservices (high operational overhead), serverless functions (limited control over retry timing), or component-based monolith.\n> - **Options Considered**: Kubernetes microservices, AWS Lambda + SQS, single process with worker threads\n> - **Decision**: Single process with worker threads and horizontal scaling\n> - **Rationale**: Minimizes operational complexity while providing good performance and scalability. Components share database connections and memory efficiently. Circuit breaker state remains consistent within each process instance.\n> - **Consequences**: Simplified deployment and debugging at the cost of fine-grained component scaling. All components scale together rather than independently.\n\nThe **application tier** consists of one or more instances of the webhook delivery service, each running as a single process containing all four system components. Each service instance operates multiple worker threads: registration handlers for processing webhook registration requests, delivery workers for consuming from the delivery queue, and monitoring threads for circuit breaker evaluation and health checking. The application processes are stateless, storing all persistent data in the shared database and queue infrastructure. This design enables horizontal scaling by simply adding more service instances when delivery volume increases, with load balancing handled automatically through the shared queue mechanism.\n\n| Service Component | Resource Requirements | Scaling Characteristics | Failure Impact |\n|------------------|----------------------|------------------------|----------------|\n| Registration Handler | Low CPU, moderate memory | Scales with registration requests | New registrations rejected, existing unaffected |\n| Delivery Workers | Moderate CPU, low memory | Scales with delivery volume | Delivery queue backs up, no data loss |\n| Circuit Breaker Monitor | Low CPU, low memory | Constant regardless of volume | Failure protection disabled temporarily |\n| Event Logger | Low CPU, high I/O | Scales with delivery attempts | Debugging capability reduced |\n\nThe **data tier** provides persistent storage for all system state through a combination of a relational database and message queue infrastructure. The primary database stores webhook registrations, delivery attempt history, and circuit breaker state using a schema optimized for the access patterns of each component. The `WebhookRegistration` table includes indexes on URL and event type for efficient webhook lookups during event ingestion. The `DeliveryAttempt` table is partitioned by timestamp to support efficient time-range queries for debugging while maintaining write performance for high-volume delivery logging. The message queue infrastructure handles the delivery queue with persistence guarantees, ensuring that queued delivery requests survive system restarts and process failures.\n\nThe **infrastructure tier** includes supporting services required for production operation: monitoring and alerting systems that track delivery success rates and queue depths, log aggregation systems that collect application logs for debugging and compliance, and secrets management systems that handle the rotation of webhook signing keys. The deployment also includes HTTP load balancers for distributing registration requests across service instances, and database connection pooling to efficiently manage database connections across multiple worker threads and service instances.\n\n```\nProduction Deployment Layout:\n\n┌─────────────────────────────┐\n│     Load Balancer           │\n│  (Registration API)         │\n└──────────┬──────────────────┘\n           │\n    ┌──────▼──────┐    ┌─────────────┐    ┌─────────────┐\n    │   Instance  │    │  Instance   │    │  Instance   │\n    │     #1      │    │     #2      │    │     #3      │\n    │ ┌─────────┐ │    │ ┌─────────┐ │    │ ┌─────────┐ │\n    │ │Registry │ │    │ │Registry │ │    │ │Registry │ │\n    │ │Delivery │ │    │ │Delivery │ │    │ │Delivery │ │\n    │ │Circuit  │ │    │ │Circuit  │ │    │ │Circuit  │ │\n    │ │Logger   │ │    │ │Logger   │ │    │ │Logger   │ │\n    │ └─────────┘ │    │ └─────────┘ │    │ └─────────┘ │\n    └──────┬──────┘    └──────┬──────┘    └──────┬──────┘\n           │                  │                  │\n           └──────────────────┼──────────────────┘\n                              │\n    ┌─────────────────────────▼─────────────────────────┐\n    │              Shared Data Layer                    │\n    │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐  │\n    │ │  Database   │ │ Message     │ │   Redis     │  │\n    │ │(PostgreSQL) │ │ Queue       │ │ (Circuit    │  │\n    │ │             │ │ (RabbitMQ)  │ │  State)     │  │\n    │ └─────────────┘ └─────────────┘ └─────────────┘  │\n    └───────────────────────────────────────────────────┘\n```\n\nThe **configuration management** approach uses environment-based configuration with sensible defaults for all timing and threshold parameters. The `WebhookConfig` dataclass encapsulates all configurable parameters including database connection strings, retry parameters (`MAX_RETRY_ATTEMPTS`, base delay values), circuit breaker thresholds (`CIRCUIT_BREAKER_FAILURE_THRESHOLD`), and timeout values (`DELIVERY_TIMEOUT`). This configuration approach enables the same application binary to be deployed across development, staging, and production environments with environment-specific parameter tuning.\n\n| Environment | Database | Queue | Instance Count | Special Configuration |\n|-------------|----------|-------|----------------|----------------------|\n| Development | SQLite | In-memory | 1 | Reduced timeouts, verbose logging |\n| Staging | PostgreSQL | RabbitMQ | 2 | Production timeouts, integration test endpoints |\n| Production | PostgreSQL (HA) | RabbitMQ (Cluster) | 3-10 | Security hardening, monitoring integration |\n\nThe **monitoring and observability** deployment includes comprehensive metrics collection and alerting configured to track the health of each system component. Key metrics include delivery success rates per endpoint, queue depths for early detection of processing bottlenecks, circuit breaker state changes to identify problematic endpoints, and end-to-end delivery latency to monitor system performance. The deployment integrates with standard observability tools, exposing metrics in Prometheus format and structured logs compatible with centralized logging systems.\n\n> **Scalability Considerations**: The system's bottleneck is typically HTTP delivery throughput rather than queue processing or database operations. Each service instance can handle approximately 100-200 concurrent HTTP deliveries, with actual throughput depending on target endpoint response times. Scaling decisions should be based on delivery queue depth and worker thread utilization rather than CPU or memory usage.\n\nThe **security hardening** for production deployment includes network-level protections against SSRF attacks through firewall rules that prevent webhook deliveries to private IP ranges, secure secrets management for webhook signing keys with automatic rotation capabilities, and comprehensive audit logging of all registration and delivery activities. The deployment also includes rate limiting at the load balancer level to protect against registration abuse and DDoS attacks against the registration API.\n\n### Common Architecture Pitfalls\n\n⚠️ **Pitfall: Shared Circuit Breaker State Across Instances**\nWhen deploying multiple service instances, a common mistake is failing to synchronize circuit breaker state across instances. This leads to inconsistent behavior where some instances block deliveries to a failing endpoint while others continue attempting delivery. The circuit breaker state must be stored in a shared location (Redis or database) with proper locking to ensure all instances see consistent endpoint health status. Implement circuit breaker state as a shared resource with atomic updates and cache invalidation to maintain consistency.\n\n⚠️ **Pitfall: Database Connection Exhaustion Under Load**\nEach delivery worker thread requires database connections for logging delivery attempts and updating circuit breaker state. Without proper connection pooling, high delivery volumes can exhaust the database connection limit, causing new delivery attempts to fail. The `DatabaseManager` must implement connection pooling with appropriate sizing based on the number of worker threads across all instances. Size the connection pool to handle peak load plus a safety margin, and implement connection retry logic for transient connection failures.\n\n⚠️ **Pitfall: Queue Message Loss During Process Restarts**\nIf delivery workers don't properly acknowledge message consumption, queued delivery requests can be lost during process restarts or crashes. This violates the at-least-once delivery guarantee. Implement proper message acknowledgment patterns where messages are only acknowledged after successful delivery or after being placed in the dead letter queue. Use manual acknowledgment mode in the message queue configuration rather than auto-acknowledgment.\n\n⚠️ **Pitfall: Unbounded Queue Growth from Circuit Breaker Backlog**\nWhen circuit breakers open for popular endpoints, delivery requests continue to accumulate in the queue without being processed. This can lead to memory exhaustion or disk space issues if the queue grows unboundedly. Implement queue depth monitoring with alerting, and consider implementing backpressure mechanisms that temporarily halt event ingestion when queue depths exceed safe thresholds. The dead letter queue also needs size limits and retention policies.\n\n⚠️ **Pitfall: Inconsistent Timing Between Development and Production**\nDevelopment environments often use shorter timeout values and retry intervals for faster testing, but forgetting to adjust these values for production can lead to premature delivery failures or excessive retry attempts. The `WebhookConfig` must include environment-specific defaults, and deployment automation should validate that production configurations use appropriate values for `DELIVERY_TIMEOUT`, retry intervals, and circuit breaker thresholds.\n\n### Implementation Guidance\n\nThe webhook delivery system implementation requires careful attention to concurrent programming patterns, reliable message processing, and robust error handling. This section provides practical guidance for building each architectural component with production-ready reliability and performance characteristics.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option | Production Considerations |\n|-----------|---------------|-----------------|-------------------------|\n| Database | SQLite with WAL mode | PostgreSQL with connection pooling | PostgreSQL required for multi-instance deployment |\n| Message Queue | Redis Lists with blocking pop | RabbitMQ with persistent queues | RabbitMQ provides better ordering guarantees |\n| HTTP Client | `requests` with session pooling | `httpx` with async support | Connection pooling essential for performance |\n| Configuration | Environment variables | `pydantic` settings with validation | Validation prevents runtime configuration errors |\n| Logging | Python `logging` module | Structured logging with `structlog` | Structured logs essential for debugging |\n| Monitoring | Simple metrics collection | Prometheus metrics with alerting | Required for production observability |\n\n#### Recommended File Structure\n\n```\nwebhook-delivery-system/\n├── main.py                          ← Application entry point\n├── config.py                        ← WebhookConfig and environment handling\n├── models/                          ← Data models and database schemas\n│   ├── __init__.py\n│   ├── webhook.py                   ← WebhookRegistration model\n│   └── delivery.py                  ← DeliveryAttempt model\n├── components/                      ← Core system components\n│   ├── __init__.py\n│   ├── registry.py                  ← Webhook registration and verification\n│   ├── delivery_engine.py           ← Queue processing and HTTP delivery\n│   ├── circuit_breaker.py           ← Endpoint health monitoring\n│   └── event_logger.py              ← Delivery audit and replay\n├── infrastructure/                  ← Supporting infrastructure\n│   ├── __init__.py\n│   ├── database.py                  ← DatabaseManager and connection pooling\n│   ├── queue.py                     ← Message queue abstraction\n│   └── http_client.py               ← WebhookHTTPClient with connection pooling\n├── tests/                          ← Test suite\n│   ├── test_registry.py\n│   ├── test_delivery_engine.py\n│   ├── test_circuit_breaker.py\n│   └── integration/\n└── scripts/                        ← Operational scripts\n    ├── migrate_db.py\n    └── replay_events.py\n```\n\n#### Infrastructure Starter Code\n\nThe following infrastructure components provide the foundation for the webhook delivery system. These are complete, production-ready implementations that handle connection pooling, error recovery, and resource management.\n\n**Database Connection Manager (`infrastructure/database.py`):**\n```python\nimport psycopg2\nfrom psycopg2 import pool\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom typing import Generator\nimport threading\nimport logging\n\n@dataclass\nclass DatabaseConfig:\n    host: str\n    port: int\n    database: str\n    username: str\n    password: str\n    min_connections: int = 2\n    max_connections: int = 20\n\nclass DatabaseManager:\n    \"\"\"Thread-safe database connection pool manager.\"\"\"\n    \n    def __init__(self, config: DatabaseConfig):\n        self.config = config\n        self._pool = None\n        self._lock = threading.Lock()\n        self._initialize_pool()\n    \n    def _initialize_pool(self):\n        \"\"\"Initialize the connection pool with retry logic.\"\"\"\n        try:\n            self._pool = psycopg2.pool.ThreadedConnectionPool(\n                minconn=self.config.min_connections,\n                maxconn=self.config.max_connections,\n                host=self.config.host,\n                port=self.config.port,\n                database=self.config.database,\n                user=self.config.username,\n                password=self.config.password,\n                # Connection pool configuration for reliability\n                cursor_factory=psycopg2.extras.RealDictCursor,\n                connect_timeout=10,\n                application_name=\"webhook-delivery-system\"\n            )\n            logging.info(\"Database connection pool initialized\")\n        except Exception as e:\n            logging.error(f\"Failed to initialize database pool: {e}\")\n            raise\n    \n    @contextmanager\n    def get_connection(self) -> Generator[psycopg2.extensions.connection, None, None]:\n        \"\"\"Get a database connection from the pool with automatic cleanup.\"\"\"\n        connection = None\n        try:\n            with self._lock:\n                connection = self._pool.getconn()\n            yield connection\n        except Exception as e:\n            if connection:\n                connection.rollback()\n            raise\n        finally:\n            if connection:\n                with self._lock:\n                    self._pool.putconn(connection)\n    \n    def health_check(self) -> bool:\n        \"\"\"Verify database connectivity for health monitoring.\"\"\"\n        try:\n            with self.get_connection() as conn:\n                with conn.cursor() as cursor:\n                    cursor.execute(\"SELECT 1\")\n                    return True\n        except Exception as e:\n            logging.error(f\"Database health check failed: {e}\")\n            return False\n```\n\n**HTTP Client with Connection Pooling (`infrastructure/http_client.py`):**\n```python\nimport requests\nimport time\nimport logging\nfrom typing import Tuple, Optional\nfrom urllib.parse import urlparse\nfrom dataclasses import dataclass\n\n@dataclass\nclass HTTPResponse:\n    status_code: int\n    response_time: float\n    error_message: Optional[str] = None\n    headers: Optional[dict] = None\n\nclass WebhookHTTPClient:\n    \"\"\"HTTP client optimized for webhook delivery with connection pooling.\"\"\"\n    \n    def __init__(self, timeout: int = 30, max_retries: int = 0):\n        self.timeout = timeout\n        self.session = requests.Session()\n        \n        # Configure connection pooling for better performance\n        adapter = requests.adapters.HTTPAdapter(\n            pool_connections=20,  # Number of connection pools to cache\n            pool_maxsize=100,     # Maximum connections per pool\n            max_retries=max_retries\n        )\n        self.session.mount('http://', adapter)\n        self.session.mount('https://', adapter)\n        \n        # Set default headers for webhook deliveries\n        self.session.headers.update({\n            'Content-Type': 'application/json',\n            'User-Agent': 'WebhookDeliverySystem/1.0'\n        })\n    \n    def deliver_webhook(self, url: str, payload: str, signature: str) -> HTTPResponse:\n        \"\"\"Deliver webhook payload with signature authentication.\"\"\"\n        headers = {\n            'X-Webhook-Signature-256': f'sha256={signature}',\n            'X-Webhook-Timestamp': str(int(time.time())),\n            'X-Webhook-Delivery-ID': self._generate_delivery_id()\n        }\n        \n        start_time = time.time()\n        try:\n            response = self.session.post(\n                url, \n                data=payload.encode('utf-8'),\n                headers=headers,\n                timeout=self.timeout,\n                allow_redirects=False  # Security: don't follow redirects\n            )\n            \n            response_time = time.time() - start_time\n            \n            return HTTPResponse(\n                status_code=response.status_code,\n                response_time=response_time,\n                headers=dict(response.headers)\n            )\n            \n        except requests.exceptions.Timeout:\n            response_time = time.time() - start_time\n            return HTTPResponse(\n                status_code=0,  # Special code for timeout\n                response_time=response_time,\n                error_message=\"Request timeout\"\n            )\n        except requests.exceptions.ConnectionError as e:\n            response_time = time.time() - start_time\n            return HTTPResponse(\n                status_code=0,  # Special code for connection error\n                response_time=response_time,\n                error_message=f\"Connection error: {str(e)}\"\n            )\n        except Exception as e:\n            response_time = time.time() - start_time\n            return HTTPResponse(\n                status_code=0,\n                response_time=response_time,\n                error_message=f\"Unexpected error: {str(e)}\"\n            )\n    \n    def _generate_delivery_id(self) -> str:\n        \"\"\"Generate unique delivery ID for tracking.\"\"\"\n        import uuid\n        return str(uuid.uuid4())\n    \n    def validate_url(self, url: str) -> bool:\n        \"\"\"Validate webhook URL for security (SSRF protection).\"\"\"\n        try:\n            parsed = urlparse(url)\n            \n            # Must use HTTPS in production\n            if parsed.scheme != 'https':\n                return False\n            \n            # Block private IP ranges to prevent SSRF\n            import ipaddress\n            try:\n                ip = ipaddress.ip_address(parsed.hostname)\n                if ip.is_private or ip.is_loopback:\n                    return False\n            except ValueError:\n                # Hostname is not an IP address, DNS resolution will be handled by requests\n                pass\n            \n            return True\n        except Exception:\n            return False\n```\n\n#### Core Component Skeletons\n\n**Webhook Registry Component (`components/registry.py`):**\n```python\nfrom typing import Dict, Optional, List\nfrom datetime import datetime\nimport secrets\nimport hmac\nimport hashlib\nimport json\n\nclass WebhookRegistry:\n    \"\"\"Manages webhook endpoint registration and signature verification.\"\"\"\n    \n    def __init__(self, db_manager, http_client):\n        self.db = db_manager\n        self.http_client = http_client\n    \n    def register_webhook(self, url: str, events: List[str], owner_id: str) -> dict:\n        \"\"\"Register a new webhook endpoint with ownership verification.\n        \n        Returns:\n            dict: Registration result with webhook_id and verification status\n        \"\"\"\n        # TODO 1: Validate the webhook URL using http_client.validate_url()\n        # TODO 2: Generate a cryptographically secure webhook secret using generate_webhook_secret()\n        # TODO 3: Store WebhookRegistration record in database with verified=False\n        # TODO 4: Initiate ownership verification process\n        # TODO 5: Return registration response with webhook_id and next steps\n        # Hint: Use uuid.uuid4() for webhook_id generation\n        pass\n    \n    def verify_webhook_ownership(self, webhook_id: str) -> bool:\n        \"\"\"Send challenge request to verify endpoint ownership.\n        \n        Args:\n            webhook_id: UUID of the webhook to verify\n            \n        Returns:\n            bool: True if verification succeeds, False otherwise\n        \"\"\"\n        # TODO 1: Retrieve webhook registration from database\n        # TODO 2: Generate verification challenge token\n        # TODO 3: Send HTTP GET request with challenge parameter\n        # TODO 4: Validate the response contains expected challenge echo\n        # TODO 5: Update webhook registration with verified=True on success\n        # Hint: Challenge should be in query parameters: ?webhook_challenge=TOKEN\n        pass\n    \n    def generate_webhook_secret(self) -> str:\n        \"\"\"Generate cryptographically secure signing key for webhook authentication.\"\"\"\n        # TODO 1: Use secrets.token_urlsafe() to generate 32 bytes of randomness\n        # TODO 2: Ensure the secret is suitable for HMAC-SHA256 operations\n        # Hint: 32 bytes provides 256 bits of entropy, same as SHA256 output\n        pass\n    \n    def generate_hmac_signature(self, payload: str, secret: str) -> str:\n        \"\"\"Compute HMAC-SHA256 signature for payload authentication.\n        \n        Args:\n            payload: JSON string to be signed\n            secret: Webhook signing secret\n            \n        Returns:\n            str: Hex-encoded HMAC signature\n        \"\"\"\n        # TODO 1: Create HMAC instance with SHA256 hash function\n        # TODO 2: Update HMAC with payload bytes (ensure UTF-8 encoding)\n        # TODO 3: Return hexadecimal digest of the signature\n        # Hint: Use hmac.new(secret.encode(), payload.encode(), hashlib.sha256)\n        pass\n```\n\n**Delivery Engine Component (`components/delivery_engine.py`):**\n```python\nimport random\nimport time\nimport logging\nfrom typing import Tuple, Optional\nfrom datetime import datetime, timedelta\n\nclass DeliveryEngine:\n    \"\"\"Handles queued delivery processing with exponential backoff retry logic.\"\"\"\n    \n    def __init__(self, db_manager, http_client, registry, circuit_breaker, logger):\n        self.db = db_manager\n        self.http_client = http_client\n        self.registry = registry\n        self.circuit_breaker = circuit_breaker\n        self.event_logger = logger\n    \n    def process_delivery(self, event_id: str, webhook_id: str, payload: str) -> bool:\n        \"\"\"Process a single webhook delivery with complete error handling.\n        \n        Args:\n            event_id: Unique identifier for the event being delivered\n            webhook_id: Target webhook endpoint identifier\n            payload: JSON payload to deliver\n            \n        Returns:\n            bool: True if delivery succeeded, False if failed/should retry\n        \"\"\"\n        # TODO 1: Check circuit breaker status for the target endpoint\n        # TODO 2: Retrieve webhook registration details (URL, secret, verification status)\n        # TODO 3: Generate HMAC signature for the payload\n        # TODO 4: Attempt HTTP delivery using http_client.deliver_webhook()\n        # TODO 5: Log the delivery attempt with event_logger\n        # TODO 6: Update circuit breaker with success/failure result\n        # TODO 7: Return success status for retry decision logic\n        # Hint: Only attempt delivery if circuit breaker allows and webhook is verified\n        pass\n    \n    def deliver_webhook(self, url: str, payload: str, signature: str) -> Tuple[int, float, Optional[str]]:\n        \"\"\"Execute HTTP webhook delivery with timeout and error handling.\n        \n        Args:\n            url: Target endpoint URL\n            payload: JSON payload string\n            signature: HMAC signature for authentication\n            \n        Returns:\n            Tuple of (status_code, response_time_seconds, error_message)\n        \"\"\"\n        # TODO 1: Use http_client to perform the POST request\n        # TODO 2: Handle timeout and connection errors appropriately\n        # TODO 3: Return structured response information for retry logic\n        # Hint: This method delegates to WebhookHTTPClient but adds delivery-specific logic\n        pass\n    \n    def calculate_retry_delay(self, attempt_number: int, base_delay: int = 60) -> int:\n        \"\"\"Calculate exponential backoff delay with jitter for retry scheduling.\n        \n        Args:\n            attempt_number: Current retry attempt (1-based)\n            base_delay: Base delay in seconds for first retry\n            \n        Returns:\n            int: Delay in seconds before next retry attempt\n        \"\"\"\n        # TODO 1: Calculate exponential backoff: base_delay * (2 ** (attempt_number - 1))\n        # TODO 2: Add random jitter to prevent thundering herd (±25% of calculated delay)\n        # TODO 3: Cap maximum delay at reasonable value (e.g., 1 hour = 3600 seconds)\n        # TODO 4: Return final delay value\n        # Hint: Use random.uniform() for jitter: delay * random.uniform(0.75, 1.25)\n        pass\n    \n    def should_retry_delivery(self, status_code: int, attempt_number: int) -> bool:\n        \"\"\"Determine if delivery failure should trigger retry based on response.\n        \n        Args:\n            status_code: HTTP response status code from delivery attempt\n            attempt_number: Current attempt number\n            \n        Returns:\n            bool: True if delivery should be retried, False otherwise\n        \"\"\"\n        # TODO 1: Check if maximum retry attempts have been exceeded\n        # TODO 2: Classify status codes: 5xx and 429 are retryable, 4xx are not\n        # TODO 3: Handle special case of status_code=0 (network/timeout errors)\n        # TODO 4: Return retry decision\n        # Hint: Don't retry 4xx errors except 429 (Too Many Requests)\n        pass\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Checkpoint - Webhook Registration:**\n```bash\n# Test webhook registration API\npython -m pytest tests/test_registry.py::test_webhook_registration -v\n\n# Manual verification steps:\n# 1. Start the application: python main.py\n# 2. Register a webhook: curl -X POST localhost:8000/webhooks -d '{\"url\":\"https://example.com/webhook\",\"events\":[\"user.created\"]}'\n# 3. Verify the response includes webhook_id and verification challenge instructions\n# 4. Check database for WebhookRegistration record with verified=False\n# 5. Simulate ownership verification and verify the record updates to verified=True\n```\n\nExpected behavior: Registration creates database record, generates secure secret, initiates ownership verification process. HMAC signature generation produces consistent signatures for the same payload and secret.\n\n**Milestone 2 Checkpoint - Delivery Processing:**\n```bash\n# Test delivery engine with mock endpoints\npython -m pytest tests/test_delivery_engine.py::test_exponential_backoff -v\npython -m pytest tests/test_delivery_engine.py::test_retry_logic -v\n\n# Manual verification with test server:\n# 1. Start test webhook endpoint: python scripts/test_webhook_server.py\n# 2. Register webhook pointing to test server\n# 3. Send test event and verify delivery appears in test server logs\n# 4. Stop test server and verify retry attempts with exponential backoff\n# 5. Restart test server and verify eventual successful delivery\n```\n\nExpected behavior: Delivery attempts follow exponential backoff pattern, failed deliveries are retried based on status codes, successful deliveries are logged and removed from retry queue.\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Webhooks not being delivered | Circuit breaker opened | Check circuit breaker state in Redis/database | Manually reset circuit breaker or fix endpoint |\n| Exponential backoff not working | Jitter calculation error | Log actual delay values vs expected | Verify jitter calculation uses proper bounds |\n| Database connection exhausted | Too many concurrent workers | Monitor connection pool usage | Increase pool size or reduce worker threads |\n| HMAC signature verification fails | Timestamp/payload mismatch | Log exact payload and timestamp used | Ensure consistent payload serialization |\n| Queue backing up under load | Slow HTTP deliveries | Monitor delivery response times | Increase timeout or worker concurrency |\n\n\n## Data Model\n\n> **Milestone(s):** Foundation for all milestones - data entities established here are used in webhook registration (Milestone 1), delivery tracking (Milestone 2), circuit breaker state (Milestone 3), and event logging (Milestone 4)\n\n### Mental Model: The Digital Postal Service Database\n\nThink of the webhook delivery system's data model as the filing system for a sophisticated digital postal service. Just as a postal service maintains customer registrations (addresses, preferences, delivery instructions), delivery logs (tracking numbers, attempts, status updates), and operational state (route health, capacity limits), our webhook system needs structured data to track three core entities: registered webhook endpoints, events awaiting or completing delivery, and the detailed history of every delivery attempt.\n\nThe data model serves as the authoritative record for the entire system's state. Unlike a traditional postal service that might lose a package or delivery record, our digital system maintains complete audit trails and guarantees no data loss through persistent storage and careful relationship modeling.\n\n![Data Model Relationships](./diagrams/data-model.svg)\n\nThe data model consists of three primary entity types that capture the complete lifecycle of webhook delivery. The `WebhookRegistration` entity represents customer-registered endpoints with their security credentials and event preferences. The `WebhookEvent` entity represents individual messages that need delivery, containing payloads and targeting information. The `DeliveryAttempt` entity provides the detailed audit trail of every delivery attempt, successful or failed, creating an immutable history for debugging and compliance.\n\n> **Decision: Normalized Relational Design vs Denormalized Event Store**\n> - **Context**: Webhook systems need to balance query performance, data consistency, and audit requirements while handling high-volume delivery operations\n> - **Options Considered**: Normalized relational tables, denormalized event sourcing, hybrid approach with separate OLTP/OLAP stores\n> - **Decision**: Normalized relational design with immutable delivery attempt records\n> - **Rationale**: Provides strong consistency for webhook configuration, efficient querying for delivery status, and complete audit trails without data duplication. Event sourcing would complicate simple operations like \"show all webhooks for this customer\"\n> - **Consequences**: Excellent data integrity and debugging capability, slightly more complex queries for analytics, straightforward implementation with standard SQL databases\n\nThe relationship design enforces data integrity while supporting the system's operational needs. Each webhook registration can receive multiple events, and each event generates multiple delivery attempts over time. This one-to-many relationship structure naturally supports the retry logic and audit requirements while preventing orphaned records that could lead to data inconsistencies.\n\n### Webhook Registration Model\n\nThe webhook registration model captures everything needed to securely and reliably deliver events to customer endpoints. This model serves as the foundation for endpoint security, event filtering, and delivery targeting throughout the system's operation.\n\n![Registration Sequence](./diagrams/registration-sequence.svg)\n\n| Field | Type | Description |\n|-------|------|-------------|\n| id | str | UUID primary key uniquely identifying this webhook registration |\n| url | str | HTTPS endpoint URL where events will be delivered via HTTP POST |\n| secret | str | Cryptographically secure signing key for HMAC-SHA256 payload signatures |\n| events | list[str] | Event type subscriptions determining which events this endpoint receives |\n| verified | bool | Ownership verification status indicating endpoint control confirmation |\n| created_at | datetime | Registration timestamp for audit trails and debugging |\n| updated_at | datetime | Last modification timestamp tracking configuration changes |\n| active | bool | Operational status allowing temporary endpoint disabling |\n| failure_count | int | Consecutive failure counter for circuit breaker state tracking |\n| circuit_state | str | Current circuit breaker state: \"closed\", \"open\", or \"half-open\" |\n| last_success_at | datetime | Most recent successful delivery timestamp for health monitoring |\n| rate_limit_rpm | int | Delivery rate limit in requests per minute for this endpoint |\n| metadata | json | Extensible key-value pairs for customer-specific configuration |\n\nThe `WebhookRegistration` model balances security requirements with operational flexibility. The `secret` field contains a cryptographically random 32-byte key encoded as a hex string, providing sufficient entropy for HMAC signature security. The `events` field uses a simple string array rather than a complex subscription model, making event filtering straightforward while remaining extensible for future event type additions.\n\n> **Decision: Embedded Circuit Breaker State vs Separate State Table**\n> - **Context**: Circuit breaker functionality requires persistent state tracking per webhook endpoint\n> - **Options Considered**: Store circuit state in webhook table, separate circuit_breaker_state table, in-memory state only\n> - **Decision**: Embed circuit breaker fields directly in webhook registration table\n> - **Rationale**: Circuit breaker state is tightly coupled to webhook identity, embedded approach reduces join complexity and ensures state persistence across service restarts\n> - **Consequences**: Simpler queries and stronger consistency, slightly denormalized design, circuit state survives service restarts automatically\n\nThe verification mechanism uses the `verified` boolean to track ownership confirmation through challenge-response validation. Unverified webhooks remain in the database but cannot receive event deliveries, preventing unauthorized endpoint registration while allowing customers to complete the verification process at their convenience.\n\n**URL Validation and SSRF Protection**\n\nThe webhook URL undergoes strict validation to prevent server-side request forgery (SSRF) attacks and ensure delivery reliability. The validation process checks that URLs use HTTPS protocol exclusively, resolve to public IP addresses, and respond appropriately to challenge requests during ownership verification.\n\n| Validation Rule | Purpose | Implementation |\n|-----------------|---------|----------------|\n| HTTPS Only | Prevents credential interception | Reject any URL not starting with `https://` |\n| Public IP Only | SSRF attack prevention | Resolve hostname and block private/internal IP ranges |\n| Valid Hostname | DNS security | Validate hostname format and successful resolution |\n| Reachable Endpoint | Delivery viability | Test HTTP connectivity during registration |\n| Challenge Response | Ownership proof | Send unique token and verify correct response |\n\nThe SSRF protection specifically blocks delivery to private IP ranges (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16), localhost (127.0.0.0/8), and other reserved ranges to prevent internal network access through webhook delivery requests.\n\n### Event Model\n\nThe event model represents individual messages queued for webhook delivery, capturing both the payload data and the delivery orchestration metadata required for reliable processing.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| id | str | UUID primary key uniquely identifying this event across the system |\n| event_type | str | Event classification used for webhook subscription filtering |\n| payload | json | Event data payload delivered to matching webhook endpoints |\n| source | str | Originating system or service that generated this event |\n| created_at | datetime | Event creation timestamp for ordering and audit purposes |\n| webhook_id | str | Foreign key referencing the target webhook registration |\n| delivery_status | str | Current status: \"pending\", \"delivered\", \"failed\", \"dead_letter\" |\n| scheduled_at | datetime | Next delivery attempt timestamp for retry scheduling |\n| attempt_count | int | Number of delivery attempts made for this event |\n| signature | str | Pre-computed HMAC-SHA256 signature for delivery authentication |\n| idempotency_key | str | Unique identifier enabling safe event replay and deduplication |\n| priority | int | Delivery priority level for queue processing order (1=highest, 5=lowest) |\n| expires_at | datetime | Event expiration timestamp after which delivery stops |\n| metadata | json | Additional event context and customer-specific fields |\n\nThe event model supports the complete delivery lifecycle from initial queuing through final disposition. The `delivery_status` field provides clear state tracking, while `scheduled_at` enables precise retry timing control using exponential backoff calculations.\n\n> **Decision: Pre-computed Signatures vs Dynamic Generation**\n> - **Context**: HMAC signatures must be calculated for every delivery attempt, potentially creating computational overhead\n> - **Options Considered**: Calculate signatures on-demand during delivery, pre-compute and store signatures, hybrid caching approach\n> - **Decision**: Pre-compute signatures during event creation and store in event record\n> - **Rationale**: Reduces delivery latency by eliminating signature calculation from the critical path, simplifies delivery worker logic, signatures rarely change after event creation\n> - **Consequences**: Slightly increased storage requirements, faster delivery processing, simpler worker implementation, signatures survive service restarts\n\nThe `idempotency_key` serves dual purposes: enabling safe event replay for debugging and providing downstream endpoints with deduplication capabilities. When events are replayed through the system, they receive new event IDs but retain the same idempotency key, allowing receiving systems to detect and ignore duplicate deliveries.\n\n**Event Lifecycle States**\n\nEvents transition through a well-defined state machine that governs delivery processing and error handling:\n\n| Current State | Trigger Event | Next State | Actions Taken |\n|---------------|---------------|------------|---------------|\n| pending | delivery_attempted | pending | Increment attempt_count, update scheduled_at with backoff delay |\n| pending | delivery_succeeded | delivered | Set final status, record success timestamp |\n| pending | max_attempts_reached | failed | Move to dead letter queue, alert operations |\n| pending | circuit_breaker_open | pending | Delay scheduling until circuit recovers |\n| failed | manual_replay | pending | Reset attempt_count, generate new delivery_id |\n| delivered | manual_replay | pending | Create new event instance with same idempotency_key |\n\nThe state transitions ensure events never become lost or forgotten within the system. Failed events remain queryable for debugging, while delivered events provide an audit trail of successful operations.\n\n### Delivery Tracking Model\n\nThe delivery tracking model provides comprehensive audit trails and debugging information for every webhook delivery attempt, creating an immutable record of system behavior that supports troubleshooting and compliance requirements.\n\n![Delivery Sequence](./diagrams/delivery-sequence.svg)\n\n| Field | Type | Description |\n|-------|------|-------------|\n| id | str | UUID primary key uniquely identifying this delivery attempt |\n| event_id | str | Foreign key linking to the webhook event being delivered |\n| webhook_id | str | Foreign key referencing the target webhook registration |\n| attempt_number | int | Sequential attempt counter starting from 1 for each event |\n| status_code | int | HTTP response status code returned by the webhook endpoint |\n| response_time | float | Request duration in seconds from send to response completion |\n| response_headers | json | HTTP response headers returned by the endpoint |\n| response_body | str | Response payload body for debugging failed deliveries |\n| error_message | str | Error description for failed attempts (timeouts, connection errors) |\n| attempted_at | datetime | Precise timestamp when this delivery attempt was initiated |\n| completed_at | datetime | Timestamp when response was received or error occurred |\n| request_headers | json | Complete HTTP headers sent with the delivery request |\n| request_payload | str | Exact payload delivered to the endpoint for audit purposes |\n| delivery_duration | int | Total processing time including queue delays and retries |\n| worker_instance | str | Identifier of the worker process handling this delivery |\n| circuit_breaker_triggered | bool | Whether this attempt triggered circuit breaker activation |\n\nThe `DeliveryAttempt` model captures every detail necessary for comprehensive debugging and system monitoring. Unlike the mutable event model, delivery attempt records remain immutable after creation, providing a trustworthy audit trail that supports both automated monitoring and manual investigation.\n\n> **Decision: Immutable Attempt Records vs Mutable Status Updates**\n> - **Context**: Delivery attempts need detailed logging for debugging while supporting efficient status queries\n> - **Options Considered**: Update single delivery record with latest status, create immutable attempt record per delivery, hybrid with summary + detail tables\n> - **Decision**: Create immutable delivery attempt record for every delivery try\n> - **Rationale**: Provides complete audit trail for compliance and debugging, prevents accidental data loss, supports detailed analytics on delivery patterns\n> - **Consequences**: Higher storage requirements, complete debugging capability, slight complexity in \"current status\" queries\n\nThe delivery tracking model supports advanced debugging scenarios by preserving complete request and response information. When webhook deliveries fail due to endpoint issues, developers can examine the exact headers, payload, and response to identify integration problems without reproducing the original event.\n\n**Response Classification and Retry Logic**\n\nThe delivery tracking model supports sophisticated retry logic through detailed response classification:\n\n| Status Code Range | Classification | Retry Behavior | Circuit Breaker Impact |\n|------------------|----------------|----------------|----------------------|\n| 200-299 | Success | No retry needed | Reset failure counter |\n| 300-399 | Redirect | Follow redirect, then apply success/failure rules | Neutral |\n| 400-499 (except 429) | Client Error | No retry (permanent failure) | No impact on circuit |\n| 429 | Rate Limited | Retry with Retry-After header respect | Neutral |\n| 500-599 | Server Error | Retry with exponential backoff | Increment failure counter |\n| Timeout/Connection | Network Error | Retry with exponential backoff | Increment failure counter |\n\nThe classification logic prevents inappropriate retries for client errors while ensuring transient server failures receive proper retry treatment. The `circuit_breaker_triggered` field tracks which delivery attempts contributed to circuit breaker state changes, enabling debugging of protection mechanism activation.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Storing Webhook Secrets in Plain Text**\n\nMany implementations store webhook signing secrets as plain text in the database, creating a significant security vulnerability. If the database is compromised, attackers can forge webhook signatures for any registered endpoint.\n\n**Why it's wrong**: Plain text secrets provide no protection against database breaches and make secret rotation unnecessarily complex since there's no way to distinguish between different secret versions.\n\n**Fix**: Hash webhook secrets using a strong key derivation function (PBKDF2, scrypt, or Argon2) before database storage. Store both the hashed secret and a salt value, then use the same derivation process to generate signatures during delivery.\n\n⚠️ **Pitfall: Missing Foreign Key Constraints**\n\nImplementing the data model without proper foreign key constraints allows orphaned records that break data integrity. Events without corresponding webhooks or delivery attempts without parent events create debugging nightmares.\n\n**Why it's wrong**: Without foreign key constraints, application bugs can create invalid data states that crash delivery workers or produce confusing audit trails with missing context.\n\n**Fix**: Implement foreign key constraints with appropriate cascade behaviors. Use `ON DELETE CASCADE` for delivery attempts when events are deleted, but `ON DELETE RESTRICT` for webhook deletions to prevent accidental data loss.\n\n⚠️ **Pitfall: Inadequate Indexing for Query Performance**\n\nThe webhook delivery system generates high-volume time-series data, but many implementations neglect proper indexing, leading to slow queries that impact delivery performance and user experience.\n\n**Why it's wrong**: Without proper indexes, queries for delivery status, retry scheduling, and dashboard displays become prohibitively slow as data volume grows, eventually making the system unusable.\n\n**Fix**: Create composite indexes on frequently queried combinations: `(webhook_id, created_at)` for delivery history, `(delivery_status, scheduled_at)` for retry processing, and `(event_type, created_at)` for event filtering.\n\n### Implementation Guidance\n\nThe data model implementation requires careful attention to database schema design, relationship integrity, and query performance. The following guidance provides practical implementation strategies using Python with SQLAlchemy ORM.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Database | PostgreSQL with SQLAlchemy | PostgreSQL with custom connection pooling |\n| Schema Migration | Alembic migration scripts | Custom migration framework with rollback |\n| Connection Management | SQLAlchemy Session | AsyncPG with connection pooling |\n| Serialization | JSON columns with validation | Protocol Buffers with schema evolution |\n\n**File Structure:**\n```\nwebhook-system/\n├── models/\n│   ├── __init__.py\n│   ├── base.py              ← SQLAlchemy base configuration\n│   ├── webhook.py           ← WebhookRegistration model\n│   ├── event.py             ← WebhookEvent model  \n│   └── delivery.py          ← DeliveryAttempt model\n├── database/\n│   ├── __init__.py\n│   ├── connection.py        ← DatabaseManager implementation\n│   └── migrations/          ← Alembic migration files\n└── schemas/\n    ├── __init__.py\n    └── validation.py        ← Pydantic schemas for API validation\n```\n\n**Database Configuration and Connection Management:**\n\n```python\n# models/base.py - Complete SQLAlchemy configuration\nfrom sqlalchemy import create_engine, MetaData\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom contextlib import contextmanager\nimport logging\n\n# SQLAlchemy base configuration with naming conventions\nmetadata = MetaData(naming_convention={\n    \"ix\": \"ix_%(column_0_label)s\",\n    \"uq\": \"uq_%(table_name)s_%(column_0_name)s\",\n    \"ck\": \"ck_%(table_name)s_%(constraint_name)s\",\n    \"fk\": \"fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s\",\n    \"pk\": \"pk_%(table_name)s\"\n})\n\nBase = declarative_base(metadata=metadata)\n\nclass DatabaseManager:\n    \"\"\"Connection pool manager with get_connection context manager\"\"\"\n    \n    def __init__(self, database_url: str):\n        self.engine = create_engine(\n            database_url,\n            pool_size=20,\n            max_overflow=30,\n            pool_pre_ping=True,  # Verify connections before use\n            pool_recycle=3600,   # Recycle connections hourly\n            echo=False           # Set True for SQL debugging\n        )\n        self.SessionLocal = sessionmaker(bind=self.engine)\n    \n    @contextmanager\n    def get_connection(self):\n        \"\"\"Context manager for database connections with automatic cleanup\"\"\"\n        session = self.SessionLocal()\n        try:\n            yield session\n            session.commit()\n        except Exception:\n            session.rollback()\n            raise\n        finally:\n            session.close()\n    \n    def create_tables(self):\n        \"\"\"Create all tables defined by SQLAlchemy models\"\"\"\n        Base.metadata.create_all(self.engine)\n```\n\n**Webhook Registration Model Implementation:**\n\n```python\n# models/webhook.py - Complete WebhookRegistration model\nfrom sqlalchemy import Column, String, Boolean, DateTime, Integer, JSON, Text\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import relationship\nfrom datetime import datetime\nimport uuid\nfrom .base import Base\n\nclass WebhookRegistration(Base):\n    \"\"\"Webhook endpoint registration with security and circuit breaker state\"\"\"\n    \n    __tablename__ = 'webhook_registrations'\n    \n    # Core identification and endpoint configuration  \n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    url = Column(String(2048), nullable=False)  # Support long URLs\n    secret = Column(String(128), nullable=False)  # Hex-encoded signing key\n    events = Column(JSON, nullable=False, default=list)  # Event type subscriptions\n    \n    # Ownership and operational status\n    verified = Column(Boolean, nullable=False, default=False)\n    active = Column(Boolean, nullable=False, default=True)\n    \n    # Circuit breaker state tracking\n    failure_count = Column(Integer, nullable=False, default=0)\n    circuit_state = Column(String(20), nullable=False, default='closed')\n    last_success_at = Column(DateTime, nullable=True)\n    \n    # Rate limiting and operational configuration\n    rate_limit_rpm = Column(Integer, nullable=False, default=60)\n    metadata = Column(JSON, nullable=False, default=dict)\n    \n    # Audit timestamps\n    created_at = Column(DateTime, nullable=False, default=datetime.utcnow)\n    updated_at = Column(DateTime, nullable=False, default=datetime.utcnow, \n                       onupdate=datetime.utcnow)\n    \n    # Relationships to related entities\n    events_relationship = relationship(\"WebhookEvent\", back_populates=\"webhook\")\n    delivery_attempts = relationship(\"DeliveryAttempt\", back_populates=\"webhook\")\n    \n    def __repr__(self):\n        return f\"<WebhookRegistration(id={self.id}, url={self.url}, verified={self.verified})>\"\n```\n\n**Event and Delivery Tracking Models:**\n\n```python\n# models/event.py - WebhookEvent model with delivery tracking\nfrom sqlalchemy import Column, String, DateTime, Integer, JSON, Text, ForeignKey\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import relationship\nfrom datetime import datetime, timedelta\nimport uuid\nfrom .base import Base\n\nclass WebhookEvent(Base):\n    \"\"\"Individual webhook event awaiting or completing delivery\"\"\"\n    \n    __tablename__ = 'webhook_events'\n    \n    # Event identification and content\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    event_type = Column(String(100), nullable=False, index=True)\n    payload = Column(JSON, nullable=False)\n    source = Column(String(100), nullable=False)\n    \n    # Delivery targeting and scheduling\n    webhook_id = Column(UUID(as_uuid=True), ForeignKey('webhook_registrations.id'), \n                       nullable=False)\n    delivery_status = Column(String(20), nullable=False, default='pending', index=True)\n    scheduled_at = Column(DateTime, nullable=False, default=datetime.utcnow, index=True)\n    \n    # Delivery attempt tracking  \n    attempt_count = Column(Integer, nullable=False, default=0)\n    signature = Column(String(128), nullable=False)  # Pre-computed HMAC\n    \n    # Deduplication and lifecycle management\n    idempotency_key = Column(String(128), nullable=False, unique=True)\n    priority = Column(Integer, nullable=False, default=3)  # 1=highest, 5=lowest\n    expires_at = Column(DateTime, nullable=False, \n                       default=lambda: datetime.utcnow() + timedelta(days=7))\n    \n    # Extensible metadata and audit trail\n    metadata = Column(JSON, nullable=False, default=dict)\n    created_at = Column(DateTime, nullable=False, default=datetime.utcnow, index=True)\n    \n    # Relationships\n    webhook = relationship(\"WebhookRegistration\", back_populates=\"events_relationship\")\n    delivery_attempts = relationship(\"DeliveryAttempt\", back_populates=\"event\")\n\n# models/delivery.py - DeliveryAttempt immutable audit records  \nfrom sqlalchemy import Column, String, DateTime, Integer, JSON, Text, Boolean, Float, ForeignKey\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import relationship\nfrom datetime import datetime\nimport uuid\nfrom .base import Base\n\nclass DeliveryAttempt(Base):\n    \"\"\"Immutable record of individual webhook delivery attempt\"\"\"\n    \n    __tablename__ = 'delivery_attempts'\n    \n    # Attempt identification and relationships\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    event_id = Column(UUID(as_uuid=True), ForeignKey('webhook_events.id'), nullable=False)\n    webhook_id = Column(UUID(as_uuid=True), ForeignKey('webhook_registrations.id'), nullable=False)\n    attempt_number = Column(Integer, nullable=False)\n    \n    # HTTP delivery results\n    status_code = Column(Integer, nullable=True)  # None for connection errors\n    response_time = Column(Float, nullable=True)  # Seconds\n    error_message = Column(Text, nullable=True)\n    \n    # Complete request/response audit trail\n    response_headers = Column(JSON, nullable=False, default=dict)\n    response_body = Column(Text, nullable=True)  # Truncated for large responses\n    request_headers = Column(JSON, nullable=False, default=dict)  \n    request_payload = Column(Text, nullable=False)\n    \n    # Timing and processing metadata\n    attempted_at = Column(DateTime, nullable=False, default=datetime.utcnow, index=True)\n    completed_at = Column(DateTime, nullable=True)\n    delivery_duration = Column(Integer, nullable=True)  # Milliseconds\n    worker_instance = Column(String(100), nullable=True)\n    \n    # Circuit breaker impact tracking\n    circuit_breaker_triggered = Column(Boolean, nullable=False, default=False)\n    \n    # Relationships\n    event = relationship(\"WebhookEvent\", back_populates=\"delivery_attempts\")\n    webhook = relationship(\"WebhookRegistration\", back_populates=\"delivery_attempts\")\n```\n\n**Essential Database Indexes:**\n\n```python\n# Add to models after class definitions\nfrom sqlalchemy import Index\n\n# Composite indexes for common query patterns\nIndex('ix_events_webhook_created', WebhookEvent.webhook_id, WebhookEvent.created_at)\nIndex('ix_events_status_scheduled', WebhookEvent.delivery_status, WebhookEvent.scheduled_at)\nIndex('ix_attempts_event_attempt', DeliveryAttempt.event_id, DeliveryAttempt.attempt_number)\nIndex('ix_attempts_webhook_attempted', DeliveryAttempt.webhook_id, DeliveryAttempt.attempted_at)\n```\n\n**Milestone Checkpoint:**\n\nAfter implementing the data model:\n\n1. **Database Creation**: Run `python -m models.base` to create all tables with proper indexes and constraints\n2. **Model Validation**: Create test webhook registration - verify foreign key relationships work correctly\n3. **Query Performance**: Insert 1000 test events and verify delivery status queries complete under 100ms\n4. **Data Integrity**: Attempt to create orphaned records - foreign key constraints should prevent creation\n\nExpected behavior: All CRUD operations should work smoothly, complex queries should perform well, and the database should enforce referential integrity automatically.\n\n\n## Webhook Registry Component\n\n> **Milestone(s):** Milestone 1 (Webhook Registration & Security) - implements endpoint registration, signature verification, and ownership validation that forms the security foundation for all webhook deliveries\n\n### Mental Model: The Secure Post Office Registration System\n\nThink of the webhook registry as a post office that manages delivery addresses, but with strict security requirements. Just as you can't simply claim ownership of someone else's postal address, webhook endpoints must prove they control their URL before receiving deliveries. The registry acts like a postal clerk who:\n\n1. **Verifies address ownership** - sends a verification letter to confirm you actually receive mail at that address\n2. **Issues secure delivery certificates** - provides cryptographic \"stamps\" (HMAC signatures) that prove packages came from the legitimate postal service\n3. **Maintains address books** - tracks which addresses want which types of mail (event subscriptions)\n4. **Rotates security credentials** - periodically updates the cryptographic stamps while ensuring packages in transit remain valid\n\nThis mental model captures the core challenge: balancing security (preventing unauthorized deliveries and spoofing) with usability (making registration straightforward for legitimate users).\n\nThe webhook registry component serves as the secure foundation for the entire delivery system. Before any webhook can receive events, it must successfully register with ownership verification. This component generates the cryptographic signatures that authenticate every delivery attempt, manages secret rotation to maintain long-term security, and protects against common attack vectors like Server-Side Request Forgery (SSRF).\n\n### Registration and Ownership Verification\n\nThe registration process establishes a trusted relationship between the webhook delivery system and endpoint owners through a multi-step verification protocol. This process prevents unauthorized webhook registrations that could be used for attacks or data exfiltration.\n\n#### Registration Protocol Design\n\nThe registration protocol follows a challenge-response pattern that ensures only users who control an endpoint can register it for webhook deliveries. This prevents attackers from registering endpoints they don't own and intercepting sensitive webhook data intended for legitimate applications.\n\n> **Decision: Challenge-Response Ownership Verification**\n> - **Context**: Need to verify that registration requests come from users who actually control the endpoint URL\n> - **Options Considered**: \n>   1. No verification (trust registration requests)\n>   2. DNS-based verification (verify DNS ownership)\n>   3. Challenge-response verification (send test request to endpoint)\n> - **Decision**: Challenge-response verification with cryptographic challenges\n> - **Rationale**: DNS verification doesn't prove HTTP endpoint control; no verification enables trivial attacks; challenge-response directly verifies HTTP endpoint control with minimal complexity\n> - **Consequences**: Adds registration latency but provides strong security guarantees; requires endpoints to implement challenge handling\n\n| Registration Step | Action | Purpose | Security Consideration |\n|-------------------|--------|---------|----------------------|\n| 1. Initial Request | Validate URL format and accessibility | Prevent obviously invalid endpoints | Block private IP ranges to prevent SSRF |\n| 2. Challenge Generation | Create cryptographically random challenge token | Ensure unpredictable verification | Use secure random number generator |\n| 3. Challenge Delivery | Send HTTP POST with challenge to endpoint | Verify endpoint receives requests | Set short timeout to prevent hanging |\n| 4. Response Validation | Verify correct challenge response format | Confirm endpoint understands protocol | Validate response within time window |\n| 5. Registration Completion | Store verified endpoint with generated secret | Enable future webhook deliveries | Mark endpoint as verified and active |\n\nThe registration request validation performs comprehensive URL analysis to prevent Server-Side Request Forgery attacks. The system blocks requests to private IP address ranges, localhost, and other internal network resources that could be exploited to access internal services.\n\n#### URL Validation and SSRF Protection\n\nSSRF protection represents a critical security boundary that prevents attackers from using the webhook system to probe internal networks or access restricted services. The validation logic must be comprehensive while avoiding overly restrictive policies that block legitimate use cases.\n\nThe URL validation process begins with parsing the provided endpoint URL using a strict parser that rejects malformed URLs, unsupported schemes, and suspicious components. Only HTTPS URLs are accepted, ensuring all webhook deliveries occur over encrypted connections.\n\n> ⚠️ **Pitfall: Insufficient SSRF Protection**\n> Many developers focus only on blocking obvious private IPs like 127.0.0.1 and 192.168.x.x, but attackers can use DNS rebinding, URL redirects, and IPv6 addresses to bypass simple IP filtering. Comprehensive protection requires DNS resolution validation, redirect following limits, and IPv6 private range blocking.\n\n| SSRF Protection Layer | Implementation | Purpose |\n|----------------------|----------------|---------|\n| URL Scheme Validation | Accept only HTTPS schemes | Prevent file://, ftp://, and other protocol abuse |\n| IP Address Filtering | Block RFC 1918 private ranges | Prevent internal network access |\n| DNS Resolution Check | Resolve hostname before allowing registration | Detect DNS rebinding attacks |\n| Port Restriction | Allow only standard HTTPS ports (443, 8443) | Prevent port scanning of internal services |\n| Redirect Following | Limit redirect chains to 3 hops | Prevent redirect-based SSRF bypass |\n| IPv6 Protection | Block IPv6 private ranges (fc00::/7) | Comprehensive private network protection |\n\nThe challenge-response mechanism uses a time-limited cryptographic token that the endpoint must echo back in a specific format. This proves the endpoint can receive HTTP POST requests and parse JSON payloads, validating it can handle actual webhook deliveries.\n\n#### Challenge-Response Implementation\n\nThe challenge mechanism generates a cryptographically secure random token and sends it to the candidate endpoint via HTTP POST request. The endpoint must respond within a configured time window (typically 60 seconds) with the challenge token in the expected format.\n\nThe challenge request includes metadata about the webhook system, the event types being subscribed to, and instructions for completing verification. This helps endpoint developers understand the registration process and implement appropriate response handlers.\n\n| Challenge Field | Type | Purpose | Example Value |\n|-----------------|------|---------|---------------|\n| challenge_token | string | Cryptographic proof token | \"chg_7f3e8d9a2b1c4e6f\" |\n| webhook_url | string | Callback URL being verified | \"https://api.example.com/webhooks\" |\n| event_types | array | Subscribed event types | [\"user.created\", \"order.completed\"] |\n| expires_at | timestamp | Challenge expiration time | \"2024-01-15T14:30:00Z\" |\n| verification_url | string | URL to complete registration | \"https://webhooks.service.com/verify/abc123\" |\n\nThe endpoint must respond with a JSON payload containing the challenge token and additional confirmation data. This response format validation ensures the endpoint can handle structured webhook payloads and isn't simply echoing requests without parsing.\n\nThe verification process includes timestamp validation to prevent replay attacks where an attacker captures a legitimate challenge response and reuses it later. Challenge tokens are single-use and expire quickly to minimize the attack window.\n\n### HMAC Signature Generation\n\nHMAC (Hash-based Message Authentication Code) signature generation provides cryptographic proof that webhook payloads originate from the legitimate delivery system and haven't been tampered with during transmission. This signature mechanism forms the core of webhook payload authentication.\n\n#### Cryptographic Design Foundation\n\nThe HMAC signature system uses SHA-256 as the underlying hash function, providing strong cryptographic properties and wide compatibility across programming languages and platforms. The signature covers both the payload content and metadata to prevent replay attacks and payload tampering.\n\n> **Decision: HMAC-SHA256 with Timestamp Protection**\n> - **Context**: Need cryptographic authentication for webhook payloads with replay attack protection\n> - **Options Considered**:\n>   1. JWT signatures (RS256 or HS256)\n>   2. Simple hash signatures (MD5 or SHA-256)\n>   3. HMAC-SHA256 with timestamp validation\n> - **Decision**: HMAC-SHA256 with timestamp validation and structured signing\n> - **Rationale**: HMAC provides mutual authentication without key distribution complexity; SHA-256 offers strong security; timestamp validation prevents replay attacks; simpler than JWT with equivalent security\n> - **Consequences**: Requires clock synchronization between systems; slightly more complex than simple hashing but much more secure\n\nThe signature generation process creates a canonical representation of the webhook payload and metadata, ensuring consistent signature calculation across different implementations and preventing subtle variations that could break verification.\n\n| Signature Component | Purpose | Format | Example |\n|--------------------|---------|---------|---------|\n| Timestamp | Replay attack prevention | Unix timestamp (seconds) | 1642265400 |\n| Payload Hash | Content integrity | SHA-256 hex digest | \"a3f5d...\" |\n| Webhook ID | Delivery authentication | UUID string | \"wh_7f3e8d9a2b1c4e6f\" |\n| Event Type | Context validation | Dot-separated string | \"user.created\" |\n| Delivery ID | Request uniqueness | UUID string | \"del_9a2b1c4e6f8d3e7a\" |\n\nThe signing process concatenates these components in a specific order, separated by newline characters, creating a canonical string that gets processed through HMAC-SHA256 with the webhook's secret key. This structure ensures that any modification to the payload, metadata, or timestamp results in signature verification failure.\n\n#### Signature Calculation Process\n\nThe signature calculation follows a deterministic process that creates identical signatures for identical inputs, enabling reliable verification at the receiving endpoint. The process must handle edge cases like empty payloads, special characters, and large payload sizes consistently.\n\nThe canonical signing string construction follows this precise format:\n\n1. Start with the Unix timestamp as a string\n2. Add newline character (\\n)\n3. Add the webhook ID\n4. Add newline character (\\n)\n5. Add the delivery ID\n6. Add newline character (\\n)\n7. Add the event type\n8. Add newline character (\\n)\n9. Add the complete JSON payload (without additional formatting)\n\nThis canonical string gets processed through HMAC-SHA256 using the webhook's secret key, producing a 256-bit hash value that gets encoded as a hexadecimal string for HTTP header transmission.\n\n> The critical insight here is that signature verification must be timing-attack resistant. Naive string comparison of signatures can leak information about correct signature bytes through timing differences, potentially enabling signature forgery. Use constant-time comparison functions provided by cryptographic libraries.\n\n| Signature Header | Format | Example Value |\n|------------------|--------|---------------|\n| X-Webhook-Timestamp | Unix timestamp | 1642265400 |\n| X-Webhook-Signature-256 | sha256=<hex_digest> | sha256=a3f5d9e7c2b8f1a4... |\n| X-Webhook-ID | Webhook registration ID | wh_7f3e8d9a2b1c4e6f |\n| X-Webhook-Delivery | Unique delivery attempt ID | del_9a2b1c4e6f8d3e7a |\n\n#### Timestamp-Based Replay Protection\n\nTimestamp validation prevents replay attacks where attackers capture valid webhook requests and retransmit them later. The validation window must balance security (narrow window) with operational flexibility (allowing for network delays and clock skew).\n\nThe replay protection mechanism compares the timestamp in the webhook headers against the current time, rejecting requests outside the acceptable window. The default tolerance of 5 minutes (`TIMESTAMP_TOLERANCE = 300` seconds) accommodates normal network delays and minor clock differences while preventing old requests from being replayed.\n\nClock skew handling recognizes that distributed systems rarely have perfectly synchronized clocks. The tolerance window allows for reasonable clock differences between the webhook delivery system and receiving endpoints without compromising security significantly.\n\n| Timestamp Validation Check | Condition | Action | Rationale |\n|---------------------------|-----------|--------|-----------|\n| Missing Timestamp | No X-Webhook-Timestamp header | Reject request | Cannot validate replay protection |\n| Invalid Format | Non-numeric or malformed timestamp | Reject request | Prevents parsing errors and bypasses |\n| Future Timestamp | Timestamp > current_time + tolerance | Reject request | Prevents time-based attacks |\n| Expired Timestamp | Timestamp < current_time - tolerance | Reject request | Prevents replay attacks |\n| Valid Window | Within tolerance range | Accept for signature verification | Normal operation |\n\nThe timestamp validation occurs before signature verification to avoid unnecessary cryptographic computation for obviously invalid requests. However, the timestamp itself is included in the signature to prevent timestamp tampering attacks.\n\n### Secret Rotation Strategy\n\nSecret rotation maintains long-term security by periodically updating the cryptographic keys used for signature generation while ensuring seamless operation during the transition period. The rotation strategy must handle in-flight deliveries and allow gradual migration without service disruption.\n\n#### Overlapping Validity Periods\n\nThe secret rotation mechanism uses overlapping validity periods where both old and new secrets remain valid during a transition window. This approach prevents delivery failures when webhook events signed with the old secret are still being processed or retried.\n\n> **Decision: Overlapping Secret Validity with Graceful Migration**\n> - **Context**: Need to rotate secrets regularly for security while maintaining delivery reliability\n> - **Options Considered**:\n>   1. Immediate secret replacement (old secret invalid immediately)\n>   2. Overlapping validity periods with gradual migration\n>   3. Secret versioning with explicit version negotiation\n> - **Decision**: Overlapping validity periods with configurable transition windows\n> - **Rationale**: Immediate replacement breaks in-flight deliveries; version negotiation adds complexity; overlapping periods provide security and reliability\n> - **Consequences**: Requires tracking multiple active secrets per webhook; slightly more complex verification logic but prevents delivery failures\n\nThe rotation schedule uses a configurable interval (typically 30-90 days) with automatic secret generation and gradual migration. During the transition period, new deliveries use the new secret while the system continues accepting verification attempts with either secret.\n\n| Rotation Phase | Duration | New Deliveries | Verification Accepts | Purpose |\n|----------------|----------|----------------|---------------------|---------|\n| Pre-rotation | Normal operation | Current secret | Current secret only | Stable state |\n| Rotation Start | Immediate | New secret | Both secrets | Begin transition |\n| Transition Period | 7-14 days | New secret | Both secrets | Allow in-flight completion |\n| Post-rotation | Ongoing | New secret | New secret only | Complete migration |\n\nThe transition period length depends on the maximum retry window for webhook deliveries. Since failed deliveries may retry for several days with exponential backoff, the secret overlap must accommodate the longest possible retry scenario.\n\n#### Secret Generation and Storage\n\nSecret generation uses cryptographically secure random number generation to produce unpredictable keys resistant to brute-force attacks. The secret length (256 bits) provides sufficient entropy to prevent practical key guessing attacks while remaining manageable for storage and transmission.\n\nThe secret storage mechanism protects keys at rest using envelope encryption, where secrets are encrypted with a master key that's managed separately from the application database. This approach provides defense in depth if the application database is compromised.\n\n| Secret Attribute | Specification | Purpose |\n|------------------|---------------|---------|\n| Length | 256 bits (32 bytes) | Cryptographic strength against brute force |\n| Encoding | Base64 URL-safe | Safe transmission and storage |\n| Generation | Cryptographic PRNG | Unpredictable key material |\n| Storage | Envelope encryption | Protection at rest |\n| Rotation Frequency | 30-90 days | Balance security and operational overhead |\n\nSecret versioning tracks multiple active secrets per webhook registration, enabling gradual migration and emergency rollback scenarios. The version metadata includes creation timestamp, activation timestamp, and planned expiration to support automated rotation management.\n\nThe secret distribution mechanism ensures that all delivery workers have access to current secrets for signature generation. This typically involves a secure configuration service or encrypted configuration files that workers can access with appropriate authentication.\n\n#### Emergency Rotation Procedures\n\nEmergency secret rotation handles compromise scenarios where secrets may have been exposed and require immediate replacement. The emergency procedure bypasses normal transition periods while maintaining delivery reliability for uncompromised endpoints.\n\nEmergency rotation triggers include suspected key exposure, security breach notifications, compliance requirements, or proactive security measures. The procedure generates new secrets immediately and notifies endpoint owners about the required configuration updates.\n\n| Emergency Scenario | Trigger Condition | Response Time | Notification Method |\n|--------------------|-------------------|---------------|-------------------|\n| Suspected Compromise | Security incident report | 1 hour | Immediate email + webhook |\n| Compliance Requirement | Audit finding or policy change | 24 hours | Email notification |\n| Proactive Rotation | Scheduled security maintenance | 1 week | Advance email notice |\n| Bulk Compromise | System-wide security event | 30 minutes | All notification channels |\n\nThe emergency notification includes the new secret, implementation timeline, and verification instructions. Endpoint owners receive sample code for updating their signature verification logic and testing connectivity with the new credentials.\n\n### Common Registry Pitfalls\n\nThe webhook registry component involves complex security considerations that frequently lead to implementation mistakes. These pitfalls can create serious vulnerabilities or operational problems that affect the entire delivery system.\n\n#### SSRF Attack Vectors\n\n⚠️ **Pitfall: Incomplete Private IP Filtering**\n\nMany developers implement basic SSRF protection by blocking obvious private IP ranges like 127.0.0.1 and 192.168.x.x, but miss IPv6 private ranges, DNS rebinding attacks, and cloud metadata endpoints. Attackers can exploit these gaps to access internal services, cloud credentials, or other sensitive resources.\n\nThe vulnerability occurs when URL validation only checks the initial hostname without following DNS resolution or considering all private address formats. For example, an attacker might register a webhook pointing to a domain that resolves to an internal IP address, bypassing hostname-based filtering.\n\n**How to prevent**: Implement comprehensive IP filtering that includes all RFC 1918 IPv4 ranges, IPv6 private ranges (fc00::/7), loopback addresses, link-local addresses, and cloud metadata endpoints (169.254.169.254). Perform DNS resolution during validation and block any URLs that resolve to private addresses.\n\n⚠️ **Pitfall: DNS Rebinding Bypass**\n\nAttackers can use DNS rebinding attacks where a domain initially resolves to a public IP address (passing validation) but later resolves to a private IP address (enabling internal network access). This time-of-check-time-of-use vulnerability bypasses validation that only occurs during registration.\n\n**How to prevent**: Implement DNS resolution validation at delivery time, not just registration time. Use DNS caching with reasonable TTLs and re-validate IP addresses if DNS responses change unexpectedly. Consider using DNS-over-HTTPS or other secure DNS mechanisms to prevent DNS manipulation.\n\n⚠️ **Pitfall: URL Redirect Chain Exploitation**\n\nHTTP redirects can bypass SSRF protection when the initial URL points to a public endpoint that redirects to a private address. Attackers register webhooks pointing to their controlled servers, which then redirect webhook requests to internal services.\n\n**How to prevent**: Limit redirect following to a maximum of 3 hops and validate each destination in the redirect chain against SSRF filters. Consider disabling redirect following entirely for webhook deliveries if redirects aren't required for legitimate use cases.\n\n#### Weak Secret Generation\n\n⚠️ **Pitfall: Predictable Secret Generation**\n\nUsing weak random number generators or deterministic seed values creates predictable secrets that attackers can guess or reproduce. This completely undermines the security provided by HMAC signatures, allowing attackers to forge valid webhook signatures.\n\nCommon mistakes include using time-based seeds, process IDs, or programming language default random number generators that aren't cryptographically secure. Predictable secrets enable signature forgery attacks where attackers can generate valid signatures for malicious payloads.\n\n**How to prevent**: Use cryptographically secure random number generators provided by the operating system or cryptographic libraries. In Python, use `secrets.token_bytes()` or `os.urandom()`. Ensure sufficient entropy (256 bits minimum) and avoid any deterministic components in secret generation.\n\n⚠️ **Pitfall: Secret Exposure in Logs**\n\nWebhook secrets may accidentally appear in application logs, error messages, or debug output, especially during development or troubleshooting. Secret exposure through logs creates a persistent security vulnerability that may not be detected for extended periods.\n\n**How to prevent**: Implement secret redaction in logging systems that automatically masks or removes secret values from log output. Use structured logging that can identify and redact sensitive fields. Regularly audit logs for accidental secret exposure and implement log retention policies that limit exposure windows.\n\n#### Signature Verification Bypasses\n\n⚠️ **Pitfall: Timing Attack Vulnerabilities**\n\nNaive string comparison for signature verification can leak information about correct signature bytes through timing differences, potentially enabling signature forgery through timing attacks. Standard string comparison functions return immediately upon finding the first differing character, creating measurable timing differences.\n\n**How to prevent**: Use constant-time comparison functions provided by cryptographic libraries that always take the same amount of time regardless of input differences. In Python, use `hmac.compare_digest()`. Never use standard string comparison operators (==) for cryptographic verification.\n\n⚠️ **Pitfall: Insufficient Timestamp Validation**\n\nWeak timestamp validation enables replay attacks where captured webhook requests can be retransmitted outside the intended time window. Common mistakes include accepting timestamps too far in the future, using overly generous tolerance windows, or failing to validate timestamp format.\n\n**How to prevent**: Implement strict timestamp validation with reasonable tolerance windows (5-15 minutes maximum). Reject requests with timestamps in the future beyond a small tolerance for clock skew. Validate timestamp format and reject malformed or non-numeric values. Include timestamps in signature calculation to prevent timestamp tampering.\n\n### Implementation Guidance\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Database | SQLite with SQLAlchemy ORM | PostgreSQL with connection pooling |\n| HTTP Client | Python `requests` library | `httpx` with async support |\n| Cryptography | Python `hmac` and `hashlib` standard library | `cryptography` library with hardware acceleration |\n| Secret Storage | Environment variables | HashiCorp Vault or AWS Secrets Manager |\n| URL Validation | `urllib.parse` with custom validation | `validators` library with comprehensive checks |\n\n#### Recommended File Structure\n\n```\nproject-root/\n├── src/\n│   ├── webhook_registry/\n│   │   ├── __init__.py\n│   │   ├── registry.py              ← Main registration logic\n│   │   ├── verification.py          ← Challenge-response verification\n│   │   ├── signature.py             ← HMAC signature generation\n│   │   ├── validation.py            ← URL and SSRF validation\n│   │   └── models.py                ← Database models\n│   ├── common/\n│   │   ├── database.py              ← Database connection management\n│   │   ├── http_client.py           ← HTTP client utilities\n│   │   └── security.py              ← Cryptographic utilities\n│   └── config/\n│       └── webhook_config.py        ← Configuration management\n├── tests/\n│   ├── test_registry.py\n│   ├── test_verification.py\n│   └── test_signature.py\n└── requirements.txt\n```\n\n#### Infrastructure Starter Code\n\n**Database Models (complete implementation):**\n\n```python\nfrom sqlalchemy import Column, String, Boolean, DateTime, Integer, JSON, Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.sql import func\nfrom datetime import datetime\nimport uuid\n\nBase = declarative_base()\n\nclass WebhookRegistration(Base):\n    \"\"\"Webhook endpoint registration with signature verification and circuit breaker state.\"\"\"\n    __tablename__ = 'webhook_registrations'\n    \n    id = Column(String, primary_key=True, default=lambda: f\"wh_{uuid.uuid4().hex}\")\n    url = Column(String, nullable=False)\n    secret = Column(String, nullable=False)  # Base64-encoded signing secret\n    events = Column(JSON, nullable=False)    # List of subscribed event types\n    verified = Column(Boolean, default=False)\n    created_at = Column(DateTime, default=datetime.utcnow)\n    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n    active = Column(Boolean, default=True)\n    failure_count = Column(Integer, default=0)\n    circuit_state = Column(String, default='closed')  # closed, open, half-open\n    last_success_at = Column(DateTime)\n    rate_limit_rpm = Column(Integer, default=60)\n    metadata = Column(JSON, default=dict)\n    \n    def __repr__(self):\n        return f\"<WebhookRegistration(id='{self.id}', url='{self.url}', verified={self.verified})>\"\n\nclass WebhookSecret(Base):\n    \"\"\"Stores multiple active secrets per webhook for rotation support.\"\"\"\n    __tablename__ = 'webhook_secrets'\n    \n    id = Column(String, primary_key=True, default=lambda: f\"secret_{uuid.uuid4().hex}\")\n    webhook_id = Column(String, nullable=False)\n    secret_value = Column(Text, nullable=False)  # Encrypted secret\n    created_at = Column(DateTime, default=datetime.utcnow)\n    activated_at = Column(DateTime)\n    expires_at = Column(DateTime)\n    is_active = Column(Boolean, default=True)\n    version = Column(Integer, nullable=False)\n```\n\n**HTTP Client Utilities (complete implementation):**\n\n```python\nimport httpx\nimport ssl\nfrom typing import Dict, Optional, Tuple\nfrom dataclasses import dataclass\nfrom urllib.parse import urlparse\nimport ipaddress\nimport socket\n\n@dataclass\nclass HTTPResponse:\n    \"\"\"HTTP response with timing and error information.\"\"\"\n    status_code: int\n    response_time: float\n    error_message: Optional[str]\n    headers: Dict[str, str]\n    body: str = \"\"\n\nclass WebhookHTTPClient:\n    \"\"\"HTTP client with SSRF protection and timeout handling.\"\"\"\n    \n    def __init__(self, timeout: int = 30):\n        self.timeout = timeout\n        self.session = httpx.Client(\n            timeout=httpx.Timeout(timeout),\n            follow_redirects=True,\n            max_redirects=3,\n            verify=True  # Enforce SSL verification\n        )\n        \n    def __enter__(self):\n        return self\n        \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.session.close()\n    \n    def validate_url_security(self, url: str) -> bool:\n        \"\"\"Validate URL against SSRF attacks and security policies.\"\"\"\n        try:\n            parsed = urlparse(url)\n            \n            # Only allow HTTPS\n            if parsed.scheme != 'https':\n                return False\n                \n            # Only allow standard HTTPS ports\n            if parsed.port and parsed.port not in [443, 8443]:\n                return False\n                \n            # Resolve hostname and check IP\n            hostname = parsed.hostname\n            if not hostname:\n                return False\n                \n            # Get IP addresses for hostname\n            try:\n                addrs = socket.getaddrinfo(hostname, parsed.port or 443, socket.AF_UNSPEC, socket.SOCK_STREAM)\n                for addr in addrs:\n                    ip = ipaddress.ip_address(addr[4][0])\n                    if ip.is_private or ip.is_loopback or ip.is_link_local:\n                        return False\n                    # Block cloud metadata endpoints\n                    if str(ip) == '169.254.169.254':\n                        return False\n            except (socket.gaierror, ValueError):\n                return False\n                \n            return True\n            \n        except Exception:\n            return False\n    \n    def post_json(self, url: str, payload: Dict, headers: Optional[Dict] = None) -> HTTPResponse:\n        \"\"\"Send JSON POST request with comprehensive error handling.\"\"\"\n        if not self.validate_url_security(url):\n            return HTTPResponse(\n                status_code=0,\n                response_time=0.0,\n                error_message=\"URL failed security validation\",\n                headers={}\n            )\n        \n        # Implementation continues with actual HTTP request...\n        # TODO: Complete implementation based on requirements\n```\n\n#### Core Logic Skeleton\n\n**Webhook Registration (main implementation target):**\n\n```python\nimport hmac\nimport hashlib\nimport secrets\nimport time\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass WebhookConfig:\n    \"\"\"Configuration for webhook system.\"\"\"\n    database_url: str\n    redis_url: str\n    delivery_timeout: int = 30\n    max_retry_attempts: int = 5\n    circuit_breaker_failure_threshold: int = 5\n    rate_limit_rpm: int = 60\n    timestamp_tolerance: int = 300\n\nclass WebhookRegistry:\n    \"\"\"Manages webhook endpoint registration and verification.\"\"\"\n    \n    def __init__(self, config: WebhookConfig, db_manager, http_client):\n        self.config = config\n        self.db = db_manager\n        self.http = http_client\n    \n    def register_webhook(self, url: str, events: List[str], metadata: Optional[Dict] = None) -> Dict:\n        \"\"\"Register a new webhook endpoint with ownership verification.\n        \n        Returns:\n            Dict with registration_id, challenge_token, and verification_url\n        \"\"\"\n        # TODO 1: Validate URL format and basic security checks\n        # TODO 2: Check if webhook URL is already registered\n        # TODO 3: Generate cryptographically secure secret using generate_webhook_secret()\n        # TODO 4: Create webhook registration record in database (unverified state)\n        # TODO 5: Generate challenge token for ownership verification\n        # TODO 6: Send challenge request to webhook URL using verify_webhook_ownership()\n        # TODO 7: Return registration details with verification instructions\n        # Hint: Set verified=False initially, only mark True after challenge success\n        pass\n    \n    def verify_webhook_ownership(self, webhook_id: str) -> bool:\n        \"\"\"Send challenge request to verify endpoint ownership.\n        \n        Returns:\n            bool indicating if ownership verification succeeded\n        \"\"\"\n        # TODO 1: Retrieve webhook registration from database\n        # TODO 2: Generate time-limited challenge token (60 second expiry)\n        # TODO 3: Create challenge payload with token, webhook_url, event_types\n        # TODO 4: Send HTTP POST to webhook URL with challenge payload\n        # TODO 5: Validate response contains correct challenge token within time limit\n        # TODO 6: Update webhook registration to verified=True if challenge succeeds\n        # TODO 7: Return verification success/failure status\n        # Hint: Challenge should include timestamp to prevent replay\n        pass\n    \n    def generate_webhook_secret(self) -> str:\n        \"\"\"Generate cryptographically secure signing secret.\n        \n        Returns:\n            Base64-encoded secret suitable for HMAC signing\n        \"\"\"\n        # TODO 1: Generate 32 bytes of cryptographically secure random data\n        # TODO 2: Encode as URL-safe base64 string\n        # TODO 3: Return encoded secret for storage\n        # Hint: Use secrets.token_bytes() for cryptographic randomness\n        pass\n    \n    def generate_hmac_signature(self, payload: str, secret: str, timestamp: int, \n                              webhook_id: str, delivery_id: str, event_type: str) -> str:\n        \"\"\"Generate HMAC-SHA256 signature for webhook payload.\n        \n        Args:\n            payload: JSON string of webhook payload\n            secret: Base64-encoded webhook secret\n            timestamp: Unix timestamp for replay protection\n            webhook_id: Webhook registration identifier\n            delivery_id: Unique delivery attempt identifier\n            event_type: Event type string (e.g., 'user.created')\n            \n        Returns:\n            Hex-encoded HMAC signature for X-Webhook-Signature-256 header\n        \"\"\"\n        # TODO 1: Decode base64 secret to bytes\n        # TODO 2: Create canonical signing string with format:\n        #         {timestamp}\\n{webhook_id}\\n{delivery_id}\\n{event_type}\\n{payload}\n        # TODO 3: Compute HMAC-SHA256 of canonical string using decoded secret\n        # TODO 4: Return hex-encoded signature\n        # Hint: Use hmac.new() with hashlib.sha256 and consistent string encoding\n        pass\n    \n    def rotate_webhook_secret(self, webhook_id: str) -> Dict:\n        \"\"\"Rotate webhook secret with overlapping validity period.\n        \n        Returns:\n            Dict with new_secret, old_secret_expiry, and transition details\n        \"\"\"\n        # TODO 1: Retrieve current webhook registration and active secret\n        # TODO 2: Generate new secret using generate_webhook_secret()\n        # TODO 3: Store new secret with current timestamp as activated_at\n        # TODO 4: Set expiry for old secret (7-14 days from now)\n        # TODO 5: Update webhook registration with new primary secret\n        # TODO 6: Return rotation details for endpoint owner notification\n        # Hint: Keep old secret valid during transition to handle in-flight deliveries\n        pass\n\n# Constants referenced in implementation\nDELIVERY_TIMEOUT = 30\nMAX_RETRY_ATTEMPTS = 5\nCIRCUIT_BREAKER_FAILURE_THRESHOLD = 5\nRATE_LIMIT_RPM = 60\nTIMESTAMP_TOLERANCE = 300\n```\n\n#### Language-Specific Hints\n\n**Python Security Best Practices:**\n- Use `secrets.token_bytes(32)` for generating webhook secrets, never `random`\n- Use `hmac.compare_digest()` for signature verification to prevent timing attacks\n- Use `base64.urlsafe_b64encode()` for secret encoding to avoid URL encoding issues\n- Validate all inputs with type hints and runtime validation (consider `pydantic`)\n- Use `sqlalchemy.text()` for raw SQL to prevent injection attacks in complex queries\n\n**Database Connection Management:**\n- Use SQLAlchemy connection pooling with `pool_pre_ping=True` for connection health\n- Implement database transactions for multi-step operations (register + verify)\n- Use `session.merge()` for upsert operations during secret rotation\n- Set reasonable connection timeouts (`pool_timeout=30`)\n\n**HTTP Client Configuration:**\n- Set `verify=True` for SSL certificate verification - never disable in production\n- Use connection pooling with `httpx.Client()` for better performance\n- Implement request timeout that's shorter than overall delivery timeout\n- Configure retry logic only for network errors, not HTTP status errors\n\n#### Milestone Checkpoint\n\nAfter implementing the webhook registry component, verify functionality:\n\n**Registration Test:**\n```bash\ncurl -X POST http://localhost:8000/webhooks/register \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"url\": \"https://myapp.example.com/webhooks\", \"events\": [\"user.created\"]}'\n```\n\n**Expected Response:**\n```json\n{\n  \"webhook_id\": \"wh_7f3e8d9a2b1c4e6f\",\n  \"challenge_token\": \"chg_a1b2c3d4e5f6\",\n  \"verification_url\": \"https://webhook-service.com/verify/wh_7f3e8d9a2b1c4e6f\",\n  \"status\": \"pending_verification\"\n}\n```\n\n**Verification Indicators:**\n- Challenge request sent to webhook URL within 5 seconds\n- Challenge payload includes correct token and metadata\n- Database record created with `verified=False` initially\n- Secret generated with proper entropy (32 bytes, base64 encoded)\n- URL validation rejects private IPs and non-HTTPS schemes\n\n**Common Issues:**\n- **No challenge request sent**: Check URL validation logic and HTTP client configuration\n- **Challenge request fails**: Verify SSRF protection isn't blocking legitimate URLs\n- **Database errors**: Ensure proper connection pooling and transaction handling\n- **Weak secret generation**: Confirm using `secrets` module, not `random`\n\n\n## Delivery Engine Component\n\n> **Milestone(s):** Milestone 2 (Delivery Queue & Retry Logic) - implements reliable webhook delivery with exponential backoff, timeout handling, and dead letter queue management\n\n### Mental Model: The Smart Package Delivery Service\n\nThink of the **delivery engine** as a sophisticated package delivery service that never gives up on deliveries. When a package (webhook event) arrives at the sorting facility, it gets labeled with a destination address (webhook endpoint) and placed in the appropriate delivery truck queue. If the first delivery attempt fails because nobody's home (endpoint is down), the delivery driver doesn't just abandon the package. Instead, they follow a systematic retry schedule: try again in 2 minutes, then 4 minutes, then 8 minutes, with each delay getting progressively longer to avoid overwhelming the recipient.\n\nThe delivery service has smart routing logic - if a package can't be delivered because the address is wrong (4xx HTTP error), they don't keep trying. But if the recipient's mailbox is full (5xx error), they know this is temporary and worth retrying. After exhausting all retry attempts, packages that still can't be delivered go to a special \"undeliverable mail\" facility (dead letter queue) where postal workers can manually investigate what went wrong.\n\nJust like a real postal service maintains delivery records, our engine tracks every delivery attempt, recording when it was tried, what response was received, and how long it took. This audit trail becomes invaluable for debugging delivery issues and understanding endpoint reliability patterns.\n\n### Queue Management and Ordering\n\nThe **queue management system** serves as the backbone of reliable webhook delivery, ensuring that events reach their destinations in the correct order while providing persistence guarantees against system failures. Unlike simple in-memory queues that lose data during crashes, our queue system uses persistent message queues that survive restarts and maintain delivery contracts.\n\nThe fundamental principle behind our queue architecture is **per-endpoint ordering guarantees**. This means that all events destined for a specific webhook endpoint are processed sequentially, preventing race conditions where a \"user deleted\" event might be delivered before the preceding \"user created\" event. However, events for different endpoints can be processed in parallel, maximizing throughput while preserving semantic ordering where it matters.\n\n> **Decision: Per-Endpoint Queue Partitioning**\n> - **Context**: Webhook events must maintain causal ordering per endpoint while maximizing parallel processing across different endpoints\n> - **Options Considered**: Single global queue, per-event-type queues, per-endpoint queues\n> - **Decision**: Implement per-endpoint queue partitioning with parallel workers\n> - **Rationale**: Prevents ordering violations within endpoint event streams while enabling horizontal scaling across endpoints\n> - **Consequences**: Requires queue routing logic but guarantees semantic consistency and enables independent endpoint processing rates\n\n| Queue Architecture Option | Pros | Cons | Chosen? |\n|---------------------------|------|------|---------|\n| Single Global FIFO Queue | Simple implementation, guaranteed global ordering | Head-of-line blocking, no parallelization | ❌ |\n| Per-Event-Type Queues | Parallel processing by event type, simple routing | No ordering guarantees per endpoint | ❌ |\n| Per-Endpoint Queues | Ordering per endpoint, parallel processing, endpoint-specific backpressure | Complex routing, queue proliferation | ✅ |\n\nThe queue implementation leverages **Redis Streams** for persistence and ordering, with each webhook endpoint getting its own stream identified by `webhook:{webhook_id}:events`. This design provides several critical capabilities:\n\n1. **Persistent Storage**: Events survive system restarts and worker crashes\n2. **Consumer Groups**: Multiple worker instances can process different endpoints simultaneously\n3. **Acknowledgment Tracking**: Events remain in the queue until successfully processed\n4. **Failure Recovery**: Unacknowledged events can be reclaimed and retried\n\nThe queue entry format captures all information needed for delivery attempts and retry logic:\n\n| Queue Entry Field | Type | Description |\n|------------------|------|-------------|\n| `event_id` | string | Unique identifier linking to stored event |\n| `webhook_id` | string | Target endpoint identifier |\n| `attempt_count` | integer | Number of delivery attempts made |\n| `next_attempt_at` | timestamp | Scheduled time for next delivery attempt |\n| `payload_hash` | string | SHA-256 hash for integrity verification |\n| `priority` | integer | Delivery priority (0=highest, 9=lowest) |\n| `expires_at` | timestamp | Event expiration time after which delivery stops |\n| `metadata` | json | Additional context for debugging and routing |\n\n**Queue consumption** follows a pull-based model where worker processes continuously poll their assigned queues for ready events. The polling mechanism implements exponential backoff when queues are empty to reduce Redis load while maintaining low latency for new events:\n\n1. Worker queries Redis Stream for events with `next_attempt_at <= current_time`\n2. If events are found, worker claims them using Redis consumer groups\n3. For each claimed event, worker retrieves full event details from primary storage\n4. Worker attempts delivery and updates attempt tracking\n5. On success, worker acknowledges the message, removing it from the queue\n6. On failure, worker reschedules the event with calculated backoff delay\n\nThe queue management system handles **backpressure** gracefully when downstream endpoints become overwhelmed. Rather than dropping events or crashing workers, the system implements several pressure relief mechanisms:\n\n- **Queue Length Monitoring**: When per-endpoint queues exceed configurable thresholds, the system triggers alerts and may pause new event ingestion for that endpoint\n- **Worker Rate Limiting**: Each worker respects per-endpoint rate limits, slowing consumption when delivery rates exceed configured maximums\n- **Circuit Breaker Integration**: When circuit breakers open for failing endpoints, their queues pause consumption until the breaker transitions to half-open state\n\n> The queue management system's most critical responsibility is maintaining the durability contract. Once an event enters a queue, the system guarantees it will either be successfully delivered or explicitly moved to a dead letter queue after exhausting all retry attempts. This guarantee holds even across system restarts, worker crashes, and Redis failovers.\n\n### Exponential Backoff Retry Logic\n\nThe **exponential backoff retry system** implements intelligent retry scheduling that balances rapid recovery for transient failures with respectful backing off for persistent issues. Unlike naive retry approaches that hammer failing endpoints with repeated requests, exponential backoff progressively increases delays between attempts, giving downstream systems time to recover while preventing thundering herd scenarios.\n\nThe mathematical foundation of exponential backoff follows the formula: `delay = base_delay * (2 ^ attempt_number) + jitter`, where jitter introduces randomization to prevent synchronized retry storms when multiple events fail simultaneously. Our implementation uses a base delay of 30 seconds and caps maximum delays at 1 hour to prevent indefinite postponement of retry attempts.\n\n| Attempt Number | Base Delay (seconds) | Max Delay (seconds) | Jitter Range (seconds) |\n|----------------|---------------------|---------------------|----------------------|\n| 1 | 30 | 30 | 0-15 |\n| 2 | 60 | 60 | 0-30 |\n| 3 | 120 | 120 | 0-60 |\n| 4 | 240 | 240 | 0-120 |\n| 5 | 480 | 480 | 0-240 |\n| 6+ | 3600 | 3600 | 0-1800 |\n\nThe retry decision logic incorporates **HTTP status code analysis** to distinguish between retryable and non-retryable failures. This classification prevents wasted retry attempts on permanent failures while ensuring transient issues get appropriate retry treatment:\n\n| Status Code Range | Retry Decision | Rationale | Examples |\n|------------------|----------------|-----------|-----------|\n| 2xx | Success - No Retry | Request succeeded | 200 OK, 201 Created |\n| 3xx | No Retry | Redirect handling should be automatic | 301, 302, 307 |\n| 4xx (except 429) | No Retry | Client error - request is malformed | 400 Bad Request, 401 Unauthorized, 404 Not Found |\n| 429 | Retry with Rate Limit | Rate limited - respect Retry-After header | 429 Too Many Requests |\n| 5xx | Retry | Server error - likely transient | 500 Internal Server Error, 502 Bad Gateway |\n| Timeout/Network | Retry | Infrastructure issue - likely transient | Connection timeout, DNS failure |\n\nThe retry logic integrates closely with the circuit breaker system to prevent futile retry attempts against consistently failing endpoints. When a circuit breaker opens for an endpoint, pending retries for that endpoint are either paused (if the circuit might recover soon) or moved directly to the dead letter queue (if the failure pattern suggests permanent issues).\n\n> **Decision: Status-Based Retry Classification**\n> - **Context**: Not all HTTP failures should trigger retry attempts - some indicate permanent client errors\n> - **Options Considered**: Retry all failures, retry only 5xx errors, configurable retry status codes\n> - **Decision**: Built-in classification with special handling for 429 rate limiting\n> - **Rationale**: Prevents wasted resources on non-retryable errors while handling rate limiting gracefully\n> - **Consequences**: Reduces load on failing endpoints but requires careful status code interpretation\n\n**Jitter implementation** uses cryptographically secure random number generation to ensure even distribution across the jitter range. The specific jitter algorithm is `uniform_random(0, delay / 2)`, which provides sufficient randomization without excessively delaying retries. This approach prevents the thundering herd problem where many failed webhook deliveries might all retry at exactly the same time after a downstream service recovers.\n\nThe retry scheduling process follows these detailed steps:\n\n1. **Failure Detection**: Delivery attempt completes with non-2xx status or network error\n2. **Status Code Analysis**: Classify failure as retryable or non-retryable using status code rules\n3. **Attempt Count Check**: Verify current attempt count is below `MAX_RETRY_ATTEMPTS` threshold\n4. **Circuit Breaker Check**: Confirm endpoint circuit breaker is not in open state\n5. **Delay Calculation**: Compute exponential backoff delay with jitter for next attempt\n6. **Queue Rescheduling**: Update queue entry with new `next_attempt_at` timestamp\n7. **Attempt Logging**: Record failure details and calculated retry delay in delivery log\n\n**Retry-After header handling** provides special logic for 429 rate limiting responses. When an endpoint returns 429 with a Retry-After header, our system respects the server's guidance rather than using exponential backoff. The retry delay becomes `max(retry_after_seconds, exponential_backoff_delay)` to ensure we never retry more aggressively than the server requests.\n\nThe retry system maintains **attempt state persistence** across worker restarts and system failures. All retry scheduling information is stored in Redis alongside the queue entries, ensuring that partially-processed events resume with correct attempt counts and delay calculations after system recovery.\n\n### Dead Letter Queue Handling\n\nThe **dead letter queue (DLQ)** serves as the final repository for webhook events that cannot be delivered despite exhaustive retry attempts. Unlike simply discarding failed events, the DLQ preserves them for manual investigation, debugging, and potential replay once underlying issues are resolved. This design maintains the system's durability guarantees while preventing infinite retry loops that could exhaust system resources.\n\nEvents transition to the dead letter queue under several specific conditions, each indicating a different type of permanent delivery failure:\n\n| DLQ Trigger Condition | Description | Next Steps |\n|----------------------|-------------|------------|\n| Max Retry Attempts Exceeded | Event failed delivery after `MAX_RETRY_ATTEMPTS` attempts | Manual investigation, potential replay |\n| Circuit Breaker Permanent Failure | Endpoint circuit breaker indicates permanent failure | Endpoint owner notification, webhook disabling |\n| Event Expiration | Event exceeded `expires_at` timestamp | Event discarded, no recovery possible |\n| Malformed Event Data | Event payload corruption or signature mismatch | Data integrity investigation |\n| Webhook Deletion | Target webhook was deleted during retry processing | Event discarded, cleanup required |\n\nThe dead letter queue implementation uses a separate Redis Stream (`dlq:events`) with enhanced metadata to support manual intervention workflows. Each DLQ entry preserves the complete event history along with diagnostic information:\n\n| DLQ Entry Field | Type | Description |\n|-----------------|------|-------------|\n| `original_event_id` | string | Reference to original webhook event |\n| `webhook_id` | string | Target endpoint (may no longer exist) |\n| `failure_reason` | string | Enumerated reason for DLQ placement |\n| `attempt_history` | json | Complete list of all delivery attempts |\n| `final_error` | string | Last error message from final delivery attempt |\n| `dlq_timestamp` | timestamp | When event was moved to DLQ |\n| `investigation_status` | string | Manual review status (pending, investigating, resolved) |\n| `replay_eligible` | boolean | Whether event can be safely replayed |\n\n**DLQ monitoring and alerting** systems continuously track dead letter queue growth patterns and trigger notifications when intervention is needed. The monitoring system distinguishes between expected DLQ activity (occasional failed events from flaky endpoints) and concerning patterns (sudden spikes indicating systemic issues):\n\n1. **Volume Alerts**: Trigger when DLQ receives more than X events per hour for any single webhook\n2. **Pattern Alerts**: Detect when multiple webhooks start failing simultaneously (indicating infrastructure issues)\n3. **Staleness Alerts**: Flag DLQ events that remain in \"pending investigation\" status beyond configured thresholds\n4. **Capacity Alerts**: Warn when DLQ storage approaches configured retention limits\n\nThe dead letter queue supports several **manual intervention workflows** to handle different types of delivery failures:\n\n**Replay Workflow**: For events that failed due to temporary endpoint issues, operators can trigger replay once the underlying problem is resolved. The replay process creates new delivery attempts with fresh attempt counters while preserving original event timestamps and signatures.\n\n**Batch Analysis Workflow**: When multiple events fail with similar error patterns, operators can export DLQ entries for batch analysis. This workflow helps identify common failure causes like endpoint URL changes, authentication issues, or payload format problems.\n\n**Webhook Health Assessment**: The DLQ serves as a data source for evaluating webhook endpoint reliability. Endpoints with high DLQ rates may need owner notification, rate limiting adjustments, or removal from the system.\n\n> **Decision: Structured DLQ with Manual Intervention Support**\n> - **Context**: Failed webhook events need preservation for debugging while preventing infinite retry resource consumption\n> - **Options Considered**: Simple discard after max retries, basic DLQ storage, structured DLQ with workflows\n> - **Decision**: Implement structured dead letter queue with manual intervention and replay capabilities\n> - **Rationale**: Maintains durability guarantees while providing operational tools for failure resolution\n> - **Consequences**: Requires additional storage and operational procedures but prevents data loss and enables failure analysis\n\n**DLQ retention policies** balance storage costs with debugging needs. Events remain in the DLQ for 30 days by default, with automatic archival to cold storage for compliance requirements. During the retention period, all DLQ entries remain available for analysis and replay.\n\nThe DLQ cleanup process runs daily to remove expired entries and archive events marked as \"resolved\" by operators. This process maintains DLQ performance while preserving audit trails for compliance and debugging purposes.\n\n**Replay safety mechanisms** prevent duplicate deliveries when events are replayed from the DLQ. Each replay creates a new `delivery_id` while preserving the original `event_id` and `idempotency_key`. Receiving endpoints can use these identifiers to detect and safely ignore duplicate deliveries from replay operations.\n\n### Common Delivery Pitfalls\n\nUnderstanding and avoiding common delivery implementation mistakes is crucial for building a reliable webhook system. These pitfalls represent real-world issues that can lead to poor endpoint relationships, resource exhaustion, and data loss.\n\n⚠️ **Pitfall: Thundering Herd on Endpoint Recovery**\n\nWhen a popular endpoint goes down and many webhook events start failing, naive retry implementations will schedule all retry attempts for the exact same time using simple exponential backoff. When the endpoint recovers, it gets hit with hundreds or thousands of simultaneous retry requests, immediately overwhelming it again.\n\n**Why it's wrong**: Synchronized retries create artificial load spikes that can crash recovered endpoints, creating a cycle of failure and recovery that never stabilizes.\n\n**How to fix**: Implement jitter in retry delays by adding random variation (`delay + random(0, delay/2)`). This spreads retry attempts across a time window, giving recovered endpoints a chance to handle the retry load gradually.\n\n⚠️ **Pitfall: Retrying Non-Retryable Errors**\n\nA common mistake is implementing blanket retry logic that attempts to redeliver events regardless of the HTTP status code received. This leads to wasted resources trying to retry 400 Bad Request or 404 Not Found errors that will never succeed.\n\n**Why it's wrong**: Retrying permanent client errors (4xx codes) wastes system resources and creates unnecessary load on endpoints that are correctly rejecting malformed requests.\n\n**How to fix**: Implement status code classification that only retries 5xx server errors, network timeouts, and 429 rate limiting responses. Treat 4xx errors (except 429) as permanent failures that should go directly to the dead letter queue.\n\n⚠️ **Pitfall: Unbounded Queue Growth**\n\nWithout proper backpressure handling, delivery queues can grow indefinitely when endpoint failures outpace retry processing. This eventually leads to memory exhaustion and system crashes, ironically making delivery problems worse.\n\n**Why it's wrong**: Unbounded queues hide delivery problems until system resources are exhausted, creating catastrophic failures that affect all endpoints, not just the failing ones.\n\n**How to fix**: Implement queue length monitoring with configurable limits. When queues exceed thresholds, trigger alerts, pause new event ingestion for that endpoint, and consider emergency DLQ promotion for oldest events.\n\n⚠️ **Pitfall: Losing Event Ordering During Parallel Retries**\n\nWhen implementing parallel processing for better performance, it's tempting to allow multiple workers to process events for the same endpoint simultaneously. This breaks ordering guarantees and can lead to events being delivered out of sequence.\n\n**Why it's wrong**: Out-of-order delivery violates the semantic contracts that webhook consumers depend on, potentially causing data corruption in downstream systems.\n\n**How to fix**: Implement per-endpoint queue partitioning where each endpoint's events are processed by exactly one worker at a time. Use Redis consumer groups or similar mechanisms to ensure exclusive processing per endpoint.\n\n⚠️ **Pitfall: Ignoring Retry-After Headers**\n\nWhen endpoints return 429 rate limiting responses with Retry-After headers, naive implementations ignore this guidance and continue using exponential backoff delays, often retrying much more aggressively than the endpoint can handle.\n\n**Why it's wrong**: Ignoring explicit rate limiting guidance from endpoints demonstrates poor API citizenship and can lead to endpoint operators blocking webhook deliveries entirely.\n\n**How to fix**: Always respect Retry-After headers when present, using `max(retry_after_seconds, exponential_backoff_delay)` to ensure you never retry more aggressively than the endpoint requests.\n\n⚠️ **Pitfall: Circuit Breaker State Race Conditions**\n\nIn multi-worker environments, race conditions in circuit breaker state updates can lead to inconsistent behavior where some workers continue attempting deliveries to endpoints that other workers have marked as failed.\n\n**Why it's wrong**: Inconsistent circuit breaker state defeats the protection mechanism, allowing continued load on failing endpoints and wasting retry attempts.\n\n**How to fix**: Use atomic operations for circuit breaker state transitions and ensure all workers check current circuit breaker state before attempting deliveries. Consider using Redis for shared circuit breaker state across worker instances.\n\n⚠️ **Pitfall: Event Payload Mutations During Retries**\n\nWhen retry logic reconstructs HTTP requests from stored event data, timestamp headers or signature calculations might be regenerated, creating different payloads for retry attempts than the original delivery.\n\n**Why it's wrong**: Changing event payloads between delivery attempts violates idempotency expectations and can confuse endpoint validation logic that expects consistent payloads.\n\n**How to fix**: Store complete HTTP request details (headers, payload, signature) with each event and replay them identically for all delivery attempts. Only update attempt-specific metadata like delivery attempt counts.\n\n### Implementation Guidance\n\nThis section provides practical implementation patterns and starter code for building the delivery engine component. The implementation uses Python with Celery for task processing, Redis for queuing, and comprehensive error handling.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Task Queue | Celery with Redis backend | Apache Kafka with consumer groups |\n| HTTP Client | `requests` with timeout configuration | `aiohttp` with connection pooling |\n| Retry Logic | Built-in exponential backoff with jitter | Custom retry with circuit breaker integration |\n| Dead Letter Storage | Redis Lists with TTL | Dedicated database table with indexes |\n| Monitoring | Basic logging with structured messages | Prometheus metrics with Grafana dashboards |\n\n#### Recommended File Structure\n\n```\nwebhook_system/\n├── delivery_engine/\n│   ├── __init__.py\n│   ├── queue_manager.py           # Queue operations and partitioning\n│   ├── delivery_worker.py         # Core delivery logic\n│   ├── retry_handler.py           # Exponential backoff and retry decisions\n│   ├── dead_letter_handler.py     # DLQ management and replay\n│   ├── http_client.py             # Webhook HTTP delivery client\n│   └── models.py                  # DeliveryAttempt and related models\n├── config/\n│   └── delivery_config.py         # Configuration constants and settings\n└── tests/\n    └── test_delivery_engine.py    # Comprehensive delivery tests\n```\n\n#### Infrastructure Starter Code\n\n**Queue Manager Implementation** (Complete, ready to use):\n\n```python\nimport redis\nimport json\nimport time\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass, asdict\n\n@dataclass\nclass QueueEntry:\n    event_id: str\n    webhook_id: str\n    attempt_count: int\n    next_attempt_at: float\n    payload_hash: str\n    priority: int\n    expires_at: float\n    metadata: Dict\n\nclass QueueManager:\n    \"\"\"Manages per-endpoint webhook delivery queues with Redis Streams.\"\"\"\n    \n    def __init__(self, redis_client: redis.Redis, config: 'WebhookConfig'):\n        self.redis = redis_client\n        self.config = config\n        self.consumer_group = \"delivery_workers\"\n        \n    def enqueue_event(self, webhook_id: str, event_id: str, \n                     priority: int = 5, expires_at: Optional[datetime] = None) -> bool:\n        \"\"\"Add event to webhook-specific delivery queue.\"\"\"\n        stream_key = f\"webhook:{webhook_id}:events\"\n        \n        # Calculate expiration (default 7 days from now)\n        if expires_at is None:\n            expires_at = datetime.now(timezone.utc).timestamp() + (7 * 24 * 3600)\n        else:\n            expires_at = expires_at.timestamp()\n            \n        queue_entry = QueueEntry(\n            event_id=event_id,\n            webhook_id=webhook_id,\n            attempt_count=0,\n            next_attempt_at=time.time(),\n            payload_hash=\"\",  # Will be calculated by delivery worker\n            priority=priority,\n            expires_at=expires_at,\n            metadata={\"enqueued_at\": time.time()}\n        )\n        \n        # Add to Redis Stream\n        message_id = self.redis.xadd(stream_key, asdict(queue_entry))\n        \n        # Create consumer group if it doesn't exist\n        try:\n            self.redis.xgroup_create(stream_key, self.consumer_group, id='0', mkstream=True)\n        except redis.ResponseError as e:\n            if \"BUSYGROUP\" not in str(e):\n                raise\n                \n        return message_id is not None\n        \n    def claim_ready_events(self, consumer_name: str, batch_size: int = 10) -> List[Tuple[str, Dict]]:\n        \"\"\"Claim events ready for delivery across all webhook streams.\"\"\"\n        current_time = time.time()\n        ready_events = []\n        \n        # Get list of all webhook streams\n        webhook_streams = self.redis.keys(\"webhook:*:events\")\n        \n        for stream_key in webhook_streams:\n            try:\n                # Read pending messages for this consumer\n                pending = self.redis.xreadgroup(\n                    self.consumer_group, \n                    consumer_name, \n                    {stream_key: '>'}, \n                    count=batch_size, \n                    block=1000\n                )\n                \n                for stream, messages in pending:\n                    for message_id, fields in messages:\n                        entry = QueueEntry(**fields)\n                        \n                        # Check if event is ready for delivery\n                        if entry.next_attempt_at <= current_time and entry.expires_at > current_time:\n                            ready_events.append((message_id.decode(), asdict(entry)))\n                            \n            except redis.ResponseError:\n                # Stream might not exist or have no pending messages\n                continue\n                \n        return ready_events[:batch_size]\n        \n    def reschedule_event(self, stream_key: str, message_id: str, \n                        delay_seconds: int, attempt_count: int) -> bool:\n        \"\"\"Reschedule failed event for later retry.\"\"\"\n        try:\n            # Acknowledge the current message\n            self.redis.xack(stream_key, self.consumer_group, message_id)\n            \n            # Get original message data\n            messages = self.redis.xrange(stream_key, message_id, message_id)\n            if not messages:\n                return False\n                \n            _, original_fields = messages[0]\n            entry = QueueEntry(**original_fields)\n            \n            # Update for retry\n            entry.attempt_count = attempt_count\n            entry.next_attempt_at = time.time() + delay_seconds\n            entry.metadata.update({\"last_retry_scheduled\": time.time()})\n            \n            # Re-add to stream\n            new_message_id = self.redis.xadd(stream_key, asdict(entry))\n            return new_message_id is not None\n            \n        except Exception as e:\n            print(f\"Failed to reschedule event {message_id}: {e}\")\n            return False\n            \n    def move_to_dlq(self, stream_key: str, message_id: str, \n                   failure_reason: str, attempt_history: List[Dict]) -> bool:\n        \"\"\"Move failed event to dead letter queue.\"\"\"\n        dlq_key = \"dlq:events\"\n        \n        try:\n            # Get original event data\n            messages = self.redis.xrange(stream_key, message_id, message_id)\n            if not messages:\n                return False\n                \n            _, original_fields = messages[0]\n            entry = QueueEntry(**original_fields)\n            \n            # Create DLQ entry\n            dlq_entry = {\n                \"original_event_id\": entry.event_id,\n                \"webhook_id\": entry.webhook_id,\n                \"failure_reason\": failure_reason,\n                \"attempt_history\": json.dumps(attempt_history),\n                \"final_error\": attempt_history[-1].get(\"error_message\", \"\") if attempt_history else \"\",\n                \"dlq_timestamp\": time.time(),\n                \"investigation_status\": \"pending\",\n                \"replay_eligible\": failure_reason in [\"max_retries_exceeded\", \"circuit_breaker_timeout\"]\n            }\n            \n            # Add to DLQ\n            dlq_message_id = self.redis.xadd(dlq_key, dlq_entry)\n            \n            # Acknowledge original message\n            self.redis.xack(stream_key, self.consumer_group, message_id)\n            \n            return dlq_message_id is not None\n            \n        except Exception as e:\n            print(f\"Failed to move event {message_id} to DLQ: {e}\")\n            return False\n```\n\n**HTTP Client with Retry Logic** (Complete, ready to use):\n\n```python\nimport requests\nimport time\nimport random\nimport hashlib\nimport hmac\nfrom typing import Dict, Tuple, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass HTTPResponse:\n    status_code: int\n    response_time: float\n    error_message: str\n    headers: Dict[str, str]\n    body: str\n\nclass WebhookHTTPClient:\n    \"\"\"HTTP client for webhook deliveries with timeout and retry logic.\"\"\"\n    \n    def __init__(self, config: 'WebhookConfig'):\n        self.config = config\n        self.session = requests.Session()\n        self.session.timeout = config.delivery_timeout\n        \n        # Configure connection pooling\n        adapter = requests.adapters.HTTPAdapter(\n            pool_connections=10,\n            pool_maxsize=20,\n            max_retries=0  # We handle retries ourselves\n        )\n        self.session.mount('http://', adapter)\n        self.session.mount('https://', adapter)\n        \n    def post_json(self, url: str, payload: str, headers: Dict[str, str]) -> HTTPResponse:\n        \"\"\"Send JSON POST request with comprehensive error handling.\"\"\"\n        start_time = time.time()\n        \n        try:\n            response = self.session.post(\n                url,\n                data=payload,\n                headers=headers,\n                timeout=self.config.delivery_timeout,\n                allow_redirects=False  # Don't follow redirects for security\n            )\n            \n            response_time = time.time() - start_time\n            \n            return HTTPResponse(\n                status_code=response.status_code,\n                response_time=response_time,\n                error_message=\"\",\n                headers=dict(response.headers),\n                body=response.text[:1000]  # Truncate large responses\n            )\n            \n        except requests.exceptions.Timeout:\n            return HTTPResponse(\n                status_code=0,\n                response_time=time.time() - start_time,\n                error_message=\"Request timeout\",\n                headers={},\n                body=\"\"\n            )\n            \n        except requests.exceptions.ConnectionError as e:\n            return HTTPResponse(\n                status_code=0,\n                response_time=time.time() - start_time,\n                error_message=f\"Connection error: {str(e)}\",\n                headers={},\n                body=\"\"\n            )\n            \n        except requests.exceptions.RequestException as e:\n            return HTTPResponse(\n                status_code=0,\n                response_time=time.time() - start_time,\n                error_message=f\"Request error: {str(e)}\",\n                headers={},\n                body=\"\"\n            )\n            \n    def should_retry_delivery(self, status_code: int, attempt_number: int) -> bool:\n        \"\"\"Determine if delivery attempt should be retried based on response.\"\"\"\n        if attempt_number >= self.config.max_retry_attempts:\n            return False\n            \n        # Retry server errors and timeouts\n        if status_code == 0 or status_code >= 500:\n            return True\n            \n        # Retry rate limiting\n        if status_code == 429:\n            return True\n            \n        # Don't retry client errors (except rate limiting)\n        if 400 <= status_code < 500:\n            return False\n            \n        # Don't retry successful responses\n        if 200 <= status_code < 300:\n            return False\n            \n        # Don't retry redirects (security policy)\n        if 300 <= status_code < 400:\n            return False\n            \n        return True\n        \n    def calculate_retry_delay(self, attempt_number: int, base_delay: int = 30) -> int:\n        \"\"\"Calculate exponential backoff delay with jitter.\"\"\"\n        # Exponential backoff: base_delay * (2 ^ attempt_number)\n        exponential_delay = base_delay * (2 ** attempt_number)\n        \n        # Cap maximum delay at 1 hour\n        capped_delay = min(exponential_delay, 3600)\n        \n        # Add jitter: random value between 0 and delay/2\n        jitter = random.randint(0, capped_delay // 2)\n        \n        return capped_delay + jitter\n```\n\n#### Core Delivery Logic Skeleton\n\n**DeliveryWorker Class** (Signatures with detailed TODOs):\n\n```python\nfrom typing import Dict, List, Optional, Tuple\nimport json\nimport time\nfrom datetime import datetime, timezone\n\nclass DeliveryWorker:\n    \"\"\"Processes webhook deliveries with retry logic and circuit breaker integration.\"\"\"\n    \n    def __init__(self, queue_manager: QueueManager, http_client: WebhookHTTPClient,\n                 registry: 'WebhookRegistry', config: 'WebhookConfig'):\n        self.queue_manager = queue_manager\n        self.http_client = http_client\n        self.registry = registry\n        self.config = config\n        self.worker_id = f\"worker_{int(time.time())}\"\n        \n    def process_delivery(self, event_id: str, webhook_id: str, payload: str) -> bool:\n        \"\"\"\n        Attempt webhook delivery with comprehensive error handling and retry logic.\n        Returns True if delivery succeeded, False if it should be retried or moved to DLQ.\n        \"\"\"\n        # TODO 1: Retrieve webhook registration details from registry\n        #   - Get webhook URL, secret, and current circuit breaker state\n        #   - Return False if webhook doesn't exist or is disabled\n        #   - Check if circuit breaker is open - if so, move to DLQ with reason\n        \n        # TODO 2: Generate HMAC signature for payload\n        #   - Use webhook secret to sign payload with current timestamp\n        #   - Include event_id and webhook_id in signature calculation\n        #   - Format signature as \"sha256=<hex_digest>\"\n        \n        # TODO 3: Construct HTTP request headers\n        #   - Content-Type: application/json\n        #   - X-Webhook-Signature: <generated_signature>\n        #   - X-Webhook-Event-ID: <event_id>\n        #   - X-Webhook-Timestamp: <current_unix_timestamp>\n        #   - User-Agent: WebhookSystem/1.0\n        \n        # TODO 4: Attempt HTTP delivery using webhook HTTP client\n        #   - Call http_client.post_json() with URL, payload, and headers\n        #   - Record attempt start time and end time\n        #   - Handle any exceptions from HTTP client\n        \n        # TODO 5: Create DeliveryAttempt record\n        #   - Store attempt details including status code, response time, headers\n        #   - Include request details for debugging purposes\n        #   - Save to database for audit trail\n        \n        # TODO 6: Analyze response and determine next action\n        #   - If 2xx status: mark as successful, return True\n        #   - If should_retry_delivery() returns False: move to DLQ\n        #   - If should retry: calculate delay and reschedule in queue\n        #   - Update circuit breaker state based on success/failure\n        \n        # TODO 7: Handle circuit breaker state transitions\n        #   - On success: reset failure count, close circuit if in half-open\n        #   - On failure: increment failure count, open circuit if threshold exceeded\n        #   - Update webhook registration with new circuit breaker state\n        \n        pass  # Replace with implementation\n        \n    def deliver_webhook(self, url: str, payload: str, signature: str) -> Tuple[bool, HTTPResponse]:\n        \"\"\"\n        Send webhook HTTP request and return success status with response details.\n        This method handles the actual HTTP delivery mechanics.\n        \"\"\"\n        # TODO 1: Validate URL format and security constraints\n        #   - Ensure URL uses HTTPS (never HTTP for security)\n        #   - Check against SSRF protection rules (no private IPs)\n        #   - Validate URL structure and reachability\n        \n        # TODO 2: Prepare headers for webhook delivery\n        #   - Content-Type: application/json\n        #   - X-Webhook-Signature: signature parameter\n        #   - X-Webhook-Timestamp: current timestamp\n        #   - Include any custom headers from webhook configuration\n        \n        # TODO 3: Execute HTTP POST request\n        #   - Use http_client.post_json() with timeout handling\n        #   - Capture full response details including headers and timing\n        #   - Handle network errors gracefully without crashing\n        \n        # TODO 4: Analyze response for success determination\n        #   - Success: 2xx status codes\n        #   - Consider 3xx as delivery failure (don't follow redirects)\n        #   - Log response details for debugging and compliance\n        \n        # TODO 5: Return structured results\n        #   - Boolean success indicator\n        #   - Complete HTTPResponse object with all details\n        #   - Ensure no sensitive data leaks in error messages\n        \n        pass  # Replace with implementation\n        \n    def run_worker_loop(self):\n        \"\"\"\n        Main worker loop that continuously processes events from delivery queues.\n        This method implements the worker's primary event processing cycle.\n        \"\"\"\n        # TODO 1: Initialize worker state and register with system\n        #   - Set worker ID and start timestamp\n        #   - Register worker in Redis for monitoring purposes\n        #   - Initialize performance counters and health metrics\n        \n        # TODO 2: Implement continuous event polling loop\n        #   - Claim ready events from queue_manager\n        #   - Handle empty queue gracefully with backoff\n        #   - Respect shutdown signals for clean worker termination\n        \n        # TODO 3: Process each claimed event\n        #   - Extract event details from queue entry\n        #   - Load full event payload from database\n        #   - Call process_delivery() for actual delivery attempt\n        \n        # TODO 4: Handle delivery results appropriately\n        #   - Success: acknowledge message and remove from queue\n        #   - Retry needed: reschedule with calculated backoff delay\n        #   - Permanent failure: move to dead letter queue\n        \n        # TODO 5: Update worker health metrics\n        #   - Track delivery success/failure rates\n        #   - Monitor processing latency and queue depths\n        #   - Report worker status to monitoring system\n        \n        # TODO 6: Handle worker shutdown gracefully\n        #   - Complete current deliveries before stopping\n        #   - Release any claimed but unprocessed messages\n        #   - Update worker registry to show offline status\n        \n        pass  # Replace with implementation\n```\n\n#### Language-Specific Implementation Hints\n\n**Redis Operations**:\n- Use `redis-py` library with connection pooling: `redis.ConnectionPool(max_connections=20)`\n- For atomic operations, use Redis pipelines: `pipe = redis_client.pipeline()` followed by `pipe.execute()`\n- Redis Streams operations: `XADD` for enqueueing, `XREADGROUP` for claiming, `XACK` for acknowledgment\n\n**HTTP Client Configuration**:\n- Set reasonable timeouts: `requests.Session(timeout=(5, 30))` for 5s connect, 30s read\n- Disable redirects for security: `allow_redirects=False` in all requests\n- Use connection pooling: `HTTPAdapter(pool_connections=10, pool_maxsize=20)`\n\n**Error Handling Patterns**:\n- Always catch specific exceptions: `requests.exceptions.Timeout`, `requests.exceptions.ConnectionError`\n- Use structured logging: `logging.getLogger(__name__).error(\"Delivery failed\", extra={\"webhook_id\": webhook_id})`\n- Never let worker crashes lose events - wrap main processing in try/except with event rescheduling\n\n**Database Operations**:\n- Use SQLAlchemy sessions with proper cleanup: `with session_scope() as session:`\n- For high-throughput inserts, use batch operations: `session.bulk_insert_mappings()`\n- Index frequently queried fields: `webhook_id`, `event_id`, `attempted_at`\n\n#### Milestone Checkpoints\n\n**Checkpoint 1: Basic Queue Operations**\n```bash\n# Start Redis server\nredis-server\n\n# Run basic queue test\npython -m pytest tests/test_queue_manager.py::test_enqueue_and_claim -v\n```\nExpected behavior: Events enqueued to webhook-specific streams can be claimed by workers and acknowledged successfully.\n\n**Checkpoint 2: HTTP Delivery with Retries**\n```bash\n# Start mock webhook endpoint\npython tests/mock_webhook_server.py --port 8080\n\n# Run delivery test\npython -m pytest tests/test_delivery_worker.py::test_successful_delivery -v\n```\nExpected behavior: Webhook events are delivered via HTTP POST with proper signatures and retry logic handles failures.\n\n**Checkpoint 3: Dead Letter Queue Processing**\n```bash\n# Run DLQ test with failing endpoint\npython -m pytest tests/test_delivery_worker.py::test_dlq_processing -v\n```\nExpected behavior: Events that exceed retry limits are moved to dead letter queue with complete attempt history.\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|-------------|----------------|-----|\n| Events stuck in queue | Worker crash or infinite loop | Check Redis streams: `XPENDING webhook:123:events delivery_workers` | Restart workers, check for unhandled exceptions |\n| Duplicate deliveries | Message not acknowledged after processing | Check XACK calls in delivery logic | Ensure acknowledgment happens after successful processing |\n| High retry rates | Endpoint returning 5xx errors or timing out | Check delivery attempt logs for status codes | Review endpoint health, adjust timeout settings |\n| Circuit breaker not opening | Failure threshold too high or state not persisted | Check webhook registration failure_count field | Lower threshold, verify state updates are atomic |\n| Memory usage growing | Dead letter queue or delivery logs growing unbounded | Check DLQ size: `XLEN dlq:events` | Implement retention policies, archive old entries |\n\n\n## Circuit Breaker and Rate Limiting\n\n> **Milestone(s):** Milestone 3 (Circuit Breaker & Rate Limiting) - implements protection mechanisms that prevent failing endpoints from overwhelming the delivery system while supporting automatic recovery\n\n### Mental Model: The Overworked Postal Worker\n\nThink of the circuit breaker pattern like a postal worker who becomes selective about delivery routes. When the postal worker repeatedly encounters a house where no one answers the door (failing webhook endpoint), they don't keep wasting time and energy making delivery attempts. Instead, they mark that address as \"temporarily undeliverable\" and skip it for a while, allowing them to focus on successful deliveries to other addresses.\n\nAfter some time passes, the postal worker gives that problematic address another chance with a single test delivery (half-open state). If someone finally answers, great - normal delivery resumes. If not, the address goes back on the \"skip\" list for an even longer period. This prevents one problematic address from blocking deliveries to everyone else.\n\nRate limiting works like the postal service's capacity management. Even for addresses that work perfectly, the postal worker can only handle so many deliveries per hour. If they try to deliver too fast, they make mistakes, drop packages, or burn out. So they maintain a steady, sustainable pace that ensures quality delivery to all customers.\n\n![Circuit Breaker State Machine](./diagrams/circuit-breaker-states.svg)\n\nThe webhook delivery system faces identical challenges. Some endpoints will inevitably fail - servers go down, networks have issues, or applications crash. Without protection mechanisms, these failing endpoints can consume all available delivery workers, create massive retry queues, and degrade service for healthy endpoints. Circuit breakers and rate limiting provide the essential protection that keeps the entire system healthy.\n\n### Circuit Breaker State Machine\n\nThe circuit breaker operates as a finite state machine with three distinct states that protect failing endpoints while enabling automatic recovery. Each webhook registration maintains its own independent circuit breaker, allowing fine-grained failure isolation without affecting delivery to healthy endpoints.\n\n> **Decision: Per-Endpoint Circuit Breaker Architecture**\n> - **Context**: Need to protect against failing endpoints without impacting healthy ones, while handling different failure patterns across diverse webhook consumers\n> - **Options Considered**: Global circuit breaker for all endpoints, per-endpoint circuit breakers, endpoint groups with shared circuit breakers\n> - **Decision**: Independent circuit breaker per webhook endpoint\n> - **Rationale**: Different endpoints have vastly different reliability characteristics, scaling patterns, and operational schedules. A social media platform might have planned maintenance windows, while a payment processor requires 24/7 availability. Global circuit breakers create inappropriate coupling between unrelated services.\n> - **Consequences**: Higher memory overhead for circuit breaker state storage, more complex monitoring across many breakers, but provides precise failure isolation and recovery control\n\n#### Circuit Breaker States and Transitions\n\n| Current State | Triggering Event | Next State | Actions Taken | Conditions |\n|---------------|------------------|------------|---------------|------------|\n| **Closed** | Successful delivery | Closed | Reset failure count, update `last_success_at` | Normal operation state |\n| **Closed** | Failed delivery | Closed | Increment failure count | `failure_count < CIRCUIT_BREAKER_FAILURE_THRESHOLD` |\n| **Closed** | Failed delivery | Open | Set `circuit_state = 'open'`, schedule recovery attempt | `failure_count >= CIRCUIT_BREAKER_FAILURE_THRESHOLD` |\n| **Open** | Delivery attempt | Open | Reject delivery immediately, return circuit breaker error | Before recovery timeout expires |\n| **Open** | Recovery timeout | Half-Open | Set `circuit_state = 'half_open'`, allow limited test traffic | After configurable open duration |\n| **Half-Open** | Successful test delivery | Closed | Reset failure count, set `circuit_state = 'closed'` | Test delivery succeeds |\n| **Half-Open** | Failed test delivery | Open | Increment open duration, set `circuit_state = 'open'` | Test delivery fails |\n\nThe **closed state** represents normal operation where all delivery attempts are allowed to proceed. The system tracks consecutive failures for each endpoint, incrementing the `failure_count` field in the `WebhookRegistration` record after each failed delivery attempt. When this count reaches the `CIRCUIT_BREAKER_FAILURE_THRESHOLD` (typically 5 consecutive failures), the circuit breaker transitions to the open state.\n\nIn the **open state**, the circuit breaker immediately rejects all delivery attempts without making HTTP requests to the failing endpoint. This prevents resource waste on requests that are likely to fail and allows the delivery system to focus on healthy endpoints. The system sets a recovery timer (starting at 60 seconds, with exponential backoff for repeated openings) that eventually transitions the breaker to half-open state.\n\nThe **half-open state** serves as a cautious testing phase where the system allows a single delivery attempt to probe whether the endpoint has recovered. If this test delivery succeeds, the endpoint is considered healthy and the circuit returns to closed state with reset failure counters. If the test fails, the circuit returns to open state with an increased recovery timeout (doubled from the previous duration, capped at 30 minutes).\n\n#### Circuit Breaker Implementation Strategy\n\n> **Decision: Failure Count vs Time Window Approach**\n> - **Context**: Need to determine how to measure endpoint failures for circuit breaker activation\n> - **Options Considered**: Consecutive failure count, sliding window failure rate, exponential decay scoring\n> - **Decision**: Consecutive failure count with success-based reset\n> - **Rationale**: Consecutive failures indicate persistent endpoint issues requiring immediate protection. Rate-based approaches can miss sustained outages if occasional successes reset the window. Exponential decay adds complexity without clear reliability benefits for webhook delivery patterns.\n> - **Consequences**: May open circuits for temporary network blips, but provides fast protection against sustained failures. Simple to implement and reason about during debugging.\n\nThe circuit breaker state is persisted in the `WebhookRegistration` record to survive system restarts and enable coordination across multiple delivery workers. The key fields for circuit breaker operation include:\n\n| Field Name | Type | Description | Usage |\n|------------|------|-------------|--------|\n| `failure_count` | int | Consecutive delivery failures | Compared against threshold for state transitions |\n| `circuit_state` | str | Current breaker state ('closed', 'open', 'half_open') | Controls delivery attempt behavior |\n| `last_success_at` | datetime | Timestamp of most recent successful delivery | Used for health monitoring and recovery decisions |\n| `circuit_opened_at` | datetime | When circuit last opened | Calculates recovery timeout expiration |\n| `circuit_recovery_timeout` | int | Seconds until next recovery attempt | Exponentially increased after repeated failures |\n\nThe delivery worker checks circuit breaker state before attempting any webhook delivery. For closed circuits, delivery proceeds normally. For open circuits, the worker immediately marks the attempt as failed with `circuit_breaker_triggered = true` in the `DeliveryAttempt` record and schedules the event for retry after the circuit recovery timeout expires.\n\nDuring half-open state, only a single delivery worker should attempt the test delivery to prevent thundering herd conditions. This is coordinated using Redis atomic operations:\n\n1. Worker checks if circuit is half-open and no test is in progress\n2. Worker attempts to set a Redis key `circuit_test:{webhook_id}` with short TTL (10 seconds)\n3. If successful, worker proceeds with test delivery; if key exists, worker backs off\n4. After test completion, worker updates circuit state and clears the test coordination key\n\n#### Adaptive Recovery Timing\n\nThe circuit breaker implements adaptive recovery timing that increases open duration after repeated failures, preventing rapid cycling between open and half-open states for persistently failing endpoints.\n\n| Failure Cycle | Recovery Timeout | Rationale |\n|---------------|------------------|-----------|\n| First opening | 60 seconds | Quick recovery for temporary issues |\n| Second opening | 120 seconds | Longer grace period for service restarts |\n| Third opening | 300 seconds | Extended timeout for maintenance windows |\n| Fourth+ opening | 600 seconds (10 minutes) | Maximum timeout for persistent failures |\n\nThis exponential backoff approach balances quick recovery for transient issues with system protection against long-term failures. The recovery timeout resets to 60 seconds after any successful delivery, allowing endpoints that recover to immediately return to normal operation cadence.\n\n![Retry Decision Flowchart](./diagrams/retry-flowchart.svg)\n\n### Rate Limiting Strategy\n\nRate limiting prevents webhook delivery systems from overwhelming downstream endpoints, even when those endpoints are healthy and responding successfully. Unlike circuit breakers that respond to failures, rate limiting provides proactive protection by controlling the delivery pace regardless of endpoint health status.\n\n> **Decision: Token Bucket vs Sliding Window Rate Limiting**\n> - **Context**: Need to control delivery rate per endpoint while allowing reasonable burst capacity and respecting endpoint preferences\n> - **Options Considered**: Token bucket algorithm, sliding window rate limiting, leaky bucket algorithm\n> - **Decision**: Token bucket with configurable refill rate and burst capacity\n> - **Rationale**: Token bucket naturally handles burst traffic by accumulating tokens during idle periods, matches common webhook consumer expectations, and integrates well with HTTP Retry-After header responses. Sliding windows require more complex time-based calculations and don't support bursting.\n> - **Consequences**: Allows temporary bursts above steady-state rate, requires token state persistence for multi-worker coordination, simpler to tune and monitor than sliding window approaches\n\n#### Token Bucket Implementation\n\nThe token bucket algorithm maintains a bucket of tokens for each webhook endpoint, with tokens representing permission to make delivery attempts. The bucket refills at a configured rate (default 60 tokens per minute, or 1 request per second) and has a maximum capacity that allows brief bursts above the sustained rate.\n\n| Token Bucket Parameter | Default Value | Configuration Field | Description |\n|------------------------|---------------|-------------------|-------------|\n| **Refill Rate** | 60 tokens/minute | `rate_limit_rpm` | Sustained delivery rate per endpoint |\n| **Bucket Capacity** | 10 tokens | `rate_limit_burst` | Maximum burst size above sustained rate |\n| **Token Refill Interval** | 1 second | `rate_limit_refill_interval` | How frequently to add tokens |\n| **Minimum Delivery Interval** | 1000ms | `min_delivery_interval_ms` | Absolute minimum time between requests |\n\nBefore attempting any webhook delivery, the delivery worker must acquire a token from the endpoint's bucket. If no tokens are available, the delivery attempt is delayed until the next refill cycle. This ensures that even healthy endpoints receive deliveries at a sustainable pace.\n\nThe token bucket state is maintained in Redis using atomic operations to coordinate across multiple delivery workers:\n\n| Redis Key Pattern | Value Type | Description | TTL |\n|------------------|------------|-------------|-----|\n| `rate_limit:{webhook_id}:tokens` | Integer | Current token count | 3600 seconds |\n| `rate_limit:{webhook_id}:last_refill` | Unix timestamp | Last refill time | 3600 seconds |\n| `rate_limit:{webhook_id}:locked_until` | Unix timestamp | Delay until next allowed request | Variable |\n\n#### Retry-After Header Handling\n\nWhen webhook endpoints return HTTP 429 (Too Many Requests) responses, they often include a `Retry-After` header specifying how long the client should wait before making another request. The rate limiting system respects these headers and temporarily reduces the delivery rate beyond the configured token bucket limits.\n\n```\nHTTP/1.1 429 Too Many Requests\nRetry-After: 300\nContent-Type: application/json\n\n{\"error\": \"Rate limit exceeded\", \"reset_time\": \"2024-01-15T10:35:00Z\"}\n```\n\nWhen a 429 response includes a `Retry-After` header, the system:\n\n1. Parses the header value (supports both delta-seconds and HTTP-date formats)\n2. Sets the `rate_limit:{webhook_id}:locked_until` Redis key to the calculated retry time\n3. Suspends all delivery attempts to that endpoint until the lock expires\n4. Resumes normal token bucket operation after the lock period\n\nThis mechanism allows webhook consumers to dynamically control their incoming rate during high load periods, maintenance windows, or capacity constraints.\n\n#### Dynamic Rate Limit Adjustment\n\nThe system supports dynamic rate limit adjustment based on endpoint response patterns and explicit consumer preferences. This enables automatic adaptation to endpoint capacity changes without requiring manual configuration updates.\n\n| Adjustment Trigger | Action Taken | Duration | Rationale |\n|-------------------|--------------|----------|-----------|\n| **Successful delivery < 100ms** | Increase rate limit by 10% | Until next failure | Endpoint has spare capacity |\n| **Successful delivery > 2000ms** | Decrease rate limit by 20% | 300 seconds | Endpoint showing stress signs |\n| **HTTP 429 response** | Set rate to 50% of current | Until Retry-After expires | Explicit endpoint feedback |\n| **Consecutive timeouts** | Decrease rate limit by 50% | 600 seconds | Endpoint overload indication |\n\nRate limit adjustments are bounded by configured minimum and maximum values to prevent runaway increases or decreases. The base rate limit from the webhook registration serves as the default value that the system returns to after adjustment periods expire.\n\n### Endpoint Health Monitoring\n\nContinuous health monitoring provides the observability foundation that enables circuit breakers and rate limiting to make informed decisions about endpoint status and capacity. The monitoring system tracks multiple health dimensions simultaneously to build a comprehensive view of each endpoint's operational status.\n\n#### Health Metrics Collection\n\nThe system collects detailed metrics for every delivery attempt, building a real-time picture of endpoint health across multiple dimensions. These metrics feed into both circuit breaker state decisions and rate limiting adjustments.\n\n| Metric Category | Specific Metrics | Collection Method | Retention Period |\n|----------------|------------------|------------------|------------------|\n| **Response Time** | p50, p90, p95, p99 latency | Histogram in Redis | 24 hours |\n| **Success Rate** | 2xx responses vs total attempts | Counter with time buckets | 7 days |\n| **Error Distribution** | Count by HTTP status code | Hash map per endpoint | 24 hours |\n| **Availability** | Uptime percentage over rolling window | Sliding window calculation | 24 hours |\n| **Throughput** | Successful deliveries per minute | Time-series data | 24 hours |\n\nResponse time tracking focuses on total delivery duration from HTTP request start to complete response processing. This includes DNS resolution, connection establishment, request transmission, server processing, and response download. High latencies often precede outright failures and can trigger preemptive rate limiting adjustments.\n\nSuccess rate calculation considers any HTTP response in the 2xx range as successful, with special handling for specific codes:\n\n| HTTP Status Range | Classification | Circuit Breaker Impact | Retry Behavior |\n|------------------|----------------|----------------------|----------------|\n| **2xx Success** | Healthy | Reset failure count | No retry needed |\n| **3xx Redirect** | Healthy | Reset failure count | Follow redirect if allowed |\n| **4xx Client Error** | Healthy (bad request) | Reset failure count | No retry (except 429) |\n| **429 Rate Limited** | Healthy (capacity limit) | Reset failure count | Retry after delay |\n| **5xx Server Error** | Unhealthy | Increment failure count | Retry with backoff |\n| **Timeout/Network** | Unhealthy | Increment failure count | Retry with backoff |\n\nThis classification scheme distinguishes between endpoint failures (5xx, timeouts) and request problems (4xx) that indicate healthy endpoints receiving invalid requests.\n\n#### Health Score Calculation\n\nThe system calculates a composite health score for each endpoint that combines multiple metrics into a single value between 0 (completely unhealthy) and 100 (perfectly healthy). This score drives circuit breaker state transitions and rate limiting adjustments.\n\n> **Decision: Composite Health Score vs Individual Thresholds**\n> - **Context**: Need to make circuit breaker and rate limiting decisions based on multiple health indicators\n> - **Options Considered**: Individual thresholds per metric, weighted composite score, machine learning-based health prediction\n> - **Decision**: Weighted composite health score with configurable weights\n> - **Rationale**: Individual thresholds create complex decision matrices and can conflict with each other. Composite scores provide a single decision point while preserving the ability to weight different aspects based on endpoint characteristics. ML approaches add significant complexity without clear accuracy benefits for webhook delivery patterns.\n> - **Consequences**: Requires tuning of weight values, may mask specific failure modes, but provides consistent decision-making framework across all endpoints\n\nThe health score combines five weighted components:\n\n| Component | Weight | Calculation Method | Score Range |\n|-----------|--------|-------------------|-------------|\n| **Success Rate** | 40% | (Successful requests / Total requests) × 100 | 0-100 |\n| **Response Time** | 25% | max(0, 100 - (p95_latency_ms / 50)) | 0-100 |\n| **Error Rate** | 20% | max(0, 100 - (5xx_count / total_count × 100)) | 0-100 |\n| **Availability** | 10% | (Non-timeout requests / Total requests) × 100 | 0-100 |\n| **Consistency** | 5% | 100 - (response_time_stddev / mean_response_time × 100) | 0-100 |\n\nThe overall health score is calculated as: `health_score = (success_rate × 0.4) + (response_time_score × 0.25) + (error_rate_score × 0.2) + (availability_score × 0.1) + (consistency_score × 0.05)`\n\nHealth scores are recalculated every 30 seconds using a sliding 10-minute window of delivery attempts. Circuit breaker thresholds are based on both consecutive failures and sustained low health scores:\n\n- Circuit opens when health score drops below 30 for more than 5 minutes\n- Circuit closes when health score exceeds 80 for more than 2 minutes in half-open state\n- Rate limits decrease when health score drops below 60\n- Rate limits increase when health score exceeds 90\n\n#### Alerting and Notification\n\nThe health monitoring system generates alerts when endpoints show signs of degradation, enabling proactive intervention before complete failures occur. Alerts are configured with escalation levels that match the severity of detected issues.\n\n| Alert Level | Trigger Conditions | Recipients | Response Time SLA |\n|-------------|-------------------|------------|-------------------|\n| **Info** | Health score 60-70 for 10 minutes | Endpoint owner (email) | No SLA - informational |\n| **Warning** | Health score 40-60 for 5 minutes | Endpoint owner (email + Slack) | 4 hours |\n| **Critical** | Health score < 40 or circuit breaker opens | Endpoint owner + webhook admin (PagerDuty) | 30 minutes |\n| **Emergency** | Multiple endpoints failing in same organization | All stakeholders (phone + PagerDuty) | 15 minutes |\n\nAlert notifications include actionable context that helps endpoint owners diagnose and resolve issues:\n\n- Recent error distribution with example error messages\n- Response time trends over the past hour\n- Comparison with typical performance baselines\n- Suggested remediation steps based on observed failure patterns\n- Direct links to delivery logs and debugging tools\n\nThe system implements alert fatigue prevention by grouping related alerts and suppressing duplicate notifications during known issue periods. When an endpoint's circuit breaker opens, subsequent health alerts are suppressed until the circuit returns to closed state.\n\n### Common Protection Pitfalls\n\n⚠️ **Pitfall: Premature Circuit Opening on Cold Starts**\n\nMany developers configure circuit breaker failure thresholds too aggressively, causing circuits to open during normal cold start periods when applications are initializing and may respond slowly or return temporary errors.\n\n**Why It's Wrong**: Applications often need 30-60 seconds to fully initialize after deployment or scaling events. A circuit breaker with a 3-failure threshold can open within seconds of a deployment, preventing the application from receiving the traffic it needs to finish warming up.\n\n**How to Fix**: Use minimum failure counts of 5-7 for most applications, implement cold start detection by tracking deployment events, and consider longer response timeouts (30+ seconds) during the first few minutes after circuit closure.\n\n⚠️ **Pitfall: Ignoring HTTP 4xx Responses in Circuit Breaker Logic**\n\nA common mistake is treating all HTTP error responses as endpoint failures, including 4xx client errors that indicate problems with the webhook payload rather than endpoint health.\n\n**Why It's Wrong**: When webhook payloads become malformed due to upstream bugs, treating 400 Bad Request responses as endpoint failures can open circuit breakers for perfectly healthy endpoints. This prevents delivery of valid webhook events that would succeed.\n\n**How to Fix**: Only count 5xx responses, timeouts, and connection failures as endpoint failures. Reset failure counts on 4xx responses since they indicate the endpoint is healthy enough to process and reject bad requests.\n\n⚠️ **Pitfall: Token Bucket Implementation Without Burst Capacity**\n\nImplementing rate limiting with strict per-second limits prevents endpoints from handling natural traffic bursts, even when they have available capacity.\n\n**Why It's Wrong**: Webhook traffic often comes in bursts - a social media post might generate 50 webhook events simultaneously, but the endpoint can handle this burst fine as long as sustained rate remains reasonable. Rejecting burst traffic creates artificial delays.\n\n**How to Fix**: Always implement token bucket capacity that's 3-5x the per-second rate limit. For a 10 RPS limit, allow a bucket capacity of 30-50 tokens so that bursts can be handled immediately while maintaining sustainable average rates.\n\n⚠️ **Pitfall: Circuit Breaker State Races in Multi-Worker Systems**\n\nIn distributed systems with multiple delivery workers, race conditions during circuit state transitions can cause inconsistent behavior where some workers think a circuit is open while others attempt deliveries.\n\n**Why It's Wrong**: Without proper coordination, multiple workers might simultaneously detect that a circuit should open, or worse, multiple workers might attempt \"test\" deliveries during half-open state, creating thundering herd conditions.\n\n**How to Fix**: Use atomic Redis operations for all circuit state changes, implement test delivery coordination with Redis locks during half-open state, and include circuit state timestamps to detect stale reads.\n\n⚠️ **Pitfall: Rate Limiting Without Retry-After Header Support**\n\nMany implementations ignore the `Retry-After` header in HTTP 429 responses, continuing to send requests at the configured rate limit even when endpoints explicitly request slower delivery.\n\n**Why It's Wrong**: Endpoints include `Retry-After` headers during maintenance windows, scaling events, or capacity issues. Ignoring these headers can cause unnecessary circuit breaker activations when the endpoint just needs temporary delivery pauses.\n\n**How to Fix**: Always parse and respect `Retry-After` headers from 429 responses. Suspend delivery attempts until the specified time, and consider this a successful interaction (don't increment failure counters) since the endpoint is communicating properly.\n\n⚠️ **Pitfall: Health Score Calculation Based on Insufficient Data**\n\nComputing health scores and making circuit breaker decisions based on small sample sizes leads to erratic behavior where single failed requests cause circuit openings.\n\n**Why It's Wrong**: An endpoint that receives 2 requests per hour shouldn't have its circuit opened because both requests in a 10-minute window failed. The sample size is too small to determine actual endpoint health.\n\n**How to Fix**: Require minimum request counts (10-20 requests) before computing health scores, extend observation windows for low-traffic endpoints, and use different thresholds based on request volume patterns.\n\n⚠️ **Pitfall: Circuit Breaker Recovery Without Exponential Backoff**\n\nImplementing fixed recovery timeouts causes repeated rapid cycling between open and half-open states for endpoints with sustained issues.\n\n**Why It's Wrong**: If an endpoint is down for maintenance, a 60-second recovery timeout will cause the circuit breaker to test every minute, generating unnecessary load and creating noise in monitoring systems.\n\n**How to Fix**: Implement exponential backoff for recovery timeouts, starting at 60 seconds and doubling on each failure up to a maximum of 10-15 minutes. Reset to base timeout only after successful deliveries.\n\n### Implementation Guidance\n\nThe circuit breaker and rate limiting components require careful coordination between multiple system layers. The following technology choices provide a robust foundation for implementing these protection mechanisms at scale.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **Circuit Breaker State Storage** | Redis with atomic operations | Redis Cluster with consistent hashing |\n| **Rate Limiting Backend** | Redis token bucket implementation | Redis with Lua scripts for atomicity |\n| **Health Metrics Collection** | Redis time-series with TTL | InfluxDB or TimescaleDB |\n| **Alerting System** | SMTP email + Slack webhooks | PagerDuty + OpsGenie integration |\n| **Configuration Management** | Environment variables + database | Consul/etcd with dynamic reloading |\n\n#### File Structure\n\n```\nproject-root/\n  src/\n    webhook_delivery/\n      protection/                    ← Circuit breaker and rate limiting\n        __init__.py\n        circuit_breaker.py          ← Circuit breaker state machine\n        rate_limiter.py             ← Token bucket rate limiting\n        health_monitor.py           ← Endpoint health tracking\n        protection_middleware.py     ← Integration with delivery pipeline\n        redis_backend.py            ← Redis operations for state storage\n      delivery/\n        worker.py                   ← Modified to integrate protection\n        queue_manager.py            ← Modified for circuit-aware queueing\n      models/\n        webhook.py                  ← Extended WebhookRegistration model\n        delivery.py                 ← Extended DeliveryAttempt model\n    config/\n      protection_config.py          ← Configuration constants and validation\n    tests/\n      protection/\n        test_circuit_breaker.py\n        test_rate_limiter.py\n        test_integration.py\n```\n\n#### Infrastructure Starter Code\n\n**Redis Backend Operations** (`protection/redis_backend.py`):\n```python\nimport redis\nimport json\nimport time\nfrom typing import Optional, Dict, Any\nfrom datetime import datetime, timedelta\n\nclass RedisBackend:\n    \"\"\"Redis operations for circuit breaker and rate limiting state management.\"\"\"\n    \n    def __init__(self, redis_url: str):\n        self.redis = redis.from_url(redis_url, decode_responses=True)\n        \n    def get_circuit_state(self, webhook_id: str) -> Dict[str, Any]:\n        \"\"\"Get current circuit breaker state for webhook endpoint.\"\"\"\n        pipe = self.redis.pipeline()\n        pipe.hgetall(f\"circuit:{webhook_id}\")\n        pipe.get(f\"circuit_test_lock:{webhook_id}\")\n        \n        result = pipe.execute()\n        state_data = result[0]\n        test_lock = result[1]\n        \n        return {\n            'state': state_data.get('state', 'closed'),\n            'failure_count': int(state_data.get('failure_count', 0)),\n            'opened_at': float(state_data.get('opened_at', 0)),\n            'recovery_timeout': int(state_data.get('recovery_timeout', 60)),\n            'test_in_progress': test_lock is not None\n        }\n    \n    def update_circuit_state(self, webhook_id: str, state: str, failure_count: int = 0, recovery_timeout: int = 60) -> bool:\n        \"\"\"Atomically update circuit breaker state.\"\"\"\n        current_time = time.time()\n        \n        state_data = {\n            'state': state,\n            'failure_count': failure_count,\n            'recovery_timeout': recovery_timeout\n        }\n        \n        if state == 'open':\n            state_data['opened_at'] = current_time\n        \n        return self.redis.hset(f\"circuit:{webhook_id}\", mapping=state_data)\n    \n    def acquire_test_lock(self, webhook_id: str, ttl_seconds: int = 10) -> bool:\n        \"\"\"Acquire exclusive lock for circuit breaker test delivery.\"\"\"\n        return self.redis.set(f\"circuit_test_lock:{webhook_id}\", \"locked\", nx=True, ex=ttl_seconds)\n    \n    def release_test_lock(self, webhook_id: str) -> None:\n        \"\"\"Release circuit breaker test lock.\"\"\"\n        self.redis.delete(f\"circuit_test_lock:{webhook_id}\")\n    \n    def get_rate_limit_tokens(self, webhook_id: str, rate_limit_rpm: int) -> int:\n        \"\"\"Get current token count for rate limiting bucket.\"\"\"\n        current_time = time.time()\n        \n        # Lua script for atomic token bucket operations\n        lua_script = \"\"\"\n        local bucket_key = KEYS[1]\n        local refill_key = KEYS[2]\n        local current_time = tonumber(ARGV[1])\n        local rate_limit_rpm = tonumber(ARGV[2])\n        local max_tokens = tonumber(ARGV[3])\n        \n        local current_tokens = tonumber(redis.call('GET', bucket_key) or max_tokens)\n        local last_refill = tonumber(redis.call('GET', refill_key) or current_time)\n        \n        -- Calculate tokens to add based on elapsed time\n        local elapsed_seconds = current_time - last_refill\n        local tokens_to_add = math.floor(elapsed_seconds * rate_limit_rpm / 60)\n        \n        if tokens_to_add > 0 then\n            current_tokens = math.min(max_tokens, current_tokens + tokens_to_add)\n            redis.call('SET', bucket_key, current_tokens, 'EX', 3600)\n            redis.call('SET', refill_key, current_time, 'EX', 3600)\n        end\n        \n        return current_tokens\n        \"\"\"\n        \n        max_tokens = max(10, rate_limit_rpm // 6)  # 10-second burst capacity\n        \n        return self.redis.eval(\n            lua_script,\n            2,\n            f\"rate_limit:{webhook_id}:tokens\",\n            f\"rate_limit:{webhook_id}:last_refill\",\n            current_time,\n            rate_limit_rpm,\n            max_tokens\n        )\n    \n    def consume_rate_limit_token(self, webhook_id: str) -> bool:\n        \"\"\"Attempt to consume a rate limiting token.\"\"\"\n        lua_script = \"\"\"\n        local bucket_key = KEYS[1]\n        local current_tokens = tonumber(redis.call('GET', bucket_key) or 0)\n        \n        if current_tokens > 0 then\n            redis.call('DECR', bucket_key)\n            return 1\n        else\n            return 0\n        end\n        \"\"\"\n        \n        return bool(self.redis.eval(lua_script, 1, f\"rate_limit:{webhook_id}:tokens\"))\n```\n\n**Protection Configuration** (`config/protection_config.py`):\n```python\nfrom dataclasses import dataclass\nfrom typing import Dict, Any\nimport os\n\n@dataclass\nclass CircuitBreakerConfig:\n    \"\"\"Circuit breaker configuration parameters.\"\"\"\n    failure_threshold: int = 5\n    recovery_timeout_base: int = 60  # seconds\n    recovery_timeout_max: int = 600  # 10 minutes\n    health_score_threshold: int = 30\n    half_open_test_timeout: int = 10  # seconds\n    \n@dataclass \nclass RateLimitConfig:\n    \"\"\"Rate limiting configuration parameters.\"\"\"\n    default_rpm: int = 60\n    burst_multiplier: float = 2.0\n    refill_interval: int = 1  # seconds\n    retry_after_max: int = 3600  # 1 hour maximum delay\n    dynamic_adjustment: bool = True\n    \n@dataclass\nclass HealthMonitorConfig:\n    \"\"\"Health monitoring configuration parameters.\"\"\"\n    metrics_window: int = 600  # 10 minutes\n    metrics_retention: int = 86400  # 24 hours\n    health_check_interval: int = 30  # seconds\n    min_requests_for_score: int = 10\n    \ndef load_protection_config() -> Dict[str, Any]:\n    \"\"\"Load protection configuration from environment and defaults.\"\"\"\n    return {\n        'circuit_breaker': CircuitBreakerConfig(\n            failure_threshold=int(os.getenv('CIRCUIT_BREAKER_FAILURE_THRESHOLD', 5)),\n            recovery_timeout_base=int(os.getenv('CIRCUIT_RECOVERY_TIMEOUT_BASE', 60)),\n            recovery_timeout_max=int(os.getenv('CIRCUIT_RECOVERY_TIMEOUT_MAX', 600))\n        ),\n        'rate_limit': RateLimitConfig(\n            default_rpm=int(os.getenv('RATE_LIMIT_DEFAULT_RPM', 60)),\n            burst_multiplier=float(os.getenv('RATE_LIMIT_BURST_MULTIPLIER', 2.0)),\n            dynamic_adjustment=os.getenv('RATE_LIMIT_DYNAMIC', 'true').lower() == 'true'\n        ),\n        'health_monitor': HealthMonitorConfig(\n            metrics_window=int(os.getenv('HEALTH_METRICS_WINDOW', 600)),\n            health_check_interval=int(os.getenv('HEALTH_CHECK_INTERVAL', 30))\n        )\n    }\n```\n\n#### Core Logic Skeleton Code\n\n**Circuit Breaker State Machine** (`protection/circuit_breaker.py`):\n```python\nfrom enum import Enum\nfrom typing import Optional, Dict, Any\nfrom datetime import datetime\nimport time\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"\n    OPEN = \"open\" \n    HALF_OPEN = \"half_open\"\n\nclass CircuitBreaker:\n    \"\"\"Per-endpoint circuit breaker with state persistence.\"\"\"\n    \n    def __init__(self, redis_backend, config: Dict[str, Any]):\n        self.redis = redis_backend\n        self.config = config['circuit_breaker']\n    \n    def should_allow_delivery(self, webhook_id: str) -> bool:\n        \"\"\"Check if delivery should be attempted based on circuit state.\"\"\"\n        # TODO 1: Get current circuit state from Redis\n        # TODO 2: If state is CLOSED, return True\n        # TODO 3: If state is OPEN, check if recovery timeout has passed\n        # TODO 4: If recovery timeout passed, transition to HALF_OPEN and return True\n        # TODO 5: If state is HALF_OPEN, check if test lock can be acquired\n        # TODO 6: Return True only if test lock acquired, False otherwise\n        pass\n    \n    def record_success(self, webhook_id: str) -> None:\n        \"\"\"Record successful delivery and update circuit state.\"\"\"\n        # TODO 1: Get current circuit state\n        # TODO 2: If state is HALF_OPEN, transition to CLOSED\n        # TODO 3: Reset failure count to 0\n        # TODO 4: Update last_success_at timestamp\n        # TODO 5: Release any active test locks\n        # Hint: Use atomic Redis operations for state changes\n        pass\n    \n    def record_failure(self, webhook_id: str, error_type: str) -> None:\n        \"\"\"Record delivery failure and update circuit state.\"\"\"\n        # TODO 1: Get current circuit state and failure count\n        # TODO 2: Increment failure count\n        # TODO 3: If state is HALF_OPEN, transition to OPEN with increased timeout\n        # TODO 4: If state is CLOSED and failure count exceeds threshold, transition to OPEN\n        # TODO 5: Calculate next recovery timeout with exponential backoff\n        # TODO 6: Log circuit state changes for monitoring\n        pass\n    \n    def calculate_recovery_timeout(self, current_timeout: int, failure_cycle: int) -> int:\n        \"\"\"Calculate next recovery timeout with exponential backoff.\"\"\"\n        # TODO 1: Start with base timeout from config\n        # TODO 2: Apply exponential backoff: timeout = base * (2 ** (failure_cycle - 1))\n        # TODO 3: Cap at maximum timeout from config\n        # TODO 4: Return calculated timeout\n        # Hint: failure_cycle represents how many times circuit has opened\n        pass\n```\n\n**Token Bucket Rate Limiter** (`protection/rate_limiter.py`):\n```python\nfrom typing import Optional, Tuple\nimport time\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass RateLimiter:\n    \"\"\"Token bucket rate limiter with Redis backend.\"\"\"\n    \n    def __init__(self, redis_backend, config: Dict[str, Any]):\n        self.redis = redis_backend\n        self.config = config['rate_limit']\n    \n    def can_proceed(self, webhook_id: str, rate_limit_rpm: int) -> Tuple[bool, Optional[float]]:\n        \"\"\"Check if delivery can proceed and return delay if rate limited.\"\"\"\n        # TODO 1: Check for active Retry-After lock from previous 429 responses\n        # TODO 2: If locked, return False and remaining lock time\n        # TODO 3: Get current token count using redis_backend.get_rate_limit_tokens()\n        # TODO 4: If tokens available, consume one token and return True\n        # TODO 5: If no tokens, calculate delay until next token refill\n        # TODO 6: Return False with calculated delay\n        pass\n    \n    def handle_retry_after_response(self, webhook_id: str, retry_after_seconds: int) -> None:\n        \"\"\"Handle HTTP 429 response with Retry-After header.\"\"\"\n        # TODO 1: Validate retry_after_seconds against maximum allowed delay\n        # TODO 2: Set Redis lock key with expiration matching retry_after\n        # TODO 3: Log rate limiting activation for monitoring\n        # TODO 4: Optionally adjust base rate limit if dynamic adjustment enabled\n        # Hint: Use Redis SETEX for atomic lock creation with TTL\n        pass\n    \n    def adjust_rate_limit(self, webhook_id: str, response_time_ms: float, success: bool) -> None:\n        \"\"\"Dynamically adjust rate limits based on endpoint performance.\"\"\"\n        # TODO 1: Check if dynamic adjustment is enabled in config\n        # TODO 2: If response time < 100ms and success, consider rate increase\n        # TODO 3: If response time > 2000ms, consider rate decrease  \n        # TODO 4: Calculate new rate limit within configured bounds\n        # TODO 5: Update rate limit in webhook registration if significantly changed\n        # TODO 6: Log rate limit changes for monitoring\n        pass\n    \n    def calculate_next_token_time(self, rate_limit_rpm: int) -> float:\n        \"\"\"Calculate when next token will be available.\"\"\"\n        # TODO 1: Convert RPM to tokens per second\n        # TODO 2: Calculate seconds per token\n        # TODO 3: Return current time + seconds per token\n        # Hint: tokens_per_second = rate_limit_rpm / 60.0\n        pass\n```\n\n#### Milestone Checkpoint\n\nAfter implementing circuit breaker and rate limiting protection:\n\n1. **Start the webhook delivery system with Redis backend**\n2. **Register a test webhook endpoint that can simulate failures**\n3. **Send 10 webhook events to trigger circuit breaker**:\n   ```bash\n   curl -X POST http://localhost:8080/webhooks/test/events \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"event\": \"test\", \"data\": {\"message\": \"Circuit breaker test\"}}'\n   ```\n\n4. **Expected behavior**:\n   - First 5 delivery attempts should reach the endpoint\n   - Circuit should open after 5th consecutive failure\n   - Subsequent attempts should be rejected immediately without HTTP requests\n   - After 60 seconds, circuit should transition to half-open\n   - Single test delivery should be attempted in half-open state\n\n5. **Verification commands**:\n   ```bash\n   # Check circuit breaker state\n   redis-cli HGETALL circuit:webhook_test_id\n   \n   # Check rate limiting tokens\n   redis-cli GET rate_limit:webhook_test_id:tokens\n   \n   # View delivery attempt logs\n   curl http://localhost:8080/webhooks/test/delivery-log\n   ```\n\n6. **Signs of correct implementation**:\n   - Circuit state transitions logged in application logs\n   - Rate limiting respects token bucket refill timing\n   - Health metrics update after each delivery attempt\n   - No delivery attempts during circuit open state\n   - Test delivery coordination prevents multiple simultaneous attempts\n\n\n## Event Logging and Replay\n\n> **Milestone(s):** Milestone 4 (Event Log & Replay) - implements comprehensive delivery audit trail with replay capability for debugging, compliance, and recovery from delivery failures\n\n### Mental Model: The Digital Postal Service Archive\n\nThink of event logging as a comprehensive postal service archive that maintains detailed records of every letter sent, every delivery attempt made, and every response received. Just as a postal service might keep detailed logs of package tracking information, delivery attempts, and customer signatures for accountability and service improvement, our webhook delivery system maintains an exhaustive audit trail of every event processed.\n\nThe replay mechanism functions like a postal service's ability to resend a lost package or retry a failed delivery. When a customer calls to report a missing package, the postal service can look up the original shipment details, verify what happened, and initiate a new delivery using the same contents but with a fresh tracking number. Similarly, webhook event replay allows operators to re-deliver specific events while maintaining proper tracking and avoiding confusion with the original delivery attempts.\n\nThe archive system must balance completeness with storage efficiency - a postal service cannot keep every piece of mail forever but must retain records long enough to handle disputes and provide service accountability. Our event logging system faces the same challenge: maintaining comprehensive delivery history while managing storage costs through intelligent retention and archival policies.\n\n### Delivery Audit Trail: Complete Event Sourcing for Debugging and Compliance\n\nThe delivery audit trail serves as the system's memory, capturing every significant action and decision throughout the webhook delivery lifecycle. This comprehensive logging enables debugging complex delivery failures, provides compliance documentation for audit requirements, and supports operational analytics for system optimization.\n\n**Event Sourcing Architecture**\n\nThe audit trail implements event sourcing principles where every state change is captured as an immutable event record. Unlike traditional database updates that overwrite previous values, event sourcing appends new records that describe what happened, when it happened, and what the system state was at that moment. This approach provides several critical benefits for webhook delivery systems.\n\nFirst, it enables complete reconstruction of any delivery's history. When debugging a complex delivery failure that involved multiple retry attempts, circuit breaker activations, and rate limiting delays, operators can replay the exact sequence of events to understand what went wrong. Second, it provides audit compliance by maintaining an immutable record of all delivery attempts, making it impossible to lose or accidentally modify historical delivery data.\n\nThe event sourcing model captures multiple event types throughout the delivery lifecycle. These include delivery attempts with their HTTP responses, circuit breaker state transitions, rate limiting decisions, queue operations, and system-level events like worker crashes or configuration changes. Each event contains sufficient context to understand the system state at that moment without requiring external lookups.\n\n| Event Type | Captured Data | Storage Frequency | Retention Period |\n|------------|---------------|-------------------|------------------|\n| `delivery_attempted` | Request payload, headers, response status, timing | Every HTTP attempt | 90 days hot, 1 year cold |\n| `delivery_succeeded` | Final response, total attempts, duration | Successful completions | 30 days hot, 6 months cold |\n| `delivery_failed_permanent` | Final error, attempt history, DLQ placement | Permanent failures | 1 year hot, 3 years cold |\n| `circuit_breaker_opened` | Failure count, endpoint health, trigger reason | State transitions | 6 months hot, 2 years cold |\n| `rate_limit_applied` | Current rate, delay imposed, token bucket state | Rate limiting events | 7 days hot, 30 days cold |\n| `event_replayed` | Original event ID, replay reason, new delivery ID | Manual replays | 1 year hot, permanent cold |\n| `secret_rotated` | Webhook ID, old/new secret IDs, rotation reason | Security operations | 2 years hot, permanent cold |\n| `worker_crashed` | Worker instance, active deliveries, crash reason | System failures | 30 days hot, 1 year cold |\n\n**Delivery Attempt Logging Schema**\n\nThe `DeliveryAttempt` records form the core of the audit trail, capturing comprehensive information about each HTTP delivery attempt. These records enable detailed analysis of delivery patterns, endpoint behavior, and system performance.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `id` | str | Unique identifier for this delivery attempt |\n| `event_id` | str | Reference to the original webhook event |\n| `webhook_id` | str | Target webhook endpoint identifier |\n| `attempt_number` | int | Sequential attempt number (1-based) within this delivery |\n| `status_code` | int | HTTP response status code (null if network failure) |\n| `response_time` | float | Total request duration in milliseconds |\n| `error_message` | str | Detailed error description for failed attempts |\n| `response_headers` | json | Complete HTTP response headers for analysis |\n| `response_body` | str | Response body (truncated if exceeds size limit) |\n| `request_headers` | json | HTTP request headers sent to endpoint |\n| `request_payload` | str | Complete request payload (may be compressed) |\n| `attempted_at` | datetime | When the HTTP request was initiated |\n| `completed_at` | datetime | When the response was received or timeout occurred |\n| `delivery_duration` | int | Time from queue claim to attempt completion |\n| `worker_instance` | str | Identifier of worker that processed this attempt |\n| `circuit_breaker_triggered` | bool | Whether circuit breaker prevented this attempt |\n\nThe schema design balances comprehensive logging with storage efficiency. Response bodies are truncated at 10KB to prevent storage explosion from verbose API responses, while still capturing enough information for debugging. Request payloads are stored with compression to reduce storage costs for large webhook events.\n\n**Time-Series Optimization Strategy**\n\nWebhook delivery logs exhibit strong time-series characteristics where recent data is accessed frequently for debugging and monitoring, while historical data serves primarily archival and compliance purposes. The logging system optimizes for this access pattern through a multi-tiered storage approach.\n\nHot storage maintains the most recent 30-90 days of delivery data in high-performance databases optimized for analytical queries. This tier uses time-series databases like InfluxDB or time-partitioned PostgreSQL tables that enable fast range queries and aggregations. The hot tier supports real-time debugging, monitoring dashboards, and operational analytics.\n\nWarm storage archives data from 30 days to 1-3 years in compressed formats optimized for occasional access. This tier typically uses object storage like S3 with intelligent tiering to automatically migrate less-accessed data to cheaper storage classes. Warm storage supports compliance audits, historical analysis, and replay operations that reference older events.\n\nCold storage provides long-term archival for data older than 1-3 years using the most cost-effective storage available. This tier may use glacier storage or tape backup systems with retrieval times measured in hours rather than seconds. Cold storage primarily serves legal compliance and forensic analysis requirements.\n\n> **Decision: Time-Series Partitioning Strategy**\n> - **Context**: Webhook delivery logs grow continuously and exhibit clear time-based access patterns where recent data is accessed frequently while historical data serves primarily compliance purposes\n> - **Options Considered**: Single table with indexes, hash partitioning by webhook ID, time-based partitioning by delivery date\n> - **Decision**: Time-based partitioning with monthly partitions and automated migration between storage tiers\n> - **Rationale**: Time-based partitioning aligns with natural access patterns, enables efficient data lifecycle management, supports fast queries on recent data while maintaining cost-effective long-term storage\n> - **Consequences**: Requires partition management automation, enables predictable storage cost scaling, simplifies backup and archival processes, may complicate cross-partition queries\n\n### Event Replay Mechanism: Safe Re-delivery with Deduplication and Rate Limit Respect\n\nEvent replay provides operators with the ability to re-deliver specific webhook events after resolving delivery failures or endpoint issues. The replay mechanism must handle this operation safely without overwhelming recovered endpoints, creating duplicate deliveries, or bypassing established security and rate limiting controls.\n\n**Replay Safety and Deduplication**\n\nSafe event replay requires careful handling of idempotency to prevent duplicate processing by webhook endpoints. When an event is replayed, the receiving endpoint must be able to distinguish between the original delivery attempt and the replay, even if both requests contain identical payloads.\n\nThe system generates a new delivery identifier for each replay operation while maintaining references to the original event. This approach provides clear audit trails showing the relationship between original and replayed deliveries while giving endpoints the information needed to implement proper deduplication.\n\nThe HMAC signature generation for replayed events includes additional metadata to ensure uniqueness while maintaining security. The signature calculation incorporates the original event ID, the new delivery ID, and a replay timestamp to create a signature that is cryptographically distinct from the original delivery.\n\n```\nReplay Signature Components:\n- Original event payload (unchanged)\n- Original event ID and timestamp\n- New delivery ID and replay timestamp\n- Replay reason and operator identification\n- Webhook secret (current active secret, not original)\n```\n\nHeaders sent with replayed events include explicit replay indicators that help endpoints implement appropriate handling. The `X-Webhook-Replay` header contains the original event ID and delivery timestamp, while `X-Webhook-Delivery-Id` contains the new delivery identifier for this replay attempt.\n\n**Replay Rate Limiting and Endpoint Protection**\n\nReplay operations must respect the same rate limiting and circuit breaker protections applied to normal webhook deliveries. This prevents operators from accidentally overwhelming endpoints through bulk replay operations and maintains the system's protective mechanisms.\n\nWhen multiple events are selected for replay, the system schedules them through the normal delivery queues rather than attempting immediate delivery. This approach ensures that replayed events compete fairly with new events for delivery capacity and respect per-endpoint rate limits.\n\n| Replay Scenario | Rate Limiting Behavior | Circuit Breaker Behavior | Scheduling Strategy |\n|------------------|------------------------|--------------------------|-------------------|\n| Single event replay | Uses current endpoint rate limit | Respects current circuit state | Immediate queue placement |\n| Bulk replay (< 100 events) | Spreads over 1-hour window | Halts if circuit opens during replay | Gradual queue placement |\n| Bulk replay (> 100 events) | Spreads over 24-hour window | Requires manual circuit override | Background batch processing |\n| Historical replay (> 30 days old) | Reduced rate limit (50% of normal) | Requires operator acknowledgment | Low priority queue |\n\nThe replay system includes safeguards against replay storms where operators accidentally trigger massive replay operations. Bulk replay requests require explicit confirmation and are processed in the background with progress reporting. If an endpoint's circuit breaker opens during a bulk replay operation, the system pauses the replay and alerts the operator rather than continuing to attempt deliveries to a known-failing endpoint.\n\n**Replay Audit and Metadata Tracking**\n\nEvery replay operation creates comprehensive audit records that capture the replay decision, execution, and results. This audit trail helps operators understand the impact of replay operations and provides accountability for manual system interventions.\n\n| Replay Audit Field | Type | Description |\n|--------------------|------|-------------|\n| `replay_id` | str | Unique identifier for this replay operation |\n| `operator_id` | str | Identity of operator who initiated replay |\n| `original_event_ids` | list | Events selected for replay |\n| `replay_reason` | str | Operator-provided justification for replay |\n| `replay_requested_at` | datetime | When replay was requested |\n| `replay_completed_at` | datetime | When all replay deliveries finished |\n| `events_replayed` | int | Number of events successfully replayed |\n| `events_failed_replay` | int | Number of events that failed during replay |\n| `endpoints_affected` | list | Webhook endpoints that received replayed events |\n| `delivery_ids_generated` | list | New delivery IDs created for replay attempts |\n\nThe replay metadata enables operators to track the effectiveness of replay operations and understand their impact on system performance. This information supports decision-making about future replay strategies and helps identify patterns in delivery failures that might require systemic fixes rather than individual event replay.\n\n> **Decision: Replay Deduplication Strategy**\n> - **Context**: Replayed events must be distinguishable from original deliveries to prevent duplicate processing while maintaining security through proper signature validation\n> - **Options Considered**: Same delivery ID with replay flag, new delivery ID with original reference, separate replay-specific endpoints\n> - **Decision**: New delivery ID for each replay with original event metadata in headers and signature\n> - **Rationale**: Provides clear audit separation between original and replayed deliveries, enables endpoint deduplication through delivery ID tracking, maintains signature security while indicating replay context\n> - **Consequences**: Requires endpoint updates to handle replay headers, creates additional audit complexity, enables precise replay tracking and prevents accidental duplicate processing\n\n### Log Retention and Archival: Time-Series Optimization with Cold Storage Migration\n\nWebhook delivery logs accumulate rapidly in high-volume systems, requiring sophisticated retention and archival strategies to balance operational needs with storage costs. The system must maintain immediate access to recent delivery data while providing cost-effective long-term storage for compliance and forensic analysis.\n\n**Hierarchical Storage Management**\n\nThe log retention system implements hierarchical storage management (HSM) that automatically migrates data between storage tiers based on age and access patterns. This approach optimizes costs while maintaining appropriate access performance for different use cases.\n\nThe hot storage tier maintains 30-90 days of delivery logs in high-performance databases optimized for analytical queries and real-time access. This tier uses SSD storage with aggressive caching and supports the real-time monitoring, debugging, and alerting operations that require immediate data access.\n\nHot tier storage uses time-partitioned tables that enable efficient pruning and migration operations. Daily partitions allow granular control over data movement while maintaining query performance through partition elimination. The partitioning strategy aligns with natural query patterns where most operational queries focus on recent time windows.\n\n| Storage Tier | Duration | Access Time | Storage Cost | Query Performance | Use Cases |\n|--------------|----------|-------------|-------------|-------------------|-----------|\n| Hot (SSD) | 30-90 days | < 100ms | High ($0.10/GB/month) | Excellent | Real-time debugging, monitoring dashboards |\n| Warm (Standard) | 90 days - 1 year | < 1 second | Medium ($0.05/GB/month) | Good | Historical analysis, replay operations |\n| Cold (Archive) | 1-3 years | < 1 minute | Low ($0.01/GB/month) | Fair | Compliance audits, forensic analysis |\n| Glacier (Deep Archive) | > 3 years | < 4 hours | Very Low ($0.002/GB/month) | Restore required | Legal compliance, long-term forensics |\n\n**Automated Migration Pipelines**\n\nData migration between storage tiers operates through automated pipelines that run continuously to maintain appropriate data distribution. These pipelines handle compression, format optimization, and metadata preservation during migration operations.\n\nThe migration process preserves data integrity through checksums and validation steps at each tier transition. Before removing data from a higher-performance tier, the system verifies successful migration and validates that the archived data can be retrieved and decompressed correctly.\n\nMigration operations run during low-traffic periods to minimize impact on operational performance. The system monitors query patterns and adjusts migration timing to avoid moving frequently accessed data during peak usage periods.\n\nData compression strategies vary by storage tier to optimize for access patterns and cost requirements. Hot storage uses minimal compression to maintain query performance, warm storage applies medium compression for balanced access and cost, while cold storage uses aggressive compression to minimize storage costs.\n\n| Migration Trigger | Source Tier | Target Tier | Compression Ratio | Validation Process |\n|-------------------|-------------|-------------|------------------|-------------------|\n| Age > 30 days | Hot | Warm | 2:1 | Checksum validation, sample query test |\n| Age > 1 year | Warm | Cold | 5:1 | Full data integrity check, restore test |\n| Age > 3 years | Cold | Glacier | 8:1 | Cryptographic hash validation |\n| Access < 1/month | Any | Lower tier | Varies | Access pattern analysis |\n\n**Retention Policy Configuration**\n\nRetention policies provide flexible control over data lifecycle management while ensuring compliance with legal and business requirements. The system supports multiple retention schedules that can be configured per webhook, event type, or organizational policy.\n\nDefault retention policies balance operational needs with storage costs, but organizations can customize retention based on specific compliance requirements or business needs. Some industries require longer retention periods for audit purposes, while others prioritize cost optimization through aggressive data lifecycle management.\n\nThe retention configuration supports both time-based and size-based policies. Time-based policies automatically archive or delete data after specific durations, while size-based policies manage storage consumption by archiving oldest data when storage limits are approached.\n\nRetention policies include legal hold capabilities that prevent automatic deletion of data involved in legal proceedings or compliance investigations. When a legal hold is placed, the system suspends normal retention processing for affected data until the hold is released.\n\n| Policy Type | Configuration Options | Enforcement Method | Override Capabilities |\n|-------------|----------------------|-------------------|----------------------|\n| Time-based | Hot (30-180 days), Warm (1-5 years), Cold (3-10 years) | Automated daily processing | Legal hold suspension |\n| Size-based | Per-webhook limits, total system limits | Triggered by storage monitoring | Emergency retention extension |\n| Compliance-based | Industry-specific requirements (PCI, HIPAA, SOX) | Regulatory compliance engine | Audit-approved modifications only |\n| Event-specific | Critical vs normal event classification | Event metadata-driven | Manual operator override |\n\n### Common Logging Pitfalls\n\n⚠️ **Pitfall: Unbounded Log Growth Leading to Storage Explosion**\n\nMany webhook delivery implementations start with simple logging that captures every delivery attempt without considering long-term storage implications. In high-volume systems processing millions of webhooks daily, this approach quickly leads to storage costs that exceed the entire infrastructure budget and query performance degradation that makes the logs unusable for debugging.\n\nThe root cause is treating webhook logs like traditional application logs with simple append-only behavior. Unlike application logs that are primarily used for debugging during development, webhook delivery logs serve operational, compliance, and business intelligence purposes that require different retention and access strategies.\n\nTo prevent storage explosion, implement tiered storage from the beginning rather than attempting to retrofit it after storage costs become problematic. Design log schemas to support compression by avoiding highly variable fields that compress poorly, and implement automated retention policies that enforce data lifecycle management without manual intervention.\n\nEstablish storage budgets and monitoring alerts that trigger when log storage grows beyond expected patterns. This early warning system prevents surprise storage costs and enables proactive capacity planning for log infrastructure.\n\n⚠️ **Pitfall: Replay Storms Overwhelming Recovered Endpoints**\n\nOperators often attempt to resolve delivery failures through bulk event replay without considering the cumulative load this places on recovered endpoints. When an endpoint experiences downtime and accumulates hundreds of failed deliveries, replaying all events simultaneously can overwhelm the recovered endpoint and cause it to fail again.\n\nThis problem is particularly common when operators bypass normal rate limiting and circuit breaker protections during replay operations, believing that these protective mechanisms are unnecessary for retry operations. The result is often a cycle where replay operations trigger new failures that require additional replay operations.\n\nImplement replay throttling that spreads replayed events over time windows appropriate to the endpoint's normal capacity. Use the same rate limiting infrastructure for replay operations that protects normal webhook deliveries, and consider implementing reduced rate limits for bulk replay operations to provide additional safety margin.\n\nDesign replay interfaces that encourage operators to start with small batches and verify endpoint behavior before proceeding with larger replay operations. Provide clear feedback about replay progress and endpoint health during bulk operations to help operators make informed decisions about continuing or pausing replay processes.\n\n⚠️ **Pitfall: Inadequate Retention Policy Leading to Compliance Violations**\n\nOrganizations often implement webhook logging without consulting legal and compliance teams about data retention requirements. This oversight can lead to either premature data deletion that violates regulatory requirements or excessive data retention that increases privacy risks and storage costs.\n\nDifferent types of webhook events may have different retention requirements based on the data they contain and the business processes they support. Payment webhooks might require longer retention for financial auditing, while user activity webhooks might need shorter retention to comply with privacy regulations.\n\nEstablish retention policies through collaboration between engineering, legal, and compliance teams before implementing the logging system. Document the business and legal justification for each retention period to support future audits and policy reviews.\n\nImplement retention policy enforcement that is auditable and reversible. Avoid hard deletion in favor of archival strategies that can restore data if retention policies change or legal holds are imposed on historical data.\n\n⚠️ **Pitfall: Insufficient Replay Deduplication Causing Business Logic Errors**\n\nWebhook endpoints that do not properly implement idempotency checking can experience significant business logic errors when events are replayed. For example, replaying payment confirmation webhooks might trigger duplicate payment processing, or replaying user registration webhooks might create multiple user accounts.\n\nThe problem is compounded when the webhook delivery system does not provide sufficient metadata for endpoints to implement proper deduplication. Without delivery IDs, replay indicators, or original event timestamps, endpoints cannot reliably distinguish between legitimate duplicate events and replayed events.\n\nDesign replay mechanisms to include comprehensive metadata that enables endpoint deduplication. Include original event IDs, delivery IDs, replay flags, and original delivery timestamps in replay requests to give endpoints all information needed for proper duplicate detection.\n\nProvide clear documentation and examples showing how endpoints should implement idempotency checking using the replay metadata. Consider offering client libraries that handle deduplication automatically to reduce the implementation burden on webhook consumers.\n\n### Implementation Guidance\n\nThe event logging and replay system requires careful balance between comprehensive data capture and system performance. This implementation provides production-ready logging infrastructure with efficient storage management and safe replay capabilities.\n\n**Technology Recommendations**\n\n| Component | Simple Option | Advanced Option |\n|-----------|--------------|-----------------|\n| Time-Series Database | PostgreSQL with time partitions | InfluxDB or TimescaleDB |\n| Object Storage | Local filesystem with rotation | AWS S3 with Intelligent Tiering |\n| Data Pipeline | Celery background tasks | Apache Kafka with Kafka Streams |\n| Compression | gzip built-in compression | Parquet with Snappy compression |\n| Query Interface | SQL queries with indexes | Grafana with pre-built dashboards |\n\n**File Structure**\n\n```\nwebhook-system/\n├── internal/\n│   ├── logging/\n│   │   ├── audit_logger.py           ← Main logging interface\n│   │   ├── storage_manager.py        ← Tiered storage management\n│   │   ├── replay_engine.py          ← Event replay functionality\n│   │   └── retention_policy.py       ← Data lifecycle management\n│   ├── storage/\n│   │   ├── time_series_db.py         ← Time-series database interface\n│   │   └── object_store.py           ← Object storage interface\n│   └── models/\n│       ├── delivery_attempt.py       ← Delivery attempt data model\n│       └── replay_request.py         ← Replay request data model\n├── scripts/\n│   ├── migrate_logs.py               ← Storage tier migration\n│   └── cleanup_expired_logs.py       ← Retention policy enforcement\n└── tests/\n    ├── test_audit_logging.py\n    ├── test_replay_engine.py\n    └── test_storage_migration.py\n```\n\n**Audit Logger Infrastructure (Complete Implementation)**\n\n```python\nimport json\nimport logging\nimport time\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, asdict\nimport hashlib\nimport gzip\nfrom contextlib import contextmanager\n\nfrom ..storage.time_series_db import TimeSeriesDB\nfrom ..storage.object_store import ObjectStore\nfrom ..models.delivery_attempt import DeliveryAttempt\nfrom ..config import WebhookConfig\n\n@dataclass\nclass AuditEvent:\n    \"\"\"Base class for all audit events in the webhook system.\"\"\"\n    event_type: str\n    timestamp: datetime\n    webhook_id: str\n    event_id: Optional[str] = None\n    metadata: Dict[str, Any] = None\n    \n    def to_json(self) -> str:\n        \"\"\"Serialize audit event to JSON string.\"\"\"\n        data = asdict(self)\n        data['timestamp'] = self.timestamp.isoformat()\n        return json.dumps(data, separators=(',', ':'))\n    \n    @classmethod\n    def from_json(cls, json_str: str) -> 'AuditEvent':\n        \"\"\"Deserialize audit event from JSON string.\"\"\"\n        data = json.loads(json_str)\n        data['timestamp'] = datetime.fromisoformat(data['timestamp'])\n        return cls(**data)\n\nclass AuditLogger:\n    \"\"\"\n    Comprehensive audit logging for webhook delivery system.\n    \n    Captures all significant events in the webhook delivery lifecycle\n    including delivery attempts, circuit breaker changes, replay operations,\n    and system-level events. Implements tiered storage with automatic\n    migration and retention policy enforcement.\n    \"\"\"\n    \n    def __init__(self, config: WebhookConfig):\n        self.config = config\n        self.time_series_db = TimeSeriesDB(config.database_url)\n        self.object_store = ObjectStore(config.storage_config)\n        self.logger = logging.getLogger(__name__)\n        \n        # Storage tier thresholds\n        self.hot_retention_days = 30\n        self.warm_retention_days = 365\n        self.cold_retention_days = 1095  # 3 years\n        \n    def log_delivery_attempt(self, attempt: DeliveryAttempt) -> None:\n        \"\"\"\n        Log a complete delivery attempt with all request/response details.\n        \n        Captures comprehensive delivery information for debugging and audit\n        purposes. Compresses large payloads and truncates response bodies\n        to prevent storage explosion while maintaining debugging utility.\n        \"\"\"\n        # TODO 1: Validate attempt data and ensure required fields are present\n        # TODO 2: Compress large payloads and truncate response bodies > 10KB\n        # TODO 3: Calculate payload hash for deduplication and integrity checking\n        # TODO 4: Insert attempt record into hot storage time-series database\n        # TODO 5: Create audit event for delivery attempt and queue for processing\n        # TODO 6: Update delivery statistics and health metrics asynchronously\n        # Hint: Use gzip for payload compression, SHA-256 for payload hashing\n        pass\n    \n    def log_circuit_breaker_event(self, webhook_id: str, event_type: str, \n                                  previous_state: str, new_state: str,\n                                  failure_count: int, metadata: Dict[str, Any]) -> None:\n        \"\"\"Log circuit breaker state transitions with context.\"\"\"\n        # TODO 1: Create circuit breaker audit event with state transition details\n        # TODO 2: Include failure count, error patterns, and trigger conditions\n        # TODO 3: Record timing information for circuit breaker analysis\n        # TODO 4: Store event in hot storage for immediate monitoring access\n        # Hint: Include error type distribution in metadata for pattern analysis\n        pass\n    \n    def log_replay_operation(self, replay_id: str, operator_id: str,\n                           event_ids: List[str], reason: str) -> None:\n        \"\"\"Log event replay operations with full audit context.\"\"\"\n        # TODO 1: Create replay audit event with operator identification\n        # TODO 2: Record all event IDs selected for replay with selection criteria\n        # TODO 3: Store replay justification and approval workflow information\n        # TODO 4: Generate unique tracking ID for monitoring replay progress\n        # Hint: Include original failure reasons for replayed events in metadata\n        pass\n    \n    @contextmanager\n    def delivery_timing_context(self, event_id: str, webhook_id: str):\n        \"\"\"Context manager for timing delivery operations.\"\"\"\n        start_time = time.perf_counter()\n        start_timestamp = datetime.utcnow()\n        \n        try:\n            yield\n        finally:\n            duration = time.perf_counter() - start_time\n            self._log_timing_event(event_id, webhook_id, start_timestamp, duration)\n    \n    def _log_timing_event(self, event_id: str, webhook_id: str, \n                         start_time: datetime, duration: float) -> None:\n        \"\"\"Log delivery timing information for performance analysis.\"\"\"\n        # TODO 1: Create timing audit event with precise duration measurements\n        # TODO 2: Include queue wait time, processing time, and network time\n        # TODO 3: Store timing data in time-series format for trend analysis\n        # TODO 4: Update performance metrics and SLA tracking\n        pass\n\nclass StorageManager:\n    \"\"\"\n    Manages tiered storage and automated data migration for audit logs.\n    \n    Implements hierarchical storage management with automatic migration\n    between hot, warm, and cold storage tiers based on age and access\n    patterns. Includes retention policy enforcement and cost optimization.\n    \"\"\"\n    \n    def __init__(self, config: WebhookConfig):\n        self.config = config\n        self.time_series_db = TimeSeriesDB(config.database_url)\n        self.object_store = ObjectStore(config.storage_config)\n        \n    def migrate_to_warm_storage(self, cutoff_date: datetime) -> int:\n        \"\"\"\n        Migrate delivery logs older than cutoff_date to warm storage.\n        \n        Returns number of records migrated.\n        \"\"\"\n        # TODO 1: Query hot storage for delivery attempts older than cutoff_date\n        # TODO 2: Batch process records for efficient migration (1000 records/batch)\n        # TODO 3: Compress and serialize records for warm storage format\n        # TODO 4: Upload compressed batches to object storage with metadata\n        # TODO 5: Verify successful upload before removing from hot storage\n        # TODO 6: Update migration tracking and storage usage statistics\n        # Hint: Use parquet format for efficient analytical queries on warm data\n        pass\n    \n    def migrate_to_cold_storage(self, cutoff_date: datetime) -> int:\n        \"\"\"Migrate logs from warm to cold storage with maximum compression.\"\"\"\n        # TODO 1: Identify warm storage files eligible for cold migration\n        # TODO 2: Apply maximum compression (gzip level 9 or better)\n        # TODO 3: Generate cryptographic checksums for integrity verification\n        # TODO 4: Transfer to cold storage with appropriate metadata tags\n        # TODO 5: Verify cold storage integrity before removing warm copies\n        # Hint: Consider using columnar compression for better ratios\n        pass\n    \n    def enforce_retention_policy(self, policy_config: Dict[str, int]) -> Dict[str, int]:\n        \"\"\"\n        Enforce retention policies across all storage tiers.\n        \n        Returns statistics about data processed and deleted.\n        \"\"\"\n        # TODO 1: Check for legal holds that prevent normal retention processing\n        # TODO 2: Identify data eligible for deletion based on retention policies\n        # TODO 3: Archive data requiring longer retention to appropriate tiers\n        # TODO 4: Permanently delete data past maximum retention periods\n        # TODO 5: Generate retention compliance report with deletion statistics\n        # TODO 6: Update storage usage metrics and cost tracking\n        # Hint: Always create backup snapshots before permanent deletion\n        pass\n```\n\n**Event Replay Engine (Core Logic Skeleton)**\n\n```python\nfrom typing import List, Dict, Optional, Tuple\nfrom datetime import datetime, timedelta\nimport uuid\nfrom dataclasses import dataclass\n\nfrom ..models.webhook_event import WebhookEvent\nfrom ..models.delivery_attempt import DeliveryAttempt\nfrom ..delivery.queue_manager import QueueManager\nfrom ..security.signature import generate_hmac_signature\nfrom .audit_logger import AuditLogger\n\n@dataclass\nclass ReplayRequest:\n    \"\"\"Represents a request to replay specific webhook events.\"\"\"\n    replay_id: str\n    operator_id: str\n    event_ids: List[str]\n    reason: str\n    requested_at: datetime\n    rate_limit_override: Optional[int] = None\n    circuit_breaker_override: bool = False\n\nclass ReplayEngine:\n    \"\"\"\n    Safe event replay with deduplication and rate limiting.\n    \n    Handles manual replay of webhook events while maintaining all\n    protective mechanisms including rate limiting, circuit breakers,\n    and proper audit trails. Provides safeguards against replay storms\n    and ensures endpoint deduplication support.\n    \"\"\"\n    \n    def __init__(self, queue_manager: QueueManager, audit_logger: AuditLogger):\n        self.queue_manager = queue_manager\n        self.audit_logger = audit_logger\n        \n    def replay_events(self, replay_request: ReplayRequest) -> Dict[str, Any]:\n        \"\"\"\n        Replay specified events with full safety checks and audit logging.\n        \n        Returns replay operation results with success/failure statistics.\n        \"\"\"\n        # TODO 1: Validate replay request and check operator permissions\n        # TODO 2: Retrieve original events and verify they exist and are replayable\n        # TODO 3: Check endpoint circuit breaker states unless override specified\n        # TODO 4: Generate new delivery IDs while preserving original event references\n        # TODO 5: Calculate replay-specific HMAC signatures with replay metadata\n        # TODO 6: Schedule replayed events through normal delivery queues with rate limiting\n        # TODO 7: Create comprehensive audit records for replay operation\n        # TODO 8: Return replay tracking information for monitoring progress\n        # Hint: Include original delivery failure reasons in replay audit metadata\n        pass\n    \n    def validate_replay_safety(self, event_ids: List[str]) -> Tuple[bool, List[str]]:\n        \"\"\"\n        Validate that events are safe to replay.\n        \n        Returns (is_safe, list_of_issues) where issues explain any problems.\n        \"\"\"\n        # TODO 1: Check if events still exist and haven't been archived to cold storage\n        # TODO 2: Verify target webhooks are still active and not deleted\n        # TODO 3: Check for recent successful deliveries that might indicate duplicates\n        # TODO 4: Validate that payload sizes won't overwhelm endpoints\n        # TODO 5: Ensure replay won't violate daily/hourly rate limits\n        # TODO 6: Check for any legal holds or compliance restrictions\n        # Hint: Consider implementing cooling-off periods between replays\n        pass\n    \n    def generate_replay_headers(self, original_event: WebhookEvent, \n                               replay_id: str, delivery_id: str) -> Dict[str, str]:\n        \"\"\"Generate HTTP headers for replayed webhook delivery.\"\"\"\n        # TODO 1: Include standard webhook headers (delivery ID, timestamp, signature)\n        # TODO 2: Add replay-specific headers identifying original event and delivery\n        # TODO 3: Include replay reason and timestamp for endpoint deduplication\n        # TODO 4: Add replay tracking information for debugging purposes\n        # TODO 5: Ensure headers provide all information needed for endpoint idempotency\n        # Hint: Use X-Webhook-Replay header to clearly mark replayed events\n        pass\n    \n    def schedule_bulk_replay(self, replay_request: ReplayRequest, \n                           batch_size: int = 100) -> str:\n        \"\"\"Schedule bulk replay operation with progress tracking.\"\"\"\n        # TODO 1: Divide replay request into manageable batches\n        # TODO 2: Create background task for processing replay batches\n        # TODO 3: Implement progress tracking and operator notification\n        # TODO 4: Schedule batches with appropriate delays to respect rate limits\n        # TODO 5: Handle partial failures and provide retry options for failed batches\n        # TODO 6: Generate final report with complete replay statistics\n        # Hint: Use exponential backoff between batches if circuit breakers activate\n        pass\n```\n\n**Milestone Checkpoint**\n\nAfter implementing the event logging and replay system, verify correct operation:\n\n**Testing Event Logging:**\n```bash\n# Generate test webhook deliveries with various outcomes\npython -m pytest tests/test_audit_logging.py::test_delivery_attempt_logging -v\n\n# Expected output: All delivery attempts logged with complete metadata\n# Verify: Check time-series database for delivery_attempt records\n# Verify: Confirm payload compression and response truncation working\n```\n\n**Testing Storage Migration:**\n```bash\n# Trigger storage tier migration\npython scripts/migrate_logs.py --dry-run --cutoff-days 30\n\n# Expected output: Migration plan showing records to move and storage savings\n# Verify: Confirm migration preserves data integrity through checksums\n# Verify: Validate compressed data can be queried and restored\n```\n\n**Testing Event Replay:**\n```bash\n# Replay failed webhook events\ncurl -X POST http://localhost:8080/api/v1/replay \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"event_ids\": [\"event-123\", \"event-456\"],\n    \"reason\": \"Endpoint recovered after maintenance\",\n    \"operator_id\": \"ops-team\"\n  }'\n\n# Expected output: Replay tracking ID and operation status\n# Verify: Replayed events have new delivery IDs and replay headers\n# Verify: Original rate limits and circuit breakers respected\n```\n\n**Debugging Tips**\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Log storage growing too fast | Missing compression or retention | Check storage growth rate vs delivery volume | Implement tiered storage migration |\n| Replay events not delivered | Circuit breaker blocking replay | Check circuit breaker states for target webhooks | Reset circuit breaker or use override flag |\n| Cannot query historical logs | Data migrated to slow storage | Check storage tier of requested time range | Restore from archive or use async query |\n| Duplicate events after replay | Missing replay deduplication | Check endpoint logs for delivery ID handling | Update endpoint to check X-Webhook-Replay header |\n\n\n## Component Interactions and Data Flow\n\n> **Milestone(s):** All milestones (1-4) - this section describes how components from webhook registration through event logging interact to provide end-to-end reliable webhook delivery\n\n### Mental Model: The Orchestrated Assembly Line\n\nThink of the webhook delivery system as a sophisticated assembly line in a high-tech manufacturing plant. The **event ingestion flow** is like the receiving dock where raw materials (webhook events) arrive and get sorted, labeled, and prepared for processing. Each event gets a work order with delivery instructions and security credentials. The **delivery processing flow** is the main assembly line where workers (delivery workers) pick up prepared events, perform the actual delivery work, and handle quality control checks. The **failure recovery flow** is like the quality assurance and maintenance department - when something goes wrong on the assembly line, they step in to diagnose problems, reroute work, and get production back on track.\n\nJust as an assembly line has conveyor belts, quality checkpoints, and feedback loops, our webhook system has message queues, circuit breakers, and retry mechanisms. The key insight is that each component has a specific role, but they must work together in precise coordination to ensure no event gets lost and every delivery attempt is tracked and recoverable.\n\n### Event Ingestion Flow: Webhook lookup, signature generation, and queue placement\n\nThe event ingestion flow represents the entry point where external events enter the webhook delivery system and get transformed into deliverable webhook notifications. This flow bridges the gap between the event source (your application) and the delivery infrastructure, ensuring that every event is properly authenticated, routed, and queued for reliable delivery.\n\n#### Event Reception and Validation\n\nWhen an event enters the webhook delivery system, the ingestion process begins with fundamental validation and preparation steps. The system receives an event payload along with metadata indicating the event type and source information. Think of this as a post office receiving a letter - before it can be delivered, the postal service needs to verify the destination address exists and prepare the envelope with proper postage and routing information.\n\nThe ingestion flow starts by looking up all webhook registrations that have subscribed to the specific event type. This lookup process queries the `WebhookRegistry` to find active webhook endpoints where the `events` field contains the incoming event type and the `active` field is true. The system must handle the case where no webhooks are subscribed to an event type - this is not an error condition, but rather a normal scenario that requires logging for observability.\n\n| Validation Step | Purpose | Failure Handling |\n|-----------------|---------|------------------|\n| Event type validation | Ensure event type is recognized by system | Log warning, continue processing |\n| Payload size check | Prevent oversized payloads from overwhelming endpoints | Reject event, return error to source |\n| Content type validation | Verify payload can be serialized as JSON | Reject event, return error to source |\n| Required metadata validation | Ensure source, timestamp, and idempotency key present | Auto-generate missing non-critical fields |\n\n> **Decision: Event Deduplication Strategy**\n> - **Context**: Events may be submitted multiple times due to retries from the event source\n> - **Options Considered**: 1) No deduplication, 2) Idempotency keys with time windows, 3) Content-based hashing\n> - **Decision**: Idempotency keys with 24-hour time windows\n> - **Rationale**: Provides protection against duplicate submissions while allowing intentional re-delivery of identical content after reasonable time periods\n> - **Consequences**: Requires storing idempotency keys in fast-access storage (Redis), but prevents duplicate webhook deliveries during normal retry scenarios\n\n#### Webhook Event Creation\n\nOnce validation passes, the system creates a `WebhookEvent` record for each webhook registration that should receive the event. This step transforms a single incoming event into multiple deliverable webhook events, each customized for its target endpoint. The event creation process generates unique identifiers, calculates delivery priorities, and sets expiration times based on webhook configuration.\n\nThe `WebhookEvent` creation process follows these steps:\n\n1. Generate a unique `event_id` using a UUID4 to ensure global uniqueness across the distributed system\n2. Copy the event payload and metadata, ensuring the payload remains immutable during processing\n3. Set the initial `delivery_status` to \"pending\" to indicate the event awaits processing\n4. Calculate the `scheduled_at` timestamp based on the webhook's delivery preferences and current system load\n5. Set the `expires_at` timestamp using the webhook's configured expiration policy or system default\n6. Generate an `idempotency_key` combining the source event's idempotency key with the webhook ID\n7. Assign a `priority` value based on the event type, webhook tier, and business rules\n8. Initialize `attempt_count` to zero since no delivery attempts have been made yet\n\n| WebhookEvent Field | Population Logic | Example Value |\n|-------------------|------------------|---------------|\n| id | UUID4 generation | \"550e8400-e29b-41d4-a716-446655440000\" |\n| event_type | Copy from source event | \"user.created\" |\n| payload | JSON serialization of event data | {\"user_id\": 12345, \"email\": \"user@example.com\"} |\n| webhook_id | Target webhook registration ID | \"webhook_789\" |\n| delivery_status | Always starts as \"pending\" | \"pending\" |\n| scheduled_at | Current time + any configured delay | \"2024-01-15T10:30:00Z\" |\n| attempt_count | Always starts at 0 | 0 |\n| idempotency_key | source_key + \"_\" + webhook_id | \"event123_webhook_789\" |\n| priority | Based on event type and webhook tier | 5 (1=highest, 10=lowest) |\n| expires_at | scheduled_at + retention period | \"2024-01-22T10:30:00Z\" |\n\n#### HMAC Signature Generation\n\nBefore a webhook event can be queued for delivery, the system must generate the cryptographic signature that will authenticate the webhook payload at the receiving endpoint. This signature generation process is critical for webhook security and must be performed during ingestion to ensure consistency and prevent timing attacks during delivery.\n\nThe signature generation process retrieves the current active secret for the target webhook using the `WebhookSecret` model. The system constructs a canonical signing string that includes the event payload, timestamp, webhook ID, delivery ID, and event type. This comprehensive signing approach prevents various attack vectors including replay attacks, signature reuse, and payload tampering.\n\nThe canonical signing string format follows this structure:\n```\ntimestamp.webhook_id.delivery_id.event_type.payload_hash\n```\n\nWhere each component serves a specific security purpose:\n- `timestamp`: Prevents replay attacks by including the current Unix timestamp\n- `webhook_id`: Binds the signature to a specific webhook endpoint\n- `delivery_id`: Ensures each delivery attempt has a unique signature\n- `event_type`: Prevents event type confusion attacks\n- `payload_hash`: SHA-256 hash of the JSON payload for integrity verification\n\n> The canonical signing string approach provides defense in depth against signature-based attacks. By including multiple contextual elements, we prevent attackers from reusing signatures across different webhooks, event types, or time periods even if they intercept valid webhook deliveries.\n\n| Signature Component | Security Purpose | Attack Prevention |\n|-------------------|------------------|-------------------|\n| Timestamp | Temporal binding | Replay attacks, signature aging |\n| Webhook ID | Endpoint binding | Cross-webhook signature reuse |\n| Delivery ID | Uniqueness guarantee | Duplicate delivery confusion |\n| Event Type | Content binding | Event type confusion attacks |\n| Payload Hash | Integrity protection | Payload tampering detection |\n\n#### Queue Placement and Routing\n\nThe final step in the event ingestion flow places the prepared webhook events into the appropriate delivery queues. The queue placement process must ensure that events are routed to the correct per-webhook queues while maintaining ordering guarantees and handling queue overflow scenarios.\n\nThe `QueueManager` handles the queue placement process using Redis streams to provide per-webhook ordering guarantees. Each webhook endpoint has a dedicated Redis stream identified by the webhook ID, ensuring that events for a specific endpoint are processed in first-in-first-out order. This ordering guarantee is critical for maintaining data consistency at the receiving endpoint.\n\nThe queue entry creation process transforms the `WebhookEvent` into a `QueueEntry` with additional routing metadata:\n\n1. Calculate the `next_attempt_at` timestamp based on the scheduled delivery time and any rate limiting delays\n2. Generate a `payload_hash` for deduplication and integrity checking during delivery\n3. Set the queue `priority` to enable priority-based processing within the webhook stream\n4. Copy expiration and metadata for queue-level processing decisions\n5. Serialize the queue entry and add it to the webhook's Redis stream using `XADD`\n\n> **Decision: Per-Webhook Queue Architecture**\n> - **Context**: Need to maintain ordering guarantees while enabling parallel processing across different webhook endpoints\n> - **Options Considered**: 1) Single global queue, 2) Per-webhook queues, 3) Event-type-based queues\n> - **Decision**: Per-webhook Redis streams with parallel processing across webhooks\n> - **Rationale**: Provides ordering guarantees per endpoint while maximizing parallelism, prevents slow endpoints from blocking others\n> - **Consequences**: Requires more complex queue management but enables better isolation and performance characteristics\n\n#### Error Handling and Rollback\n\nThe event ingestion flow must handle various failure scenarios gracefully, ensuring that events are not lost and system state remains consistent even when individual steps fail. The error handling strategy uses database transactions to ensure atomicity of the ingestion process.\n\nWhen errors occur during ingestion, the system follows a rollback strategy:\n\n1. **Validation Failures**: Return error immediately to event source without persisting any state\n2. **Database Failures**: Roll back the transaction and retry with exponential backoff\n3. **Queue Failures**: Mark events as \"queuing_failed\" for later retry and alert operations\n4. **Partial Failures**: Complete successful webhook events and retry failed ones individually\n\nThe ingestion process tracks these error metrics for monitoring and alerting:\n\n| Error Type | Metric | Alert Threshold | Recovery Action |\n|------------|--------|-----------------|-----------------|\n| Invalid payload | ingestion.validation_errors | >5% of events | Review event source integration |\n| Database timeout | ingestion.db_timeouts | >1% of events | Scale database resources |\n| Queue unavailable | ingestion.queue_errors | Any occurrence | Immediate escalation |\n| Signature generation failure | ingestion.crypto_errors | Any occurrence | Check secret rotation status |\n\n### Delivery Processing Flow: Queue consumption, HTTP delivery, and response handling\n\nThe delivery processing flow represents the core operational component of the webhook delivery system, where queued events are consumed, transformed into HTTP requests, and delivered to registered endpoint URLs. This flow must handle the complexity of distributed HTTP delivery while maintaining reliability guarantees and providing comprehensive observability.\n\n#### Queue Consumption and Event Claiming\n\nThe delivery processing begins with `DeliveryWorker` instances claiming ready events from the Redis streams managed by the `QueueManager`. The worker processes run continuously, polling for events that are ready for delivery based on their `next_attempt_at` timestamps. This polling mechanism must balance responsiveness with system efficiency, avoiding both excessive polling overhead and delivery delays.\n\nThe event claiming process uses Redis stream consumer groups to provide at-least-once delivery guarantees with automatic failure handling. Each `DeliveryWorker` instance joins a consumer group and claims events using the `XREADGROUP` command with a configured batch size. The claiming process prioritizes events based on their scheduled delivery time and priority levels.\n\nThe worker's event claiming algorithm follows these steps:\n\n1. Connect to Redis and join the appropriate consumer group for webhook streams\n2. Execute `XREADGROUP` with a batch size limit to claim ready events across multiple webhook streams\n3. Filter claimed events based on the current timestamp and `next_attempt_at` values\n4. Sort events by priority and scheduled time to determine processing order\n5. Acknowledge successfully claimed events to prevent duplicate processing by other workers\n6. Return the batch of claimed events for delivery processing\n\n| Consumer Group Parameter | Purpose | Typical Value |\n|--------------------------|---------|---------------|\n| Group Name | Identifies worker pool | \"webhook_delivery_workers\" |\n| Consumer Name | Unique worker identifier | \"{hostname}_{pid}_{thread_id}\" |\n| Batch Size | Events claimed per poll | 10-50 events |\n| Block Timeout | Maximum wait time for new events | 5000ms |\n| Message ID | Starting point for consumption | \">\" (new messages only) |\n\n> The consumer group pattern ensures that if a worker crashes after claiming events but before completing delivery, those events become available for other workers to process after a configured timeout period. This provides automatic failure recovery without requiring external coordination.\n\n#### Circuit Breaker and Rate Limit Checks\n\nBefore attempting HTTP delivery, each event must pass through circuit breaker and rate limiting checks to ensure the target endpoint is healthy and not overwhelmed. The `CircuitBreakerManager` and rate limiting components work together to protect both the webhook system and the receiving endpoints from overload conditions.\n\nThe circuit breaker check examines the current state for the target webhook endpoint. If the circuit breaker is in the `OPEN` state due to previous failures, the delivery attempt is immediately failed and the event is rescheduled for retry after the circuit recovery timeout. For endpoints in the `HALF_OPEN` state, only a limited number of test deliveries are allowed to proceed.\n\nThe rate limiting check uses a token bucket algorithm implemented in Redis to enforce per-endpoint delivery rate limits. The rate limiter respects both the default system limits and any endpoint-specific rate limits configured in the `WebhookRegistration`. When rate limits are exceeded, the event is rescheduled rather than failed, preserving the delivery guarantee.\n\n| Check Type | Pass Condition | Fail Action | Scheduling Delay |\n|------------|---------------|-------------|-----------------|\n| Circuit Closed | Normal operation | Proceed to delivery | None |\n| Circuit Half-Open | Test slot available | Proceed with monitoring | None |\n| Circuit Open | Never passes | Reschedule event | Circuit recovery timeout |\n| Rate Limit OK | Tokens available | Proceed and consume token | None |\n| Rate Limit Exceeded | No tokens | Reschedule event | Token refill time |\n| HTTP 429 Response | Retry-After header | Reschedule event | Retry-After duration |\n\n> **Decision: Pre-Delivery Protection Checks**\n> - **Context**: Need to balance delivery guarantees with endpoint protection and system stability\n> - **Options Considered**: 1) Deliver all events immediately, 2) Circuit breaker only, 3) Comprehensive pre-delivery checks\n> - **Decision**: Combined circuit breaker and rate limiting checks before each delivery attempt\n> - **Rationale**: Prevents cascading failures while maintaining delivery guarantees through rescheduling rather than dropping events\n> - **Consequences**: Adds latency to delivery process but significantly improves system resilience and endpoint protection\n\n#### HTTP Request Construction and Delivery\n\nWhen an event passes the protection checks, the delivery worker constructs an HTTP POST request with the properly signed payload and headers. The HTTP request construction process must handle authentication, content formatting, and security headers while maintaining compatibility with webhook standards.\n\nThe HTTP request construction follows the webhook specification standards:\n\n1. Set the HTTP method to POST for all webhook deliveries\n2. Set the `Content-Type` header to `application/json` for JSON payloads\n3. Include the HMAC signature in the `X-Webhook-Signature-256` header using the format `sha256={signature}`\n4. Add a `X-Webhook-Timestamp` header with the Unix timestamp used in signature generation\n5. Include a `X-Webhook-ID` header with the webhook registration ID for recipient identification\n6. Add a unique `X-Delivery-ID` header for deduplication and debugging purposes\n7. Set appropriate timeout headers and User-Agent identification\n\nThe payload delivery process uses the `WebhookHTTPClient` which provides SSRF protection, timeout handling, and comprehensive error capture. The HTTP client is configured with conservative timeout values and retry-safe settings to prevent resource exhaustion.\n\n| HTTP Header | Purpose | Example Value |\n|-------------|---------|---------------|\n| Content-Type | Payload format specification | \"application/json\" |\n| X-Webhook-Signature-256 | HMAC signature for authentication | \"sha256=a0b1c2d3...\" |\n| X-Webhook-Timestamp | Signature timestamp for replay protection | \"1642248600\" |\n| X-Webhook-ID | Webhook registration identifier | \"wh_1234567890\" |\n| X-Delivery-ID | Unique delivery attempt identifier | \"del_abcd1234efgh5678\" |\n| User-Agent | System identification | \"WebhookDeliverySystem/1.0\" |\n\n#### Response Handling and Status Classification\n\nThe HTTP response handling process must interpret the webhook endpoint's response to determine whether the delivery was successful and how to handle any failures. The response classification logic follows HTTP semantics while accounting for webhook-specific behaviors and common endpoint implementation patterns.\n\nThe response handling process captures comprehensive delivery metrics:\n\n1. Record the HTTP status code and response time for performance monitoring\n2. Capture response headers, particularly `Retry-After` for rate limiting coordination  \n3. Store a truncated version of the response body for debugging purposes\n4. Classify the response as success, temporary failure, or permanent failure\n5. Update circuit breaker statistics based on the response classification\n6. Generate a `DeliveryAttempt` record with complete delivery metadata\n\nThe status code classification determines the next action for the webhook event:\n\n| Status Code Range | Classification | Next Action | Circuit Breaker Impact |\n|-------------------|---------------|-------------|----------------------|\n| 200-299 | Success | Mark delivered, remove from queue | Record success, potentially close circuit |\n| 400-499 (except 429) | Permanent failure | Move to dead letter queue | Record failure |\n| 429 | Rate limited | Reschedule with Retry-After delay | No impact on circuit breaker |\n| 500-599 | Temporary failure | Schedule retry with backoff | Record failure |\n| Timeout/Connection Error | Temporary failure | Schedule retry with backoff | Record failure |\n\n> HTTP 4xx errors (except 429) indicate permanent failures because they represent client errors where retrying the same request will not succeed. The webhook payload or configuration has a fundamental problem that requires manual intervention to resolve.\n\n#### Delivery Attempt Recording\n\nEvery delivery attempt, successful or failed, must be recorded in the delivery audit trail for debugging, compliance, and retry decision making. The `DeliveryAttempt` creation process captures comprehensive metadata while managing storage efficiency through response body truncation and header filtering.\n\nThe delivery attempt recording process creates a complete audit record:\n\n1. Generate a unique `attempt_id` for tracking and correlation purposes\n2. Record all request details including headers, payload hash, and delivery timestamp  \n3. Capture response metadata with truncation for large bodies (limit: 10KB)\n4. Calculate and store the total delivery duration including network time\n5. Identify the worker instance that performed the delivery for debugging\n6. Note any circuit breaker state changes triggered by this delivery attempt\n7. Persist the complete record to the delivery audit database\n\nThe audit record enables comprehensive debugging and analysis:\n\n| Audit Field | Purpose | Retention |\n|-------------|---------|-----------|\n| Request headers | Debug signature and formatting issues | 30 days hot storage |\n| Response status/headers | Understand endpoint behavior | 365 days warm storage |\n| Response body (truncated) | Debug endpoint errors | 30 days hot storage |\n| Timing metrics | Performance analysis and SLA monitoring | 1095 days cold storage |\n| Worker identification | Debug system-side delivery issues | 30 days hot storage |\n| Circuit breaker events | Understand endpoint health patterns | 365 days warm storage |\n\n### Failure Recovery Flow: Retry scheduling, circuit breaker activation, and alerting\n\nThe failure recovery flow handles the complex scenarios where webhook deliveries fail and the system must make intelligent decisions about retry scheduling, endpoint health management, and escalation to human operators. This flow is critical for maintaining the system's reliability guarantees while preventing cascading failures.\n\n#### Retry Scheduling and Exponential Backoff\n\nWhen a webhook delivery fails with a temporary error condition, the retry scheduling system must calculate an appropriate delay before the next attempt. The exponential backoff algorithm balances quick recovery from transient issues with respect for overwhelmed endpoints that need time to recover.\n\nThe retry scheduling algorithm implements exponential backoff with jitter:\n\n1. Determine if the failure is retryable based on HTTP status code and error type\n2. Check if the maximum retry attempts limit has been exceeded for this event\n3. Calculate the base delay using exponential backoff: `base_delay * (2 ^ attempt_number)`\n4. Add jitter by randomizing the delay within ±25% of the calculated value\n5. Respect any `Retry-After` header from the endpoint by using the larger of calculated delay or header value\n6. Cap the delay at a maximum value (typically 1 hour) to prevent indefinite delays\n7. Update the event's `next_attempt_at` timestamp and increment the `attempt_count`\n8. Reschedule the event in the appropriate webhook stream for future processing\n\nThe jitter calculation prevents the thundering herd problem where multiple failed endpoints all retry simultaneously when they recover. The randomization spreads retry attempts over time, reducing load spikes on recovering endpoints.\n\n| Attempt Number | Base Delay | With Jitter Range | Maximum Effective Delay |\n|---------------|------------|-------------------|------------------------|\n| 1 | 30 seconds | 22.5 - 37.5 seconds | 37.5 seconds |\n| 2 | 60 seconds | 45 - 75 seconds | 75 seconds |\n| 3 | 2 minutes | 1.5 - 2.5 minutes | 2.5 minutes |\n| 4 | 4 minutes | 3 - 5 minutes | 5 minutes |\n| 5 | 8 minutes | 6 - 10 minutes | 10 minutes |\n| 6+ | 16+ minutes | Capped at 1 hour | 1 hour maximum |\n\n> **Decision: Exponential Backoff with Jitter and Caps**\n> - **Context**: Need to balance quick recovery from transient failures with protection of overwhelmed endpoints\n> - **Options Considered**: 1) Linear backoff, 2) Pure exponential backoff, 3) Exponential with jitter and caps\n> - **Decision**: Exponential backoff with ±25% jitter and 1-hour maximum delay\n> - **Rationale**: Exponential growth handles systematic problems, jitter prevents thundering herd, caps prevent indefinite delays\n> - **Consequences**: More complex scheduling logic but significantly better behavior under load and during recovery\n\n#### Circuit Breaker State Management\n\nThe circuit breaker system monitors endpoint health and automatically disables delivery to consistently failing endpoints to prevent resource waste and allow endpoints time to recover. The circuit breaker state management must track failure patterns, manage state transitions, and coordinate recovery testing.\n\nThe circuit breaker operates as a state machine with three primary states:\n\n**CLOSED State**: Normal operation where all delivery attempts are allowed. The circuit breaker monitors failure rates and response times to detect developing problems. When the failure threshold is exceeded within the monitoring window, the circuit transitions to OPEN.\n\n**OPEN State**: All delivery attempts are blocked and immediately failed without making HTTP requests. Events are rescheduled with increasingly longer delays to allow the endpoint time to recover. After a recovery timeout period, the circuit transitions to HALF_OPEN for testing.\n\n**HALF_OPEN State**: Limited testing mode where only a small number of delivery attempts are allowed to probe endpoint health. If test deliveries succeed, the circuit returns to CLOSED. If test deliveries fail, the circuit returns to OPEN with a longer recovery timeout.\n\nThe circuit breaker maintains per-endpoint state in Redis with atomic updates:\n\n| Circuit State Field | Purpose | Example Value |\n|---------------------|---------|---------------|\n| state | Current circuit breaker state | \"OPEN\" |\n| failure_count | Consecutive failures in current window | 7 |\n| last_failure_at | Timestamp of most recent failure | 1642248600 |\n| recovery_timeout | Seconds until next HALF_OPEN attempt | 300 |\n| test_delivery_count | Number of test deliveries in HALF_OPEN | 2 |\n| success_count | Consecutive successes (for closing circuit) | 0 |\n| window_start | Start of current monitoring window | 1642248300 |\n\n> The circuit breaker's recovery timeout increases with each failed recovery attempt: initial timeout of 5 minutes, doubling up to a maximum of 1 hour. This progressive backoff prevents rapid oscillation between states when endpoints have intermittent issues.\n\n#### Dead Letter Queue Management\n\nWhen webhook events exhaust all retry attempts or encounter permanent failure conditions, they must be moved to a dead letter queue for manual review and potential replay. The dead letter queue system provides a safety net that prevents event loss while enabling human intervention for complex failure scenarios.\n\nThe dead letter queue process handles multiple failure scenarios:\n\n1. **Retry Exhaustion**: Events that have exceeded the maximum retry attempt limit\n2. **Permanent Failures**: HTTP 4xx responses (except 429) that indicate client errors\n3. **Expired Events**: Events that have passed their expiration timestamp without successful delivery  \n4. **Configuration Errors**: Events targeting deleted or misconfigured webhook endpoints\n\nThe dead letter queue entry captures comprehensive failure context:\n\n1. Copy the complete original event payload and metadata for potential replay\n2. Record the complete delivery attempt history with all response details\n3. Categorize the failure reason for operational triage and automated handling\n4. Calculate failure statistics for trend analysis and system improvement\n5. Generate operational alerts based on failure volume and patterns\n6. Create replay preparation metadata for streamlined manual recovery\n\n| Dead Letter Field | Purpose | Alert Trigger |\n|-------------------|---------|---------------|\n| failure_reason | Categorized root cause | High-frequency reason types |\n| attempt_history | Complete delivery timeline | Patterns indicating system issues |\n| original_payload | Event data for replay | None |\n| failure_timestamp | When event was moved to DLQ | Volume thresholds |\n| webhook_metadata | Endpoint configuration at failure time | Configuration drift detection |\n| replay_metadata | Pre-computed replay parameters | None |\n\n#### Alerting and Escalation\n\nThe failure recovery system must detect patterns that require human intervention and generate appropriate alerts for different stakeholder groups. The alerting system balances comprehensive coverage with alert fatigue, using intelligent grouping and escalation rules.\n\nThe alerting system monitors multiple failure dimensions:\n\n**Endpoint-Level Alerts**: Generated when individual webhook endpoints experience problems that may require customer support or endpoint owner intervention. These alerts include circuit breaker activations, consistent delivery failures, and configuration issues.\n\n**System-Level Alerts**: Generated when failure patterns indicate broader system problems such as queue backlogs, database performance issues, or infrastructure failures. These alerts target the operations team and trigger automated scaling or failover procedures.\n\n**Security Alerts**: Generated when failure patterns suggest potential security issues such as SSRF attempts, signature verification bypasses, or unusual traffic patterns. These alerts require immediate security team response.\n\nThe alert escalation process follows defined severity levels:\n\n| Severity Level | Trigger Conditions | Initial Notification | Escalation Timeline |\n|---------------|-------------------|-------------------|-------------------|\n| INFO | Circuit breaker transitions, retry patterns | Email to endpoint owner | No escalation |\n| WARN | Dead letter queue growth, rate limit violations | Email + dashboard alert | 2 hours to operations |\n| ERROR | System queue backlogs, database timeouts | Immediate slack + email | 30 minutes to on-call |\n| CRITICAL | Security violations, data integrity issues | Phone + slack + email | Immediate escalation |\n\n> **Decision: Multi-Dimensional Alerting Strategy**\n> - **Context**: Different failure types require different response teams and urgency levels\n> - **Options Considered**: 1) Simple threshold alerts, 2) Pattern-based alerts, 3) Multi-dimensional alerting with escalation\n> - **Decision**: Layered alerting system with endpoint, system, and security dimensions\n> - **Rationale**: Enables appropriate response matching failure impact, reduces alert fatigue through intelligent grouping\n> - **Consequences**: More complex alerting logic but significantly better operational outcomes and customer satisfaction\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Event Loss During Ingestion Failures**\nWhen database transactions fail during event ingestion, developers often implement retry logic that can cause duplicate events or lose events entirely. The correct approach requires idempotent ingestion with proper transaction boundaries. Use database transactions that include both event creation and queue placement, with idempotency keys to handle duplicate submissions safely.\n\n⚠️ **Pitfall: Signature Generation Timing Attacks**\nGenerating HMAC signatures during delivery processing rather than ingestion can create timing-based security vulnerabilities and consistency issues. Signatures should be generated once during ingestion with a fixed timestamp, not recalculated for each retry attempt. This ensures consistent authentication and prevents timing attack vectors.\n\n⚠️ **Pitfall: Circuit Breaker Oscillation**\nImplementing circuit breakers without proper recovery testing mechanisms causes rapid oscillation between OPEN and CLOSED states when endpoints are intermittently failing. The HALF_OPEN state must limit test deliveries and require multiple consecutive successes before fully closing the circuit. Use exponentially increasing recovery timeouts to prevent rapid state changes.\n\n⚠️ **Pitfall: Queue Ordering Violations**\nUsing a single global queue with multiple workers can violate per-endpoint ordering guarantees when workers process events concurrently. Implement per-webhook queues using Redis streams to ensure that events for a specific endpoint are processed sequentially while maintaining parallelism across different endpoints.\n\n⚠️ **Pitfall: Rate Limiting Bypass During Retries**\nFailed delivery attempts that are retried without rate limit checks can overwhelm recovered endpoints and trigger new failures. All delivery attempts, including retries, must pass through rate limiting validation. Respect Retry-After headers from endpoints and implement exponential backoff to prevent retry storms.\n\n⚠️ **Pitfall: Dead Letter Queue Monitoring Gaps**\nMoving events to dead letter queues without proper alerting and review processes results in silent event loss from the customer perspective. Implement automated alerts for dead letter queue growth, categorize failure reasons for triage, and provide operational tools for event replay and customer notification.\n\n### Implementation Guidance\n\nThis section provides concrete implementation patterns and starter code for building the component interaction flows. The code focuses on Python with Redis for queue management and PostgreSQL for persistent storage.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Message Queues | Redis Streams with python redis-py | Apache Kafka with kafka-python |\n| HTTP Client | requests library with retry decorators | aiohttp with circuit breaker integration |\n| Background Workers | Celery with Redis broker | Custom asyncio workers with proper shutdown |\n| Database Operations | SQLAlchemy ORM with connection pooling | Async SQLAlchemy with connection management |\n| Circuit Breaker | Simple Redis-based state machine | py-breaker library with custom extensions |\n| Monitoring | Python logging with structured output | Prometheus metrics with custom collectors |\n\n#### File Structure\n\n```\nwebhook_system/\n├── core/\n│   ├── __init__.py\n│   ├── models.py              ← SQLAlchemy models\n│   └── config.py              ← Configuration management\n├── ingestion/\n│   ├── __init__.py\n│   ├── event_processor.py     ← Event ingestion flow\n│   └── signature_service.py   ← HMAC signature generation\n├── delivery/\n│   ├── __init__.py\n│   ├── queue_manager.py       ← Redis stream management\n│   ├── delivery_worker.py     ← Core delivery processing\n│   └── http_client.py         ← Webhook HTTP delivery\n├── protection/\n│   ├── __init__.py\n│   ├── circuit_breaker.py     ← Circuit breaker state management\n│   └── rate_limiter.py        ← Token bucket rate limiting\n├── recovery/\n│   ├── __init__.py\n│   ├── retry_scheduler.py     ← Exponential backoff logic\n│   └── dead_letter_handler.py ← DLQ management\n└── monitoring/\n    ├── __init__.py\n    └── alerting.py            ← Alert generation and escalation\n```\n\n#### Infrastructure Starter Code\n\n**Queue Manager with Redis Streams:**\n\n```python\nimport redis\nimport json\nimport time\nfrom typing import List, Dict, Optional, Tuple\nfrom dataclasses import asdict\n\nclass QueueManager:\n    \"\"\"Manages per-webhook delivery queues using Redis streams.\"\"\"\n    \n    def __init__(self, redis_url: str, consumer_group: str = \"webhook_workers\"):\n        self.redis_client = redis.from_url(redis_url, decode_responses=True)\n        self.consumer_group = consumer_group\n        self._ensure_consumer_groups()\n    \n    def _ensure_consumer_groups(self):\n        \"\"\"Create consumer groups for all webhook streams.\"\"\"\n        # Consumer group creation is handled per webhook stream\n        pass\n    \n    def enqueue_event(self, webhook_id: str, event_id: str, \n                     priority: int, expires_at: float) -> bool:\n        \"\"\"Add event to webhook-specific delivery queue.\"\"\"\n        stream_key = f\"webhook_queue:{webhook_id}\"\n        queue_entry = QueueEntry(\n            event_id=event_id,\n            webhook_id=webhook_id,\n            attempt_count=0,\n            next_attempt_at=time.time(),\n            payload_hash=\"\", # Calculate from payload\n            priority=priority,\n            expires_at=expires_at,\n            metadata={}\n        )\n        \n        try:\n            # TODO 1: Create consumer group if it doesn't exist\n            # TODO 2: Add event to Redis stream with XADD\n            # TODO 3: Handle stream length limits and cleanup\n            # TODO 4: Return success/failure status\n            pass\n        except redis.RedisError as e:\n            # Log error and return False\n            return False\n    \n    def claim_ready_events(self, consumer_name: str, \n                          batch_size: int = 10) -> List[Tuple[str, Dict]]:\n        \"\"\"Claim events ready for delivery across webhook streams.\"\"\"\n        current_time = time.time()\n        claimed_events = []\n        \n        try:\n            # TODO 1: Get list of active webhook streams\n            # TODO 2: Use XREADGROUP to claim events from multiple streams\n            # TODO 3: Filter events by next_attempt_at timestamp\n            # TODO 4: Sort by priority and scheduled time\n            # TODO 5: Return list of (stream_key, event_data) tuples\n            pass\n        except redis.RedisError as e:\n            # Log error and return empty list\n            return []\n```\n\n**HTTP Client with Protection Integration:**\n\n```python\nimport requests\nimport time\nfrom typing import Optional\nfrom urllib.parse import urlparse\n\nclass WebhookHTTPClient:\n    \"\"\"HTTP client with SSRF protection and webhook-specific features.\"\"\"\n    \n    def __init__(self, config: WebhookConfig):\n        self.config = config\n        self.session = requests.Session()\n        self.session.headers.update({\n            'User-Agent': 'WebhookDeliverySystem/1.0',\n            'Content-Type': 'application/json'\n        })\n    \n    def post_json(self, url: str, payload: dict, headers: dict) -> HTTPResponse:\n        \"\"\"Send JSON POST request with comprehensive error handling.\"\"\"\n        start_time = time.time()\n        \n        try:\n            # TODO 1: Validate URL for SSRF protection\n            # TODO 2: Merge custom headers with default headers\n            # TODO 3: Make HTTP POST request with timeout\n            # TODO 4: Handle various exception types (timeout, connection, etc.)\n            # TODO 5: Calculate response time and create HTTPResponse object\n            # TODO 6: Truncate response body if too large\n            pass\n        except requests.exceptions.Timeout:\n            return HTTPResponse(\n                status_code=0,\n                response_time=time.time() - start_time,\n                error_message=\"Request timeout\",\n                headers={},\n                body=\"\"\n            )\n        except Exception as e:\n            return HTTPResponse(\n                status_code=0,\n                response_time=time.time() - start_time,\n                error_message=str(e),\n                headers={},\n                body=\"\"\n            )\n```\n\n#### Core Logic Skeleton\n\n**Event Ingestion Processor:**\n\n```python\nfrom typing import Dict, List\nimport uuid\nimport time\nimport json\n\nclass EventIngestionProcessor:\n    \"\"\"Handles the complete event ingestion flow from validation to queue placement.\"\"\"\n    \n    def __init__(self, webhook_registry: WebhookRegistry, \n                 queue_manager: QueueManager,\n                 signature_service: SignatureService):\n        self.webhook_registry = webhook_registry\n        self.queue_manager = queue_manager\n        self.signature_service = signature_service\n    \n    def process_incoming_event(self, event_type: str, payload: dict, \n                              source: str, idempotency_key: str) -> Dict[str, any]:\n        \"\"\"Process incoming event through complete ingestion flow.\"\"\"\n        \n        try:\n            # TODO 1: Validate event payload size and format\n            # TODO 2: Check for duplicate events using idempotency key\n            # TODO 3: Look up webhook registrations subscribed to event_type\n            # TODO 4: For each matching webhook, create WebhookEvent record\n            # TODO 5: Generate HMAC signature for each webhook event\n            # TODO 6: Enqueue events in webhook-specific queues\n            # TODO 7: Return success response with event IDs and webhook count\n            # Hint: Use database transaction to ensure atomicity\n            # Hint: Handle case where no webhooks subscribe to event_type\n            pass\n        except Exception as e:\n            # TODO: Log error and return failure response\n            # TODO: Ensure no partial state is persisted\n            pass\n    \n    def create_webhook_event(self, webhook_reg: WebhookRegistration,\n                           event_type: str, payload: dict,\n                           source: str, idempotency_key: str) -> WebhookEvent:\n        \"\"\"Create WebhookEvent record for specific webhook endpoint.\"\"\"\n        \n        # TODO 1: Generate unique event ID using UUID4\n        # TODO 2: Calculate priority based on event type and webhook tier\n        # TODO 3: Set expiration time based on webhook configuration\n        # TODO 4: Create idempotency key combining source key and webhook ID\n        # TODO 5: Initialize delivery status and attempt count\n        # TODO 6: Return populated WebhookEvent object\n        # Hint: Use current timestamp for created_at and scheduled_at\n        pass\n```\n\n**Delivery Worker with Circuit Breaker Integration:**\n\n```python\nimport asyncio\nimport logging\nfrom typing import Optional\n\nclass DeliveryWorker:\n    \"\"\"Processes webhook deliveries with retry logic and protection mechanisms.\"\"\"\n    \n    def __init__(self, queue_manager: QueueManager,\n                 http_client: WebhookHTTPClient,\n                 circuit_breaker: CircuitBreakerManager,\n                 rate_limiter: RateLimitManager):\n        self.queue_manager = queue_manager\n        self.http_client = http_client\n        self.circuit_breaker = circuit_breaker\n        self.rate_limiter = rate_limiter\n        self.worker_id = f\"{socket.gethostname()}_{os.getpid()}\"\n        self.running = False\n    \n    def run_worker_loop(self):\n        \"\"\"Continuously process events from delivery queues.\"\"\"\n        self.running = True\n        \n        while self.running:\n            try:\n                # TODO 1: Claim batch of ready events from queue manager\n                # TODO 2: For each event, load webhook registration and event details\n                # TODO 3: Check circuit breaker and rate limiting before delivery\n                # TODO 4: Perform HTTP delivery if checks pass\n                # TODO 5: Handle delivery response and update circuit breaker\n                # TODO 6: Schedule retries for failed deliveries or move to DLQ\n                # TODO 7: Acknowledge processed events in queue\n                # TODO 8: Sleep briefly if no events available\n                # Hint: Use process_delivery method for individual deliveries\n                pass\n            except Exception as e:\n                logging.error(f\"Worker loop error: {e}\")\n                time.sleep(5)  # Back off on errors\n    \n    def process_delivery(self, event_id: str, webhook_id: str, \n                        payload: dict) -> bool:\n        \"\"\"Attempt webhook delivery with error handling and retry logic.\"\"\"\n        \n        try:\n            # TODO 1: Load webhook registration and verify it's active\n            # TODO 2: Check circuit breaker state - return False if OPEN\n            # TODO 3: Check rate limiting - reschedule if rate limited\n            # TODO 4: Load webhook secret and generate request headers\n            # TODO 5: Make HTTP delivery request using webhook HTTP client  \n            # TODO 6: Create DeliveryAttempt record with response details\n            # TODO 7: Update circuit breaker based on response status\n            # TODO 8: Schedule retry for failures or mark success\n            # TODO 9: Return True for success, False for failure\n            # Hint: Use should_retry_delivery to classify response codes\n            pass\n        except Exception as e:\n            # TODO: Log error, create failed delivery attempt record\n            # TODO: Schedule retry or move to DLQ based on attempt count\n            return False\n```\n\n#### Milestone Checkpoints\n\n**Milestone 1 Checkpoint - Event Ingestion:**\n```bash\n# Run ingestion tests\npython -m pytest tests/test_event_ingestion.py -v\n\n# Expected behavior:\n# - Events create multiple WebhookEvent records for subscribed endpoints\n# - HMAC signatures generated correctly for each webhook\n# - Events queued in correct per-webhook Redis streams\n# - Idempotency protection prevents duplicate processing\n```\n\n**Milestone 2 Checkpoint - Delivery Processing:**\n```bash\n# Start delivery worker\npython -m webhook_system.delivery.worker\n\n# Send test event\ncurl -X POST http://localhost:8080/events \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"event_type\": \"test.event\", \"payload\": {\"test\": true}}'\n\n# Expected behavior:\n# - Worker claims events from Redis streams\n# - HTTP requests sent to registered webhook endpoints\n# - Delivery attempts recorded with response details\n# - Failed deliveries scheduled for retry with exponential backoff\n```\n\n**Milestone 3 Checkpoint - Protection Mechanisms:**\n```bash\n# Test circuit breaker\npython scripts/test_circuit_breaker.py\n\n# Expected behavior:\n# - Circuit opens after configured failure threshold\n# - Deliveries blocked when circuit is OPEN\n# - Circuit transitions to HALF_OPEN for recovery testing\n# - Rate limiting enforces per-endpoint delivery limits\n```\n\n#### Debugging Tips\n\n| Symptom | Likely Cause | How to Diagnose | Fix |\n|---------|--------------|-----------------|-----|\n| Events not being delivered | Worker not claiming events | Check Redis consumer group status | Restart worker, verify consumer group creation |\n| Signatures failing validation | Clock skew or incorrect secret | Compare timestamps and verify secret rotation | Sync clocks, check active secret versions |\n| Circuit breaker not opening | Failure threshold too high | Review failure counts in Redis | Adjust threshold or verify failure recording |\n| Memory usage growing | Large response bodies not truncated | Monitor delivery attempt record sizes | Implement response body truncation |\n| Queue backlog growing | Workers slower than ingestion rate | Compare ingestion vs processing rates | Scale worker instances or optimize delivery code |\n\n\n## Error Handling and Edge Cases\n\n> **Milestone(s):** All milestones (1-4) - error handling patterns established here apply to webhook registration failures (Milestone 1), delivery and retry failures (Milestone 2), circuit breaker edge cases (Milestone 3), and event logging failures (Milestone 4)\n\n### Mental Model: The Resilient Communication Network\n\nThink of our webhook delivery system as a resilient communication network, similar to how postal services handle mail during natural disasters or infrastructure failures. Just as the postal service has established protocols for handling undeliverable mail, routing around damaged infrastructure, and recovering from facility outages, our webhook system must gracefully handle network partitions, endpoint failures, and system crashes.\n\nThe postal service doesn't simply give up when a delivery truck breaks down - it has backup vehicles, alternative routes, and procedures for handling mail that can't be delivered immediately. Similarly, our webhook delivery system implements comprehensive error handling that categorizes failures by their nature and recoverability, applies appropriate recovery strategies, and maintains system consistency even during cascading failures.\n\nConsider how a postal service handles different types of delivery problems: temporary road closures (network timeouts) get retried later with alternative routes, incorrect addresses (4xx errors) are returned to sender without retry, and damaged packages (system failures) are handled through insurance and replacement processes. Our webhook system applies similar classification and handling strategies to ensure reliable delivery despite the inevitable failures in distributed systems.\n\n### Network and Timeout Handling\n\nNetwork and timeout handling forms the foundation of resilient webhook delivery, as network failures represent the most common category of transient errors in distributed systems. The delivery engine must distinguish between different types of network failures to apply appropriate recovery strategies while avoiding resource exhaustion and cascading failures.\n\n**Connection Establishment Failures** occur when the HTTP client cannot establish a TCP connection to the target endpoint. These failures manifest as DNS resolution failures, connection timeouts, or connection refused errors. Each type requires different handling strategies based on the underlying cause and likelihood of recovery.\n\n| Failure Type | Typical Causes | Detection Method | Recovery Strategy | Retry Classification |\n|--------------|----------------|------------------|-------------------|---------------------|\n| DNS Resolution | Invalid hostname, DNS server down | DNS lookup exception | Exponential backoff, alternative DNS | Retriable with backoff |\n| Connection Timeout | Network congestion, endpoint overload | Socket timeout exception | Longer timeout, circuit breaker | Retriable, counts toward failures |\n| Connection Refused | Service down, port closed | Connection refused error | Immediate retry contraindicated | Retriable with longer backoff |\n| Network Unreachable | Routing issues, network partition | Network unreachable error | Wait for network recovery | Retriable with extended backoff |\n\nDNS resolution failures require special handling because they can indicate either temporary DNS server issues or permanent hostname errors. The system implements a tiered DNS resolution strategy where initial failures trigger retries with alternative DNS servers before classifying the hostname as permanently invalid.\n\n**Read and Write Timeout Handling** manages partial connection establishment where the TCP handshake succeeds but HTTP request processing encounters delays. Write timeouts occur when the client cannot send the request payload within the configured timeout period, while read timeouts happen when the server doesn't respond within the expected timeframe.\n\nThe `WebhookHTTPClient` implements sophisticated timeout handling that distinguishes between connection timeouts, request transmission timeouts, and response timeout scenarios:\n\n| Timeout Stage | Configuration | Failure Implications | Retry Decision |\n|---------------|---------------|---------------------|----------------|\n| Connection Timeout | `DELIVERY_TIMEOUT` / 3 | Network or endpoint issues | Retry with exponential backoff |\n| Request Write Timeout | `DELIVERY_TIMEOUT` / 3 | Large payload or slow upload | Retry once, then circuit breaker |\n| Response Read Timeout | `DELIVERY_TIMEOUT` | Server processing delay | Retry with jitter |\n| Total Request Timeout | `DELIVERY_TIMEOUT` | Overall request duration | No retry, mark as failed |\n\n> **Key Design Insight**: Timeout handling must account for the fact that a request timeout doesn't guarantee the server didn't process the request. The webhook payload might have been successfully received and processed even if the response was lost due to timeout.\n\n**Partial Response Handling** addresses scenarios where the HTTP response is partially received before the connection is interrupted. This creates ambiguity about whether the webhook was successfully delivered, requiring careful handling to prevent both data loss and duplicate processing.\n\nWhen a partial response is detected, the system records the attempt with a special status indicating uncertainty about delivery success. The `DeliveryAttempt` record includes sufficient information for manual investigation:\n\n| Response State | Status Code Received | Headers Received | Body Received | Classification | Next Action |\n|----------------|---------------------|------------------|---------------|----------------|-------------|\n| Complete Response | Yes | Yes | Yes | Definitive | Apply normal retry logic |\n| Partial Headers | Yes | Partial | No | Uncertain Success | Short retry delay |\n| Partial Body | Yes | Yes | Partial | Likely Success | Extended retry delay |\n| Connection Lost | No | No | No | Likely Failure | Normal retry logic |\n| Timeout During Body | Yes | Yes | Timeout | Uncertain Success | Manual investigation flag |\n\n**Network Partition Recovery** handles scenarios where the webhook delivery system loses connectivity to external endpoints due to network infrastructure failures. During network partitions, the system must avoid accumulating excessive retry load while maintaining delivery ordering guarantees.\n\nThe network partition detection mechanism monitors global delivery failure rates and connection establishment success rates across all webhook endpoints. When partition conditions are detected, the system enters a degraded mode with modified retry behavior:\n\n1. Suspend normal retry schedules for connection-level failures\n2. Increase circuit breaker sensitivity to prevent queue buildup\n3. Implement partition-aware exponential backoff with extended maximum delays  \n4. Enable priority-based processing to handle critical webhooks first\n5. Alert operators about system-wide connectivity issues\n\n> **Decision: Network Partition Detection Strategy**\n> - **Context**: During network partitions, individual endpoint failures can overwhelm retry queues and delay recovery\n> - **Options Considered**: Per-endpoint detection, global failure rate monitoring, external health check services\n> - **Decision**: Implement global failure rate monitoring with per-endpoint override capabilities\n> - **Rationale**: Balances automated detection with endpoint-specific network conditions while preventing false positives\n> - **Consequences**: Enables faster recovery from partitions but requires careful tuning of detection thresholds\n\n### Endpoint Error Classification\n\nEndpoint error classification determines retry eligibility and failure handling based on HTTP response codes, response content, and error patterns. Proper classification prevents wasteful retries of permanent failures while ensuring transient errors receive appropriate retry treatment.\n\n**HTTP Status Code Classification** follows RFC specifications but includes webhook-specific interpretations based on common endpoint implementation patterns. The classification directly drives retry decisions and circuit breaker state transitions.\n\n| Status Code Range | Classification | Retry Behavior | Circuit Breaker Impact | Common Webhook Causes |\n|-------------------|----------------|----------------|------------------------|----------------------|\n| 200-299 | Success | No retry needed | Reset failure count | Successful delivery |\n| 300-399 | Client Error | No retry, log redirect | No impact | Endpoint URL changed |\n| 400 | Bad Request | No retry | No impact | Malformed payload or headers |\n| 401 | Unauthorized | No retry, alert | No impact | Invalid signature or auth |\n| 403 | Forbidden | No retry | No impact | Endpoint rejects webhook source |\n| 404 | Not Found | No retry | No impact | Endpoint URL no longer valid |\n| 408 | Request Timeout | Retry with backoff | Count as failure | Server-side timeout |\n| 409 | Conflict | No retry | No impact | Duplicate delivery detected |\n| 410 | Gone | No retry, deactivate | No impact | Endpoint permanently removed |\n| 413 | Payload Too Large | No retry | No impact | Webhook payload exceeds limits |\n| 422 | Unprocessable Entity | No retry | No impact | Valid format, invalid content |\n| 429 | Rate Limited | Retry with delay | Special handling | Endpoint rate limiting |\n| 500-502 | Server Error | Retry with backoff | Count as failure | Temporary server issues |\n| 503 | Service Unavailable | Retry with longer delay | Count as failure | Server overload or maintenance |\n| 504 | Gateway Timeout | Retry with backoff | Count as failure | Upstream timeout |\n\nThe `should_retry_delivery` function implements this classification with additional logic for webhook-specific scenarios:\n\n**Rate Limiting Response Handling** provides special treatment for HTTP 429 responses because they indicate temporary capacity constraints rather than permanent failures. The system examines the `Retry-After` header to determine appropriate retry scheduling.\n\n| Retry-After Header | Value Type | Interpretation | Retry Scheduling |\n|-------------------|------------|----------------|------------------|\n| Present | Seconds (integer) | Exact delay requested | Schedule retry at specified time |\n| Present | HTTP-date | Absolute time | Schedule retry at specified timestamp |\n| Missing | N/A | Standard rate limiting | Apply default rate limit backoff |\n| Invalid | Malformed | Parse error | Log warning, use default backoff |\n\nWhen processing 429 responses, the system updates the endpoint's rate limiting state through the `handle_retry_after_response` method, which temporarily reduces the delivery rate below the requested threshold. This prevents immediate re-triggering of rate limiting while respecting the endpoint's capacity constraints.\n\n**Authentication and Authorization Failures** (401/403 responses) indicate configuration issues rather than transient failures. These responses trigger immediate alerting to the webhook owner and temporarily suspend delivery attempts to prevent continued authentication failures.\n\nThe system maintains an authentication failure tracking mechanism that distinguishes between signature verification failures (likely system clock skew or secret rotation issues) and authorization failures (endpoint policy changes or webhook subscription cancellation):\n\n| Error Pattern | Detection Method | Alert Priority | Remediation Action |\n|---------------|------------------|----------------|--------------------|\n| Signature Rejection | 401 with signature error message | High | Check secret rotation status |\n| Expired Timestamp | 401 with timestamp error | Medium | Verify system clock synchronization |\n| Source Rejection | 403 with source policy message | Low | Contact endpoint owner |\n| Subscription Cancelled | 403 with subscription message | High | Update webhook registration status |\n\n**Malformed Response Handling** addresses scenarios where endpoints return structurally invalid HTTP responses or responses that violate HTTP specifications. These failures require careful classification because they might indicate endpoint implementation issues rather than temporary failures.\n\nThe `HTTPResponse` object captures response parsing failures and categorizes them based on the type of malformation:\n\n| Malformation Type | Detection | Classification | Retry Decision |\n|-------------------|-----------|----------------|----------------|\n| Invalid Status Line | HTTP parsing exception | Server Error | Retry with backoff |\n| Malformed Headers | Header parsing failure | Server Error | Retry with backoff |\n| Invalid Content-Length | Length mismatch | Server Error | Single retry attempt |\n| Encoding Errors | Character encoding issues | Server Error | No retry, log for investigation |\n| Truncated Response | Incomplete response | Network Error | Retry with normal backoff |\n\n### System-Level Failure Recovery\n\nSystem-level failure recovery ensures webhook delivery system consistency and availability during infrastructure failures, worker process crashes, and database connectivity issues. The recovery mechanisms must handle both graceful shutdowns and unexpected failures while preserving delivery ordering and preventing data loss.\n\n**Worker Process Crash Recovery** handles scenarios where `DeliveryWorker` processes terminate unexpectedly during webhook delivery processing. The system implements a combination of message acknowledgment, worker heartbeats, and orphaned task recovery to ensure no deliveries are lost during worker failures.\n\nEach `DeliveryWorker` maintains a heartbeat record in Redis that includes the worker's current processing state and the events it has claimed for delivery. The heartbeat mechanism enables rapid detection of worker failures and prevents indefinite message locks:\n\n| Worker State | Heartbeat Interval | Timeout Threshold | Recovery Action |\n|--------------|-------------------|-------------------|-----------------|\n| Idle | 30 seconds | 90 seconds | Mark worker as available |\n| Processing Event | 10 seconds | 45 seconds | Reclaim orphaned event |\n| Delivering Webhook | 5 seconds | 20 seconds | Retry delivery from checkpoint |\n| Circuit Breaker Wait | 60 seconds | 180 seconds | Resume normal processing |\n\nThe orphaned task recovery process runs as a separate background service that periodically scans for events claimed by workers that have exceeded their heartbeat timeout. When orphaned events are detected, the recovery service releases the message locks and re-queues the events for processing by healthy workers.\n\n**Database Connection Failure Recovery** implements connection pool management with automatic retry and circuit breaking to handle database connectivity issues gracefully. The `DatabaseManager` maintains multiple connection pools with different priorities for different types of operations.\n\n| Operation Type | Connection Pool | Retry Strategy | Failure Handling |\n|----------------|-----------------|----------------|------------------|\n| Event Queuing | Primary Pool | 3 retries with backoff | Switch to secondary pool |\n| Delivery Logging | Secondary Pool | 2 retries | Buffer to local storage |\n| Configuration Queries | Read-Only Pool | 5 retries | Use cached configuration |\n| Health Checks | Dedicated Pool | No retries | Mark database unhealthy |\n\nThe connection failure recovery implements a tiered fallback strategy where less critical operations gracefully degrade while preserving core delivery functionality. Event queuing operations receive the highest priority, followed by delivery attempt logging, with configuration and analytics queries receiving lower priority during resource constraints.\n\n> **Decision: Database Failure Handling Strategy**  \n> - **Context**: Database connectivity issues can cause webhook delivery system outages if not handled gracefully\n> - **Options Considered**: Immediate failure, local buffering, secondary database, full degraded mode\n> - **Decision**: Implement tiered fallback with local buffering and connection pool management\n> - **Rationale**: Balances delivery reliability with system complexity while maintaining data consistency\n> - **Consequences**: Enables continued operation during database issues but requires local storage management and eventual consistency handling\n\n**Message Queue Persistence and Recovery** ensures that webhook events are not lost during Redis failures or restarts. The system implements a dual-persistence strategy using Redis Streams for primary queuing and PostgreSQL for durable backup storage.\n\nThe queue persistence mechanism maintains synchronized state between Redis and PostgreSQL, with Redis serving as the high-performance primary queue and PostgreSQL providing durability guarantees:\n\n| Queue Operation | Redis Action | PostgreSQL Action | Consistency Guarantee |\n|-----------------|--------------|-------------------|----------------------|\n| Event Enqueue | XADD to stream | INSERT to events table | At-least-once delivery |\n| Event Claim | XREADGROUP | UPDATE claim timestamp | Exactly-once claim |\n| Delivery Success | XACK message | UPDATE delivery status | Eventually consistent |\n| Delivery Failure | Update retry count | INSERT attempt record | Eventually consistent |\n| Dead Letter | XADD to DLQ stream | UPDATE to failed status | At-least-once DLQ |\n\nDuring Redis recovery, the system rebuilds the in-memory queue state by scanning PostgreSQL for events that were not successfully delivered, ensuring no events are lost during infrastructure failures.\n\n**Configuration Hot Reloading** enables webhook system configuration updates without service restarts, which is critical for production systems that must maintain high availability. The configuration system monitors for changes to webhook registrations, rate limiting settings, and circuit breaker thresholds.\n\nThe hot reload mechanism uses Redis pub/sub notifications to coordinate configuration changes across multiple worker processes:\n\n| Configuration Type | Change Detection | Distribution Method | Application Timing |\n|-------------------|------------------|-------------------|-------------------|\n| Webhook Registration | Database trigger | Redis pub/sub | Immediate |\n| Rate Limit Updates | Admin API | Redis pub/sub | Next request |\n| Circuit Breaker Thresholds | Configuration file | File system watcher | Next health check |\n| Security Settings | Environment variables | Process signal | Next request batch |\n\nConfiguration changes that affect security (such as signature validation settings) are applied with additional validation to prevent configuration errors from compromising webhook security.\n\n**Split-Brain Prevention** addresses scenarios where multiple instances of the webhook delivery system become isolated from each other but continue processing events. This can lead to duplicate deliveries or inconsistent state if not properly handled.\n\nThe system implements distributed coordination using Redis-based distributed locks with lease expiration to ensure only one instance processes events for each webhook endpoint at any given time:\n\n| Coordination Mechanism | Implementation | Lease Duration | Failure Handling |\n|----------------------|----------------|----------------|------------------|\n| Endpoint Processing Lock | Redis SETNX with TTL | 60 seconds | Automatic release on timeout |\n| Circuit Breaker State | Redis hash with TTL | 120 seconds | Conservative state assumption |\n| Rate Limit Buckets | Redis sorted set | 300 seconds | Reset to safe defaults |\n| Dead Letter Processing | Redis queue with timeout | 180 seconds | Manual intervention required |\n\nThe distributed coordination prevents split-brain scenarios while allowing for rapid failover when primary instances become unavailable.\n\n### ![Retry Decision Flowchart](./diagrams/retry-flowchart.svg)\n\nThe retry decision flowchart illustrates the comprehensive decision tree used by the `should_retry_delivery` function to determine appropriate handling for each delivery attempt. The flowchart shows how HTTP status codes, attempt counts, circuit breaker states, and rate limiting constraints combine to determine whether an event should be retried, rescheduled, or moved to the dead letter queue.\n\n### ![Failure Recovery Architecture](./diagrams/failure-recovery.svg)\n\nThe failure recovery architecture diagram shows the interaction between system components during failure scenarios, including worker crash recovery, database failover, and split-brain prevention mechanisms. The diagram illustrates how different types of failures trigger different recovery pathways while maintaining system consistency.\n\n### Common Pitfalls\n\n⚠️ **Pitfall: Retry Amplification During Recovery**\n\nA common mistake is implementing retry logic that creates exponentially increasing load during system recovery. When many webhook endpoints fail simultaneously (such as during network partitions), naive retry implementations can create a \"thundering herd\" effect where all retries execute simultaneously when connectivity is restored.\n\n**Why this is problematic**: Recovery periods are when system resources are most constrained. Simultaneous retry attempts can overwhelm recovered endpoints, extend outage duration, and trigger cascading failures in downstream systems.\n\n**How to avoid**: Implement retry jitter and staggered recovery scheduling. Add randomization to retry delays and implement global rate limiting during recovery periods to spread retry load over time.\n\n⚠️ **Pitfall: Incorrect Timeout Cascade Classification**\n\nMany implementations incorrectly classify all timeout errors as retriable failures, leading to persistent retry attempts against endpoints that are permanently overloaded or misconfigured.\n\n**Why this is problematic**: Continuous retry attempts against timing-out endpoints can prevent proper circuit breaker activation and waste system resources on deliveries that will never succeed.\n\n**How to avoid**: Implement timeout pattern analysis that distinguishes between network-level timeouts (retriable) and application-level timeouts (potential circuit breaker trigger). Track timeout duration patterns to identify chronically slow endpoints.\n\n⚠️ **Pitfall: Database Connection Leak During Failures**\n\nConnection pool management often fails during database connectivity issues, leading to connection exhaustion and preventing system recovery even after database connectivity is restored.\n\n**Why this is problematic**: Connection leaks during failure scenarios create resource exhaustion that persists beyond the original failure, extending outage duration and requiring manual intervention.\n\n**How to avoid**: Implement aggressive connection timeouts during failure detection and connection pool reset mechanisms that forcibly close potentially stale connections during recovery procedures.\n\n⚠️ **Pitfall: Inconsistent Error Classification Across Workers**\n\nDifferent worker processes applying different error classification logic leads to inconsistent retry behavior and circuit breaker state divergence across the distributed system.\n\n**Why this is problematic**: Inconsistent error handling creates unpredictable webhook delivery behavior and makes debugging difficult. Circuit breaker states can become inconsistent across workers, leading to delivery confusion.\n\n**How to avoid**: Centralize error classification logic in shared libraries and implement configuration distribution mechanisms that ensure all workers apply identical error handling rules.\n\n### Implementation Guidance\n\nThis section provides comprehensive implementation support for robust error handling across all webhook delivery system components. The error handling patterns established here apply to webhook registration failures, delivery processing errors, circuit breaker edge cases, and event logging failures.\n\n**Technology Recommendations:**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| HTTP Client | `requests` with timeout configuration | `aiohttp` with connection pooling and circuit breakers |\n| Error Tracking | Python logging with structured output | `sentry-sdk` with error aggregation and alerting |\n| Retry Logic | Simple exponential backoff | `tenacity` library with advanced retry strategies |\n| Health Monitoring | Basic success rate tracking | `prometheus-client` with detailed metrics |\n| Database Resilience | Connection retry with backoff | `SQLAlchemy` with connection pooling and failover |\n\n**Recommended File Structure:**\n```\nwebhook-system/\n├── src/\n│   ├── error_handling/\n│   │   ├── __init__.py                 ← error handling exports\n│   │   ├── network_errors.py           ← network and timeout handling\n│   │   ├── endpoint_classification.py  ← HTTP status code classification  \n│   │   ├── system_recovery.py          ← worker and database failure recovery\n│   │   ├── retry_strategies.py         ← retry logic and backoff algorithms\n│   │   └── failure_detection.py        ← failure pattern detection\n│   ├── delivery/\n│   │   ├── http_client.py              ← enhanced HTTP client with error handling\n│   │   └── worker_recovery.py          ← worker crash detection and recovery\n│   ├── infrastructure/\n│   │   ├── database_manager.py         ← connection pool management\n│   │   ├── queue_recovery.py           ← message queue persistence recovery\n│   │   └── health_monitoring.py        ← system health and alerting\n│   └── tests/\n│       ├── test_error_scenarios.py     ← comprehensive error testing\n│       └── test_recovery_procedures.py ← failure recovery validation\n```\n\n**Infrastructure Starter Code - Enhanced HTTP Client:**\n\n```python\nimport asyncio\nimport aiohttp\nimport time\nimport logging\nfrom typing import Optional, Dict, Any, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass NetworkErrorType(Enum):\n    DNS_RESOLUTION = \"dns_resolution\"\n    CONNECTION_TIMEOUT = \"connection_timeout\" \n    CONNECTION_REFUSED = \"connection_refused\"\n    READ_TIMEOUT = \"read_timeout\"\n    WRITE_TIMEOUT = \"write_timeout\"\n    NETWORK_UNREACHABLE = \"network_unreachable\"\n\n@dataclass\nclass HTTPResponse:\n    status_code: int\n    response_time: float\n    error_message: str\n    headers: dict\n    body: str\n    network_error_type: Optional[NetworkErrorType] = None\n\nclass WebhookHTTPClient:\n    \"\"\"Enhanced HTTP client with comprehensive error handling and timeout management.\"\"\"\n    \n    def __init__(self, config: 'WebhookConfig'):\n        self.config = config\n        self.logger = logging.getLogger(__name__)\n        self.session = None\n        \n    async def __aenter__(self):\n        timeout = aiohttp.ClientTimeout(\n            total=self.config.delivery_timeout,\n            connect=self.config.delivery_timeout // 3,\n            sock_read=self.config.delivery_timeout // 3,\n            sock_connect=self.config.delivery_timeout // 3\n        )\n        \n        connector = aiohttp.TCPConnector(\n            limit=100,\n            limit_per_host=10,\n            ttl_dns_cache=300,\n            use_dns_cache=True,\n            keepalive_timeout=30\n        )\n        \n        self.session = aiohttp.ClientSession(\n            timeout=timeout,\n            connector=connector,\n            headers={'User-Agent': 'WebhookDeliverySystem/1.0'}\n        )\n        return self\n        \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        if self.session:\n            await self.session.close()\n    \n    async def post_json(self, url: str, payload: dict, headers: dict) -> HTTPResponse:\n        \"\"\"\n        Send JSON POST request with comprehensive error handling.\n        \n        Handles all categories of network errors, timeouts, and malformed responses\n        with appropriate classification for retry decision making.\n        \"\"\"\n        start_time = time.time()\n        \n        try:\n            async with self.session.post(url, json=payload, headers=headers) as response:\n                response_time = time.time() - start_time\n                \n                try:\n                    body = await response.text()\n                except asyncio.TimeoutError:\n                    return HTTPResponse(\n                        status_code=0,\n                        response_time=response_time,\n                        error_message=\"Response body read timeout\",\n                        headers={},\n                        body=\"\",\n                        network_error_type=NetworkErrorType.READ_TIMEOUT\n                    )\n                \n                return HTTPResponse(\n                    status_code=response.status,\n                    response_time=response_time,\n                    error_message=\"\",\n                    headers=dict(response.headers),\n                    body=body\n                )\n                \n        except asyncio.TimeoutError as e:\n            response_time = time.time() - start_time\n            return HTTPResponse(\n                status_code=0,\n                response_time=response_time,\n                error_message=f\"Request timeout after {response_time:.2f}s\",\n                headers={},\n                body=\"\",\n                network_error_type=NetworkErrorType.CONNECTION_TIMEOUT\n            )\n            \n        except aiohttp.ClientConnectorError as e:\n            response_time = time.time() - start_time\n            error_type = self._classify_connection_error(e)\n            \n            return HTTPResponse(\n                status_code=0,\n                response_time=response_time,\n                error_message=str(e),\n                headers={},\n                body=\"\",\n                network_error_type=error_type\n            )\n            \n        except Exception as e:\n            response_time = time.time() - start_time\n            self.logger.error(f\"Unexpected HTTP client error: {e}\")\n            \n            return HTTPResponse(\n                status_code=0,\n                response_time=response_time,\n                error_message=f\"Unexpected error: {str(e)}\",\n                headers={},\n                body=\"\"\n            )\n    \n    def _classify_connection_error(self, error: aiohttp.ClientConnectorError) -> NetworkErrorType:\n        \"\"\"Classify connection errors for appropriate retry handling.\"\"\"\n        error_str = str(error).lower()\n        \n        if \"name or service not known\" in error_str or \"nodename nor servname provided\" in error_str:\n            return NetworkErrorType.DNS_RESOLUTION\n        elif \"connection refused\" in error_str:\n            return NetworkErrorType.CONNECTION_REFUSED\n        elif \"network is unreachable\" in error_str:\n            return NetworkErrorType.NETWORK_UNREACHABLE\n        else:\n            return NetworkErrorType.CONNECTION_TIMEOUT\n```\n\n**Infrastructure Starter Code - Database Connection Manager:**\n\n```python\nimport asyncpg\nimport asyncio\nimport logging\nfrom contextlib import asynccontextmanager\nfrom typing import AsyncGenerator, Optional\nfrom dataclasses import dataclass\nimport time\n\n@dataclass\nclass DatabaseConfig:\n    host: str\n    port: int\n    database: str\n    username: str\n    password: str\n    min_connections: int = 5\n    max_connections: int = 20\n    command_timeout: int = 30\n    max_retries: int = 3\n    retry_delay: float = 1.0\n\nclass DatabaseManager:\n    \"\"\"Database connection manager with automatic failure recovery and connection pooling.\"\"\"\n    \n    def __init__(self, config: DatabaseConfig):\n        self.config = config\n        self.logger = logging.getLogger(__name__)\n        self.primary_pool: Optional[asyncpg.Pool] = None\n        self.is_healthy = True\n        self.last_health_check = 0\n        self.health_check_interval = 60  # seconds\n        \n    async def initialize(self):\n        \"\"\"Initialize the database connection pool with retry logic.\"\"\"\n        for attempt in range(self.config.max_retries):\n            try:\n                self.primary_pool = await asyncpg.create_pool(\n                    host=self.config.host,\n                    port=self.config.port,\n                    database=self.config.database,\n                    user=self.config.username,\n                    password=self.config.password,\n                    min_size=self.config.min_connections,\n                    max_size=self.config.max_connections,\n                    command_timeout=self.config.command_timeout\n                )\n                \n                # Test connection\n                async with self.primary_pool.acquire() as conn:\n                    await conn.execute(\"SELECT 1\")\n                \n                self.is_healthy = True\n                self.logger.info(\"Database connection pool initialized successfully\")\n                return\n                \n            except Exception as e:\n                self.logger.error(f\"Database connection attempt {attempt + 1} failed: {e}\")\n                if attempt < self.config.max_retries - 1:\n                    await asyncio.sleep(self.config.retry_delay * (2 ** attempt))\n                else:\n                    self.is_healthy = False\n                    raise\n    \n    @asynccontextmanager\n    async def get_connection(self) -> AsyncGenerator[asyncpg.Connection, None]:\n        \"\"\"\n        Get database connection with automatic retry and health checking.\n        \n        Implements connection-level retry with exponential backoff and automatic\n        pool recreation during extended outages.\n        \"\"\"\n        if not self.is_healthy or not self.primary_pool:\n            await self._attempt_recovery()\n            \n        for attempt in range(self.config.max_retries):\n            try:\n                async with self.primary_pool.acquire() as conn:\n                    yield conn\n                return\n                \n            except Exception as e:\n                self.logger.warning(f\"Database connection attempt {attempt + 1} failed: {e}\")\n                \n                if attempt < self.config.max_retries - 1:\n                    await asyncio.sleep(self.config.retry_delay * (2 ** attempt))\n                else:\n                    self.is_healthy = False\n                    raise\n    \n    async def _attempt_recovery(self):\n        \"\"\"Attempt to recover database connectivity with pool recreation.\"\"\"\n        current_time = time.time()\n        if current_time - self.last_health_check < self.health_check_interval:\n            return\n            \n        self.last_health_check = current_time\n        self.logger.info(\"Attempting database connection recovery\")\n        \n        try:\n            if self.primary_pool:\n                await self.primary_pool.close()\n                \n            await self.initialize()\n            \n        except Exception as e:\n            self.logger.error(f\"Database recovery failed: {e}\")\n            self.is_healthy = False\n```\n\n**Core Logic Skeleton - Error Classification:**\n\n```python\nfrom typing import Tuple, Optional\nfrom enum import Enum\n\nclass RetryDecision(Enum):\n    RETRY_IMMEDIATELY = \"retry_immediately\"\n    RETRY_WITH_BACKOFF = \"retry_with_backoff\"\n    RETRY_WITH_DELAY = \"retry_with_delay\"\n    NO_RETRY = \"no_retry\"\n    MOVE_TO_DLQ = \"move_to_dlq\"\n\ndef should_retry_delivery(status_code: int, attempt_number: int, response_headers: dict = None, error_type: Optional[NetworkErrorType] = None) -> Tuple[RetryDecision, Optional[int]]:\n    \"\"\"\n    Determine retry eligibility based on response characteristics and attempt history.\n    \n    Returns tuple of (retry_decision, delay_seconds) where delay_seconds is None\n    for immediate retry or no retry scenarios.\n    \"\"\"\n    # TODO 1: Check if maximum retry attempts exceeded - return MOVE_TO_DLQ if so\n    # TODO 2: Handle network-level errors (status_code == 0) based on error_type\n    #         - DNS_RESOLUTION: RETRY_WITH_BACKOFF with exponential delay\n    #         - CONNECTION_TIMEOUT: RETRY_WITH_BACKOFF, count toward circuit breaker\n    #         - CONNECTION_REFUSED: RETRY_WITH_DELAY with longer delay\n    #         - READ_TIMEOUT: RETRY_WITH_BACKOFF with normal exponential backoff\n    # TODO 3: Handle success responses (200-299) - return NO_RETRY\n    # TODO 4: Handle client errors (400-499):\n    #         - 408 (Request Timeout): RETRY_WITH_BACKOFF\n    #         - 429 (Rate Limited): RETRY_WITH_DELAY, extract delay from Retry-After header\n    #         - All other 4xx: NO_RETRY (permanent client errors)\n    # TODO 5: Handle server errors (500-599): RETRY_WITH_BACKOFF for all\n    # TODO 6: Calculate appropriate delay based on attempt_number and retry decision\n    #         - Use exponential backoff: base_delay * (2 ** attempt_number) with jitter\n    #         - Cap maximum delay at 300 seconds (5 minutes)\n    # TODO 7: Return tuple of (decision, delay_seconds)\n    pass\n\ndef calculate_retry_delay(attempt_number: int, base_delay: int = 5) -> int:\n    \"\"\"\n    Calculate exponential backoff delay with jitter to prevent thundering herd.\n    \n    Base delay doubles with each attempt, adds randomization to spread retry load.\n    \"\"\"\n    # TODO 1: Calculate exponential backoff: base_delay * (2 ** attempt_number)\n    # TODO 2: Add jitter: random value between 0.5x and 1.5x the calculated delay\n    # TODO 3: Apply maximum delay cap of 300 seconds\n    # TODO 4: Ensure minimum delay of 1 second\n    # TODO 5: Return integer delay in seconds\n    pass\n\ndef extract_retry_after_delay(retry_after_header: str) -> Optional[int]:\n    \"\"\"\n    Extract delay from HTTP Retry-After header supporting both seconds and HTTP-date formats.\n    \n    Returns delay in seconds, or None if header is malformed.\n    \"\"\"\n    # TODO 1: Check if header value is integer (delay-seconds format)\n    # TODO 2: If integer, validate range (1-86400 seconds) and return\n    # TODO 3: If not integer, try parsing as HTTP-date format\n    # TODO 4: Calculate seconds until specified timestamp\n    # TODO 5: Return None for malformed headers or past timestamps\n    # TODO 6: Cap maximum delay at 3600 seconds (1 hour) for security\n    pass\n```\n\n**Core Logic Skeleton - System Recovery:**\n\n```python\nimport asyncio\nimport json\nimport time\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass WorkerHeartbeat:\n    worker_id: str\n    last_heartbeat: float\n    current_event_id: Optional[str]\n    processing_state: str\n    claimed_events: List[str]\n\nclass SystemRecoveryManager:\n    \"\"\"Manages system-level failure recovery including worker crashes and database failures.\"\"\"\n    \n    def __init__(self, database_manager: DatabaseManager, redis_client, config: 'WebhookConfig'):\n        self.db = database_manager\n        self.redis = redis_client\n        self.config = config\n        self.logger = logging.getLogger(__name__)\n        self.worker_id = f\"worker_{int(time.time())}_{id(self)}\"\n        \n    async def run_worker_recovery_monitor(self):\n        \"\"\"\n        Continuously monitor for failed workers and recover orphaned events.\n        \n        Scans worker heartbeats to detect crashes and reclaims orphaned delivery events.\n        \"\"\"\n        while True:\n            try:\n                # TODO 1: Scan all worker heartbeat keys in Redis\n                # TODO 2: Identify workers that haven't updated heartbeat within timeout threshold\n                # TODO 3: For each failed worker, retrieve its claimed_events list\n                # TODO 4: Release message locks for orphaned events using XDEL or XCLAIM\n                # TODO 5: Re-queue orphaned events for processing by healthy workers\n                # TODO 6: Clean up stale worker heartbeat records\n                # TODO 7: Sleep for monitoring interval before next scan\n                await asyncio.sleep(30)  # Monitor every 30 seconds\n                \n            except Exception as e:\n                self.logger.error(f\"Worker recovery monitor error: {e}\")\n                await asyncio.sleep(60)  # Extended delay on errors\n                \n    async def update_worker_heartbeat(self, current_event_id: Optional[str] = None, processing_state: str = \"idle\"):\n        \"\"\"\n        Update worker heartbeat with current processing state.\n        \n        Heartbeat includes worker health and current processing context for recovery.\n        \"\"\"\n        # TODO 1: Create WorkerHeartbeat object with current timestamp and state\n        # TODO 2: Serialize heartbeat data to JSON\n        # TODO 3: Store in Redis with expiration slightly longer than monitor interval\n        # TODO 4: Handle Redis connection errors gracefully (log but don't fail)\n        # TODO 5: Update claimed_events list if currently processing events\n        pass\n        \n    async def recover_database_connections(self):\n        \"\"\"\n        Recover from database connectivity issues with progressive backoff.\n        \n        Implements tiered recovery strategy based on failure duration and severity.\n        \"\"\"\n        recovery_attempts = 0\n        while not self.db.is_healthy:\n            try:\n                # TODO 1: Attempt database connection test query\n                # TODO 2: If successful, mark database as healthy and reset attempt counter\n                # TODO 3: If failed, increment recovery_attempts and calculate backoff delay\n                # TODO 4: Implement progressive backoff: longer delays for repeated failures\n                # TODO 5: Log recovery attempts with appropriate severity levels\n                # TODO 6: Consider switching to degraded mode after extended failures\n                recovery_attempts += 1\n                await asyncio.sleep(min(recovery_attempts * 30, 300))  # Cap at 5 minutes\n                \n            except Exception as e:\n                self.logger.error(f\"Database recovery attempt {recovery_attempts} failed: {e}\")\n                \n    async def handle_queue_persistence_failure(self, event_data: Dict[str, Any], error: Exception):\n        \"\"\"\n        Handle Redis queue failures by falling back to database persistence.\n        \n        Ensures event delivery guarantees even during message queue outages.\n        \"\"\"\n        # TODO 1: Log the original queue failure with full context\n        # TODO 2: Attempt to persist event to PostgreSQL as fallback\n        # TODO 3: Mark event with special flag indicating queue failure recovery\n        # TODO 4: Implement eventual consistency sync when Redis recovers\n        # TODO 5: Alert operations team about queue persistence issues\n        # TODO 6: Return success/failure status for upstream error handling\n        pass\n```\n\n**Milestone Checkpoints:**\n\n**Error Classification Checkpoint:**\n```bash\n# Test error classification behavior\npython -m pytest tests/test_error_scenarios.py -v\n# Expected: All HTTP status codes classified correctly with appropriate retry decisions\n\n# Manual verification:\ncurl -X POST localhost:8080/webhooks/test-endpoint/simulate-error \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"error_type\": \"500\", \"delay\": 30}'\n# Expected: Retry with exponential backoff, circuit breaker activation after threshold\n```\n\n**System Recovery Checkpoint:**  \n```bash\n# Test worker crash recovery\npython scripts/test_worker_crash.py\n# Expected: Orphaned events reclaimed within 60 seconds, no delivery loss\n\n# Test database failover\ndocker stop webhook-postgres\npython -c \"import src.delivery.worker; worker.process_single_event()\"  \n# Expected: Graceful degradation, local buffering, recovery when DB returns\n```\n\n**Integration Test Checkpoint:**\n```bash\n# End-to-end error handling test\npython -m pytest tests/test_integration_errors.py::test_comprehensive_failure_scenarios\n# Expected: System maintains delivery guarantees through cascading failures\n```\n\n**Debugging Tips:**\n\n| Symptom | Likely Cause | Diagnosis Steps | Fix |\n|---------|--------------|-----------------|-----|\n| Events stuck in retry loop | Incorrect error classification | Check `should_retry_delivery` logic for status code | Fix classification rules, implement circuit breaker |  \n| Worker processes crash silently | Unhandled exceptions in delivery loop | Review worker logs, add exception handlers | Wrap delivery logic in try/catch, implement graceful shutdown |\n| Database connection exhaustion | Connection leaks during errors | Monitor connection pool metrics | Add connection timeouts, implement aggressive cleanup |\n| Memory growth during failures | Event accumulation without processing | Check dead letter queue size, worker processing rates | Implement backpressure, increase worker count |\n| Delivery duplicates after recovery | Improper message acknowledgment | Verify XACK calls after successful delivery | Fix message acknowledgment timing |\n\n\n## Testing Strategy and Milestone Checkpoints\n\n> **Milestone(s):** All milestones (1-4) - comprehensive testing strategy covering webhook registration validation (Milestone 1), delivery queue and retry testing (Milestone 2), circuit breaker and rate limiting verification (Milestone 3), and event logging and replay testing (Milestone 4)\n\n### Mental Model: The Quality Assurance Inspection System\n\nThink of testing a webhook delivery system like inspecting a sophisticated mail sorting and delivery operation. Just as a postal service must verify address accuracy, test delivery routes under various conditions, and ensure packages reach their destinations reliably, webhook delivery testing requires systematic validation of registration security, delivery resilience, and failure recovery mechanisms.\n\nThe testing strategy resembles a multi-stage quality control process. First, we inspect incoming mail (webhook registration) to ensure addresses are valid and customers can receive packages. Next, we test the sorting machinery (delivery queues) under normal and peak loads. Then we verify safety systems (circuit breakers) prevent damage when delivery routes fail. Finally, we audit the complete paper trail (event logging) and test our ability to resend lost packages (replay functionality).\n\nThis comprehensive approach ensures our webhook delivery system maintains reliability guarantees even when facing network failures, endpoint downtime, malicious attacks, and system overload conditions.\n\n### Milestone Verification Checkpoints\n\nThe milestone verification strategy employs progressive validation, where each checkpoint builds upon the previous milestone's foundation while introducing new complexity. Each milestone includes specific acceptance tests, behavioral validation, and integration checkpoints that verify the system meets its reliability and security requirements.\n\n#### Milestone 1: Webhook Registration & Security Testing\n\nThe first milestone testing focuses on security validation, SSRF protection, and ownership verification. These tests ensure that webhook endpoints are properly registered, signatures are correctly generated, and malicious registration attempts are blocked.\n\n**Registration Security Validation:**\n\n| Test Case | Expected Behavior | Verification Method |\n|-----------|------------------|-------------------|\n| Valid HTTPS endpoint registration | Registration succeeds with generated secret | POST to `/webhooks` returns 201 with webhook_id |\n| HTTP endpoint rejection | Registration fails with security error | POST returns 400 with \"HTTPS required\" message |\n| Private IP SSRF attempt | Registration blocked with SSRF protection error | localhost/192.168.x.x/10.x.x.x URLs return 403 |\n| Challenge-response verification | Endpoint ownership confirmed via challenge | Mock endpoint receives GET with challenge token |\n| Duplicate endpoint registration | Second registration updates existing webhook | Same URL returns existing webhook_id |\n| Invalid URL format | Registration fails with validation error | Malformed URLs return 400 with specific error |\n\n**Signature Generation Testing:**\n\nThe signature verification testing validates HMAC-SHA256 computation, timestamp inclusion, and replay protection mechanisms. These tests ensure webhook signatures provide cryptographic authentication and prevent replay attacks.\n\n| Component | Test Scenario | Expected Result |\n|-----------|--------------|-----------------|\n| `generate_hmac_signature()` | Payload + secret + timestamp | Deterministic HMAC-SHA256 hex string |\n| Signature validation | Valid signature within tolerance | `verify_signature()` returns True |\n| Timestamp replay protection | Signature older than `TIMESTAMP_TOLERANCE` | Verification fails with replay error |\n| Secret rotation overlap | Both old and new secrets valid | Either signature validates during transition |\n| Signature header format | Complete X-Webhook-Signature header | Format: \"t=timestamp,v1=signature\" |\n\n**Ownership Verification Process:**\n\nThe ownership verification testing ensures legitimate endpoint control while preventing unauthorized webhook registration. This process validates challenge-response protocols and timeout handling.\n\n1. **Challenge Generation**: System generates unique challenge token with 5-minute expiration\n2. **Challenge Delivery**: GET request sent to webhook URL with `?webhook_challenge=TOKEN` parameter\n3. **Response Validation**: Endpoint must return challenge token in response body within 30 seconds\n4. **Verification Recording**: Successful verification marks `WebhookRegistration.verified = True`\n5. **Retry Logic**: Failed verification attempts retry 3 times with exponential backoff\n6. **Timeout Handling**: Verification failure after retries marks webhook as unverified\n\n> **Critical Testing Insight:** Ownership verification tests must use real HTTP endpoints (not mocks) to validate network connectivity, DNS resolution, and certificate validation behavior.\n\n**Common Registration Pitfalls Testing:**\n\n⚠️ **Pitfall: SSRF Bypass Attempts**\nTest malicious URLs that attempt to bypass SSRF protection through URL encoding, redirects, or DNS rebinding attacks. Validation must catch `http://localhost`, `https://169.254.169.254/`, and redirect chains to private IPs.\n\n⚠️ **Pitfall: Weak Secret Generation**\nVerify webhook secrets use cryptographically secure random generation with sufficient entropy (minimum 256 bits). Secrets should never be predictable or reused across webhooks.\n\n⚠️ **Pitfall: Timestamp Tolerance Edge Cases**\nTest signature validation with timestamps exactly at tolerance boundaries, accounting for clock skew and network delays. Both past and future timestamp limits must be validated.\n\n#### Milestone 2: Delivery Queue & Retry Logic Testing\n\nThe second milestone testing validates delivery reliability, retry behavior, and dead letter queue processing. These tests ensure webhook events reach their destinations despite network failures and endpoint downtime.\n\n**Queue Management Testing:**\n\n| Queue Operation | Test Scenario | Expected Behavior |\n|-----------------|--------------|------------------|\n| Event ingestion | High-volume event creation | Events queued without loss, ordered by webhook |\n| Per-endpoint ordering | Multiple events to same webhook | FIFO delivery order maintained per endpoint |\n| Priority handling | Mix of normal and high priority events | High priority events delivered first |\n| Queue persistence | System restart during processing | Queued events survive restart and resume processing |\n| Batch consumption | Worker claims multiple events | `claim_ready_events()` returns batch with locks |\n\n**Exponential Backoff Validation:**\n\nThe retry testing validates exponential backoff behavior, jitter application, and status code-based retry decisions. These tests ensure failed deliveries are retried appropriately without overwhelming recovered endpoints.\n\n| Attempt Number | Base Delay | Expected Range (with jitter) | Status Codes to Retry |\n|----------------|------------|-------------------------------|----------------------|\n| 1 | 2 seconds | 1.5 - 2.5 seconds | 5xx, 429, timeout, connection error |\n| 2 | 4 seconds | 3.0 - 5.0 seconds | Same as above |\n| 3 | 8 seconds | 6.0 - 10.0 seconds | Same as above |\n| 4 | 16 seconds | 12.0 - 20.0 seconds | Same as above |\n| 5 | 32 seconds | 24.0 - 40.0 seconds | Same as above |\n\n**Dead Letter Queue Processing:**\n\nThe dead letter queue testing validates that permanently failed events are captured for manual intervention while maintaining complete delivery history for debugging.\n\n1. **Failure Classification**: Events failing all retry attempts move to DLQ with failure reason\n2. **Attempt History Preservation**: Complete `DeliveryAttempt` records maintained for debugging\n3. **Manual Inspection Interface**: DLQ provides filtering and search capabilities for operators\n4. **Bulk Replay Support**: Selected DLQ events can be replayed after endpoint recovery\n5. **Alerting Integration**: DLQ growth triggers alerts for immediate operator attention\n\n**HTTP Delivery Client Testing:**\n\n| Test Case | Mock Response | Expected Behavior |\n|-----------|---------------|-------------------|\n| Successful delivery | 200 OK with response body | Mark delivery successful, no retry |\n| Temporary server error | 503 Service Unavailable | Schedule exponential backoff retry |\n| Rate limiting response | 429 with Retry-After: 60 | Respect Retry-After header, bypass normal backoff |\n| Client error response | 400 Bad Request | Do not retry, log as permanent failure |\n| Connection timeout | No response within `DELIVERY_TIMEOUT` | Treat as temporary failure, retry |\n| DNS resolution failure | Network error | Treat as temporary failure, retry |\n\n> **Testing Architecture Decision:** Use real HTTP servers for integration tests rather than mocking HTTP responses. This validates timeout handling, connection pooling, and certificate validation behavior that mocks cannot replicate.\n\n**Delivery Worker Testing:**\n\nThe delivery worker testing validates concurrent processing, graceful shutdown, and worker recovery mechanisms. These tests ensure the delivery engine scales reliably under production loads.\n\nWorker behavior validation includes:\n- **Concurrent Processing**: Multiple workers process different webhook queues simultaneously\n- **Graceful Shutdown**: Workers complete in-flight deliveries before terminating\n- **Worker Health Monitoring**: Heartbeat mechanism detects crashed workers\n- **Load Balancing**: Event distribution spreads work across available workers\n- **Resource Limits**: Workers respect memory and connection pool limits\n\n#### Milestone 3: Circuit Breaker & Rate Limiting Testing\n\nThe third milestone testing validates endpoint protection mechanisms, ensuring failing endpoints don't overwhelm the system while rate limiting prevents abuse.\n\n**Circuit Breaker State Machine Testing:**\n\n| Current State | Failure Count | Action | Next State | Expected Behavior |\n|---------------|---------------|---------|-----------|-------------------|\n| CLOSED | 0-4 failures | Delivery attempt | CLOSED | Normal delivery processing |\n| CLOSED | 5 failures | Delivery failure | OPEN | Block all deliveries, start recovery timer |\n| OPEN | Any | Delivery attempt | OPEN | Reject immediately, no HTTP call |\n| OPEN | Timer expires | Recovery check | HALF_OPEN | Allow single test delivery |\n| HALF_OPEN | 1 success | Test delivery succeeds | CLOSED | Resume normal processing |\n| HALF_OPEN | 1 failure | Test delivery fails | OPEN | Extend recovery timeout |\n\n**Rate Limiting Validation:**\n\nThe rate limiting testing validates token bucket behavior, burst capacity handling, and Retry-After header respect. These tests ensure endpoints aren't overwhelmed while maintaining delivery throughput.\n\n| Scenario | Request Rate | Expected Behavior |\n|----------|-------------|-------------------|\n| Normal operation | 50 RPM (under 60 limit) | All deliveries proceed immediately |\n| Rate limit hit | 70 RPM (over 60 limit) | Excess requests delayed to maintain 60 RPM |\n| Burst handling | 120 requests in 30 seconds | First 60 proceed, remainder spaced over next minute |\n| Retry-After respect | 429 with Retry-After: 300 | Wait 300 seconds before next attempt |\n| Rate limit recovery | Return to normal rate | Resume immediate processing |\n\n**Circuit Breaker Configuration Testing:**\n\nThe circuit breaker configuration testing validates different failure thresholds and recovery timeouts for various endpoint reliability profiles.\n\n| Endpoint Type | Failure Threshold | Base Recovery Timeout | Max Recovery Timeout |\n|---------------|-------------------|----------------------|---------------------|\n| Critical production | 3 failures | 30 seconds | 300 seconds |\n| Standard endpoint | 5 failures | 60 seconds | 600 seconds |\n| Development/test | 10 failures | 10 seconds | 120 seconds |\n\n**Health Monitoring Integration:**\n\nThe health monitoring testing validates success rate tracking, latency measurement, and automated recovery detection for circuit breaker decision making.\n\nHealth metrics tracked include:\n- **Success Rate**: Percentage of successful deliveries over sliding time window\n- **Response Latency**: P50, P95, P99 response times for endpoint performance\n- **Error Distribution**: Classification of 4xx vs 5xx vs network errors\n- **Recovery Signals**: Sustained success after circuit breaker opens\n\n#### Milestone 4: Event Logging & Replay Testing\n\nThe fourth milestone testing validates comprehensive audit trails, replay functionality, and log retention management for compliance and debugging requirements.\n\n**Event Logging Comprehensive Testing:**\n\n| Log Component | Data Captured | Storage Requirements |\n|---------------|---------------|---------------------|\n| Delivery attempts | Full HTTP request/response, timing, worker ID | Hot storage 30 days |\n| Replay operations | Operator ID, reason, event list, rate overrides | Permanent retention |\n| Circuit breaker events | State changes, failure reasons, recovery timing | Warm storage 1 year |\n| Security events | Registration attempts, SSRF blocks, signature failures | Cold storage 3 years |\n\n**Event Replay Safety Testing:**\n\nThe replay testing validates safe re-delivery with deduplication support, rate limiting respect, and circuit breaker integration.\n\nReplay safety validations include:\n1. **Deduplication Headers**: Replayed events include `X-Webhook-Replay-Id` and `X-Webhook-Original-Delivery-Id`\n2. **Rate Limit Respect**: Replay operations honor current rate limits unless explicitly overridden\n3. **Circuit Breaker Integration**: Replay attempts blocked if circuit breaker is open\n4. **Bulk Replay Protection**: Large replay operations spread across time to prevent endpoint overwhelming\n5. **Operator Audit Trail**: Complete logging of who initiated replay and why\n\n**Log Retention Policy Testing:**\n\n| Storage Tier | Retention Period | Migration Trigger | Compression | Query Performance |\n|--------------|------------------|-------------------|-------------|-------------------|\n| Hot | 30 days | Age-based | None | Sub-second |\n| Warm | 365 days | 30 day age | GZIP | Seconds |\n| Cold | 1095 days | 365 day age | LZMA | Minutes |\n| Archive | 7 years | 3 year age | Maximum | Hours |\n\n**Replay Operation Testing:**\n\nThe replay operation testing validates various replay scenarios including single event replay, bulk operations, and selective filtering.\n\n| Replay Type | Test Scenario | Expected Behavior |\n|-------------|---------------|-------------------|\n| Single event | Operator replays specific failed delivery | Event re-queued with replay metadata |\n| Bulk replay | Replay all events for endpoint in time range | Events processed with rate limiting |\n| Filtered replay | Replay only events matching event_type filter | Correct subset identified and replayed |\n| Cross-endpoint replay | Replay events across multiple webhooks | Per-endpoint rate limits respected |\n\n### Integration Testing Strategy\n\nThe integration testing strategy validates end-to-end workflows using realistic scenarios with mock webhook endpoints. These tests ensure component interactions work correctly under various network conditions and failure scenarios.\n\n#### End-to-End Scenario Testing\n\n**Complete Webhook Lifecycle Testing:**\n\nThe end-to-end testing validates the complete webhook lifecycle from registration through successful delivery, including all intermediate states and error conditions.\n\nIntegration test scenarios include:\n1. **Successful Flow**: Register webhook → verify ownership → receive events → deliver successfully\n2. **Failure Recovery**: Endpoint fails → retry with backoff → circuit breaker opens → endpoint recovers → circuit closes\n3. **Rate Limiting**: High event volume → rate limiting activated → deliveries throttled → backlog processed\n4. **Replay Scenario**: Delivery failures → events in DLQ → endpoint fixed → successful replay\n\n**Mock Endpoint Testing Infrastructure:**\n\nThe mock endpoint infrastructure provides controlled webhook targets that simulate various endpoint behaviors for comprehensive testing coverage.\n\n| Mock Behavior | Configuration | Use Case |\n|---------------|---------------|----------|\n| Successful endpoint | Always return 200 OK | Happy path testing |\n| Intermittent failures | Random 5xx responses | Retry logic testing |\n| Rate limited endpoint | Return 429 after N requests | Rate limiting testing |\n| Slow endpoint | Configurable response delay | Timeout testing |\n| Malicious endpoint | Redirect to private IPs | SSRF protection testing |\n\n**Network Condition Simulation:**\n\nThe network simulation testing validates webhook delivery behavior under various network conditions including latency, packet loss, and connectivity failures.\n\nNetwork simulation scenarios:\n- **High Latency**: 500ms+ response times to test timeout handling\n- **Packet Loss**: Intermittent connection failures to test retry behavior  \n- **DNS Failures**: Temporary name resolution failures\n- **Connection Limits**: Endpoint refusing connections to test backpressure\n- **SSL Certificate Issues**: Invalid certificates to test security validation\n\n> **Integration Testing Architecture Decision:** Use containerized test environments with network policy controls rather than live internet endpoints. This provides deterministic network conditions while preventing accidental external service calls during testing.\n\n#### Component Integration Validation\n\n**Registry-Delivery Integration:**\n\nThe registry-delivery integration testing validates data flow between webhook registration and event delivery systems.\n\nIntegration validation points:\n1. **Webhook Lookup**: Delivery engine correctly retrieves webhook configuration from registry\n2. **Secret Management**: Signature generation uses current active secret from registry\n3. **Circuit Breaker State**: Registry reflects current circuit breaker status from delivery engine\n4. **Configuration Updates**: Changes to webhook configuration propagate to delivery workers\n\n**Queue-Worker Integration:**\n\nThe queue-worker integration testing validates message processing, acknowledgment, and failure handling between queue management and delivery workers.\n\n| Integration Aspect | Test Scenario | Expected Behavior |\n|---------------------|---------------|-------------------|\n| Message acknowledgment | Successful delivery | Message removed from queue |\n| Failure handling | Delivery fails, not exhausted | Message rescheduled with backoff |\n| Dead letter routing | All retries exhausted | Message moved to DLQ |\n| Worker crash recovery | Worker dies during processing | Message returns to queue |\n| Queue persistence | System restart | Messages survive and resume processing |\n\n**Circuit Breaker-Rate Limiter Integration:**\n\nThe circuit breaker and rate limiter integration testing validates protection mechanism coordination and proper prioritization of protection rules.\n\nProtection mechanism coordination:\n- **Circuit Open**: Rate limiter bypassed when circuit breaker blocks delivery\n- **Rate Limited**: Circuit breaker failure count not incremented for rate limited requests\n- **Recovery Coordination**: Both systems must agree endpoint is healthy for full recovery\n- **Configuration Conflicts**: Rate limits that would trigger circuit breaker thresholds\n\n#### Multi-Component Failure Testing\n\n**Cascading Failure Scenarios:**\n\nThe cascading failure testing validates system behavior when multiple components fail simultaneously, ensuring graceful degradation rather than complete system failure.\n\n| Failure Combination | System Response | Recovery Behavior |\n|---------------------|-----------------|-------------------|\n| Database + Queue failure | Accept events in memory buffer | Persist when connectivity returns |\n| Multiple worker failures | Remaining workers handle load | Auto-scale or alert operators |\n| Registry + Circuit breaker failure | Use cached webhook configuration | Refresh when registry recovers |\n| Rate limiter + Network partition | Default to conservative rate limits | Sync state when partition heals |\n\n**Resource Exhaustion Testing:**\n\nThe resource exhaustion testing validates system behavior under memory, CPU, and network connection limits.\n\nResource exhaustion scenarios:\n- **Memory Pressure**: Large event payloads consuming available memory\n- **Connection Pool Exhaustion**: More concurrent deliveries than HTTP connections\n- **CPU Saturation**: Signature generation overwhelming processing capacity  \n- **Disk Space**: Event logs filling available storage\n- **Queue Depth**: More events than queue system can efficiently handle\n\n### Load and Reliability Testing\n\nThe load and reliability testing validates system performance under production-scale traffic while maintaining delivery guarantees and protection mechanisms.\n\n#### Stress Testing Delivery Queues\n\n**High-Volume Event Processing:**\n\nThe high-volume testing validates queue performance, worker scaling, and delivery throughput under realistic production loads.\n\n| Load Level | Events/Second | Webhooks | Expected Throughput | Queue Depth Limit |\n|------------|---------------|----------|---------------------|-------------------|\n| Light | 100 | 50 | <1 second delivery | <1000 events |\n| Moderate | 1,000 | 500 | <5 second delivery | <10,000 events |\n| Heavy | 10,000 | 2,000 | <30 second delivery | <100,000 events |\n| Peak | 50,000 | 5,000 | <5 minute delivery | <500,000 events |\n\n**Queue Scaling Behavior:**\n\nThe queue scaling testing validates horizontal and vertical scaling behavior as event volume increases.\n\nQueue scaling validations:\n1. **Worker Auto-scaling**: Additional workers start when queue depth increases\n2. **Memory Management**: Queue system handles large event backlogs without memory exhaustion\n3. **Persistence Performance**: High write volumes don't degrade queue persistence\n4. **Query Performance**: Event claiming performance remains stable under load\n5. **Graceful Degradation**: System prioritizes critical events when overwhelmed\n\n#### Circuit Breaker Load Testing\n\n**Failure Threshold Validation:**\n\nThe circuit breaker load testing validates protection mechanism behavior under high failure rates and recovery scenarios.\n\n| Failure Rate | Circuit Response | Recovery Time | Expected Behavior |\n|--------------|------------------|---------------|-------------------|\n| 10% failures | Circuit remains closed | N/A | Normal retry processing |\n| 50% failures | Circuit opens quickly | 60 seconds | Block further attempts |\n| 90% failures | Circuit opens immediately | 300 seconds | Extended recovery timeout |\n| 100% failures | Circuit opens on threshold | 600 seconds | Maximum recovery timeout |\n\n**Recovery Performance Testing:**\n\nThe recovery performance testing validates circuit breaker behavior during endpoint recovery, ensuring prompt resumption of normal delivery without overwhelming recovering endpoints.\n\nRecovery validation scenarios:\n- **Gradual Recovery**: Endpoint success rate slowly improves over time\n- **Immediate Recovery**: Endpoint immediately returns to full functionality\n- **False Recovery**: Endpoint appears recovered but fails again quickly\n- **Partial Recovery**: Endpoint handles some request types but not others\n\n#### Rate Limiting Performance\n\n**Token Bucket Algorithm Validation:**\n\nThe token bucket performance testing validates rate limiting accuracy and fairness under various load patterns.\n\n| Load Pattern | Request Distribution | Expected Behavior |\n|--------------|---------------------|-------------------|\n| Steady state | Evenly distributed | Smooth delivery rate |\n| Burst traffic | High initial spike | Burst allowed, then throttled |\n| Bursty workload | Periodic spikes | Each burst handled independently |\n| Sustained overload | Continuous high rate | Strict rate enforcement |\n\n**Rate Limiting Fairness:**\n\nThe rate limiting fairness testing validates that webhook endpoints receive fair treatment and aren't starved by high-volume endpoints.\n\nFairness validation includes:\n- **Per-endpoint Isolation**: High-volume webhook doesn't affect others\n- **Priority Handling**: Critical events bypass normal rate limits\n- **Adaptive Limits**: Rate limits adjust based on endpoint capacity\n- **Burst Credit**: Endpoints accumulate burst capacity during quiet periods\n\n#### Reliability Under Failure Conditions\n\n**Network Partition Resilience:**\n\nThe network partition testing validates system behavior when components cannot communicate, ensuring data consistency and recovery when connectivity returns.\n\n| Partition Scenario | System Response | Data Consistency | Recovery Behavior |\n|--------------------|-----------------|------------------|-------------------|\n| Worker-Queue partition | Workers use local buffer | At-least-once delivery | Sync on reconnect |\n| Registry-Worker partition | Use cached webhook config | Eventual consistency | Refresh on reconnect |\n| Database partition | Read-only mode with alerts | Read-only consistency | Full sync on reconnect |\n\n**Component Crash Recovery:**\n\nThe crash recovery testing validates data persistence and state recovery when individual components fail unexpectedly.\n\nComponent crash scenarios:\n- **Worker Process Crash**: In-flight deliveries return to queue, processing resumes\n- **Queue System Crash**: Persistent events survive restart, temporary buffer lost\n- **Database Crash**: Transaction log enables full state recovery\n- **Registry Crash**: Webhook configuration cached by workers continues operation\n\n> **Reliability Testing Architecture Decision:** Use chaos engineering techniques with random component failures rather than scheduled maintenance windows. This validates recovery mechanisms under realistic failure timing and ensures production resilience.\n\n**Performance Degradation Testing:**\n\nThe performance degradation testing validates graceful performance reduction rather than complete failure when system resources become constrained.\n\nPerformance degradation scenarios:\n- **Slow Database**: Increased query latency affects event processing speed\n- **Limited Memory**: Reduced buffer sizes slow event ingestion\n- **CPU Throttling**: Signature generation becomes bottleneck\n- **Network Congestion**: Delivery attempts experience higher latency\n\n#### Load Testing Results Analysis\n\n**Performance Metrics Collection:**\n\nThe load testing metrics provide comprehensive performance visibility for capacity planning and performance optimization.\n\n| Metric Category | Key Measurements | Target Values |\n|------------------|------------------|---------------|\n| Throughput | Events processed/second | 10,000+ events/sec |\n| Latency | End-to-end delivery time | P95 < 30 seconds |\n| Error Rates | Failed deliveries/total | < 0.1% permanent failures |\n| Resource Usage | CPU, memory, disk I/O | < 70% sustained usage |\n| Queue Metrics | Queue depth, processing lag | < 60 second queue lag |\n\n**Capacity Planning Data:**\n\nThe capacity planning analysis provides scaling recommendations based on load testing results and resource utilization patterns.\n\nScaling recommendations include:\n- **Worker Scaling**: Events per second to worker count ratios\n- **Database Scaling**: Connection pool sizing for concurrent webhook management\n- **Queue Scaling**: Memory and disk requirements for various queue depths\n- **Network Scaling**: Bandwidth requirements for delivery throughput\n- **Storage Scaling**: Log storage growth rates and retention requirements\n\n### Implementation Guidance\n\nThe testing implementation provides comprehensive test infrastructure for validating webhook delivery system reliability across all milestones. This guidance includes complete test frameworks, mock infrastructure, and validation tools.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Test Framework | `pytest` with fixtures | `pytest` + `pytest-asyncio` + `pytest-xdist` |\n| HTTP Mocking | `responses` library | Custom HTTP server with `aiohttp` |\n| Database Testing | SQLite in-memory | PostgreSQL test containers |\n| Queue Testing | Redis test instance | RabbitMQ test containers |\n| Load Testing | `locust` with Python | `k6` with JavaScript scenarios |\n| Mock Services | `Flask` test servers | `Docker Compose` test environment |\n\n#### Recommended File Structure\n\n```\nwebhook-system/\n  tests/\n    unit/\n      test_webhook_registry.py      ← Registry component tests\n      test_delivery_engine.py       ← Delivery and retry logic tests  \n      test_circuit_breaker.py       ← Circuit breaker state tests\n      test_event_logging.py         ← Logging and replay tests\n    integration/\n      test_end_to_end.py           ← Complete workflow tests\n      test_failure_scenarios.py    ← Error condition tests\n      test_component_integration.py ← Inter-component tests\n    load/\n      test_queue_performance.py     ← Queue scaling tests\n      test_delivery_throughput.py   ← Delivery performance tests\n      locustfile.py                ← Load testing scenarios\n    fixtures/\n      mock_endpoints.py            ← HTTP endpoint mocking\n      test_data.py                 ← Test data generation\n      database_setup.py            ← Test database management\n    conftest.py                    ← Pytest configuration and fixtures\n  scripts/\n    run_milestone_tests.py         ← Milestone validation runner\n    performance_analysis.py       ← Load test result analysis\n```\n\n#### Mock Infrastructure Implementation\n\n**Complete HTTP Endpoint Mocking:**\n\n```python\n# tests/fixtures/mock_endpoints.py\n\"\"\"\nComprehensive HTTP endpoint mocking for webhook delivery testing.\nProvides configurable endpoint behaviors for integration testing.\n\"\"\"\n\nimport time\nimport random\nfrom typing import Dict, List, Optional, Callable\nfrom dataclasses import dataclass\nfrom flask import Flask, request, jsonify, Response\nimport threading\nimport requests\nfrom contextlib import contextmanager\n\n@dataclass\nclass EndpointConfig:\n    \"\"\"Configuration for mock webhook endpoint behavior.\"\"\"\n    success_rate: float = 1.0  # 0.0 to 1.0\n    response_delay: float = 0.0  # seconds\n    status_codes: List[int] = None  # Custom status code distribution\n    rate_limit_rpm: Optional[int] = None\n    response_body: str = \"OK\"\n    custom_headers: Dict[str, str] = None\n    \n    def __post_init__(self):\n        if self.status_codes is None:\n            self.status_codes = [200]\n        if self.custom_headers is None:\n            self.custom_headers = {}\n\nclass MockWebhookEndpoint:\n    \"\"\"Configurable mock webhook endpoint for testing delivery behavior.\"\"\"\n    \n    def __init__(self, port: int = 0):\n        self.app = Flask(__name__)\n        self.port = port\n        self.server = None\n        self.thread = None\n        self.configs: Dict[str, EndpointConfig] = {}\n        self.request_history: List[Dict] = []\n        self.rate_limit_counters: Dict[str, List[float]] = {}\n        \n        # Setup Flask routes\n        self.app.add_url_rule('/webhook/<endpoint_id>', 'webhook', \n                             self.handle_webhook, methods=['POST'])\n        self.app.add_url_rule('/challenge/<endpoint_id>', 'challenge',\n                             self.handle_challenge, methods=['GET'])\n    \n    def configure_endpoint(self, endpoint_id: str, config: EndpointConfig):\n        \"\"\"Configure behavior for specific endpoint ID.\"\"\"\n        # TODO 1: Store endpoint configuration in configs dictionary\n        # TODO 2: Initialize rate limiting counter for endpoint if specified\n        # TODO 3: Validate configuration parameters (success_rate 0-1, etc.)\n        pass\n    \n    def handle_webhook(self, endpoint_id: str) -> Response:\n        \"\"\"Handle webhook POST request with configured behavior.\"\"\"\n        # TODO 1: Record request details in request_history\n        # TODO 2: Check rate limiting if configured for endpoint\n        # TODO 3: Apply response delay if configured\n        # TODO 4: Determine response status code based on success_rate\n        # TODO 5: Return response with configured body and headers\n        pass\n    \n    def handle_challenge(self, endpoint_id: str) -> Response:\n        \"\"\"Handle ownership verification challenge.\"\"\"\n        # TODO 1: Extract challenge token from query parameters\n        # TODO 2: Return challenge token in response body\n        # TODO 3: Log challenge attempt in request_history\n        pass\n    \n    def check_rate_limit(self, endpoint_id: str) -> bool:\n        \"\"\"Check if request should be rate limited.\"\"\"\n        # TODO 1: Get rate limit configuration for endpoint\n        # TODO 2: Clean old timestamps outside rate limit window  \n        # TODO 3: Count requests in current window\n        # TODO 4: Return True if under limit, False if rate limited\n        pass\n    \n    def get_request_count(self, endpoint_id: str) -> int:\n        \"\"\"Get total request count for endpoint.\"\"\"\n        return len([r for r in self.request_history \n                   if r['endpoint_id'] == endpoint_id])\n    \n    def clear_history(self):\n        \"\"\"Clear request history for fresh test.\"\"\"\n        self.request_history.clear()\n        self.rate_limit_counters.clear()\n\n@contextmanager\ndef mock_webhook_server(configs: Dict[str, EndpointConfig]):\n    \"\"\"Context manager for mock webhook server lifecycle.\"\"\"\n    server = MockWebhookEndpoint()\n    \n    # TODO 1: Configure endpoints with provided configs\n    # TODO 2: Start server in background thread\n    # TODO 3: Yield server instance for test use\n    # TODO 4: Clean shutdown server and thread\n    pass\n```\n\n**Database Test Infrastructure:**\n\n```python\n# tests/fixtures/database_setup.py\n\"\"\"\nTest database infrastructure for webhook system testing.\nProvides isolated database instances for test execution.\n\"\"\"\n\nimport tempfile\nimport asyncio\nfrom contextlib import contextmanager\nfrom webhook_system.database import DatabaseManager\nfrom webhook_system.models import Base\n\nclass TestDatabaseManager:\n    \"\"\"Database manager for testing with cleanup capabilities.\"\"\"\n    \n    def __init__(self, database_url: str = None):\n        if database_url is None:\n            # Use in-memory SQLite for unit tests\n            database_url = \"sqlite:///:memory:\"\n        self.database_url = database_url\n        self.db_manager = DatabaseManager(database_url)\n    \n    async def setup_test_database(self):\n        \"\"\"Initialize test database with schema.\"\"\"\n        # TODO 1: Create all tables using SQLAlchemy models\n        # TODO 2: Seed test data if specified in fixture\n        # TODO 3: Return database connection for test use\n        pass\n    \n    async def cleanup_test_database(self):\n        \"\"\"Clean up test database after test completion.\"\"\"\n        # TODO 1: Close all active connections\n        # TODO 2: Drop all tables if using dedicated test database\n        # TODO 3: Remove temporary files if using file-based SQLite\n        pass\n    \n    @contextmanager\n    def test_transaction(self):\n        \"\"\"Provide transactional test context with rollback.\"\"\"\n        # TODO 1: Begin database transaction\n        # TODO 2: Yield connection for test operations\n        # TODO 3: Rollback transaction on exit (keeps database clean)\n        pass\n\n@contextmanager\ndef test_database_session():\n    \"\"\"Provide clean database session for each test.\"\"\"\n    db_manager = TestDatabaseManager()\n    \n    try:\n        # TODO 1: Setup test database schema\n        # TODO 2: Yield database manager for test use  \n        # TODO 3: Cleanup database after test completion\n        pass\n    finally:\n        # Ensure cleanup even if test fails\n        pass\n```\n\n#### Core Test Implementation Skeletons\n\n**Milestone 1 Registration Testing:**\n\n```python\n# tests/unit/test_webhook_registry.py\n\"\"\"\nComprehensive webhook registration and security testing.\nValidates HMAC signatures, SSRF protection, and ownership verification.\n\"\"\"\n\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom webhook_system.registry import WebhookRegistry\nfrom webhook_system.models import WebhookRegistration, WebhookSecret\n\nclass TestWebhookRegistration:\n    \"\"\"Test webhook endpoint registration functionality.\"\"\"\n    \n    @pytest.fixture\n    def registry(self, test_database):\n        return WebhookRegistry(test_database)\n    \n    def test_valid_https_registration(self, registry):\n        \"\"\"Test successful webhook registration with valid HTTPS URL.\"\"\"\n        # TODO 1: Call register_webhook with valid HTTPS URL\n        # TODO 2: Verify webhook record created in database\n        # TODO 3: Verify secret generated and stored\n        # TODO 4: Verify webhook marked as unverified initially\n        # TODO 5: Verify response contains webhook_id and secret\n        pass\n    \n    def test_http_url_rejection(self, registry):\n        \"\"\"Test rejection of HTTP URLs for security.\"\"\"\n        # TODO 1: Attempt registration with HTTP URL\n        # TODO 2: Verify registration fails with security error\n        # TODO 3: Verify no database record created\n        # TODO 4: Verify error message mentions HTTPS requirement\n        pass\n    \n    def test_ssrf_protection(self, registry):\n        \"\"\"Test SSRF protection against private IP addresses.\"\"\"\n        ssrf_urls = [\n            \"https://localhost/webhook\",\n            \"https://127.0.0.1/webhook\", \n            \"https://192.168.1.100/webhook\",\n            \"https://10.0.0.1/webhook\",\n            \"https://169.254.169.254/webhook\"  # AWS metadata\n        ]\n        \n        for url in ssrf_urls:\n            # TODO 1: Attempt registration with SSRF URL\n            # TODO 2: Verify registration blocked with SSRF error\n            # TODO 3: Verify no database record created\n            pass\n\nclass TestHMACSignatures:\n    \"\"\"Test HMAC-SHA256 signature generation and validation.\"\"\"\n    \n    def test_signature_generation(self, registry):\n        \"\"\"Test deterministic HMAC signature generation.\"\"\"\n        payload = '{\"event\": \"test\", \"data\": {\"key\": \"value\"}}'\n        secret = \"test_secret_key_12345\"\n        timestamp = 1640995200\n        \n        # TODO 1: Generate signature using generate_hmac_signature\n        # TODO 2: Verify signature is consistent across multiple calls\n        # TODO 3: Verify signature format matches expected pattern\n        # TODO 4: Verify signature changes with different payload/secret/timestamp\n        pass\n    \n    def test_signature_validation(self, registry):\n        \"\"\"Test signature validation with various scenarios.\"\"\"\n        # TODO 1: Generate valid signature and verify it validates\n        # TODO 2: Test signature validation with wrong secret\n        # TODO 3: Test signature validation with modified payload\n        # TODO 4: Test timestamp tolerance boundaries\n        pass\n    \n    def test_replay_protection(self, registry):\n        \"\"\"Test timestamp-based replay attack prevention.\"\"\"\n        old_timestamp = int(time.time()) - (TIMESTAMP_TOLERANCE + 100)\n        future_timestamp = int(time.time()) + (TIMESTAMP_TOLERANCE + 100)\n        \n        # TODO 1: Test signature with timestamp too far in past\n        # TODO 2: Test signature with timestamp too far in future  \n        # TODO 3: Test signature with timestamp at exact tolerance boundary\n        # TODO 4: Verify appropriate error messages for each case\n        pass\n\nclass TestOwnershipVerification:\n    \"\"\"Test webhook endpoint ownership verification.\"\"\"\n    \n    def test_successful_verification(self, registry, mock_webhook_server):\n        \"\"\"Test successful ownership verification flow.\"\"\"\n        endpoint_config = EndpointConfig(success_rate=1.0)\n        \n        with mock_webhook_server({\"test\": endpoint_config}) as server:\n            # TODO 1: Register webhook with mock server URL\n            # TODO 2: Trigger ownership verification\n            # TODO 3: Verify challenge request sent to endpoint\n            # TODO 4: Verify webhook marked as verified in database\n            # TODO 5: Verify challenge token properly validated\n            pass\n    \n    def test_verification_failure(self, registry, mock_webhook_server):\n        \"\"\"Test ownership verification with unresponsive endpoint.\"\"\"\n        endpoint_config = EndpointConfig(success_rate=0.0, status_codes=[404])\n        \n        with mock_webhook_server({\"test\": endpoint_config}) as server:\n            # TODO 1: Register webhook with mock server URL\n            # TODO 2: Trigger ownership verification\n            # TODO 3: Verify verification fails after retries\n            # TODO 4: Verify webhook remains unverified\n            # TODO 5: Verify failure reason recorded\n            pass\n\n# Checkpoint validation for Milestone 1\ndef test_milestone_1_checkpoint():\n    \"\"\"Verify Milestone 1 acceptance criteria.\"\"\"\n    # Run: python -m pytest tests/unit/test_webhook_registry.py::test_milestone_1_checkpoint\n    # Expected: All registration security tests pass\n    # Manual verification: \n    #   1. Start webhook system\n    #   2. POST https://your-server.com/webhooks {\"url\": \"https://httpbin.org/post\", \"events\": [\"user.created\"]}\n    #   3. Should return {\"webhook_id\": \"...\", \"secret\": \"...\", \"verified\": false}\n    #   4. Check httpbin request logs for verification challenge\n    pass\n```\n\n**Milestone 2 Delivery Testing:**\n\n```python\n# tests/unit/test_delivery_engine.py\n\"\"\"\nComprehensive delivery engine testing including retry logic and DLQ.\nValidates exponential backoff, queue management, and failure handling.\n\"\"\"\n\nimport pytest\nimport asyncio\nfrom unittest.mock import AsyncMock, patch\nfrom webhook_system.delivery import DeliveryEngine, QueueManager\nfrom webhook_system.models import WebhookEvent, DeliveryAttempt\n\nclass TestDeliveryQueue:\n    \"\"\"Test webhook delivery queue management.\"\"\"\n    \n    @pytest.fixture\n    async def queue_manager(self, test_database, redis_connection):\n        return QueueManager(redis_connection)\n    \n    async def test_event_queuing(self, queue_manager):\n        \"\"\"Test event queuing with ordering guarantees.\"\"\"\n        webhook_id = \"webhook_123\"\n        events = [\n            {\"event_id\": f\"event_{i}\", \"priority\": 1} \n            for i in range(10)\n        ]\n        \n        # TODO 1: Queue all events for same webhook\n        # TODO 2: Verify events queued in FIFO order\n        # TODO 3: Verify events isolated per webhook\n        # TODO 4: Verify priority events processed first\n        pass\n    \n    async def test_queue_persistence(self, queue_manager):\n        \"\"\"Test queue persistence across system restarts.\"\"\"\n        # TODO 1: Queue several events  \n        # TODO 2: Simulate system restart by creating new QueueManager\n        # TODO 3: Verify events still available for processing\n        # TODO 4: Verify event order preserved after restart\n        pass\n\nclass TestRetryLogic:\n    \"\"\"Test exponential backoff retry logic.\"\"\"\n    \n    def test_backoff_calculation(self):\n        \"\"\"Test exponential backoff delay calculation.\"\"\"\n        base_delay = 2.0\n        \n        for attempt in range(1, 6):\n            delay = calculate_retry_delay(attempt, base_delay)\n            expected_base = base_delay * (2 ** (attempt - 1))\n            \n            # TODO 1: Verify delay is in expected range (with jitter)\n            # TODO 2: Verify jitter prevents exact timing\n            # TODO 3: Verify maximum delay cap enforced\n            assert expected_base * 0.75 <= delay <= expected_base * 1.25\n    \n    async def test_retry_status_decisions(self, delivery_engine):\n        \"\"\"Test retry decisions based on HTTP status codes.\"\"\"\n        retry_scenarios = [\n            (200, False),  # Success - no retry\n            (404, False),  # Client error - no retry  \n            (429, True),   # Rate limited - retry\n            (500, True),   # Server error - retry\n            (503, True),   # Service unavailable - retry\n            (0, True),     # Connection error - retry\n        ]\n        \n        for status_code, should_retry in retry_scenarios:\n            # TODO 1: Create mock delivery attempt with status code\n            # TODO 2: Call should_retry_delivery function\n            # TODO 3: Verify retry decision matches expected behavior\n            # TODO 4: Test with different attempt numbers\n            pass\n\nclass TestDeadLetterQueue:\n    \"\"\"Test dead letter queue processing.\"\"\"\n    \n    async def test_dlq_routing(self, delivery_engine, mock_webhook_server):\n        \"\"\"Test events moved to DLQ after max retries.\"\"\"\n        # Configure endpoint to always fail\n        endpoint_config = EndpointConfig(success_rate=0.0, status_codes=[500])\n        \n        with mock_webhook_server({\"failing\": endpoint_config}) as server:\n            # TODO 1: Queue event for failing endpoint\n            # TODO 2: Process through all retry attempts\n            # TODO 3: Verify event moved to DLQ after max retries\n            # TODO 4: Verify delivery history preserved\n            # TODO 5: Verify DLQ contains failure reason\n            pass\n    \n    async def test_dlq_inspection(self, delivery_engine):\n        \"\"\"Test DLQ provides filtering and search capabilities.\"\"\"\n        # TODO 1: Create events with various failure reasons\n        # TODO 2: Move events to DLQ with different timestamps\n        # TODO 3: Test filtering by webhook_id, failure reason, time range\n        # TODO 4: Test pagination for large DLQ contents\n        pass\n\n# Checkpoint validation for Milestone 2  \ndef test_milestone_2_checkpoint():\n    \"\"\"Verify Milestone 2 acceptance criteria.\"\"\"\n    # Run: python -m pytest tests/unit/test_delivery_engine.py::test_milestone_2_checkpoint\n    # Expected: All delivery and retry tests pass\n    # Manual verification:\n    #   1. Queue webhook event for unreachable endpoint\n    #   2. Observe retry attempts with increasing delays\n    #   3. Verify event moves to DLQ after MAX_RETRY_ATTEMPTS\n    pass\n```\n\n#### Load Testing Infrastructure\n\n**Complete Load Testing Implementation:**\n\n```python\n# tests/load/locustfile.py\n\"\"\"\nComprehensive load testing scenarios for webhook delivery system.\nValidates performance under realistic production traffic patterns.\n\"\"\"\n\nimport random\nimport time\nfrom locust import HttpUser, task, between\nfrom locust.exception import StopUser\n\nclass WebhookSystemUser(HttpUser):\n    \"\"\"Simulated user generating webhook traffic.\"\"\"\n    \n    wait_time = between(0.1, 2.0)  # Realistic event generation rate\n    \n    def on_start(self):\n        \"\"\"Initialize test user with webhook registration.\"\"\"\n        # TODO 1: Register test webhook endpoint\n        # TODO 2: Store webhook_id for event generation\n        # TODO 3: Configure mock endpoint for delivery testing\n        pass\n    \n    @task(10)\n    def send_webhook_event(self):\n        \"\"\"Generate webhook event for delivery.\"\"\"\n        event_payload = {\n            \"event_type\": random.choice([\"user.created\", \"order.placed\", \"payment.completed\"]),\n            \"timestamp\": int(time.time()),\n            \"data\": self.generate_test_payload()\n        }\n        \n        # TODO 1: POST event to webhook system ingestion endpoint  \n        # TODO 2: Verify event accepted (2xx response)\n        # TODO 3: Track response time in Locust metrics\n        pass\n    \n    @task(2) \n    def query_delivery_status(self):\n        \"\"\"Query delivery status for generated events.\"\"\"\n        # TODO 1: GET delivery status for recent events\n        # TODO 2: Verify response contains expected delivery data\n        # TODO 3: Track query performance\n        pass\n    \n    def generate_test_payload(self) -> dict:\n        \"\"\"Generate realistic test payload with size variation.\"\"\"\n        # TODO 1: Create payload with realistic field structure\n        # TODO 2: Vary payload size to simulate different event types\n        # TODO 3: Include nested objects and arrays\n        return {\n            \"user_id\": random.randint(1, 100000),\n            \"metadata\": {\"key\": \"value\" * random.randint(1, 100)}\n        }\n\nclass HighVolumeUser(WebhookSystemUser):\n    \"\"\"User simulating high-volume webhook producers.\"\"\"\n    \n    wait_time = between(0.01, 0.1)  # Much higher event rate\n    \n    @task(20)\n    def burst_events(self):\n        \"\"\"Generate burst of events to test queue handling.\"\"\"\n        # TODO 1: Generate multiple events in rapid succession\n        # TODO 2: Vary event priority and expiration\n        # TODO 3: Monitor queue depth and processing lag\n        pass\n\nclass CircuitBreakerTestUser(WebhookSystemUser):\n    \"\"\"User testing circuit breaker behavior.\"\"\"\n    \n    def on_start(self):\n        super().on_start()\n        # TODO 1: Register webhook with failing mock endpoint\n        # TODO 2: Configure endpoint to fail after success threshold\n        pass\n    \n    @task(5)\n    def trigger_circuit_breaker(self):\n        \"\"\"Generate events to trigger circuit breaker.\"\"\"\n        # TODO 1: Send events that will cause delivery failures\n        # TODO 2: Monitor circuit breaker state transitions\n        # TODO 3: Verify delivery attempts stop when circuit opens\n        pass\n```\n\n#### Milestone Checkpoint Validation\n\n**Automated Milestone Testing:**\n\n```python\n# scripts/run_milestone_tests.py\n\"\"\"\nAutomated milestone validation runner.\nProvides step-by-step verification of acceptance criteria.\n\"\"\"\n\nimport subprocess\nimport sys\nimport time\nimport requests\nfrom typing import Dict, List, Optional\n\nclass MilestoneValidator:\n    \"\"\"Automated validation of milestone acceptance criteria.\"\"\"\n    \n    def __init__(self, base_url: str = \"http://localhost:8000\"):\n        self.base_url = base_url\n        self.test_webhook_id: Optional[str] = None\n        self.test_results: Dict[str, bool] = {}\n    \n    def validate_milestone_1(self) -> bool:\n        \"\"\"Validate Milestone 1: Webhook Registration & Security.\"\"\"\n        print(\"🔐 Validating Milestone 1: Webhook Registration & Security\")\n        \n        success = True\n        \n        # Test 1: Valid webhook registration\n        success &= self.test_webhook_registration()\n        \n        # Test 2: SSRF protection\n        success &= self.test_ssrf_protection()\n        \n        # Test 3: Signature generation\n        success &= self.test_signature_generation()\n        \n        # Test 4: Ownership verification\n        success &= self.test_ownership_verification()\n        \n        self.test_results[\"milestone_1\"] = success\n        return success\n    \n    def test_webhook_registration(self) -> bool:\n        \"\"\"Test webhook endpoint registration functionality.\"\"\"\n        # TODO 1: POST valid webhook registration request\n        # TODO 2: Verify response contains webhook_id and secret\n        # TODO 3: Verify webhook stored in database\n        # TODO 4: Store webhook_id for subsequent tests\n        print(\"  ✓ Webhook registration validation\")\n        return True\n    \n    def test_ssrf_protection(self) -> bool:\n        \"\"\"Test SSRF protection prevents private IP registration.\"\"\"\n        # TODO 1: Attempt registration with localhost URL\n        # TODO 2: Attempt registration with private IP ranges\n        # TODO 3: Verify all attempts rejected with security error\n        print(\"  ✓ SSRF protection validation\")\n        return True\n    \n    def validate_milestone_2(self) -> bool:\n        \"\"\"Validate Milestone 2: Delivery Queue & Retry Logic.\"\"\"  \n        print(\"🚀 Validating Milestone 2: Delivery Queue & Retry Logic\")\n        \n        success = True\n        \n        # Test 1: Event queuing and ordering\n        success &= self.test_event_queuing()\n        \n        # Test 2: Retry logic with backoff\n        success &= self.test_retry_logic()\n        \n        # Test 3: Dead letter queue\n        success &= self.test_dead_letter_queue()\n        \n        self.test_results[\"milestone_2\"] = success\n        return success\n    \n    def validate_milestone_3(self) -> bool:\n        \"\"\"Validate Milestone 3: Circuit Breaker & Rate Limiting.\"\"\"\n        print(\"🛡️ Validating Milestone 3: Circuit Breaker & Rate Limiting\")\n        \n        success = True\n        \n        # Test 1: Circuit breaker state transitions\n        success &= self.test_circuit_breaker()\n        \n        # Test 2: Rate limiting behavior\n        success &= self.test_rate_limiting()\n        \n        # Test 3: Health monitoring\n        success &= self.test_health_monitoring()\n        \n        self.test_results[\"milestone_3\"] = success\n        return success\n    \n    def validate_milestone_4(self) -> bool:\n        \"\"\"Validate Milestone 4: Event Log & Replay.\"\"\"\n        print(\"📋 Validating Milestone 4: Event Log & Replay\")\n        \n        success = True\n        \n        # Test 1: Delivery logging\n        success &= self.test_delivery_logging()\n        \n        # Test 2: Event replay\n        success &= self.test_event_replay()\n        \n        # Test 3: Log retention\n        success &= self.test_log_retention()\n        \n        self.test_results[\"milestone_4\"] = success\n        return success\n    \n    def run_all_validations(self) -> bool:\n        \"\"\"Run all milestone validations in sequence.\"\"\"\n        print(\"🧪 Starting Comprehensive Milestone Validation\\n\")\n        \n        all_success = True\n        \n        all_success &= self.validate_milestone_1()\n        all_success &= self.validate_milestone_2()  \n        all_success &= self.validate_milestone_3()\n        all_success &= self.validate_milestone_4()\n        \n        self.print_summary()\n        return all_success\n    \n    def print_summary(self):\n        \"\"\"Print validation results summary.\"\"\"\n        print(\"\\n📊 Milestone Validation Summary\")\n        print(\"=\" * 40)\n        \n        for milestone, success in self.test_results.items():\n            status = \"✅ PASS\" if success else \"❌ FAIL\"\n            print(f\"{milestone.replace('_', ' ').title()}: {status}\")\n        \n        overall = all(self.test_results.values())\n        print(f\"\\nOverall Result: {'✅ ALL PASS' if overall else '❌ SOME FAILURES'}\")\n\nif __name__ == \"__main__\":\n    validator = MilestoneValidator()\n    success = validator.run_all_validations()\n    sys.exit(0 if success else 1)\n\n```\n\n\n## Debugging Guide\n\n> **Milestone(s):** All milestones (1-4) - debugging techniques covering webhook registration issues (Milestone 1), delivery failures and retry loops (Milestone 2), circuit breaker and rate limiting problems (Milestone 3), and event logging and replay complications (Milestone 4)\n\n### Mental Model: The Detective's Toolkit\n\nThink of debugging a webhook delivery system like being a detective investigating why packages aren't being delivered in a complex postal network. Just as a detective follows clues from the mailroom through sorting facilities to final delivery, debugging webhooks requires following the event trail through registration, queuing, delivery attempts, and logging. Each component leaves evidence - logs, metrics, state changes - that tell the story of what went wrong. The key is knowing where to look first, what symptoms indicate which root causes, and how to fix problems without disrupting the entire delivery network.\n\nUnlike debugging a simple web application where you can trace a single request-response cycle, webhook delivery systems involve asynchronous processing, distributed state, and complex retry logic. A single event might leave traces across multiple databases, queue systems, and log stores. The challenge is correlating these distributed traces to understand the complete failure story.\n\n### Delivery Failure Debugging: Diagnosing Stuck Queues, Failed Deliveries, and Retry Loops\n\n**Stuck Queue Analysis**\n\nThe most common webhook delivery problem is events getting stuck in queues without being processed. This manifests as growing queue depths with no corresponding delivery attempts being logged. The detective work starts with identifying whether the problem is in event ingestion, queue consumption, or delivery processing.\n\nQueue stagnation typically occurs in three locations within the delivery pipeline. First, events may fail to enter the queue due to webhook registration lookup failures or signature generation errors. Second, events may accumulate in queues because `DeliveryWorker` instances have crashed or become unresponsive. Third, events may be dequeued but never complete processing due to hanging HTTP requests or database connection issues.\n\nThe diagnostic approach begins with queue depth monitoring across all webhook endpoints. Each `WebhookRegistration` should have an associated Redis stream containing pending `QueueEntry` items. Sudden spikes in queue depth without corresponding increases in delivery attempt logs indicate worker consumption issues.\n\n| Symptom | Likely Cause | Diagnostic Command | Fix |\n|---------|--------------|-------------------|-----|\n| Queue depth growing steadily | Worker crashed or stuck | Check `WorkerHeartbeat` timestamps | Restart worker instances |\n| Queue depth steady but no deliveries | Database connection failure | Check delivery attempt table writes | Restart database connections |\n| Events enter queue then disappear | Dead letter queue activation | Check DLQ depth and failure reasons | Review circuit breaker thresholds |\n| Queue processes slowly | Rate limiting active | Check `RateLimitConfig` token consumption | Adjust rate limits or add workers |\n\n**Failed Delivery Root Cause Analysis**\n\nWhen deliveries fail, the `DeliveryAttempt` records provide the primary evidence for diagnosis. However, interpreting HTTP status codes, response times, and error messages requires understanding the subtle differences between temporary network issues, endpoint configuration problems, and systematic failures.\n\nHTTP 5xx responses generally indicate temporary endpoint issues that warrant retry attempts, while 4xx responses suggest permanent configuration problems that should not be retried. However, HTTP 429 (rate limiting) and 408 (timeout) responses require special handling with respect to the endpoint's `Retry-After` headers and circuit breaker state.\n\nThe investigation process starts with filtering `DeliveryAttempt` records by `webhook_id` and examining the progression of `status_code` values across attempts. Consistent 4xx responses indicate endpoint configuration issues, while intermittent 5xx responses suggest capacity or network problems. Timeout errors (indicated by null `status_code` and network error messages) point to connectivity or DNS resolution issues.\n\n> **Critical Insight**: Failed deliveries often follow patterns that reveal root causes. A sequence of successful deliveries followed by sudden 5xx failures suggests endpoint overload, while consistent DNS resolution errors indicate infrastructure changes.\n\n**Retry Loop Detection and Resolution**\n\nRetry loops occur when the exponential backoff logic becomes stuck in a pattern where events are continuously rescheduled but never successfully delivered or moved to the dead letter queue. This happens when circuit breaker thresholds are misconfigured, when the `MAX_RETRY_ATTEMPTS` limit is too high, or when system clock drift affects retry scheduling.\n\nThe diagnostic signature of retry loops includes `DeliveryAttempt` records with `attempt_number` values that exceed reasonable thresholds, combined with `next_attempt_at` timestamps that show regular scheduling patterns without progression toward success or final failure.\n\n| Loop Pattern | Root Cause | Detection Method | Resolution |\n|--------------|------------|------------------|------------|\n| Exponential backoff plateau | Max delay reached but endpoint still failing | `next_attempt_at` intervals stop growing | Reduce max retry attempts or enable circuit breaker |\n| Clock drift retry acceleration | System time inconsistency | Negative or zero retry delays | Synchronize system clocks across workers |\n| Circuit breaker flapping | Threshold too sensitive | Rapid OPEN/CLOSED state transitions | Increase failure threshold or extend recovery timeout |\n| Rate limit retry storms | Retry-After header ignored | Bursts of attempts after rate limit responses | Implement proper Retry-After header handling |\n\nThe resolution approach depends on whether the loop is caused by configuration, infrastructure, or endpoint-specific issues. Configuration problems require updating `CircuitBreakerConfig` or `RateLimitConfig` parameters. Infrastructure issues may require worker restarts or system clock synchronization. Endpoint-specific problems might require manual intervention to update webhook URLs or temporarily disable problematic endpoints.\n\n### Security and Signature Debugging: HMAC Verification Failures and Timestamp Validation Issues\n\n**HMAC Signature Verification Failures**\n\nHMAC signature verification failures are among the most subtle and difficult debugging challenges in webhook systems because they involve cryptographic operations that fail silently, leaving minimal diagnostic traces. The verification process depends on exact byte-for-byte reproduction of the signed payload, making it sensitive to character encoding, JSON serialization order, and HTTP header manipulation.\n\nThe signature verification process begins when webhook endpoints receive delivery requests and attempt to validate the `X-Webhook-Signature` header against their stored secret. Failures occur when the receiving endpoint cannot reproduce the same HMAC-SHA256 value that was generated during delivery. This mismatch can result from payload modification during transit, incorrect secret retrieval, or differences in the canonical signing string format.\n\nThe debugging approach requires correlating delivery logs with endpoint-side verification attempts. The `DeliveryAttempt` records contain the `request_payload` and `request_headers` that were sent, while endpoint logs should show the signature verification inputs and results. The key insight is that HMAC verification requires bit-perfect reproduction of both the payload and the signing metadata.\n\n> **Security Insight**: HMAC verification failures often indicate either implementation bugs in the signing process or active tampering with webhook deliveries. Never ignore signature verification failures as mere configuration issues.\n\nCommon signature verification failure modes include JSON canonicalization differences where the sending system serializes JSON with different key ordering or whitespace than the receiving system expects. Character encoding mismatches can occur when payload strings contain Unicode characters that are encoded differently during signing versus verification. HTTP proxy modifications may alter payload content or headers during transit, breaking signature verification.\n\n| Verification Failure Type | Symptoms | Debugging Steps | Common Fixes |\n|---------------------------|----------|-----------------|-------------|\n| JSON serialization mismatch | Consistent verification failures for JSON payloads | Compare sent vs received JSON byte-for-byte | Use deterministic JSON serialization |\n| Character encoding issues | Failures only with Unicode content | Check payload encoding in transit | Ensure UTF-8 encoding throughout pipeline |\n| Header tampering | Signature header present but invalid | Compare delivered headers with generation logs | Investigate proxy or load balancer configuration |\n| Clock skew impacts | Intermittent failures related to time | Check timestamp differences between systems | Increase `TIMESTAMP_TOLERANCE` or sync clocks |\n\n**Timestamp Validation and Replay Protection**\n\nTimestamp validation failures occur when the difference between the signature generation time and verification time exceeds the configured `TIMESTAMP_TOLERANCE` window. This protection mechanism prevents replay attacks but can cause legitimate delivery failures when system clocks are not synchronized or when network delays cause extended delivery times.\n\nThe timestamp validation process embeds the current Unix timestamp into the HMAC signing string, ensuring that signature validation fails if attempted outside the acceptable time window. However, this creates operational complexity when webhook deliveries experience delays due to retry logic, rate limiting, or network congestion.\n\nTimestamp-related failures manifest as successful signature generation followed by verification failures at the receiving endpoint. The `DeliveryAttempt` records will show successful HTTP delivery (2xx status codes) but endpoint logs will indicate timestamp validation failures. This pattern distinguishes timestamp issues from HMAC computation problems.\n\nThe diagnostic process involves comparing the `attempted_at` timestamp in `DeliveryAttempt` records with the embedded signature timestamp and the endpoint's verification timestamp. Delays longer than `TIMESTAMP_TOLERANCE` (default 300 seconds) will cause validation failures even with correct HMAC computation.\n\n**Secret Rotation Debugging**\n\nSecret rotation introduces additional complexity because multiple `WebhookSecret` entries may be valid simultaneously during rotation periods. The receiving endpoint must attempt verification with all active secrets, but implementation bugs can cause verification to fail with older secrets even when they should remain valid.\n\nThe rotation process creates overlapping validity periods where both old and new secrets remain active. The `WebhookSecret` model tracks `activated_at` and `expires_at` timestamps to manage this overlap, but endpoint implementations must correctly handle multiple secret validation attempts.\n\n| Rotation Issue | Symptom Pattern | Root Cause | Resolution |\n|----------------|-----------------|------------|------------|\n| Immediate post-rotation failures | All deliveries fail after rotation | Endpoint using only newest secret | Implement multi-secret validation |\n| Gradual rotation failures | Increasing failure rate during overlap period | Inconsistent secret selection in delivery | Fix secret selection algorithm |\n| Expired secret usage | Sudden failures after rotation completion | Cached expired secrets in delivery workers | Clear secret caches after rotation |\n| Clock synchronization issues | Random verification failures | System clock differences during rotation | Synchronize clocks or extend overlap periods |\n\n### Performance and Scaling Issues: Queue Backlog, Rate Limiting Bottlenecks, and Resource Exhaustion\n\n**Queue Backlog Analysis and Resolution**\n\nQueue backlogs develop when event ingestion rates consistently exceed delivery processing capacity. This imbalance can occur due to insufficient worker instances, slow endpoint response times, or resource contention in the delivery pipeline. Unlike temporary queue spikes from traffic bursts, sustained backlogs indicate systematic capacity problems that require architectural solutions.\n\nThe backlog formation process begins when the `enqueue_event` operation adds events faster than `DeliveryWorker` instances can process them. Each webhook endpoint maintains its own Redis stream, so backlogs can be per-endpoint (indicating endpoint-specific issues) or system-wide (indicating infrastructure capacity limits).\n\nQueue backlog diagnosis requires analyzing both depth trends and processing velocity across webhook endpoints. The `QueueManager` provides metrics for queue depth, event age, and processing rates that reveal whether backlogs are growing, stable, or shrinking. Correlation with endpoint response times and circuit breaker states helps identify root causes.\n\n> **Scalability Insight**: Queue backlogs are symptoms, not causes. The root cause is always an imbalance between event ingestion and delivery capacity. Focus on identifying and removing the delivery bottlenecks rather than just adding more queue capacity.\n\n**Rate Limiting Bottleneck Identification**\n\nRate limiting bottlenecks occur when the configured delivery rates are too conservative for the endpoint's actual capacity, causing artificial delays that contribute to queue growth. The `RateLimitConfig` parameters may be set too low, or the token bucket implementation may not properly handle burst traffic patterns.\n\nThe bottleneck manifests as consistent delays in the `can_proceed` method calls, with delivery attempts being postponed despite endpoint availability. The `DeliveryAttempt` records show successful deliveries but with longer than necessary delays between attempts. This pattern differs from endpoint-imposed rate limiting (HTTP 429 responses) which comes from the receiving side.\n\nDiagnosis involves analyzing the relationship between configured rate limits, actual endpoint capacity, and delivery timing patterns. If endpoints consistently respond successfully within acceptable timeframes but deliveries are artificially delayed by rate limiting, the configuration needs adjustment.\n\n| Bottleneck Type | Performance Impact | Detection Method | Optimization Strategy |\n|------------------|-------------------|------------------|----------------------|\n| Conservative rate limits | Artificial delivery delays | Compare endpoint response capacity with configured limits | Increase RPM limits based on endpoint testing |\n| Token bucket starvation | Burst traffic cannot be processed | Queue spikes during traffic bursts | Increase burst multiplier in `RateLimitConfig` |\n| Global rate limiting | Single endpoint limits affect others | Cross-endpoint delivery correlation | Implement per-endpoint rate limiting isolation |\n| Retry-After mishandling | Rate limit responses cause excessive delays | Extended delays after HTTP 429 responses | Implement proper Retry-After header parsing |\n\n**Resource Exhaustion Diagnosis**\n\nResource exhaustion occurs when system components run out of database connections, memory, file handles, or network sockets. This typically manifests as intermittent failures that worsen under load, rather than consistent failure patterns. The webhook delivery system is particularly susceptible because it maintains persistent connections to message queues, databases, and HTTP endpoints.\n\nDatabase connection exhaustion is the most common resource issue, occurring when the connection pool in `DatabaseManager` becomes depleted due to long-running queries, connection leaks, or insufficient pool sizing. The symptoms include database timeout errors in `DeliveryAttempt` records and growing connection counts in database monitoring tools.\n\nMemory exhaustion can occur when large webhook payloads accumulate in worker memory, especially during retry processing. The `WebhookEvent` model stores full payload content, and workers processing many large events simultaneously can exceed available memory. This leads to worker crashes and restart cycles that appear as intermittent processing failures.\n\nNetwork socket exhaustion affects HTTP delivery when workers attempt to establish more concurrent connections than the system allows. This is particularly problematic when endpoints have slow response times, causing connections to remain open longer and depleting the available socket pool.\n\n| Resource Type | Exhaustion Symptoms | Monitoring Approach | Mitigation Strategies |\n|---------------|-------------------|-------------------|----------------------|\n| Database connections | Query timeouts and connection failures | Monitor active connection counts vs pool limits | Increase pool size or optimize query performance |\n| Memory | Worker crashes and OOM errors | Track worker memory usage and payload sizes | Implement payload size limits and memory-efficient processing |\n| File handles | File operation failures | Monitor open file descriptor counts | Ensure proper file closure and increase system limits |\n| Network sockets | HTTP connection failures | Track concurrent connection counts | Implement connection pooling and timeout optimization |\n\n**Scaling Bottleneck Resolution Strategies**\n\nScaling bottlenecks require systematic analysis of component throughput limits and resource utilization patterns. The webhook delivery system has multiple potential bottlenecks: webhook registration database queries, event queuing operations, delivery processing throughput, and logging write performance.\n\nThe identification process involves load testing individual components to determine their maximum sustainable throughput. Database operations can be bottlenecked by query performance, connection pool limits, or storage I/O capacity. Queue operations may be limited by Redis memory, network bandwidth, or persistence configuration. HTTP delivery throughput depends on endpoint response times, worker concurrency, and network capacity.\n\nResolution strategies range from configuration tuning (increasing connection pools, adjusting rate limits) to architectural changes (horizontal scaling, read replicas, queue sharding). The choice depends on where bottlenecks are identified and the cost-benefit trade-offs of different approaches.\n\n### Implementation Guidance\n\n**Technology Stack for Debugging**\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Logging Framework | Python `logging` with JSON formatter | Structured logging with ELK stack |\n| Metrics Collection | Basic counters and gauges | Prometheus with Grafana dashboards |\n| Tracing | Custom correlation IDs | OpenTelemetry distributed tracing |\n| Database Monitoring | SQL query logging | Performance insights with slow query analysis |\n| Queue Monitoring | Redis INFO command | Redis monitoring with alerting |\n\n**Project Structure for Debugging Tools**\n\n```\nwebhook-system/\n├── src/webhook_delivery/\n│   ├── debugging/\n│   │   ├── __init__.py\n│   │   ├── queue_analyzer.py          ← Queue backlog analysis tools\n│   │   ├── delivery_tracer.py         ← Delivery attempt correlation\n│   │   ├── signature_validator.py     ← HMAC verification testing\n│   │   └── performance_profiler.py    ← Resource usage analysis\n│   ├── monitoring/\n│   │   ├── metrics_collector.py       ← System health metrics\n│   │   ├── alerting.py                ← Threshold-based alerts\n│   │   └── dashboard_data.py          ← Metrics aggregation for dashboards\n│   └── tools/\n│       ├── debug_cli.py               ← Command-line debugging interface\n│       ├── replay_analyzer.py         ← Event replay debugging\n│       └── config_validator.py        ← Configuration validation\n```\n\n**Queue Analyzer Infrastructure**\n\n```python\nimport redis\nimport json\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass\n\n@dataclass\nclass QueueHealth:\n    webhook_id: str\n    queue_depth: int\n    oldest_event_age: float\n    processing_rate: float\n    last_successful_delivery: Optional[datetime]\n    circuit_state: str\n    rate_limit_tokens: int\n\nclass QueueAnalyzer:\n    \"\"\"Comprehensive queue health analysis and bottleneck detection.\"\"\"\n    \n    def __init__(self, redis_client: redis.Redis, db_manager):\n        self.redis = redis_client\n        self.db = db_manager\n        self.analysis_window = timedelta(hours=1)\n    \n    def analyze_queue_health(self, webhook_id: str) -> QueueHealth:\n        \"\"\"Analyze queue health for a specific webhook endpoint.\"\"\"\n        # TODO: Get queue depth from Redis stream length\n        # TODO: Find oldest pending event timestamp\n        # TODO: Calculate processing rate from recent delivery attempts\n        # TODO: Get last successful delivery from DeliveryAttempt table\n        # TODO: Check current circuit breaker state\n        # TODO: Get available rate limit tokens\n        pass\n    \n    def detect_stuck_queues(self) -> List[Tuple[str, str]]:\n        \"\"\"Detect queues with events but no processing activity.\"\"\"\n        # TODO: Scan all webhook streams in Redis\n        # TODO: Compare queue depths with recent delivery activity\n        # TODO: Identify queues with events older than threshold\n        # TODO: Return list of (webhook_id, reason) tuples\n        pass\n    \n    def diagnose_delivery_failures(self, webhook_id: str, hours: int = 24) -> Dict:\n        \"\"\"Analyze delivery failure patterns for debugging.\"\"\"\n        # TODO: Query DeliveryAttempt records for time window\n        # TODO: Group failures by status code and error message\n        # TODO: Identify retry loop patterns\n        # TODO: Calculate failure progression rates\n        # TODO: Return diagnostic summary with recommendations\n        pass\n```\n\n**Signature Verification Testing Tools**\n\n```python\nimport hmac\nimport hashlib\nimport json\nimport time\nfrom typing import Dict, Any, Tuple\n\nclass SignatureDebugger:\n    \"\"\"Tools for debugging HMAC signature verification issues.\"\"\"\n    \n    def __init__(self):\n        self.timestamp_tolerance = 300  # 5 minutes\n    \n    def generate_test_signature(self, payload: Dict[Any, Any], secret: str, \n                              timestamp: Optional[int] = None) -> Tuple[str, str]:\n        \"\"\"Generate HMAC signature with debugging information.\"\"\"\n        # TODO: Convert payload to canonical JSON string\n        # TODO: Create signing string with timestamp and metadata\n        # TODO: Generate HMAC-SHA256 signature\n        # TODO: Return signature and canonical payload for comparison\n        pass\n    \n    def verify_signature_step_by_step(self, payload: str, signature: str, \n                                    secret: str, timestamp: int) -> Dict[str, Any]:\n        \"\"\"Step-by-step signature verification with detailed diagnostics.\"\"\"\n        # TODO: Parse signature components (timestamp, hash)\n        # TODO: Validate timestamp against tolerance window\n        # TODO: Reproduce signing string exactly\n        # TODO: Calculate expected HMAC and compare\n        # TODO: Return detailed verification report\n        pass\n    \n    def diagnose_verification_failure(self, delivery_attempt_id: str) -> Dict[str, Any]:\n        \"\"\"Analyze why signature verification might have failed.\"\"\"\n        # TODO: Retrieve delivery attempt details from database\n        # TODO: Get webhook secret that was used for signing\n        # TODO: Reproduce signature generation process\n        # TODO: Identify potential mismatch sources\n        # TODO: Return diagnostic report with recommendations\n        pass\n```\n\n**Performance Monitoring Core Logic**\n\n```python\nimport psutil\nimport time\nfrom collections import deque\nfrom typing import Dict, List, Optional\nfrom datetime import datetime, timedelta\n\nclass PerformanceProfiler:\n    \"\"\"System resource monitoring and bottleneck detection.\"\"\"\n    \n    def __init__(self, sample_interval: int = 60):\n        self.sample_interval = sample_interval\n        self.metrics_history = deque(maxlen=1440)  # 24 hours of samples\n        self.alert_thresholds = {\n            'cpu_percent': 80,\n            'memory_percent': 85,\n            'db_connections': 80,  # % of pool\n            'queue_depth': 1000,\n            'delivery_latency': 30.0  # seconds\n        }\n    \n    def collect_system_metrics(self) -> Dict[str, float]:\n        \"\"\"Collect comprehensive system performance metrics.\"\"\"\n        # TODO: Get CPU usage percentage\n        # TODO: Get memory usage percentage  \n        # TODO: Count active database connections\n        # TODO: Sum queue depths across all webhooks\n        # TODO: Calculate average delivery latency\n        # TODO: Return metrics dictionary\n        pass\n    \n    def detect_resource_exhaustion(self) -> List[Dict[str, Any]]:\n        \"\"\"Detect resource exhaustion patterns and bottlenecks.\"\"\"\n        # TODO: Analyze metrics trends over time window\n        # TODO: Identify metrics exceeding alert thresholds\n        # TODO: Correlate resource usage with delivery performance\n        # TODO: Return list of detected issues with severity\n        pass\n    \n    def diagnose_scaling_bottlenecks(self) -> Dict[str, Any]:\n        \"\"\"Identify system components limiting throughput scaling.\"\"\"\n        # TODO: Analyze component throughput vs resource utilization\n        # TODO: Identify components with highest resource consumption\n        # TODO: Calculate theoretical maximum throughput per component\n        # TODO: Return bottleneck analysis with scaling recommendations\n        pass\n```\n\n**Debugging Command Line Interface**\n\n```python\nimport click\nfrom webhook_delivery.debugging.queue_analyzer import QueueAnalyzer\nfrom webhook_delivery.debugging.signature_validator import SignatureDebugger\nfrom webhook_delivery.debugging.performance_profiler import PerformanceProfiler\n\n@click.group()\ndef debug_cli():\n    \"\"\"Webhook delivery system debugging tools.\"\"\"\n    pass\n\n@debug_cli.command()\n@click.argument('webhook_id')\ndef analyze_queue(webhook_id: str):\n    \"\"\"Analyze queue health for a specific webhook.\"\"\"\n    # TODO: Initialize QueueAnalyzer with Redis connection\n    # TODO: Run queue health analysis\n    # TODO: Display formatted results with recommendations\n    pass\n\n@debug_cli.command()\n@click.argument('delivery_attempt_id') \ndef debug_signature(delivery_attempt_id: str):\n    \"\"\"Debug HMAC signature verification failure.\"\"\"\n    # TODO: Initialize SignatureDebugger\n    # TODO: Run verification failure diagnosis\n    # TODO: Display step-by-step verification process\n    pass\n\n@debug_cli.command()\ndef system_health():\n    \"\"\"Check overall system health and performance.\"\"\"\n    # TODO: Initialize PerformanceProfiler\n    # TODO: Collect current metrics\n    # TODO: Run bottleneck detection\n    # TODO: Display health summary with alerts\n    pass\n\nif __name__ == '__main__':\n    debug_cli()\n```\n\n**Language-Specific Implementation Notes**\n\nFor Python webhook delivery debugging:\n- Use `logging.getLogger(__name__)` with structured JSON formatters for consistent log correlation\n- Leverage `redis-py` XINFO and XPENDING commands for detailed queue analysis\n- Use `psutil` library for comprehensive system resource monitoring\n- Implement custom exception classes for different failure modes to enable specific error handling\n- Use `dataclasses` for structured debugging output that's easy to serialize and analyze\n\n**Milestone Debugging Checkpoints**\n\nAfter implementing each milestone, use these debugging validation steps:\n\n**Milestone 1 Debugging Checkpoint:**\n- Generate test webhook with known secret and verify signature creation matches expected HMAC\n- Test signature verification failure by modifying payload and confirm proper error reporting\n- Validate URL security checks by attempting registration with private IP addresses\n- Verify challenge-response ownership validation handles network timeouts gracefully\n\n**Milestone 2 Debugging Checkpoint:**  \n- Simulate network failures during delivery and verify exponential backoff timing\n- Test queue processing by monitoring Redis streams during worker startup and shutdown\n- Validate dead letter queue behavior by exhausting retry attempts on unreachable endpoint\n- Confirm retry loop prevention by checking attempt limits are respected\n\n**Milestone 3 Debugging Checkpoint:**\n- Trigger circuit breaker by simulating consecutive endpoint failures and verify state transitions\n- Test rate limiting by sending bursts above configured limits and measuring actual delivery rates  \n- Validate Retry-After header handling by returning HTTP 429 responses with delay instructions\n- Confirm circuit recovery by fixing failing endpoint and observing automatic state restoration\n\n**Milestone 4 Debugging Checkpoint:**\n- Verify delivery logs capture complete request/response data for failed deliveries\n- Test event replay functionality with deduplication headers to prevent duplicate processing\n- Validate log retention policies by checking automatic archival of old delivery records\n- Confirm debugging tools can correlate events across multiple system components\n\n⚠️ **Common Debugging Pitfalls**\n\n⚠️ **Pitfall: Correlation ID Missing**\nMany debugging sessions fail because events cannot be correlated across system components. Each webhook event should have a unique correlation ID that appears in queue messages, delivery attempts, and log entries. Without this, debugging distributed failures becomes nearly impossible.\n\n⚠️ **Pitfall: Insufficient Error Context**  \nGeneric error messages like \"delivery failed\" provide no debugging value. Each failure should capture the complete context: endpoint URL, HTTP status code, response headers, response body, network timing, and retry attempt number. This context is essential for root cause analysis.\n\n⚠️ **Pitfall: Clock Synchronization Ignored**\nTimestamp-based debugging assumes synchronized system clocks across components. Clock drift can make retry timing appear incorrect, signature verification seem random, and event ordering look corrupted. Always verify system clock synchronization before debugging timing-related issues.\n\n⚠️ **Pitfall: Production Debugging Without Safety**\nRunning debugging tools in production can impact performance or expose sensitive data. Always implement rate limiting, data sanitization, and read-only access controls in debugging interfaces. Never run performance profiling tools continuously in production without proper resource limits.\n\n\n## Future Extensions and Scalability\n\n> **Milestone(s):** Post-delivery advanced features - builds upon all completed milestones (1-4) to provide enterprise-grade capabilities including conditional delivery, comprehensive analytics, and horizontal scaling architecture\n\nThe webhook delivery system we've designed through the four core milestones provides a solid foundation for reliable event delivery with security, fault tolerance, and observability. However, as organizations scale their webhook infrastructure and adopt more sophisticated integration patterns, additional capabilities become essential. This section explores advanced features and architectural evolution paths that transform our system from a reliable webhook delivery service into a comprehensive event distribution platform.\n\nThink of this evolution like transforming a neighborhood postal service into a global logistics network. While the fundamental concepts of addressing, delivery, and tracking remain the same, the scale and sophistication of operations require new capabilities: conditional routing based on package contents, real-time visibility into delivery performance across regions, predictive analytics to prevent service disruptions, and distributed coordination mechanisms to handle traffic volumes that would overwhelm a single processing center.\n\nThe extensions we'll explore fall into three categories: advanced delivery features that add intelligence and geographic distribution to our delivery logic, enhanced monitoring and analytics that provide deep visibility into system behavior and customer experience, and horizontal scaling considerations that enable the system to handle enterprise-scale traffic across multiple geographic regions. Each category builds upon the foundational components we've established while introducing new architectural patterns and operational complexities.\n\n### Advanced Delivery Features\n\nModern webhook consumers often require more sophisticated delivery semantics than simple fire-and-forget HTTP requests. Organizations need conditional delivery based on event content, payload transformation to match diverse consumer formats, and multi-region deployment for reduced latency and compliance with data sovereignty requirements. These features transform our delivery engine from a simple HTTP dispatcher into an intelligent event router and transformer.\n\n#### Conditional Delivery Logic\n\n**Mental Model: Smart Mail Filtering**\nImagine a postal service where mail carriers can read package labels and apply complex routing rules: \"If this package is marked 'urgent' and the recipient is in the downtown district, deliver immediately. If it's a routine document for a residential address, batch it with other deliveries for efficiency.\" Conditional delivery applies similar intelligence to webhook events, allowing fine-grained control over when and how events reach their destinations.\n\nTraditional webhook systems deliver every subscribed event to every registered endpoint, leaving filtering and relevance decisions to the consumer. This creates unnecessary network traffic, processing overhead, and potential security exposure when sensitive events are delivered to endpoints that shouldn't receive them. Conditional delivery moves this intelligence into the delivery system itself.\n\n> **Decision: Event Filtering Architecture**\n> - **Context**: Organizations need to filter webhook deliveries based on event content, recipient characteristics, or external conditions without modifying every consuming application\n> - **Options Considered**: \n>   1. Consumer-side filtering (current approach)\n>   2. Static subscription filters at registration time  \n>   3. Dynamic filtering with expression evaluation engine\n> - **Decision**: Implement dynamic filtering with expression evaluation engine\n> - **Rationale**: Provides maximum flexibility while reducing network overhead and improving security by preventing delivery of irrelevant or sensitive events\n> - **Consequences**: Adds complexity to delivery pipeline but enables sophisticated routing patterns and reduces downstream processing burden\n\nThe conditional delivery system extends our `WebhookRegistration` model with filter expressions that are evaluated against each event before delivery decisions:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `filter_expression` | `str` | JSONPath or CEL expression defining delivery conditions |\n| `filter_version` | `int` | Schema version for backward compatibility during filter evolution |\n| `filter_variables` | `json` | External variables available during filter evaluation |\n| `delivery_conditions` | `json` | Complex conditions including time windows, rate limits per filter match |\n| `content_requirements` | `json` | Required fields or patterns in event payload for delivery eligibility |\n\nThe filter evaluation process integrates into our delivery queue logic before events are scheduled for HTTP delivery:\n\n1. **Event Ingestion Enhancement**: When events are queued for delivery, the `QueueManager` evaluates filter expressions for each subscribed webhook endpoint\n2. **Expression Evaluation**: The system supports JSONPath expressions for simple field matching and Common Expression Language (CEL) for complex logical conditions\n3. **Context Enrichment**: Filter expressions have access to event payload, metadata, webhook configuration, and external context variables\n4. **Performance Optimization**: Frequently evaluated filters are cached in Redis with invalidation on webhook configuration changes\n5. **Audit Logging**: All filter evaluations are logged to support debugging and compliance requirements\n\nConsider a financial services platform that sends transaction events to multiple downstream systems. The fraud detection system only needs high-value transactions, while the analytics platform wants all transactions but only during business hours. The loyalty program service needs transactions from retail merchants but excludes internal transfers:\n\n- **Fraud Detection Filter**: `event.transaction.amount > 10000 || event.transaction.risk_score > 0.7`\n- **Analytics Filter**: `hour(now()) >= 9 && hour(now()) <= 17 && weekday(now()) <= 5`\n- **Loyalty Program Filter**: `event.merchant.category == 'retail' && !event.transaction.internal`\n\n#### Payload Transformation Pipeline\n\n**Mental Model: Universal Package Converter**\nThink of payload transformation like a package conversion center at an international shipping hub. Packages arrive in various sizes and formats, but each destination country has specific requirements: different labeling standards, customs declarations, packaging materials. The conversion center automatically reformats packages to match destination requirements while preserving the original contents.\n\nModern organizations often need to integrate systems with different data formats, field naming conventions, or payload structures. Rather than requiring each webhook consumer to implement transformation logic, the delivery system can handle these conversions centrally, reducing integration complexity and ensuring consistent data formats.\n\n> **Decision: Transformation Engine Architecture**\n> - **Context**: Webhook consumers often require different payload formats, field mappings, or data enrichment from the original event structure\n> - **Options Considered**:\n>   1. Consumer-side transformation (current approach)\n>   2. Static field mapping configuration\n>   3. Template-based transformation with scripting support\n> - **Decision**: Implement template-based transformation with scripting support using JSONata or JavaScript expressions\n> - **Rationale**: Balances flexibility with performance and security, enabling complex transformations while maintaining deterministic behavior\n> - **Consequences**: Requires transformation engine infrastructure but dramatically reduces consumer-side integration complexity\n\nThe transformation system extends webhook configurations with transformation templates and enrichment rules:\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `transformation_template` | `str` | JSONata template or JavaScript function for payload transformation |\n| `enrichment_sources` | `json` | External data sources for payload enrichment during transformation |\n| `field_mappings` | `json` | Simple field rename and type conversion rules |\n| `output_format` | `str` | Target format: JSON, XML, form-encoded, or custom |\n| `transformation_version` | `int` | Template version for A/B testing and gradual rollout |\n\nThe transformation pipeline operates between filter evaluation and HTTP delivery:\n\n1. **Template Compilation**: Transformation templates are compiled and cached on webhook registration or update\n2. **Context Preparation**: The original event payload, metadata, and enrichment data are prepared for template execution\n3. **Safe Execution**: Templates execute in sandboxed environments with resource limits and timeout protection\n4. **Format Conversion**: Transformed data is serialized to the target format specified in webhook configuration\n5. **Validation**: Transformed payloads are validated against optional JSON schemas before delivery\n6. **Fallback Handling**: If transformation fails, the system can deliver the original payload or skip delivery based on webhook configuration\n\nExample transformations demonstrate the system's flexibility:\n\n**Legacy System Integration**: A legacy CRM system expects customer data in XML format with specific field names:\n```\nOriginal Event: {\"customer\": {\"id\": 123, \"email\": \"user@example.com\", \"created_at\": \"2023-10-15T10:30:00Z\"}}\n\nTransformation Template:\n{\n  \"CustomerRecord\": {\n    \"ID\": customer.id,\n    \"EmailAddress\": customer.email,\n    \"RegistrationDate\": $formatDate(customer.created_at, \"MM/DD/YYYY\")\n  }\n}\n\nOutput Format: XML\n```\n\n**Data Enrichment**: An analytics system needs customer events enriched with account tier and geographic information:\n```\nEnrichment Sources: \n- customer_service: /api/customers/{customer.id}/details\n- geo_service: /api/lookup/country/{customer.ip_address}\n\nTemplate:\nevent ~> |$| { \n  \"customer_tier\": $lookup(\"customer_service\").tier,\n  \"country\": $lookup(\"geo_service\").country_code,\n  \"enriched_at\": $now()\n}|\n```\n\n#### Multi-Region Deployment Architecture\n\n**Mental Model: Global Distribution Network**\nConsider how global shipping companies operate: they maintain regional distribution centers connected by coordinated logistics networks. A package shipped from New York to Tokyo doesn't travel directly - it moves through regional hubs that handle local delivery while maintaining global tracking and coordination. Multi-region webhook deployment follows similar principles.\n\nOrganizations with global operations need webhook delivery systems that can handle events and deliver to endpoints across multiple geographic regions while maintaining consistency, compliance with data sovereignty requirements, and optimal performance through reduced latency.\n\n> **Decision: Multi-Region Architecture Pattern**\n> - **Context**: Global organizations need webhook delivery with regional compliance, reduced latency, and disaster recovery capabilities\n> - **Options Considered**:\n>   1. Single global deployment with geographic load balancing\n>   2. Independent regional deployments with manual coordination\n>   3. Federated architecture with regional autonomy and global coordination\n> - **Decision**: Implement federated architecture with regional webhook delivery clusters and global state coordination\n> - **Rationale**: Balances performance, compliance, and operational complexity while enabling true disaster recovery and data sovereignty compliance\n> - **Consequences**: Requires sophisticated coordination mechanisms but provides best-in-class performance and compliance capabilities\n\nThe multi-region architecture introduces several new components and extends existing ones for global operation:\n\n| Component | Regional Responsibility | Global Responsibility |\n|-----------|------------------------|---------------------|\n| `RegionalDeliveryCluster` | Event delivery within region, circuit breaker state, rate limiting | Global webhook registration, cross-region event routing |\n| `GlobalWebhookRegistry` | Regional webhook cache, ownership verification | Master webhook configuration, secret rotation coordination |\n| `EventRouter` | Regional event processing, local delivery queues | Cross-region event routing, compliance rule enforcement |\n| `ConsensusManager` | Regional coordinator node, health reporting | Global configuration consensus, leader election across regions |\n| `ComplianceEngine` | Regional data residency enforcement | Global compliance policy management, audit trail consolidation |\n\nThe federated deployment model operates through coordinated regional clusters:\n\n1. **Regional Cluster Architecture**: Each geographic region operates a complete webhook delivery system with its own delivery queues, circuit breakers, and event logs\n2. **Global State Synchronization**: Webhook registrations, configurations, and policy updates are synchronized across regions using distributed consensus protocols\n3. **Event Routing Intelligence**: Events are routed to the appropriate regional cluster based on webhook endpoint location, compliance requirements, and performance optimization\n4. **Cross-Region Failover**: If a regional cluster becomes unavailable, events can be rerouted to secondary regions with appropriate compliance validation\n5. **Consolidated Monitoring**: Global dashboards provide unified visibility into delivery performance and system health across all regions\n\n**Data Sovereignty and Compliance Handling**\nThe multi-region system enforces data sovereignty requirements through policy-based event routing:\n\n| Policy Type | Description | Enforcement Mechanism |\n|-------------|-------------|----------------------|\n| `data_residency` | Events containing personal data must be processed in specific regions | Geographic event routing with payload analysis |\n| `cross_border_restrictions` | Certain event types cannot cross national boundaries | Compliance tags on events with routing validation |\n| `encryption_requirements` | Events in specific regions require enhanced encryption | Regional encryption key management and payload protection |\n| `audit_retention` | Different regions have varying audit log retention requirements | Regional audit policy enforcement with legal hold support |\n\n### Enhanced Monitoring and Analytics\n\nAs webhook delivery systems mature from basic operational tools to critical business infrastructure, organizations require sophisticated monitoring and analytics capabilities that go beyond simple delivery success rates. Enhanced monitoring provides deep visibility into system behavior, customer experience, and business impact through comprehensive metrics, predictive analytics, and intelligent alerting.\n\n#### Comprehensive Metrics Dashboard\n\n**Mental Model: Air Traffic Control Center**\nThink of enhanced monitoring like an air traffic control center managing a busy metropolitan airport. Controllers need real-time visibility into every aircraft's position, speed, and destination, but they also need predictive analytics to anticipate congestion, weather impact analysis, and historical pattern recognition to optimize flight scheduling. Similarly, webhook monitoring requires both real-time operational metrics and analytical insights that enable proactive system management.\n\nTraditional webhook monitoring focuses on basic delivery metrics: success rates, error counts, and response times. Enhanced monitoring expands this to provide comprehensive visibility into system performance, customer experience, and business impact through multidimensional metrics collection and analysis.\n\nThe enhanced metrics system extends our existing monitoring infrastructure with comprehensive data collection and analysis capabilities:\n\n| Metric Category | Key Metrics | Analysis Dimensions |\n|----------------|-------------|-------------------|\n| `delivery_performance` | Success rate, P50/P95/P99 latency, throughput per endpoint | Time windows, geographic region, event type, endpoint characteristics |\n| `customer_experience` | End-to-end delivery time, retry frequency, circuit breaker activations | Customer segments, integration patterns, business criticality |\n| `system_health` | Queue depth, worker utilization, database performance, memory usage | Component-level detail, resource allocation, scaling efficiency |\n| `business_impact` | Revenue-critical event delivery, SLA compliance, customer satisfaction | Business unit correlation, cost attribution, ROI analysis |\n| `security_metrics` | Authentication failures, SSRF attempts, rate limiting activations | Attack pattern analysis, geographic threat distribution |\n\n**Real-Time Dashboard Architecture**\nThe metrics dashboard provides multiple views optimized for different stakeholders and operational scenarios:\n\n1. **Operations Dashboard**: Real-time system health with immediate alerting for operational issues\n2. **Customer Success Dashboard**: Customer-facing delivery performance metrics with SLA tracking\n3. **Engineering Dashboard**: Deep technical metrics for system optimization and capacity planning\n4. **Business Dashboard**: Business impact metrics connecting webhook performance to revenue and customer satisfaction\n5. **Security Dashboard**: Security event monitoring with threat detection and response coordination\n\nThe dashboard implementation leverages time-series databases optimized for high-volume metrics ingestion and real-time querying:\n\n| Component | Technology Choice | Responsibility |\n|-----------|------------------|----------------|\n| `MetricsCollector` | StatsD with Prometheus exposition | High-frequency metric collection from all system components |\n| `TimeSeriesDatabase` | InfluxDB or Prometheus with long-term storage | Efficient storage and querying of metric time series |\n| `DashboardEngine` | Grafana with custom panels | Real-time visualization and alerting based on metric thresholds |\n| `AnalyticsProcessor` | Apache Spark for batch processing | Complex analytical queries and trend analysis |\n\n#### SLA Tracking and Customer Health Scoring\n\n**Mental Model: Customer Health Monitoring**\nConsider how a healthcare monitoring system tracks patient vital signs: it doesn't just record individual measurements, but analyzes patterns, trends, and correlations to provide an overall health score. It can predict potential issues before they become critical and alert medical staff when intervention is needed. SLA tracking and customer health scoring applies similar principles to webhook delivery performance.\n\nOrganizations using webhook delivery systems need to monitor not just technical performance metrics, but the overall health of their customer integrations. This includes SLA compliance tracking, customer experience scoring, and predictive analytics that identify potential integration issues before they impact business operations.\n\nThe SLA tracking system extends our monitoring infrastructure with customer-centric health metrics:\n\n| Health Metric | Calculation Method | Business Impact |\n|---------------|-------------------|-----------------|\n| `integration_health_score` | Weighted average of delivery success, latency, and error patterns | Overall integration reliability from customer perspective |\n| `sla_compliance_percentage` | Percentage of events delivered within SLA commitments | Direct customer satisfaction and contract compliance measurement |\n| `customer_experience_index` | Complex score incorporating retry frequency, circuit breaker activations, support tickets | Predictive indicator of customer satisfaction and churn risk |\n| `business_criticality_factor` | Revenue-weighted delivery performance for high-value events | Business impact prioritization for operational decision making |\n\n**Predictive Health Analytics**\nThe system employs machine learning models to predict customer health trends and proactively identify integration issues:\n\n1. **Delivery Pattern Analysis**: Identifies unusual patterns in delivery timing, frequency, or success rates that may indicate integration problems\n2. **Endpoint Health Prediction**: Uses historical data to predict when endpoints are likely to experience issues, enabling proactive support\n3. **Resource Utilization Forecasting**: Predicts system resource requirements based on customer growth patterns and event volume trends\n4. **Churn Risk Assessment**: Correlates delivery performance with customer satisfaction metrics to identify at-risk customer integrations\n\nConsider how the health scoring system operates for a typical enterprise customer:\n\n**Customer: E-commerce Platform**\n- **Integration Health Score**: 94/100 (Excellent)\n  - Delivery Success Rate: 99.8% (weight: 40%)\n  - Average Delivery Latency: 150ms (weight: 30%)\n  - Circuit Breaker Activations: 1 in last 30 days (weight: 20%)\n  - Error Pattern Consistency: Low variance (weight: 10%)\n\n- **SLA Compliance**: 98.5% (Target: 99.0%)\n  - Events delivered within 500ms: 98.2%\n  - Events delivered within 5 seconds: 99.9%\n  - Monthly downtime: 23 minutes (Target: 14.4 minutes)\n\n- **Predictive Alerts**: \n  - Warning: Endpoint response time trending upward (investigate)\n  - Info: Traffic volume 15% above historical average (capacity planning)\n\n#### Predictive Analytics and Alerting\n\n**Mental Model: Weather Forecasting System**\nThink of predictive analytics like an advanced weather forecasting system that doesn't just report current conditions, but uses atmospheric models, historical patterns, and real-time sensor data to predict storms, temperature changes, and severe weather events days in advance. This enables people to prepare and take preventive action rather than simply reacting to problems as they occur.\n\nTraditional monitoring systems are reactive - they alert when problems have already occurred. Predictive analytics transforms this into proactive system management by identifying trends, patterns, and early warning signals that indicate potential issues before they impact service delivery.\n\n> **Decision: Predictive Analytics Architecture**\n> - **Context**: Traditional reactive monitoring cannot prevent service disruptions or optimize system performance proactively\n> - **Options Considered**:\n>   1. Rule-based threshold alerting (current approach)\n>   2. Statistical anomaly detection with fixed baselines\n>   3. Machine learning-based predictive analytics with dynamic baselines\n> - **Decision**: Implement ML-based predictive analytics with multiple prediction models and ensemble methods\n> - **Rationale**: Provides most accurate predictions and adapts to changing system behavior patterns over time\n> - **Consequences**: Requires ML infrastructure and expertise but enables proactive system management and improved reliability\n\nThe predictive analytics system operates through multiple specialized prediction models:\n\n| Prediction Model | Purpose | Input Data | Prediction Horizon |\n|-----------------|---------|------------|-------------------|\n| `DeliveryFailurePrediction` | Predict endpoint failures before they occur | Response times, error rates, external monitoring | 15 minutes to 4 hours |\n| `CapacityDemandForecasting` | Predict resource requirements for scaling decisions | Event volume, customer growth, seasonal patterns | 1 hour to 30 days |\n| `SecurityThreatDetection` | Identify potential security attacks or abuse | Request patterns, IP geolocation, payload analysis | Real-time to 24 hours |\n| `CustomerChurnRiskAssessment` | Predict customer integration health and satisfaction | Delivery performance, support interactions, usage patterns | 7 to 90 days |\n\n**Intelligent Alerting System**\nThe alerting system uses predictive insights to generate actionable alerts with context and recommended actions:\n\n1. **Anomaly Detection**: Statistical models identify unusual patterns in system metrics that may indicate emerging issues\n2. **Trend Analysis**: Long-term trend analysis identifies gradual degradation that might not trigger threshold-based alerts\n3. **Correlation Analysis**: Multi-dimensional correlation analysis identifies relationships between seemingly unrelated metrics\n4. **Impact Assessment**: Alerts include predicted business impact and recommended response priority\n5. **Action Recommendations**: Alerts include specific recommended actions based on historical resolution patterns\n\n**Example Predictive Alert Scenarios:**\n\n**Scenario 1: Endpoint Degradation Prediction**\n```\nAlert: Predicted Endpoint Failure\nSeverity: Warning\nWebhook: customer-orders.retailco.com\nPrediction: 78% probability of circuit breaker activation within 2 hours\nEvidence: \n- Response time increased 40% over last 30 minutes\n- Error rate trending from 0.1% to 1.2%\n- Similar pattern preceded last outage on 2023-09-15\nRecommended Actions:\n1. Contact customer technical team\n2. Prepare traffic rerouting to backup endpoint\n3. Monitor customer infrastructure status page\nBusiness Impact: $12,000 revenue exposure if prediction accurate\n```\n\n**Scenario 2: Capacity Scaling Prediction**\n```\nAlert: Capacity Planning Required\nSeverity: Info\nComponent: Delivery Workers (US-East-1)\nPrediction: 90% worker utilization expected within 6 hours\nEvidence:\n- Event volume up 25% week-over-week\n- Current utilization at 68% with growing queue depth\n- Historical pattern matches Black Friday traffic surge\nRecommended Actions:\n1. Scale worker pool from 10 to 15 instances\n2. Pre-warm additional Redis connection pools\n3. Notify on-call team of expected traffic surge\nCost Impact: $48/hour additional infrastructure cost\n```\n\n### Horizontal Scaling Considerations\n\nAs webhook delivery systems grow from handling thousands of events per day to millions of events per hour, the architectural patterns that worked for single-instance deployments become bottlenecks. Horizontal scaling requires fundamental changes to how we think about state management, work coordination, and system boundaries. This involves transforming our component-based architecture into a distributed system with multiple coordinating instances.\n\n#### Sharding Strategies for Event Distribution\n\n**Mental Model: Postal Service Hub System**\nThink of horizontal scaling like transforming a single post office into a network of regional distribution hubs. Mail cannot be processed randomly by any hub - specific routing rules determine which hub handles mail for which geographic areas or postal codes. However, all hubs must coordinate to ensure mail tracking works globally and packages can be rerouted if one hub becomes unavailable.\n\nTraditional webhook delivery systems process all events through a single queue or processing pipeline. Horizontal scaling requires partitioning the event space across multiple processing instances while maintaining consistency guarantees and enabling coordination for cross-partition operations.\n\n> **Decision: Event Sharding Strategy**\n> - **Context**: Single-instance processing cannot handle enterprise-scale event volumes or provide geographic distribution\n> - **Options Considered**:\n>   1. Random distribution across workers (no sharding)\n>   2. Webhook endpoint-based sharding for processing locality\n>   3. Hybrid sharding with event type and customer-based partitioning\n> - **Decision**: Implement webhook endpoint-based sharding with customer affinity and failover capability\n> - **Rationale**: Provides processing locality, maintains ordering guarantees per endpoint, and enables customer-specific scaling while supporting automatic failover\n> - **Consequences**: Requires partition rebalancing logic but provides optimal performance and consistency characteristics\n\nThe sharding system divides the webhook delivery workload across multiple processing instances while maintaining strong consistency guarantees:\n\n| Sharding Dimension | Strategy | Benefits | Challenges |\n|-------------------|----------|----------|------------|\n| `webhook_endpoint` | Hash-based partitioning on webhook URL | Processing locality, ordering guarantees | Uneven distribution if customer sizes vary |\n| `customer_tenant` | Customer-based partition assignment | Resource isolation, billing accuracy | Complex rebalancing when customers grow |\n| `geographic_region` | Event source location-based routing | Compliance, latency optimization | Cross-region coordination complexity |\n| `event_priority` | High/normal priority separate processing | SLA differentiation, resource allocation | Additional infrastructure complexity |\n\n**Partition Assignment and Rebalancing**\nThe sharding system uses consistent hashing with virtual nodes to distribute webhook endpoints across processing instances:\n\n1. **Hash Ring Construction**: Webhook endpoints are assigned to partitions using SHA-256 hash of the URL, creating uniform distribution\n2. **Virtual Node Mapping**: Each physical processing instance handles multiple virtual partitions, enabling fine-grained rebalancing\n3. **Partition Assignment**: New instances claim partitions from the hash ring, while failing instances trigger automatic reassignment\n4. **Rebalancing Algorithm**: Gradual partition migration maintains system availability during topology changes\n5. **Consistency Maintenance**: Partition ownership is managed through distributed consensus to prevent split-brain scenarios\n\nConsider how partition assignment works for a system with 1000 webhook endpoints distributed across 5 processing instances:\n\n**Initial Distribution:**\n- Instance 1: Partitions 0-199 (webhooks with hash values 0x0000-0x3333)\n- Instance 2: Partitions 200-399 (webhooks with hash values 0x3334-0x6666)\n- Instance 3: Partitions 400-599 (webhooks with hash values 0x6667-0x9999)\n- Instance 4: Partitions 600-799 (webhooks with hash values 0x999A-0xCCCC)\n- Instance 5: Partitions 800-999 (webhooks with hash values 0xCCCD-0xFFFF)\n\n**After Instance 6 Joins:**\nThe system gradually reassigns partitions to achieve uniform distribution across 6 instances, with each instance handling approximately 167 partitions.\n\n#### Distributed Circuit Breaker Coordination\n\n**Mental Model: Traffic Control Network**\nImagine a city-wide traffic management system where multiple traffic control centers manage different districts, but they must coordinate to handle major incidents. If a highway bridge fails, all control centers need to know immediately so they can reroute traffic appropriately. However, day-to-day traffic decisions can be made locally without consulting other centers.\n\nIn a distributed webhook delivery system, circuit breaker decisions must be coordinated across instances while avoiding the performance bottlenecks and single points of failure that would result from centralized state management.\n\nTraditional circuit breakers maintain state in local memory within a single process instance. Distributed systems require circuit breaker state that can be shared across instances while providing fast local decision-making and coordinated failure detection.\n\n> **Decision: Distributed Circuit Breaker Architecture**\n> - **Context**: Circuit breaker decisions must be coordinated across multiple processing instances to prevent overwhelming failing endpoints\n> - **Options Considered**:\n>   1. Centralized circuit breaker state in shared database\n>   2. Eventually consistent circuit breaker state with local caching\n>   3. Hybrid approach with local decisions and global coordination\n> - **Decision**: Implement hybrid architecture with local circuit breakers and global state synchronization\n> - **Rationale**: Provides fast local decisions while ensuring global coordination, balancing performance with consistency\n> - **Consequences**: Requires sophisticated state synchronization but provides optimal performance and reliability characteristics\n\nThe distributed circuit breaker system maintains both local and global state for optimal decision-making:\n\n| State Layer | Responsibility | Update Frequency | Consistency Model |\n|-------------|----------------|------------------|-------------------|\n| `LocalCircuitState` | Fast delivery decisions, immediate failure recording | Every delivery attempt | Strongly consistent within instance |\n| `GlobalCircuitState` | Cross-instance coordination, authoritative failure counts | Every 10-30 seconds | Eventually consistent across instances |\n| `CircuitEventLog` | Audit trail, coordination events, manual overrides | Every state transition | Strong consistency via distributed log |\n\n**Coordination Protocol**\nThe distributed circuit breaker operates through a hierarchical coordination protocol:\n\n1. **Local Decision Making**: Each processing instance maintains local circuit breaker state for fast delivery decisions\n2. **Failure Aggregation**: Local failures are aggregated and periodically synchronized to global state storage\n3. **Global State Propagation**: Circuit breaker state changes are propagated to all instances through pub/sub messaging\n4. **Coordination Events**: Major state transitions (circuit opening/closing) trigger immediate coordination events\n5. **Conflict Resolution**: Conflicting circuit breaker states are resolved using timestamp-based last-writer-wins with manual override capability\n\nConsider how the distributed circuit breaker handles a webhook endpoint failure scenario:\n\n**Initial State**: All instances show webhook endpoint `api.customer.com` in CLOSED state with 2/5 failure count\n\n**Failure Cascade**:\n1. **T+0**: Instance 3 experiences 3 consecutive failures, local count reaches 5/5, circuit opens locally\n2. **T+5s**: Instance 3 publishes circuit state change to global coordination channel\n3. **T+7s**: Instances 1, 2, 4, 5 receive state update and open their local circuit breakers\n4. **T+30s**: Global state storage is updated with authoritative circuit state\n5. **T+5m**: Recovery timer expires, Instance 3 transitions to HALF_OPEN and attempts test delivery\n6. **T+5m+2s**: Test delivery succeeds, circuit closes and success event is propagated globally\n\n#### Global State Management and Consensus\n\n**Mental Model: United Nations Security Council**\nThink of global state management like the United Nations Security Council coordinating international decisions. Member nations maintain their sovereignty and make most decisions independently, but certain critical decisions require global consensus. The UN provides mechanisms for proposal, discussion, voting, and enforcement while ensuring that temporary communication failures don't paralyze the entire system.\n\nDistributed webhook delivery systems require coordination of global state such as webhook registrations, configuration changes, and system-wide policies while maintaining high availability and partition tolerance. This requires sophisticated consensus protocols that can handle network partitions, instance failures, and conflicting updates.\n\n> **Decision: Global State Management Architecture**\n> - **Context**: Webhook registrations, secrets, and system configuration must be consistent across all processing instances while maintaining availability during network partitions\n> - **Options Considered**:\n>   1. Master-slave replication with single authoritative instance\n>   2. Multi-master replication with conflict resolution\n>   3. Consensus-based coordination using Raft or similar protocols\n> - **Decision**: Implement Raft consensus for critical state with eventual consistency for metrics and logs\n> - **Rationale**: Provides strong consistency for configuration data while maintaining availability and partition tolerance\n> - **Consequences**: Requires consensus protocol implementation but provides optimal consistency and availability characteristics\n\nThe global state management system partitions different types of state based on consistency requirements:\n\n| State Category | Consistency Model | Storage Mechanism | Update Protocol |\n|---------------|-------------------|-------------------|-----------------|\n| `webhook_registrations` | Strong consistency | Raft consensus cluster | Majority quorum for writes |\n| `system_configuration` | Strong consistency | Raft consensus cluster | Two-phase commit for complex changes |\n| `delivery_metrics` | Eventual consistency | Distributed time-series database | Best-effort propagation with reconciliation |\n| `audit_logs` | Strong consistency | Replicated append-only log | Write-ahead logging with replication |\n| `circuit_breaker_state` | Bounded inconsistency | Local state with global synchronization | Periodic sync with conflict resolution |\n\n**Consensus Protocol Implementation**\nThe system implements Raft consensus for managing critical global state:\n\n1. **Leader Election**: Processing instances participate in leader election for global state coordination\n2. **Log Replication**: Configuration changes are replicated through Raft log consensus before taking effect\n3. **Membership Changes**: Instance joining and leaving events are handled through Raft membership change protocols\n4. **Partition Handling**: Network partitions are handled by maintaining majority quorum requirements for global state changes\n5. **Recovery Protocol**: Failed instances can rejoin the cluster and catch up through log replay\n\n**State Synchronization Patterns**\nDifferent types of state require different synchronization patterns optimized for their specific consistency and performance requirements:\n\n**Webhook Registration Synchronization**:\n```\n1. New webhook registration submitted to leader instance\n2. Leader validates registration and generates unique webhook ID\n3. Leader proposes registration entry to Raft cluster\n4. Majority of instances accept proposal and commit to local state\n5. Leader acknowledges successful registration to client\n6. Configuration change is propagated to all follower instances\n7. Background process validates endpoint ownership across all instances\n```\n\n**Metrics Aggregation Synchronization**:\n```\n1. Each instance maintains local metrics counters for performance\n2. Every 60 seconds, instances publish metrics snapshots to time-series database\n3. Global metrics dashboard aggregates data from all instances\n4. Inconsistencies are resolved through timestamp-based conflict resolution\n5. Missing data is backfilled through instance heartbeat recovery\n```\n\nThe horizontal scaling architecture enables the webhook delivery system to handle enterprise-scale workloads while maintaining the reliability, security, and observability characteristics established in our core milestone design. By carefully partitioning state and coordinating global decisions through consensus protocols, the system can scale to handle millions of webhook deliveries per hour across multiple geographic regions while preserving strong consistency guarantees where required.\n\n### Implementation Guidance\n\nThe advanced features and scaling capabilities described above represent sophisticated extensions that build upon the solid foundation established in the core four milestones. The implementation approach should be incremental, starting with advanced delivery features before moving to comprehensive analytics and horizontal scaling.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| **Conditional Delivery** | JSONPath with Redis caching | Common Expression Language (CEL) with compiled expression cache |\n| **Payload Transformation** | JSONata template engine | JavaScript V8 sandbox with TypeScript support |\n| **Multi-Region Coordination** | Redis Cluster with geographic replication | Consul with WAN federation for global state |\n| **Metrics and Analytics** | Prometheus with Grafana | InfluxDB + Apache Spark with custom dashboards |\n| **Predictive Analytics** | scikit-learn with periodic model updates | TensorFlow Serving with real-time model deployment |\n| **Distributed Consensus** | etcd cluster for critical state | Custom Raft implementation optimized for webhook workloads |\n| **Event Sharding** | Consistent hash ring with Redis coordination | Apache Kafka with custom partitioning strategy |\n\n#### Recommended Architecture Evolution\n\nThe scaling implementation should follow a phased approach that maintains system stability while adding advanced capabilities:\n\n```\nwebhook-system/\n├── cmd/\n│   ├── webhook-server/           ← Core delivery system from milestones 1-4\n│   ├── analytics-processor/      ← Advanced analytics and metrics processing\n│   ├── transformation-engine/    ← Payload transformation service\n│   └── global-coordinator/       ← Multi-region state coordination\n├── internal/\n│   ├── delivery/                 ← Enhanced delivery engine with sharding\n│   │   ├── sharding.go          ← Consistent hashing and partition management\n│   │   ├── coordinator.go       ← Distributed coordination protocols\n│   │   └── filters.go           ← Conditional delivery and filtering\n│   ├── transformation/          ← Payload transformation pipeline\n│   │   ├── engine.go            ← Template execution and caching\n│   │   ├── jsonata.go           ← JSONata template processor\n│   │   └── security.go          ← Sandbox and resource limits\n│   ├── analytics/               ← Advanced monitoring and predictions\n│   │   ├── collector.go         ← High-frequency metrics collection\n│   │   ├── predictor.go         ← ML-based predictive models\n│   │   └── health.go            ← Customer health scoring\n│   ├── consensus/               ← Distributed state management\n│   │   ├── raft.go              ← Raft consensus implementation\n│   │   ├── state.go             ← Global state management\n│   │   └── coordination.go      ← Cross-region coordination\n│   └── scaling/                 ← Horizontal scaling infrastructure\n│       ├── partitioner.go       ← Event partitioning and rebalancing\n│       ├── circuit_distributed.go ← Distributed circuit breakers\n│       └── discovery.go         ← Service discovery and health checking\n├── deployments/\n│   ├── kubernetes/              ← K8s manifests for multi-region deployment\n│   ├── terraform/               ← Infrastructure as code for cloud resources\n│   └── monitoring/              ← Advanced monitoring and alerting configuration\n└── ml-models/                   ← Machine learning models for predictions\n    ├── failure-prediction/      ← Endpoint failure prediction model\n    ├── capacity-forecasting/    ← Resource demand forecasting model\n    └── churn-analysis/          ← Customer health and churn prediction\n```\n\n#### Advanced Filtering Engine\n\n```python\nfrom typing import Dict, List, Any, Optional\nimport json\nimport re\nfrom datetime import datetime, timezone\nfrom dataclasses import dataclass\nimport redis\nimport hashlib\n\n@dataclass\nclass FilterExpression:\n    \"\"\"Represents a compiled filter expression for webhook delivery decisions.\"\"\"\n    expression: str\n    compiled_form: Any\n    version: int\n    variables: Dict[str, Any]\n    \nclass ConditionalDeliveryEngine:\n    \"\"\"Advanced filtering engine for conditional webhook delivery.\"\"\"\n    \n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.expression_cache = {}\n        \n    def evaluate_delivery_conditions(self, webhook_id: str, event: 'WebhookEvent', \n                                   webhook_config: 'WebhookRegistration') -> bool:\n        \"\"\"\n        Determine if event should be delivered to webhook based on filter conditions.\n        \n        Returns True if event matches all delivery conditions, False otherwise.\n        \"\"\"\n        # TODO 1: Check if webhook has filter expressions configured\n        # TODO 2: Load or compile filter expression from cache\n        # TODO 3: Prepare evaluation context with event data, metadata, and variables\n        # TODO 4: Execute filter expression in safe environment with timeout\n        # TODO 5: Log filter evaluation result for debugging and audit\n        # TODO 6: Return boolean delivery decision\n        # Hint: Cache compiled expressions to avoid recompilation overhead\n        pass\n        \n    def compile_filter_expression(self, expression: str, variables: Dict[str, Any]) -> FilterExpression:\n        \"\"\"\n        Compile filter expression into optimized executable form.\n        \n        Supports JSONPath for simple field access and CEL for complex conditions.\n        \"\"\"\n        # TODO 1: Parse expression to determine type (JSONPath vs CEL)\n        # TODO 2: Validate expression syntax and security constraints\n        # TODO 3: Compile expression into executable form with optimization\n        # TODO 4: Create FilterExpression object with metadata\n        # TODO 5: Cache compiled expression for reuse\n        # Hint: Use expression hash as cache key for efficient lookup\n        pass\n        \n    def prepare_evaluation_context(self, event: 'WebhookEvent', \n                                 webhook_config: 'WebhookRegistration') -> Dict[str, Any]:\n        \"\"\"Prepare context variables available during filter expression evaluation.\"\"\"\n        # TODO 1: Extract event payload and metadata into context\n        # TODO 2: Add webhook configuration fields to context\n        # TODO 3: Include system variables (current time, region, etc.)\n        # TODO 4: Merge custom variables from webhook filter configuration\n        # TODO 5: Validate context size and complexity limits\n        pass\n\nclass PayloadTransformationEngine:\n    \"\"\"Template-based payload transformation for webhook delivery.\"\"\"\n    \n    def __init__(self):\n        self.template_cache = {}\n        self.enrichment_clients = {}\n        \n    def transform_payload(self, original_payload: Dict[str, Any], \n                         transformation_config: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Transform webhook payload according to template configuration.\n        \n        Supports JSONata templates, field mapping, and data enrichment.\n        \"\"\"\n        # TODO 1: Load transformation template from configuration\n        # TODO 2: Prepare transformation context with payload and enrichment data\n        # TODO 3: Execute template transformation in secure sandbox\n        # TODO 4: Apply field mappings and format conversions\n        # TODO 5: Validate transformed payload against schema if configured\n        # TODO 6: Handle transformation errors with fallback strategies\n        # Hint: Implement resource limits and timeout protection for template execution\n        pass\n        \n    def enrich_payload_data(self, payload: Dict[str, Any], \n                           enrichment_sources: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Fetch additional data from external sources for payload enrichment.\"\"\"\n        # TODO 1: Iterate through configured enrichment sources\n        # TODO 2: Extract lookup keys from original payload\n        # TODO 3: Make parallel requests to enrichment APIs with timeout\n        # TODO 4: Merge enrichment data into payload context\n        # TODO 5: Handle enrichment failures gracefully with partial data\n        # Hint: Cache enrichment results to reduce external API calls\n        pass\n```\n\n#### Predictive Analytics Infrastructure\n\n```python\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest, RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\nfrom typing import List, Tuple, Dict, Optional\nfrom datetime import datetime, timedelta\nimport asyncio\n\nclass WebhookPredictiveAnalytics:\n    \"\"\"Machine learning-based predictive analytics for webhook delivery system.\"\"\"\n    \n    def __init__(self, metrics_database):\n        self.metrics_db = metrics_database\n        self.models = {}\n        self.scalers = {}\n        \n    def predict_endpoint_failure(self, webhook_id: str, \n                               prediction_horizon_minutes: int = 60) -> Tuple[float, Dict[str, Any]]:\n        \"\"\"\n        Predict probability of webhook endpoint failure within specified time horizon.\n        \n        Returns probability score (0.0-1.0) and evidence dictionary.\n        \"\"\"\n        # TODO 1: Fetch recent delivery metrics for webhook endpoint\n        # TODO 2: Extract feature vector from metrics (response time, error rate, etc.)\n        # TODO 3: Load or train endpoint failure prediction model\n        # TODO 4: Apply feature scaling and generate prediction\n        # TODO 5: Calculate confidence intervals and evidence summary\n        # TODO 6: Return prediction with supporting evidence for alerting\n        # Hint: Use sliding time windows for feature extraction\n        pass\n        \n    def forecast_capacity_requirements(self, region: str, \n                                     forecast_horizon_hours: int = 24) -> Dict[str, Any]:\n        \"\"\"\n        Forecast resource requirements for webhook delivery capacity planning.\n        \n        Predicts worker instances, queue capacity, and infrastructure needs.\n        \"\"\"\n        # TODO 1: Analyze historical event volume patterns by time and region\n        # TODO 2: Extract seasonal, trend, and cyclical components\n        # TODO 3: Apply time series forecasting model (ARIMA or Prophet)\n        # TODO 4: Convert event volume forecast to resource requirements\n        # TODO 5: Include confidence intervals and scenario analysis\n        # TODO 6: Generate scaling recommendations with cost estimates\n        pass\n        \n    def detect_security_anomalies(self, request_patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Identify potential security threats or abuse patterns in webhook requests.\"\"\"\n        # TODO 1: Extract features from request patterns (IP, timing, payload size, etc.)\n        # TODO 2: Apply anomaly detection model (Isolation Forest or similar)\n        # TODO 3: Score requests for anomaly likelihood\n        # TODO 4: Cluster similar anomalous patterns for threat classification\n        # TODO 5: Generate security alerts with threat analysis\n        # Hint: Update anomaly detection baseline regularly to adapt to normal patterns\n        pass\n\nclass CustomerHealthScoring:\n    \"\"\"Advanced customer health scoring based on webhook delivery performance.\"\"\"\n    \n    def calculate_integration_health_score(self, customer_id: str, \n                                         time_window_days: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Calculate comprehensive health score for customer webhook integration.\n        \n        Returns health score (0-100) with component breakdown and trends.\n        \"\"\"\n        # TODO 1: Fetch delivery metrics for all customer webhook endpoints\n        # TODO 2: Calculate component scores (success rate, latency, reliability)\n        # TODO 3: Apply weighted scoring based on business criticality\n        # TODO 4: Analyze trends and velocity of health changes\n        # TODO 5: Generate actionable insights and recommendations\n        # TODO 6: Return comprehensive health assessment with drill-down data\n        pass\n```\n\n#### Distributed Scaling Infrastructure\n\n```python\nimport hashlib\nimport asyncio\nfrom typing import Dict, List, Set, Optional, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\nimport redis.asyncio as redis\nimport json\n\nclass ShardingStrategy(Enum):\n    WEBHOOK_ENDPOINT = \"webhook_endpoint\"\n    CUSTOMER_TENANT = \"customer_tenant\" \n    GEOGRAPHIC_REGION = \"geographic_region\"\n\n@dataclass\nclass PartitionInfo:\n    partition_id: int\n    start_hash: int\n    end_hash: int\n    assigned_instance: str\n    last_rebalanced: datetime\n\nclass ConsistentHashSharding:\n    \"\"\"Consistent hashing implementation for webhook delivery load distribution.\"\"\"\n    \n    def __init__(self, redis_client: redis.Redis, virtual_nodes: int = 150):\n        self.redis = redis_client\n        self.virtual_nodes = virtual_nodes\n        self.hash_ring = {}\n        self.instance_partitions = {}\n        \n    async def assign_webhook_to_partition(self, webhook_url: str) -> str:\n        \"\"\"\n        Determine which processing instance should handle deliveries for webhook URL.\n        \n        Returns instance identifier responsible for this webhook endpoint.\n        \"\"\"\n        # TODO 1: Calculate hash value for webhook URL using SHA-256\n        # TODO 2: Find appropriate position on consistent hash ring\n        # TODO 3: Locate assigned processing instance for this hash range\n        # TODO 4: Handle partition reassignment during rebalancing\n        # TODO 5: Cache partition assignment for performance\n        # TODO 6: Return instance identifier for delivery routing\n        # Hint: Use virtual nodes to ensure uniform distribution\n        pass\n        \n    async def rebalance_partitions(self, available_instances: Set[str]) -> Dict[str, List[int]]:\n        \"\"\"\n        Rebalance webhook partitions across available processing instances.\n        \n        Minimizes partition movement while achieving uniform distribution.\n        \"\"\"\n        # TODO 1: Calculate target partition count per instance\n        # TODO 2: Identify over-loaded and under-loaded instances\n        # TODO 3: Plan partition migrations to achieve balance\n        # TODO 4: Execute gradual migration to avoid service disruption\n        # TODO 5: Update hash ring and routing tables atomically\n        # TODO 6: Return new partition assignment mapping\n        pass\n\nclass DistributedCircuitBreaker:\n    \"\"\"Distributed circuit breaker with global state coordination.\"\"\"\n    \n    def __init__(self, redis_client: redis.Redis, instance_id: str):\n        self.redis = redis_client\n        self.instance_id = instance_id\n        self.local_state = {}\n        \n    async def should_allow_delivery(self, webhook_id: str) -> Tuple[bool, Optional[str]]:\n        \"\"\"\n        Check if delivery should be attempted considering distributed circuit state.\n        \n        Returns (allow_delivery, reason) tuple for delivery decision.\n        \"\"\"\n        # TODO 1: Check local circuit breaker state for fast decision\n        # TODO 2: If local state is uncertain, consult global state\n        # TODO 3: Apply circuit breaker logic (CLOSED/OPEN/HALF_OPEN)\n        # TODO 4: Handle race conditions during state transitions\n        # TODO 5: Return delivery decision with reasoning for debugging\n        # Hint: Prioritize local decisions for performance, global for accuracy\n        pass\n        \n    async def record_delivery_result(self, webhook_id: str, success: bool, \n                                   response_time: float) -> None:\n        \"\"\"Record delivery result and update circuit breaker state accordingly.\"\"\"\n        # TODO 1: Update local circuit breaker state with delivery result\n        # TODO 2: Check if local state change triggers global coordination\n        # TODO 3: Publish state change events to other instances if needed\n        # TODO 4: Handle consensus conflicts during concurrent updates\n        # TODO 5: Log state transitions for debugging and audit\n        pass\n        \n    async def coordinate_global_state(self, webhook_id: str, \n                                    local_state: 'CircuitState') -> None:\n        \"\"\"Coordinate circuit breaker state changes across all processing instances.\"\"\"\n        # TODO 1: Aggregate failure counts from all processing instances\n        # TODO 2: Determine authoritative circuit breaker state\n        # TODO 3: Publish state changes to coordination channel\n        # TODO 4: Handle network partitions and instance failures gracefully\n        # TODO 5: Ensure all instances converge to consistent state\n        pass\n\nclass GlobalStateCoordination:\n    \"\"\"Raft-based consensus for global webhook system state management.\"\"\"\n    \n    def __init__(self, instance_id: str, peer_instances: List[str]):\n        self.instance_id = instance_id\n        self.peers = peer_instances\n        self.is_leader = False\n        self.current_term = 0\n        self.log = []\n        \n    async def propose_configuration_change(self, change: Dict[str, Any]) -> bool:\n        \"\"\"\n        Propose global configuration change through Raft consensus protocol.\n        \n        Returns True if change was accepted by majority quorum.\n        \"\"\"\n        # TODO 1: Validate that current instance is elected leader\n        # TODO 2: Create log entry for proposed configuration change\n        # TODO 3: Replicate log entry to majority of peer instances\n        # TODO 4: Apply configuration change once consensus is reached\n        # TODO 5: Notify all instances of successful configuration update\n        # TODO 6: Return success status for client acknowledgment\n        # Hint: Implement proper Raft leader election and log replication\n        pass\n        \n    async def handle_leader_election(self) -> bool:\n        \"\"\"Execute Raft leader election protocol when current leader is unavailable.\"\"\"\n        # TODO 1: Increment current term and vote for self\n        # TODO 2: Send vote requests to all peer instances\n        # TODO 3: Collect vote responses within election timeout\n        # TODO 4: Become leader if majority votes received\n        # TODO 5: Send heartbeats to maintain leadership authority\n        # TODO 6: Step down if higher term discovered or split vote\n        pass\n```\n\n#### Milestone Checkpoints for Advanced Features\n\n**Advanced Delivery Features Validation:**\n- Conditional delivery: Configure filter expressions and verify only matching events are delivered\n- Payload transformation: Create transformation templates and validate output format correctness\n- Multi-region deployment: Deploy to multiple regions and verify cross-region state synchronization\n\n**Enhanced Monitoring Validation:**\n- Comprehensive metrics: Validate all metric categories are collected and displayed in dashboards\n- Predictive analytics: Generate predictions and verify alert accuracy through controlled failure scenarios\n- Customer health scoring: Calculate health scores and validate correlation with actual customer satisfaction\n\n**Horizontal Scaling Validation:**\n- Sharding functionality: Add/remove processing instances and verify automatic partition rebalancing\n- Distributed coordination: Create network partitions and verify system maintains consistency and availability\n- Global state management: Perform concurrent configuration changes and verify consensus behavior\n\nThe advanced features and scaling capabilities described in this section transform the webhook delivery system from a reliable single-instance service into a comprehensive enterprise-grade event distribution platform. The implementation approach emphasizes incremental development, operational excellence, and maintainability while providing the sophisticated capabilities required for modern cloud-native architectures.\n\n\n## Glossary\n\n> **Milestone(s):** All milestones (1-4) - technical terms and domain-specific vocabulary used throughout the webhook delivery system design and implementation\n\nUnderstanding a webhook delivery system requires familiarity with terminology spanning distributed systems, cryptography, HTTP protocols, and reliability engineering. This glossary provides precise definitions of technical terms used throughout the design document, organized to build understanding from basic concepts to advanced patterns.\n\n### Mental Model: The Technical Dictionary\n\nThink of this glossary as a technical dictionary specifically tailored to webhook delivery systems. Just as a medical dictionary defines terms differently than a general dictionary (where \"culture\" means bacterial growth, not art), this glossary defines common terms within the specific context of reliable webhook delivery. Many terms like \"circuit breaker\" or \"exponential backoff\" have precise meanings in distributed systems that differ from their everyday usage.\n\nThe glossary serves as a reference for junior developers learning the domain, ensuring consistent terminology across teams, and providing the precise technical definitions needed for implementation. Each entry includes not just the definition but the context in which the term is used within webhook delivery systems.\n\n### Core Webhook Concepts\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **webhook delivery** | Asynchronous HTTP notification system that sends event data to registered HTTP endpoints when specific events occur in the source system | Primary system function - the core service being built | endpoint, event, payload |\n| **webhook endpoint** | HTTP URL that receives webhook notifications via POST requests with event payload data | Destination for all delivery attempts - registered and verified by customers | callback URL, destination URL |\n| **event payload** | JSON data structure containing the actual event information being delivered to webhook endpoints | Core data being transmitted - contains business event details | event data, message body |\n| **webhook signature** | Cryptographic authentication token included in HTTP headers that allows endpoints to verify the authenticity and integrity of webhook deliveries | Security mechanism preventing spoofing and tampering | HMAC signature, authentication |\n| **endpoint registration** | Process of adding a new webhook endpoint to the system, including URL validation, ownership verification, and secret generation | Initial setup required before any deliveries can occur | webhook onboarding, subscription |\n| **event subscription** | Configuration specifying which event types a webhook endpoint wants to receive notifications for | Filtering mechanism that determines delivery targets | event filtering, subscription rules |\n| **delivery attempt** | Single HTTP POST request sent to a webhook endpoint with signed event payload data | Individual unit of work in the delivery process | webhook request, delivery try |\n| **delivery guarantee** | System promise about webhook delivery reliability, typically \"at-least-once\" meaning events will not be lost but may be delivered multiple times | Reliability contract with customers using the webhook service | delivery semantics, reliability SLA |\n\n### Reliability and Fault Tolerance\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **circuit breaker** | Failure protection pattern that disables failing endpoints after consecutive failures, preventing wasted resources on known-bad destinations | Protection mechanism preventing resource waste on failing endpoints | fault isolation, failure protection |\n| **exponential backoff** | Retry strategy where delay between attempts increases exponentially (e.g., 1s, 2s, 4s, 8s) to avoid overwhelming recovering services | Retry timing strategy that balances fast recovery with system protection | retry delay, backoff strategy |\n| **jitter** | Random variation added to retry delays to prevent multiple failed requests from retrying simultaneously and overwhelming a recovering endpoint | Prevents thundering herd when many webhooks fail at the same time | randomization, staggered retry |\n| **dead letter queue** | Storage location for webhook events that have exhausted all retry attempts and cannot be delivered successfully | Final destination for permanently failed deliveries requiring manual intervention | DLQ, failed message storage |\n| **at-least-once delivery** | Guarantee that webhook events will be delivered successfully at least one time, though duplicate deliveries are possible during failure recovery | Core reliability promise - no events are lost due to system failures | delivery guarantee, reliability SLA |\n| **thundering herd** | Problem where many clients simultaneously retry failed requests when a service recovers, potentially overwhelming it again | Failure pattern prevented by jitter and circuit breakers | retry storm, recovery overload |\n| **circuit breaker failure threshold** | Number of consecutive delivery failures that will trigger the circuit breaker to open and stop delivery attempts | Configuration parameter controlling circuit breaker sensitivity | failure limit, trip threshold |\n| **circuit breaker recovery timeout** | Duration the circuit breaker waits in open state before attempting test deliveries to check if the endpoint has recovered | Time-based recovery mechanism allowing endpoints to heal | recovery period, healing time |\n\n### Circuit Breaker States\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **closed circuit state** | Normal operating state where delivery attempts are allowed and the endpoint is considered healthy | Default state when endpoint is working correctly | normal operation, healthy state |\n| **open circuit state** | Protective state where delivery attempts are blocked after repeated failures, preventing resource waste on known-bad endpoints | Failure state protecting system resources from bad endpoints | blocked state, failure protection |\n| **half-open circuit state** | Testing state where limited probe requests are sent to check if a failed endpoint has recovered and can handle normal traffic | Recovery testing phase between failure and normal operation | recovery testing, probe state |\n| **circuit breaker flapping** | Rapid oscillation between open and closed states, typically caused by an endpoint that intermittently fails under load | Unstable behavior indicating endpoint capacity or reliability issues | state oscillation, unstable circuit |\n\n### Security and Authentication\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **HMAC signature** | Hash-based Message Authentication Code computed using SHA-256 over the webhook payload with a shared secret key | Primary authentication mechanism preventing webhook spoofing | cryptographic signature, payload authentication |\n| **canonical signing string** | Standardized format combining webhook payload, timestamp, webhook ID, and delivery ID used as input for HMAC signature calculation | Ensures consistent signature generation and verification | signature input, signing format |\n| **webhook secret** | Cryptographically random shared key used for HMAC signature generation and verification between the webhook service and endpoint | Shared authentication credential enabling signature verification | signing key, shared secret |\n| **secret rotation** | Process of generating new webhook secrets while maintaining overlapping validity periods to ensure seamless key updates | Security practice preventing long-lived key compromise | key rotation, credential refresh |\n| **ownership verification** | Challenge-response protocol where endpoints must prove they control the registered URL by responding to a verification request | Prevents unauthorized webhook registration to endpoints not owned by the requester | endpoint verification, challenge-response |\n| **replay protection** | Mechanism using timestamps and nonces to prevent reuse of captured webhook requests for malicious purposes | Prevents replay attacks using recorded webhook deliveries | anti-replay, request freshness |\n| **SSRF protection** | Security measures preventing webhook registration to internal network addresses that could be exploited for server-side request forgery attacks | Prevents attackers from using webhook system to probe internal networks | request forgery prevention, network security |\n| **timing attack** | Cryptographic attack that exploits differences in signature verification execution time to infer information about the secret key | Security vulnerability prevented by constant-time signature comparison | side-channel attack, cryptographic timing |\n| **envelope encryption** | Technique where webhook secrets are encrypted with a separate master key rather than stored in plaintext | Additional security layer protecting secrets from database compromise | key encryption, layered security |\n\n### Queue Management and Processing\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **delivery queue** | Persistent message queue storing webhook events waiting to be delivered to their target endpoints | Core infrastructure ensuring reliable event storage and processing | message queue, event queue |\n| **queue ordering** | Guarantee that webhook events for a specific endpoint are processed in the order they were received | Ensures event sequence integrity for stateful webhook consumers | FIFO processing, event ordering |\n| **queue backlog** | Accumulation of unprocessed webhook events in delivery queues, typically indicating processing capacity issues | Performance metric indicating system stress or endpoint problems | message backlog, processing lag |\n| **message persistence** | Storage of queued webhook events in durable storage to survive system restarts and failures | Ensures events are not lost due to system crashes or restarts | durable storage, queue durability |\n| **queue partitioning** | Division of webhook events across multiple queue partitions to enable parallel processing and horizontal scaling | Scaling technique allowing multiple workers to process events concurrently | queue sharding, parallel processing |\n| **consumer group** | Set of worker processes that cooperatively consume events from delivery queues with load balancing and failure recovery | Worker coordination pattern ensuring events are processed exactly once | worker pool, consumer coordination |\n| **queue health** | Metrics indicating the operational status of delivery queues, including depth, processing rate, and error rates | Monitoring data used for capacity planning and problem detection | queue metrics, operational health |\n\n### Rate Limiting and Flow Control\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **rate limiting** | Mechanism that controls the maximum number of webhook delivery attempts per endpoint within a specific time window | Protects endpoints from being overwhelmed by high delivery rates | throttling, flow control |\n| **token bucket** | Rate limiting algorithm that allows burst traffic up to a capacity limit while maintaining average rate limits over time | Implementation technique providing flexible rate control with burst handling | burst capacity, rate control |\n| **Retry-After header** | HTTP response header indicating how long clients should wait before making another request to a rate-limited endpoint | Standard mechanism for endpoints to communicate their preferred retry timing | backpressure signal, rate limit communication |\n| **burst capacity** | Maximum number of requests that can be sent in rapid succession before rate limiting takes effect | Allows short traffic spikes while maintaining overall rate limits | burst allowance, traffic spike handling |\n| **rate limit bypass** | Configuration option allowing certain high-priority events or trusted customers to exceed normal rate limits | Emergency mechanism for critical business events | priority delivery, limit override |\n| **backpressure** | System response to downstream capacity limits by slowing or stopping upstream processing to prevent overload | Flow control mechanism protecting the entire delivery pipeline | flow control, congestion control |\n\n### Monitoring and Health\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **endpoint health monitoring** | Continuous tracking of delivery success rates, response times, and error patterns for webhook endpoints | Operational intelligence for detecting problems and managing circuit breakers | health tracking, endpoint monitoring |\n| **health score** | Composite metric combining delivery success rate, response time, and availability to assess overall endpoint reliability | Single number summarizing endpoint operational quality | reliability metric, endpoint score |\n| **delivery latency** | Time elapsed between when an event is generated and when it is successfully delivered to the webhook endpoint | Performance metric indicating system responsiveness | response time, delivery delay |\n| **success rate** | Percentage of webhook delivery attempts that result in successful HTTP responses (2xx status codes) | Primary reliability metric for endpoints and overall system health | delivery success, reliability percentage |\n| **error rate** | Percentage of webhook delivery attempts that result in HTTP errors, timeouts, or other failure conditions | Failure metric used for alerting and circuit breaker decisions | failure rate, delivery failures |\n| **endpoint availability** | Percentage of time that a webhook endpoint is responsive and accepting delivery attempts successfully | Uptime metric indicating endpoint operational status | uptime percentage, service availability |\n\n### Event Sourcing and Audit\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **event sourcing** | Pattern of capturing all state changes as immutable event records, providing complete audit trail and replay capability | Architectural approach enabling comprehensive delivery logging and replay | audit trail, immutable log |\n| **delivery audit trail** | Complete historical record of every webhook delivery attempt including payloads, responses, timing, and error information | Compliance and debugging capability tracking all delivery activity | audit log, delivery history |\n| **event replay** | Capability to re-send previously delivered webhook events, typically used for recovery from endpoint outages or debugging | Recovery mechanism allowing reprocessing of historical events | message replay, event redelivery |\n| **replay deduplication** | Mechanism to identify and handle duplicate webhook deliveries during event replay operations | Prevents duplicate processing when events are replayed multiple times | duplicate detection, idempotency |\n| **idempotency key** | Unique identifier included in webhook headers that allows endpoints to detect and safely ignore duplicate deliveries | Enables safe retry and replay operations without side effects | duplicate detection, safe retry |\n| **delivery correlation** | Ability to trace related webhook deliveries and system events using correlation IDs and request tracking | Debugging capability linking events across system components | request tracing, event correlation |\n\n### Storage and Data Management\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **hierarchical storage management** | Automated data lifecycle management that moves older audit logs through multiple storage tiers based on age and access patterns | Cost optimization strategy for long-term audit log retention | data lifecycle, tiered storage |\n| **hot storage** | High-performance storage tier for recent delivery logs that require fast query response times | Recent audit data requiring immediate access for debugging | active storage, high-performance tier |\n| **warm storage** | Medium-performance storage tier for older delivery logs that are occasionally accessed for compliance or investigation | Intermediate storage for less frequently accessed audit data | standard storage, intermediate tier |\n| **cold storage** | Low-cost archive storage tier for old delivery logs that are rarely accessed but must be retained for compliance | Long-term retention for compliance and legal requirements | archive storage, compliance retention |\n| **storage explosion** | Uncontrolled growth in audit log storage leading to excessive costs and performance degradation | Operational problem requiring retention policies and data lifecycle management | log growth, storage bloat |\n| **time-series optimization** | Database schema and query optimization techniques designed for time-based audit log data | Performance optimization for chronological delivery log queries | temporal optimization, log performance |\n| **data retention policy** | Rules governing how long different types of delivery data are kept before automatic deletion or archival | Compliance and cost management framework for audit data | retention rules, data lifecycle |\n\n### Failure Recovery and Resilience\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **graceful degradation** | System behavior that maintains partial functionality when some components fail rather than complete system failure | Resilience pattern allowing continued operation during partial failures | partial failure handling, service degradation |\n| **failure isolation** | Design principle that prevents failures in one component from cascading to other system components | Architectural pattern limiting blast radius of component failures | fault containment, failure boundaries |\n| **auto-recovery** | Capability for system components to automatically detect and recover from certain types of failures without manual intervention | Operational efficiency feature reducing manual intervention requirements | self-healing, automatic recovery |\n| **manual intervention** | Human operational action required to resolve system problems that cannot be automatically recovered | Escalation path for problems exceeding automatic recovery capabilities | manual recovery, operational escalation |\n| **failure cascade** | Pattern where initial component failure triggers failures in dependent components, potentially causing system-wide outage | Dangerous failure pattern prevented by circuit breakers and isolation | cascading failure, failure propagation |\n| **recovery window** | Time period during which a failed component is expected to recover normal operation | Planning parameter for circuit breaker timeouts and alerting | healing time, restoration period |\n\n### Testing and Validation\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **milestone verification** | Systematic validation that implementation meets acceptance criteria defined for each development milestone | Quality assurance process ensuring project progress and functionality | acceptance testing, milestone validation |\n| **integration testing** | Testing approach that validates complete workflows across multiple system components | End-to-end validation ensuring component interactions work correctly | system testing, workflow validation |\n| **load testing** | Performance validation using production-scale traffic to identify bottlenecks and capacity limits | Performance assurance ensuring system handles expected traffic volumes | stress testing, capacity validation |\n| **mock endpoint** | Configurable test webhook endpoint that simulates various response behaviors for testing delivery logic | Testing infrastructure enabling validation of delivery and error handling | test endpoint, simulated receiver |\n| **test fixtures** | Reusable test setup and teardown code that creates consistent testing environments | Testing infrastructure ensuring reproducible test conditions | test harness, testing framework |\n| **chaos engineering** | Testing approach that deliberately introduces failures to validate system resilience and recovery capabilities | Resilience validation through controlled failure injection | failure testing, resilience engineering |\n\n### Performance and Scaling\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **horizontal scaling** | Increasing system capacity by adding more processing instances rather than upgrading existing hardware | Scaling strategy enabling linear capacity growth with demand | scale-out, distributed scaling |\n| **vertical scaling** | Increasing system capacity by upgrading hardware resources (CPU, memory, storage) on existing instances | Alternative scaling approach with hardware-imposed limits | scale-up, hardware scaling |\n| **sharding strategy** | Method for partitioning webhook workload across multiple processing instances to enable horizontal scaling | Distribution technique enabling parallel processing across instances | data partitioning, workload distribution |\n| **consistent hashing** | Algorithm that distributes webhook endpoints uniformly across processing instances with minimal redistribution during scaling events | Load balancing technique minimizing disruption during scaling | hash-based distribution, load balancing |\n| **delivery bottleneck** | System component or resource that limits overall webhook delivery throughput | Performance constraint requiring optimization or scaling | throughput limit, capacity constraint |\n| **resource exhaustion** | Condition where system components run out of critical resources like connections, memory, or file descriptors | Operational problem requiring monitoring and resource management | capacity limit, resource depletion |\n\n### Advanced Features\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **conditional delivery** | Advanced filtering capability that delivers webhook events only when specific content or recipient criteria are met | Intelligent filtering reducing unnecessary webhook traffic | smart filtering, content-based routing |\n| **payload transformation** | Automatic modification of webhook event data to match the format expectations of different endpoint consumers | Data adaptation enabling compatibility with diverse endpoint requirements | data mapping, format conversion |\n| **multi-region deployment** | Geographic distribution of webhook delivery infrastructure across multiple data centers for performance and reliability | Scaling pattern improving latency and providing disaster recovery | geographic distribution, global deployment |\n| **predictive analytics** | Machine learning techniques applied to webhook delivery data to forecast failures, capacity needs, and performance trends | Advanced monitoring enabling proactive system management | ML monitoring, failure prediction |\n| **customer health scoring** | Comprehensive metrics combining technical delivery performance with business impact assessment for customer success management | Business intelligence combining technical and business metrics | integration health, customer success metrics |\n\n### Distributed Systems Concepts\n\n| Term | Definition | Context | Related Terms |\n|------|------------|---------|---------------|\n| **distributed circuit breaker** | Circuit breaker implementation that coordinates state across multiple processing instances for consistent failure protection | Advanced fault tolerance requiring cross-instance coordination | global circuit breaker, distributed fault protection |\n| **global state management** | Coordination of configuration and operational state across multiple distributed system instances | Consistency requirement for distributed webhook processing | distributed coordination, state synchronization |\n| **consensus protocol** | Distributed algorithm enabling multiple system instances to agree on configuration changes and operational decisions | Coordination mechanism for distributed system management | distributed consensus, agreement protocol |\n| **network partition** | Loss of network connectivity between system components, potentially causing operational inconsistencies | Failure scenario requiring careful handling in distributed systems | split-brain, network isolation |\n| **split-brain scenario** | Condition where network partitions cause isolated system instances to operate independently with potentially conflicting state | Dangerous distributed systems failure mode requiring prevention | partition handling, consistency conflict |\n| **leader election** | Protocol for selecting a single coordinator instance among multiple candidates in a distributed system | Coordination pattern ensuring single point of control for global decisions | coordinator selection, distributed leadership |\n\n### Implementation Guidance\n\nBuilding a webhook delivery system requires understanding terminology from multiple technical domains. The implementation should establish a consistent vocabulary across all code, documentation, and operational procedures.\n\n#### Technology Recommendations\n\n| Component | Simple Option | Advanced Option |\n|-----------|---------------|-----------------|\n| Documentation | Markdown with inline glossary | Searchable documentation portal with cross-references |\n| Code Comments | Inline definitions for domain terms | Automated glossary generation from code annotations |\n| API Documentation | OpenAPI with term definitions | Interactive API docs with contextual glossary |\n| Monitoring Dashboards | Basic metric labels | Tooltip definitions for technical terms |\n\n#### Recommended File Structure\n\n```\nproject-root/\n  docs/\n    design-document.md        ← main design document\n    glossary.md              ← standalone glossary reference\n    api-reference.md         ← API documentation with term usage\n  src/webhook_delivery/\n    models/\n      __init__.py            ← domain model definitions\n      glossary.py            ← code-embedded term definitions\n    components/\n      registry.py            ← webhook registration with term usage\n      delivery.py            ← delivery engine with consistent terminology\n    utils/\n      documentation.py       ← documentation generation utilities\n  tests/\n    test_terminology.py      ← validate consistent term usage\n```\n\n#### Glossary Management Infrastructure\n\n```python\n\"\"\"\nEmbedded glossary system for maintaining consistent terminology.\nProvides runtime access to technical definitions and validates term usage.\n\"\"\"\n\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n@dataclass\nclass GlossaryEntry:\n    \"\"\"Single glossary term with definition and usage context.\"\"\"\n    term: str\n    definition: str\n    context: str\n    related_terms: List[str]\n    aliases: List[str]\n    category: str\n\nclass TermCategory(Enum):\n    \"\"\"Categories for organizing glossary terms.\"\"\"\n    CORE_CONCEPTS = \"core_concepts\"\n    RELIABILITY = \"reliability\"\n    SECURITY = \"security\"\n    PERFORMANCE = \"performance\"\n    OPERATIONS = \"operations\"\n\nclass WebhookGlossary:\n    \"\"\"\n    Central glossary system for webhook delivery terminology.\n    Provides programmatic access to definitions and validates term usage.\n    \"\"\"\n    \n    def __init__(self):\n        self._entries: Dict[str, GlossaryEntry] = {}\n        self._aliases: Dict[str, str] = {}\n        self._load_core_definitions()\n    \n    def define_term(self, entry: GlossaryEntry) -> None:\n        \"\"\"\n        Add a term definition to the glossary.\n        Validates for conflicts and maintains alias mappings.\n        \"\"\"\n        # TODO: Validate term doesn't conflict with existing definitions\n        # TODO: Add term to main entries dictionary\n        # TODO: Register all aliases pointing to canonical term\n        # TODO: Validate related terms exist in glossary\n        # TODO: Log term registration for auditing\n        pass\n    \n    def get_definition(self, term: str) -> Optional[GlossaryEntry]:\n        \"\"\"\n        Retrieve definition for a term or its alias.\n        Returns None if term is not found in glossary.\n        \"\"\"\n        # TODO: Check if term exists directly in entries\n        # TODO: Check if term is an alias and resolve to canonical form\n        # TODO: Return GlossaryEntry if found, None otherwise\n        # TODO: Log definition access for usage analytics\n        pass\n    \n    def validate_term_usage(self, text: str) -> List[str]:\n        \"\"\"\n        Analyze text for inconsistent terminology usage.\n        Returns list of potential terminology issues found.\n        \"\"\"\n        # TODO: Scan text for technical terms and aliases\n        # TODO: Check for mixed usage of terms and aliases\n        # TODO: Identify undefined terms that should be in glossary\n        # TODO: Flag deprecated terms or inconsistent naming\n        # TODO: Return list of issues with suggestions for fixes\n        pass\n    \n    def generate_documentation(self, category: Optional[TermCategory] = None) -> str:\n        \"\"\"\n        Generate formatted glossary documentation.\n        Optionally filter by term category.\n        \"\"\"\n        # TODO: Filter entries by category if specified\n        # TODO: Sort terms alphabetically within categories\n        # TODO: Format as markdown table with columns for term, definition, context\n        # TODO: Include cross-references to related terms\n        # TODO: Add category headers and organization\n        pass\n\n# Global glossary instance for consistent term access\nwebhook_glossary = WebhookGlossary()\n```\n\n#### Core Term Definitions\n\n```python\n\"\"\"\nCore webhook delivery system terminology definitions.\nLoaded into the glossary system for consistent usage validation.\n\"\"\"\n\nCORE_DEFINITIONS = [\n    GlossaryEntry(\n        term=\"webhook delivery\",\n        definition=\"Asynchronous HTTP notification system that sends event data to registered HTTP endpoints when specific events occur in the source system\",\n        context=\"Primary system function - the core service being built\",\n        related_terms=[\"endpoint\", \"event\", \"payload\"],\n        aliases=[\"webhook notification\", \"event delivery\"],\n        category=TermCategory.CORE_CONCEPTS\n    ),\n    GlossaryEntry(\n        term=\"circuit breaker\",\n        definition=\"Failure protection pattern that disables failing endpoints after consecutive failures, preventing wasted resources on known-bad destinations\",\n        context=\"Protection mechanism preventing resource waste on failing endpoints\",\n        related_terms=[\"fault isolation\", \"failure protection\", \"exponential backoff\"],\n        aliases=[\"fault breaker\", \"endpoint protection\"],\n        category=TermCategory.RELIABILITY\n    ),\n    GlossaryEntry(\n        term=\"HMAC signature\",\n        definition=\"Hash-based Message Authentication Code computed using SHA-256 over the webhook payload with a shared secret key\",\n        context=\"Primary authentication mechanism preventing webhook spoofing\",\n        related_terms=[\"webhook secret\", \"payload authentication\", \"canonical signing string\"],\n        aliases=[\"webhook signature\", \"cryptographic signature\"],\n        category=TermCategory.SECURITY\n    ),\n    # Additional core definitions would be included here\n]\n\ndef load_core_definitions(glossary: WebhookGlossary) -> None:\n    \"\"\"Load core webhook delivery terminology into glossary system.\"\"\"\n    for definition in CORE_DEFINITIONS:\n        glossary.define_term(definition)\n```\n\n#### Terminology Validation Tools\n\n```python\n\"\"\"\nTools for validating consistent terminology usage across codebase.\nIntegrates with development workflow to catch terminology issues early.\n\"\"\"\n\nimport ast\nimport re\nfrom typing import Set, List, Tuple\n\nclass TerminologyValidator:\n    \"\"\"\n    Static analysis tool for validating terminology consistency.\n    Scans code and documentation for terminology usage issues.\n    \"\"\"\n    \n    def __init__(self, glossary: WebhookGlossary):\n        self.glossary = glossary\n        self.known_terms = self._extract_known_terms()\n    \n    def validate_code_file(self, filepath: str) -> List[str]:\n        \"\"\"\n        Scan Python file for terminology usage issues.\n        Returns list of issues found with line numbers and suggestions.\n        \"\"\"\n        # TODO: Parse Python AST to extract strings and comments\n        # TODO: Check class names, method names, and variable names against glossary\n        # TODO: Validate docstring terminology usage\n        # TODO: Flag inconsistent term usage within same file\n        # TODO: Return detailed issues with line numbers and fix suggestions\n        pass\n    \n    def validate_documentation(self, filepath: str) -> List[str]:\n        \"\"\"\n        Scan markdown documentation for terminology consistency.\n        Checks for proper term usage and missing definitions.\n        \"\"\"\n        # TODO: Extract technical terms from markdown content\n        # TODO: Check for undefined terms that should be in glossary\n        # TODO: Validate consistent usage of terms vs aliases\n        # TODO: Flag potential terminology improvements\n        # TODO: Return list of documentation issues with recommendations\n        pass\n    \n    def suggest_missing_definitions(self, text: str) -> List[str]:\n        \"\"\"\n        Analyze text to identify technical terms missing from glossary.\n        Helps maintain comprehensive terminology coverage.\n        \"\"\"\n        # TODO: Extract potential technical terms using pattern matching\n        # TODO: Filter out terms already defined in glossary\n        # TODO: Rank suggestions by frequency and technical likelihood\n        # TODO: Return list of suggested terms for glossary addition\n        pass\n```\n\n#### Milestone Checkpoint: Terminology Consistency\n\nAfter implementing the glossary system, validate terminology consistency across the project:\n\n**Expected Behavior:**\n- All technical terms used consistently across code and documentation\n- Glossary provides programmatic access to term definitions\n- Validation tools catch terminology inconsistencies in development workflow\n- Documentation generation produces comprehensive reference material\n\n**Validation Commands:**\n```bash\n# Run terminology validation across codebase\npython -m tests.test_terminology --validate-all\n\n# Generate glossary documentation\npython -m src.webhook_delivery.utils.documentation --generate-glossary\n\n# Check specific file for terminology issues\npython -m src.webhook_delivery.utils.terminology --validate docs/design-document.md\n```\n\n**Success Indicators:**\n- Zero terminology validation failures in CI pipeline\n- Consistent technical vocabulary across all documentation\n- Developer IDE integration provides term definitions on hover\n- Glossary covers all technical concepts used in implementation\n\n**Common Issues:**\n- **Inconsistent Term Usage**: Different parts of codebase using different names for same concept\n  - *Symptom*: Validation tools report mixed usage of \"webhook delivery\" vs \"event notification\"\n  - *Cause*: Multiple developers using different terminology preferences\n  - *Fix*: Establish canonical terms in glossary and update all usage to match\n\n- **Missing Definitions**: Technical terms used without glossary entries\n  - *Symptom*: Documentation references undefined terms\n  - *Cause*: New concepts introduced without updating glossary\n  - *Fix*: Add comprehensive definitions for all technical concepts\n\n- **Overloaded Terms**: Same word used with different meanings in different contexts\n  - *Symptom*: Confusion about what \"retry\" means in different components\n  - *Cause*: Generic terms lacking specific context definitions\n  - *Fix*: Create context-specific definitions (e.g., \"retry attempt\", \"retry policy\", \"retry delay\")\n"}