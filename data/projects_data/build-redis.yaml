id: build-redis
name: Build Your Own Redis
description: >-
  In-memory data store with RESP protocol, single-threaded event loop,
  multiple data structures, dual persistence, and pub/sub messaging.
difficulty: expert
estimated_hours: 65
essence: >-
  Single-threaded event loop (epoll/kqueue) multiplexing concurrent TCP client
  sessions, RESP binary protocol parsing, memory-efficient data structures
  (hash tables, linked lists, skip lists), time-based key expiration with
  lazy and active strategies, and dual persistence via fork-based RDB snapshots
  and append-only file logging.
why_important: >-
  Building Redis teaches fundamental systems programming—event-driven I/O
  multiplexing, binary protocol design, memory management, and persistence
  mechanisms—that are essential for backend infrastructure and database
  engineering roles.
learning_outcomes:
  - Implement a single-threaded event loop using epoll/kqueue for I/O multiplexing
  - Parse and generate RESP wire format for all five data types
  - Design an in-memory key-value store with thread-safe (via event loop) concurrent client access
  - Build key expiration with both lazy and active deletion strategies
  - Implement multiple data structures (strings, lists, sets, hashes)
  - Build RDB snapshot persistence with fork-based background saves
  - Design append-only file logging with fsync policies and log compaction
  - Implement publish/subscribe messaging with channel and pattern subscriptions
skills:
  - Event-Driven I/O (epoll/kqueue)
  - Binary Protocol Parsing
  - In-Memory Data Structures
  - Process Forking and Copy-on-Write
  - Persistence Mechanisms
  - Time-Based Eviction
  - Pub/Sub Messaging
tags:
  - build-from-scratch
  - data-structures
  - databases
  - expert
  - in-memory
  - key-value
  - networking
  - persistence
  - protocols
architecture_doc: architecture-docs/build-redis/index.md
languages:
  recommended:
    - C
    - Rust
    - Go
  also_possible:
    - Python
    - Java
resources:
  - name: Redis Protocol Specification (RESP)
    url: https://redis.io/docs/reference/protocol-spec/
    type: documentation
  - name: Build Your Own Redis (Book)
    url: https://build-your-own.org/redis/
    type: book
  - name: CodeCrafters Redis Challenge
    url: https://app.codecrafters.io/courses/redis/overview
    type: tool
  - name: Redis Internals Documentation
    url: https://redis.io/docs/reference/internals/
    type: documentation
prerequisites:
  - type: skill
    name: TCP/IP networking basics
  - type: skill
    name: Hash tables and data structures
  - type: skill
    name: File I/O and system calls
  - type: skill
    name: Process management (fork)
milestones:
  - id: build-redis-m1
    name: TCP Server & RESP Protocol
    description: >-
      Create a TCP server that accepts connections and implements full RESP
      protocol parsing and serialization. Respond to PING with PONG.
    acceptance_criteria:
      - "TCP server listens on a configurable port (default 6379) and accepts multiple client connections"
      - "RESP parser correctly decodes all five RESP types: Simple Strings (+), Errors (-), Integers (:), Bulk Strings ($), and Arrays (*)"
      - "RESP parser handles partial reads by buffering incomplete messages until a full RESP frame is received"
      - "RESP serializer produces wire-format output that redis-cli can parse correctly"
      - "PING command returns +PONG\\r\\n, verified by connecting with redis-cli"
      - "ECHO command returns the argument as a bulk string"
      - "Server handles client disconnection without crashing or leaking file descriptors"
    pitfalls:
      - "TCP is a stream protocol—a single recv() may contain partial messages or multiple messages; you must buffer and parse incrementally"
      - "RESP uses CRLF (\\r\\n) line endings, not just LF (\\n)—forgetting \\r breaks redis-cli compatibility"
      - "Bulk string length of -1 represents null, not an error—handle this as a distinct case"
      - "File descriptor leaks on client disconnect eventually exhaust the OS limit (ulimit -n)"
    concepts:
      - TCP socket lifecycle (bind, listen, accept, read, write, close)
      - RESP protocol framing with type prefix and CRLF delimiters
      - Buffered I/O for incremental protocol parsing
      - Client connection lifecycle management
    skills:
      - TCP socket programming
      - Protocol parsing with state machines
      - Buffered I/O
      - Connection management
    deliverables:
      - TCP server accepting client connections on configurable port
      - RESP parser decoding all five data types from byte stream
      - RESP serializer encoding responses into wire format
      - PING and ECHO command implementation
      - Client connection cleanup on disconnect
    estimated_hours: 6

  - id: build-redis-m2
    name: Single-Threaded Event Loop
    description: >-
      Replace the naive connection handling with a single-threaded event loop
      using epoll (Linux), kqueue (macOS), or equivalent I/O multiplexer.
      This is the architectural core of Redis's performance.
    acceptance_criteria:
      - "Event loop uses epoll/kqueue/poll to multiplex I/O across all connected clients in a single thread"
      - "No threads are used for client handling—all I/O is non-blocking and driven by the event loop"
      - "Server handles at least 100 concurrent clients without degradation, verified by a load test"
      - "Throughput is at least 10,000 PING/PONG operations per second with 10 concurrent clients (measured via redis-benchmark or custom tool)"
      - "Event loop integrates time-based callbacks for future use by expiration and background tasks"
    pitfalls:
      - "Blocking I/O in the event loop thread blocks ALL clients—every read/write must be non-blocking"
      - "Forgetting to re-arm edge-triggered epoll events causes silent connection stalls"
      - "Not handling EAGAIN/EWOULDBLOCK from non-blocking sockets causes data loss"
      - "Large command processing in the event loop blocks other clients; keep command execution fast"
    concepts:
      - I/O multiplexing allows a single thread to handle thousands of concurrent connections
      - epoll (Linux) and kqueue (macOS/BSD) are kernel-level event notification mechanisms
      - Non-blocking sockets return immediately instead of waiting for data
      - Event loop pattern: wait for events → process ready sockets → repeat
      - Time events enable periodic background tasks within the event loop
    skills:
      - epoll/kqueue system calls
      - Non-blocking I/O
      - Event loop architecture
      - Performance benchmarking
    deliverables:
      - Event loop using epoll/kqueue for I/O multiplexing
      - Non-blocking socket configuration for all client connections
      - Time event registration for periodic callbacks
      - Load test demonstrating concurrent client handling
      - Throughput benchmark measuring operations per second
    estimated_hours: 8

  - id: build-redis-m3
    name: Core Commands (GET/SET/DEL)
    description: >-
      Implement basic key-value operations with an in-memory hash map.
    acceptance_criteria:
      - "SET stores a key-value pair; subsequent GET returns the stored value as a bulk string"
      - "GET returns null bulk string ($-1\\r\\n) for non-existent keys"
      - "DEL removes one or more keys and returns integer count of keys actually deleted"
      - "SET supports NX (set only if not exists) and XX (set only if exists) flags"
      - "SET supports EX (seconds) and PX (milliseconds) expiration options"
      - "INCR/DECR atomically increment/decrement integer values, returning error for non-integer values"
      - "MSET/MGET set/get multiple keys in a single command"
      - "Keys and values are binary-safe (can contain null bytes)"
    pitfalls:
      - "Not handling binary-safe strings (assuming null-terminated C strings) corrupts data with embedded nulls"
      - "Case sensitivity: Redis keys are case-sensitive; command names are case-insensitive"
      - "INCR on a non-existent key should treat it as 0 and return 1"
      - "INCR on a value exceeding 64-bit signed integer range must return an error"
    concepts:
      - Hash table with chaining or open addressing for O(1) key lookup
      - Command dispatch pattern: parse command name → route to handler
      - Binary-safe string storage (length-prefixed, not null-terminated)
      - Atomic operations via single-threaded event loop
    skills:
      - Hash table implementation
      - Command routing
      - Binary-safe string handling
      - Atomic integer operations
    deliverables:
      - In-memory hash table storing key-value pairs
      - SET command with NX, XX, EX, PX options
      - GET command with null response for missing keys
      - DEL command removing keys and returning count
      - INCR/DECR commands with integer validation
      - MSET/MGET for multi-key operations
    estimated_hours: 4

  - id: build-redis-m4
    name: Key Expiration (TTL)
    description: >-
      Add key expiration support with both lazy and active deletion strategies.
    acceptance_criteria:
      - "EXPIRE sets TTL in seconds on existing key, returning 1 on success, 0 if key does not exist"
      - "PEXPIRE sets TTL in milliseconds"
      - "TTL returns remaining seconds (-1 if no expiry, -2 if key does not exist)"
      - "GET on an expired key returns null (lazy deletion: key is removed on access)"
      - "Active expiration runs periodically in the event loop, sampling 20 random keys and deleting expired ones; if >25% expired, repeat immediately"
      - "PERSIST removes expiration from a key, making it permanent"
      - "Expiration uses absolute timestamps internally (not relative TTL) to handle clock monotonicity"
    pitfalls:
      - "Using relative remaining time instead of absolute expiration timestamp causes drift under load"
      - "Without active expiration, keys that are never accessed consume memory indefinitely"
      - "Active expiration must be time-bounded per cycle (e.g., max 25ms) to avoid blocking the event loop"
      - "Clock changes (NTP adjustments) can cause premature or delayed expiration—use monotonic clock where available"
    concepts:
      - Lazy deletion: check expiry on every key access
      - Active deletion: periodic probabilistic sampling of keys for expiration
      - Absolute timestamp storage vs relative TTL
      - Event loop time events for periodic background tasks
    skills:
      - Time-based eviction
      - Probabilistic sampling
      - Background task scheduling
      - Timestamp arithmetic
    deliverables:
      - EXPIRE and PEXPIRE commands setting expiration timestamps
      - TTL and PTTL commands returning remaining time
      - Lazy expiration removing expired keys on access
      - Active expiration periodic task sampling and deleting expired keys
      - PERSIST command removing key expiration
    estimated_hours: 4

  - id: build-redis-m5
    name: Data Structures (List, Set, Hash)
    description: >-
      Implement Redis compound data structures beyond simple strings.
    acceptance_criteria:
      - "LPUSH/RPUSH prepend/append elements to a list; LPOP/RPOP remove from head/tail"
      - "LRANGE returns list elements within start and stop indices, supporting negative indices (-1 = last element)"
      - "SADD adds unique members to a set, returning count of newly added elements"
      - "SMEMBERS returns all members of a set; SISMEMBER returns 1 or 0 for membership check"
      - "HSET stores field-value pairs in a hash; HGET retrieves by field; HGETALL returns all field-value pairs"
      - "Operations on wrong type (e.g., LPUSH on a string key) return WRONGTYPE error without modifying data"
      - "List operations are O(1) for push/pop (implemented via doubly-linked list or deque, not array)"
    pitfalls:
      - "Using array/vector for lists makes LPUSH O(n)—use doubly-linked list or VecDeque"
      - "LRANGE with negative indices requires careful bounds calculation (start=-2, stop=-1 = last two elements)"
      - "Type tag per key is mandatory; missing type checks cause undefined behavior and data corruption"
      - "Sets must enforce uniqueness; using a list instead of a hash set violates O(1) membership semantics"
    concepts:
      - Type-tagged keys: each key has a type (string, list, set, hash) checked before operations
      - Doubly-linked list for O(1) head/tail operations
      - Hash set for O(1) membership testing
      - Nested hash table for hash data type
    skills:
      - Complex data structure implementation
      - Type system design
      - Negative index arithmetic
      - Error handling for type mismatches
    deliverables:
      - List type with LPUSH, RPUSH, LPOP, RPOP, LRANGE, LLEN
      - Set type with SADD, SREM, SMEMBERS, SISMEMBER, SCARD
      - Hash type with HSET, HGET, HDEL, HGETALL, HLEN
      - Type checking returning WRONGTYPE error for mismatched operations
    estimated_hours: 6

  - id: build-redis-m6
    name: RDB Snapshot Persistence
    description: >-
      Implement point-in-time snapshots. SAVE blocks; BGSAVE forks a child
      process leveraging copy-on-write for non-blocking persistence.
    acceptance_criteria:
      - "SAVE serializes all keys, values, types, and TTLs to a custom binary file format and blocks until complete"
      - "BGSAVE forks a child process that writes the snapshot while the parent continues serving clients"
      - "Fork-based BGSAVE leverages OS copy-on-write so memory is shared until parent modifies a page"
      - "RDB file is written to a temporary file and atomically renamed on completion to prevent corruption from incomplete writes"
      - "On startup, server loads RDB file and restores all keys, values, and unexpired TTLs"
      - "Automatic save triggers when at least N changes occur within M seconds (configurable, e.g., 'save 900 1' = save after 900s if ≥1 change)"
      - "Expired keys are NOT written to the RDB file"
    pitfalls:
      - "SAVE blocks the event loop—all clients are frozen during save; BGSAVE is the production-grade approach"
      - "Not using fork() for BGSAVE means you must lock the data structure during save, defeating the purpose"
      - "Incomplete RDB writes (crash during save) corrupt the file—always write to temp file and atomic rename"
      - "fork() on large datasets can cause latency spike from page table duplication; monitor and document"
      - "Languages without fork() (Go, Java) must use alternative approaches (separate process, snapshot-on-copy)"
    concepts:
      - Process forking creates a child with a copy-on-write view of parent memory
      - Atomic file operations (write to temp, fsync, rename) prevent partial writes
      - Binary serialization with type tags and length prefixes
      - Copy-on-write allows parent to continue serving while child writes
    skills:
      - Process forking and IPC
      - Binary file format design
      - Atomic filesystem operations
      - Serialization
    deliverables:
      - Custom binary RDB file format with type tags, key-value serialization, and TTL encoding
      - SAVE command writing blocking snapshot
      - BGSAVE command forking child process for non-blocking snapshot
      - RDB loading on startup restoring database state
      - Automatic save triggers based on change count thresholds
    estimated_hours: 7

  - id: build-redis-m7
    name: AOF Persistence
    description: >-
      Implement Append-Only File logging for write durability, with configurable
      fsync policies and log compaction via rewrite.
    acceptance_criteria:
      - "Every write command is appended to the AOF file in RESP wire format"
      - "AOF replay on startup reconstructs database state by re-executing all logged commands"
      - "Fsync policy supports three modes: 'always' (fsync every write), 'everysec' (fsync once per second), 'no' (OS-controlled)"
      - "BGREWRITEAOF rewrites the AOF to a compact equivalent of the current database state using a forked child process"
      - "During BGREWRITEAOF, new write commands are buffered and appended to the rewritten AOF after the child completes"
      - "BGSAVE and BGREWRITEAOF are mutually exclusive—if one is running, the other is queued"
      - "If both AOF and RDB exist on startup, AOF takes priority for recovery (only when AOF is enabled)"
    pitfalls:
      - "AOF grows unbounded without rewrite—a database with 1M SET operations on the same key stores 1M lines instead of 1"
      - "fsync='always' is durable but reduces throughput by 100x; 'everysec' is the practical default, accepting up to 1s of data loss"
      - "During BGREWRITEAOF, new writes must go to BOTH the old AOF and a rewrite buffer; missing either causes data loss"
      - "BGSAVE and BGREWRITEAOF running simultaneously cause excessive I/O and fork overhead—serialize them"
      - "Buffered writes without fsync can lose data on power failure; document the durability guarantees of each mode"
    concepts:
      - Write-ahead logging appends operations before acknowledging client
      - fsync forces OS to flush file buffers to disk
      - Log compaction rewrites the log to contain only the minimal commands for current state
      - Rewrite buffer captures writes during background rewrite for later append
    skills:
      - Write-ahead logging
      - fsync and durability
      - Background process coordination
      - Log compaction
    deliverables:
      - AOF writer appending every write command in RESP format
      - AOF replay reconstructing database state on startup
      - Configurable fsync policy (always, everysec, no)
      - BGREWRITEAOF with forked child and rewrite buffer
      - Mutual exclusion between BGSAVE and BGREWRITEAOF
      - AOF priority over RDB for recovery when AOF is enabled
    estimated_hours: 7

  - id: build-redis-m8
    name: Pub/Sub
    description: >-
      Implement publish/subscribe messaging with channel and pattern subscriptions.
    acceptance_criteria:
      - "SUBSCRIBE registers client on one or more channels; client receives a subscription confirmation message per channel"
      - "PUBLISH sends a message to all subscribers of the target channel and returns the number of receivers"
      - "UNSUBSCRIBE removes client from specified channels (or all channels if none specified)"
      - "PSUBSCRIBE matches channels using glob patterns (e.g., 'news.*' matches 'news.sports')"
      - "A subscribed client can only issue SUBSCRIBE, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, and PING commands"
      - "Client disconnection automatically removes all subscriptions without leaking channel state"
    pitfalls:
      - "Subscribed clients entering a special mode that blocks other commands is intentional Redis behavior—enforce it"
      - "Memory leaks from not cleaning up subscription state on client disconnect"
      - "PUBLISH must iterate all subscribers synchronously in the event loop—slow subscribers cannot block delivery to fast ones (use output buffer limits)"
      - "Pattern matching with glob characters (*, ?, []) must be implemented correctly; naive substring matching is wrong"
    concepts:
      - Pub/Sub messaging pattern decouples producers from consumers
      - Channel subscription management using hash map of channel → subscriber set
      - Glob pattern matching for wildcard channel subscriptions
      - Connection state modes (normal vs subscribed)
    skills:
      - Subscription management
      - Pattern matching
      - Stateful connection handling
      - Broadcasting
    deliverables:
      - SUBSCRIBE and UNSUBSCRIBE commands managing channel subscriptions
      - PUBLISH command broadcasting messages to channel subscribers
      - PSUBSCRIBE and PUNSUBSCRIBE for glob-pattern channel matching
      - Subscription state enforcement limiting commands in subscribed mode
      - Automatic cleanup on client disconnection
    estimated_hours: 5

  - id: build-redis-m9
    name: Transactions (MULTI/EXEC)
    description: >-
      Implement transaction support with MULTI/EXEC command queuing and
      WATCH-based optimistic locking.
    acceptance_criteria:
      - "MULTI begins a transaction; subsequent commands are queued (returning +QUEUED) instead of executed immediately"
      - "EXEC executes all queued commands atomically (no other client commands interleave) and returns an array of results"
      - "DISCARD aborts the transaction and clears the command queue"
      - "WATCH key(s) before MULTI enables optimistic locking—EXEC returns null if any watched key was modified by another client"
      - "Errors during queueing (e.g., wrong number of arguments) are reported at queue time; EXEC still executes remaining valid commands"
      - "Command errors during EXEC (e.g., WRONGTYPE) do not abort the entire transaction; each command result is independent"
    pitfalls:
      - "MULTI/EXEC is NOT equivalent to database transactions with rollback—there is no rollback; all commands execute or none execute (if WATCH fails)"
      - "WATCH must track key modification by ANY client, not just the watching client—use a watched-key registry checked on every write"
      - "Queued commands consume memory—set a limit on queue size to prevent abuse"
      - "Nested MULTI (calling MULTI inside MULTI) should return an error, not create nested transactions"
    concepts:
      - Command queuing defers execution until EXEC
      - Atomic execution means no interleaving with other clients (single-threaded guarantees this)
      - WATCH implements optimistic concurrency control via key version tracking
      - Redis transactions have no rollback—partial failures are possible
    skills:
      - Command queuing
      - Optimistic concurrency
      - Connection state management
      - Atomic execution semantics
    deliverables:
      - MULTI command entering transaction mode and queuing subsequent commands
      - EXEC command executing all queued commands and returning results array
      - DISCARD command aborting transaction and clearing queue
      - WATCH/UNWATCH commands implementing optimistic locking on key modifications
    estimated_hours: 5

  - id: build-redis-m10
    name: Cluster Mode (Hash Slot Sharding)
    description: >-
      Implement horizontal scaling with hash slot-based sharding across
      multiple nodes.
    acceptance_criteria:
      - "16384 hash slots are distributed across cluster nodes, with each node owning a contiguous range of slots"
      - "Key-to-slot mapping uses CRC16(key) mod 16384, producing deterministic routing"
      - "MOVED response (e.g., -MOVED 3999 127.0.0.1: 7001) redirects clients to the correct node for a given key"
      - "ASK response handles in-progress slot migration, directing the client to retry at the migration target"
      - "Cluster nodes exchange topology information via a gossip protocol with periodic PING/PONG messages"
      - "Hash tags (e.g., {user}.name and {user}.email) ensure related keys map to the same slot"
      - "Cross-slot commands (e.g., MGET on keys in different slots) return CROSSSLOT error"
    pitfalls:
      - "Not handling key migration during slot rebalancing causes data inconsistency"
      - "Cross-slot operations (MGET across slots) cannot be supported in cluster mode without multi-key command restrictions"
      - "Network partitions can cause split-brain—implement a quorum-based or leader-based approach for partition detection"
      - "Gossip protocol must handle node failure detection within bounded time (configurable failure timeout)"
      - "Hash tags must be parsed correctly: only the first occurrence of {…} is used for hashing"
    concepts:
      - Hash slot partitioning divides keyspace into 16384 slots for flexible rebalancing
      - CRC16 hash function maps keys to slots deterministically
      - MOVED/ASK redirects enable smart client-side routing
      - Gossip protocol disseminates cluster topology across nodes
      - Hash tags enable multi-key operations on co-located keys
    skills:
      - Distributed hash table design
      - Inter-node communication
      - Cluster topology management
      - Slot migration
    deliverables:
      - Hash slot assignment distributing 16384 slots across nodes
      - CRC16-based key-to-slot mapping with hash tag support
      - MOVED and ASK redirect responses for client routing
      - Gossip protocol exchanging node state via PING/PONG
      - Slot migration support with ASK-based client redirection
      - CROSSSLOT error for multi-key commands spanning slots
    estimated_hours: 13