id: config-parser
name: Config File Parser
description: Parse INI, TOML, and YAML-subset configuration formats
difficulty: intermediate
estimated_hours: "18-28"
essence: >
  Character stream tokenization through finite state machines, recursive
  descent parsing translating grammar productions into mutually-recursive
  functions, and context-sensitive indentation handling that transforms
  three syntactically distinct formats (flat INI, table-based TOML,
  whitespace-hierarchical YAML subset) into unified in-memory data
  structures.
why_important: >
  Configuration file parsing is ubiquitous in software systems and building
  parsers from scratch teaches fundamental compiler frontend techniques
  (lexing, tokenization, recursive descent) that transfer directly to DSL
  design, data serialization, and language tooling.
learning_outcomes:
  - Implement a lexer/tokenizer that converts character streams into semantic tokens
  - Design recursive descent parser functions mapping grammar rules to code
  - Build finite state machines for recognizing patterns in configuration syntax
  - Handle indentation-based parsing for hierarchical data structures
  - Transform parsed tokens into language-native data structures (maps, arrays, nested objects)
  - Implement parser error reporting with line and column numbers
  - Validate parsed data against format specifications and handle edge cases
  - Compare tradeoffs between hand-written parsers and parser generator tools
skills:
  - Lexical Analysis
  - Recursive Descent Parsing
  - Grammar Design
  - Tokenization
  - State Machine Implementation
  - Data Structure Mapping
  - Format Specification Compliance
  - Parser Error Handling
tags:
  - compilers
  - configuration
  - formats
  - go
  - intermediate
  - merging
  - parsing
  - python
  - rust
  - validation
architecture_doc: architecture-docs/config-parser/index.md
languages:
  recommended:
    - Python
    - Go
    - Rust
  also_possible:
    - JavaScript
    - C
resources:
  - name: TOML Specification v1.0.0
    url: "https://toml.io/en/v1.0.0"
    type: specification
  - name: INI File Format
    url: "https://en.wikipedia.org/wiki/INI_file"
    type: reference
  - name: YAML 1.2 Specification
    url: "https://yaml.org/spec/1.2.2/"
    type: specification
  - name: Writing a Parser in Python
    url: "https://www.freecodecamp.org/news/how-to-write-a-parser-in-python/"
    type: tutorial
prerequisites:
  - type: skill
    name: String manipulation
  - type: skill
    name: Data structures (maps, lists, trees)
  - type: skill
    name: Recursive thinking
milestones:
  - id: config-parser-m1
    name: INI Parser
    description: Parse INI files with sections, key-value pairs, and comments.
    estimated_hours: "3-4"
    concepts:
      - Line-based parsing
      - Section scoping
      - Type coercion
    skills:
      - String parsing and manipulation
      - Pattern matching
      - Configuration file I/O
      - Data validation
    acceptance_criteria:
      - "Parse [section] headers creating nested dictionary structure; section names are case-sensitive"
      - "Parse key=value and key: value pairs with whitespace trimming around both key and value"
      - "Handle keys before any section header as belonging to a 'DEFAULT' or global section"
      - "Handle ; and # full-line comments by ignoring them; handle inline comments after values (separated by ; or #)"
      - "Support quoted string values (single and double quotes) with proper escape sequences (\\n, \\t, \\\\, \\\")"
      - "Do NOT parse = or : inside quoted strings as key-value delimiters"
      - "Report parsing errors with line numbers for malformed lines"
      - "Return nested dictionary: {section_name: {key: value, ...}, ...}"
      - "Verify by round-tripping: parse then serialize back and re-parse; result must be identical"
    pitfalls:
      - "INI has no formal spec; explicitly document which dialect you implement (e.g., Python configparser compatible)"
      - "Forgetting to handle inline comments after values (e.g., 'key = value ; comment')"
      - "'=' inside quoted strings must not split key from value"
      - "Keys outside any section are common in some INI dialects but not others; decide and document"
      - "Multi-line values (continuation lines) exist in some dialects; decide whether to support"
    deliverables:
      - Section header parser with bracket notation
      - Key-value parser for both = and : delimiters
      - Comment handling (full-line and inline)
      - Quoted string handling with escape sequences
      - Error reporting with line numbers

  - id: config-parser-m2
    name: TOML Tokenizer
    description: Build a lexer/tokenizer for TOML format per the v1.0.0 specification.
    estimated_hours: "4-5"
    concepts:
      - Lexical analysis
      - State machines
      - Token types
    skills:
      - Tokenization and lexical analysis
      - Finite state machine implementation
      - Character stream processing
      - Unicode string handling
    acceptance_criteria:
      - "Tokenize all TOML grammar elements: brackets, dots, equals, commas, strings, numbers, booleans, datetime"
      - "Handle basic strings (double-quoted with escapes), literal strings (single-quoted, no escapes), and their multiline variants (triple-quoted)"
      - "Recognize integers (decimal, hex 0x, octal 0o, binary 0b) with underscore separators (e.g., 1_000)"
      - "Recognize floats including special values inf and nan"
      - "Recognize booleans (true, false) as distinct tokens"
      - "Recognize RFC 3339 date-time values (offset, local date-time, local date, local time)"
      - "Track line and column numbers in every token for error reporting"
      - "Reject invalid tokens with clear error messages including position"
    pitfalls:
      - "TOML multiline basic strings strip the first newline after opening quotes but not subsequent ones"
      - "Literal strings do NOT process escape sequences; backslash is literal"
      - "Integer underscores are allowed between digits only (not leading, trailing, or consecutive)"
      - "Date-time values can look like bare keys or numbers during initial scanning; context matters"
    deliverables:
      - Token type definitions for all TOML grammar elements
      - String literal tokenizer handling 4 string variants (basic, literal, multiline basic, multiline literal)
      - Numeric literal tokenizer handling integers (4 bases), floats, inf, nan
      - Date-time tokenizer for RFC 3339 variants
      - Position-tracked token stream with line and column metadata

  - id: config-parser-m3
    name: TOML Parser
    description: Build recursive descent parser consuming TOML tokens into nested data structures.
    estimated_hours: "5-6"
    concepts:
      - Recursive descent parsing
      - Table scoping
      - Nested data structures
    skills:
      - Recursive parsing algorithms
      - Namespace and scope management
      - Complex data structure construction
      - Specification compliance testing
    acceptance_criteria:
      - "Parse [table] and [table.subtable] headers creating nested dictionary path"
      - "Parse [[array.of.tables]] creating or appending to lists of dictionaries"
      - "Parse inline tables { key = value, ... } as immutable (cannot be extended after definition)"
      - "Parse inline arrays [ 1, 2, 3 ] supporting mixed types and nested structures"
      - "Handle dotted keys (e.g., physical.color = \"orange\") creating intermediate tables implicitly"
      - "Reject duplicate key definitions with clear error messages (TOML spec forbids key redefinition)"
      - "Reject defining a key as both a table and a value"
      - "Pass the official TOML test suite (https: //github.com/toml-lang/toml-test) for valid inputs; reject all invalid inputs"
    pitfalls:
      - "Cannot redefine a key that already exists; this includes implicit tables created by dotted keys"
      - "Array of tables ([[x]]) and inline arrays ([1,2]) have completely different syntax and semantics"
      - "Inline tables are immutable; you cannot add keys to them via later [table] headers"
      - "Super-tables can be implicitly defined and later explicitly defined, but not vice versa"
    deliverables:
      - Table header parser with nested dotted key path resolution
      - Array of tables parser with double-bracket syntax
      - Inline table and inline array parsers
      - Key redefinition detection and rejection
      - Full TOML v1.0.0 specification compliance for supported features

  - id: config-parser-m4
    name: "YAML Subset Parser: Block Mappings and Sequences"
    description: Parse a minimal YAML subset supporting block-style mappings and sequences only.
    estimated_hours: "4-5"
    concepts:
      - Indentation-sensitive parsing
      - Stack-based nesting
      - Restricted type inference
    skills:
      - Indentation-based syntax parsing
      - Context-aware parsing with stack management
      - Controlled type inference
    acceptance_criteria:
      - "Parse block mappings (key: value) with indentation determining nesting depth"
      - "Parse block sequences (- item) with indentation determining nesting depth"
      - "Use consistent indentation (spaces only; reject tabs with clear error per YAML spec)"
      - "Handle quoted strings (single and double) preserving exact content"
      - "Handle unquoted scalars with YAML 1.2 Core Schema type inference ONLY: null (null, ~), boolean (true, false only—NOT yes/no/on/off), integer (decimal), float (decimal, inf, nan)"
      - "All other unquoted values are treated as strings (safe default)"
      - "Handle comments (# to end of line)"
      - "Explicitly OUT OF SCOPE: flow style, multi-line scalars (| and >), anchors/aliases, tags, merge keys"
      - "Report errors with line numbers for indentation violations or malformed syntax"
      - "Verify against PyYAML output for a test suite of 10+ YAML files (block-style only)"
    pitfalls:
      - "Tabs are forbidden for indentation in YAML; detect and reject with clear error"
      - "YAML 1.1 type inference (yes/no/on/off as booleans) caused the infamous 'Norway problem'; restrict to YAML 1.2 Core Schema"
      - "Indentation must be consistent within a level but different levels can use different amounts"
      - "Empty values after colon (key: ) should produce null, not empty string"
      - "Nested mappings inside sequences and vice versa create complex indentation tracking"
    deliverables:
      - Indentation tracker using a stack to manage nesting depth
      - Block mapping parser for key-value pairs
      - Block sequence parser for list items
      - Restricted YAML 1.2 Core Schema type inference
      - Error reporter with line numbers

  - id: config-parser-m5
    name: Unified API and Format Detection
    description: Build a unified interface that auto-detects format and parses any supported config file.
    estimated_hours: "2-3"
    concepts:
      - Format detection heuristics
      - API design
      - Data structure normalization
    skills:
      - API design and abstraction
      - File format detection
      - Integration testing
    acceptance_criteria:
      - "Auto-detect format from file extension (.ini, .toml, .yaml/.yml) with fallback to content heuristics"
      - "Provide a single parse(filepath) function returning a normalized nested dictionary"
      - "Provide format-specific parse_ini(), parse_toml(), parse_yaml() functions for explicit format selection"
      - "All parsers return the same data structure type (nested dictionaries with lists and scalar values)"
      - "Error messages include the detected format, file path, line number, and description"
      - "Write an integration test suite with at least 5 files per format covering edge cases"
    pitfalls:
      - "Content-based format detection is unreliable; prefer extension-based detection"
      - "INI values are always strings unless you add type coercion; TOML and YAML have native types—document the difference"
      - "Normalization across formats may lose format-specific information (e.g., TOML datetime types)"
    deliverables:
      - Format detection from file extension and content heuristics
      - Unified parse() API returning normalized data structures
      - Format-specific parser entry points
      - Integration test suite covering all three formats