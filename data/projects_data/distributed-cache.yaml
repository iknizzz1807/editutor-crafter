id: distributed-cache
name: Distributed Cache
description: >
  Build a distributed caching system with consistent hashing,
  replication, and cache invalidation strategies. Learn how Redis
  Cluster and Memcached scale horizontally.

difficulty: advanced
estimated_hours: 35-50
domain: distributed

essence: >
  Horizontal scaling through consistent hashing with virtual nodes for
  balanced key distribution, replica management for fault tolerance,
  cache eviction policies (LRU/LFU/TTL), and invalidation strategies
  (write-through, write-behind, cache-aside) for data consistency.

why_important: >
  Distributed caching is fundamental to high-traffic systems like
  social networks, e-commerce, and real-time applications. Understanding
  cache architecture is valuable at $140K-250K+ for backend and
  infrastructure engineers.

learning_outcomes:
  - Implement consistent hashing with virtual nodes
  - Build LRU and LFU eviction policies
  - Implement replica management and failover
  - Handle cache stampede and thundering herd
  - Build TTL-based expiration with lazy eviction
  - Implement write-through and write-behind patterns
  - Handle network partitions and eventual consistency
  - Measure cache hit rate and latency percentiles

skills:
  - Consistent Hashing
  - Cache Eviction Policies
  - Replication
  - Failover Handling
  - Cache Patterns
  - Memory Management
  - Network Partitions
  - Performance Metrics

tags:
  - advanced
  - caching
  - distributed
  - hashing
  - memcached
  - redis
  - replication
  - scalability

languages:
  recommended:
    - Go
    - Rust
    - Java
  also_possible:
    - C++
    - Python

resources:
  - name: "Redis Cluster Specification"
    url: https://redis.io/docs/management/scaling/
    type: documentation
  - name: "Consistent Hashing Paper"
    url: https://www.akamai.com/site/en/documents/technical-paper/consistent-hashing-and-random-trees-distributed-caching-protocols-for-mitigating-hot-spots-on-the-web-technical-publication.pdf
    type: paper
  - name: "Memcached Protocol"
    url: https://github.com/memcached/memcached/blob/master/doc/protocol.txt
    type: documentation
  - name: "Cache Patterns"
    url: https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside
    type: article

prerequisites:
  - type: project
    id: memory-pool
    name: Memory Pool Allocator
  - type: skill
    name: Network programming (TCP sockets)
  - type: skill
    name: Hash tables and data structures
  - type: skill
    name: Concurrency primitives

milestones:
  - id: distributed-cache-m1
    name: Single Node Cache with Eviction
    description: >
      Build an in-memory cache with configurable eviction policies
      and TTL expiration.
    acceptance_criteria:
      - Key-value store with get, set, delete operations
      - LRU eviction when cache reaches capacity limit
      - LFU eviction as alternative policy
      - TTL-based expiration with lazy eviction on access
      - Background cleanup for expired entries (optional)
      - Thread-safe operations with proper locking
      - Memory usage stays within configured limit
    pitfalls:
      - "LRU implementation needs O(1) access; use hashmap + doubly linked list"
      - "TTL cleanup can cause latency spikes; spread over time"
      - "Lock contention under high throughput; consider sharded locks"
      - Memory fragmentation from varying value sizes
      - Not handling large values can cause OOM
    concepts:
      - Cache eviction policies
      - Time-to-live expiration
      - Thread-safe data structures
      - Memory management
    skills:
      - LRU/LFU implementation
      - TTL handling
      - Concurrency control
      - Memory limits
    deliverables:
      - In-memory cache with get/set/delete
      - LRU and LFU eviction policies
      - TTL expiration support
      - Thread-safe implementation
      - Memory limit enforcement
    estimated_hours: "8-10"

  - id: distributed-cache-m2
    name: Consistent Hashing & Sharding
    description: >
      Implement consistent hashing with virtual nodes for balanced
      key distribution across multiple cache nodes.
    acceptance_criteria:
      - Consistent hashing ring with configurable virtual nodes per server
      - Key distribution balanced within 10% variance across nodes
      - Node addition moves only K/N keys (minimal remapping)
      - Node removal handled gracefully
      - Client-side sharding logic
      - Support for weighted nodes (different capacities)
      - Hash function configurable (murmurhash, fnv, etc.)
    pitfalls:
      - Uneven distribution without virtual nodes
      - Hash function choice affects distribution quality
      - Node weight calculation affects balance
      - Client and server must agree on hash function
      - Ring visualization helps debug distribution issues
    concepts:
      - Consistent hashing
      - Virtual nodes
      - Key distribution
      - Minimal remapping
    skills:
      - Hash ring implementation
      - Distribution analysis
      - Node management
      - Weighted hashing
    deliverables:
      - Consistent hash ring implementation
      - Virtual node configuration
      - Key distribution analysis
      - Node add/remove handling
      - Client-side sharding
    estimated_hours: "8-10"

  - id: distributed-cache-m3
    name: Replication & Failover
    description: >
      Implement replica management with primary-secondary replication
      and automatic failover on node failure.
    acceptance_criteria:
      - Configurable replication factor (N replicas per key)
      - Primary-secondary replication with write to primary
      - Reads can go to any replica (eventual consistency)
      - Automatic failover when primary fails
      - Replica promotion preserves data consistency
      - Heartbeat mechanism for failure detection
      - Configurable failure timeout and retry logic
    pitfalls:
      - "Split-brain during network partition; use quorum"
      - Replica lag causes stale reads
      - Failover during write causes data loss
      - False positive failure detection from transient issues
      - Replica synchronization after network recovery
    concepts:
      - Primary-secondary replication
      - Failover mechanisms
      - Failure detection
      - Eventual consistency
    skills:
      - Replication implementation
      - Failure detection
      - Automatic failover
      - State synchronization
    deliverables:
      - Replica configuration
      - Primary election on failover
      - Heartbeat failure detection
      - Replica synchronization
      - Consistency guarantees documented
    estimated_hours: "10-12"

  - id: distributed-cache-m4
    name: Cache Patterns & Stampede Prevention
    description: >
      Implement cache-aside pattern, write-through, write-behind,
      and thundering herd protection.
    acceptance_criteria:
      - Cache-aside pattern: application manages cache explicitly
      - Write-through: writes go to cache and backend atomically
      - Write-behind: writes buffered and flushed asynchronously
      - Thundering herd protection with request coalescing
      - Cache warming for predictable latency
      - Cache stampede prevention with probabilistic early expiration
      - "Metrics: hit rate, miss rate, latency percentiles"
    pitfalls:
      - Thundering herd on cache miss can overwhelm backend
      - Write-behind loses data on crash before flush
      - Write-through doubles latency
      - Cache warming can cause startup spikes
      - Probabilistic expiration needs tuning
    concepts:
      - Cache patterns (aside, through, behind)
      - Thundering herd
      - Request coalescing
      - Probabilistic early expiration
    skills:
      - Cache pattern implementation
      - Stampede prevention
      - Request coalescing
      - Metrics collection
    deliverables:
      - Cache-aside implementation
      - Write-through support
      - Write-behind buffering
      - Thundering herd protection
      - Cache metrics dashboard
    estimated_hours: "8-10"

  - id: distributed-cache-m5
    name: Network Protocol & Client Library
    description: >
      Define wire protocol and build client library supporting
      connection pooling and automatic retries.
    acceptance_criteria:
      - Binary or text protocol specification documented
      - Support for get, set, delete, incr, decr operations
      - Connection pooling with configurable pool size
      - Automatic retries with exponential backoff
      - Client-side consistent hashing
      - Pipeline support for batch operations
      - Protocol compatible with simple telnet test
    pitfalls:
      - Protocol versioning for future compatibility
      - Connection pool exhaustion under load
      - Retry storms when cluster is unhealthy
      - Pipeline memory buffering limits
      - Client timeout vs server timeout mismatch
    concepts:
      - Wire protocol design
      - Connection pooling
      - Retry strategies
      - Pipelining
    skills:
      - Protocol implementation
      - Connection management
      - Client library design
      - Error handling
    deliverables:
      - Protocol specification
      - Server protocol handler
      - Client library
      - Connection pool
      - Pipeline support
    estimated_hours: "8-10"
