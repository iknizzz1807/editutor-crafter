id: dma-engine
name: DMA Engine
description: >
  Implement a Direct Memory Access (DMA) engine for high-throughput
  data transfers. Learn DMA controller programming, scatter-gather
  lists, ring buffer management, and zero-copy data movement.

difficulty: advanced
estimated_hours: 40-55
domain: systems

essence: >
  Offloading memory copy operations from the CPU to dedicated hardware
  controllers, scatter-gather I/O for non-contiguous buffer handling,
  descriptor ring management for async operation submission, and
  interrupt-driven completion notification for zero-CPU-overhead transfers.

why_important: >
  DMA is fundamental to high-performance I/O in operating systems, embedded
  systems, and hardware accelerators. Understanding DMA enables work in driver
  development, high-performance networking (100Gbps+), storage systems, and
  hardware acceleration at $140K-250K+ for systems/firmware engineers.

learning_outcomes:
  - Program DMA controllers for memory-to-memory transfers
  - Implement scatter-gather lists for non-contiguous buffers
  - Build descriptor ring buffers for async operation queuing
  - Handle DMA completion via interrupts and polling
  - Implement cache coherency management for DMA buffers
  - Build zero-copy data paths using DMA
  - Debug DMA-related issues (alignment, coherency, overflow)
  - Measure and optimize DMA throughput

skills:
  - DMA Controller Programming
  - Scatter-Gather I/O
  - Ring Buffer Management
  - Cache Coherency
  - Zero-Copy Design
  - Interrupt Handling
  - Memory Alignment
  - Performance Optimization

tags:
  - advanced
  - dma
  - embedded
  - hardware
  - io
  - kernel
  - performance
  - zero-copy

languages:
  recommended:
    - C
    - Rust
  also_possible:
    - C++

resources:
  - name: "Linux DMA Engine Documentation"
    url: https://www.kernel.org/doc/html/latest/driver-api/dmaengine.html
    type: documentation
  - name: "Understanding DMA"
    url: https://developer.arm.com/documentation/den0024/a/Direct-Memory-Access
    type: documentation
  - name: "Scatter-Gather I/O"
    url: https://man7.org/linux/man-pages/man2/readv.2.html
    type: documentation

prerequisites:
  - type: skill
    name: C programming with pointers
  - type: skill
    name: Memory-mapped I/O concepts
  - type: skill
    name: Interrupt handling basics
  - type: skill
    name: Understanding of CPU cache hierarchy

milestones:
  - id: dma-engine-m1
    name: Basic DMA Memory Copy
    description: >
      Implement basic DMA-controlled memory-to-memory transfers,
      handling buffer alignment and completion detection.
    acceptance_criteria:
      - DMA controller registers are correctly mapped and configured
      - Source and destination buffers are aligned to DMA alignment requirements (typically 4-8 bytes minimum, often cache-line aligned)
      - DMA transfer is initiated by writing to control registers
      - Completion is detected either via polling status register or interrupt
      - Transfer correctness verified by comparing source and destination buffers
      - Performance comparison shows DMA outperforms CPU memcpy for transfers > 4KB
    pitfalls:
      - Buffer alignment requirements vary by DMA controller; unaligned buffers cause silent corruption or errors
      - Not invalidating/cleaning caches before/after DMA causes stale data issues
      - Polling in a tight loop wastes CPU; use interrupts or sleep-polling for long transfers
      - DMA transfers are non-atomic from CPU perspective; avoid concurrent access to DMA buffers
      - Forgetting to wait for completion before reusing buffers causes data corruption
    concepts:
      - DMA controller register interface
      - Memory alignment constraints
      - Cache coherency with DMA
      - Synchronous vs asynchronous completion
    skills:
      - Register-level programming
      - Memory alignment handling
      - Cache management
      - Performance measurement
    deliverables:
      - DMA controller abstraction with init, transfer, wait APIs
      - Aligned buffer allocation helper
      - Memory-to-memory copy implementation
      - Performance benchmark vs CPU memcpy
    estimated_hours: "8-10"

  - id: dma-engine-m2
    name: Scatter-Gather DMA
    description: >
      Implement scatter-gather DMA for transferring non-contiguous
      memory regions in a single operation.
    acceptance_criteria:
      - Scatter-gather descriptor chain links multiple buffer segments into one logical transfer
      - Each descriptor contains address, length, and next-descriptor pointer
      - Circular descriptor ring allows pre-allocating descriptor pools
      - Multiple scatter-gather transfers can be queued concurrently
      - Supports at least 16 segments per transfer
      - Zero-copy file read implemented using scatter-gather into pre-allocated buffers
    pitfalls:
      - Descriptor chains must be properly terminated (last descriptor's NEXT pointer is NULL or marked)
      - Descriptor memory must be DMA-accessible (not in high memory, properly mapped)
      - Descriptor ring wrap-around handling is error-prone; off-by-one causes corruption
      - Not handling partial transfers when DMA stops mid-chain
      - Race conditions when updating descriptors while DMA is active
    concepts:
      - Scatter-gather I/O model
      - Descriptor chains and rings
      - Non-contiguous buffer handling
      - Zero-copy data paths
    skills:
      - Descriptor chain construction
      - Ring buffer implementation
      - Zero-copy design patterns
      - Concurrent descriptor management
    deliverables:
      - Scatter-gather descriptor struct and chain builder
      - Ring buffer for descriptor allocation
      - Multi-segment DMA transfer API
      - Zero-copy read operation using scatter-gather
    estimated_hours: "10-12"

  - id: dma-engine-m3
    name: Interrupt-Driven Completion
    description: >
      Implement interrupt-driven DMA completion with callback
      registration and multiple concurrent transfer tracking.
    acceptance_criteria:
      - DMA completion interrupt handler is registered and correctly clears interrupt status
      - Each transfer has an associated callback that is invoked on completion
      - Transfer tracking structure maintains pending, completed, and failed transfers
      - Interrupt handler runs in minimal time, deferring callback invocation to tasklet or work queue
      - At least 32 concurrent transfers can be tracked without overflow
      - Latency from DMA completion to callback invocation is measured and < 100 microseconds
    pitfalls:
      - Spending too much time in interrupt context causes system latency issues
      - Not clearing interrupt status causes interrupt storm (infinite re-triggering)
      - Callback re-entrancy issues if callback submits new DMA transfers
      - Transfer tracking overflow causes lost completions
      - Race between interrupt and transfer submission/retirement
    concepts:
      - Interrupt-driven I/O completion
      - Top-half/bottom-half interrupt handling
      - Callback registration and invocation
      - Concurrent operation tracking
    skills:
      - Interrupt handler implementation
      - Deferred work (tasklets, work queues)
      - Callback-based async APIs
      - Lock-free or low-contention tracking
    deliverables:
      - DMA completion interrupt handler
      - Callback registration API per transfer
      - Transfer tracking with pending/completed queues
      - Deferred callback invocation mechanism
    estimated_hours: "8-10"

  - id: dma-engine-m4
    name: Cache Coherency & DMA Pools
    description: >
      Implement proper cache management for DMA buffers and build
      a DMA buffer pool for efficient allocation.
    acceptance_criteria:
      - DMA buffer pool allocates from DMA-coherent memory region
      - Cache clean (write-back) is performed before DMA reads from buffer
      - Cache invalidate is performed before CPU reads after DMA write to buffer
      - Pool supports alloc, free, and batch-alloc operations
      - Pool handles fragmentation with compaction or slab allocation
      - Benchmark shows pool allocation is < 1 microsecond vs > 10 microseconds for dma_alloc_coherent
    pitfalls:
      - Wrong cache operation direction: clean before DMA-read, invalidate before CPU-read-after-DMA-write
      - Cache invalidate destroys uncommitted CPU writes; must clean first if buffer was written
      - Pool fragmentation causes allocation failures even with sufficient total free space
      - Not tracking buffer ownership (CPU vs DMA) causes cache coherency bugs
      - Alignment padding wastes memory; round up efficiently
    concepts:
      - Cache coherency protocols (snooping vs software-managed)
      - DMA-coherent vs DMA-consistent memory
      - Buffer pool allocation strategies
      - Ownership tracking for cache management
    skills:
      - Cache management operations
      - Memory pool implementation
      - Fragmentation handling
      - Ownership state tracking
    deliverables:
      - DMA buffer pool with alloc/free
      - Cache clean/invalidate helper functions
      - Ownership tracking (CPU-owned vs DMA-owned states)
      - Pool performance benchmark
    estimated_hours: "8-10"

  - id: dma-engine-m5
    name: Zero-Copy Data Path
    description: >
      Build a complete zero-copy data path using DMA for
      network packet or storage I/O processing.
    acceptance_criteria:
      - Network packets or disk blocks are received directly into pre-allocated buffers via DMA
      - Data is processed in-place without copying to intermediate buffers
      - Processed data is transmitted directly from buffers via DMA
      - Buffer lifecycle is managed with reference counting
      - End-to-end latency and throughput are measured and documented
      - Zero-copy path achieves at least 2x throughput improvement over copy-based implementation
    pitfalls:
      - Buffer lifetime management is critical; premature free causes corruption
      - Reference counting bugs (leaks or double-free) are common
      - Not handling buffer exhaustion gracefully causes packet drops or I/O errors
      - Zero-copy path must handle all edge cases the copy path handles
      - Debugging zero-copy issues is harder because data is in expected locations
    concepts:
      - Zero-copy I/O architecture
      - Buffer lifecycle and ownership
      - Reference counting for shared buffers
      - End-to-end performance optimization
    skills:
      - Zero-copy pipeline design
      - Reference counting implementation
      - Performance profiling
      - Complete system integration
    deliverables:
      - Zero-copy receive path using DMA
      - In-place processing without intermediate copies
      - Zero-copy transmit path using DMA
      - Reference-counted buffer management
      - Performance comparison: zero-copy vs copy-based
    estimated_hours: "10-12"
