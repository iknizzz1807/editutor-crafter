id: gitops-deployment
name: GitOps Deployment System
description: Git-driven declarative deployments with drift detection and rollback
difficulty: advanced
estimated_hours: "50-65"
essence: >
  Continuous state reconciliation between Git-declared manifests and live
  Kubernetes clusters through automated control loops that perform three-way
  diffs (Git desired state, last-applied state, live cluster state), detect
  configuration drift from manual changes, and apply corrective actions to
  maintain eventual consistency.
why_important: >
  GitOps is the industry standard for cloud-native deployment management.
  Building this teaches production-grade infrastructure automation—
  reconciliation loops, drift detection, manifest generation, secret
  management, and rollback—combining distributed systems concepts with
  practical Kubernetes API programming.
learning_outcomes:
  - Implement Git repository polling and webhook-triggered sync
  - Generate Kubernetes manifests from plain YAML, Kustomize, and Helm
  - Build three-way diff reconciliation detecting both Git changes and cluster drift
  - Handle secret management in Git using encrypted secrets (SealedSecrets/SOPS)
  - Implement health assessment for deployed resources
  - Build deployment history tracking and rollback to previous revisions
  - Implement dry-run validation before every apply
skills:
  - Git operations and webhook handling
  - Kubernetes API (server-side apply, dry-run)
  - Manifest generation (YAML, Kustomize, Helm)
  - Three-way diff and drift detection
  - Secret management in GitOps workflows
  - Health assessment and status aggregation
  - Deployment history and rollback
tags:
  - advanced
  - argocd
  - declarative
  - devops
  - drift-detection
  - flux
  - gitops
  - sync
architecture_doc: architecture-docs/gitops-deployment/index.md
languages:
  recommended:
    - Go
    - Python
  also_possible:
    - Java
resources:
  - name: Argo CD Documentation""
    url: "https://argo-cd.readthedocs.io/en/stable/"
    type: documentation
  - name: OpenGitOps Principles""
    url: "https://opengitops.dev/"
    type: documentation
  - name: Kubernetes Server-Side Apply""
    url: "https://kubernetes.io/docs/reference/using-api/server-side-apply/"
    type: documentation
  - name: SealedSecrets""
    url: "https://github.com/bitnami-labs/sealed-secrets"
    type: tool
  - name: SOPS - Secrets OPerationS""
    url: "https://github.com/getsops/sops"
    type: tool
prerequisites:
  - type: skill
    name: "Kubernetes basics (Deployments, Services, kubectl, RBAC)"
  - type: skill
    name: "Git (branches, commits, webhooks)"
  - type: skill
    name: "YAML, Helm, or Kustomize basics"
milestones:
  - id: gitops-deployment-m1
    name: "Git Repository Sync"
    description: >
      Clone Git repositories, detect new commits via polling or webhook,
      and track the current synced commit SHA. Handle authentication and
      webhook signature verification.
    acceptance_criteria:
      - "Clone a Git repository from a remote URL with a specific branch checked out; support shallow clones (--depth 1) to reduce bandwidth"
      - "Poll for changes at a configurable interval (default: 3 minutes); detect new commits by comparing local HEAD SHA with remote HEAD SHA"
      - "Webhook receiver accepts POST requests on /webhook endpoint; triggers immediate sync when a push event is received"
      - "Webhook signature verification: validate the webhook payload against a shared secret using HMAC-SHA256 (GitHub) or equivalent; reject requests with invalid signatures (test: send a webhook with wrong signature and verify 403 response)"
      - "Support both SSH key and HTTPS token authentication for private repositories; credentials are loaded from Kubernetes Secrets or environment variables, never hardcoded"
      - "Track current synced commit SHA persistently (in a ConfigMap or local file); on restart, compare with remote HEAD and sync only if behind"
      - "Exponential backoff on polling failures (e.g., network error, auth failure); maximum backoff of 5 minutes"
    pitfalls:
      - "Cloning full history on every sync wastes bandwidth and time; use shallow clones and git fetch --depth 1 for updates"
      - "Missing webhook signature verification allows anyone to trigger deployments by sending a POST request to the webhook endpoint"
      - "Hardcoding credentials in code or config files is a security vulnerability; always use secret management"
      - "Not tracking synced commit SHA means every restart triggers a full re-sync even if nothing changed"
    concepts:
      - Git shallow cloning and fetch for efficient updates
      - Webhook payload validation with HMAC signatures
      - SSH and HTTPS authentication for Git
      - Polling with exponential backoff
    deliverables:
      - "Repository cloner with shallow clone and branch selection"
      - "Polling loop with configurable interval and commit comparison"
      - "Webhook receiver with HMAC signature verification"
      - "Credential management loading SSH keys or tokens from secrets"
      - "Synced commit SHA tracking for restart resilience"
    estimated_hours: "8-10"

  - id: gitops-deployment-m2
    name: "Manifest Generation & Secret Management"
    description: >
      Generate Kubernetes manifests from plain YAML, Kustomize overlays,
      and Helm charts. Decrypt encrypted secrets (SealedSecrets or SOPS)
      before applying. Validate all generated manifests against the
      Kubernetes API schema.
    acceptance_criteria:
      - "Detect manifest source type from repository structure: plain YAML (directory of .yaml files), Kustomize (kustomization.yaml present), Helm (Chart.yaml present)"
      - "Plain YAML: read and parse all .yaml files in the configured directory; concatenate into a manifest list"
      - "Kustomize: run kustomize build on the configured overlay directory; produce final manifests with patches and overlays applied"
      - "Helm: render templates using helm template with configurable values files and release name; produce final manifests"
      - "Secret decryption: detect SOPS-encrypted files (sops metadata in YAML) and decrypt them using a configured key (age, GPG, or cloud KMS) before including in manifest list"
      - "Manifest validation: run kubectl apply --dry-run=server on all generated manifests to validate against the live cluster's API schema; reject manifests that fail validation with detailed error messages"
      - "Validation test: introduce an invalid manifest (wrong apiVersion, missing required field); verify the system detects and reports the error before applying"
      - "Environment-specific configuration: support per-environment values files or Kustomize overlays (dev, staging, prod) selected by configuration"
    pitfalls:
      - "Not validating YAML syntax before applying causes cryptic API server errors; validate locally first"
      - "Helm template rendering with missing values produces empty or incorrect manifests silently; always validate rendered output"
      - "Storing secrets in Git without encryption is the #1 GitOps anti-pattern; require encryption for all Secret resources"
      - "SOPS decryption requires the decryption key to be available at runtime; store the key as a Kubernetes Secret mounted into the GitOps controller"
      - "Kustomize overlays that reference non-existent bases fail silently or with confusing errors; validate overlay structure"
    concepts:
      - Manifest source type detection and generation
      - Helm template rendering with value hierarchy
      - Kustomize overlay and patch application
      - SOPS/SealedSecrets for Git-safe secret storage
      - Server-side dry-run validation
    deliverables:
      - "Manifest source detector (plain YAML, Kustomize, Helm)"
      - "Plain YAML reader and parser"
      - "Kustomize build integration"
      - "Helm template rendering with values file support"
      - "SOPS decryption integration for encrypted secrets"
      - "Server-side dry-run validation for all generated manifests"
      - "Environment-specific configuration selection"
    estimated_hours: "10-14"

  - id: gitops-deployment-m3
    name: "Three-Way Diff, Sync & Drift Detection"
    description: >
      Implement three-way diff reconciliation comparing Git desired state,
      last-applied state (annotation), and live cluster state. Detect both
      Git-driven changes and manual cluster drift. Apply changes using
      server-side apply with dry-run validation first.
    acceptance_criteria:
      - "Three-way diff: compare (1) desired state from Git, (2) last-applied state stored in kubectl.kubernetes.io/last-applied-configuration annotation, and (3) live cluster state; correctly identify fields changed in Git, fields changed manually in cluster, and fields changed in both (conflict)"
      - "Drift detection: if a resource in the cluster has been manually modified (field differs from last-applied but matches Git), flag it as drifted; report drifted resources in sync status"
      - "Sync operation: first run kubectl apply --dry-run=server to validate; if dry-run succeeds, run kubectl apply --server-side to apply changes; log all changes made"
      - "Resource pruning: resources that exist in the cluster with the GitOps label but do NOT exist in the Git manifests are deleted (opt-in, with configuration flag)"
      - "Sync hooks: support PreSync, Sync, and PostSync hooks (Kubernetes Jobs or other resources) that execute before, during, and after the main sync"
      - "Sync waves: resources are applied in wave order (lower wave first) to handle dependencies (e.g., Namespace before Deployment)"
      - "Selective sync: support syncing specific resources by name or kind without syncing everything"
      - "Drift detection test: create a resource from Git, manually modify it with kubectl edit, trigger sync, verify the system detects the drift and reports it"
    pitfalls:
      - "Two-way diff (Git vs cluster) misses manual changes that should be preserved; three-way diff is required to correctly handle drift"
      - "Pruning resources still in use by other applications that happen to lack the GitOps label is dangerous; prune only resources with the system's ownership label"
      - "Applying without dry-run first risks breaking the cluster with invalid manifests; always dry-run before real apply"
      - "Resource ordering matters: creating a Deployment before its Namespace causes a 404 error; implement wave-based ordering"
      - "Server-side apply field management conflicts with other controllers (e.g., HPA modifying replicas); configure field ownership correctly"
    concepts:
      - Three-way merge (desired, last-applied, live)
      - Kubernetes server-side apply with field ownership
      - Drift detection and reporting
      - Resource pruning with ownership labels
      - Sync waves and hooks for ordered deployment
    deliverables:
      - "Three-way diff engine comparing desired, last-applied, and live state"
      - "Drift detector flagging manually modified cluster resources"
      - "Server-side apply with mandatory pre-apply dry-run validation"
      - "Resource pruning for orphaned resources with ownership label"
      - "Sync waves for ordered resource application"
      - "Sync hooks (PreSync, Sync, PostSync) for custom deployment logic"
      - "Selective sync by resource name or kind"
    estimated_hours: "12-16"

  - id: gitops-deployment-m4
    name: "Health Assessment & Drift Monitoring"
    description: >
      Monitor deployed resource health using kind-specific status checks.
      Continuously detect drift between synced state and live cluster.
      Classify resources as Healthy, Progressing, Degraded, or Missing.
    acceptance_criteria:
      - "Built-in health checks for core resource kinds: Deployment (available replicas == desired replicas), Service (endpoints exist), StatefulSet (ready replicas == replicas), Job (succeeded), Pod (phase=Running and containers ready)"
      - "Custom health check support: user-defined Lua scripts or rules that evaluate health for CRDs or non-standard resources"
      - "Resource health classification: Healthy (all conditions met), Progressing (rollout in progress), Degraded (partial failure), Missing (resource deleted from cluster), Unknown (unable to determine)"
      - "Application-level health aggregation: overall application health is the worst health status among all its resources (if any resource is Degraded, application is Degraded)"
      - "Continuous drift monitoring: periodically (configurable, default every 60s) compare live cluster state with last-synced state; report any drifted resources"
      - "Health status is exposed via API endpoint and stored in sync status record"
      - "Health check test: deploy a Deployment with replicas=3, scale one replica down manually, verify health changes from Healthy to Degraded"
    pitfalls:
      - "Relying only on Pod phase without checking container readiness misses CrashLoopBackOff states where phase=Running but container is restarting"
      - "Not distinguishing Progressing from Degraded causes false alarms during normal rollouts"
      - "Health check timeouts too short for applications with slow startup (e.g., JVM warmup) cause false Degraded status"
      - "Drift monitoring that queries the API server too frequently causes rate limiting; use informer watches instead of polling where possible"
    concepts:
      - Kind-specific health check logic
      - Health status classification and aggregation
      - Continuous drift detection via cluster watches
      - Custom health check extensibility
    deliverables:
      - "Built-in health checkers for Deployment, Service, StatefulSet, Job, Pod"
      - "Custom health check interface for user-defined CRD health logic"
      - "Health aggregation engine computing overall application health"
      - "Continuous drift monitor detecting manual cluster modifications"
      - "Health status API endpoint and status record storage"
    estimated_hours: "10-12"

  - id: gitops-deployment-m5
    name: "Deployment History & Rollback"
    description: >
      Track deployment history with commit SHAs, manifest snapshots, and
      sync results. Support rollback to any previous revision. Implement
      auto-rollback on health degradation.
    acceptance_criteria:
      - "Each successful sync creates a history record containing: revision number, Git commit SHA, sync timestamp, synced manifest snapshot (or hash), sync result (success/partial/fail), and user/trigger (webhook/poll/manual)"
      - "History is stored persistently (in a CRD, ConfigMap, or database) and survives system restarts"
      - "CLI/API command to list deployment history showing revision, commit SHA, timestamp, status"
      - "Rollback to a specific revision re-applies that revision's manifest snapshot to the cluster; the rollback itself creates a new history entry referencing the original revision"
      - "Diff between any two revisions shows which resources were added, modified, or removed"
      - "Auto-rollback (opt-in): if application health degrades to Degraded within a configurable window after sync (e.g., 5 minutes), automatically rollback to the previous revision and alert"
      - "Auto-rollback test: deploy a broken manifest that causes health degradation; verify auto-rollback restores the previous working state within the configured window"
      - "Audit trail: all sync and rollback operations are logged with timestamp, trigger source, commit SHA, and user identity (if applicable)"
    pitfalls:
      - "Not preserving enough history means old revisions are unavailable for rollback; keep at least 10 revisions (configurable)"
      - "Rollback without validating the target revision's manifests against the current cluster API schema may fail if the cluster has been upgraded since that revision"
      - "Auto-rollback that triggers during a normal slow rollout (Progressing state) causes unnecessary rollbacks; only trigger on Degraded, not Progressing"
      - "Storing full manifest snapshots for every revision consumes significant storage; consider storing diffs or using Git commit references instead"
      - "Partial rollbacks (when only some resources fail) are complex; start with all-or-nothing rollback"
    concepts:
      - Deployment revision history with manifest snapshots
      - Rollback as re-application of previous manifests
      - Auto-rollback triggered by health degradation
      - Audit logging for compliance and debugging
      - Revision comparison and diff visualization
    deliverables:
      - "History storage recording each sync with commit SHA, manifests, and result"
      - "History list API/CLI showing deployment revisions"
      - "Rollback command re-applying a specific revision's manifests"
      - "Revision diff showing changes between any two revisions"
      - "Auto-rollback on health degradation with configurable threshold and window"
      - "Audit log recording all sync and rollback operations with attribution"
    estimated_hours: "10-14"