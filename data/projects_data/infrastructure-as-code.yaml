id: infrastructure-as-code
name: Infrastructure as Code Engine
description: Build a Terraform-like declarative infrastructure provisioning engine with state management, dependency resolution, drift detection, and provider abstraction.
difficulty: advanced
estimated_hours: 60-90
essence: 'Declarative configuration parsing into a resource graph, three-way state reconciliation (desired config vs. stored state vs. live infrastructure), topological ordering of resource dependencies for parallel execution of infrastructure mutations, and provider abstraction for idempotent CRUD operations across cloud APIs—all with crash-safe state persistence and distributed locking.

  '
why_important: 'Understanding IaC internals (like Terraform) helps you debug state corruption, write better modules, build custom providers, and reason about drift detection and reconciliation loops—skills critical for platform engineering and DevOps.

  '
learning_outcomes:
- Design and parse a declarative configuration language with variable interpolation
- Implement state management with distributed locking and crash recovery
- Build a DAG-based dependency graph with cycle detection and parallel execution
- Implement three-way diff reconciliation between config, state, and live infrastructure
- Design a provider plugin interface for idempotent cloud resource CRUD
- Handle partial apply failures with state consistency guarantees
skills:
- DSL Parsing
- State File Management
- Directed Acyclic Graphs
- Topological Sorting
- Resource Lifecycle Management
- Distributed Locking
- Provider Plugin Architecture
- Three-Way Diff Algorithm
tags:
- advanced
- automation
- declarative
- devops
- infrastructure
- providers
- state
- terraform
architecture_doc: architecture-docs/infrastructure-as-code/index.md
languages:
  recommended:
  - Go
  - Python
  also_possible:
  - Rust
  - TypeScript
resources:
- name: Terraform Language Documentation""
  url: https://developer.hashicorp.com/terraform/language
  type: documentation
- name: HCL Syntax Specification""
  url: https://github.com/hashicorp/hcl/blob/main/hclsyntax/spec.md
  type: documentation
- name: Terraform State Management""
  url: https://developer.hashicorp.com/terraform/language/state
  type: documentation
- name: Dependency Graph Resolution Algorithm""
  url: https://www.electricmonk.nl/docs/dependency_resolving_algorithm/dependency_resolving_algorithm.html
  type: article
- name: How Terraform Works Internals""
  url: https://www.youtube.com/watch?v=MYbf_BODFeg
  type: video
prerequisites:
- type: skill
  name: File I/O and JSON/YAML parsing
- type: skill
  name: Graph algorithms (DFS, topological sort)
- type: skill
  name: REST API consumption
milestones:
- id: infrastructure-as-code-m1
  name: Configuration Parser
  description: 'Parse HCL-like or YAML configuration files into a structured resource graph with variable interpolation, module support, and schema validation.

    '
  acceptance_criteria:
  - Parser tokenizes and parses HCL or YAML configuration files into structured resource block objects
  - Variable interpolation resolves ${var.name} references including nested references and default values
  - Module references import external configuration files and merge their resources into the main graph
  - Circular variable references are detected and reported as errors before evaluation
  - Schema validation rejects unknown resource types and missing required attributes with line-number error messages
  pitfalls:
  - Circular variable references cause infinite resolution loops—must detect cycles before evaluation
  - Interpolation inside count or for_each creates a chicken-and-egg problem (value depends on unresolved expression)
  - Module source paths need normalization for relative vs. absolute vs. remote references
  - String interpolation must handle nested expressions like ${var.prefix}-${var.suffix}
  concepts:
  - Recursive descent parsing
  - Abstract syntax tree construction
  - Variable interpolation and expression evaluation
  - Module resolution
  - Schema validation
  skills:
  - Lexical analysis and tokenization
  - Recursive data structure traversal
  - Configuration validation patterns
  - Path normalization
  deliverables:
  - Parser converting configuration files into structured resource definition objects
  - Variable interpolation engine resolving ${var.name} references with cycle detection
  - Module loader importing and composing external configuration files
  - Schema validator rejecting invalid resource types and missing required attributes
  estimated_hours: 10-15
- id: infrastructure-as-code-m2
  name: State Management & Locking
  description: 'Implement persistent state tracking of deployed resources with distributed locking, atomic writes, and crash recovery.

    '
  acceptance_criteria:
  - State file stores resource IDs, all attributes, dependency metadata, and a serial version number
  - 'State writes are atomic: use write-to-temp-file + rename to prevent corruption on crash'
  - Distributed lock acquisition prevents concurrent apply operations; lock includes owner ID and expiry timestamp
  - Stale locks from crashed processes expire after configurable TTL and can be force-unlocked
  - State backup is created automatically before every apply operation
  - Remote state backend (S3 or equivalent) supports read/write with optimistic concurrency via ETag or version ID
  pitfalls:
  - Partial write on crash corrupts state—must use atomic rename, never in-place overwrite
  - Stale lock from crashed process blocks all subsequent operations—implement lease-based expiry
  - 'Remote state race condition: two processes read same version, both write—use ETag-based conditional put'
  - State file grows unboundedly with resource history—implement periodic compaction
  concepts:
  - Atomic file operations
  - Lease-based distributed locking
  - Optimistic concurrency control
  - State serialization and versioning
  - Crash recovery
  skills:
  - Concurrent access synchronization
  - Atomic filesystem operations
  - Remote storage API integration
  - Crash recovery design
  deliverables:
  - State file format with resource IDs, attributes, dependencies, and serial version
  - Atomic state writer using temp-file + rename pattern
  - Distributed lock with owner ID, TTL-based expiry, and force-unlock capability
  - Remote state backend with optimistic concurrency (ETag or version-based conditional writes)
  - Automatic state backup before each apply operation
  estimated_hours: 12-18
- id: infrastructure-as-code-m3
  name: Dependency Graph & Execution Planning
  description: 'Build a resource dependency DAG, detect cycles, perform topological sort, and generate an execution plan with create/update/delete/replace actions.

    '
  acceptance_criteria:
  - Dependency graph is built from explicit depends_on declarations and implicit attribute references (e.g., resource.id used in another resource)
  - Cycle detection identifies and reports circular dependencies with the cycle path
  - Topological sort produces a valid execution order; independent resources are identified for parallel execution
  - Plan generates create, update, delete, and replace (destroy-then-create) actions based on config-vs-state diff
  - Plan output displays a human-readable diff showing attribute changes, additions, and deletions per resource
  - Targeted plan filters execution to only specified resources and their transitive dependencies
  pitfalls:
  - Implicit dependency detection must parse attribute references, not just depends_on—missing implicit deps causes ordering errors
  - Replace action (force-new) must destroy before create when unique constraints exist (e.g., DNS names)
  - Parallel execution must respect dependency edges—only independent subgraphs can run concurrently
  - Plan without refresh shows stale diff if live infrastructure has drifted from state
  concepts:
  - Directed acyclic graph construction
  - Topological sort with parallelism levels
  - Diff algorithms for resource comparison
  - Implicit dependency inference
  - Cycle detection (Kahn's algorithm or DFS)
  skills:
  - Graph algorithm implementation
  - Change set calculation
  - Parallel execution planning
  - Resource lifecycle management
  deliverables:
  - DAG builder extracting explicit and implicit dependencies between resources
  - Cycle detector reporting circular dependency paths
  - Topological sort with parallelism: resources at the same depth level can execute concurrently
  - Plan generator computing create/update/delete/replace actions from config-vs-state diff
  - Human-readable plan output showing per-resource attribute changes
  estimated_hours: 12-18
- id: infrastructure-as-code-m4
  name: Refresh & Three-Way Drift Detection
  description: 'Implement the refresh operation that queries live infrastructure via provider APIs and performs three-way reconciliation between desired config, stored state, and actual live state to detect drift.

    '
  acceptance_criteria:
  - Refresh operation reads current attributes of every managed resource from the live cloud API
  - 'Three-way diff compares desired config vs. stored state vs. live state and categorizes each attribute as: in-sync, config-changed, drifted, or conflict'
  - Drifted resources (live != state, config unchanged) are flagged with a drift warning in the plan output
  - Conflicting resources (live != state AND config != state) require explicit user decision (keep live, apply config, or abort)
  - Refresh updates the stored state to match live reality before plan generation
  - Resources deleted outside of IaC (present in state but missing in live) are detected and reported
  pitfalls:
  - Refresh on large infrastructure is slow—must parallelize API calls across independent resources
  - API eventual consistency means refresh may read stale data immediately after an apply
  - Some attributes are computed server-side (e.g., ARN, creation timestamp) and should not trigger drift alerts
  - Refresh failures on individual resources should not abort the entire refresh—use partial success semantics
  concepts:
  - Three-way merge/diff algorithm
  - Configuration drift detection
  - Attribute classification (user-managed vs. computed)
  - Partial failure handling
  skills:
  - Multi-source data reconciliation
  - API pagination and parallel fetching
  - Diff algorithm design
  - Error handling for partial operations
  deliverables:
  - Refresh engine querying live resource state via provider read operations
  - Three-way diff comparator categorizing each attribute across config, state, and live
  - Drift report listing resources and attributes that have diverged from stored state
  - State updater writing refreshed live values back to the state file
  estimated_hours: 10-15
- id: infrastructure-as-code-m5
  name: Provider Abstraction & Apply Engine
  description: 'Build the provider plugin interface for idempotent CRUD operations and the apply engine that executes plans in dependency order with partial failure handling.

    '
  acceptance_criteria:
  - Provider interface defines Create, Read, Update, Delete methods with standardized input/output schemas
  - At least one provider is implemented end-to-end (e.g., local file provider, mock AWS, or Docker)
  - 'All provider operations are idempotent: retrying a failed Create does not produce duplicate resources'
  - Apply engine executes plan actions in topological order, updating state after each successful resource operation
  - 'Partial apply failure leaves state consistent: successfully applied resources are recorded, failed resources are reported, and remaining resources are skipped'
  - Provider operations implement retry with exponential backoff and jitter for transient API failures
  - Provider authentication reads credentials from environment variables or configuration file
  pitfalls:
  - Non-idempotent Create produces duplicates on retry—use client-side idempotency tokens or check-before-create
  - API rate limits require retry with exponential backoff—fixed delays cause thundering herd
  - Resource stuck in pending/creating state needs polling with timeout, not synchronous wait
  - Partial failure during apply means state is inconsistent with plan—must update state per-resource, not batch
  - Eventual consistency in cloud APIs means Read immediately after Create may return not-found
  concepts:
  - Interface-based abstraction
  - Idempotent operations
  - Exponential backoff with jitter
  - Partial failure handling
  - Per-resource state updates
  skills:
  - Plugin architecture design
  - REST API integration
  - Retry logic implementation
  - Error classification and recovery
  - Timeout and deadline handling
  deliverables:
  - Provider interface with Create, Read, Update, Delete method signatures and schema definitions
  - At least one concrete provider implementation with full CRUD lifecycle
  - Apply engine executing plan in topological order with per-resource state updates
  - Retry logic with exponential backoff and jitter for transient API failures
  - Partial failure report listing succeeded, failed, and skipped resources after apply
  estimated_hours: 15-22
domain: distributed
