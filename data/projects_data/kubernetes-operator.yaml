id: kubernetes-operator
name: Kubernetes Operator
description: Custom controller with CRDs for automated application management
difficulty: advanced
estimated_hours: "45-60"
essence: >
  Event-driven reconciliation of cluster state through controllers that
  continuously watch custom resources, compare actual state against declared
  specifications, execute idempotent operations to eliminate configuration
  drift, use finalizers for external resource cleanup, and handle concurrent
  modifications and failure scenarios.
why_important: >
  Operators automate complex, stateful application lifecycle management at
  scale. Understanding the controller pattern—reconciliation loops, CRDs,
  finalizers, webhooks—is essential for platform engineering and managing
  production Kubernetes infrastructure.
learning_outcomes:
  - Define Custom Resource Definitions with OpenAPI validation and status subresources
  - Set up controllers with informers, work queues, and leader election
  - Implement idempotent reconciliation logic comparing desired vs actual state
  - Use finalizers to clean up external resources on custom resource deletion
  - Build validating and mutating admission webhooks
  - Write unit tests with fake clients and integration tests with envtest
  - Deploy operators with proper RBAC following least privilege
skills:
  - Kubernetes API and client-go
  - Custom Resource Definitions (CRDs)
  - Controller pattern and reconciliation loops
  - Finalizers for resource cleanup
  - Admission webhooks (validating and mutating)
  - Leader election for HA
  - envtest for integration testing
  - RBAC and security
tags:
  - advanced
  - controllers
  - crds
  - devops
  - finalizers
  - reconciliation
  - webhooks
architecture_doc: architecture-docs/kubernetes-operator/index.md
languages:
  recommended:
    - Go
  also_possible:
    - Java
    - Python
resources:
  - name: "Kubernetes Operator Pattern"
    url: "https://kubernetes.io/docs/concepts/extend-kubernetes/operator/"
    type: documentation
  - name: "Kubebuilder Book"
    url: "https://book.kubebuilder.io/"
    type: tutorial
  - name: "Custom Resources Documentation"
    url: "https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"
    type: documentation
  - name: "Operator SDK Documentation"
    url: "https://sdk.operatorframework.io/"
    type: documentation
  - name: "Programming Kubernetes (O'Reilly)"
    url: "https://www.oreilly.com/library/view/programming-kubernetes/9781492047094/"
    type: book
prerequisites:
  - type: skill
    name: "Kubernetes basics (Pods, Deployments, Services, kubectl)"
  - type: skill
    name: "Go programming (recommended) or Python/Java"
  - type: skill
    name: "YAML and Kubernetes manifest structure"
milestones:
  - id: kubernetes-operator-m1
    name: "Custom Resource Definition"
    description: >
      Define a CRD with OpenAPI schema validation, status subresource,
      printer columns, and default values. The CRD represents the domain
      object your operator will manage.
    acceptance_criteria:
      - "CRD YAML manifest defines a custom resource with Group, Version, Kind (e.g., apps.example.com/v1/MyApp) and is successfully applied to the cluster"
      - "OpenAPI v3 schema validation rejects resources with missing required fields (test: apply a CR missing a required field and verify the API server returns a validation error)"
      - "Spec and status are separate subresources: updating spec does not overwrite status and vice versa (test: update spec, verify status is unchanged; update status, verify spec is unchanged)"
      - "Printer columns display at least 3 relevant fields (e.g., status, replicas, age) in 'kubectl get myapp' output"
      - "Default values are set for optional fields via the schema defaulting mechanism (test: create a CR without an optional field and verify the default is applied)"
      - "Scope is correctly set (Namespaced or Cluster) and the CR can be created in the intended scope"
    pitfalls:
      - "Not marking fields as 'required' in the schema allows empty specs that cause nil pointer panics in the controller"
      - "Forgetting to enable the status subresource (subresources.status: {}) means spec and status updates overwrite each other"
      - "OpenAPI schema validation cannot express all constraints (e.g., 'field A required if field B is set'); complex validation requires webhooks (Milestone 4)"
      - "Schema changes on a live CRD can break existing CRs if fields are renamed or types changed; use versioning for breaking changes"
    concepts:
      - OpenAPI v3 schema validation in CRD spec
      - Status subresource for decoupled spec/status updates
      - Structural schema requirements for Kubernetes 1.16+
      - CRD versioning strategies
    deliverables:
      - "CRD YAML manifest with OpenAPI schema, status subresource, and printer columns"
      - "Go types (or equivalent) representing the CR spec and status structs"
      - Validation test: CR with invalid fields is rejected by API server
      - Default values test: CR with omitted optional fields gets defaults
    estimated_hours: "8-10"

  - id: kubernetes-operator-m2
    name: "Controller Setup & Informers"
    description: >
      Set up the controller with a Kubernetes client, shared informer for
      the custom resource, rate-limited work queue, and event handlers.
      Implement leader election for HA deployments.
    acceptance_criteria:
      - "Controller uses a SharedInformer for the custom resource that caches objects locally and reduces API server load"
      - "Informer cache is synced before the controller starts processing events (verified by WaitForCacheSync returning true)"
      - "Event handlers for Add, Update, and Delete enqueue the resource's namespace/name key into a rate-limited work queue"
      - "Work queue uses exponential backoff: first retry after 5ms, max backoff 1000s, with rate limiting to prevent overloading the API server"
      - "Worker goroutines (configurable count, default 2) continuously dequeue items and call the reconcile function"
      - "Leader election is configured so that only one controller replica actively processes events; standby replicas wait for the lease (test: run 2 replicas, verify only one is reconciling)"
      - "RBAC: controller ServiceAccount has only the permissions needed to watch/list/get/update the custom resource and manage owned resources (test: remove a permission and verify the controller logs an authorization error)"
    pitfalls:
      - "Processing events before informer cache sync causes the controller to see partial state and create duplicate resources"
      - "Using direct API calls instead of informer cache lookups causes unnecessary API server load and latency"
      - "Forgetting to implement proper queue shutdown causes goroutine leaks on controller termination"
      - "Leader election lease not renewed due to GC pauses or network issues causes the leader to lose the lease; configure appropriate lease duration and renew deadline"
      - "RBAC too permissive (ClusterAdmin) hides permission issues until production; always use least-privilege RBAC from the start"
    concepts:
      - SharedIndexInformer with resync for cache consistency
      - Rate-limited work queue with exponential backoff
      - Leader election via Kubernetes Lease objects
      - RBAC ClusterRole vs Role scope decisions
    deliverables:
      - "Kubernetes client configuration (in-cluster and kubeconfig)"
      - "SharedInformer for custom resource with cache sync verification"
      - "Event handlers enqueuing namespace/name keys on Add/Update/Delete"
      - "Rate-limited work queue with configurable backoff"
      - "Worker goroutines processing queue items"
      - "Leader election configuration with Lease-based locking"
      - "RBAC manifests with minimal required permissions"
    estimated_hours: "10-12"

  - id: kubernetes-operator-m3
    name: "Reconciliation Loop & Finalizers"
    description: >
      Implement the core reconciliation logic that compares desired state
      (from CR spec) with actual state (from cluster), creates/updates/deletes
      owned resources, and uses finalizers to clean up external resources
      on CR deletion.
    acceptance_criteria:
      - "Reconciler fetches the CR from the informer cache; if not found (deleted), returns without error"
      - "Reconciler compares the desired state (CR spec) with actual state of owned Kubernetes resources (e.g., Deployment, Service) and creates, updates, or deletes them to match"
      - "Owner references are set on all created resources so Kubernetes garbage collector deletes them when the CR is deleted"
      - "Status subresource is updated after each reconciliation with: conditions (Ready, Degraded), observed generation, ready replicas count, and last reconciled timestamp"
      - "Finalizer implementation: on CR creation, the controller adds a finalizer string to metadata.finalizers; on CR deletion (DeletionTimestamp is set), the controller performs cleanup of external resources (e.g., simulated external DB deletion), then removes the finalizer to allow Kubernetes to complete deletion"
      - "Finalizer test: create a CR, verify finalizer is added; delete the CR, verify external cleanup occurs before the CR is actually removed from the cluster"
      - "Idempotency test: trigger reconciliation 3 times on the same unchanged CR; verify no duplicate resources are created and no unnecessary API calls are made"
      - "Reconciliation errors trigger requeue with exponential backoff; permanent errors (e.g., invalid spec) do not requeue and are reported in status conditions"
      - "Generation tracking: reconciler skips reconciliation if spec has not changed (metadata.generation == status.observedGeneration)"
    pitfalls:
      - "Not setting owner references means owned resources are NOT cleaned up when the CR is deleted, causing orphaned resources"
      - "Forgetting to remove the finalizer after cleanup causes the CR to be stuck in Terminating state forever"
      - "Infinite reconciliation loops from status updates triggering new reconcile events; use generation tracking to skip no-op reconciliations"
      - "Partial failure in multi-resource reconciliation (e.g., Deployment created but Service creation fails) requires the next reconciliation to handle the partially-created state; always check 'does resource exist?' before creating"
      - "Not distinguishing transient errors (requeue with backoff) from permanent errors (don't requeue, report in status) causes endless retries of invalid configurations"
    concepts:
      - Declarative reconciliation (desired vs actual state diff)
      - Finalizers for external resource cleanup
      - Owner references for garbage collection
      - Status conditions for detailed health reporting
      - Generation-based reconciliation skipping
    deliverables:
      - "Reconcile function comparing desired spec with actual cluster state"
      - "Resource mutator creating/updating/deleting owned Deployments, Services, etc."
      - Finalizer lifecycle: add on create, cleanup on delete, remove after cleanup
      - "Status updater writing conditions, observed generation, and metrics"
      - Idempotency: repeated reconciliation produces no duplicate resources
      - Error classification: transient errors requeue, permanent errors report in status
    estimated_hours: "12-14"

  - id: kubernetes-operator-m4
    name: "Admission Webhooks"
    description: >
      Implement validating and mutating admission webhooks for the custom
      resource. Handle TLS certificate provisioning and webhook registration.
    acceptance_criteria:
      - "Validating webhook rejects CRs that violate business rules not expressible in OpenAPI schema (e.g., replicas must be odd for quorum, name must match a pattern); rejection includes a human-readable reason string"
      - "Mutating webhook injects default values or computed fields into the CR spec before it is persisted (e.g., add a label, set a computed field)"
      - "Webhook is served over HTTPS with a valid TLS certificate; cert-manager or a self-signed CA provisioned by the operator handles certificate lifecycle"
      - "Webhook failurePolicy is set to 'Fail' for validating (to enforce rules) and tested with the webhook service down to verify the API server rejects CR modifications"
      - "Namespace selector ensures the webhook only intercepts resources in the operator's target namespace(s), not system namespaces (kube-system)"
      - "Mutating webhook executes before validating webhook (Kubernetes default ordering); test: mutating webhook sets a field, validating webhook validates that field is set"
    pitfalls:
      - "Self-signed certificates expire without rotation; use cert-manager or implement rotation with a renewal timer"
      - "Webhook service unavailability with failurePolicy=Fail blocks ALL CR operations cluster-wide; ensure HA or use failurePolicy=Ignore during initial development (but switch to Fail for production)"
      - "Missing namespace selector causes the webhook to intercept system resources, potentially breaking the cluster"
      - "Not returning proper AdmissionReview response format causes the API server to treat the response as a rejection"
    concepts:
      - AdmissionReview request/response structure
      - Certificate management for webhook TLS
      - Webhook failure policies and their implications
      - Mutating vs validating webhook ordering
      - Namespace selectors for scope limiting
    deliverables:
      - "HTTPS webhook server handling AdmissionReview requests"
      - "Validating webhook enforcing business rules with clear rejection messages"
      - "Mutating webhook injecting defaults and computed fields"
      - "TLS certificate provisioning (cert-manager or self-signed with rotation)"
      - "Webhook configuration manifests with namespace selector"
      - Test: webhook rejects invalid CR; webhook mutates CR; webhook down blocks operations
    estimated_hours: "8-10"

  - id: kubernetes-operator-m5
    name: "Testing & Deployment"
    description: >
      Write comprehensive unit and integration tests, build the container
      image, and create deployment manifests (Helm chart or plain YAML)
      with proper RBAC.
    acceptance_criteria:
      - "Unit tests using a fake Kubernetes client cover: create, update, delete reconciliation paths; finalizer add/remove; status update; error handling with requeue; idempotency"
      - "Integration tests using envtest (real API server in-process) verify end-to-end reconciliation: create CR -> owned resources created -> update CR spec -> owned resources updated -> delete CR -> finalizer cleanup -> CR removed"
      - "Test coverage: reconciliation logic has >80% line coverage"
      - "Container image is built with a multi-stage Dockerfile (build stage + minimal runtime stage) and tagged with version"
      - "Deployment manifests include: Namespace, ServiceAccount, ClusterRole/Role, ClusterRoleBinding/RoleBinding, Deployment with resource limits, CRD, and webhook configuration"
      - "RBAC follows least privilege: controller can only watch/list/get/update custom resources and manage owned resource types (Deployment, Service, etc.)"
      - "Helm chart (optional but recommended) parameterizes image, replicas, resource limits, namespace, and RBAC scope"
      - "Smoke test: deploy operator to a test cluster, create a CR, verify owned resources are created, update CR, verify changes propagate, delete CR, verify cleanup"
    pitfalls:
      - "Not testing reconciliation with concurrent updates (e.g., user updates CR while controller is reconciling) misses race conditions; use envtest with parallel operations"
      - "Missing RBAC permissions discovered only in production; run the operator with --v=6 logging to see API server authorization denials during testing"
      - "Helm chart not handling CRD upgrades correctly; CRDs should be applied separately from the Helm release because Helm doesn't manage CRD lifecycle well"
      - "Not testing operator behavior during API server unavailability; informer reconnection and queue backoff must be verified"
    concepts:
      - Fake client for unit testing controller logic
      - envtest for integration testing with real API server
      - Multi-stage Docker builds for minimal images
      - Helm chart best practices for operators
      - RBAC least privilege for operator ServiceAccounts
    deliverables:
      - "Unit test suite with fake client covering all reconciliation paths"
      - "Integration test suite with envtest covering end-to-end lifecycle"
      - "Dockerfile with multi-stage build"
      - "Deployment manifests (RBAC, Deployment, CRD, Webhooks)"
      - "Helm chart with configurable values (optional)"
      - "Smoke test script for deployment verification"
    estimated_hours: "8-12"