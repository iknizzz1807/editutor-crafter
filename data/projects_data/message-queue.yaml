id: message-queue
name: "Message Queue"
description: >-
  Build a message broker supporting both pub/sub fan-out and consumer-group
  competitive consumption over TCP with a custom binary wire protocol,
  acknowledgment-based reliability, persistent append-only log, backpressure,
  and dead letter queues.
difficulty: intermediate
estimated_hours: "30-40"
essence: >-
  Asynchronous message routing with configurable delivery semantics (fan-out for
  pub/sub, competitive consumption for consumer groups) over TCP with a
  length-prefixed binary protocol, acknowledgment-based at-least-once reliability,
  persistent append-only log storage, and flow control through application-level
  backpressure.
why_important: >-
  Message queues are the backbone of async communication in modern distributed
  systems. Understanding how they work internally — delivery guarantees, consumer
  coordination, backpressure, persistence — is essential for designing reliable
  microservice architectures.
learning_outcomes:
  - Implement both pub/sub fan-out and consumer-group competitive consumption patterns
  - Design a length-prefixed binary wire protocol with message framing
  - Build message acknowledgment and redelivery mechanisms with poison message detection
  - Handle backpressure with explicit application-level flow control
  - Implement message persistence with an append-only log and crash recovery
  - Design consumer group rebalancing when members join or leave
skills:
  - Message Queue Design
  - Wire Protocol Design
  - Pub/Sub and Consumer Group Patterns
  - Backpressure Mechanisms
  - Append-only Log Persistence
  - Consumer Coordination
tags:
  - messaging
  - pub/sub
  - distributed-systems
  - async
  - intermediate
architecture_doc: architecture-docs/message-queue/index.md
languages:
  recommended:
    - Go
    - Rust
    - Python
  also_possible:
    - Java
    - JavaScript
resources:
  - name: RabbitMQ AMQP Concepts""
    url: https://www.rabbitmq.com/tutorials/amqp-concepts
    type: documentation
  - name: Kafka Design Documentation""
    url: https://kafka.apache.org/documentation/#design
    type: documentation
  - name: Redis Pub/Sub Documentation""
    url: https://redis.io/docs/latest/develop/interact/pubsub/
    type: documentation
prerequisites:
  - type: skill
    name: TCP socket programming (client and server)
  - type: skill
    name: Concurrency basics (threads, locks, or async)
  - type: skill
    name: Data structures (queues, hash maps, linked lists)
milestones:
  - id: message-queue-m1
    name: "Wire Protocol & Pub/Sub Fan-out"
    description: >-
      Implement a TCP server with a length-prefixed binary wire protocol
      supporting PUBLISH, SUBSCRIBE, and UNSUBSCRIBE commands. Messages published
      to a topic are delivered to ALL subscribers (fan-out mode). Establish
      message framing and connection lifecycle.
    estimated_hours: "8-10"
    concepts:
      - TCP server with concurrent client handling
      - Length-prefixed binary message framing
      - Pub/sub fan-out delivery (every subscriber gets every message)
      - Topic-based message routing
      - Connection lifecycle management
    skills:
      - TCP networking with non-blocking or threaded model
      - Binary protocol design with framing
      - Concurrent data structure management
      - Connection state tracking
    acceptance_criteria:
      - "TCP server accepts multiple concurrent client connections (at least 100 simultaneous)"
      - "Wire protocol uses 4-byte big-endian length prefix followed by message payload; protocol spec document defines all command types and field layouts"
      - "PUBLISH command sends a message to a named topic; server acknowledges receipt with a PUBLISH_ACK response"
      - "SUBSCRIBE command registers the client for a topic; UNSUBSCRIBE removes the registration"
      - "Messages published to a topic are delivered to ALL current subscribers of that topic (fan-out) in the order they were published"
      - "Partial TCP reads are handled correctly — the receiver buffers until a complete length-prefixed message is assembled before parsing"
      - "Client disconnection is detected (via read error or heartbeat timeout) and all subscriptions are cleaned up"
      - "Message ordering is guaranteed per-topic — all subscribers receive messages for a given topic in the same order"
    pitfalls:
      - "TCP is a byte stream, not a message stream; without length-prefix framing, message boundaries are lost and parsing corrupts"
      - "Partial TCP reads are the #1 networking bug — always buffer and parse only complete frames"
      - "Fan-out to slow subscribers can block the publisher if done synchronously; use per-subscriber send buffers"
      - "Connection cleanup on disconnect must be atomic with subscription removal; otherwise, messages are routed to dead connections"
      - "Big-endian length prefix must use network byte order consistently; mixing endianness corrupts framing"
    deliverables:
      - TCP server with concurrent connection handling
      - Wire protocol specification document with message framing, command types, and field layouts
      - PUBLISH, SUBSCRIBE, UNSUBSCRIBE command handlers
      - Topic-based fan-out router delivering messages to all subscribers
      - Connection manager with heartbeat-based liveness detection and cleanup
      - Partial-read buffer assembling complete frames before parsing

  - id: message-queue-m2
    name: "Consumer Groups, ACK/NACK & Poison Detection"
    description: >-
      Implement consumer groups where messages for a topic are distributed across
      group members (competitive consumption), with ACK/NACK-based delivery and
      poison message detection when retry count is exceeded.
    estimated_hours: "10-12"
    concepts:
      - Consumer groups (competitive consumption vs pub/sub fan-out)
      - Message acknowledgment (ACK/NACK) protocol
      - Visibility timeout for unacknowledged messages
      - Round-robin or sticky partition assignment
      - Poison message detection (max retry count)
      - Rebalancing on member join/leave
    skills:
      - Consumer group coordination
      - At-least-once delivery implementation
      - Retry tracking per message
      - Rebalancing protocol design
    acceptance_criteria:
      - "Topic delivery mode is configurable — fan-out (all subscribers get all messages) or consumer-group (messages distributed across group members)"
      - "Consumer group members are assigned topic partitions (or message ranges) using round-robin assignment; each message is delivered to exactly one member"
      - "Messages require explicit ACK within a configurable visibility timeout (default 30 seconds); unacknowledged messages are redelivered to another group member"
      - "NACK causes immediate redelivery to a different group member in the group (not the same consumer)"
      - "Each message tracks a retry count; messages exceeding configurable max_retries (default 5) are flagged as poison and removed from the active queue"
      - "Poison messages are moved to a dead letter holding area (prepared for M4 DLQ implementation) rather than silently dropped"
      - "When a consumer joins or leaves the group, partitions are reassigned; in-flight messages for reassigned partitions are redelivered after visibility timeout"
      - "During rebalancing, a brief pause (rebalancing window) is acceptable; the pause duration is logged and must be under 5 seconds for groups with <10 members"
      - "Head-of-line blocking is avoided — a slow consumer processing one message does not block delivery of other messages to other group members"
    pitfalls:
      - "Duplicate delivery during rebalancing is unavoidable with at-least-once semantics; consumers must be idempotent"
      - "Poison messages without retry count tracking cause infinite redelivery loops that consume all broker resources"
      - "Head-of-line blocking occurs if messages are dispatched sequentially per-consumer; use per-consumer prefetch buffers"
      - "Visibility timeout too short causes spurious redelivery (duplicates); too long delays failure recovery — make it configurable"
      - "NACK to a different consumer requires tracking which consumers have already seen the message; otherwise the same consumer gets it again"
    deliverables:
      - Consumer group coordinator with partition/message assignment
      - ACK/NACK protocol with visibility timeout and redelivery
      - Retry counter per message with max_retries enforcement
      - Poison message detector flagging messages exceeding retry limit
      - Rebalancing logic reassigning partitions on member join/leave
      - Delivery mode configuration (fan-out vs consumer-group) per topic

  - id: message-queue-m3
    name: "Persistence, Crash Recovery & Backpressure"
    description: >-
      Add message persistence using an append-only log file with offset-based
      indexing, crash recovery of unacknowledged messages, and application-level
      backpressure when consumers fall behind.
    estimated_hours: "8-10"
    concepts:
      - Append-only log storage with sequential offsets
      - fsync durability tradeoffs
      - Crash recovery from log replay
      - Consumer offset tracking
      - Application-level backpressure (THROTTLE command)
      - Retention policies (time-based and size-based)
    skills:
      - Append-only log file design
      - Crash recovery implementation
      - Consumer offset management
      - Backpressure protocol design
    acceptance_criteria:
      - "Messages are appended to a per-topic log file with monotonically increasing offsets before delivery confirmation (PUBLISH_ACK) is sent to the producer"
      - "Log format includes offset, timestamp, message length, message payload, and CRC32 checksum per entry"
      - "On broker restart, unacknowledged messages are recovered by replaying the log from the last committed consumer offset"
      - "Consumer offsets are persisted durably; each consumer group's position per topic is recoverable after crash"
      - "Application-level backpressure is implemented — when consumer lag (difference between latest offset and consumer offset) exceeds a configurable threshold, the broker sends a THROTTLE response to producers instead of PUBLISH_ACK, signaling them to slow down"
      - "Producers receiving THROTTLE back off using configurable delay (not dropped messages); normal PUBLISH_ACK resumes when lag decreases below threshold"
      - "Per-topic retention policy supports both time-based (delete messages older than N hours) and size-based (delete oldest messages when log exceeds N MB) with automatic cleanup"
      - "Log corruption (CRC mismatch) during recovery is detected and the corrupted record is skipped with a warning; recovery continues from the next valid record"
      - "Durability is configurable — fsync on every write (safe, slow), fsync every N writes (batched), or OS-managed (fast, risky)"
    pitfalls:
      - "fsync on every message write gives durability but destroys throughput; batch fsync every N messages or every M milliseconds is the standard tradeoff"
      - "Log files grow unbounded without retention; size-based retention must not delete messages that haven't been consumed yet"
      - "Backpressure via dropping messages silently violates at-least-once guarantees; always use explicit signaling (THROTTLE command)"
      - "CRC corruption on recovery must not halt the entire broker; skip-and-warn is safer than abort"
      - "Consumer offset commit must be atomic — partial offset updates cause messages to be re-consumed or skipped"
    deliverables:
      - Append-only log file with offset-based indexing and CRC32 checksums
      - Log writer with configurable fsync policy (per-write, batched, OS-managed)
      - Crash recovery replaying log from last committed consumer offset
      - Consumer offset persistence with atomic commit
      - Backpressure protocol with THROTTLE command and producer-side delay
      - Retention manager with time-based and size-based cleanup policies

  - id: message-queue-m4
    name: "Dead Letter Queue & Monitoring API"
    description: >-
      Implement dead letter queues for poison messages with inspection and replay
      capabilities, and a monitoring API exposing queue depths, consumer lag,
      throughput, and health status.
    estimated_hours: "6-8"
    concepts:
      - Dead letter queue as a separate topic
      - Message replay with ordering considerations
      - Monitoring metrics (queue depth, lag, throughput)
      - Consumer heartbeat and liveness
    skills:
      - DLQ design and management
      - Message replay implementation
      - Metrics collection and HTTP API design
      - Health check implementation
    acceptance_criteria:
      - "Messages exceeding max_retries in M2 are automatically moved to a dead letter topic named {original_topic}.dlq"
      - "DLQ messages include original topic, original offset, retry count, last failure reason, and timestamp of final failure"
      - "DLQ messages can be listed and inspected via a REST or command-line API showing all metadata"
      - "DLQ messages can be replayed back to the original topic via API; replayed messages are appended as new messages (new offsets) with a 'replayed' flag"
      - "Monitoring HTTP endpoint exposes per-topic metrics — current queue depth, consumer group lag, publish rate (msgs/sec), consume rate (msgs/sec), and DLQ depth"
      - "Consumer heartbeat protocol detects dead consumers (no heartbeat within configurable interval, default 10 seconds) and triggers rebalancing"
      - "Health endpoint reports overall broker status (HEALTHY, DEGRADED, UNHEALTHY) based on component checks (log file writable, consumer groups active, no excessive DLQ growth)"
      - "DLQ growth rate alerting — if DLQ message count exceeds configurable threshold, monitoring endpoint includes a warning in health response"
    pitfalls:
      - "DLQ growing without alerting is a silent failure mode; always monitor DLQ depth alongside active queues"
      - "Replayed messages get new offsets, so they may be processed out of order relative to messages published after the original failure — document this behavior"
      - "Monitoring endpoint must not block the broker's message processing path; use a separate HTTP listener or async metrics collection"
      - "Consumer heartbeat timeout too aggressive causes false dead-consumer detection during GC pauses or network blips"
    deliverables:
      - Dead letter queue implementation as a dedicated topic per source topic
      - DLQ inspection API listing messages with full metadata
      - DLQ replay API moving messages back to the original topic
      - Monitoring HTTP API with per-topic queue depth, lag, throughput, and DLQ depth
      - Consumer heartbeat tracker with dead-consumer detection and rebalancing trigger
      - Health check endpoint with component-level status reporting