id: neural-rendering
name: Neural Rendering
description: >
  Build neural rendering systems including NeRF (Neural Radiance Fields) and
  3D Gaussian Splatting. Learn to synthesize novel views of 3D scenes from
  2D images using neural networks.

difficulty: expert
estimated_hours: 70-90
domain: ai-ml

essence: >
  Scene representation as neural network (NeRF) or explicit primitives (Gaussians),
  differentiable rendering to synthesize views by projecting representations through
  camera models, and optimization against ground truth images for reconstruction.

why_important: >
  Neural rendering is revolutionizing VFX, AR/VR, and digital twins. Companies like
  NVIDIA, Meta, and Apple are heavily investing in this technology. Skills are
  valuable at $200K-400K+ for computer vision and graphics engineers.

learning_outcomes:
  - Implement NeRF with positional encoding and volume rendering
  - Build hierarchical sampling for efficient ray marching
  - Implement 3D Gaussian Splatting with differentiable rasterization
  - Handle camera poses and calibration
  - Build training loop with perceptual losses
  - Implement real-time rendering optimizations
  - Handle large scenes with spatial data structures
  - Export reconstructions for conventional renderers

skills:
  - Neural Radiance Fields
  - Gaussian Splatting
  - Differentiable Rendering
  - Volume Rendering
  - Camera Models
  - Positional Encoding
  - Spatial Data Structures
  - Real-Time Optimization

tags:
  - expert
  - neural-rendering
  - nerf
  - gaussian-splatting
  - 3d-reconstruction
  - computer-vision

languages:
  recommended:
    - Python
  also_possible: []

resources:
  - name: "NeRF: Representing Scenes as Neural Radiance Fields"
    url: https://arxiv.org/abs/2003.08934
    type: paper
  - name: "3D Gaussian Splatting for Real-Time Radiance Field Rendering"
    url: https://arxiv.org/abs/2308.04079
    type: paper
  - name: "Nerfstudio"
    url: https://docs.nerf.studio/
    type: documentation
  - name: "Instant-NGP"
    url: https://github.com/NVlabs/instant-ngp
    type: code

prerequisites:
  - type: project
    name: transformer-scratch or equivalent deep learning
  - type: skill
    name: PyTorch proficiency
  - type: skill
    name: Understanding of 3D geometry and cameras
  - type: skill
    name: Differentiable programming concepts

milestones:
  - id: neural-rendering-m1
    name: NeRF Core Architecture
    description: >
      Implement the core NeRF architecture with positional encoding
      and MLP for density and color prediction.
    acceptance_criteria:
      - Positional encoding maps 3D coordinates to high-dim features
      - MLP predicts density (sigma) and RGB color per point
      - Architecture follows original NeRF (8 layers, 256 hidden)
      - Separate coarse and fine networks for hierarchical sampling
      - Model processes batch of 3D points efficiently
    pitfalls:
      - Positional encoding dimension affects quality and speed
      - Network too small underfits, too large slow
      - Not handling coordinate normalization
      - Skipping connections important for quality
    concepts:
      - Positional encoding
      - Radiance field MLP
      - Density prediction
      - Network architecture
    skills:
      - MLP design
      - Positional encoding
      - Batch processing
      - Architecture tuning
    deliverables:
      - Positional encoding
      - Density/color MLP
      - Coarse/fine networks
      - Forward pass
    estimated_hours: "12-16"

  - id: neural-rendering-m2
    name: Volume Rendering & Ray Marching
    description: >
      Implement differentiable volume rendering that accumulates
      color and density along rays.
    acceptance_criteria:
      - Ray generation from camera pose and intrinsics
      - Point sampling along rays (stratified sampling)
      - Volume rendering equation: C = sum(T_i * alpha_i * c_i)
      - Transmittance T computed as product of (1 - alpha)
      - Gradients flow through rendering to MLP
      - Alpha computed from density: alpha = 1 - exp(-sigma * delta)
    pitfalls:
      - Numerical instability in transmittance computation
      - Delta (step size) affects rendering quality
      - Not handling ray termination (opaque surface)
      - Sampling strategy affects quality/speed tradeoff
    concepts:
      - Ray generation
      - Volume rendering
      - Transmittance
      - Alpha compositing
    skills:
      - Ray marching
      - Volume rendering
      - Differentiable ops
      - Sampling strategies
    deliverables:
      - Ray generator
      - Point sampler
      - Volume renderer
      - Differentiable pipeline
    estimated_hours: "14-18"

  - id: neural-rendering-m3
    name: Hierarchical Sampling & Training
    description: >
      Implement hierarchical sampling for efficient ray marching
      and training loop with photometric loss.
    acceptance_criteria:
      - Coarse network provides density estimate
      - Inverse transform sampling concentrates fine samples
      - Photometric loss (MSE) between rendered and ground truth
      - Training uses Adam optimizer with learning rate schedule
      - PSNR metric tracks reconstruction quality
      - Training converges on simple synthetic scenes
    pitfalls:
      - Coarse samples too few miss important regions
      - Learning rate too high causes instability
      - Not normalizing images affects loss scale
      - Training takes many iterations (hours on GPU)
    concepts:
      - Hierarchical sampling
      - Importance sampling
      - Photometric loss
      - Training loop
    skills:
      - Sampling optimization
      - Loss design
      - Training stability
      - Metric tracking
    deliverables:
      - Hierarchical sampler
      - Training loop
      - Loss functions
      - Quality metrics
    estimated_hours: "14-18"

  - id: neural-rendering-m4
    name: 3D Gaussian Splatting Basics
    description: >
      Implement 3D Gaussian Splatting as an alternative to NeRF
      with explicit Gaussian primitives.
    acceptance_criteria:
      - 3D Gaussians parameterized by position, covariance, opacity, color
      - Covariance decomposed into scale and rotation
      - Spherical harmonics for view-dependent color
      - Gaussians projected to 2D image plane
      - Alpha blending for final pixel color
      - Differentiable w.r.t. Gaussian parameters
    pitfalls:
      - Covariance must remain positive semi-definite
      - Projection degeneracy for flat Gaussians
      - Too many Gaussians memory intensive
      - Spherical harmonics order affects quality
    concepts:
      - 3D Gaussians
      - Covariance matrices
      - Splatting projection
      - Spherical harmonics
    skills:
      - Gaussian representation
      - Differentiable projection
      - Spherical harmonics
      - Parameter management
    deliverables:
      - Gaussian representation
      - Splatting rasterizer
      - Spherical harmonics
      - Differentiable pipeline
    estimated_hours: "14-18"

  - id: neural-rendering-m5
    name: Optimization & Real-Time Rendering
    description: >
      Build optimization loop for Gaussian Splatting with adaptive
      density control and real-time rendering.
    acceptance_criteria:
      - Gaussians optimized via gradient descent
      - Adaptive density: split, clone, prune Gaussians
      - SSIM loss in addition to L1 for perceptual quality
      - Real-time rendering target: > 30 FPS at 1080p
      - Export to standard 3D formats (.ply)
      - Compare reconstruction quality with NeRF
    pitfalls:
      - Unbounded Gaussian growth without pruning
      - Real-time rendering needs CUDA/Triton kernels
      - Memory grows without density control
      - Loss balance between L1 and SSIM
    concepts:
      - Adaptive density
      - Real-time rendering
      - Perceptual loss
      - Export formats
    skills:
      - Optimization loop
      - Adaptive control
      - Real-time implementation
      - Format export
    deliverables:
      - Optimization loop
      - Adaptive density control
      - Real-time renderer
      - Format export
    estimated_hours: "14-18"
