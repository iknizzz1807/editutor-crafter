id: recommendation-engine
name: Recommendation Engine
description: >-
  Build a production recommendation system implementing collaborative filtering,
  matrix factorization, content-based filtering, and hybrid approaches with
  rigorous offline evaluation.
difficulty: intermediate
estimated_hours: "40-55"
essence: >-
  Sparse matrix decomposition and similarity computation across user-item
  interactions, with multiple algorithmic approaches (neighborhood-based CF,
  FunkSVD/ALS factorization, content-based filtering) evaluated through
  offline ranking metrics and served via a multi-stage retrieval pipeline.
why_important: >-
  Recommendation systems are one of the most commercially impactful ML
  applications. Building one teaches production ML system design—from algorithm
  implementation to real-world challenges like cold-start, sparsity, scalability,
  and the critical discipline of offline evaluation before deployment.
learning_outcomes:
  - Load and explore user-item interaction data, understanding sparsity patterns
  - Implement user-based and item-based collaborative filtering with similarity metrics
  - Build matrix factorization models using FunkSVD and ALS for latent factor discovery
  - Design content-based filtering with feature extraction and user preference modeling
  - Evaluate recommendation quality using Precision@K, Recall@K, NDCG, and Hit Rate
  - Handle cold-start problems using fallback strategies and hybrid approaches
  - Implement multi-stage retrieval and ranking pipelines for low-latency recommendations
  - Build a recommendation API with caching and model serving
skills:
  - Matrix Factorization (FunkSVD, ALS)
  - Collaborative Filtering
  - Sparse Matrix Operations
  - Content-Based Filtering
  - Offline Evaluation Metrics
  - Feature Engineering
  - Model Serving
  - Hybrid Systems
tags:
  - collaborative-filtering
  - content-based
  - intermediate
  - python
  - ranking
  - evaluation
  - recommendation
architecture_doc: architecture-docs/recommendation-engine/index.md
languages:
  recommended:
    - Python
  also_possible:
    - Go
    - Scala
resources:
  - name: Surprise Library
    url: https://surpriselib.com/
    type: documentation
  - name: Netflix Recommendation Paper (BellKor)
    url: https://www.cs.uic.edu/~liub/KDD-cup-2007/proceedings/The-BellKor-Solution.pdf
    type: paper
  - name: Implicit Library (for implicit feedback)
    url: https://github.com/benfred/implicit
    type: documentation
prerequisites:
  - type: skill
    name: Python
  - type: skill
    name: Linear algebra basics
  - type: skill
    name: Database fundamentals
milestones:
  - id: recommendation-engine-m1
    name: Data Loading & Collaborative Filtering
    description: >-
      Load interaction data, build the user-item matrix, and implement
      neighborhood-based collaborative filtering (user-based and item-based).
    acceptance_criteria:
      - "Load a standard dataset (e.g., MovieLens 100K/1M) into a sparse user-item rating matrix using scipy.sparse"
      - "Report sparsity statistics (% non-zero, users with <5 ratings, items with <5 ratings)"
      - "Implement user-to-user cosine similarity computation over sparse vectors (not densified)"
      - "Implement item-to-item cosine similarity using co-rating patterns"
      - "Predict ratings using K-nearest neighbors (K configurable, default 20) weighted average"
      - "Generate top-N recommendations for a given user by predicting scores for unrated items"
      - "Demonstrate that cold-start users (0 ratings) produce no recommendations and document this limitation explicitly"
    pitfalls:
      - "Densifying the sparse matrix for similarity computation causes OOM on large datasets"
      - "Precomputing all-pairs similarity does not scale beyond ~10K users; use on-demand computation or approximate methods"
      - "Cold-start is inherent to CF—claiming to \"handle\" it without a fallback strategy is dishonest"
      - "Popularity bias causes the same popular items to dominate all recommendation lists"
      - "Not filtering out items the user has already interacted with from recommendations"
    concepts:
      - Sparse matrix representations (CSR, COO)
      - Cosine and Pearson similarity on sparse vectors
      - K-nearest neighbor prediction
      - Cold-start problem in collaborative filtering
    skills:
      - Sparse matrix manipulation with scipy
      - Cosine and Pearson similarity computation
      - Nearest neighbor search
      - Data exploration and statistics
    deliverables:
      - Data loader producing a scipy sparse user-item rating matrix with sparsity statistics
      - User-user similarity module computing cosine similarity over sparse vectors
      - Item-item similarity module computing co-occurrence based similarity
      - KNN rating predictor using weighted average of K nearest neighbor ratings
      - Top-N recommendation generator for a given user
    estimated_hours: "8-12"

  - id: recommendation-engine-m2
    name: Matrix Factorization
    description: >-
      Implement latent factor models using FunkSVD (SGD-based) and ALS. Understand
      why standard SVD cannot be applied directly to sparse matrices with missing values.
    acceptance_criteria:
      - "Document why standard SVD (e.g., np.linalg.svd) cannot be applied to sparse rating matrices with missing entries"
      - "Implement FunkSVD using stochastic gradient descent on observed ratings only"
      - "Implement ALS alternating between fixing user factors and solving for item factors, and vice versa"
      - "Apply L2 regularization to both user and item factor matrices with configurable lambda"
      - "Training loss (RMSE on observed ratings) decreases monotonically over epochs with reasonable learning rate"
      - "Latent dimension count is configurable (default 50) and its effect on train/validation RMSE is demonstrated"
      - "Implicit feedback variant using weighted ALS (as in Hu et al. 2008) is implemented as an optional extension"
    pitfalls:
      - "Confusing standard SVD with FunkSVD—standard SVD requires a fully populated matrix and does not handle missing values"
      - "Learning rate too high causes SGD divergence; too low causes painfully slow convergence"
      - "Overfitting without regularization—validation RMSE diverges from training RMSE"
      - "Factor initialization matters: random normal with small std (0.01) works; zeros cause symmetry problems"
      - "Implicit feedback requires a fundamentally different loss function (confidence-weighted), not just treating missing=0"
    concepts:
      - FunkSVD vs standard SVD
      - Alternating Least Squares
      - Stochastic gradient descent on sparse data
      - Regularization to prevent overfitting
      - Implicit vs explicit feedback
    skills:
      - Implementing SGD optimization from scratch
      - Matrix decomposition techniques
      - Regularization tuning
      - Training loop with convergence monitoring
    deliverables:
      - FunkSVD trainer using SGD on observed ratings with configurable rank, learning rate, and regularization
      - ALS trainer alternating user/item factor optimization with L2 regularization
      - Rating prediction module computing dot product of user and item latent factors plus bias terms
      - Training curve plotter showing train and validation RMSE over epochs
      - Hyperparameter sweep utility testing different latent dimensions and regularization strengths
    estimated_hours: "8-12"

  - id: recommendation-engine-m3
    name: Content-Based Filtering & Hybrid
    description: >-
      Implement content-based recommendations using item features, then combine
      with collaborative filtering into a hybrid system.
    acceptance_criteria:
      - "Extract item feature vectors from text descriptions using TF-IDF (or embeddings as optional extension)"
      - "Build user preference profile by averaging feature vectors of items the user rated highly (>= 4 stars)"
      - "Compute content-based scores as cosine similarity between user profile and candidate item features"
      - "Hybrid score combines CF prediction and content-based score using configurable weighted sum"
      - "Cold-start users (with no CF data) fall back to content-based recommendations using explicit preference input"
      - "Generate explainable recommendations showing top contributing features for each recommendation"
    pitfalls:
      - "TF-IDF on short text (e.g., movie titles) produces poor features—use descriptions or tags"
      - "User profile dominated by a few highly-rated items; consider IDF-weighted profile construction"
      - "Filter bubble: pure content-based only recommends similar items, reducing diversity"
      - "Explanation text that doesn't match actual scoring logic erodes user trust"
      - "Hybrid weight tuning without evaluation data is guesswork"
    concepts:
      - TF-IDF feature extraction
      - User preference profiling
      - Hybrid recommendation strategies (weighted, switching, cascade)
      - Explainability in recommendations
    skills:
      - Text feature extraction with TF-IDF
      - User preference profile construction
      - Score fusion and normalization
      - Generating human-readable explanations
    deliverables:
      - Item feature extractor producing TF-IDF vectors from descriptions, categories, and tags
      - User preference profile builder averaging features of highly-rated items
      - Content-based scorer computing user-profile to item-feature cosine similarity
      - Hybrid combiner fusing CF and content-based scores with configurable weights
      - Cold-start fallback routing new users to content-based recommendations
      - Explanation generator showing top features contributing to each recommendation
    estimated_hours: "6-10"

  - id: recommendation-engine-m4
    name: Offline Evaluation
    description: >-
      Build a rigorous offline evaluation framework. You cannot deploy a
      recommendation system without knowing if it works.
    acceptance_criteria:
      - "Temporal train/test split holds out the most recent 20% of interactions per user for testing"
      - "Precision@K and Recall@K computed at K=5, 10, 20 for all recommendation algorithms"
      - "NDCG@10 computed with graded relevance (rating value as relevance)"
      - "Hit Rate@10 computed as the fraction of users for whom at least one test item appears in top-10"
      - "Coverage metric reports the fraction of catalog items that appear in any user's top-10 recommendations"
      - "Comparison table shows all metrics side-by-side for user-CF, item-CF, FunkSVD, ALS, content-based, and hybrid"
      - "Statistical significance test (paired t-test or bootstrap) determines if hybrid significantly outperforms best baseline"
    pitfalls:
      - "Random train/test split leaks future interactions into training—always use temporal split"
      - "Evaluating only on users with many ratings overstates performance; report results stratified by user activity level"
      - "High precision but low coverage means the system only recommends popular items"
      - "Not computing multiple metrics gives a misleading picture; a system can have high NDCG but low coverage"
      - "Small test sets per user produce high-variance metrics"
    concepts:
      - Temporal train/test splitting
      - Ranking evaluation metrics (Precision@K, Recall@K, NDCG, Hit Rate)
      - Coverage and diversity metrics
      - Statistical significance testing
    skills:
      - Implementing IR-style ranking metrics
      - Temporal data splitting
      - Statistical hypothesis testing
      - Result aggregation and comparison
    deliverables:
      - Temporal train/test splitter holding out recent interactions per user
      - Precision@K and Recall@K calculators
      - NDCG@K calculator with graded relevance
      - Hit Rate@K calculator
      - Coverage and diversity metric calculators
      - Comparison table generator showing all algorithms side-by-side on all metrics
    estimated_hours: "6-8"

  - id: recommendation-engine-m5
    name: Production API & Serving
    description: >-
      Build a recommendation serving API with caching, the two-stage
      retrieval/ranking pattern, and basic monitoring.
    acceptance_criteria:
      - "REST API endpoint returns top-N recommendations for a given user ID with sub-500ms latency"
      - "Two-stage pipeline: fast candidate generation (e.g., precomputed top-200 from CF) followed by hybrid re-ranking"
      - "Precomputed recommendations are cached in-memory or Redis, refreshed on configurable schedule"
      - "New user requests fall back to popularity-based or content-based recommendations"
      - "API logs recommendation requests and latency for monitoring"
      - "Model version is exposed in API response metadata for traceability"
      - "Basic A/B test support routes users deterministically (by user ID hash) to different model versions"
    pitfalls:
      - "Cold cache at startup causes latency spikes; pre-warm cache before accepting traffic"
      - "A/B test user assignment must be deterministic (hash-based) or results are invalid"
      - "Not implementing a fallback for unknown user IDs returns empty results"
      - "Precomputed recommendations become stale if not refreshed after model retraining"
      - "Logging every recommendation without sampling causes storage explosion"
    concepts:
      - Two-stage retrieval and ranking
      - Recommendation caching strategies
      - A/B testing with deterministic assignment
      - Model serving and API design
    skills:
      - REST API design (FastAPI/Flask)
      - Caching with Redis or in-memory stores
      - Deterministic hashing for traffic splitting
      - Latency monitoring and logging
    deliverables:
      - Recommendation API endpoint returning ranked item suggestions for a user
      - Two-stage pipeline with precomputed candidate generation and real-time re-ranking
      - Recommendation cache with configurable TTL and pre-warming
      - Cold-start fallback returning popularity-based recommendations for new users
      - A/B test router splitting users deterministically between model versions
      - Request logger recording user ID, recommendations returned, latency, and model version
    estimated_hours: "10-14"