id: s3-like-object-storage
name: S3-like Object Storage
description: >
  Build an object storage service like Amazon S3 with erasure coding,
  eventual consistency, and virtually unlimited scalability. Implement
  PUT/GET operations, multipart upload, and lifecycle management.

difficulty: expert
estimated_hours: 80-100
domain: world-scale

essence: >
  Distributed object storage with flat namespace, HTTP API, erasure coding for
  durability (11 nines), eventual consistency for availability, and horizontal
  scalability through consistent hashing and metadata sharding.

why_important: >
  S3 stores trillions of objects and is the backbone of cloud storage.
  Understanding object storage architecture, erasure coding, and eventual
  consistency is valuable for cloud infrastructure engineers at $200K-400K+.

learning_outcomes:
  - Implement RESTful object storage API (PUT, GET, DELETE, LIST)
  - Build erasure coding for durability (Reed-Solomon)
  - Implement consistent hashing for data placement
  - Handle eventual consistency across replicas
  - Build multipart upload for large objects
  - Implement lifecycle policies for automatic expiration
  - Handle metadata indexing and prefix-based listing
  - Build rate limiting and access control

skills:
  - Object Storage Design
  - Erasure Coding
  - Consistent Hashing
  - Eventual Consistency
  - Multipart Upload
  - Lifecycle Management
  - Metadata Indexing
  - Access Control

tags:
  - expert
  - object-storage
  - s3
  - erasure-coding
  - distributed-storage
  - cloud

languages:
  recommended:
    - Go
    - Rust
  also_possible:
    - Java
    - Python

resources:
  - name: "Amazon S3 FAQ"
    url: https://aws.amazon.com/s3/faqs/
    type: documentation
  - name: "Ceph Architecture"
    url: https://docs.ceph.com/en/latest/architecture/
    type: documentation
  - name: "MinIO Architecture"
    url: https://min.io/docs/minio/linux/operations/architecture.html
    type: documentation
  - name: "Erasure Coding for Distributed Systems"
    url: https://web.eecs.utk.edu/~jplank/plank/papers/CS-08-627.html
    type: paper

prerequisites:
  - type: skill
    name: Distributed systems fundamentals
  - type: skill
    name: HTTP API design
  - type: skill
    name: Understanding of replication and consistency
  - type: project
    name: distributed-cache or equivalent

milestones:
  - id: s3-storage-m1
    name: Core Object API
    description: >
      Implement the core PUT/GET/DELETE operations for object storage
      with flat namespace.
    acceptance_criteria:
      - PUT /bucket/key stores object with metadata
      - GET /bucket/key retrieves object and metadata
      - DELETE /bucket/key removes object
      - Object metadata includes content-type, size, etag, last-modified
      - ETag is MD5 hash of object content
      - HTTP status codes correct (200, 404, 204, etc.)
      - Range requests supported for partial GET
    pitfalls:
      - Not handling concurrent writes to same key
      - Metadata size limits not enforced
      - Range request edge cases (invalid ranges)
      - Not returning proper error responses
    concepts:
      - Object storage API
      - Flat namespace
      - Metadata management
      - HTTP semantics
    skills:
      - RESTful API
      - Object storage
      - Metadata handling
      - HTTP implementation
    deliverables:
      - PUT/GET/DELETE API
      - Metadata management
      - Range requests
      - Error handling
    estimated_hours: "14-18"

  - id: s3-storage-m2
    name: Erasure Coding
    description: >
      Implement Reed-Solomon erasure coding for durability with
      configurable data/parity shards.
    acceptance_criteria:
      - Objects encoded into K data + M parity shards
      - Can tolerate loss of any M shards without data loss
      - Decoding reconstructs data from any K shards
      - Typical config: 8+4 (tolerates 4 failures, 1.5x overhead)
      - Encoding/decoding benchmarks show reasonable throughput
      - Shards distributed across different failure domains
    pitfalls:
      - Encoding CPU overhead for small objects
      - Partial writes require re-encoding entire object
      - Not distributing shards across failure domains
      - Decoding latency when many shards missing
    concepts:
      - Erasure coding
      - Reed-Solomon
      - Data vs parity shards
      - Failure tolerance
    skills:
      - Erasure coding
      - Reed-Solomon implementation
      - Shard distribution
      - Performance tuning
    deliverables:
      - Reed-Solomon encoder/decoder
      - Configurable K+M
      - Shard distribution
      - Durability calculation
    estimated_hours: "16-20"

  - id: s3-storage-m3
    name: Distributed Placement & Consistent Hashing
    description: >
      Implement consistent hashing for object placement across
      storage nodes with minimal reshuffling on node changes.
    acceptance_criteria:
      - Objects placed on storage nodes via consistent hashing
      - Virtual nodes improve distribution uniformity
      - Node addition/removal moves minimal objects (< 1/N)
      - Replication places copies on distinct nodes
      - Node health monitoring removes failed nodes
      - Rebalancing happens gradually in background
    pitfalls:
      - Hot keys/objects cause load imbalance
      - Not handling node churn gracefully
      - Rebalancing overwhelms network if too aggressive
      - Virtual node count affects distribution quality
    concepts:
      - Consistent hashing
      - Virtual nodes
      - Data placement
      - Rebalancing
    skills:
      - Consistent hashing
      - Placement algorithm
      - Health monitoring
      - Rebalancing
    deliverables:
      - Consistent hashing ring
      - Placement algorithm
      - Health monitoring
      - Rebalancing process
    estimated_hours: "14-18"

  - id: s3-storage-m4
    name: Multipart Upload
    description: >
      Implement multipart upload for reliable large object handling
      with parallel upload support.
    acceptance_criteria:
      - InitiateMultipartUpload creates upload session
      - UploadPart uploads individual parts with part number
      - CompleteMultipartUpload assembles parts into final object
      - AbortMultipartUpload cancels and cleans up parts
      - ListParts shows uploaded parts for incomplete upload
      - Parts uploaded in parallel from different clients
      - At-least-once semantics for part upload
    pitfalls:
      - Incomplete uploads waste storage - need cleanup
      - Part ordering must be maintained
      - Concurrent Complete calls race
      - Part size validation
    concepts:
      - Multipart upload
      - Parallel uploads
      - Upload sessions
      - Part assembly
    skills:
      - Multipart implementation
      - Session management
      - Parallel handling
      - Cleanup policies
    deliverables:
      - Multipart upload API
      - Part management
      - Complete/Abort
      - Cleanup job
    estimated_hours: "12-16"

  - id: s3-storage-m5
    name: Listing & Metadata Index
    description: >
      Implement prefix-based object listing with delimiter support
      for hierarchical navigation.
    acceptance_criteria:
      - ListObjects returns objects with given prefix
      - Delimiter (/) groups objects into "directories"
      - CommonPrefixes returned for delimiter-matched prefixes
      - Pagination with MaxKeys and NextContinuationToken
      - List performance independent of total objects (index-based)
      - Metadata index supports prefix queries efficiently
    pitfalls:
      - Listing slow without proper index
      - Large result sets need pagination
      - Consistency between list and actual objects
      - Delimiter handling edge cases
    concepts:
      - Metadata indexing
      - Prefix queries
      - Pagination
      - Directory emulation
    skills:
      - Index design
      - Query optimization
      - Pagination
      - Hierarchical listing
    deliverables:
      - Metadata index
      - Prefix listing
      - Delimiter support
      - Pagination
    estimated_hours: "12-16"

  - id: s3-storage-m6
    name: Lifecycle Management
    description: >
      Implement lifecycle policies for automatic object expiration,
      tiering, and cleanup.
    acceptance_criteria:
      - Lifecycle rules defined per bucket
      - Expiration rules delete objects after N days
      - Transition rules move objects between storage tiers
      - Incomplete multipart upload cleanup after N days
      - Rules applied daily via background job
      - Rule configuration via API (PutBucketLifecycleConfiguration)
    pitfalls:
      - Lifecycle rules not applied immediately
      - Transition to cheaper storage loses immediate access
      - Not communicating deletion to users
      - Rule evaluation complexity
    concepts:
      - Lifecycle policies
      - Expiration
      - Storage tiering
      - Multipart cleanup
    skills:
      - Lifecycle engine
      - Policy evaluation
      - Background jobs
      - Tier management
    deliverables:
      - Lifecycle policy API
      - Expiration engine
      - Transition support
      - Cleanup jobs
    estimated_hours: "10-14"
