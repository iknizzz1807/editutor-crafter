id: scientific-computing-toolkit
name: Scientific Computing Toolkit
description: >
  Build a high-performance scientific computing library implementing
  BLAS operations, numerical linear algebra, ODE/PDE solvers, and
  sparse matrix operations from scratch.

difficulty: advanced
estimated_hours: 60-80
domain: specialized

essence: >
  Numerically stable algorithms for linear algebra and differential equations,
  cache-optimized matrix operations, sparse matrix storage formats and
  iterative solvers, and understanding floating-point arithmetic precision
  limits and error propagation in scientific computations.

why_important: >
  Scientific computing underpins simulation, ML infrastructure, computational
  finance, and engineering software. Understanding numerical algorithms enables
  work in HPC, computational science, and ML systems at $150K-300K+ for
  computational scientists and HPC engineers.

learning_outcomes:
  - Implement BLAS Level 1, 2, and 3 operations
  - Build numerically stable matrix factorizations (LU, QR, SVD)
  - Implement iterative solvers (Jacobi, Gauss-Seidel, CG, GMRES)
  - Handle sparse matrix formats (CSR, CSC, COO)
  - Build ODE solvers with adaptive step size
  - Implement finite difference PDE solvers
  - Understand floating-point precision and error analysis
  - Optimize for cache efficiency and SIMD

skills:
  - Numerical Linear Algebra
  - BLAS Implementation
  - Sparse Matrix Methods
  - ODE/PDE Solvers
  - Floating-Point Arithmetic
  - Numerical Stability
  - Cache Optimization
  - SIMD Vectorization

tags:
  - advanced
  - blas
  - hpc
  - linear-algebra
  - numerical-methods
  - ode
  - pde
  - scientific-computing

languages:
  recommended:
    - C
    - C++
    - Fortran
  also_possible:
    - Rust
    - Julia

resources:
  - name: "Numerical Recipes"
    url: http://numerical.recipes/
    type: book
  - name: "Matrix Computations (Golub & Van Loan)"
    url: https://www.cs.cornell.edu/cv/GVL4/
    type: book
  - name: "BLAS Technical Forum"
    url: https://www.netlib.org/blas/
    type: documentation
  - name: "SciPy Lecture Notes"
    url: https://scipy-lectures.org/
    type: tutorial

prerequisites:
  - type: skill
    name: Linear algebra (matrices, eigenvalues, factorizations)
  - type: skill
    name: Calculus and differential equations
  - type: skill
    name: C/C++ programming with memory management
  - type: skill
    name: Understanding of floating-point representation

milestones:
  - id: scientific-computing-toolkit-m1
    name: BLAS Level 1 & 2 Operations
    description: >
      Implement basic BLAS operations: vector operations (Level 1)
      and matrix-vector operations (Level 2).
    acceptance_criteria:
      - Level 1: SAXPY (y = a*x + y), DOT product, SCAL (x = a*x), NORM (||x||2)
      - Level 2: SGEMV (y = a*A*x + b*y), SGER (A = a*x*y^T + A), STRMV (x = A*x for triangular A)
      - All operations handle stride correctly for non-contiguous vectors
      - Numerical accuracy verified against reference implementation (error < 1e-6 relative)
      - Performance benchmarked and achieves > 50% of theoretical memory bandwidth
      - Edge cases handled: zero-length vectors, NaN inputs, overflow detection
    pitfalls:
      - Floating-point accumulation error in DOT product; use Kahan or pairwise summation for accuracy
      - Stride handling errors cause incorrect results or out-of-bounds access
      - Not handling NaN/Inf inputs can propagate errors silently
      - Memory bandwidth is the bottleneck for BLAS 1/2; CPU optimization has limited effect
      - Different indexing conventions (0-based vs 1-based) cause confusion with literature
    concepts:
      - BLAS hierarchy and design principles
      - Floating-point accumulation error
      - Memory bandwidth as bottleneck
      - Strided access patterns
    skills:
      - Vector operation implementation
      - Matrix-vector multiplication
      - Stride handling
      - Numerical accuracy verification
    deliverables:
      - Level 1 BLAS functions (SAXPY, DOT, SCAL, NORM)
      - Level 2 BLAS functions (SGEMV, SGER, STRMV)
      - Stride support for all operations
      - Accuracy tests against reference
      - Performance benchmark with bandwidth analysis
    estimated_hours: "10-12"

  - id: scientific-computing-toolkit-m2
    name: BLAS Level 3 & Matrix Factorizations
    description: >
      Implement matrix-matrix operations (BLAS Level 3) and
      numerically stable matrix factorizations.
    acceptance_criteria:
      - Level 3: SGEMM (C = a*A*B + b*C), STRSM (triangular solve), SSYRK (symmetric rank-k update)
      - SGEMM achieves at least 30% of peak FLOPS on single core with proper blocking
      - LU factorization with partial pivoting for solving linear systems Ax = b
      - QR factorization using Householder reflections
      - All factorizations include condition number estimation
      - Determinant computation via LU factorization
    pitfalls:
      - LU without pivoting is numerically unstable; partial pivoting is essential
      - SGEMM blocking size must be tuned for cache; too small or too large hurts performance
      - Householder QR accumulation order affects numerical stability
      - Condition number estimation is approximate; don't rely on it for exact detection
      - Matrix storage order (row-major vs column-major) significantly affects SGEMM performance
    concepts:
      - Cache blocking for matrix operations
      - Pivoting for numerical stability
      - Householder transformations
      - Condition number and ill-conditioning
    skills:
      - Cache-optimized matrix multiplication
      - LU factorization with pivoting
      - QR factorization
      - Condition number estimation
    deliverables:
      - Blocked SGEMM achieving > 30% peak FLOPS
      - LU factorization with partial pivoting
      - QR factorization using Householder
      - Linear system solver using factorizations
      - Condition number estimation
    estimated_hours: "14-16"

  - id: scientific-computing-toolkit-m3
    name: Sparse Matrix Operations
    description: >
      Implement sparse matrix storage formats and iterative
      solvers for large sparse linear systems.
    acceptance_criteria:
      - Sparse formats implemented: COO (coordinate), CSR (compressed sparse row), CSC (compressed sparse column)
      - Format conversion functions between all three formats
      - Sparse matrix-vector multiplication (SpMV) for CSR format
      - Iterative solvers: Jacobi, Gauss-Seidel, Conjugate Gradient (for SPD matrices)
      - Convergence verified on test matrices with known solutions
      - Memory usage is O(nnz) where nnz is number of non-zeros
      - SpMV performance > 50% of memory bandwidth for typical sparse matrices
    pitfalls:
      - CSR row pointer off-by-one errors cause incorrect row boundaries
      - Conjugate Gradient requires symmetric positive definite matrix; fails otherwise
      - Jacobi/Gauss-Seidel convergence depends on matrix properties (diagonal dominance)
      - Sparse format conversion allocates new memory; in-place conversion is complex
      - Zero entries in input data should not be stored; filter them during conversion
    concepts:
      - Sparse matrix storage efficiency
      - Iterative vs direct solvers
      - Convergence criteria and stopping conditions
      - Matrix properties for solver selection
    skills:
      - Sparse format implementation
      - Format conversion algorithms
      - Iterative solver implementation
      - Convergence analysis
    deliverables:
      - COO, CSR, CSC format implementations
      - Format conversion utilities
      - SpMV for CSR format
      - Jacobi and Gauss-Seidel solvers
      - Conjugate Gradient solver
      - Convergence tests on sample matrices
    estimated_hours: "12-14"

  - id: scientific-computing-toolkit-m4
    name: ODE Solvers
    description: >
      Implement ordinary differential equation solvers with
      adaptive step size control for initial value problems.
    acceptance_criteria:
      - Single-step methods: Forward Euler, RK4 (4th-order Runge-Kutta)
      - Adaptive step size control using embedded RK methods (e.g., RK45 Dormand-Prince)
      - Step size adjustment based on local error estimate
      - User-configurable error tolerance (relative and absolute)
      - Stiff ODE detection and warning (explicit methods fail on stiff problems)
      - Verified on standard test problems: harmonic oscillator, Van der Pol, two-body orbit
      - Correct handling of discontinuities in the derivative function
    pitfalls:
      - Forward Euler is only first-order accurate and can be unstable for stiff ODEs
      - Adaptive step size can oscillate if tolerance is too tight or error estimate is noisy
      - RK methods assume smooth derivatives; discontinuities require special handling
      - Stiff ODEs require implicit methods; explicit adaptive methods become extremely slow
      - Relative vs absolute tolerance confusion affects step size selection
    concepts:
      - Single-step vs multi-step methods
      - Order of accuracy and stability
      - Embedded methods for error estimation
      - Stiffness and its implications
    skills:
      - Runge-Kutta implementation
      - Adaptive step size control
      - Error estimation and tolerance
      - Test problem validation
    deliverables:
      - Forward Euler and RK4 implementations
      - RK45 with adaptive step size
      - Error-controlled integrator API
      - Test suite with standard ODE problems
      - Step size vs accuracy analysis
    estimated_hours: "12-14"

  - id: scientific-computing-toolkit-m5
    name: PDE Solvers & Integration
    description: >
      Implement finite difference methods for partial differential
      equations and integrate all components into a unified toolkit.
    acceptance_criteria:
      - 1D heat equation solver using explicit finite difference (FTCS scheme)
      - 1D wave equation solver using explicit central differences
      - Stability analysis: CFL condition verified for explicit schemes
      - Implicit scheme (Crank-Nicolson) for heat equation (unconditionally stable)
      - Sparse linear system assembled from finite difference stencil
      - Uses sparse solver from previous milestone for implicit scheme
      - Unified API for ODE/PDE solvers with consistent configuration
      - Documentation with usage examples for all major components
    pitfalls:
      - Explicit schemes have strict stability limits; violating CFL causes blow-up
      - Crank-Nicolson is unconditionally stable but can have oscillatory transients
      - Boundary condition implementation is error-prone; off-by-one errors common
      - Stencil ordering must match matrix assembly for correct sparse system
      - Time step vs spatial step trade-off affects both stability and accuracy
    concepts:
      - Finite difference discretization
      - Stability analysis (CFL condition)
      - Explicit vs implicit schemes
      - Boundary condition handling
    skills:
      - Finite difference implementation
      - PDE stability analysis
      - Implicit scheme matrix assembly
      - Toolkit integration and API design
    deliverables:
      - 1D heat equation solver (explicit and implicit)
      - 1D wave equation solver
      - CFL stability verification tests
      - Unified toolkit API
      - Documentation and examples
    estimated_hours: "12-14"
