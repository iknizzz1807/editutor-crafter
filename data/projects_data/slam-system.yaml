id: slam-system
name: SLAM System
description: >
  Implement Simultaneous Localization and Mapping for robot navigation,
  including feature extraction, pose estimation, loop closure, and
  map building from sensor data.

difficulty: expert
estimated_hours: 70-90
domain: specialized

essence: >
  Real-time estimation of robot pose and environment map from sensor
  observations, probabilistic state estimation (EKF, particle filters),
  feature matching and tracking, loop closure detection for drift
  correction, and optimization over pose graph for globally consistent maps.

why_important: >
  SLAM is fundamental to autonomous vehicles, drones, AR/VR, and robotics.
  SLAM engineers earn $150K-300K+ at autonomous vehicle companies, robotics
  startups, and tech giants building spatial computing platforms.

learning_outcomes:
  - Implement visual feature extraction and matching (ORB, SIFT)
  - Build pose estimation from feature correspondences
  - Implement Extended Kalman Filter for state estimation
  - Build particle filter SLAM (FastSLAM)
  - Implement loop closure detection and pose graph optimization
  - Build occupancy grid mapping from laser/depth data
  - Implement bundle adjustment for visual SLAM
  - Handle sensor fusion (IMU + camera, laser + odometry)

skills:
  - Feature Extraction
  - Pose Estimation
  - Kalman Filtering
  - Particle Filters
  - Graph Optimization
  - Loop Closure
  - Occupancy Mapping
  - Sensor Fusion

tags:
  - autonomous
  - computer-vision
  - ekf
  - expert
  - mapping
  - robotics
  - slam
  - state-estimation

languages:
  recommended:
    - C++
    - Python
  also_possible:
    - Rust
    - CUDA

resources:
  - name: "Probabilistic Robotics (Thrun et al.)"
    url: https://www.probabilistic-robotics.org/
    type: book
  - name: "SLAM for Dummies"
    url: https://www.cs.rice.edu/~devika/Resources/SLAM_Documentation.pdf
    type: tutorial
  - name: "ORB-SLAM2"
    url: https://github.com/raulmur/ORB_SLAM2
    type: reference
  - name: "GTSAM Documentation"
    url: https://gtsam.org/
    type: library

prerequisites:
  - type: skill
    name: Linear algebra and matrix operations
  - type: skill
    name: Probability and statistics
  - type: skill
    name: Computer vision basics
  - type: skill
    name: C++ or Python proficiency

milestones:
  - id: slam-system-m1
    name: Feature Extraction & Matching
    description: >
      Implement visual feature extraction and matching for
      correspondence finding across frames.
    acceptance_criteria:
      - ORB feature detection extracts keypoints and descriptors
      - Feature matching using descriptor distance (Hamming for ORB)
      - Ratio test or cross-check for outlier rejection
      - RANSAC-based fundamental matrix estimation to filter matches
      - Feature tracking across video frames (optical flow alternative)
      - Handles rotation and scale changes in features
      - Performance: > 30 FPS for 640x480 images with 500+ features
    pitfalls:
      - Too few features in textureless regions causes tracking failure
      - Feature matching without outlier rejection gives many false matches
      - Descriptor distance threshold is scene-dependent; tune carefully
      - Motion blur degrades feature quality; need motion model
      - Scale changes cause feature loss; use scale-invariant features
    concepts:
      - Feature detection and description
      - Descriptor matching strategies
      - Outlier rejection with RANSAC
      - Feature tracking vs matching
    skills:
      - Feature detector implementation
      - Descriptor matching
      - RANSAC usage
      - Performance optimization
    deliverables:
      - ORB feature extractor
      - Feature matcher with ratio test
      - RANSAC outlier filter
      - Feature tracker
      - Performance benchmark
    estimated_hours: "12-14"

  - id: slam-system-m2
    name: Pose Estimation & EKF
    description: >
      Implement pose estimation from feature correspondences and
      Extended Kalman Filter for state estimation.
    acceptance_criteria:
      - Camera pose estimation from 2D-3D correspondences (PnP)
      - Essential matrix estimation from 2D-2D correspondences
      - Motion model for pose prediction (constant velocity)
      - EKF implementation with state (position, orientation, velocity)
      - State prediction and update steps correctly implemented
      - Covariance matrix tracks estimation uncertainty
      - Handles measurement outliers gracefully
      - EKF converges on simulated trajectory with noise
    pitfalls:
      - Quaternion normalization in EKF state; use error-state representation
      - Covariance matrix can become non-positive-definite; use square-root form
      - Linearization errors in EKF accumulate; compare with particle filter
      - PnP requires at least 4 points; degenerate configurations cause failure
      - Gimbal lock with Euler angles; use quaternions or rotation matrices
    concepts:
      - Perspective-n-Point (PnP)
      - Essential matrix geometry
      - Kalman filter prediction/update
      - Error-state Kalman filter
    skills:
      - Camera pose estimation
      - EKF implementation
      - Quaternion handling
      - Covariance management
    deliverables:
      - PnP pose estimator
      - Essential matrix estimator
      - EKF state estimator
      - Motion model predictor
      - Simulation test with ground truth
    estimated_hours: "14-16"

  - id: slam-system-m3
    name: Particle Filter SLAM
    description: >
      Implement FastSLAM using particle filters for robot pose
      and landmark mapping.
    acceptance_criteria:
      - Particle filter represents distribution over robot poses
      - Each particle maintains its own map of landmarks
      - Motion model updates particles based on odometry
      - Observation model weights particles based on landmark matches
      - Resampling prevents particle degeneracy
      - Landmark initialization for new observations
      - Handles at least 100 particles with 50 landmarks in real-time
      - Works with simulated robot navigating 2D environment
    pitfalls:
      - Particle depletion: all particles converge to wrong pose
      - Map size grows unbounded; need landmark management
      - Resampling too often causes particle depletion
      - Motion model noise parameters are critical for performance
      - Data association: assigning observations to correct landmarks
    concepts:
      - Particle filter representation
      - Importance sampling and resampling
      - Per-particle mapping
      - Data association
    skills:
      - Particle filter implementation
      - Motion and observation models
      - Resampling strategies
      - Landmark management
    deliverables:
      - Particle filter framework
      - Motion model for robot
      - Observation model for landmarks
      - Resampling implementation
      - FastSLAM integration
      - 2D navigation simulation
    estimated_hours: "14-16"

  - id: slam-system-m4
    name: Loop Closure & Graph Optimization
    description: >
      Implement loop closure detection for drift correction and
      pose graph optimization for globally consistent maps.
    acceptance_criteria:
      - Loop closure detection using visual place recognition (bag of words)
      - Loop closure candidate verification with geometric consistency
      - Pose graph construction with edges from odometry and loop closures
      - Graph optimization using Gauss-Newton or Levenberg-Marquardt
      - Drift correction propagates through the entire trajectory
      - Handles large trajectories (1000+ poses) efficiently
      - Detects and rejects false loop closures
    pitfalls:
      - False loop closures corrupt the entire map; verify carefully
      - Graph optimization can be slow for large graphs; use sparse methods
      - Place recognition requires training or vocabulary tree
      - Loop closure delay: detecting loop after significant drift
      - Optimization divergence with poor initial estimate
    concepts:
      - Visual place recognition
      - Pose graph representation
      - Nonlinear least squares optimization
      - False positive rejection
    skills:
      - Bag of words for place recognition
      - Pose graph construction
      - Nonlinear optimization
      - Robust loop closure
    deliverables:
      - Loop closure detector
      - Pose graph data structure
      - Graph optimizer (Gauss-Newton)
      - Drift correction demonstration
      - False loop rejection
    estimated_hours: "14-16"

  - id: slam-system-m5
    name: Occupancy Mapping & Sensor Fusion
    description: >
      Build occupancy grid mapping from depth/laser data and
      implement basic sensor fusion.
    acceptance_criteria:
      - Occupancy grid mapping with log-odds representation
      - Ray casting for laser scan integration
      - Inverse sensor model for occupancy updates
      - Map resolution configurable (typical 5-10cm per cell)
      - IMU integration for motion prediction between camera frames
      - Basic visual-inertial odometry: IMU prediction, visual correction
      - Real-time mapping at 10+ Hz for indoor robot navigation
      - Map saving and loading for persistence
    pitfalls:
      - Log-odds overflow; clamp values to prevent numerical issues
      - Dynamic objects cause flickering in occupancy map
      - IMU bias drift requires online estimation
      - Time synchronization between sensors is critical for fusion
      - Map resolution vs memory trade-off for large environments
    concepts:
      - Occupancy grid representation
      - Log-odds probability
      - Inverse sensor model
      - Visual-inertial fusion
    skills:
      - Occupancy mapping
      - Laser/range integration
      - IMU state prediction
      - Multi-sensor fusion
    deliverables:
      - Occupancy grid mapper
      - Laser scan integration
      - IMU motion predictor
      - Visual-inertial odometry
      - Real-time mapping demo
      - Map persistence (save/load)
    estimated_hours: "14-16"
