id: workflow-orchestrator
name: Workflow Orchestrator
description: >-
  DAG-based task scheduling engine with persistent state, dependency resolution,
  distributed execution, retry logic, and monitoring dashboard.
difficulty: advanced
estimated_hours: 84
essence: >-
  Topological ordering of task dependencies in a DAG for scheduling, combined
  with a persistent state machine tracking per-task-instance lifecycle transitions
  (queued → running → success/failed), distributed worker coordination via
  message queues with heartbeat-based failure detection, and transactional state
  persistence enabling idempotent retry logic and crash recovery.
why_important: >-
  Building this teaches distributed systems coordination, task scheduling
  algorithms, persistent state management, and fault-tolerant execution—core
  skills for data engineering platforms, CI/CD systems, and any large-scale
  automation infrastructure.
learning_outcomes:
  - Design DAG-based workflow definitions with dependency validation and cycle detection
  - Implement a persistent state store for task instance lifecycle and DAG run metadata
  - Build a scheduler with cron-based triggers, backfill, and catchup behavior
  - Implement task execution with dependency resolution, retries with exponential backoff, and timeouts
  - Design distributed task distribution with worker health monitoring and task reassignment
  - Build a monitoring dashboard with DAG visualization, log viewing, and manual controls
skills:
  - DAG scheduling
  - Task state machines
  - Persistent state management
  - Distributed execution
  - Failure handling and retries
  - Cron scheduling
  - Monitoring and observability
tags:
  - advanced
  - dags
  - dependencies
  - devops
  - execution
  - orchestration
  - state-management
architecture_doc: architecture-docs/workflow-orchestrator/index.md
languages:
  recommended:
    - Go
    - Python
    - Java
  also_possible:
    - Rust
    - TypeScript
resources:
  - name: Apache Airflow Documentation
    url: https://airflow.apache.org/docs/apache-airflow/stable/index.html
    type: documentation
  - name: DAG Concepts Guide
    url: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html
    type: documentation
  - name: Build an Orchestrator in Go (From Scratch)
    url: https://www.manning.com/books/build-an-orchestrator-in-go-from-scratch
    type: book
  - name: Designing a DAG-Based Workflow Engine from Scratch
    url: https://bugfree.ai/knowledge-hub/designing-a-dag-based-workflow-engine-from-scratch
    type: article
prerequisites:
  - type: skill
    name: Background jobs
  - type: skill
    name: Relational databases
  - type: skill
    name: Process management
  - type: skill
    name: Concurrency fundamentals
milestones:
  - id: workflow-orchestrator-m1
    name: DAG Definition & Validation
    description: >-
      Define workflows as directed acyclic graphs with task dependencies,
      validate graph structure, and support parameterized execution.
    acceptance_criteria:
      - "Task definition includes a unique ID, callable reference, upstream dependency list, retry count, retry delay, and timeout duration"
      - "DAG definition file (YAML or Python DSL) is parsed into an in-memory dependency graph"
      - "Cycle detection using DFS-based topological sort rejects DAGs containing cycles with a clear error message identifying the cycle path"
      - "Unreachable tasks (not connected to any root or leaf) are flagged as warnings during validation"
      - "Task parameters support runtime variable substitution using a template syntax (e.g., '{{ ds }}' for execution date)"
      - "Multiple operator types are supported (at minimum: shell command, Python callable, SQL query)"
      - "DAG file discovery scans a configured directory and loads all valid DAG definitions on startup"
    pitfalls:
      - "Forgetting to validate for cycles before execution leads to infinite loops or deadlocks"
      - "Self-referencing tasks create implicit cycles—validate that no task depends on itself"
      - "Task ID collisions across DAGs cause routing errors—enforce globally unique task identifiers or namespace by DAG ID"
      - "Dynamic dependencies that change at runtime break the static scheduling assumptions—freeze the DAG before execution"
      - "Template variables must be validated at parse time, not at execution time, to catch errors early"
    concepts:
      - Directed Acyclic Graph (DAG) representation with adjacency lists
      - DFS-based cycle detection and topological sort
      - Domain-specific language (DSL) parsing for workflow definitions
      - Task parameterization with template variable substitution
      - Graph serialization formats (YAML, JSON) for persistence
    skills:
      - Graph data structures
      - DSL design and parsing
      - Input validation
      - Template engines
    deliverables:
      - Task class with ID, callable, dependencies, retry config, and timeout
      - DAG class with dependency graph and topological ordering
      - DAG parser loading definitions from YAML or Python DSL files
      - Cycle detection rejecting invalid DAGs with cycle path reporting
      - Operator types for shell, Python, and SQL tasks
      - DAG file discovery and auto-loading from configured directory
    estimated_hours: 12

  - id: workflow-orchestrator-m2
    name: Persistent State Store
    description: >-
      Implement a persistent database-backed state store for DAG runs, task
      instances, and scheduler metadata. This is the backbone that enables
      crash recovery and distributed coordination.
    acceptance_criteria:
      - "DAG Run table persists run ID, DAG ID, execution date, state (running/success/failed), and timestamps"
      - "Task Instance table persists task ID, DAG run ID, state (none/queued/running/success/failed/upstream_failed/skipped), attempt number, start time, end time, and worker assignment"
      - "Task instance state transitions are enforced by the state store (e.g., cannot transition from SUCCESS to RUNNING)"
      - "All state mutations are transactional—concurrent updates to the same task instance are serialized via row-level locking or optimistic concurrency"
      - "State store survives process restart—scheduler can reconstruct in-progress DAG runs from the database on startup"
      - "Query API returns task instances by state (e.g., all RUNNING tasks, all FAILED tasks for a DAG run)"
      - "Schema migration support allows adding new columns without data loss"
    pitfalls:
      - "Using in-memory state without persistence means all progress is lost on scheduler crash"
      - "Missing transactional guarantees on state transitions leads to inconsistent states under concurrent access"
      - "Not indexing state columns causes slow queries when scanning for ready tasks across thousands of instances"
      - "Storing large task logs in the state store bloats the database—store log references, not log content"
      - "Schema migrations must be backward compatible to support rolling upgrades"
    concepts:
      - Task instance state machine with well-defined transitions
      - Transactional state persistence for crash recovery
      - Optimistic concurrency control for distributed schedulers
      - Database indexing for efficient state queries
      - Schema migration patterns for evolving state stores
    skills:
      - Relational database schema design
      - State machine implementation
      - Transaction management
      - Database indexing
      - Schema migration
    deliverables:
      - Database schema for DAG runs, task instances, and scheduler metadata
      - Task instance state machine enforcing valid transitions with error on invalid transition
      - Transactional state mutation API with optimistic concurrency or row-level locking
      - State recovery on startup reconstructing in-progress DAG runs from database
      - Query API for task instances by state, DAG run, and time range
      - Schema migration mechanism for future state store changes
    estimated_hours: 12

  - id: workflow-orchestrator-m3
    name: Scheduler
    description: >-
      Schedule DAG runs based on cron expressions or manual triggers, with
      backfill and catchup support.
    acceptance_criteria:
      - "Cron-based scheduling triggers DAG runs at intervals defined by standard 5-field cron expressions"
      - "Manual trigger creates a DAG run with the current time (or specified time) as execution date"
      - "Scheduler loop runs at a configurable interval (default 10 seconds) checking for pending schedules"
      - "Backfill creates DAG runs for all missed intervals within a specified historical date range"
      - "Catchup configuration (per DAG) controls whether past missed runs are auto-triggered on DAG enablement"
      - "Maximum concurrent DAG runs limit (per DAG) prevents resource exhaustion from overlapping runs"
      - "Timezone handling correctly computes next run time across DST transitions"
    pitfalls:
      - "Timezone conversions are error-prone, especially across DST boundaries—use UTC internally and convert only at display time"
      - "Not limiting concurrent DAG runs causes resource exhaustion and cascading failures"
      - "Cron parsing edge cases (Feb 29, day-of-week vs day-of-month conflicts) must be handled correctly"
      - "Backfill without idempotency creates duplicate runs if triggered twice—use execution date as deduplication key"
      - "Scheduler drift from long-running scheduling loops causes missed or delayed triggers"
    concepts:
      - Cron expression parsing and next-fire-time calculation
      - Backfill operations for historical data processing
      - Catchup behavior for missed scheduled runs
      - Timezone handling with UTC normalization
      - Scheduler heartbeat and leader election for HA
    skills:
      - Cron expression parsing
      - Time arithmetic and timezone handling
      - Scheduler loop design
      - Concurrency limiting
    deliverables:
      - Cron parser computing next execution time from cron expression
      - Scheduling loop checking for pending runs at configurable intervals
      - Manual trigger API creating ad-hoc DAG runs
      - Backfill command creating runs for a historical date range
      - Catchup configuration per DAG controlling auto-trigger of past runs
      - Concurrent DAG run limit enforcement
    estimated_hours: 12

  - id: workflow-orchestrator-m4
    name: Task Execution Engine
    description: >-
      Execute tasks respecting dependency order, with concurrent execution of
      independent branches, retries with exponential backoff, and timeouts.
    acceptance_criteria:
      - "Tasks execute only after all upstream dependencies have reached SUCCESS state (verified via state store query)"
      - "Independent tasks (no mutual dependency) execute concurrently up to a configurable parallelism limit"
      - "Failed tasks retry with exponential backoff (delay = base_delay * 2^attempt) up to configurable max retries"
      - "Task timeout kills execution that exceeds configured duration and transitions task to FAILED state"
      - "Upstream failure propagates UPSTREAM_FAILED state to all downstream tasks without executing them"
      - "Inter-task data passing allows a task to publish small key-value data accessible by downstream tasks"
      - "Task execution is idempotent—re-executing a task with the same inputs produces the same side effects (enforced by design convention, documented)"
    pitfalls:
      - "Not propagating upstream failures causes downstream tasks to hang waiting for a dependency that will never succeed"
      - "Unbounded parallelism causes resource exhaustion—always enforce a concurrency limit"
      - "Retry without exponential backoff can overwhelm downstream services"
      - "Task timeout must use process-level kill (SIGKILL after SIGTERM grace period), not cooperative timeout, for reliability"
      - "Inter-task data passing must have size limits to prevent memory abuse (e.g., max 1MB per key)"
    concepts:
      - Topological sort determines valid execution order for scheduling
      - Task instance state machine governs lifecycle transitions
      - Exponential backoff reduces retry pressure on failing systems
      - Process-level timeout ensures runaway tasks are killed
      - Trigger rules define when a task should execute based on upstream states
    skills:
      - Topological sort execution
      - Parallel task execution with thread/goroutine pools
      - Retry and backoff strategies
      - Process management and timeout enforcement
      - State machine transitions
    deliverables:
      - Dependency resolution engine querying state store for upstream task completion
      - Parallel executor running independent tasks concurrently within parallelism limit
      - Retry handler with exponential backoff and max attempt tracking
      - Timeout enforcer killing tasks exceeding configured duration
      - Upstream failure propagation marking downstream tasks as UPSTREAM_FAILED
      - Inter-task data passing with size limits
    estimated_hours: 14

  - id: workflow-orchestrator-m5
    name: Distributed Worker Pool
    description: >-
      Distribute task execution across multiple worker processes with
      heartbeat-based health monitoring and failed task reassignment.
    acceptance_criteria:
      - "Workers pull tasks from a message queue (or are assigned tasks by the scheduler) and execute them in isolated processes"
      - "Worker heartbeat reports liveness at configurable intervals; scheduler marks workers as dead after missing 3 consecutive heartbeats"
      - "Tasks assigned to dead workers are re-queued and reassigned to healthy workers"
      - "Task results (success/failure, stdout, stderr, return data) are persisted to the state store before worker acknowledges completion"
      - "Worker pool supports at least 3 concurrent workers with even task distribution (measured via integration test)"
      - "Resource slot management limits the number of concurrent tasks per worker based on configured capacity"
    pitfalls:
      - "Not persisting task results before acknowledging completion causes data loss if worker crashes after ack"
      - "Network partitions between scheduler and workers can cause duplicate execution—use state store as source of truth"
      - "Heartbeat interval too aggressive causes false positives; too lenient delays failure detection"
      - "Worker crashes during task execution leave tasks in RUNNING state indefinitely—scheduler must time out and reassign"
      - "Task priority starvation: ensure high-priority tasks are dequeued before low-priority ones"
    concepts:
      - Message queue-based task distribution decouples scheduler from executor
      - Heartbeat mechanism for distributed health monitoring
      - Task result persistence before acknowledgment for durability
      - Worker pool scaling and resource management
      - At-least-once task execution with state store deduplication
    skills:
      - Message queue integration
      - Worker process management
      - Heartbeat implementation
      - Distributed failure detection
      - Resource management
    deliverables:
      - Worker process pulling and executing tasks from a queue
      - Heartbeat mechanism with configurable interval and dead-worker detection
      - Dead worker task reassignment re-queuing orphaned tasks
      - Task result persistence writing output and status to state store
      - Worker pool with configurable capacity and concurrent task limits
      - Integration test demonstrating 3-worker task distribution
    estimated_hours: 14

  - id: workflow-orchestrator-m6
    name: Web UI & Monitoring
    description: >-
      Build a monitoring dashboard for workflow visualization, log viewing,
      manual controls, and failure alerting.
    acceptance_criteria:
      - "DAG list view displays all registered DAGs with their schedule, last run status, and next scheduled run"
      - "DAG graph view renders task dependencies as a visual DAG with nodes colored by current task instance state"
      - "Task log viewer displays captured stdout and stderr for each task instance attempt"
      - "Manual trigger button creates a new DAG run from the UI with optional parameter overrides"
      - "Run history view shows past DAG runs with start time, duration, and outcome, paginated for large histories"
      - "Failure alerting sends notifications (webhook or email) when a task fails after exhausting all retries"
    pitfalls:
      - "Not implementing pagination for large DAG/run lists causes UI freezes and backend memory issues"
      - "Stale data in dashboards misleads operators—use polling or SSE for near-real-time updates"
      - "Log streaming without backpressure causes browser memory leaks—implement virtual scrolling or log truncation"
      - "Missing authentication on manual trigger and clear operations allows unauthorized workflow manipulation"
      - "DAG graph rendering with many tasks (>100) requires layout algorithms; naive rendering is unusable"
    concepts:
      - Server-Sent Events (SSE) or WebSocket for real-time status updates
      - DAG visualization with graph layout algorithms
      - Log streaming and aggregation from distributed workers
      - RESTful API for workflow management operations
      - Webhook-based alerting for operational notifications
    skills:
      - Web UI development
      - Real-time data updates
      - Log aggregation
      - API design
      - Alerting integration
    deliverables:
      - DAG list view with schedule, status, and pagination
      - DAG graph visualization with state-colored task nodes
      - Task log viewer displaying stdout/stderr per task instance
      - Manual trigger and task state clear controls
      - Run history timeline with duration and outcome
      - Failure alerting via webhook or email on final task failure
    estimated_hours: 20